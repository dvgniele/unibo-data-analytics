{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 1038893\n",
    "\n",
    "fix_random(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "root = \"../../data/ml-25m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Acquisition\n",
    "def get_data_from_csv(file: str, nrows=None):\n",
    "    if nrows:\n",
    "        df = pd.read_csv(f\"{root}/{file}\", nrows=nrows)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{root}/{file}\")\n",
    "    print(f\"Loaded ml-25m data: {root}/{file}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_from_csv(nrows=None):\n",
    "    path = \"ratings.csv\"\n",
    "\n",
    "    data = get_data_from_csv(path, nrows)\n",
    "    # data = get_data_from_csv(path)\n",
    "\n",
    "    data.drop(\"timestamp\", axis=1, inplace=True)\n",
    "    # todo: drop user id\n",
    "    #data.drop(\"userId\", axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ml-25m data: ../../data/ml-25m/ratings.csv\n",
      "          userId  movieId  rating\n",
      "0              1      296     5.0\n",
      "1              1      306     3.5\n",
      "2              1      307     5.0\n",
      "3              1      665     5.0\n",
      "4              1      899     3.5\n",
      "...          ...      ...     ...\n",
      "25000090  162541    50872     4.5\n",
      "25000091  162541    55768     2.5\n",
      "25000092  162541    56176     2.0\n",
      "25000093  162541    58559     4.0\n",
      "25000094  162541    63876     5.0\n",
      "\n",
      "[25000095 rows x 3 columns]\n",
      "Loaded ml-25m data: ../../data/ml-25m/genome-scores.csv\n",
      "          movieId  tagId  relevance\n",
      "0               1      1    0.02875\n",
      "1               1      2    0.02375\n",
      "2               1      3    0.06250\n",
      "3               1      4    0.07575\n",
      "4               1      5    0.14075\n",
      "...           ...    ...        ...\n",
      "15584443   206499   1124    0.11000\n",
      "15584444   206499   1125    0.04850\n",
      "15584445   206499   1126    0.01325\n",
      "15584446   206499   1127    0.14025\n",
      "15584447   206499   1128    0.03350\n",
      "\n",
      "[15584448 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_tag_relevances_from_csv(nrows=None):\n",
    "    path = \"genome-scores.csv\"\n",
    "\n",
    "    return get_data_from_csv(path, nrows)\n",
    "genome_scores_path = \"genome-scores.csv\"\n",
    "ratings_path = \"ratings.csv\"\n",
    "ratings = get_ratings_from_csv()\n",
    "print(ratings)\n",
    "genome_scores = get_tag_relevances_from_csv()\n",
    "print(genome_scores)\n",
    "# films = get_data_from_csv(f\"{root}/{ratings}\")[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA VISUALIZATION\n",
    "\n",
    "            # # Fill in missing values with zeros\n",
    "            # X.fillna(0, inplace=True)\n",
    "\n",
    "# FARE TEST CON AVG, STD_DEV\n",
    "def addColumnOperation(ratings,X):\n",
    "     # Compute the mean rating for each user\n",
    "     count_rating = ratings.groupby('movieId', as_index=False)['rating'].count()\n",
    "     std= ratings.groupby('movieId', as_index=False)['rating'].std()\n",
    "     std.fillna(0, inplace=True)\n",
    "     min_ratings= ratings.groupby('movieId', as_index=False)['rating'].min()\n",
    "     max_ratings= ratings.groupby('movieId', as_index=False)['rating'].max()\n",
    "     median= ratings.groupby('movieId', as_index=False)['rating'].median()\n",
    "     operation = pd.DataFrame({'movieId':count_rating['movieId'],'count_rating': count_rating['rating'], 'std': std['rating'], 'min': min_ratings['rating'], 'max': max_ratings['rating'], 'median': median['rating']}) \n",
    "     X = pd.merge(X, operation, on='movieId')\n",
    "     X.drop(\"movieId\", axis=1, inplace=True)\n",
    "     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "           \n",
    "\n",
    "class TabNet:\n",
    "    def __init__(self, ratings, relevance, seed=42,width_values = 8, steps = 3, learning_rate = 2e-2):\n",
    "        self.aug = RegressionSMOTE(p=0.2)\n",
    "        #! df['rating'] = df['rating'].astype('float16')\n",
    "\n",
    "        # Reduce genome-score size\n",
    "\n",
    "        # Pivot the relevance DataFrame to create a matrix of tag relevance scores for each movie\n",
    "        relevance_matrix = relevance.pivot_table(index='movieId', columns='tagId', values='relevance', fill_value=0)\n",
    "        # Merge the ratings and relevance data\n",
    "        mean_ratings = ratings.groupby('movieId', as_index=False)['rating'].mean()\n",
    "        X = mean_ratings.merge(relevance_matrix, on='movieId')\n",
    "        #X = addColumnOperation(ratings,X)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        ratings = None  \n",
    "        train = X\n",
    "        # mescolare le righe del DataFrame\n",
    "        X = X.sample(frac=1,random_state = seed).reset_index(drop=True)\n",
    "        \n",
    "        if \"Set\" not in train.columns:\n",
    "            train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "\n",
    "        features = [ col for col in train.columns if col not in [\"rating\", \"Set\"]]\n",
    "        target = \"rating\"\n",
    "        \n",
    "        train_indices = train[train.Set==\"train\"].index\n",
    "        valid_indices = train[train.Set==\"valid\"].index\n",
    "        test_indices = train[train.Set==\"test\"].index\n",
    "\n",
    "        self.X_train = train[features].values[train_indices]\n",
    "        self.y_train = train[target].values[train_indices].reshape(-1, 1)\n",
    "\n",
    "        self.X_valid = train[features].values[valid_indices]\n",
    "        self.y_valid = train[target].values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "        self.X_test = train[features].values[test_indices]\n",
    "        self.y_test = train[target].values[test_indices].reshape(-1, 1)\n",
    "\n",
    "        pca = PCA()\n",
    "        pca.fit(self.X_train)\n",
    "        self.X_train = pca.transform(self.X_train)\n",
    "        self.X_test = pca.transform(self.X_test)\n",
    "        self.X_valid = pca.transform(self.X_valid)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.model = TabNetRegressor(n_d = width_values, n_a = width_values , n_steps = steps, optimizer_params = dict(lr=learning_rate), seed=seed, device_name=\"cuda\")  \n",
    "        else:\n",
    "            self.model = TabNetRegressor(n_d = width_values, n_a = width_values , n_steps = steps, optimizer_params = dict(lr=learning_rate), seed=seed)  \n",
    "\n",
    "\n",
    "\n",
    "    def train(self,max_epochs = 150,batchsize = 1024):\n",
    "        self.model.fit(\n",
    "            X_train=self.X_train, y_train=self.y_train,\n",
    "            eval_set=[(self.X_train,self.y_train), (self.X_valid, self.y_valid)],\n",
    "            eval_name=['train', 'valid'],\n",
    "            eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "            max_epochs=max_epochs,\n",
    "            patience=20,\n",
    "            batch_size=batchsize, virtual_batch_size=1024,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            augmentations=self.aug, #aug\n",
    "        ) \n",
    "\n",
    "    def test(self):\n",
    "        # Predict the labels of the test set: y_pred\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "        # Compute the mean squared error\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        rmse = mean_squared_error(self.y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(self.y_test, y_pred)\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "\n",
    "        print(f\"MSE: {mse} RMSE: {rmse} R2: {r2} MAE: {mae}\")\n",
    "        print(\"=====================================\")\n",
    "        return r2,self.model\n",
    "    \n",
    "    def load(self,model):\n",
    "        self.model =TabNetRegressor()\n",
    "        self.model.load_model(model)\n",
    "    \n",
    "    def save(self,root,name):\n",
    "        self.model.save_model(f\"{root}/{name}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "model = TabNet(ratings, genome_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.32546 | train_rmsle: 0.10813 | train_mae: 1.15939 | train_rmse: 1.24502 | train_mse: 1.55007 | valid_rmsle: 0.10874 | valid_mae: 1.16269 | valid_rmse: 1.24962 | valid_mse: 1.56156 |  0:00:03s\n",
      "epoch 1  | loss: 0.4776  | train_rmsle: 0.08417 | train_mae: 1.03262 | train_rmse: 1.12258 | train_mse: 1.26019 | valid_rmsle: 0.08456 | valid_mae: 1.03525 | valid_rmse: 1.12655 | valid_mse: 1.26912 |  0:00:05s\n",
      "epoch 2  | loss: 0.26254 | train_rmsle: 0.05061 | train_mae: 0.80979 | train_rmse: 0.90305 | train_mse: 0.8155  | valid_rmsle: 0.05066 | valid_mae: 0.81017 | valid_rmse: 0.90563 | valid_mse: 0.82017 |  0:00:07s\n",
      "epoch 3  | loss: 0.24059 | train_rmsle: 0.04156 | train_mae: 0.73385 | train_rmse: 0.82765 | train_mse: 0.68501 | valid_rmsle: 0.04161 | valid_mae: 0.73426 | valid_rmse: 0.83054 | valid_mse: 0.6898  |  0:00:08s\n",
      "epoch 4  | loss: 0.23195 | train_rmsle: 0.02344 | train_mae: 0.54354 | train_rmse: 0.63364 | train_mse: 0.4015  | valid_rmsle: 0.02315 | valid_mae: 0.54428 | valid_rmse: 0.63368 | valid_mse: 0.40155 |  0:00:10s\n",
      "epoch 5  | loss: 0.23992 | train_rmsle: 0.02539 | train_mae: 0.56818 | train_rmse: 0.65898 | train_mse: 0.43426 | valid_rmsle: 0.02532 | valid_mae: 0.57023 | valid_rmse: 0.66157 | valid_mse: 0.43767 |  0:00:12s\n",
      "epoch 6  | loss: 0.22143 | train_rmsle: 0.01441 | train_mae: 0.40657 | train_rmse: 0.49215 | train_mse: 0.24221 | valid_rmsle: 0.01376 | valid_mae: 0.4029  | valid_rmse: 0.48561 | valid_mse: 0.23582 |  0:00:13s\n",
      "epoch 7  | loss: 0.19207 | train_rmsle: 0.0109  | train_mae: 0.34853 | train_rmse: 0.42457 | train_mse: 0.18026 | valid_rmsle: 0.01039 | valid_mae: 0.34677 | valid_rmse: 0.4216  | valid_mse: 0.17775 |  0:00:15s\n",
      "epoch 8  | loss: 0.15937 | train_rmsle: 0.01171 | train_mae: 0.36466 | train_rmse: 0.43613 | train_mse: 0.19021 | valid_rmsle: 0.01087 | valid_mae: 0.35392 | valid_rmse: 0.42414 | valid_mse: 0.17989 |  0:00:16s\n",
      "epoch 9  | loss: 0.13789 | train_rmsle: 0.00813 | train_mae: 0.28707 | train_rmse: 0.3584  | train_mse: 0.12845 | valid_rmsle: 0.00734 | valid_mae: 0.27263 | valid_rmse: 0.34329 | valid_mse: 0.11785 |  0:00:18s\n",
      "epoch 10 | loss: 0.12635 | train_rmsle: 0.00785 | train_mae: 0.27595 | train_rmse: 0.35066 | train_mse: 0.12296 | valid_rmsle: 0.00717 | valid_mae: 0.26434 | valid_rmse: 0.33833 | valid_mse: 0.11446 |  0:00:20s\n",
      "epoch 11 | loss: 0.11606 | train_rmsle: 0.00699 | train_mae: 0.25904 | train_rmse: 0.33108 | train_mse: 0.10961 | valid_rmsle: 0.00638 | valid_mae: 0.24995 | valid_rmse: 0.32004 | valid_mse: 0.10242 |  0:00:21s\n",
      "epoch 12 | loss: 0.11324 | train_rmsle: 0.0078  | train_mae: 0.27968 | train_rmse: 0.35475 | train_mse: 0.12585 | valid_rmsle: 0.00724 | valid_mae: 0.2727  | valid_rmse: 0.34751 | valid_mse: 0.12076 |  0:00:23s\n",
      "epoch 13 | loss: 0.10947 | train_rmsle: 0.00736 | train_mae: 0.26751 | train_rmse: 0.34011 | train_mse: 0.11567 | valid_rmsle: 0.00677 | valid_mae: 0.25856 | valid_rmse: 0.32941 | valid_mse: 0.10851 |  0:00:25s\n",
      "epoch 14 | loss: 0.10505 | train_rmsle: 0.0065  | train_mae: 0.24607 | train_rmse: 0.31754 | train_mse: 0.10083 | valid_rmsle: 0.00598 | valid_mae: 0.23952 | valid_rmse: 0.30813 | valid_mse: 0.09495 |  0:00:26s\n",
      "epoch 15 | loss: 0.10751 | train_rmsle: 0.00648 | train_mae: 0.24655 | train_rmse: 0.31775 | train_mse: 0.10097 | valid_rmsle: 0.006   | valid_mae: 0.24094 | valid_rmse: 0.30994 | valid_mse: 0.09606 |  0:00:28s\n",
      "epoch 16 | loss: 0.1003  | train_rmsle: 0.00633 | train_mae: 0.24265 | train_rmse: 0.31226 | train_mse: 0.09751 | valid_rmsle: 0.00582 | valid_mae: 0.23422 | valid_rmse: 0.30269 | valid_mse: 0.09162 |  0:00:29s\n",
      "epoch 17 | loss: 0.09528 | train_rmsle: 0.00634 | train_mae: 0.24361 | train_rmse: 0.3135  | train_mse: 0.09828 | valid_rmsle: 0.00581 | valid_mae: 0.23479 | valid_rmse: 0.30268 | valid_mse: 0.09161 |  0:00:31s\n",
      "epoch 18 | loss: 0.09358 | train_rmsle: 0.00668 | train_mae: 0.2549  | train_rmse: 0.32323 | train_mse: 0.10448 | valid_rmsle: 0.00612 | valid_mae: 0.24424 | valid_rmse: 0.31224 | valid_mse: 0.09749 |  0:00:33s\n",
      "epoch 19 | loss: 0.09467 | train_rmsle: 0.00589 | train_mae: 0.22849 | train_rmse: 0.2989  | train_mse: 0.08934 | valid_rmsle: 0.00546 | valid_mae: 0.22253 | valid_rmse: 0.29118 | valid_mse: 0.08479 |  0:00:34s\n",
      "epoch 20 | loss: 0.09337 | train_rmsle: 0.00607 | train_mae: 0.23797 | train_rmse: 0.30608 | train_mse: 0.09368 | valid_rmsle: 0.00548 | valid_mae: 0.22833 | valid_rmse: 0.29435 | valid_mse: 0.08664 |  0:00:36s\n",
      "epoch 21 | loss: 0.08989 | train_rmsle: 0.00582 | train_mae: 0.22882 | train_rmse: 0.29779 | train_mse: 0.08868 | valid_rmsle: 0.0053  | valid_mae: 0.22136 | valid_rmse: 0.28808 | valid_mse: 0.08299 |  0:00:37s\n",
      "epoch 22 | loss: 0.08656 | train_rmsle: 0.00593 | train_mae: 0.23574 | train_rmse: 0.3026  | train_mse: 0.09157 | valid_rmsle: 0.0054  | valid_mae: 0.22774 | valid_rmse: 0.29218 | valid_mse: 0.08537 |  0:00:39s\n",
      "epoch 23 | loss: 0.08684 | train_rmsle: 0.00557 | train_mae: 0.22615 | train_rmse: 0.29195 | train_mse: 0.08524 | valid_rmsle: 0.00511 | valid_mae: 0.22021 | valid_rmse: 0.2834  | valid_mse: 0.08032 |  0:00:41s\n",
      "epoch 24 | loss: 0.08578 | train_rmsle: 0.00555 | train_mae: 0.22741 | train_rmse: 0.29202 | train_mse: 0.08528 | valid_rmsle: 0.00519 | valid_mae: 0.2236  | valid_rmse: 0.28564 | valid_mse: 0.08159 |  0:00:42s\n",
      "epoch 25 | loss: 0.08484 | train_rmsle: 0.00542 | train_mae: 0.219   | train_rmse: 0.28606 | train_mse: 0.08183 | valid_rmsle: 0.00503 | valid_mae: 0.21588 | valid_rmse: 0.28    | valid_mse: 0.0784  |  0:00:43s\n",
      "epoch 26 | loss: 0.08264 | train_rmsle: 0.00524 | train_mae: 0.21627 | train_rmse: 0.28139 | train_mse: 0.07918 | valid_rmsle: 0.00493 | valid_mae: 0.21438 | valid_rmse: 0.27676 | valid_mse: 0.0766  |  0:00:44s\n",
      "epoch 27 | loss: 0.08391 | train_rmsle: 0.00523 | train_mae: 0.22048 | train_rmse: 0.28369 | train_mse: 0.08048 | valid_rmsle: 0.00513 | valid_mae: 0.22422 | valid_rmse: 0.28511 | valid_mse: 0.08129 |  0:00:46s\n",
      "epoch 28 | loss: 0.08365 | train_rmsle: 0.00553 | train_mae: 0.23237 | train_rmse: 0.29443 | train_mse: 0.08669 | valid_rmsle: 0.00532 | valid_mae: 0.23557 | valid_rmse: 0.2936  | valid_mse: 0.0862  |  0:00:47s\n",
      "epoch 29 | loss: 0.08339 | train_rmsle: 0.0051  | train_mae: 0.21299 | train_rmse: 0.27768 | train_mse: 0.0771  | valid_rmsle: 0.00499 | valid_mae: 0.21583 | valid_rmse: 0.27947 | valid_mse: 0.0781  |  0:00:48s\n",
      "epoch 30 | loss: 0.07962 | train_rmsle: 0.00503 | train_mae: 0.21495 | train_rmse: 0.27748 | train_mse: 0.077   | valid_rmsle: 0.00495 | valid_mae: 0.2185  | valid_rmse: 0.27964 | valid_mse: 0.0782  |  0:00:49s\n",
      "epoch 31 | loss: 0.07878 | train_rmsle: 0.00526 | train_mae: 0.22764 | train_rmse: 0.28798 | train_mse: 0.08293 | valid_rmsle: 0.00519 | valid_mae: 0.23246 | valid_rmse: 0.28972 | valid_mse: 0.08394 |  0:00:50s\n",
      "epoch 32 | loss: 0.07707 | train_rmsle: 0.00491 | train_mae: 0.20862 | train_rmse: 0.2729  | train_mse: 0.07447 | valid_rmsle: 0.00491 | valid_mae: 0.21605 | valid_rmse: 0.27878 | valid_mse: 0.07772 |  0:00:52s\n",
      "epoch 33 | loss: 0.07733 | train_rmsle: 0.00484 | train_mae: 0.20969 | train_rmse: 0.27188 | train_mse: 0.07392 | valid_rmsle: 0.00489 | valid_mae: 0.21648 | valid_rmse: 0.27864 | valid_mse: 0.07764 |  0:00:53s\n",
      "epoch 34 | loss: 0.08016 | train_rmsle: 0.00475 | train_mae: 0.20849 | train_rmse: 0.27003 | train_mse: 0.07292 | valid_rmsle: 0.00486 | valid_mae: 0.21809 | valid_rmse: 0.27863 | valid_mse: 0.07763 |  0:00:55s\n",
      "epoch 35 | loss: 0.07635 | train_rmsle: 0.00477 | train_mae: 0.2062  | train_rmse: 0.2687  | train_mse: 0.0722  | valid_rmsle: 0.00498 | valid_mae: 0.2176  | valid_rmse: 0.28068 | valid_mse: 0.07878 |  0:00:56s\n",
      "epoch 36 | loss: 0.07622 | train_rmsle: 0.00509 | train_mae: 0.21099 | train_rmse: 0.27582 | train_mse: 0.07607 | valid_rmsle: 0.00515 | valid_mae: 0.22186 | valid_rmse: 0.28414 | valid_mse: 0.08074 |  0:00:58s\n",
      "epoch 37 | loss: 0.07459 | train_rmsle: 0.00481 | train_mae: 0.20543 | train_rmse: 0.27016 | train_mse: 0.07299 | valid_rmsle: 0.00502 | valid_mae: 0.21597 | valid_rmse: 0.2814  | valid_mse: 0.07919 |  0:00:59s\n",
      "epoch 38 | loss: 0.07677 | train_rmsle: 0.00453 | train_mae: 0.20439 | train_rmse: 0.26392 | train_mse: 0.06965 | valid_rmsle: 0.00484 | valid_mae: 0.21742 | valid_rmse: 0.27787 | valid_mse: 0.07721 |  0:01:01s\n",
      "epoch 39 | loss: 0.07333 | train_rmsle: 0.00499 | train_mae: 0.22573 | train_rmse: 0.28262 | train_mse: 0.07988 | valid_rmsle: 0.00527 | valid_mae: 0.23653 | valid_rmse: 0.29329 | valid_mse: 0.08602 |  0:01:03s\n",
      "epoch 40 | loss: 0.07203 | train_rmsle: 0.00451 | train_mae: 0.20373 | train_rmse: 0.26314 | train_mse: 0.06924 | valid_rmsle: 0.00486 | valid_mae: 0.21605 | valid_rmse: 0.27787 | valid_mse: 0.07721 |  0:01:04s\n",
      "epoch 41 | loss: 0.07095 | train_rmsle: 0.00454 | train_mae: 0.20846 | train_rmse: 0.2656  | train_mse: 0.07055 | valid_rmsle: 0.00484 | valid_mae: 0.22117 | valid_rmse: 0.27926 | valid_mse: 0.07798 |  0:01:06s\n",
      "epoch 42 | loss: 0.07044 | train_rmsle: 0.00431 | train_mae: 0.19741 | train_rmse: 0.25609 | train_mse: 0.06558 | valid_rmsle: 0.00469 | valid_mae: 0.21309 | valid_rmse: 0.27302 | valid_mse: 0.07454 |  0:01:07s\n",
      "epoch 43 | loss: 0.0674  | train_rmsle: 0.0044  | train_mae: 0.20753 | train_rmse: 0.26324 | train_mse: 0.06929 | valid_rmsle: 0.00497 | valid_mae: 0.22657 | valid_rmse: 0.28458 | valid_mse: 0.08098 |  0:01:09s\n",
      "epoch 44 | loss: 0.06784 | train_rmsle: 0.00413 | train_mae: 0.18994 | train_rmse: 0.24966 | train_mse: 0.06233 | valid_rmsle: 0.00469 | valid_mae: 0.21124 | valid_rmse: 0.27287 | valid_mse: 0.07446 |  0:01:10s\n",
      "epoch 45 | loss: 0.06584 | train_rmsle: 0.00401 | train_mae: 0.19228 | train_rmse: 0.24856 | train_mse: 0.06178 | valid_rmsle: 0.00473 | valid_mae: 0.21607 | valid_rmse: 0.27576 | valid_mse: 0.07605 |  0:01:12s\n",
      "epoch 46 | loss: 0.06384 | train_rmsle: 0.00392 | train_mae: 0.1884  | train_rmse: 0.24545 | train_mse: 0.06025 | valid_rmsle: 0.0047  | valid_mae: 0.21392 | valid_rmse: 0.27514 | valid_mse: 0.0757  |  0:01:14s\n",
      "epoch 47 | loss: 0.06463 | train_rmsle: 0.00394 | train_mae: 0.19161 | train_rmse: 0.2467  | train_mse: 0.06086 | valid_rmsle: 0.0046  | valid_mae: 0.21345 | valid_rmse: 0.27251 | valid_mse: 0.07426 |  0:01:15s\n",
      "epoch 48 | loss: 0.06448 | train_rmsle: 0.00406 | train_mae: 0.19792 | train_rmse: 0.25218 | train_mse: 0.06359 | valid_rmsle: 0.00475 | valid_mae: 0.21964 | valid_rmse: 0.27801 | valid_mse: 0.07729 |  0:01:17s\n",
      "epoch 49 | loss: 0.06847 | train_rmsle: 0.00401 | train_mae: 0.19711 | train_rmse: 0.25099 | train_mse: 0.06299 | valid_rmsle: 0.00482 | valid_mae: 0.22221 | valid_rmse: 0.27989 | valid_mse: 0.07834 |  0:01:19s\n",
      "epoch 50 | loss: 0.06331 | train_rmsle: 0.00364 | train_mae: 0.17843 | train_rmse: 0.23472 | train_mse: 0.05509 | valid_rmsle: 0.00436 | valid_mae: 0.20499 | valid_rmse: 0.26439 | valid_mse: 0.0699  |  0:01:20s\n",
      "epoch 51 | loss: 0.05992 | train_rmsle: 0.00368 | train_mae: 0.17824 | train_rmse: 0.23551 | train_mse: 0.05546 | valid_rmsle: 0.00432 | valid_mae: 0.20137 | valid_rmse: 0.26275 | valid_mse: 0.06904 |  0:01:22s\n",
      "epoch 52 | loss: 0.05934 | train_rmsle: 0.00366 | train_mae: 0.18065 | train_rmse: 0.23678 | train_mse: 0.05606 | valid_rmsle: 0.00438 | valid_mae: 0.20411 | valid_rmse: 0.26609 | valid_mse: 0.0708  |  0:01:23s\n",
      "epoch 53 | loss: 0.06331 | train_rmsle: 0.00367 | train_mae: 0.17985 | train_rmse: 0.23556 | train_mse: 0.05549 | valid_rmsle: 0.00426 | valid_mae: 0.19925 | valid_rmse: 0.26028 | valid_mse: 0.06775 |  0:01:25s\n",
      "epoch 54 | loss: 0.06333 | train_rmsle: 0.0039  | train_mae: 0.18403 | train_rmse: 0.24417 | train_mse: 0.05962 | valid_rmsle: 0.00451 | valid_mae: 0.20768 | valid_rmse: 0.27009 | valid_mse: 0.07295 |  0:01:26s\n",
      "epoch 55 | loss: 0.06308 | train_rmsle: 0.00348 | train_mae: 0.17539 | train_rmse: 0.23132 | train_mse: 0.05351 | valid_rmsle: 0.00416 | valid_mae: 0.20097 | valid_rmse: 0.2594  | valid_mse: 0.06729 |  0:01:28s\n",
      "epoch 56 | loss: 0.0564  | train_rmsle: 0.00332 | train_mae: 0.17188 | train_rmse: 0.22601 | train_mse: 0.05108 | valid_rmsle: 0.00409 | valid_mae: 0.19823 | valid_rmse: 0.25822 | valid_mse: 0.06668 |  0:01:30s\n",
      "epoch 57 | loss: 0.05648 | train_rmsle: 0.00323 | train_mae: 0.17114 | train_rmse: 0.22406 | train_mse: 0.05021 | valid_rmsle: 0.00394 | valid_mae: 0.19664 | valid_rmse: 0.25408 | valid_mse: 0.06456 |  0:01:31s\n",
      "epoch 58 | loss: 0.0532  | train_rmsle: 0.00347 | train_mae: 0.1702  | train_rmse: 0.22707 | train_mse: 0.05156 | valid_rmsle: 0.00407 | valid_mae: 0.19603 | valid_rmse: 0.25565 | valid_mse: 0.06536 |  0:01:33s\n",
      "epoch 59 | loss: 0.05374 | train_rmsle: 0.00366 | train_mae: 0.1729  | train_rmse: 0.23278 | train_mse: 0.05419 | valid_rmsle: 0.00413 | valid_mae: 0.19496 | valid_rmse: 0.25679 | valid_mse: 0.06594 |  0:01:34s\n",
      "epoch 60 | loss: 0.05374 | train_rmsle: 0.00299 | train_mae: 0.16567 | train_rmse: 0.21626 | train_mse: 0.04677 | valid_rmsle: 0.0037  | valid_mae: 0.19249 | valid_rmse: 0.2474  | valid_mse: 0.06121 |  0:01:36s\n",
      "epoch 61 | loss: 0.04912 | train_rmsle: 0.00313 | train_mae: 0.16447 | train_rmse: 0.21941 | train_mse: 0.04814 | valid_rmsle: 0.00379 | valid_mae: 0.19279 | valid_rmse: 0.24953 | valid_mse: 0.06227 |  0:01:38s\n",
      "epoch 62 | loss: 0.04846 | train_rmsle: 0.00269 | train_mae: 0.15637 | train_rmse: 0.20581 | train_mse: 0.04236 | valid_rmsle: 0.00344 | valid_mae: 0.18749 | valid_rmse: 0.23928 | valid_mse: 0.05725 |  0:01:39s\n",
      "epoch 63 | loss: 0.04682 | train_rmsle: 0.00257 | train_mae: 0.1527  | train_rmse: 0.20178 | train_mse: 0.04072 | valid_rmsle: 0.00344 | valid_mae: 0.18608 | valid_rmse: 0.24051 | valid_mse: 0.05785 |  0:01:41s\n",
      "epoch 64 | loss: 0.0457  | train_rmsle: 0.00265 | train_mae: 0.15964 | train_rmse: 0.20714 | train_mse: 0.04291 | valid_rmsle: 0.00347 | valid_mae: 0.19164 | valid_rmse: 0.24163 | valid_mse: 0.05838 |  0:01:42s\n",
      "epoch 65 | loss: 0.04589 | train_rmsle: 0.00238 | train_mae: 0.1461  | train_rmse: 0.19364 | train_mse: 0.0375  | valid_rmsle: 0.00344 | valid_mae: 0.18461 | valid_rmse: 0.23936 | valid_mse: 0.05729 |  0:01:44s\n",
      "epoch 66 | loss: 0.04329 | train_rmsle: 0.0025  | train_mae: 0.15679 | train_rmse: 0.20293 | train_mse: 0.04118 | valid_rmsle: 0.0035  | valid_mae: 0.19044 | valid_rmse: 0.2441  | valid_mse: 0.05959 |  0:01:45s\n",
      "epoch 67 | loss: 0.04115 | train_rmsle: 0.00233 | train_mae: 0.14409 | train_rmse: 0.19149 | train_mse: 0.03667 | valid_rmsle: 0.00341 | valid_mae: 0.18155 | valid_rmse: 0.24095 | valid_mse: 0.05806 |  0:01:47s\n",
      "epoch 68 | loss: 0.04182 | train_rmsle: 0.00226 | train_mae: 0.14667 | train_rmse: 0.19223 | train_mse: 0.03695 | valid_rmsle: 0.00323 | valid_mae: 0.18027 | valid_rmse: 0.23545 | valid_mse: 0.05544 |  0:01:49s\n",
      "epoch 69 | loss: 0.04067 | train_rmsle: 0.00209 | train_mae: 0.13699 | train_rmse: 0.18285 | train_mse: 0.03344 | valid_rmsle: 0.00305 | valid_mae: 0.17274 | valid_rmse: 0.22783 | valid_mse: 0.05191 |  0:01:50s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.05191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05210912650785237 RMSE: 0.2282742353132573 R2: 0.7693329755640941 MAE: 0.17691617550273947\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_70.pt.zip\n",
      "New best model: 512_8_3_0.02_70 with r2: 0.7693329755640941\n",
      "[2/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.32546 | train_rmsle: 0.10813 | train_mae: 1.15939 | train_rmse: 1.24502 | train_mse: 1.55007 | valid_rmsle: 0.10874 | valid_mae: 1.16269 | valid_rmse: 1.24962 | valid_mse: 1.56156 |  0:00:01s\n",
      "epoch 1  | loss: 0.4776  | train_rmsle: 0.08417 | train_mae: 1.03262 | train_rmse: 1.12258 | train_mse: 1.26019 | valid_rmsle: 0.08456 | valid_mae: 1.03525 | valid_rmse: 1.12655 | valid_mse: 1.26912 |  0:00:03s\n",
      "epoch 2  | loss: 0.26254 | train_rmsle: 0.05061 | train_mae: 0.80979 | train_rmse: 0.90305 | train_mse: 0.8155  | valid_rmsle: 0.05066 | valid_mae: 0.81017 | valid_rmse: 0.90563 | valid_mse: 0.82017 |  0:00:04s\n",
      "epoch 3  | loss: 0.24059 | train_rmsle: 0.04156 | train_mae: 0.73385 | train_rmse: 0.82765 | train_mse: 0.68501 | valid_rmsle: 0.04161 | valid_mae: 0.73426 | valid_rmse: 0.83054 | valid_mse: 0.6898  |  0:00:06s\n",
      "epoch 4  | loss: 0.23195 | train_rmsle: 0.02344 | train_mae: 0.54354 | train_rmse: 0.63364 | train_mse: 0.4015  | valid_rmsle: 0.02315 | valid_mae: 0.54428 | valid_rmse: 0.63368 | valid_mse: 0.40155 |  0:00:08s\n",
      "epoch 5  | loss: 0.23992 | train_rmsle: 0.02539 | train_mae: 0.56818 | train_rmse: 0.65898 | train_mse: 0.43426 | valid_rmsle: 0.02532 | valid_mae: 0.57023 | valid_rmse: 0.66157 | valid_mse: 0.43767 |  0:00:09s\n",
      "epoch 6  | loss: 0.22143 | train_rmsle: 0.01441 | train_mae: 0.40657 | train_rmse: 0.49215 | train_mse: 0.24221 | valid_rmsle: 0.01376 | valid_mae: 0.4029  | valid_rmse: 0.48561 | valid_mse: 0.23582 |  0:00:11s\n",
      "epoch 7  | loss: 0.19207 | train_rmsle: 0.0109  | train_mae: 0.34853 | train_rmse: 0.42457 | train_mse: 0.18026 | valid_rmsle: 0.01039 | valid_mae: 0.34677 | valid_rmse: 0.4216  | valid_mse: 0.17775 |  0:00:12s\n",
      "epoch 8  | loss: 0.15937 | train_rmsle: 0.01171 | train_mae: 0.36466 | train_rmse: 0.43613 | train_mse: 0.19021 | valid_rmsle: 0.01087 | valid_mae: 0.35392 | valid_rmse: 0.42414 | valid_mse: 0.17989 |  0:00:14s\n",
      "epoch 9  | loss: 0.13789 | train_rmsle: 0.00813 | train_mae: 0.28707 | train_rmse: 0.3584  | train_mse: 0.12845 | valid_rmsle: 0.00734 | valid_mae: 0.27263 | valid_rmse: 0.34329 | valid_mse: 0.11785 |  0:00:15s\n",
      "epoch 10 | loss: 0.12635 | train_rmsle: 0.00785 | train_mae: 0.27595 | train_rmse: 0.35066 | train_mse: 0.12296 | valid_rmsle: 0.00717 | valid_mae: 0.26434 | valid_rmse: 0.33833 | valid_mse: 0.11446 |  0:00:16s\n",
      "epoch 11 | loss: 0.11606 | train_rmsle: 0.00699 | train_mae: 0.25904 | train_rmse: 0.33108 | train_mse: 0.10961 | valid_rmsle: 0.00638 | valid_mae: 0.24995 | valid_rmse: 0.32004 | valid_mse: 0.10242 |  0:00:18s\n",
      "epoch 12 | loss: 0.11324 | train_rmsle: 0.0078  | train_mae: 0.27968 | train_rmse: 0.35475 | train_mse: 0.12585 | valid_rmsle: 0.00724 | valid_mae: 0.2727  | valid_rmse: 0.34751 | valid_mse: 0.12076 |  0:00:19s\n",
      "epoch 13 | loss: 0.10947 | train_rmsle: 0.00736 | train_mae: 0.26751 | train_rmse: 0.34011 | train_mse: 0.11567 | valid_rmsle: 0.00677 | valid_mae: 0.25856 | valid_rmse: 0.32941 | valid_mse: 0.10851 |  0:00:21s\n",
      "epoch 14 | loss: 0.10505 | train_rmsle: 0.0065  | train_mae: 0.24607 | train_rmse: 0.31754 | train_mse: 0.10083 | valid_rmsle: 0.00598 | valid_mae: 0.23952 | valid_rmse: 0.30813 | valid_mse: 0.09495 |  0:00:22s\n",
      "epoch 15 | loss: 0.10751 | train_rmsle: 0.00648 | train_mae: 0.24655 | train_rmse: 0.31775 | train_mse: 0.10097 | valid_rmsle: 0.006   | valid_mae: 0.24094 | valid_rmse: 0.30994 | valid_mse: 0.09606 |  0:00:24s\n",
      "epoch 16 | loss: 0.1003  | train_rmsle: 0.00633 | train_mae: 0.24265 | train_rmse: 0.31226 | train_mse: 0.09751 | valid_rmsle: 0.00582 | valid_mae: 0.23422 | valid_rmse: 0.30269 | valid_mse: 0.09162 |  0:00:26s\n",
      "epoch 17 | loss: 0.09528 | train_rmsle: 0.00634 | train_mae: 0.24361 | train_rmse: 0.3135  | train_mse: 0.09828 | valid_rmsle: 0.00581 | valid_mae: 0.23479 | valid_rmse: 0.30268 | valid_mse: 0.09161 |  0:00:27s\n",
      "epoch 18 | loss: 0.09358 | train_rmsle: 0.00668 | train_mae: 0.2549  | train_rmse: 0.32323 | train_mse: 0.10448 | valid_rmsle: 0.00612 | valid_mae: 0.24424 | valid_rmse: 0.31224 | valid_mse: 0.09749 |  0:00:29s\n",
      "epoch 19 | loss: 0.09467 | train_rmsle: 0.00589 | train_mae: 0.22849 | train_rmse: 0.2989  | train_mse: 0.08934 | valid_rmsle: 0.00546 | valid_mae: 0.22253 | valid_rmse: 0.29118 | valid_mse: 0.08479 |  0:00:30s\n",
      "epoch 20 | loss: 0.09337 | train_rmsle: 0.00607 | train_mae: 0.23797 | train_rmse: 0.30608 | train_mse: 0.09368 | valid_rmsle: 0.00548 | valid_mae: 0.22833 | valid_rmse: 0.29435 | valid_mse: 0.08664 |  0:00:32s\n",
      "epoch 21 | loss: 0.08989 | train_rmsle: 0.00582 | train_mae: 0.22882 | train_rmse: 0.29779 | train_mse: 0.08868 | valid_rmsle: 0.0053  | valid_mae: 0.22136 | valid_rmse: 0.28808 | valid_mse: 0.08299 |  0:00:34s\n",
      "epoch 22 | loss: 0.08656 | train_rmsle: 0.00593 | train_mae: 0.23574 | train_rmse: 0.3026  | train_mse: 0.09157 | valid_rmsle: 0.0054  | valid_mae: 0.22774 | valid_rmse: 0.29218 | valid_mse: 0.08537 |  0:00:35s\n",
      "epoch 23 | loss: 0.08684 | train_rmsle: 0.00557 | train_mae: 0.22615 | train_rmse: 0.29195 | train_mse: 0.08524 | valid_rmsle: 0.00511 | valid_mae: 0.22021 | valid_rmse: 0.2834  | valid_mse: 0.08032 |  0:00:37s\n",
      "epoch 24 | loss: 0.08578 | train_rmsle: 0.00555 | train_mae: 0.22741 | train_rmse: 0.29202 | train_mse: 0.08528 | valid_rmsle: 0.00519 | valid_mae: 0.2236  | valid_rmse: 0.28564 | valid_mse: 0.08159 |  0:00:38s\n",
      "epoch 25 | loss: 0.08484 | train_rmsle: 0.00542 | train_mae: 0.219   | train_rmse: 0.28606 | train_mse: 0.08183 | valid_rmsle: 0.00503 | valid_mae: 0.21588 | valid_rmse: 0.28    | valid_mse: 0.0784  |  0:00:40s\n",
      "epoch 26 | loss: 0.08264 | train_rmsle: 0.00524 | train_mae: 0.21627 | train_rmse: 0.28139 | train_mse: 0.07918 | valid_rmsle: 0.00493 | valid_mae: 0.21438 | valid_rmse: 0.27676 | valid_mse: 0.0766  |  0:00:42s\n",
      "epoch 27 | loss: 0.08391 | train_rmsle: 0.00523 | train_mae: 0.22048 | train_rmse: 0.28369 | train_mse: 0.08048 | valid_rmsle: 0.00513 | valid_mae: 0.22422 | valid_rmse: 0.28511 | valid_mse: 0.08129 |  0:00:43s\n",
      "epoch 28 | loss: 0.08365 | train_rmsle: 0.00553 | train_mae: 0.23237 | train_rmse: 0.29443 | train_mse: 0.08669 | valid_rmsle: 0.00532 | valid_mae: 0.23557 | valid_rmse: 0.2936  | valid_mse: 0.0862  |  0:00:45s\n",
      "epoch 29 | loss: 0.08339 | train_rmsle: 0.0051  | train_mae: 0.21299 | train_rmse: 0.27768 | train_mse: 0.0771  | valid_rmsle: 0.00499 | valid_mae: 0.21583 | valid_rmse: 0.27947 | valid_mse: 0.0781  |  0:00:47s\n",
      "epoch 30 | loss: 0.07962 | train_rmsle: 0.00503 | train_mae: 0.21495 | train_rmse: 0.27748 | train_mse: 0.077   | valid_rmsle: 0.00495 | valid_mae: 0.2185  | valid_rmse: 0.27964 | valid_mse: 0.0782  |  0:00:48s\n",
      "epoch 31 | loss: 0.07878 | train_rmsle: 0.00526 | train_mae: 0.22764 | train_rmse: 0.28798 | train_mse: 0.08293 | valid_rmsle: 0.00519 | valid_mae: 0.23246 | valid_rmse: 0.28972 | valid_mse: 0.08394 |  0:00:50s\n",
      "epoch 32 | loss: 0.07707 | train_rmsle: 0.00491 | train_mae: 0.20862 | train_rmse: 0.2729  | train_mse: 0.07447 | valid_rmsle: 0.00491 | valid_mae: 0.21605 | valid_rmse: 0.27878 | valid_mse: 0.07772 |  0:00:51s\n",
      "epoch 33 | loss: 0.07733 | train_rmsle: 0.00484 | train_mae: 0.20969 | train_rmse: 0.27188 | train_mse: 0.07392 | valid_rmsle: 0.00489 | valid_mae: 0.21648 | valid_rmse: 0.27864 | valid_mse: 0.07764 |  0:00:53s\n",
      "epoch 34 | loss: 0.08016 | train_rmsle: 0.00475 | train_mae: 0.20849 | train_rmse: 0.27003 | train_mse: 0.07292 | valid_rmsle: 0.00486 | valid_mae: 0.21809 | valid_rmse: 0.27863 | valid_mse: 0.07763 |  0:00:54s\n",
      "epoch 35 | loss: 0.07635 | train_rmsle: 0.00477 | train_mae: 0.2062  | train_rmse: 0.2687  | train_mse: 0.0722  | valid_rmsle: 0.00498 | valid_mae: 0.2176  | valid_rmse: 0.28068 | valid_mse: 0.07878 |  0:00:56s\n",
      "epoch 36 | loss: 0.07622 | train_rmsle: 0.00509 | train_mae: 0.21099 | train_rmse: 0.27582 | train_mse: 0.07607 | valid_rmsle: 0.00515 | valid_mae: 0.22186 | valid_rmse: 0.28414 | valid_mse: 0.08074 |  0:00:57s\n",
      "epoch 37 | loss: 0.07459 | train_rmsle: 0.00481 | train_mae: 0.20543 | train_rmse: 0.27016 | train_mse: 0.07299 | valid_rmsle: 0.00502 | valid_mae: 0.21597 | valid_rmse: 0.2814  | valid_mse: 0.07919 |  0:00:59s\n",
      "epoch 38 | loss: 0.07677 | train_rmsle: 0.00453 | train_mae: 0.20439 | train_rmse: 0.26392 | train_mse: 0.06965 | valid_rmsle: 0.00484 | valid_mae: 0.21742 | valid_rmse: 0.27787 | valid_mse: 0.07721 |  0:01:00s\n",
      "epoch 39 | loss: 0.07333 | train_rmsle: 0.00499 | train_mae: 0.22573 | train_rmse: 0.28262 | train_mse: 0.07988 | valid_rmsle: 0.00527 | valid_mae: 0.23653 | valid_rmse: 0.29329 | valid_mse: 0.08602 |  0:01:02s\n",
      "epoch 40 | loss: 0.07203 | train_rmsle: 0.00451 | train_mae: 0.20373 | train_rmse: 0.26314 | train_mse: 0.06924 | valid_rmsle: 0.00486 | valid_mae: 0.21605 | valid_rmse: 0.27787 | valid_mse: 0.07721 |  0:01:03s\n",
      "epoch 41 | loss: 0.07095 | train_rmsle: 0.00454 | train_mae: 0.20846 | train_rmse: 0.2656  | train_mse: 0.07055 | valid_rmsle: 0.00484 | valid_mae: 0.22117 | valid_rmse: 0.27926 | valid_mse: 0.07798 |  0:01:05s\n",
      "epoch 42 | loss: 0.07044 | train_rmsle: 0.00431 | train_mae: 0.19741 | train_rmse: 0.25609 | train_mse: 0.06558 | valid_rmsle: 0.00469 | valid_mae: 0.21309 | valid_rmse: 0.27302 | valid_mse: 0.07454 |  0:01:06s\n",
      "epoch 43 | loss: 0.0674  | train_rmsle: 0.0044  | train_mae: 0.20753 | train_rmse: 0.26324 | train_mse: 0.06929 | valid_rmsle: 0.00497 | valid_mae: 0.22657 | valid_rmse: 0.28458 | valid_mse: 0.08098 |  0:01:08s\n",
      "epoch 44 | loss: 0.06784 | train_rmsle: 0.00413 | train_mae: 0.18994 | train_rmse: 0.24966 | train_mse: 0.06233 | valid_rmsle: 0.00469 | valid_mae: 0.21124 | valid_rmse: 0.27287 | valid_mse: 0.07446 |  0:01:09s\n",
      "epoch 45 | loss: 0.06584 | train_rmsle: 0.00401 | train_mae: 0.19228 | train_rmse: 0.24856 | train_mse: 0.06178 | valid_rmsle: 0.00473 | valid_mae: 0.21607 | valid_rmse: 0.27576 | valid_mse: 0.07605 |  0:01:11s\n",
      "epoch 46 | loss: 0.06384 | train_rmsle: 0.00392 | train_mae: 0.1884  | train_rmse: 0.24545 | train_mse: 0.06025 | valid_rmsle: 0.0047  | valid_mae: 0.21392 | valid_rmse: 0.27514 | valid_mse: 0.0757  |  0:01:13s\n",
      "epoch 47 | loss: 0.06463 | train_rmsle: 0.00394 | train_mae: 0.19161 | train_rmse: 0.2467  | train_mse: 0.06086 | valid_rmsle: 0.0046  | valid_mae: 0.21345 | valid_rmse: 0.27251 | valid_mse: 0.07426 |  0:01:14s\n",
      "epoch 48 | loss: 0.06448 | train_rmsle: 0.00406 | train_mae: 0.19792 | train_rmse: 0.25218 | train_mse: 0.06359 | valid_rmsle: 0.00475 | valid_mae: 0.21964 | valid_rmse: 0.27801 | valid_mse: 0.07729 |  0:01:16s\n",
      "epoch 49 | loss: 0.06847 | train_rmsle: 0.00401 | train_mae: 0.19711 | train_rmse: 0.25099 | train_mse: 0.06299 | valid_rmsle: 0.00482 | valid_mae: 0.22221 | valid_rmse: 0.27989 | valid_mse: 0.07834 |  0:01:18s\n",
      "epoch 50 | loss: 0.06331 | train_rmsle: 0.00364 | train_mae: 0.17843 | train_rmse: 0.23472 | train_mse: 0.05509 | valid_rmsle: 0.00436 | valid_mae: 0.20499 | valid_rmse: 0.26439 | valid_mse: 0.0699  |  0:01:19s\n",
      "epoch 51 | loss: 0.05992 | train_rmsle: 0.00368 | train_mae: 0.17824 | train_rmse: 0.23551 | train_mse: 0.05546 | valid_rmsle: 0.00432 | valid_mae: 0.20137 | valid_rmse: 0.26275 | valid_mse: 0.06904 |  0:01:21s\n",
      "epoch 52 | loss: 0.05934 | train_rmsle: 0.00366 | train_mae: 0.18065 | train_rmse: 0.23678 | train_mse: 0.05606 | valid_rmsle: 0.00438 | valid_mae: 0.20411 | valid_rmse: 0.26609 | valid_mse: 0.0708  |  0:01:22s\n",
      "epoch 53 | loss: 0.06331 | train_rmsle: 0.00367 | train_mae: 0.17985 | train_rmse: 0.23556 | train_mse: 0.05549 | valid_rmsle: 0.00426 | valid_mae: 0.19925 | valid_rmse: 0.26028 | valid_mse: 0.06775 |  0:01:24s\n",
      "epoch 54 | loss: 0.06333 | train_rmsle: 0.0039  | train_mae: 0.18403 | train_rmse: 0.24417 | train_mse: 0.05962 | valid_rmsle: 0.00451 | valid_mae: 0.20768 | valid_rmse: 0.27009 | valid_mse: 0.07295 |  0:01:26s\n",
      "epoch 55 | loss: 0.06308 | train_rmsle: 0.00348 | train_mae: 0.17539 | train_rmse: 0.23132 | train_mse: 0.05351 | valid_rmsle: 0.00416 | valid_mae: 0.20097 | valid_rmse: 0.2594  | valid_mse: 0.06729 |  0:01:27s\n",
      "epoch 56 | loss: 0.0564  | train_rmsle: 0.00332 | train_mae: 0.17188 | train_rmse: 0.22601 | train_mse: 0.05108 | valid_rmsle: 0.00409 | valid_mae: 0.19823 | valid_rmse: 0.25822 | valid_mse: 0.06668 |  0:01:29s\n",
      "epoch 57 | loss: 0.05648 | train_rmsle: 0.00323 | train_mae: 0.17114 | train_rmse: 0.22406 | train_mse: 0.05021 | valid_rmsle: 0.00394 | valid_mae: 0.19664 | valid_rmse: 0.25408 | valid_mse: 0.06456 |  0:01:30s\n",
      "epoch 58 | loss: 0.0532  | train_rmsle: 0.00347 | train_mae: 0.1702  | train_rmse: 0.22707 | train_mse: 0.05156 | valid_rmsle: 0.00407 | valid_mae: 0.19603 | valid_rmse: 0.25565 | valid_mse: 0.06536 |  0:01:32s\n",
      "epoch 59 | loss: 0.05374 | train_rmsle: 0.00366 | train_mae: 0.1729  | train_rmse: 0.23278 | train_mse: 0.05419 | valid_rmsle: 0.00413 | valid_mae: 0.19496 | valid_rmse: 0.25679 | valid_mse: 0.06594 |  0:01:33s\n",
      "epoch 60 | loss: 0.05374 | train_rmsle: 0.00299 | train_mae: 0.16567 | train_rmse: 0.21626 | train_mse: 0.04677 | valid_rmsle: 0.0037  | valid_mae: 0.19249 | valid_rmse: 0.2474  | valid_mse: 0.06121 |  0:01:35s\n",
      "epoch 61 | loss: 0.04912 | train_rmsle: 0.00313 | train_mae: 0.16447 | train_rmse: 0.21941 | train_mse: 0.04814 | valid_rmsle: 0.00379 | valid_mae: 0.19279 | valid_rmse: 0.24953 | valid_mse: 0.06227 |  0:01:37s\n",
      "epoch 62 | loss: 0.04846 | train_rmsle: 0.00269 | train_mae: 0.15637 | train_rmse: 0.20581 | train_mse: 0.04236 | valid_rmsle: 0.00344 | valid_mae: 0.18749 | valid_rmse: 0.23928 | valid_mse: 0.05725 |  0:01:38s\n",
      "epoch 63 | loss: 0.04682 | train_rmsle: 0.00257 | train_mae: 0.1527  | train_rmse: 0.20178 | train_mse: 0.04072 | valid_rmsle: 0.00344 | valid_mae: 0.18608 | valid_rmse: 0.24051 | valid_mse: 0.05785 |  0:01:40s\n",
      "epoch 64 | loss: 0.0457  | train_rmsle: 0.00265 | train_mae: 0.15964 | train_rmse: 0.20714 | train_mse: 0.04291 | valid_rmsle: 0.00347 | valid_mae: 0.19164 | valid_rmse: 0.24163 | valid_mse: 0.05838 |  0:01:42s\n",
      "epoch 65 | loss: 0.04589 | train_rmsle: 0.00238 | train_mae: 0.1461  | train_rmse: 0.19364 | train_mse: 0.0375  | valid_rmsle: 0.00344 | valid_mae: 0.18461 | valid_rmse: 0.23936 | valid_mse: 0.05729 |  0:01:43s\n",
      "epoch 66 | loss: 0.04329 | train_rmsle: 0.0025  | train_mae: 0.15679 | train_rmse: 0.20293 | train_mse: 0.04118 | valid_rmsle: 0.0035  | valid_mae: 0.19044 | valid_rmse: 0.2441  | valid_mse: 0.05959 |  0:01:45s\n",
      "epoch 67 | loss: 0.04115 | train_rmsle: 0.00233 | train_mae: 0.14409 | train_rmse: 0.19149 | train_mse: 0.03667 | valid_rmsle: 0.00341 | valid_mae: 0.18155 | valid_rmse: 0.24095 | valid_mse: 0.05806 |  0:01:46s\n",
      "epoch 68 | loss: 0.04182 | train_rmsle: 0.00226 | train_mae: 0.14667 | train_rmse: 0.19223 | train_mse: 0.03695 | valid_rmsle: 0.00323 | valid_mae: 0.18027 | valid_rmse: 0.23545 | valid_mse: 0.05544 |  0:01:48s\n",
      "epoch 69 | loss: 0.04067 | train_rmsle: 0.00209 | train_mae: 0.13699 | train_rmse: 0.18285 | train_mse: 0.03344 | valid_rmsle: 0.00305 | valid_mae: 0.17274 | valid_rmse: 0.22783 | valid_mse: 0.05191 |  0:01:49s\n",
      "epoch 70 | loss: 0.0395  | train_rmsle: 0.00204 | train_mae: 0.1359  | train_rmse: 0.18081 | train_mse: 0.03269 | valid_rmsle: 0.00305 | valid_mae: 0.17504 | valid_rmse: 0.22908 | valid_mse: 0.05248 |  0:01:51s\n",
      "epoch 71 | loss: 0.03807 | train_rmsle: 0.00242 | train_mae: 0.1599  | train_rmse: 0.20401 | train_mse: 0.04162 | valid_rmsle: 0.00341 | valid_mae: 0.19395 | valid_rmse: 0.24553 | valid_mse: 0.06028 |  0:01:52s\n",
      "epoch 72 | loss: 0.04005 | train_rmsle: 0.00219 | train_mae: 0.14342 | train_rmse: 0.18932 | train_mse: 0.03584 | valid_rmsle: 0.00304 | valid_mae: 0.1774  | valid_rmse: 0.22922 | valid_mse: 0.05254 |  0:01:53s\n",
      "epoch 73 | loss: 0.03809 | train_rmsle: 0.00212 | train_mae: 0.14786 | train_rmse: 0.19032 | train_mse: 0.03622 | valid_rmsle: 0.00314 | valid_mae: 0.18202 | valid_rmse: 0.23305 | valid_mse: 0.05431 |  0:01:55s\n",
      "epoch 74 | loss: 0.03986 | train_rmsle: 0.00219 | train_mae: 0.15195 | train_rmse: 0.19349 | train_mse: 0.03744 | valid_rmsle: 0.00312 | valid_mae: 0.18345 | valid_rmse: 0.23304 | valid_mse: 0.05431 |  0:01:56s\n",
      "epoch 75 | loss: 0.04368 | train_rmsle: 0.00197 | train_mae: 0.14139 | train_rmse: 0.18502 | train_mse: 0.03423 | valid_rmsle: 0.00301 | valid_mae: 0.1799  | valid_rmse: 0.23037 | valid_mse: 0.05307 |  0:01:58s\n",
      "epoch 76 | loss: 0.03534 | train_rmsle: 0.00182 | train_mae: 0.13024 | train_rmse: 0.17474 | train_mse: 0.03053 | valid_rmsle: 0.00283 | valid_mae: 0.16821 | valid_rmse: 0.22345 | valid_mse: 0.04993 |  0:01:59s\n",
      "epoch 77 | loss: 0.03722 | train_rmsle: 0.00195 | train_mae: 0.14006 | train_rmse: 0.17939 | train_mse: 0.03218 | valid_rmsle: 0.00304 | valid_mae: 0.17646 | valid_rmse: 0.23084 | valid_mse: 0.05329 |  0:02:01s\n",
      "epoch 78 | loss: 0.03329 | train_rmsle: 0.00173 | train_mae: 0.13073 | train_rmse: 0.17398 | train_mse: 0.03027 | valid_rmsle: 0.00266 | valid_mae: 0.17007 | valid_rmse: 0.21843 | valid_mse: 0.04771 |  0:02:03s\n",
      "epoch 79 | loss: 0.03427 | train_rmsle: 0.00151 | train_mae: 0.11656 | train_rmse: 0.15852 | train_mse: 0.02513 | valid_rmsle: 0.00255 | valid_mae: 0.15893 | valid_rmse: 0.21227 | valid_mse: 0.04506 |  0:02:04s\n",
      "epoch 80 | loss: 0.03039 | train_rmsle: 0.00149 | train_mae: 0.1187  | train_rmse: 0.15821 | train_mse: 0.02503 | valid_rmsle: 0.00252 | valid_mae: 0.16101 | valid_rmse: 0.21124 | valid_mse: 0.04462 |  0:02:06s\n",
      "epoch 81 | loss: 0.03158 | train_rmsle: 0.00148 | train_mae: 0.11909 | train_rmse: 0.15882 | train_mse: 0.02523 | valid_rmsle: 0.00256 | valid_mae: 0.16257 | valid_rmse: 0.21228 | valid_mse: 0.04506 |  0:02:07s\n",
      "epoch 82 | loss: 0.0345  | train_rmsle: 0.00154 | train_mae: 0.12386 | train_rmse: 0.1629  | train_mse: 0.02653 | valid_rmsle: 0.00258 | valid_mae: 0.16646 | valid_rmse: 0.21451 | valid_mse: 0.04601 |  0:02:09s\n",
      "epoch 83 | loss: 0.0345  | train_rmsle: 0.00149 | train_mae: 0.11953 | train_rmse: 0.16083 | train_mse: 0.02586 | valid_rmsle: 0.00244 | valid_mae: 0.1615  | valid_rmse: 0.20901 | valid_mse: 0.04369 |  0:02:11s\n",
      "epoch 84 | loss: 0.03044 | train_rmsle: 0.0015  | train_mae: 0.1209  | train_rmse: 0.1583  | train_mse: 0.02506 | valid_rmsle: 0.00268 | valid_mae: 0.16486 | valid_rmse: 0.2157  | valid_mse: 0.04653 |  0:02:12s\n",
      "epoch 85 | loss: 0.0283  | train_rmsle: 0.00142 | train_mae: 0.11775 | train_rmse: 0.1553  | train_mse: 0.02412 | valid_rmsle: 0.00256 | valid_mae: 0.16199 | valid_rmse: 0.21286 | valid_mse: 0.04531 |  0:02:14s\n",
      "epoch 86 | loss: 0.02822 | train_rmsle: 0.00166 | train_mae: 0.12466 | train_rmse: 0.16792 | train_mse: 0.0282  | valid_rmsle: 0.00261 | valid_mae: 0.16415 | valid_rmse: 0.21448 | valid_mse: 0.046   |  0:02:15s\n",
      "epoch 87 | loss: 0.03079 | train_rmsle: 0.00131 | train_mae: 0.10835 | train_rmse: 0.14939 | train_mse: 0.02232 | valid_rmsle: 0.00245 | valid_mae: 0.15519 | valid_rmse: 0.20872 | valid_mse: 0.04356 |  0:02:17s\n",
      "epoch 88 | loss: 0.0285  | train_rmsle: 0.00153 | train_mae: 0.12651 | train_rmse: 0.16257 | train_mse: 0.02643 | valid_rmsle: 0.00263 | valid_mae: 0.16665 | valid_rmse: 0.21519 | valid_mse: 0.04631 |  0:02:18s\n",
      "epoch 89 | loss: 0.0283  | train_rmsle: 0.00123 | train_mae: 0.10701 | train_rmse: 0.14605 | train_mse: 0.02133 | valid_rmsle: 0.00233 | valid_mae: 0.15466 | valid_rmse: 0.20423 | valid_mse: 0.04171 |  0:02:20s\n",
      "epoch 90 | loss: 0.02925 | train_rmsle: 0.00131 | train_mae: 0.11287 | train_rmse: 0.15189 | train_mse: 0.02307 | valid_rmsle: 0.0023  | valid_mae: 0.15479 | valid_rmse: 0.20362 | valid_mse: 0.04146 |  0:02:22s\n",
      "epoch 91 | loss: 0.02823 | train_rmsle: 0.00127 | train_mae: 0.10918 | train_rmse: 0.14713 | train_mse: 0.02165 | valid_rmsle: 0.00231 | valid_mae: 0.15246 | valid_rmse: 0.20335 | valid_mse: 0.04135 |  0:02:23s\n",
      "epoch 92 | loss: 0.02827 | train_rmsle: 0.00137 | train_mae: 0.11697 | train_rmse: 0.15307 | train_mse: 0.02343 | valid_rmsle: 0.00246 | valid_mae: 0.15875 | valid_rmse: 0.20889 | valid_mse: 0.04364 |  0:02:25s\n",
      "epoch 93 | loss: 0.02621 | train_rmsle: 0.00112 | train_mae: 0.10105 | train_rmse: 0.13893 | train_mse: 0.0193  | valid_rmsle: 0.00221 | valid_mae: 0.1485  | valid_rmse: 0.19996 | valid_mse: 0.03998 |  0:02:27s\n",
      "epoch 94 | loss: 0.02587 | train_rmsle: 0.00118 | train_mae: 0.1043  | train_rmse: 0.14191 | train_mse: 0.02014 | valid_rmsle: 0.00217 | valid_mae: 0.14732 | valid_rmse: 0.19796 | valid_mse: 0.03919 |  0:02:28s\n",
      "epoch 95 | loss: 0.02606 | train_rmsle: 0.00114 | train_mae: 0.10488 | train_rmse: 0.14225 | train_mse: 0.02024 | valid_rmsle: 0.00214 | valid_mae: 0.14952 | valid_rmse: 0.1962  | valid_mse: 0.0385  |  0:02:30s\n",
      "epoch 96 | loss: 0.02795 | train_rmsle: 0.00166 | train_mae: 0.13199 | train_rmse: 0.16843 | train_mse: 0.02837 | valid_rmsle: 0.0027  | valid_mae: 0.17061 | valid_rmse: 0.21762 | valid_mse: 0.04736 |  0:02:32s\n",
      "epoch 97 | loss: 0.02758 | train_rmsle: 0.00118 | train_mae: 0.10418 | train_rmse: 0.1412  | train_mse: 0.01994 | valid_rmsle: 0.00208 | valid_mae: 0.14598 | valid_rmse: 0.19298 | valid_mse: 0.03724 |  0:02:33s\n",
      "epoch 98 | loss: 0.02598 | train_rmsle: 0.00113 | train_mae: 0.10468 | train_rmse: 0.14174 | train_mse: 0.02009 | valid_rmsle: 0.00204 | valid_mae: 0.14638 | valid_rmse: 0.19261 | valid_mse: 0.0371  |  0:02:35s\n",
      "epoch 99 | loss: 0.02602 | train_rmsle: 0.00122 | train_mae: 0.11147 | train_rmse: 0.1483  | train_mse: 0.02199 | valid_rmsle: 0.00212 | valid_mae: 0.15258 | valid_rmse: 0.19583 | valid_mse: 0.03835 |  0:02:36s\n",
      "epoch 100| loss: 0.02483 | train_rmsle: 0.00103 | train_mae: 0.0978  | train_rmse: 0.13555 | train_mse: 0.01837 | valid_rmsle: 0.00195 | valid_mae: 0.13976 | valid_rmse: 0.18695 | valid_mse: 0.03495 |  0:02:38s\n",
      "epoch 101| loss: 0.02397 | train_rmsle: 0.00108 | train_mae: 0.10142 | train_rmse: 0.13837 | train_mse: 0.01915 | valid_rmsle: 0.00191 | valid_mae: 0.14037 | valid_rmse: 0.18665 | valid_mse: 0.03484 |  0:02:40s\n",
      "epoch 102| loss: 0.02356 | train_rmsle: 0.00105 | train_mae: 0.09898 | train_rmse: 0.13306 | train_mse: 0.01771 | valid_rmsle: 0.0019  | valid_mae: 0.13791 | valid_rmse: 0.18306 | valid_mse: 0.03351 |  0:02:41s\n",
      "epoch 103| loss: 0.02504 | train_rmsle: 0.00098 | train_mae: 0.09348 | train_rmse: 0.13095 | train_mse: 0.01715 | valid_rmsle: 0.00181 | valid_mae: 0.13444 | valid_rmse: 0.18069 | valid_mse: 0.03265 |  0:02:43s\n",
      "epoch 104| loss: 0.02478 | train_rmsle: 0.00111 | train_mae: 0.10542 | train_rmse: 0.14116 | train_mse: 0.01993 | valid_rmsle: 0.00201 | valid_mae: 0.14708 | valid_rmse: 0.19083 | valid_mse: 0.03642 |  0:02:44s\n",
      "epoch 105| loss: 0.02155 | train_rmsle: 0.00104 | train_mae: 0.10031 | train_rmse: 0.13384 | train_mse: 0.01791 | valid_rmsle: 0.00192 | valid_mae: 0.14211 | valid_rmse: 0.18515 | valid_mse: 0.03428 |  0:02:46s\n",
      "epoch 106| loss: 0.02499 | train_rmsle: 0.00093 | train_mae: 0.0922  | train_rmse: 0.12723 | train_mse: 0.01619 | valid_rmsle: 0.00181 | valid_mae: 0.1354  | valid_rmse: 0.1811  | valid_mse: 0.0328  |  0:02:48s\n",
      "epoch 107| loss: 0.02257 | train_rmsle: 0.00095 | train_mae: 0.09684 | train_rmse: 0.13068 | train_mse: 0.01708 | valid_rmsle: 0.00175 | valid_mae: 0.13724 | valid_rmse: 0.17826 | valid_mse: 0.03178 |  0:02:49s\n",
      "epoch 108| loss: 0.02133 | train_rmsle: 0.00086 | train_mae: 0.08833 | train_rmse: 0.12164 | train_mse: 0.0148  | valid_rmsle: 0.00166 | valid_mae: 0.13003 | valid_rmse: 0.1736  | valid_mse: 0.03014 |  0:02:51s\n",
      "epoch 109| loss: 0.02208 | train_rmsle: 0.00087 | train_mae: 0.09032 | train_rmse: 0.12193 | train_mse: 0.01487 | valid_rmsle: 0.00176 | valid_mae: 0.13118 | valid_rmse: 0.17613 | valid_mse: 0.03102 |  0:02:53s\n",
      "epoch 110| loss: 0.02407 | train_rmsle: 0.00112 | train_mae: 0.10388 | train_rmse: 0.13995 | train_mse: 0.01959 | valid_rmsle: 0.00175 | valid_mae: 0.13427 | valid_rmse: 0.1797  | valid_mse: 0.03229 |  0:02:54s\n",
      "epoch 111| loss: 0.02545 | train_rmsle: 0.00156 | train_mae: 0.12158 | train_rmse: 0.15642 | train_mse: 0.02447 | valid_rmsle: 0.00219 | valid_mae: 0.1479  | valid_rmse: 0.19417 | valid_mse: 0.0377  |  0:02:56s\n",
      "epoch 112| loss: 0.02337 | train_rmsle: 0.00128 | train_mae: 0.10605 | train_rmse: 0.14838 | train_mse: 0.02202 | valid_rmsle: 0.00199 | valid_mae: 0.13899 | valid_rmse: 0.18882 | valid_mse: 0.03565 |  0:02:57s\n",
      "epoch 113| loss: 0.02033 | train_rmsle: 0.00109 | train_mae: 0.10721 | train_rmse: 0.13743 | train_mse: 0.01889 | valid_rmsle: 0.00174 | valid_mae: 0.13811 | valid_rmse: 0.17708 | valid_mse: 0.03136 |  0:02:58s\n",
      "epoch 114| loss: 0.01924 | train_rmsle: 0.0008  | train_mae: 0.08636 | train_rmse: 0.11731 | train_mse: 0.01376 | valid_rmsle: 0.00146 | valid_mae: 0.12183 | valid_rmse: 0.16185 | valid_mse: 0.0262  |  0:03:00s\n",
      "epoch 115| loss: 0.02    | train_rmsle: 0.00072 | train_mae: 0.08105 | train_rmse: 0.11155 | train_mse: 0.01244 | valid_rmsle: 0.00142 | valid_mae: 0.11561 | valid_rmse: 0.15754 | valid_mse: 0.02482 |  0:03:01s\n",
      "epoch 116| loss: 0.02129 | train_rmsle: 0.00067 | train_mae: 0.07798 | train_rmse: 0.10737 | train_mse: 0.01153 | valid_rmsle: 0.0014  | valid_mae: 0.11624 | valid_rmse: 0.1571  | valid_mse: 0.02468 |  0:03:03s\n",
      "epoch 117| loss: 0.01957 | train_rmsle: 0.00068 | train_mae: 0.07896 | train_rmse: 0.10903 | train_mse: 0.01189 | valid_rmsle: 0.00142 | valid_mae: 0.11573 | valid_rmse: 0.1582  | valid_mse: 0.02503 |  0:03:04s\n",
      "epoch 118| loss: 0.01683 | train_rmsle: 0.00062 | train_mae: 0.07579 | train_rmse: 0.10376 | train_mse: 0.01077 | valid_rmsle: 0.00128 | valid_mae: 0.11174 | valid_rmse: 0.15106 | valid_mse: 0.02282 |  0:03:05s\n",
      "epoch 119| loss: 0.01611 | train_rmsle: 0.00103 | train_mae: 0.09482 | train_rmse: 0.1227  | train_mse: 0.01506 | valid_rmsle: 0.00183 | valid_mae: 0.12889 | valid_rmse: 0.16865 | valid_mse: 0.02844 |  0:03:07s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 118 and best_valid_mse = 0.02282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.02384098172684262 RMSE: 0.15440525161678478 R2: 0.8944651602683669 MAE: 0.11771430175260135\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_120.pt.zip\n",
      "New best model: 512_8_3_0.02_120 with r2: 0.8944651602683669\n",
      "[3/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.32546 | train_rmsle: 0.10813 | train_mae: 1.15939 | train_rmse: 1.24502 | train_mse: 1.55007 | valid_rmsle: 0.10874 | valid_mae: 1.16269 | valid_rmse: 1.24962 | valid_mse: 1.56156 |  0:00:01s\n",
      "epoch 1  | loss: 0.4776  | train_rmsle: 0.08417 | train_mae: 1.03262 | train_rmse: 1.12258 | train_mse: 1.26019 | valid_rmsle: 0.08456 | valid_mae: 1.03525 | valid_rmse: 1.12655 | valid_mse: 1.26912 |  0:00:03s\n",
      "epoch 2  | loss: 0.26254 | train_rmsle: 0.05061 | train_mae: 0.80979 | train_rmse: 0.90305 | train_mse: 0.8155  | valid_rmsle: 0.05066 | valid_mae: 0.81017 | valid_rmse: 0.90563 | valid_mse: 0.82017 |  0:00:04s\n",
      "epoch 3  | loss: 0.24059 | train_rmsle: 0.04156 | train_mae: 0.73385 | train_rmse: 0.82765 | train_mse: 0.68501 | valid_rmsle: 0.04161 | valid_mae: 0.73426 | valid_rmse: 0.83054 | valid_mse: 0.6898  |  0:00:06s\n",
      "epoch 4  | loss: 0.23195 | train_rmsle: 0.02344 | train_mae: 0.54354 | train_rmse: 0.63364 | train_mse: 0.4015  | valid_rmsle: 0.02315 | valid_mae: 0.54428 | valid_rmse: 0.63368 | valid_mse: 0.40155 |  0:00:07s\n",
      "epoch 5  | loss: 0.23992 | train_rmsle: 0.02539 | train_mae: 0.56818 | train_rmse: 0.65898 | train_mse: 0.43426 | valid_rmsle: 0.02532 | valid_mae: 0.57023 | valid_rmse: 0.66157 | valid_mse: 0.43767 |  0:00:09s\n",
      "epoch 6  | loss: 0.22143 | train_rmsle: 0.01441 | train_mae: 0.40657 | train_rmse: 0.49215 | train_mse: 0.24221 | valid_rmsle: 0.01376 | valid_mae: 0.4029  | valid_rmse: 0.48561 | valid_mse: 0.23582 |  0:00:11s\n",
      "epoch 7  | loss: 0.19207 | train_rmsle: 0.0109  | train_mae: 0.34853 | train_rmse: 0.42457 | train_mse: 0.18026 | valid_rmsle: 0.01039 | valid_mae: 0.34677 | valid_rmse: 0.4216  | valid_mse: 0.17775 |  0:00:12s\n",
      "epoch 8  | loss: 0.15937 | train_rmsle: 0.01171 | train_mae: 0.36466 | train_rmse: 0.43613 | train_mse: 0.19021 | valid_rmsle: 0.01087 | valid_mae: 0.35392 | valid_rmse: 0.42414 | valid_mse: 0.17989 |  0:00:14s\n",
      "epoch 9  | loss: 0.13789 | train_rmsle: 0.00813 | train_mae: 0.28707 | train_rmse: 0.3584  | train_mse: 0.12845 | valid_rmsle: 0.00734 | valid_mae: 0.27263 | valid_rmse: 0.34329 | valid_mse: 0.11785 |  0:00:15s\n",
      "epoch 10 | loss: 0.12635 | train_rmsle: 0.00785 | train_mae: 0.27595 | train_rmse: 0.35066 | train_mse: 0.12296 | valid_rmsle: 0.00717 | valid_mae: 0.26434 | valid_rmse: 0.33833 | valid_mse: 0.11446 |  0:00:16s\n",
      "epoch 11 | loss: 0.11606 | train_rmsle: 0.00699 | train_mae: 0.25904 | train_rmse: 0.33108 | train_mse: 0.10961 | valid_rmsle: 0.00638 | valid_mae: 0.24995 | valid_rmse: 0.32004 | valid_mse: 0.10242 |  0:00:18s\n",
      "epoch 12 | loss: 0.11324 | train_rmsle: 0.0078  | train_mae: 0.27968 | train_rmse: 0.35475 | train_mse: 0.12585 | valid_rmsle: 0.00724 | valid_mae: 0.2727  | valid_rmse: 0.34751 | valid_mse: 0.12076 |  0:00:19s\n",
      "epoch 13 | loss: 0.10947 | train_rmsle: 0.00736 | train_mae: 0.26751 | train_rmse: 0.34011 | train_mse: 0.11567 | valid_rmsle: 0.00677 | valid_mae: 0.25856 | valid_rmse: 0.32941 | valid_mse: 0.10851 |  0:00:21s\n",
      "epoch 14 | loss: 0.10505 | train_rmsle: 0.0065  | train_mae: 0.24607 | train_rmse: 0.31754 | train_mse: 0.10083 | valid_rmsle: 0.00598 | valid_mae: 0.23952 | valid_rmse: 0.30813 | valid_mse: 0.09495 |  0:00:22s\n",
      "epoch 15 | loss: 0.10751 | train_rmsle: 0.00648 | train_mae: 0.24655 | train_rmse: 0.31775 | train_mse: 0.10097 | valid_rmsle: 0.006   | valid_mae: 0.24094 | valid_rmse: 0.30994 | valid_mse: 0.09606 |  0:00:24s\n",
      "epoch 16 | loss: 0.1003  | train_rmsle: 0.00633 | train_mae: 0.24265 | train_rmse: 0.31226 | train_mse: 0.09751 | valid_rmsle: 0.00582 | valid_mae: 0.23422 | valid_rmse: 0.30269 | valid_mse: 0.09162 |  0:00:25s\n",
      "epoch 17 | loss: 0.09528 | train_rmsle: 0.00634 | train_mae: 0.24361 | train_rmse: 0.3135  | train_mse: 0.09828 | valid_rmsle: 0.00581 | valid_mae: 0.23479 | valid_rmse: 0.30268 | valid_mse: 0.09161 |  0:00:27s\n",
      "epoch 18 | loss: 0.09358 | train_rmsle: 0.00668 | train_mae: 0.2549  | train_rmse: 0.32323 | train_mse: 0.10448 | valid_rmsle: 0.00612 | valid_mae: 0.24424 | valid_rmse: 0.31224 | valid_mse: 0.09749 |  0:00:29s\n",
      "epoch 19 | loss: 0.09467 | train_rmsle: 0.00589 | train_mae: 0.22849 | train_rmse: 0.2989  | train_mse: 0.08934 | valid_rmsle: 0.00546 | valid_mae: 0.22253 | valid_rmse: 0.29118 | valid_mse: 0.08479 |  0:00:30s\n",
      "epoch 20 | loss: 0.09337 | train_rmsle: 0.00607 | train_mae: 0.23797 | train_rmse: 0.30608 | train_mse: 0.09368 | valid_rmsle: 0.00548 | valid_mae: 0.22833 | valid_rmse: 0.29435 | valid_mse: 0.08664 |  0:00:32s\n",
      "epoch 21 | loss: 0.08989 | train_rmsle: 0.00582 | train_mae: 0.22882 | train_rmse: 0.29779 | train_mse: 0.08868 | valid_rmsle: 0.0053  | valid_mae: 0.22136 | valid_rmse: 0.28808 | valid_mse: 0.08299 |  0:00:33s\n",
      "epoch 22 | loss: 0.08656 | train_rmsle: 0.00593 | train_mae: 0.23574 | train_rmse: 0.3026  | train_mse: 0.09157 | valid_rmsle: 0.0054  | valid_mae: 0.22774 | valid_rmse: 0.29218 | valid_mse: 0.08537 |  0:00:35s\n",
      "epoch 23 | loss: 0.08684 | train_rmsle: 0.00557 | train_mae: 0.22615 | train_rmse: 0.29195 | train_mse: 0.08524 | valid_rmsle: 0.00511 | valid_mae: 0.22021 | valid_rmse: 0.2834  | valid_mse: 0.08032 |  0:00:37s\n",
      "epoch 24 | loss: 0.08578 | train_rmsle: 0.00555 | train_mae: 0.22741 | train_rmse: 0.29202 | train_mse: 0.08528 | valid_rmsle: 0.00519 | valid_mae: 0.2236  | valid_rmse: 0.28564 | valid_mse: 0.08159 |  0:00:38s\n",
      "epoch 25 | loss: 0.08484 | train_rmsle: 0.00542 | train_mae: 0.219   | train_rmse: 0.28606 | train_mse: 0.08183 | valid_rmsle: 0.00503 | valid_mae: 0.21588 | valid_rmse: 0.28    | valid_mse: 0.0784  |  0:00:40s\n",
      "epoch 26 | loss: 0.08264 | train_rmsle: 0.00524 | train_mae: 0.21627 | train_rmse: 0.28139 | train_mse: 0.07918 | valid_rmsle: 0.00493 | valid_mae: 0.21438 | valid_rmse: 0.27676 | valid_mse: 0.0766  |  0:00:41s\n",
      "epoch 27 | loss: 0.08391 | train_rmsle: 0.00523 | train_mae: 0.22048 | train_rmse: 0.28369 | train_mse: 0.08048 | valid_rmsle: 0.00513 | valid_mae: 0.22422 | valid_rmse: 0.28511 | valid_mse: 0.08129 |  0:00:43s\n",
      "epoch 28 | loss: 0.08365 | train_rmsle: 0.00553 | train_mae: 0.23237 | train_rmse: 0.29443 | train_mse: 0.08669 | valid_rmsle: 0.00532 | valid_mae: 0.23557 | valid_rmse: 0.2936  | valid_mse: 0.0862  |  0:00:45s\n",
      "epoch 29 | loss: 0.08339 | train_rmsle: 0.0051  | train_mae: 0.21299 | train_rmse: 0.27768 | train_mse: 0.0771  | valid_rmsle: 0.00499 | valid_mae: 0.21583 | valid_rmse: 0.27947 | valid_mse: 0.0781  |  0:00:46s\n",
      "epoch 30 | loss: 0.07962 | train_rmsle: 0.00503 | train_mae: 0.21495 | train_rmse: 0.27748 | train_mse: 0.077   | valid_rmsle: 0.00495 | valid_mae: 0.2185  | valid_rmse: 0.27964 | valid_mse: 0.0782  |  0:00:48s\n",
      "epoch 31 | loss: 0.07878 | train_rmsle: 0.00526 | train_mae: 0.22764 | train_rmse: 0.28798 | train_mse: 0.08293 | valid_rmsle: 0.00519 | valid_mae: 0.23246 | valid_rmse: 0.28972 | valid_mse: 0.08394 |  0:00:49s\n",
      "epoch 32 | loss: 0.07707 | train_rmsle: 0.00491 | train_mae: 0.20862 | train_rmse: 0.2729  | train_mse: 0.07447 | valid_rmsle: 0.00491 | valid_mae: 0.21605 | valid_rmse: 0.27878 | valid_mse: 0.07772 |  0:00:51s\n",
      "epoch 33 | loss: 0.07733 | train_rmsle: 0.00484 | train_mae: 0.20969 | train_rmse: 0.27188 | train_mse: 0.07392 | valid_rmsle: 0.00489 | valid_mae: 0.21648 | valid_rmse: 0.27864 | valid_mse: 0.07764 |  0:00:53s\n",
      "epoch 34 | loss: 0.08016 | train_rmsle: 0.00475 | train_mae: 0.20849 | train_rmse: 0.27003 | train_mse: 0.07292 | valid_rmsle: 0.00486 | valid_mae: 0.21809 | valid_rmse: 0.27863 | valid_mse: 0.07763 |  0:00:54s\n",
      "epoch 35 | loss: 0.07635 | train_rmsle: 0.00477 | train_mae: 0.2062  | train_rmse: 0.2687  | train_mse: 0.0722  | valid_rmsle: 0.00498 | valid_mae: 0.2176  | valid_rmse: 0.28068 | valid_mse: 0.07878 |  0:00:56s\n",
      "epoch 36 | loss: 0.07622 | train_rmsle: 0.00509 | train_mae: 0.21099 | train_rmse: 0.27582 | train_mse: 0.07607 | valid_rmsle: 0.00515 | valid_mae: 0.22186 | valid_rmse: 0.28414 | valid_mse: 0.08074 |  0:00:57s\n",
      "epoch 37 | loss: 0.07459 | train_rmsle: 0.00481 | train_mae: 0.20543 | train_rmse: 0.27016 | train_mse: 0.07299 | valid_rmsle: 0.00502 | valid_mae: 0.21597 | valid_rmse: 0.2814  | valid_mse: 0.07919 |  0:00:59s\n",
      "epoch 38 | loss: 0.07677 | train_rmsle: 0.00453 | train_mae: 0.20439 | train_rmse: 0.26392 | train_mse: 0.06965 | valid_rmsle: 0.00484 | valid_mae: 0.21742 | valid_rmse: 0.27787 | valid_mse: 0.07721 |  0:01:01s\n",
      "epoch 39 | loss: 0.07333 | train_rmsle: 0.00499 | train_mae: 0.22573 | train_rmse: 0.28262 | train_mse: 0.07988 | valid_rmsle: 0.00527 | valid_mae: 0.23653 | valid_rmse: 0.29329 | valid_mse: 0.08602 |  0:01:02s\n",
      "epoch 40 | loss: 0.07203 | train_rmsle: 0.00451 | train_mae: 0.20373 | train_rmse: 0.26314 | train_mse: 0.06924 | valid_rmsle: 0.00486 | valid_mae: 0.21605 | valid_rmse: 0.27787 | valid_mse: 0.07721 |  0:01:04s\n",
      "epoch 41 | loss: 0.07095 | train_rmsle: 0.00454 | train_mae: 0.20846 | train_rmse: 0.2656  | train_mse: 0.07055 | valid_rmsle: 0.00484 | valid_mae: 0.22117 | valid_rmse: 0.27926 | valid_mse: 0.07798 |  0:01:05s\n",
      "epoch 42 | loss: 0.07044 | train_rmsle: 0.00431 | train_mae: 0.19741 | train_rmse: 0.25609 | train_mse: 0.06558 | valid_rmsle: 0.00469 | valid_mae: 0.21309 | valid_rmse: 0.27302 | valid_mse: 0.07454 |  0:01:07s\n",
      "epoch 43 | loss: 0.0674  | train_rmsle: 0.0044  | train_mae: 0.20753 | train_rmse: 0.26324 | train_mse: 0.06929 | valid_rmsle: 0.00497 | valid_mae: 0.22657 | valid_rmse: 0.28458 | valid_mse: 0.08098 |  0:01:09s\n",
      "epoch 44 | loss: 0.06784 | train_rmsle: 0.00413 | train_mae: 0.18994 | train_rmse: 0.24966 | train_mse: 0.06233 | valid_rmsle: 0.00469 | valid_mae: 0.21124 | valid_rmse: 0.27287 | valid_mse: 0.07446 |  0:01:10s\n",
      "epoch 45 | loss: 0.06584 | train_rmsle: 0.00401 | train_mae: 0.19228 | train_rmse: 0.24856 | train_mse: 0.06178 | valid_rmsle: 0.00473 | valid_mae: 0.21607 | valid_rmse: 0.27576 | valid_mse: 0.07605 |  0:01:12s\n",
      "epoch 46 | loss: 0.06384 | train_rmsle: 0.00392 | train_mae: 0.1884  | train_rmse: 0.24545 | train_mse: 0.06025 | valid_rmsle: 0.0047  | valid_mae: 0.21392 | valid_rmse: 0.27514 | valid_mse: 0.0757  |  0:01:13s\n",
      "epoch 47 | loss: 0.06463 | train_rmsle: 0.00394 | train_mae: 0.19161 | train_rmse: 0.2467  | train_mse: 0.06086 | valid_rmsle: 0.0046  | valid_mae: 0.21345 | valid_rmse: 0.27251 | valid_mse: 0.07426 |  0:01:15s\n",
      "epoch 48 | loss: 0.06448 | train_rmsle: 0.00406 | train_mae: 0.19792 | train_rmse: 0.25218 | train_mse: 0.06359 | valid_rmsle: 0.00475 | valid_mae: 0.21964 | valid_rmse: 0.27801 | valid_mse: 0.07729 |  0:01:17s\n",
      "epoch 49 | loss: 0.06847 | train_rmsle: 0.00401 | train_mae: 0.19711 | train_rmse: 0.25099 | train_mse: 0.06299 | valid_rmsle: 0.00482 | valid_mae: 0.22221 | valid_rmse: 0.27989 | valid_mse: 0.07834 |  0:01:18s\n",
      "epoch 50 | loss: 0.06331 | train_rmsle: 0.00364 | train_mae: 0.17843 | train_rmse: 0.23472 | train_mse: 0.05509 | valid_rmsle: 0.00436 | valid_mae: 0.20499 | valid_rmse: 0.26439 | valid_mse: 0.0699  |  0:01:19s\n",
      "epoch 51 | loss: 0.05992 | train_rmsle: 0.00368 | train_mae: 0.17824 | train_rmse: 0.23551 | train_mse: 0.05546 | valid_rmsle: 0.00432 | valid_mae: 0.20137 | valid_rmse: 0.26275 | valid_mse: 0.06904 |  0:01:21s\n",
      "epoch 52 | loss: 0.05934 | train_rmsle: 0.00366 | train_mae: 0.18065 | train_rmse: 0.23678 | train_mse: 0.05606 | valid_rmsle: 0.00438 | valid_mae: 0.20411 | valid_rmse: 0.26609 | valid_mse: 0.0708  |  0:01:22s\n",
      "epoch 53 | loss: 0.06331 | train_rmsle: 0.00367 | train_mae: 0.17985 | train_rmse: 0.23556 | train_mse: 0.05549 | valid_rmsle: 0.00426 | valid_mae: 0.19925 | valid_rmse: 0.26028 | valid_mse: 0.06775 |  0:01:23s\n",
      "epoch 54 | loss: 0.06333 | train_rmsle: 0.0039  | train_mae: 0.18403 | train_rmse: 0.24417 | train_mse: 0.05962 | valid_rmsle: 0.00451 | valid_mae: 0.20768 | valid_rmse: 0.27009 | valid_mse: 0.07295 |  0:01:25s\n",
      "epoch 55 | loss: 0.06308 | train_rmsle: 0.00348 | train_mae: 0.17539 | train_rmse: 0.23132 | train_mse: 0.05351 | valid_rmsle: 0.00416 | valid_mae: 0.20097 | valid_rmse: 0.2594  | valid_mse: 0.06729 |  0:01:26s\n",
      "epoch 56 | loss: 0.0564  | train_rmsle: 0.00332 | train_mae: 0.17188 | train_rmse: 0.22601 | train_mse: 0.05108 | valid_rmsle: 0.00409 | valid_mae: 0.19823 | valid_rmse: 0.25822 | valid_mse: 0.06668 |  0:01:28s\n",
      "epoch 57 | loss: 0.05648 | train_rmsle: 0.00323 | train_mae: 0.17114 | train_rmse: 0.22406 | train_mse: 0.05021 | valid_rmsle: 0.00394 | valid_mae: 0.19664 | valid_rmse: 0.25408 | valid_mse: 0.06456 |  0:01:29s\n",
      "epoch 58 | loss: 0.0532  | train_rmsle: 0.00347 | train_mae: 0.1702  | train_rmse: 0.22707 | train_mse: 0.05156 | valid_rmsle: 0.00407 | valid_mae: 0.19603 | valid_rmse: 0.25565 | valid_mse: 0.06536 |  0:01:31s\n",
      "epoch 59 | loss: 0.05374 | train_rmsle: 0.00366 | train_mae: 0.1729  | train_rmse: 0.23278 | train_mse: 0.05419 | valid_rmsle: 0.00413 | valid_mae: 0.19496 | valid_rmse: 0.25679 | valid_mse: 0.06594 |  0:01:32s\n",
      "epoch 60 | loss: 0.05374 | train_rmsle: 0.00299 | train_mae: 0.16567 | train_rmse: 0.21626 | train_mse: 0.04677 | valid_rmsle: 0.0037  | valid_mae: 0.19249 | valid_rmse: 0.2474  | valid_mse: 0.06121 |  0:01:34s\n",
      "epoch 61 | loss: 0.04912 | train_rmsle: 0.00313 | train_mae: 0.16447 | train_rmse: 0.21941 | train_mse: 0.04814 | valid_rmsle: 0.00379 | valid_mae: 0.19279 | valid_rmse: 0.24953 | valid_mse: 0.06227 |  0:01:36s\n",
      "epoch 62 | loss: 0.04846 | train_rmsle: 0.00269 | train_mae: 0.15637 | train_rmse: 0.20581 | train_mse: 0.04236 | valid_rmsle: 0.00344 | valid_mae: 0.18749 | valid_rmse: 0.23928 | valid_mse: 0.05725 |  0:01:37s\n",
      "epoch 63 | loss: 0.04682 | train_rmsle: 0.00257 | train_mae: 0.1527  | train_rmse: 0.20178 | train_mse: 0.04072 | valid_rmsle: 0.00344 | valid_mae: 0.18608 | valid_rmse: 0.24051 | valid_mse: 0.05785 |  0:01:39s\n",
      "epoch 64 | loss: 0.0457  | train_rmsle: 0.00265 | train_mae: 0.15964 | train_rmse: 0.20714 | train_mse: 0.04291 | valid_rmsle: 0.00347 | valid_mae: 0.19164 | valid_rmse: 0.24163 | valid_mse: 0.05838 |  0:01:41s\n",
      "epoch 65 | loss: 0.04589 | train_rmsle: 0.00238 | train_mae: 0.1461  | train_rmse: 0.19364 | train_mse: 0.0375  | valid_rmsle: 0.00344 | valid_mae: 0.18461 | valid_rmse: 0.23936 | valid_mse: 0.05729 |  0:01:42s\n",
      "epoch 66 | loss: 0.04329 | train_rmsle: 0.0025  | train_mae: 0.15679 | train_rmse: 0.20293 | train_mse: 0.04118 | valid_rmsle: 0.0035  | valid_mae: 0.19044 | valid_rmse: 0.2441  | valid_mse: 0.05959 |  0:01:44s\n",
      "epoch 67 | loss: 0.04115 | train_rmsle: 0.00233 | train_mae: 0.14409 | train_rmse: 0.19149 | train_mse: 0.03667 | valid_rmsle: 0.00341 | valid_mae: 0.18155 | valid_rmse: 0.24095 | valid_mse: 0.05806 |  0:01:45s\n",
      "epoch 68 | loss: 0.04182 | train_rmsle: 0.00226 | train_mae: 0.14667 | train_rmse: 0.19223 | train_mse: 0.03695 | valid_rmsle: 0.00323 | valid_mae: 0.18027 | valid_rmse: 0.23545 | valid_mse: 0.05544 |  0:01:47s\n",
      "epoch 69 | loss: 0.04067 | train_rmsle: 0.00209 | train_mae: 0.13699 | train_rmse: 0.18285 | train_mse: 0.03344 | valid_rmsle: 0.00305 | valid_mae: 0.17274 | valid_rmse: 0.22783 | valid_mse: 0.05191 |  0:01:49s\n",
      "epoch 70 | loss: 0.0395  | train_rmsle: 0.00204 | train_mae: 0.1359  | train_rmse: 0.18081 | train_mse: 0.03269 | valid_rmsle: 0.00305 | valid_mae: 0.17504 | valid_rmse: 0.22908 | valid_mse: 0.05248 |  0:01:50s\n",
      "epoch 71 | loss: 0.03807 | train_rmsle: 0.00242 | train_mae: 0.1599  | train_rmse: 0.20401 | train_mse: 0.04162 | valid_rmsle: 0.00341 | valid_mae: 0.19395 | valid_rmse: 0.24553 | valid_mse: 0.06028 |  0:01:52s\n",
      "epoch 72 | loss: 0.04005 | train_rmsle: 0.00219 | train_mae: 0.14342 | train_rmse: 0.18932 | train_mse: 0.03584 | valid_rmsle: 0.00304 | valid_mae: 0.1774  | valid_rmse: 0.22922 | valid_mse: 0.05254 |  0:01:54s\n",
      "epoch 73 | loss: 0.03809 | train_rmsle: 0.00212 | train_mae: 0.14786 | train_rmse: 0.19032 | train_mse: 0.03622 | valid_rmsle: 0.00314 | valid_mae: 0.18202 | valid_rmse: 0.23305 | valid_mse: 0.05431 |  0:01:55s\n",
      "epoch 74 | loss: 0.03986 | train_rmsle: 0.00219 | train_mae: 0.15195 | train_rmse: 0.19349 | train_mse: 0.03744 | valid_rmsle: 0.00312 | valid_mae: 0.18345 | valid_rmse: 0.23304 | valid_mse: 0.05431 |  0:01:57s\n",
      "epoch 75 | loss: 0.04368 | train_rmsle: 0.00197 | train_mae: 0.14139 | train_rmse: 0.18502 | train_mse: 0.03423 | valid_rmsle: 0.00301 | valid_mae: 0.1799  | valid_rmse: 0.23037 | valid_mse: 0.05307 |  0:01:58s\n",
      "epoch 76 | loss: 0.03534 | train_rmsle: 0.00182 | train_mae: 0.13024 | train_rmse: 0.17474 | train_mse: 0.03053 | valid_rmsle: 0.00283 | valid_mae: 0.16821 | valid_rmse: 0.22345 | valid_mse: 0.04993 |  0:02:00s\n",
      "epoch 77 | loss: 0.03722 | train_rmsle: 0.00195 | train_mae: 0.14006 | train_rmse: 0.17939 | train_mse: 0.03218 | valid_rmsle: 0.00304 | valid_mae: 0.17646 | valid_rmse: 0.23084 | valid_mse: 0.05329 |  0:02:01s\n",
      "epoch 78 | loss: 0.03329 | train_rmsle: 0.00173 | train_mae: 0.13073 | train_rmse: 0.17398 | train_mse: 0.03027 | valid_rmsle: 0.00266 | valid_mae: 0.17007 | valid_rmse: 0.21843 | valid_mse: 0.04771 |  0:02:03s\n",
      "epoch 79 | loss: 0.03427 | train_rmsle: 0.00151 | train_mae: 0.11656 | train_rmse: 0.15852 | train_mse: 0.02513 | valid_rmsle: 0.00255 | valid_mae: 0.15893 | valid_rmse: 0.21227 | valid_mse: 0.04506 |  0:02:05s\n",
      "epoch 80 | loss: 0.03039 | train_rmsle: 0.00149 | train_mae: 0.1187  | train_rmse: 0.15821 | train_mse: 0.02503 | valid_rmsle: 0.00252 | valid_mae: 0.16101 | valid_rmse: 0.21124 | valid_mse: 0.04462 |  0:02:06s\n",
      "epoch 81 | loss: 0.03158 | train_rmsle: 0.00148 | train_mae: 0.11909 | train_rmse: 0.15882 | train_mse: 0.02523 | valid_rmsle: 0.00256 | valid_mae: 0.16257 | valid_rmse: 0.21228 | valid_mse: 0.04506 |  0:02:08s\n",
      "epoch 82 | loss: 0.0345  | train_rmsle: 0.00154 | train_mae: 0.12386 | train_rmse: 0.1629  | train_mse: 0.02653 | valid_rmsle: 0.00258 | valid_mae: 0.16646 | valid_rmse: 0.21451 | valid_mse: 0.04601 |  0:02:09s\n",
      "epoch 83 | loss: 0.0345  | train_rmsle: 0.00149 | train_mae: 0.11953 | train_rmse: 0.16083 | train_mse: 0.02586 | valid_rmsle: 0.00244 | valid_mae: 0.1615  | valid_rmse: 0.20901 | valid_mse: 0.04369 |  0:02:11s\n",
      "epoch 84 | loss: 0.03044 | train_rmsle: 0.0015  | train_mae: 0.1209  | train_rmse: 0.1583  | train_mse: 0.02506 | valid_rmsle: 0.00268 | valid_mae: 0.16486 | valid_rmse: 0.2157  | valid_mse: 0.04653 |  0:02:12s\n",
      "epoch 85 | loss: 0.0283  | train_rmsle: 0.00142 | train_mae: 0.11775 | train_rmse: 0.1553  | train_mse: 0.02412 | valid_rmsle: 0.00256 | valid_mae: 0.16199 | valid_rmse: 0.21286 | valid_mse: 0.04531 |  0:02:14s\n",
      "epoch 86 | loss: 0.02822 | train_rmsle: 0.00166 | train_mae: 0.12466 | train_rmse: 0.16792 | train_mse: 0.0282  | valid_rmsle: 0.00261 | valid_mae: 0.16415 | valid_rmse: 0.21448 | valid_mse: 0.046   |  0:02:15s\n",
      "epoch 87 | loss: 0.03079 | train_rmsle: 0.00131 | train_mae: 0.10835 | train_rmse: 0.14939 | train_mse: 0.02232 | valid_rmsle: 0.00245 | valid_mae: 0.15519 | valid_rmse: 0.20872 | valid_mse: 0.04356 |  0:02:17s\n",
      "epoch 88 | loss: 0.0285  | train_rmsle: 0.00153 | train_mae: 0.12651 | train_rmse: 0.16257 | train_mse: 0.02643 | valid_rmsle: 0.00263 | valid_mae: 0.16665 | valid_rmse: 0.21519 | valid_mse: 0.04631 |  0:02:19s\n",
      "epoch 89 | loss: 0.0283  | train_rmsle: 0.00123 | train_mae: 0.10701 | train_rmse: 0.14605 | train_mse: 0.02133 | valid_rmsle: 0.00233 | valid_mae: 0.15466 | valid_rmse: 0.20423 | valid_mse: 0.04171 |  0:02:20s\n",
      "epoch 90 | loss: 0.02925 | train_rmsle: 0.00131 | train_mae: 0.11287 | train_rmse: 0.15189 | train_mse: 0.02307 | valid_rmsle: 0.0023  | valid_mae: 0.15479 | valid_rmse: 0.20362 | valid_mse: 0.04146 |  0:02:22s\n",
      "epoch 91 | loss: 0.02823 | train_rmsle: 0.00127 | train_mae: 0.10918 | train_rmse: 0.14713 | train_mse: 0.02165 | valid_rmsle: 0.00231 | valid_mae: 0.15246 | valid_rmse: 0.20335 | valid_mse: 0.04135 |  0:02:23s\n",
      "epoch 92 | loss: 0.02827 | train_rmsle: 0.00137 | train_mae: 0.11697 | train_rmse: 0.15307 | train_mse: 0.02343 | valid_rmsle: 0.00246 | valid_mae: 0.15875 | valid_rmse: 0.20889 | valid_mse: 0.04364 |  0:02:25s\n",
      "epoch 93 | loss: 0.02621 | train_rmsle: 0.00112 | train_mae: 0.10105 | train_rmse: 0.13893 | train_mse: 0.0193  | valid_rmsle: 0.00221 | valid_mae: 0.1485  | valid_rmse: 0.19996 | valid_mse: 0.03998 |  0:02:27s\n",
      "epoch 94 | loss: 0.02587 | train_rmsle: 0.00118 | train_mae: 0.1043  | train_rmse: 0.14191 | train_mse: 0.02014 | valid_rmsle: 0.00217 | valid_mae: 0.14732 | valid_rmse: 0.19796 | valid_mse: 0.03919 |  0:02:28s\n",
      "epoch 95 | loss: 0.02606 | train_rmsle: 0.00114 | train_mae: 0.10488 | train_rmse: 0.14225 | train_mse: 0.02024 | valid_rmsle: 0.00214 | valid_mae: 0.14952 | valid_rmse: 0.1962  | valid_mse: 0.0385  |  0:02:30s\n",
      "epoch 96 | loss: 0.02795 | train_rmsle: 0.00166 | train_mae: 0.13199 | train_rmse: 0.16843 | train_mse: 0.02837 | valid_rmsle: 0.0027  | valid_mae: 0.17061 | valid_rmse: 0.21762 | valid_mse: 0.04736 |  0:02:31s\n",
      "epoch 97 | loss: 0.02758 | train_rmsle: 0.00118 | train_mae: 0.10418 | train_rmse: 0.1412  | train_mse: 0.01994 | valid_rmsle: 0.00208 | valid_mae: 0.14598 | valid_rmse: 0.19298 | valid_mse: 0.03724 |  0:02:33s\n",
      "epoch 98 | loss: 0.02598 | train_rmsle: 0.00113 | train_mae: 0.10468 | train_rmse: 0.14174 | train_mse: 0.02009 | valid_rmsle: 0.00204 | valid_mae: 0.14638 | valid_rmse: 0.19261 | valid_mse: 0.0371  |  0:02:35s\n",
      "epoch 99 | loss: 0.02602 | train_rmsle: 0.00122 | train_mae: 0.11147 | train_rmse: 0.1483  | train_mse: 0.02199 | valid_rmsle: 0.00212 | valid_mae: 0.15258 | valid_rmse: 0.19583 | valid_mse: 0.03835 |  0:02:36s\n",
      "epoch 100| loss: 0.02483 | train_rmsle: 0.00103 | train_mae: 0.0978  | train_rmse: 0.13555 | train_mse: 0.01837 | valid_rmsle: 0.00195 | valid_mae: 0.13976 | valid_rmse: 0.18695 | valid_mse: 0.03495 |  0:02:38s\n",
      "epoch 101| loss: 0.02397 | train_rmsle: 0.00108 | train_mae: 0.10142 | train_rmse: 0.13837 | train_mse: 0.01915 | valid_rmsle: 0.00191 | valid_mae: 0.14037 | valid_rmse: 0.18665 | valid_mse: 0.03484 |  0:02:39s\n",
      "epoch 102| loss: 0.02356 | train_rmsle: 0.00105 | train_mae: 0.09898 | train_rmse: 0.13306 | train_mse: 0.01771 | valid_rmsle: 0.0019  | valid_mae: 0.13791 | valid_rmse: 0.18306 | valid_mse: 0.03351 |  0:02:41s\n",
      "epoch 103| loss: 0.02504 | train_rmsle: 0.00098 | train_mae: 0.09348 | train_rmse: 0.13095 | train_mse: 0.01715 | valid_rmsle: 0.00181 | valid_mae: 0.13444 | valid_rmse: 0.18069 | valid_mse: 0.03265 |  0:02:43s\n",
      "epoch 104| loss: 0.02478 | train_rmsle: 0.00111 | train_mae: 0.10542 | train_rmse: 0.14116 | train_mse: 0.01993 | valid_rmsle: 0.00201 | valid_mae: 0.14708 | valid_rmse: 0.19083 | valid_mse: 0.03642 |  0:02:44s\n",
      "epoch 105| loss: 0.02155 | train_rmsle: 0.00104 | train_mae: 0.10031 | train_rmse: 0.13384 | train_mse: 0.01791 | valid_rmsle: 0.00192 | valid_mae: 0.14211 | valid_rmse: 0.18515 | valid_mse: 0.03428 |  0:02:46s\n",
      "epoch 106| loss: 0.02499 | train_rmsle: 0.00093 | train_mae: 0.0922  | train_rmse: 0.12723 | train_mse: 0.01619 | valid_rmsle: 0.00181 | valid_mae: 0.1354  | valid_rmse: 0.1811  | valid_mse: 0.0328  |  0:02:47s\n",
      "epoch 107| loss: 0.02257 | train_rmsle: 0.00095 | train_mae: 0.09684 | train_rmse: 0.13068 | train_mse: 0.01708 | valid_rmsle: 0.00175 | valid_mae: 0.13724 | valid_rmse: 0.17826 | valid_mse: 0.03178 |  0:02:49s\n",
      "epoch 108| loss: 0.02133 | train_rmsle: 0.00086 | train_mae: 0.08833 | train_rmse: 0.12164 | train_mse: 0.0148  | valid_rmsle: 0.00166 | valid_mae: 0.13003 | valid_rmse: 0.1736  | valid_mse: 0.03014 |  0:02:50s\n",
      "epoch 109| loss: 0.02208 | train_rmsle: 0.00087 | train_mae: 0.09032 | train_rmse: 0.12193 | train_mse: 0.01487 | valid_rmsle: 0.00176 | valid_mae: 0.13118 | valid_rmse: 0.17613 | valid_mse: 0.03102 |  0:02:52s\n",
      "epoch 110| loss: 0.02407 | train_rmsle: 0.00112 | train_mae: 0.10388 | train_rmse: 0.13995 | train_mse: 0.01959 | valid_rmsle: 0.00175 | valid_mae: 0.13427 | valid_rmse: 0.1797  | valid_mse: 0.03229 |  0:02:53s\n",
      "epoch 111| loss: 0.02545 | train_rmsle: 0.00156 | train_mae: 0.12158 | train_rmse: 0.15642 | train_mse: 0.02447 | valid_rmsle: 0.00219 | valid_mae: 0.1479  | valid_rmse: 0.19417 | valid_mse: 0.0377  |  0:02:55s\n",
      "epoch 112| loss: 0.02337 | train_rmsle: 0.00128 | train_mae: 0.10605 | train_rmse: 0.14838 | train_mse: 0.02202 | valid_rmsle: 0.00199 | valid_mae: 0.13899 | valid_rmse: 0.18882 | valid_mse: 0.03565 |  0:02:57s\n",
      "epoch 113| loss: 0.02033 | train_rmsle: 0.00109 | train_mae: 0.10721 | train_rmse: 0.13743 | train_mse: 0.01889 | valid_rmsle: 0.00174 | valid_mae: 0.13811 | valid_rmse: 0.17708 | valid_mse: 0.03136 |  0:02:58s\n",
      "epoch 114| loss: 0.01924 | train_rmsle: 0.0008  | train_mae: 0.08636 | train_rmse: 0.11731 | train_mse: 0.01376 | valid_rmsle: 0.00146 | valid_mae: 0.12183 | valid_rmse: 0.16185 | valid_mse: 0.0262  |  0:03:00s\n",
      "epoch 115| loss: 0.02    | train_rmsle: 0.00072 | train_mae: 0.08105 | train_rmse: 0.11155 | train_mse: 0.01244 | valid_rmsle: 0.00142 | valid_mae: 0.11561 | valid_rmse: 0.15754 | valid_mse: 0.02482 |  0:03:01s\n",
      "epoch 116| loss: 0.02129 | train_rmsle: 0.00067 | train_mae: 0.07798 | train_rmse: 0.10737 | train_mse: 0.01153 | valid_rmsle: 0.0014  | valid_mae: 0.11624 | valid_rmse: 0.1571  | valid_mse: 0.02468 |  0:03:03s\n",
      "epoch 117| loss: 0.01957 | train_rmsle: 0.00068 | train_mae: 0.07896 | train_rmse: 0.10903 | train_mse: 0.01189 | valid_rmsle: 0.00142 | valid_mae: 0.11573 | valid_rmse: 0.1582  | valid_mse: 0.02503 |  0:03:04s\n",
      "epoch 118| loss: 0.01683 | train_rmsle: 0.00062 | train_mae: 0.07579 | train_rmse: 0.10376 | train_mse: 0.01077 | valid_rmsle: 0.00128 | valid_mae: 0.11174 | valid_rmse: 0.15106 | valid_mse: 0.02282 |  0:03:06s\n",
      "epoch 119| loss: 0.01611 | train_rmsle: 0.00103 | train_mae: 0.09482 | train_rmse: 0.1227  | train_mse: 0.01506 | valid_rmsle: 0.00183 | valid_mae: 0.12889 | valid_rmse: 0.16865 | valid_mse: 0.02844 |  0:03:07s\n",
      "epoch 120| loss: 0.01762 | train_rmsle: 0.00069 | train_mae: 0.08401 | train_rmse: 0.10993 | train_mse: 0.01208 | valid_rmsle: 0.00138 | valid_mae: 0.11953 | valid_rmse: 0.15654 | valid_mse: 0.0245  |  0:03:09s\n",
      "epoch 121| loss: 0.01801 | train_rmsle: 0.00074 | train_mae: 0.0883  | train_rmse: 0.11597 | train_mse: 0.01345 | valid_rmsle: 0.0014  | valid_mae: 0.1206  | valid_rmse: 0.15832 | valid_mse: 0.02506 |  0:03:10s\n",
      "epoch 122| loss: 0.01606 | train_rmsle: 0.00072 | train_mae: 0.08758 | train_rmse: 0.11204 | train_mse: 0.01255 | valid_rmsle: 0.00136 | valid_mae: 0.11828 | valid_rmse: 0.15315 | valid_mse: 0.02345 |  0:03:11s\n",
      "epoch 123| loss: 0.01848 | train_rmsle: 0.00059 | train_mae: 0.07427 | train_rmse: 0.10317 | train_mse: 0.01064 | valid_rmsle: 0.00122 | valid_mae: 0.11122 | valid_rmse: 0.14815 | valid_mse: 0.02195 |  0:03:13s\n",
      "epoch 124| loss: 0.01464 | train_rmsle: 0.00063 | train_mae: 0.07765 | train_rmse: 0.10246 | train_mse: 0.0105  | valid_rmsle: 0.00115 | valid_mae: 0.10885 | valid_rmse: 0.14202 | valid_mse: 0.02017 |  0:03:14s\n",
      "epoch 125| loss: 0.01709 | train_rmsle: 0.00069 | train_mae: 0.08527 | train_rmse: 0.11182 | train_mse: 0.0125  | valid_rmsle: 0.00121 | valid_mae: 0.1156  | valid_rmse: 0.14812 | valid_mse: 0.02194 |  0:03:16s\n",
      "epoch 126| loss: 0.01624 | train_rmsle: 0.0007  | train_mae: 0.07932 | train_rmse: 0.10674 | train_mse: 0.01139 | valid_rmsle: 0.00114 | valid_mae: 0.10707 | valid_rmse: 0.14097 | valid_mse: 0.01987 |  0:03:17s\n",
      "epoch 127| loss: 0.01529 | train_rmsle: 0.00047 | train_mae: 0.06583 | train_rmse: 0.0907  | train_mse: 0.00823 | valid_rmsle: 0.00104 | valid_mae: 0.10146 | valid_rmse: 0.13584 | valid_mse: 0.01845 |  0:03:19s\n",
      "epoch 128| loss: 0.01465 | train_rmsle: 0.00054 | train_mae: 0.07217 | train_rmse: 0.09612 | train_mse: 0.00924 | valid_rmsle: 0.00109 | valid_mae: 0.10594 | valid_rmse: 0.13854 | valid_mse: 0.01919 |  0:03:21s\n",
      "epoch 129| loss: 0.01614 | train_rmsle: 0.00053 | train_mae: 0.06909 | train_rmse: 0.09843 | train_mse: 0.00969 | valid_rmsle: 0.00106 | valid_mae: 0.10163 | valid_rmse: 0.13806 | valid_mse: 0.01906 |  0:03:22s\n",
      "epoch 130| loss: 0.01484 | train_rmsle: 0.00056 | train_mae: 0.07419 | train_rmse: 0.09927 | train_mse: 0.00985 | valid_rmsle: 0.00112 | valid_mae: 0.10545 | valid_rmse: 0.13985 | valid_mse: 0.01956 |  0:03:24s\n",
      "epoch 131| loss: 0.0144  | train_rmsle: 0.00065 | train_mae: 0.0729  | train_rmse: 0.11076 | train_mse: 0.01227 | valid_rmsle: 0.00119 | valid_mae: 0.10752 | valid_rmse: 0.14877 | valid_mse: 0.02213 |  0:03:25s\n",
      "epoch 132| loss: 0.01462 | train_rmsle: 0.00066 | train_mae: 0.08046 | train_rmse: 0.1025  | train_mse: 0.01051 | valid_rmsle: 0.00113 | valid_mae: 0.1075  | valid_rmse: 0.13854 | valid_mse: 0.01919 |  0:03:27s\n",
      "epoch 133| loss: 0.01209 | train_rmsle: 0.00055 | train_mae: 0.07693 | train_rmse: 0.09884 | train_mse: 0.00977 | valid_rmsle: 0.00112 | valid_mae: 0.10852 | valid_rmse: 0.14032 | valid_mse: 0.01969 |  0:03:29s\n",
      "epoch 134| loss: 0.01259 | train_rmsle: 0.00038 | train_mae: 0.06109 | train_rmse: 0.08201 | train_mse: 0.00673 | valid_rmsle: 0.00091 | valid_mae: 0.09483 | valid_rmse: 0.12723 | valid_mse: 0.01619 |  0:03:30s\n",
      "epoch 135| loss: 0.0128  | train_rmsle: 0.00053 | train_mae: 0.07531 | train_rmse: 0.09923 | train_mse: 0.00985 | valid_rmsle: 0.00107 | valid_mae: 0.10704 | valid_rmse: 0.14011 | valid_mse: 0.01963 |  0:03:32s\n",
      "epoch 136| loss: 0.01286 | train_rmsle: 0.00059 | train_mae: 0.08156 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00119 | valid_mae: 0.11139 | valid_rmse: 0.14483 | valid_mse: 0.02098 |  0:03:33s\n",
      "epoch 137| loss: 0.01495 | train_rmsle: 0.001   | train_mae: 0.09884 | train_rmse: 0.12107 | train_mse: 0.01466 | valid_rmsle: 0.00157 | valid_mae: 0.12288 | valid_rmse: 0.15613 | valid_mse: 0.02438 |  0:03:35s\n",
      "epoch 138| loss: 0.01237 | train_rmsle: 0.00043 | train_mae: 0.06597 | train_rmse: 0.08767 | train_mse: 0.00769 | valid_rmsle: 0.00094 | valid_mae: 0.09956 | valid_rmse: 0.13008 | valid_mse: 0.01692 |  0:03:36s\n",
      "epoch 139| loss: 0.01312 | train_rmsle: 0.00081 | train_mae: 0.085   | train_rmse: 0.111   | train_mse: 0.01232 | valid_rmsle: 0.00137 | valid_mae: 0.11277 | valid_rmse: 0.14683 | valid_mse: 0.02156 |  0:03:37s\n",
      "epoch 140| loss: 0.01326 | train_rmsle: 0.00063 | train_mae: 0.07471 | train_rmse: 0.09587 | train_mse: 0.00919 | valid_rmsle: 0.00119 | valid_mae: 0.10445 | valid_rmse: 0.1361  | valid_mse: 0.01852 |  0:03:39s\n",
      "epoch 141| loss: 0.01678 | train_rmsle: 0.00067 | train_mae: 0.09006 | train_rmse: 0.10905 | train_mse: 0.01189 | valid_rmsle: 0.00115 | valid_mae: 0.11403 | valid_rmse: 0.14338 | valid_mse: 0.02056 |  0:03:40s\n",
      "epoch 142| loss: 0.0118  | train_rmsle: 0.00032 | train_mae: 0.05585 | train_rmse: 0.07427 | train_mse: 0.00552 | valid_rmsle: 0.00082 | valid_mae: 0.09051 | valid_rmse: 0.11937 | valid_mse: 0.01425 |  0:03:42s\n",
      "epoch 143| loss: 0.01115 | train_rmsle: 0.00032 | train_mae: 0.05658 | train_rmse: 0.07576 | train_mse: 0.00574 | valid_rmsle: 0.00081 | valid_mae: 0.09173 | valid_rmse: 0.11955 | valid_mse: 0.01429 |  0:03:43s\n",
      "epoch 144| loss: 0.01174 | train_rmsle: 0.00029 | train_mae: 0.05425 | train_rmse: 0.07306 | train_mse: 0.00534 | valid_rmsle: 0.00081 | valid_mae: 0.09084 | valid_rmse: 0.12008 | valid_mse: 0.01442 |  0:03:45s\n",
      "epoch 145| loss: 0.01035 | train_rmsle: 0.00055 | train_mae: 0.07149 | train_rmse: 0.0895  | train_mse: 0.00801 | valid_rmsle: 0.00112 | valid_mae: 0.10174 | valid_rmse: 0.13173 | valid_mse: 0.01735 |  0:03:46s\n",
      "epoch 146| loss: 0.01049 | train_rmsle: 0.00047 | train_mae: 0.07354 | train_rmse: 0.09253 | train_mse: 0.00856 | valid_rmsle: 0.001   | valid_mae: 0.10548 | valid_rmse: 0.13477 | valid_mse: 0.01816 |  0:03:48s\n",
      "epoch 147| loss: 0.01271 | train_rmsle: 0.00057 | train_mae: 0.08306 | train_rmse: 0.09921 | train_mse: 0.00984 | valid_rmsle: 0.00113 | valid_mae: 0.10985 | valid_rmse: 0.13949 | valid_mse: 0.01946 |  0:03:49s\n",
      "epoch 148| loss: 0.01083 | train_rmsle: 0.00038 | train_mae: 0.06067 | train_rmse: 0.07875 | train_mse: 0.0062  | valid_rmsle: 0.00082 | valid_mae: 0.09226 | valid_rmse: 0.12048 | valid_mse: 0.01452 |  0:03:51s\n",
      "epoch 149| loss: 0.01346 | train_rmsle: 0.00035 | train_mae: 0.06309 | train_rmse: 0.08044 | train_mse: 0.00647 | valid_rmsle: 0.00088 | valid_mae: 0.09446 | valid_rmse: 0.12393 | valid_mse: 0.01536 |  0:03:53s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 142 and best_valid_mse = 0.01425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.015865488916844934 RMSE: 0.12595828244639148 R2: 0.9297695938327043 MAE: 0.09470088260495114\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_150.pt.zip\n",
      "New best model: 512_8_3_0.02_150 with r2: 0.9297695938327043\n",
      "[4/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.32546 | train_rmsle: 0.10813 | train_mae: 1.15939 | train_rmse: 1.24502 | train_mse: 1.55007 | valid_rmsle: 0.10874 | valid_mae: 1.16269 | valid_rmse: 1.24962 | valid_mse: 1.56156 |  0:00:01s\n",
      "epoch 1  | loss: 0.4776  | train_rmsle: 0.08417 | train_mae: 1.03262 | train_rmse: 1.12258 | train_mse: 1.26019 | valid_rmsle: 0.08456 | valid_mae: 1.03525 | valid_rmse: 1.12655 | valid_mse: 1.26912 |  0:00:03s\n",
      "epoch 2  | loss: 0.26254 | train_rmsle: 0.05061 | train_mae: 0.80979 | train_rmse: 0.90305 | train_mse: 0.8155  | valid_rmsle: 0.05066 | valid_mae: 0.81017 | valid_rmse: 0.90563 | valid_mse: 0.82017 |  0:00:04s\n",
      "epoch 3  | loss: 0.24059 | train_rmsle: 0.04156 | train_mae: 0.73385 | train_rmse: 0.82765 | train_mse: 0.68501 | valid_rmsle: 0.04161 | valid_mae: 0.73426 | valid_rmse: 0.83054 | valid_mse: 0.6898  |  0:00:06s\n",
      "epoch 4  | loss: 0.23195 | train_rmsle: 0.02344 | train_mae: 0.54354 | train_rmse: 0.63364 | train_mse: 0.4015  | valid_rmsle: 0.02315 | valid_mae: 0.54428 | valid_rmse: 0.63368 | valid_mse: 0.40155 |  0:00:07s\n",
      "epoch 5  | loss: 0.23992 | train_rmsle: 0.02539 | train_mae: 0.56818 | train_rmse: 0.65898 | train_mse: 0.43426 | valid_rmsle: 0.02532 | valid_mae: 0.57023 | valid_rmse: 0.66157 | valid_mse: 0.43767 |  0:00:09s\n",
      "epoch 6  | loss: 0.22143 | train_rmsle: 0.01441 | train_mae: 0.40657 | train_rmse: 0.49215 | train_mse: 0.24221 | valid_rmsle: 0.01376 | valid_mae: 0.4029  | valid_rmse: 0.48561 | valid_mse: 0.23582 |  0:00:11s\n",
      "epoch 7  | loss: 0.19207 | train_rmsle: 0.0109  | train_mae: 0.34853 | train_rmse: 0.42457 | train_mse: 0.18026 | valid_rmsle: 0.01039 | valid_mae: 0.34677 | valid_rmse: 0.4216  | valid_mse: 0.17775 |  0:00:12s\n",
      "epoch 8  | loss: 0.15937 | train_rmsle: 0.01171 | train_mae: 0.36466 | train_rmse: 0.43613 | train_mse: 0.19021 | valid_rmsle: 0.01087 | valid_mae: 0.35392 | valid_rmse: 0.42414 | valid_mse: 0.17989 |  0:00:14s\n",
      "epoch 9  | loss: 0.13789 | train_rmsle: 0.00813 | train_mae: 0.28707 | train_rmse: 0.3584  | train_mse: 0.12845 | valid_rmsle: 0.00734 | valid_mae: 0.27263 | valid_rmse: 0.34329 | valid_mse: 0.11785 |  0:00:15s\n",
      "epoch 10 | loss: 0.12635 | train_rmsle: 0.00785 | train_mae: 0.27595 | train_rmse: 0.35066 | train_mse: 0.12296 | valid_rmsle: 0.00717 | valid_mae: 0.26434 | valid_rmse: 0.33833 | valid_mse: 0.11446 |  0:00:17s\n",
      "epoch 11 | loss: 0.11606 | train_rmsle: 0.00699 | train_mae: 0.25904 | train_rmse: 0.33108 | train_mse: 0.10961 | valid_rmsle: 0.00638 | valid_mae: 0.24995 | valid_rmse: 0.32004 | valid_mse: 0.10242 |  0:00:19s\n",
      "epoch 12 | loss: 0.11324 | train_rmsle: 0.0078  | train_mae: 0.27968 | train_rmse: 0.35475 | train_mse: 0.12585 | valid_rmsle: 0.00724 | valid_mae: 0.2727  | valid_rmse: 0.34751 | valid_mse: 0.12076 |  0:00:20s\n",
      "epoch 13 | loss: 0.10947 | train_rmsle: 0.00736 | train_mae: 0.26751 | train_rmse: 0.34011 | train_mse: 0.11567 | valid_rmsle: 0.00677 | valid_mae: 0.25856 | valid_rmse: 0.32941 | valid_mse: 0.10851 |  0:00:22s\n",
      "epoch 14 | loss: 0.10505 | train_rmsle: 0.0065  | train_mae: 0.24607 | train_rmse: 0.31754 | train_mse: 0.10083 | valid_rmsle: 0.00598 | valid_mae: 0.23952 | valid_rmse: 0.30813 | valid_mse: 0.09495 |  0:00:23s\n",
      "epoch 15 | loss: 0.10751 | train_rmsle: 0.00648 | train_mae: 0.24655 | train_rmse: 0.31775 | train_mse: 0.10097 | valid_rmsle: 0.006   | valid_mae: 0.24094 | valid_rmse: 0.30994 | valid_mse: 0.09606 |  0:00:25s\n",
      "epoch 16 | loss: 0.1003  | train_rmsle: 0.00633 | train_mae: 0.24265 | train_rmse: 0.31226 | train_mse: 0.09751 | valid_rmsle: 0.00582 | valid_mae: 0.23422 | valid_rmse: 0.30269 | valid_mse: 0.09162 |  0:00:27s\n",
      "epoch 17 | loss: 0.09528 | train_rmsle: 0.00634 | train_mae: 0.24361 | train_rmse: 0.3135  | train_mse: 0.09828 | valid_rmsle: 0.00581 | valid_mae: 0.23479 | valid_rmse: 0.30268 | valid_mse: 0.09161 |  0:00:28s\n",
      "epoch 18 | loss: 0.09358 | train_rmsle: 0.00668 | train_mae: 0.2549  | train_rmse: 0.32323 | train_mse: 0.10448 | valid_rmsle: 0.00612 | valid_mae: 0.24424 | valid_rmse: 0.31224 | valid_mse: 0.09749 |  0:00:30s\n",
      "epoch 19 | loss: 0.09467 | train_rmsle: 0.00589 | train_mae: 0.22849 | train_rmse: 0.2989  | train_mse: 0.08934 | valid_rmsle: 0.00546 | valid_mae: 0.22253 | valid_rmse: 0.29118 | valid_mse: 0.08479 |  0:00:31s\n",
      "epoch 20 | loss: 0.09337 | train_rmsle: 0.00607 | train_mae: 0.23797 | train_rmse: 0.30608 | train_mse: 0.09368 | valid_rmsle: 0.00548 | valid_mae: 0.22833 | valid_rmse: 0.29435 | valid_mse: 0.08664 |  0:00:33s\n",
      "epoch 21 | loss: 0.08989 | train_rmsle: 0.00582 | train_mae: 0.22882 | train_rmse: 0.29779 | train_mse: 0.08868 | valid_rmsle: 0.0053  | valid_mae: 0.22136 | valid_rmse: 0.28808 | valid_mse: 0.08299 |  0:00:34s\n",
      "epoch 22 | loss: 0.08656 | train_rmsle: 0.00593 | train_mae: 0.23574 | train_rmse: 0.3026  | train_mse: 0.09157 | valid_rmsle: 0.0054  | valid_mae: 0.22774 | valid_rmse: 0.29218 | valid_mse: 0.08537 |  0:00:36s\n",
      "epoch 23 | loss: 0.08684 | train_rmsle: 0.00557 | train_mae: 0.22615 | train_rmse: 0.29195 | train_mse: 0.08524 | valid_rmsle: 0.00511 | valid_mae: 0.22021 | valid_rmse: 0.2834  | valid_mse: 0.08032 |  0:00:38s\n",
      "epoch 24 | loss: 0.08578 | train_rmsle: 0.00555 | train_mae: 0.22741 | train_rmse: 0.29202 | train_mse: 0.08528 | valid_rmsle: 0.00519 | valid_mae: 0.2236  | valid_rmse: 0.28564 | valid_mse: 0.08159 |  0:00:39s\n",
      "epoch 25 | loss: 0.08484 | train_rmsle: 0.00542 | train_mae: 0.219   | train_rmse: 0.28606 | train_mse: 0.08183 | valid_rmsle: 0.00503 | valid_mae: 0.21588 | valid_rmse: 0.28    | valid_mse: 0.0784  |  0:00:41s\n",
      "epoch 26 | loss: 0.08264 | train_rmsle: 0.00524 | train_mae: 0.21627 | train_rmse: 0.28139 | train_mse: 0.07918 | valid_rmsle: 0.00493 | valid_mae: 0.21438 | valid_rmse: 0.27676 | valid_mse: 0.0766  |  0:00:42s\n",
      "epoch 27 | loss: 0.08391 | train_rmsle: 0.00523 | train_mae: 0.22048 | train_rmse: 0.28369 | train_mse: 0.08048 | valid_rmsle: 0.00513 | valid_mae: 0.22422 | valid_rmse: 0.28511 | valid_mse: 0.08129 |  0:00:43s\n",
      "epoch 28 | loss: 0.08365 | train_rmsle: 0.00553 | train_mae: 0.23237 | train_rmse: 0.29443 | train_mse: 0.08669 | valid_rmsle: 0.00532 | valid_mae: 0.23557 | valid_rmse: 0.2936  | valid_mse: 0.0862  |  0:00:45s\n",
      "epoch 29 | loss: 0.08339 | train_rmsle: 0.0051  | train_mae: 0.21299 | train_rmse: 0.27768 | train_mse: 0.0771  | valid_rmsle: 0.00499 | valid_mae: 0.21583 | valid_rmse: 0.27947 | valid_mse: 0.0781  |  0:00:46s\n",
      "epoch 30 | loss: 0.07962 | train_rmsle: 0.00503 | train_mae: 0.21495 | train_rmse: 0.27748 | train_mse: 0.077   | valid_rmsle: 0.00495 | valid_mae: 0.2185  | valid_rmse: 0.27964 | valid_mse: 0.0782  |  0:00:47s\n",
      "epoch 31 | loss: 0.07878 | train_rmsle: 0.00526 | train_mae: 0.22764 | train_rmse: 0.28798 | train_mse: 0.08293 | valid_rmsle: 0.00519 | valid_mae: 0.23246 | valid_rmse: 0.28972 | valid_mse: 0.08394 |  0:00:49s\n",
      "epoch 32 | loss: 0.07707 | train_rmsle: 0.00491 | train_mae: 0.20862 | train_rmse: 0.2729  | train_mse: 0.07447 | valid_rmsle: 0.00491 | valid_mae: 0.21605 | valid_rmse: 0.27878 | valid_mse: 0.07772 |  0:00:50s\n",
      "epoch 33 | loss: 0.07733 | train_rmsle: 0.00484 | train_mae: 0.20969 | train_rmse: 0.27188 | train_mse: 0.07392 | valid_rmsle: 0.00489 | valid_mae: 0.21648 | valid_rmse: 0.27864 | valid_mse: 0.07764 |  0:00:51s\n",
      "epoch 34 | loss: 0.08016 | train_rmsle: 0.00475 | train_mae: 0.20849 | train_rmse: 0.27003 | train_mse: 0.07292 | valid_rmsle: 0.00486 | valid_mae: 0.21809 | valid_rmse: 0.27863 | valid_mse: 0.07763 |  0:00:53s\n",
      "epoch 35 | loss: 0.07635 | train_rmsle: 0.00477 | train_mae: 0.2062  | train_rmse: 0.2687  | train_mse: 0.0722  | valid_rmsle: 0.00498 | valid_mae: 0.2176  | valid_rmse: 0.28068 | valid_mse: 0.07878 |  0:00:54s\n",
      "epoch 36 | loss: 0.07622 | train_rmsle: 0.00509 | train_mae: 0.21099 | train_rmse: 0.27582 | train_mse: 0.07607 | valid_rmsle: 0.00515 | valid_mae: 0.22186 | valid_rmse: 0.28414 | valid_mse: 0.08074 |  0:00:56s\n",
      "epoch 37 | loss: 0.07459 | train_rmsle: 0.00481 | train_mae: 0.20543 | train_rmse: 0.27016 | train_mse: 0.07299 | valid_rmsle: 0.00502 | valid_mae: 0.21597 | valid_rmse: 0.2814  | valid_mse: 0.07919 |  0:00:57s\n",
      "epoch 38 | loss: 0.07677 | train_rmsle: 0.00453 | train_mae: 0.20439 | train_rmse: 0.26392 | train_mse: 0.06965 | valid_rmsle: 0.00484 | valid_mae: 0.21742 | valid_rmse: 0.27787 | valid_mse: 0.07721 |  0:00:59s\n",
      "epoch 39 | loss: 0.07333 | train_rmsle: 0.00499 | train_mae: 0.22573 | train_rmse: 0.28262 | train_mse: 0.07988 | valid_rmsle: 0.00527 | valid_mae: 0.23653 | valid_rmse: 0.29329 | valid_mse: 0.08602 |  0:01:00s\n",
      "epoch 40 | loss: 0.07203 | train_rmsle: 0.00451 | train_mae: 0.20373 | train_rmse: 0.26314 | train_mse: 0.06924 | valid_rmsle: 0.00486 | valid_mae: 0.21605 | valid_rmse: 0.27787 | valid_mse: 0.07721 |  0:01:02s\n",
      "epoch 41 | loss: 0.07095 | train_rmsle: 0.00454 | train_mae: 0.20846 | train_rmse: 0.2656  | train_mse: 0.07055 | valid_rmsle: 0.00484 | valid_mae: 0.22117 | valid_rmse: 0.27926 | valid_mse: 0.07798 |  0:01:03s\n",
      "epoch 42 | loss: 0.07044 | train_rmsle: 0.00431 | train_mae: 0.19741 | train_rmse: 0.25609 | train_mse: 0.06558 | valid_rmsle: 0.00469 | valid_mae: 0.21309 | valid_rmse: 0.27302 | valid_mse: 0.07454 |  0:01:05s\n",
      "epoch 43 | loss: 0.0674  | train_rmsle: 0.0044  | train_mae: 0.20753 | train_rmse: 0.26324 | train_mse: 0.06929 | valid_rmsle: 0.00497 | valid_mae: 0.22657 | valid_rmse: 0.28458 | valid_mse: 0.08098 |  0:01:07s\n",
      "epoch 44 | loss: 0.06784 | train_rmsle: 0.00413 | train_mae: 0.18994 | train_rmse: 0.24966 | train_mse: 0.06233 | valid_rmsle: 0.00469 | valid_mae: 0.21124 | valid_rmse: 0.27287 | valid_mse: 0.07446 |  0:01:08s\n",
      "epoch 45 | loss: 0.06584 | train_rmsle: 0.00401 | train_mae: 0.19228 | train_rmse: 0.24856 | train_mse: 0.06178 | valid_rmsle: 0.00473 | valid_mae: 0.21607 | valid_rmse: 0.27576 | valid_mse: 0.07605 |  0:01:10s\n",
      "epoch 46 | loss: 0.06384 | train_rmsle: 0.00392 | train_mae: 0.1884  | train_rmse: 0.24545 | train_mse: 0.06025 | valid_rmsle: 0.0047  | valid_mae: 0.21392 | valid_rmse: 0.27514 | valid_mse: 0.0757  |  0:01:12s\n",
      "epoch 47 | loss: 0.06463 | train_rmsle: 0.00394 | train_mae: 0.19161 | train_rmse: 0.2467  | train_mse: 0.06086 | valid_rmsle: 0.0046  | valid_mae: 0.21345 | valid_rmse: 0.27251 | valid_mse: 0.07426 |  0:01:13s\n",
      "epoch 48 | loss: 0.06448 | train_rmsle: 0.00406 | train_mae: 0.19792 | train_rmse: 0.25218 | train_mse: 0.06359 | valid_rmsle: 0.00475 | valid_mae: 0.21964 | valid_rmse: 0.27801 | valid_mse: 0.07729 |  0:01:15s\n",
      "epoch 49 | loss: 0.06847 | train_rmsle: 0.00401 | train_mae: 0.19711 | train_rmse: 0.25099 | train_mse: 0.06299 | valid_rmsle: 0.00482 | valid_mae: 0.22221 | valid_rmse: 0.27989 | valid_mse: 0.07834 |  0:01:17s\n",
      "epoch 50 | loss: 0.06331 | train_rmsle: 0.00364 | train_mae: 0.17843 | train_rmse: 0.23472 | train_mse: 0.05509 | valid_rmsle: 0.00436 | valid_mae: 0.20499 | valid_rmse: 0.26439 | valid_mse: 0.0699  |  0:01:18s\n",
      "epoch 51 | loss: 0.05992 | train_rmsle: 0.00368 | train_mae: 0.17824 | train_rmse: 0.23551 | train_mse: 0.05546 | valid_rmsle: 0.00432 | valid_mae: 0.20137 | valid_rmse: 0.26275 | valid_mse: 0.06904 |  0:01:20s\n",
      "epoch 52 | loss: 0.05934 | train_rmsle: 0.00366 | train_mae: 0.18065 | train_rmse: 0.23678 | train_mse: 0.05606 | valid_rmsle: 0.00438 | valid_mae: 0.20411 | valid_rmse: 0.26609 | valid_mse: 0.0708  |  0:01:22s\n",
      "epoch 53 | loss: 0.06331 | train_rmsle: 0.00367 | train_mae: 0.17985 | train_rmse: 0.23556 | train_mse: 0.05549 | valid_rmsle: 0.00426 | valid_mae: 0.19925 | valid_rmse: 0.26028 | valid_mse: 0.06775 |  0:01:23s\n",
      "epoch 54 | loss: 0.06333 | train_rmsle: 0.0039  | train_mae: 0.18403 | train_rmse: 0.24417 | train_mse: 0.05962 | valid_rmsle: 0.00451 | valid_mae: 0.20768 | valid_rmse: 0.27009 | valid_mse: 0.07295 |  0:01:25s\n",
      "epoch 55 | loss: 0.06308 | train_rmsle: 0.00348 | train_mae: 0.17539 | train_rmse: 0.23132 | train_mse: 0.05351 | valid_rmsle: 0.00416 | valid_mae: 0.20097 | valid_rmse: 0.2594  | valid_mse: 0.06729 |  0:01:26s\n",
      "epoch 56 | loss: 0.0564  | train_rmsle: 0.00332 | train_mae: 0.17188 | train_rmse: 0.22601 | train_mse: 0.05108 | valid_rmsle: 0.00409 | valid_mae: 0.19823 | valid_rmse: 0.25822 | valid_mse: 0.06668 |  0:01:28s\n",
      "epoch 57 | loss: 0.05648 | train_rmsle: 0.00323 | train_mae: 0.17114 | train_rmse: 0.22406 | train_mse: 0.05021 | valid_rmsle: 0.00394 | valid_mae: 0.19664 | valid_rmse: 0.25408 | valid_mse: 0.06456 |  0:01:30s\n",
      "epoch 58 | loss: 0.0532  | train_rmsle: 0.00347 | train_mae: 0.1702  | train_rmse: 0.22707 | train_mse: 0.05156 | valid_rmsle: 0.00407 | valid_mae: 0.19603 | valid_rmse: 0.25565 | valid_mse: 0.06536 |  0:01:31s\n",
      "epoch 59 | loss: 0.05374 | train_rmsle: 0.00366 | train_mae: 0.1729  | train_rmse: 0.23278 | train_mse: 0.05419 | valid_rmsle: 0.00413 | valid_mae: 0.19496 | valid_rmse: 0.25679 | valid_mse: 0.06594 |  0:01:33s\n",
      "epoch 60 | loss: 0.05374 | train_rmsle: 0.00299 | train_mae: 0.16567 | train_rmse: 0.21626 | train_mse: 0.04677 | valid_rmsle: 0.0037  | valid_mae: 0.19249 | valid_rmse: 0.2474  | valid_mse: 0.06121 |  0:01:35s\n",
      "epoch 61 | loss: 0.04912 | train_rmsle: 0.00313 | train_mae: 0.16447 | train_rmse: 0.21941 | train_mse: 0.04814 | valid_rmsle: 0.00379 | valid_mae: 0.19279 | valid_rmse: 0.24953 | valid_mse: 0.06227 |  0:01:36s\n",
      "epoch 62 | loss: 0.04846 | train_rmsle: 0.00269 | train_mae: 0.15637 | train_rmse: 0.20581 | train_mse: 0.04236 | valid_rmsle: 0.00344 | valid_mae: 0.18749 | valid_rmse: 0.23928 | valid_mse: 0.05725 |  0:01:38s\n",
      "epoch 63 | loss: 0.04682 | train_rmsle: 0.00257 | train_mae: 0.1527  | train_rmse: 0.20178 | train_mse: 0.04072 | valid_rmsle: 0.00344 | valid_mae: 0.18608 | valid_rmse: 0.24051 | valid_mse: 0.05785 |  0:01:39s\n",
      "epoch 64 | loss: 0.0457  | train_rmsle: 0.00265 | train_mae: 0.15964 | train_rmse: 0.20714 | train_mse: 0.04291 | valid_rmsle: 0.00347 | valid_mae: 0.19164 | valid_rmse: 0.24163 | valid_mse: 0.05838 |  0:01:40s\n",
      "epoch 65 | loss: 0.04589 | train_rmsle: 0.00238 | train_mae: 0.1461  | train_rmse: 0.19364 | train_mse: 0.0375  | valid_rmsle: 0.00344 | valid_mae: 0.18461 | valid_rmse: 0.23936 | valid_mse: 0.05729 |  0:01:42s\n",
      "epoch 66 | loss: 0.04329 | train_rmsle: 0.0025  | train_mae: 0.15679 | train_rmse: 0.20293 | train_mse: 0.04118 | valid_rmsle: 0.0035  | valid_mae: 0.19044 | valid_rmse: 0.2441  | valid_mse: 0.05959 |  0:01:43s\n",
      "epoch 67 | loss: 0.04115 | train_rmsle: 0.00233 | train_mae: 0.14409 | train_rmse: 0.19149 | train_mse: 0.03667 | valid_rmsle: 0.00341 | valid_mae: 0.18155 | valid_rmse: 0.24095 | valid_mse: 0.05806 |  0:01:44s\n",
      "epoch 68 | loss: 0.04182 | train_rmsle: 0.00226 | train_mae: 0.14667 | train_rmse: 0.19223 | train_mse: 0.03695 | valid_rmsle: 0.00323 | valid_mae: 0.18027 | valid_rmse: 0.23545 | valid_mse: 0.05544 |  0:01:46s\n",
      "epoch 69 | loss: 0.04067 | train_rmsle: 0.00209 | train_mae: 0.13699 | train_rmse: 0.18285 | train_mse: 0.03344 | valid_rmsle: 0.00305 | valid_mae: 0.17274 | valid_rmse: 0.22783 | valid_mse: 0.05191 |  0:01:47s\n",
      "epoch 70 | loss: 0.0395  | train_rmsle: 0.00204 | train_mae: 0.1359  | train_rmse: 0.18081 | train_mse: 0.03269 | valid_rmsle: 0.00305 | valid_mae: 0.17504 | valid_rmse: 0.22908 | valid_mse: 0.05248 |  0:01:49s\n",
      "epoch 71 | loss: 0.03807 | train_rmsle: 0.00242 | train_mae: 0.1599  | train_rmse: 0.20401 | train_mse: 0.04162 | valid_rmsle: 0.00341 | valid_mae: 0.19395 | valid_rmse: 0.24553 | valid_mse: 0.06028 |  0:01:51s\n",
      "epoch 72 | loss: 0.04005 | train_rmsle: 0.00219 | train_mae: 0.14342 | train_rmse: 0.18932 | train_mse: 0.03584 | valid_rmsle: 0.00304 | valid_mae: 0.1774  | valid_rmse: 0.22922 | valid_mse: 0.05254 |  0:01:52s\n",
      "epoch 73 | loss: 0.03809 | train_rmsle: 0.00212 | train_mae: 0.14786 | train_rmse: 0.19032 | train_mse: 0.03622 | valid_rmsle: 0.00314 | valid_mae: 0.18202 | valid_rmse: 0.23305 | valid_mse: 0.05431 |  0:01:54s\n",
      "epoch 74 | loss: 0.03986 | train_rmsle: 0.00219 | train_mae: 0.15195 | train_rmse: 0.19349 | train_mse: 0.03744 | valid_rmsle: 0.00312 | valid_mae: 0.18345 | valid_rmse: 0.23304 | valid_mse: 0.05431 |  0:01:56s\n",
      "epoch 75 | loss: 0.04368 | train_rmsle: 0.00197 | train_mae: 0.14139 | train_rmse: 0.18502 | train_mse: 0.03423 | valid_rmsle: 0.00301 | valid_mae: 0.1799  | valid_rmse: 0.23037 | valid_mse: 0.05307 |  0:01:57s\n",
      "epoch 76 | loss: 0.03534 | train_rmsle: 0.00182 | train_mae: 0.13024 | train_rmse: 0.17474 | train_mse: 0.03053 | valid_rmsle: 0.00283 | valid_mae: 0.16821 | valid_rmse: 0.22345 | valid_mse: 0.04993 |  0:01:59s\n",
      "epoch 77 | loss: 0.03722 | train_rmsle: 0.00195 | train_mae: 0.14006 | train_rmse: 0.17939 | train_mse: 0.03218 | valid_rmsle: 0.00304 | valid_mae: 0.17646 | valid_rmse: 0.23084 | valid_mse: 0.05329 |  0:02:01s\n",
      "epoch 78 | loss: 0.03329 | train_rmsle: 0.00173 | train_mae: 0.13073 | train_rmse: 0.17398 | train_mse: 0.03027 | valid_rmsle: 0.00266 | valid_mae: 0.17007 | valid_rmse: 0.21843 | valid_mse: 0.04771 |  0:02:02s\n",
      "epoch 79 | loss: 0.03427 | train_rmsle: 0.00151 | train_mae: 0.11656 | train_rmse: 0.15852 | train_mse: 0.02513 | valid_rmsle: 0.00255 | valid_mae: 0.15893 | valid_rmse: 0.21227 | valid_mse: 0.04506 |  0:02:04s\n",
      "epoch 80 | loss: 0.03039 | train_rmsle: 0.00149 | train_mae: 0.1187  | train_rmse: 0.15821 | train_mse: 0.02503 | valid_rmsle: 0.00252 | valid_mae: 0.16101 | valid_rmse: 0.21124 | valid_mse: 0.04462 |  0:02:06s\n",
      "epoch 81 | loss: 0.03158 | train_rmsle: 0.00148 | train_mae: 0.11909 | train_rmse: 0.15882 | train_mse: 0.02523 | valid_rmsle: 0.00256 | valid_mae: 0.16257 | valid_rmse: 0.21228 | valid_mse: 0.04506 |  0:02:07s\n",
      "epoch 82 | loss: 0.0345  | train_rmsle: 0.00154 | train_mae: 0.12386 | train_rmse: 0.1629  | train_mse: 0.02653 | valid_rmsle: 0.00258 | valid_mae: 0.16646 | valid_rmse: 0.21451 | valid_mse: 0.04601 |  0:02:09s\n",
      "epoch 83 | loss: 0.0345  | train_rmsle: 0.00149 | train_mae: 0.11953 | train_rmse: 0.16083 | train_mse: 0.02586 | valid_rmsle: 0.00244 | valid_mae: 0.1615  | valid_rmse: 0.20901 | valid_mse: 0.04369 |  0:02:11s\n",
      "epoch 84 | loss: 0.03044 | train_rmsle: 0.0015  | train_mae: 0.1209  | train_rmse: 0.1583  | train_mse: 0.02506 | valid_rmsle: 0.00268 | valid_mae: 0.16486 | valid_rmse: 0.2157  | valid_mse: 0.04653 |  0:02:12s\n",
      "epoch 85 | loss: 0.0283  | train_rmsle: 0.00142 | train_mae: 0.11775 | train_rmse: 0.1553  | train_mse: 0.02412 | valid_rmsle: 0.00256 | valid_mae: 0.16199 | valid_rmse: 0.21286 | valid_mse: 0.04531 |  0:02:14s\n",
      "epoch 86 | loss: 0.02822 | train_rmsle: 0.00166 | train_mae: 0.12466 | train_rmse: 0.16792 | train_mse: 0.0282  | valid_rmsle: 0.00261 | valid_mae: 0.16415 | valid_rmse: 0.21448 | valid_mse: 0.046   |  0:02:15s\n",
      "epoch 87 | loss: 0.03079 | train_rmsle: 0.00131 | train_mae: 0.10835 | train_rmse: 0.14939 | train_mse: 0.02232 | valid_rmsle: 0.00245 | valid_mae: 0.15519 | valid_rmse: 0.20872 | valid_mse: 0.04356 |  0:02:17s\n",
      "epoch 88 | loss: 0.0285  | train_rmsle: 0.00153 | train_mae: 0.12651 | train_rmse: 0.16257 | train_mse: 0.02643 | valid_rmsle: 0.00263 | valid_mae: 0.16665 | valid_rmse: 0.21519 | valid_mse: 0.04631 |  0:02:19s\n",
      "epoch 89 | loss: 0.0283  | train_rmsle: 0.00123 | train_mae: 0.10701 | train_rmse: 0.14605 | train_mse: 0.02133 | valid_rmsle: 0.00233 | valid_mae: 0.15466 | valid_rmse: 0.20423 | valid_mse: 0.04171 |  0:02:20s\n",
      "epoch 90 | loss: 0.02925 | train_rmsle: 0.00131 | train_mae: 0.11287 | train_rmse: 0.15189 | train_mse: 0.02307 | valid_rmsle: 0.0023  | valid_mae: 0.15479 | valid_rmse: 0.20362 | valid_mse: 0.04146 |  0:02:22s\n",
      "epoch 91 | loss: 0.02823 | train_rmsle: 0.00127 | train_mae: 0.10918 | train_rmse: 0.14713 | train_mse: 0.02165 | valid_rmsle: 0.00231 | valid_mae: 0.15246 | valid_rmse: 0.20335 | valid_mse: 0.04135 |  0:02:24s\n",
      "epoch 92 | loss: 0.02827 | train_rmsle: 0.00137 | train_mae: 0.11697 | train_rmse: 0.15307 | train_mse: 0.02343 | valid_rmsle: 0.00246 | valid_mae: 0.15875 | valid_rmse: 0.20889 | valid_mse: 0.04364 |  0:02:25s\n",
      "epoch 93 | loss: 0.02621 | train_rmsle: 0.00112 | train_mae: 0.10105 | train_rmse: 0.13893 | train_mse: 0.0193  | valid_rmsle: 0.00221 | valid_mae: 0.1485  | valid_rmse: 0.19996 | valid_mse: 0.03998 |  0:02:27s\n",
      "epoch 94 | loss: 0.02587 | train_rmsle: 0.00118 | train_mae: 0.1043  | train_rmse: 0.14191 | train_mse: 0.02014 | valid_rmsle: 0.00217 | valid_mae: 0.14732 | valid_rmse: 0.19796 | valid_mse: 0.03919 |  0:02:29s\n",
      "epoch 95 | loss: 0.02606 | train_rmsle: 0.00114 | train_mae: 0.10488 | train_rmse: 0.14225 | train_mse: 0.02024 | valid_rmsle: 0.00214 | valid_mae: 0.14952 | valid_rmse: 0.1962  | valid_mse: 0.0385  |  0:02:30s\n",
      "epoch 96 | loss: 0.02795 | train_rmsle: 0.00166 | train_mae: 0.13199 | train_rmse: 0.16843 | train_mse: 0.02837 | valid_rmsle: 0.0027  | valid_mae: 0.17061 | valid_rmse: 0.21762 | valid_mse: 0.04736 |  0:02:32s\n",
      "epoch 97 | loss: 0.02758 | train_rmsle: 0.00118 | train_mae: 0.10418 | train_rmse: 0.1412  | train_mse: 0.01994 | valid_rmsle: 0.00208 | valid_mae: 0.14598 | valid_rmse: 0.19298 | valid_mse: 0.03724 |  0:02:33s\n",
      "epoch 98 | loss: 0.02598 | train_rmsle: 0.00113 | train_mae: 0.10468 | train_rmse: 0.14174 | train_mse: 0.02009 | valid_rmsle: 0.00204 | valid_mae: 0.14638 | valid_rmse: 0.19261 | valid_mse: 0.0371  |  0:02:35s\n",
      "epoch 99 | loss: 0.02602 | train_rmsle: 0.00122 | train_mae: 0.11147 | train_rmse: 0.1483  | train_mse: 0.02199 | valid_rmsle: 0.00212 | valid_mae: 0.15258 | valid_rmse: 0.19583 | valid_mse: 0.03835 |  0:02:36s\n",
      "epoch 100| loss: 0.02483 | train_rmsle: 0.00103 | train_mae: 0.0978  | train_rmse: 0.13555 | train_mse: 0.01837 | valid_rmsle: 0.00195 | valid_mae: 0.13976 | valid_rmse: 0.18695 | valid_mse: 0.03495 |  0:02:38s\n",
      "epoch 101| loss: 0.02397 | train_rmsle: 0.00108 | train_mae: 0.10142 | train_rmse: 0.13837 | train_mse: 0.01915 | valid_rmsle: 0.00191 | valid_mae: 0.14037 | valid_rmse: 0.18665 | valid_mse: 0.03484 |  0:02:39s\n",
      "epoch 102| loss: 0.02356 | train_rmsle: 0.00105 | train_mae: 0.09898 | train_rmse: 0.13306 | train_mse: 0.01771 | valid_rmsle: 0.0019  | valid_mae: 0.13791 | valid_rmse: 0.18306 | valid_mse: 0.03351 |  0:02:40s\n",
      "epoch 103| loss: 0.02504 | train_rmsle: 0.00098 | train_mae: 0.09348 | train_rmse: 0.13095 | train_mse: 0.01715 | valid_rmsle: 0.00181 | valid_mae: 0.13444 | valid_rmse: 0.18069 | valid_mse: 0.03265 |  0:02:42s\n",
      "epoch 104| loss: 0.02478 | train_rmsle: 0.00111 | train_mae: 0.10542 | train_rmse: 0.14116 | train_mse: 0.01993 | valid_rmsle: 0.00201 | valid_mae: 0.14708 | valid_rmse: 0.19083 | valid_mse: 0.03642 |  0:02:43s\n",
      "epoch 105| loss: 0.02155 | train_rmsle: 0.00104 | train_mae: 0.10031 | train_rmse: 0.13384 | train_mse: 0.01791 | valid_rmsle: 0.00192 | valid_mae: 0.14211 | valid_rmse: 0.18515 | valid_mse: 0.03428 |  0:02:45s\n",
      "epoch 106| loss: 0.02499 | train_rmsle: 0.00093 | train_mae: 0.0922  | train_rmse: 0.12723 | train_mse: 0.01619 | valid_rmsle: 0.00181 | valid_mae: 0.1354  | valid_rmse: 0.1811  | valid_mse: 0.0328  |  0:02:46s\n",
      "epoch 107| loss: 0.02257 | train_rmsle: 0.00095 | train_mae: 0.09684 | train_rmse: 0.13068 | train_mse: 0.01708 | valid_rmsle: 0.00175 | valid_mae: 0.13724 | valid_rmse: 0.17826 | valid_mse: 0.03178 |  0:02:48s\n",
      "epoch 108| loss: 0.02133 | train_rmsle: 0.00086 | train_mae: 0.08833 | train_rmse: 0.12164 | train_mse: 0.0148  | valid_rmsle: 0.00166 | valid_mae: 0.13003 | valid_rmse: 0.1736  | valid_mse: 0.03014 |  0:02:49s\n",
      "epoch 109| loss: 0.02208 | train_rmsle: 0.00087 | train_mae: 0.09032 | train_rmse: 0.12193 | train_mse: 0.01487 | valid_rmsle: 0.00176 | valid_mae: 0.13118 | valid_rmse: 0.17613 | valid_mse: 0.03102 |  0:02:51s\n",
      "epoch 110| loss: 0.02407 | train_rmsle: 0.00112 | train_mae: 0.10388 | train_rmse: 0.13995 | train_mse: 0.01959 | valid_rmsle: 0.00175 | valid_mae: 0.13427 | valid_rmse: 0.1797  | valid_mse: 0.03229 |  0:02:53s\n",
      "epoch 111| loss: 0.02545 | train_rmsle: 0.00156 | train_mae: 0.12158 | train_rmse: 0.15642 | train_mse: 0.02447 | valid_rmsle: 0.00219 | valid_mae: 0.1479  | valid_rmse: 0.19417 | valid_mse: 0.0377  |  0:02:54s\n",
      "epoch 112| loss: 0.02337 | train_rmsle: 0.00128 | train_mae: 0.10605 | train_rmse: 0.14838 | train_mse: 0.02202 | valid_rmsle: 0.00199 | valid_mae: 0.13899 | valid_rmse: 0.18882 | valid_mse: 0.03565 |  0:02:56s\n",
      "epoch 113| loss: 0.02033 | train_rmsle: 0.00109 | train_mae: 0.10721 | train_rmse: 0.13743 | train_mse: 0.01889 | valid_rmsle: 0.00174 | valid_mae: 0.13811 | valid_rmse: 0.17708 | valid_mse: 0.03136 |  0:02:58s\n",
      "epoch 114| loss: 0.01924 | train_rmsle: 0.0008  | train_mae: 0.08636 | train_rmse: 0.11731 | train_mse: 0.01376 | valid_rmsle: 0.00146 | valid_mae: 0.12183 | valid_rmse: 0.16185 | valid_mse: 0.0262  |  0:02:59s\n",
      "epoch 115| loss: 0.02    | train_rmsle: 0.00072 | train_mae: 0.08105 | train_rmse: 0.11155 | train_mse: 0.01244 | valid_rmsle: 0.00142 | valid_mae: 0.11561 | valid_rmse: 0.15754 | valid_mse: 0.02482 |  0:03:01s\n",
      "epoch 116| loss: 0.02129 | train_rmsle: 0.00067 | train_mae: 0.07798 | train_rmse: 0.10737 | train_mse: 0.01153 | valid_rmsle: 0.0014  | valid_mae: 0.11624 | valid_rmse: 0.1571  | valid_mse: 0.02468 |  0:03:03s\n",
      "epoch 117| loss: 0.01957 | train_rmsle: 0.00068 | train_mae: 0.07896 | train_rmse: 0.10903 | train_mse: 0.01189 | valid_rmsle: 0.00142 | valid_mae: 0.11573 | valid_rmse: 0.1582  | valid_mse: 0.02503 |  0:03:04s\n",
      "epoch 118| loss: 0.01683 | train_rmsle: 0.00062 | train_mae: 0.07579 | train_rmse: 0.10376 | train_mse: 0.01077 | valid_rmsle: 0.00128 | valid_mae: 0.11174 | valid_rmse: 0.15106 | valid_mse: 0.02282 |  0:03:06s\n",
      "epoch 119| loss: 0.01611 | train_rmsle: 0.00103 | train_mae: 0.09482 | train_rmse: 0.1227  | train_mse: 0.01506 | valid_rmsle: 0.00183 | valid_mae: 0.12889 | valid_rmse: 0.16865 | valid_mse: 0.02844 |  0:03:07s\n",
      "epoch 120| loss: 0.01762 | train_rmsle: 0.00069 | train_mae: 0.08401 | train_rmse: 0.10993 | train_mse: 0.01208 | valid_rmsle: 0.00138 | valid_mae: 0.11953 | valid_rmse: 0.15654 | valid_mse: 0.0245  |  0:03:09s\n",
      "epoch 121| loss: 0.01801 | train_rmsle: 0.00074 | train_mae: 0.0883  | train_rmse: 0.11597 | train_mse: 0.01345 | valid_rmsle: 0.0014  | valid_mae: 0.1206  | valid_rmse: 0.15832 | valid_mse: 0.02506 |  0:03:10s\n",
      "epoch 122| loss: 0.01606 | train_rmsle: 0.00072 | train_mae: 0.08758 | train_rmse: 0.11204 | train_mse: 0.01255 | valid_rmsle: 0.00136 | valid_mae: 0.11828 | valid_rmse: 0.15315 | valid_mse: 0.02345 |  0:03:12s\n",
      "epoch 123| loss: 0.01848 | train_rmsle: 0.00059 | train_mae: 0.07427 | train_rmse: 0.10317 | train_mse: 0.01064 | valid_rmsle: 0.00122 | valid_mae: 0.11122 | valid_rmse: 0.14815 | valid_mse: 0.02195 |  0:03:13s\n",
      "epoch 124| loss: 0.01464 | train_rmsle: 0.00063 | train_mae: 0.07765 | train_rmse: 0.10246 | train_mse: 0.0105  | valid_rmsle: 0.00115 | valid_mae: 0.10885 | valid_rmse: 0.14202 | valid_mse: 0.02017 |  0:03:15s\n",
      "epoch 125| loss: 0.01709 | train_rmsle: 0.00069 | train_mae: 0.08527 | train_rmse: 0.11182 | train_mse: 0.0125  | valid_rmsle: 0.00121 | valid_mae: 0.1156  | valid_rmse: 0.14812 | valid_mse: 0.02194 |  0:03:16s\n",
      "epoch 126| loss: 0.01624 | train_rmsle: 0.0007  | train_mae: 0.07932 | train_rmse: 0.10674 | train_mse: 0.01139 | valid_rmsle: 0.00114 | valid_mae: 0.10707 | valid_rmse: 0.14097 | valid_mse: 0.01987 |  0:03:18s\n",
      "epoch 127| loss: 0.01529 | train_rmsle: 0.00047 | train_mae: 0.06583 | train_rmse: 0.0907  | train_mse: 0.00823 | valid_rmsle: 0.00104 | valid_mae: 0.10146 | valid_rmse: 0.13584 | valid_mse: 0.01845 |  0:03:19s\n",
      "epoch 128| loss: 0.01465 | train_rmsle: 0.00054 | train_mae: 0.07217 | train_rmse: 0.09612 | train_mse: 0.00924 | valid_rmsle: 0.00109 | valid_mae: 0.10594 | valid_rmse: 0.13854 | valid_mse: 0.01919 |  0:03:21s\n",
      "epoch 129| loss: 0.01614 | train_rmsle: 0.00053 | train_mae: 0.06909 | train_rmse: 0.09843 | train_mse: 0.00969 | valid_rmsle: 0.00106 | valid_mae: 0.10163 | valid_rmse: 0.13806 | valid_mse: 0.01906 |  0:03:23s\n",
      "epoch 130| loss: 0.01484 | train_rmsle: 0.00056 | train_mae: 0.07419 | train_rmse: 0.09927 | train_mse: 0.00985 | valid_rmsle: 0.00112 | valid_mae: 0.10545 | valid_rmse: 0.13985 | valid_mse: 0.01956 |  0:03:24s\n",
      "epoch 131| loss: 0.0144  | train_rmsle: 0.00065 | train_mae: 0.0729  | train_rmse: 0.11076 | train_mse: 0.01227 | valid_rmsle: 0.00119 | valid_mae: 0.10752 | valid_rmse: 0.14877 | valid_mse: 0.02213 |  0:03:26s\n",
      "epoch 132| loss: 0.01462 | train_rmsle: 0.00066 | train_mae: 0.08046 | train_rmse: 0.1025  | train_mse: 0.01051 | valid_rmsle: 0.00113 | valid_mae: 0.1075  | valid_rmse: 0.13854 | valid_mse: 0.01919 |  0:03:28s\n",
      "epoch 133| loss: 0.01209 | train_rmsle: 0.00055 | train_mae: 0.07693 | train_rmse: 0.09884 | train_mse: 0.00977 | valid_rmsle: 0.00112 | valid_mae: 0.10852 | valid_rmse: 0.14032 | valid_mse: 0.01969 |  0:03:29s\n",
      "epoch 134| loss: 0.01259 | train_rmsle: 0.00038 | train_mae: 0.06109 | train_rmse: 0.08201 | train_mse: 0.00673 | valid_rmsle: 0.00091 | valid_mae: 0.09483 | valid_rmse: 0.12723 | valid_mse: 0.01619 |  0:03:31s\n",
      "epoch 135| loss: 0.0128  | train_rmsle: 0.00053 | train_mae: 0.07531 | train_rmse: 0.09923 | train_mse: 0.00985 | valid_rmsle: 0.00107 | valid_mae: 0.10704 | valid_rmse: 0.14011 | valid_mse: 0.01963 |  0:03:32s\n",
      "epoch 136| loss: 0.01286 | train_rmsle: 0.00059 | train_mae: 0.08156 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00119 | valid_mae: 0.11139 | valid_rmse: 0.14483 | valid_mse: 0.02098 |  0:03:34s\n",
      "epoch 137| loss: 0.01495 | train_rmsle: 0.001   | train_mae: 0.09884 | train_rmse: 0.12107 | train_mse: 0.01466 | valid_rmsle: 0.00157 | valid_mae: 0.12288 | valid_rmse: 0.15613 | valid_mse: 0.02438 |  0:03:35s\n",
      "epoch 138| loss: 0.01237 | train_rmsle: 0.00043 | train_mae: 0.06597 | train_rmse: 0.08767 | train_mse: 0.00769 | valid_rmsle: 0.00094 | valid_mae: 0.09956 | valid_rmse: 0.13008 | valid_mse: 0.01692 |  0:03:36s\n",
      "epoch 139| loss: 0.01312 | train_rmsle: 0.00081 | train_mae: 0.085   | train_rmse: 0.111   | train_mse: 0.01232 | valid_rmsle: 0.00137 | valid_mae: 0.11277 | valid_rmse: 0.14683 | valid_mse: 0.02156 |  0:03:38s\n",
      "epoch 140| loss: 0.01326 | train_rmsle: 0.00063 | train_mae: 0.07471 | train_rmse: 0.09587 | train_mse: 0.00919 | valid_rmsle: 0.00119 | valid_mae: 0.10445 | valid_rmse: 0.1361  | valid_mse: 0.01852 |  0:03:39s\n",
      "epoch 141| loss: 0.01678 | train_rmsle: 0.00067 | train_mae: 0.09006 | train_rmse: 0.10905 | train_mse: 0.01189 | valid_rmsle: 0.00115 | valid_mae: 0.11403 | valid_rmse: 0.14338 | valid_mse: 0.02056 |  0:03:41s\n",
      "epoch 142| loss: 0.0118  | train_rmsle: 0.00032 | train_mae: 0.05585 | train_rmse: 0.07427 | train_mse: 0.00552 | valid_rmsle: 0.00082 | valid_mae: 0.09051 | valid_rmse: 0.11937 | valid_mse: 0.01425 |  0:03:42s\n",
      "epoch 143| loss: 0.01115 | train_rmsle: 0.00032 | train_mae: 0.05658 | train_rmse: 0.07576 | train_mse: 0.00574 | valid_rmsle: 0.00081 | valid_mae: 0.09173 | valid_rmse: 0.11955 | valid_mse: 0.01429 |  0:03:44s\n",
      "epoch 144| loss: 0.01174 | train_rmsle: 0.00029 | train_mae: 0.05425 | train_rmse: 0.07306 | train_mse: 0.00534 | valid_rmsle: 0.00081 | valid_mae: 0.09084 | valid_rmse: 0.12008 | valid_mse: 0.01442 |  0:03:46s\n",
      "epoch 145| loss: 0.01035 | train_rmsle: 0.00055 | train_mae: 0.07149 | train_rmse: 0.0895  | train_mse: 0.00801 | valid_rmsle: 0.00112 | valid_mae: 0.10174 | valid_rmse: 0.13173 | valid_mse: 0.01735 |  0:03:47s\n",
      "epoch 146| loss: 0.01049 | train_rmsle: 0.00047 | train_mae: 0.07354 | train_rmse: 0.09253 | train_mse: 0.00856 | valid_rmsle: 0.001   | valid_mae: 0.10548 | valid_rmse: 0.13477 | valid_mse: 0.01816 |  0:03:49s\n",
      "epoch 147| loss: 0.01271 | train_rmsle: 0.00057 | train_mae: 0.08306 | train_rmse: 0.09921 | train_mse: 0.00984 | valid_rmsle: 0.00113 | valid_mae: 0.10985 | valid_rmse: 0.13949 | valid_mse: 0.01946 |  0:03:51s\n",
      "epoch 148| loss: 0.01083 | train_rmsle: 0.00038 | train_mae: 0.06067 | train_rmse: 0.07875 | train_mse: 0.0062  | valid_rmsle: 0.00082 | valid_mae: 0.09226 | valid_rmse: 0.12048 | valid_mse: 0.01452 |  0:03:52s\n",
      "epoch 149| loss: 0.01346 | train_rmsle: 0.00035 | train_mae: 0.06309 | train_rmse: 0.08044 | train_mse: 0.00647 | valid_rmsle: 0.00088 | valid_mae: 0.09446 | valid_rmse: 0.12393 | valid_mse: 0.01536 |  0:03:54s\n",
      "epoch 150| loss: 0.01076 | train_rmsle: 0.00034 | train_mae: 0.06012 | train_rmse: 0.07698 | train_mse: 0.00593 | valid_rmsle: 0.00087 | valid_mae: 0.09448 | valid_rmse: 0.12421 | valid_mse: 0.01543 |  0:03:56s\n",
      "epoch 151| loss: 0.01207 | train_rmsle: 0.00033 | train_mae: 0.05703 | train_rmse: 0.07525 | train_mse: 0.00566 | valid_rmsle: 0.0008  | valid_mae: 0.09052 | valid_rmse: 0.11936 | valid_mse: 0.01425 |  0:03:57s\n",
      "epoch 152| loss: 0.00975 | train_rmsle: 0.00043 | train_mae: 0.07135 | train_rmse: 0.08648 | train_mse: 0.00748 | valid_rmsle: 0.00095 | valid_mae: 0.10127 | valid_rmse: 0.12862 | valid_mse: 0.01654 |  0:03:59s\n",
      "epoch 153| loss: 0.0113  | train_rmsle: 0.00073 | train_mae: 0.08696 | train_rmse: 0.10308 | train_mse: 0.01063 | valid_rmsle: 0.00128 | valid_mae: 0.11243 | valid_rmse: 0.14077 | valid_mse: 0.01982 |  0:04:01s\n",
      "epoch 154| loss: 0.01069 | train_rmsle: 0.00038 | train_mae: 0.06696 | train_rmse: 0.0832  | train_mse: 0.00692 | valid_rmsle: 0.00092 | valid_mae: 0.09983 | valid_rmse: 0.12744 | valid_mse: 0.01624 |  0:04:02s\n",
      "epoch 155| loss: 0.01002 | train_rmsle: 0.00037 | train_mae: 0.06533 | train_rmse: 0.08319 | train_mse: 0.00692 | valid_rmsle: 0.00086 | valid_mae: 0.09789 | valid_rmse: 0.12375 | valid_mse: 0.01531 |  0:04:04s\n",
      "epoch 156| loss: 0.00971 | train_rmsle: 0.00049 | train_mae: 0.07993 | train_rmse: 0.09433 | train_mse: 0.0089  | valid_rmsle: 0.00102 | valid_mae: 0.1079  | valid_rmse: 0.13341 | valid_mse: 0.0178  |  0:04:06s\n",
      "epoch 157| loss: 0.00926 | train_rmsle: 0.0003  | train_mae: 0.05881 | train_rmse: 0.07393 | train_mse: 0.00547 | valid_rmsle: 0.00084 | valid_mae: 0.09525 | valid_rmse: 0.12127 | valid_mse: 0.01471 |  0:04:07s\n",
      "epoch 158| loss: 0.01028 | train_rmsle: 0.00042 | train_mae: 0.0611  | train_rmse: 0.07847 | train_mse: 0.00616 | valid_rmsle: 0.00088 | valid_mae: 0.09368 | valid_rmse: 0.12106 | valid_mse: 0.01465 |  0:04:09s\n",
      "epoch 159| loss: 0.01049 | train_rmsle: 0.00035 | train_mae: 0.05864 | train_rmse: 0.07402 | train_mse: 0.00548 | valid_rmsle: 0.00082 | valid_mae: 0.08994 | valid_rmse: 0.11744 | valid_mse: 0.01379 |  0:04:11s\n",
      "epoch 160| loss: 0.01045 | train_rmsle: 0.00021 | train_mae: 0.04669 | train_rmse: 0.06149 | train_mse: 0.00378 | valid_rmsle: 0.00073 | valid_mae: 0.08514 | valid_rmse: 0.11172 | valid_mse: 0.01248 |  0:04:12s\n",
      "epoch 161| loss: 0.00883 | train_rmsle: 0.00024 | train_mae: 0.04626 | train_rmse: 0.061   | train_mse: 0.00372 | valid_rmsle: 0.00079 | valid_mae: 0.08443 | valid_rmse: 0.11233 | valid_mse: 0.01262 |  0:04:14s\n",
      "epoch 162| loss: 0.00971 | train_rmsle: 0.00037 | train_mae: 0.06811 | train_rmse: 0.0812  | train_mse: 0.00659 | valid_rmsle: 0.00096 | valid_mae: 0.09986 | valid_rmse: 0.12658 | valid_mse: 0.01602 |  0:04:16s\n",
      "epoch 163| loss: 0.00935 | train_rmsle: 0.00025 | train_mae: 0.05135 | train_rmse: 0.06515 | train_mse: 0.00424 | valid_rmsle: 0.00075 | valid_mae: 0.08585 | valid_rmse: 0.11216 | valid_mse: 0.01258 |  0:04:17s\n",
      "epoch 164| loss: 0.01098 | train_rmsle: 0.00027 | train_mae: 0.05403 | train_rmse: 0.06961 | train_mse: 0.00485 | valid_rmsle: 0.0008  | valid_mae: 0.08924 | valid_rmse: 0.11636 | valid_mse: 0.01354 |  0:04:19s\n",
      "epoch 165| loss: 0.01013 | train_rmsle: 0.00028 | train_mae: 0.05657 | train_rmse: 0.07003 | train_mse: 0.0049  | valid_rmsle: 0.00085 | valid_mae: 0.09407 | valid_rmse: 0.11941 | valid_mse: 0.01426 |  0:04:21s\n",
      "epoch 166| loss: 0.01036 | train_rmsle: 0.00079 | train_mae: 0.10357 | train_rmse: 0.11521 | train_mse: 0.01327 | valid_rmsle: 0.00142 | valid_mae: 0.12615 | valid_rmse: 0.1522  | valid_mse: 0.02316 |  0:04:22s\n",
      "epoch 167| loss: 0.01112 | train_rmsle: 0.00045 | train_mae: 0.06097 | train_rmse: 0.07821 | train_mse: 0.00612 | valid_rmsle: 0.00101 | valid_mae: 0.09485 | valid_rmse: 0.12309 | valid_mse: 0.01515 |  0:04:24s\n",
      "epoch 168| loss: 0.00953 | train_rmsle: 0.00052 | train_mae: 0.07682 | train_rmse: 0.0918  | train_mse: 0.00843 | valid_rmsle: 0.00111 | valid_mae: 0.10691 | valid_rmse: 0.13389 | valid_mse: 0.01793 |  0:04:26s\n",
      "epoch 169| loss: 0.01004 | train_rmsle: 0.00016 | train_mae: 0.0397  | train_rmse: 0.05323 | train_mse: 0.00283 | valid_rmsle: 0.00071 | valid_mae: 0.08429 | valid_rmse: 0.11002 | valid_mse: 0.01211 |  0:04:27s\n",
      "epoch 170| loss: 0.0098  | train_rmsle: 0.00049 | train_mae: 0.07973 | train_rmse: 0.0935  | train_mse: 0.00874 | valid_rmsle: 0.00107 | valid_mae: 0.10439 | valid_rmse: 0.13481 | valid_mse: 0.01817 |  0:04:29s\n",
      "epoch 171| loss: 0.00959 | train_rmsle: 0.00022 | train_mae: 0.04869 | train_rmse: 0.06277 | train_mse: 0.00394 | valid_rmsle: 0.00078 | valid_mae: 0.08945 | valid_rmse: 0.11555 | valid_mse: 0.01335 |  0:04:30s\n",
      "epoch 172| loss: 0.01319 | train_rmsle: 0.00055 | train_mae: 0.06978 | train_rmse: 0.08978 | train_mse: 0.00806 | valid_rmsle: 0.00112 | valid_mae: 0.10109 | valid_rmse: 0.13115 | valid_mse: 0.0172  |  0:04:31s\n",
      "epoch 173| loss: 0.00856 | train_rmsle: 0.00033 | train_mae: 0.06084 | train_rmse: 0.07669 | train_mse: 0.00588 | valid_rmsle: 0.00086 | valid_mae: 0.09543 | valid_rmse: 0.12187 | valid_mse: 0.01485 |  0:04:33s\n",
      "epoch 174| loss: 0.01114 | train_rmsle: 0.00076 | train_mae: 0.10044 | train_rmse: 0.11484 | train_mse: 0.01319 | valid_rmsle: 0.00131 | valid_mae: 0.123   | valid_rmse: 0.14982 | valid_mse: 0.02245 |  0:04:34s\n",
      "epoch 175| loss: 0.00896 | train_rmsle: 0.00032 | train_mae: 0.06232 | train_rmse: 0.07571 | train_mse: 0.00573 | valid_rmsle: 0.00086 | valid_mae: 0.09639 | valid_rmse: 0.12141 | valid_mse: 0.01474 |  0:04:35s\n",
      "epoch 176| loss: 0.00954 | train_rmsle: 0.00051 | train_mae: 0.07118 | train_rmse: 0.08846 | train_mse: 0.00783 | valid_rmsle: 0.00107 | valid_mae: 0.10037 | valid_rmse: 0.12919 | valid_mse: 0.01669 |  0:04:37s\n",
      "epoch 177| loss: 0.00897 | train_rmsle: 0.0002  | train_mae: 0.04552 | train_rmse: 0.05925 | train_mse: 0.00351 | valid_rmsle: 0.00075 | valid_mae: 0.08465 | valid_rmse: 0.11127 | valid_mse: 0.01238 |  0:04:38s\n",
      "epoch 178| loss: 0.01263 | train_rmsle: 0.00019 | train_mae: 0.04435 | train_rmse: 0.05895 | train_mse: 0.00348 | valid_rmsle: 0.00072 | valid_mae: 0.08346 | valid_rmse: 0.11106 | valid_mse: 0.01234 |  0:04:40s\n",
      "epoch 179| loss: 0.01051 | train_rmsle: 0.0002  | train_mae: 0.04355 | train_rmse: 0.05699 | train_mse: 0.00325 | valid_rmsle: 0.0007  | valid_mae: 0.08122 | valid_rmse: 0.10791 | valid_mse: 0.01164 |  0:04:41s\n",
      "epoch 180| loss: 0.00967 | train_rmsle: 0.0002  | train_mae: 0.04521 | train_rmse: 0.05765 | train_mse: 0.00332 | valid_rmsle: 0.00079 | valid_mae: 0.08581 | valid_rmse: 0.11328 | valid_mse: 0.01283 |  0:04:43s\n",
      "epoch 181| loss: 0.00775 | train_rmsle: 0.00027 | train_mae: 0.05593 | train_rmse: 0.07288 | train_mse: 0.00531 | valid_rmsle: 0.00079 | valid_mae: 0.09161 | valid_rmse: 0.11773 | valid_mse: 0.01386 |  0:04:45s\n",
      "epoch 182| loss: 0.00845 | train_rmsle: 0.00028 | train_mae: 0.05814 | train_rmse: 0.07006 | train_mse: 0.00491 | valid_rmsle: 0.00082 | valid_mae: 0.09415 | valid_rmse: 0.11853 | valid_mse: 0.01405 |  0:04:46s\n",
      "epoch 183| loss: 0.00866 | train_rmsle: 0.00026 | train_mae: 0.0552  | train_rmse: 0.06889 | train_mse: 0.00475 | valid_rmsle: 0.00078 | valid_mae: 0.09278 | valid_rmse: 0.11733 | valid_mse: 0.01377 |  0:04:48s\n",
      "epoch 184| loss: 0.00795 | train_rmsle: 0.00021 | train_mae: 0.04896 | train_rmse: 0.06416 | train_mse: 0.00412 | valid_rmsle: 0.00077 | valid_mae: 0.08945 | valid_rmse: 0.11572 | valid_mse: 0.01339 |  0:04:50s\n",
      "epoch 185| loss: 0.00806 | train_rmsle: 0.00027 | train_mae: 0.05075 | train_rmse: 0.06339 | train_mse: 0.00402 | valid_rmsle: 0.00076 | valid_mae: 0.08471 | valid_rmse: 0.11199 | valid_mse: 0.01254 |  0:04:51s\n",
      "epoch 186| loss: 0.01112 | train_rmsle: 0.00029 | train_mae: 0.06077 | train_rmse: 0.07607 | train_mse: 0.00579 | valid_rmsle: 0.00082 | valid_mae: 0.09254 | valid_rmse: 0.12121 | valid_mse: 0.01469 |  0:04:53s\n",
      "epoch 187| loss: 0.01109 | train_rmsle: 0.00056 | train_mae: 0.08342 | train_rmse: 0.09465 | train_mse: 0.00896 | valid_rmsle: 0.00106 | valid_mae: 0.10436 | valid_rmse: 0.13264 | valid_mse: 0.01759 |  0:04:54s\n",
      "epoch 188| loss: 0.01091 | train_rmsle: 0.00043 | train_mae: 0.06595 | train_rmse: 0.08235 | train_mse: 0.00678 | valid_rmsle: 0.00095 | valid_mae: 0.09401 | valid_rmse: 0.12456 | valid_mse: 0.01552 |  0:04:56s\n",
      "epoch 189| loss: 0.01206 | train_rmsle: 0.00062 | train_mae: 0.08379 | train_rmse: 0.10279 | train_mse: 0.01056 | valid_rmsle: 0.00112 | valid_mae: 0.10795 | valid_rmse: 0.13921 | valid_mse: 0.01938 |  0:04:58s\n",
      "epoch 190| loss: 0.00884 | train_rmsle: 0.00018 | train_mae: 0.04301 | train_rmse: 0.05609 | train_mse: 0.00315 | valid_rmsle: 0.00071 | valid_mae: 0.08539 | valid_rmse: 0.11091 | valid_mse: 0.0123  |  0:04:59s\n",
      "epoch 191| loss: 0.0083  | train_rmsle: 0.00017 | train_mae: 0.04237 | train_rmse: 0.05581 | train_mse: 0.00311 | valid_rmsle: 0.0007  | valid_mae: 0.08395 | valid_rmse: 0.1088  | valid_mse: 0.01184 |  0:05:01s\n",
      "epoch 192| loss: 0.00939 | train_rmsle: 0.00127 | train_mae: 0.1043  | train_rmse: 0.12639 | train_mse: 0.01597 | valid_rmsle: 0.00185 | valid_mae: 0.12962 | valid_rmse: 0.16008 | valid_mse: 0.02563 |  0:05:03s\n",
      "epoch 193| loss: 0.01062 | train_rmsle: 0.00034 | train_mae: 0.05986 | train_rmse: 0.07918 | train_mse: 0.00627 | valid_rmsle: 0.00088 | valid_mae: 0.09677 | valid_rmse: 0.12313 | valid_mse: 0.01516 |  0:05:04s\n",
      "epoch 194| loss: 0.00881 | train_rmsle: 0.00079 | train_mae: 0.10444 | train_rmse: 0.11731 | train_mse: 0.01376 | valid_rmsle: 0.00133 | valid_mae: 0.12442 | valid_rmse: 0.15003 | valid_mse: 0.02251 |  0:05:06s\n",
      "epoch 195| loss: 0.01031 | train_rmsle: 0.00039 | train_mae: 0.06974 | train_rmse: 0.08295 | train_mse: 0.00688 | valid_rmsle: 0.00092 | valid_mae: 0.10139 | valid_rmse: 0.12579 | valid_mse: 0.01582 |  0:05:08s\n",
      "epoch 196| loss: 0.00797 | train_rmsle: 0.00019 | train_mae: 0.04475 | train_rmse: 0.05852 | train_mse: 0.00342 | valid_rmsle: 0.00074 | valid_mae: 0.08648 | valid_rmse: 0.11186 | valid_mse: 0.01251 |  0:05:09s\n",
      "epoch 197| loss: 0.00824 | train_rmsle: 0.00019 | train_mae: 0.04421 | train_rmse: 0.05623 | train_mse: 0.00316 | valid_rmsle: 0.00071 | valid_mae: 0.08448 | valid_rmse: 0.10945 | valid_mse: 0.01198 |  0:05:11s\n",
      "epoch 198| loss: 0.00747 | train_rmsle: 0.00027 | train_mae: 0.05088 | train_rmse: 0.06447 | train_mse: 0.00416 | valid_rmsle: 0.00082 | valid_mae: 0.08752 | valid_rmse: 0.11503 | valid_mse: 0.01323 |  0:05:13s\n",
      "epoch 199| loss: 0.00969 | train_rmsle: 0.00017 | train_mae: 0.03579 | train_rmse: 0.05026 | train_mse: 0.00253 | valid_rmsle: 0.00066 | valid_mae: 0.08018 | valid_rmse: 0.10584 | valid_mse: 0.0112  |  0:05:14s\n",
      "epoch 200| loss: 0.00844 | train_rmsle: 0.00026 | train_mae: 0.04506 | train_rmse: 0.05935 | train_mse: 0.00352 | valid_rmsle: 0.00075 | valid_mae: 0.0837  | valid_rmse: 0.11057 | valid_mse: 0.01223 |  0:05:16s\n",
      "epoch 201| loss: 0.0084  | train_rmsle: 0.00045 | train_mae: 0.07159 | train_rmse: 0.08286 | train_mse: 0.00687 | valid_rmsle: 0.00102 | valid_mae: 0.10224 | valid_rmse: 0.12789 | valid_mse: 0.01636 |  0:05:17s\n",
      "epoch 202| loss: 0.00901 | train_rmsle: 0.00041 | train_mae: 0.05555 | train_rmse: 0.07153 | train_mse: 0.00512 | valid_rmsle: 0.001   | valid_mae: 0.09315 | valid_rmse: 0.1219  | valid_mse: 0.01486 |  0:05:19s\n",
      "epoch 203| loss: 0.0119  | train_rmsle: 0.00034 | train_mae: 0.06624 | train_rmse: 0.07705 | train_mse: 0.00594 | valid_rmsle: 0.00092 | valid_mae: 0.10078 | valid_rmse: 0.12568 | valid_mse: 0.0158  |  0:05:21s\n",
      "epoch 204| loss: 0.00962 | train_rmsle: 0.00012 | train_mae: 0.036   | train_rmse: 0.04737 | train_mse: 0.00224 | valid_rmsle: 0.00068 | valid_mae: 0.08124 | valid_rmse: 0.10793 | valid_mse: 0.01165 |  0:05:22s\n",
      "epoch 205| loss: 0.01008 | train_rmsle: 0.00022 | train_mae: 0.04457 | train_rmse: 0.05762 | train_mse: 0.00332 | valid_rmsle: 0.00075 | valid_mae: 0.08206 | valid_rmse: 0.11026 | valid_mse: 0.01216 |  0:05:24s\n",
      "epoch 206| loss: 0.00835 | train_rmsle: 0.00013 | train_mae: 0.03637 | train_rmse: 0.04804 | train_mse: 0.00231 | valid_rmsle: 0.00069 | valid_mae: 0.083   | valid_rmse: 0.1083  | valid_mse: 0.01173 |  0:05:26s\n",
      "epoch 207| loss: 0.0078  | train_rmsle: 0.00029 | train_mae: 0.05926 | train_rmse: 0.07111 | train_mse: 0.00506 | valid_rmsle: 0.00084 | valid_mae: 0.09556 | valid_rmse: 0.12039 | valid_mse: 0.01449 |  0:05:27s\n",
      "epoch 208| loss: 0.00809 | train_rmsle: 0.00031 | train_mae: 0.05366 | train_rmse: 0.06931 | train_mse: 0.0048  | valid_rmsle: 0.0009  | valid_mae: 0.09285 | valid_rmse: 0.11991 | valid_mse: 0.01438 |  0:05:29s\n",
      "epoch 209| loss: 0.00754 | train_rmsle: 0.00025 | train_mae: 0.05168 | train_rmse: 0.06646 | train_mse: 0.00442 | valid_rmsle: 0.00079 | valid_mae: 0.08825 | valid_rmse: 0.11659 | valid_mse: 0.01359 |  0:05:31s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 199 and best_valid_mse = 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.012942815630610546 RMSE: 0.11376649608127407 R2: 0.9427071423105589 MAE: 0.08609831465050595\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_210.pt.zip\n",
      "New best model: 512_8_3_0.02_210 with r2: 0.9427071423105589\n",
      "[5/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.41126 | train_rmsle: 0.22451 | train_mae: 1.58922 | train_rmse: 1.66063 | train_mse: 2.75769 | valid_rmsle: 0.22542 | valid_mae: 1.59455 | valid_rmse: 1.66499 | valid_mse: 2.77219 |  0:00:01s\n",
      "epoch 1  | loss: 1.36441 | train_rmsle: 0.11745 | train_mae: 1.20246 | train_rmse: 1.28758 | train_mse: 1.65787 | valid_rmsle: 0.11776 | valid_mae: 1.20507 | valid_rmse: 1.29057 | valid_mse: 1.66558 |  0:00:03s\n",
      "epoch 2  | loss: 0.44066 | train_rmsle: 0.04683 | train_mae: 0.77922 | train_rmse: 0.87272 | train_mse: 0.76165 | valid_rmsle: 0.04683 | valid_mae: 0.77955 | valid_rmse: 0.87504 | valid_mse: 0.76569 |  0:00:04s\n",
      "epoch 3  | loss: 0.28356 | train_rmsle: 0.0478  | train_mae: 0.78705 | train_rmse: 0.88059 | train_mse: 0.77544 | valid_rmsle: 0.04781 | valid_mae: 0.7873  | valid_rmse: 0.88299 | valid_mse: 0.77967 |  0:00:05s\n",
      "epoch 4  | loss: 0.25629 | train_rmsle: 0.03395 | train_mae: 0.66253 | train_rmse: 0.75523 | train_mse: 0.57037 | valid_rmsle: 0.03384 | valid_mae: 0.6616  | valid_rmse: 0.75694 | valid_mse: 0.57296 |  0:00:07s\n",
      "epoch 5  | loss: 0.24272 | train_rmsle: 0.02662 | train_mae: 0.58335 | train_rmse: 0.67398 | train_mse: 0.45425 | valid_rmsle: 0.02638 | valid_mae: 0.58323 | valid_rmse: 0.67454 | valid_mse: 0.455   |  0:00:08s\n",
      "epoch 6  | loss: 0.23751 | train_rmsle: 0.01834 | train_mae: 0.47103 | train_rmse: 0.55857 | train_mse: 0.312   | valid_rmsle: 0.01796 | valid_mae: 0.47255 | valid_rmse: 0.55762 | valid_mse: 0.31094 |  0:00:09s\n",
      "epoch 7  | loss: 0.23428 | train_rmsle: 0.01919 | train_mae: 0.48458 | train_rmse: 0.57229 | train_mse: 0.32751 | valid_rmsle: 0.01882 | valid_mae: 0.48578 | valid_rmse: 0.57142 | valid_mse: 0.32652 |  0:00:10s\n",
      "epoch 8  | loss: 0.22362 | train_rmsle: 0.01696 | train_mae: 0.44789 | train_rmse: 0.53511 | train_mse: 0.28634 | valid_rmsle: 0.01657 | valid_mae: 0.44959 | valid_rmse: 0.53394 | valid_mse: 0.2851  |  0:00:11s\n",
      "epoch 9  | loss: 0.21654 | train_rmsle: 0.01421 | train_mae: 0.39191 | train_rmse: 0.48247 | train_mse: 0.23278 | valid_rmsle: 0.0137  | valid_mae: 0.39216 | valid_rmse: 0.47924 | valid_mse: 0.22967 |  0:00:13s\n",
      "epoch 10 | loss: 0.20475 | train_rmsle: 0.01323 | train_mae: 0.37904 | train_rmse: 0.46659 | train_mse: 0.2177  | valid_rmsle: 0.01266 | valid_mae: 0.37605 | valid_rmse: 0.46155 | valid_mse: 0.21303 |  0:00:14s\n",
      "epoch 11 | loss: 0.19394 | train_rmsle: 0.01114 | train_mae: 0.34095 | train_rmse: 0.42525 | train_mse: 0.18083 | valid_rmsle: 0.01056 | valid_mae: 0.33769 | valid_rmse: 0.41881 | valid_mse: 0.17541 |  0:00:15s\n",
      "epoch 12 | loss: 0.18006 | train_rmsle: 0.00905 | train_mae: 0.2994  | train_rmse: 0.38071 | train_mse: 0.14494 | valid_rmsle: 0.00822 | valid_mae: 0.28964 | valid_rmse: 0.36716 | valid_mse: 0.1348  |  0:00:17s\n",
      "epoch 13 | loss: 0.16872 | train_rmsle: 0.00802 | train_mae: 0.27838 | train_rmse: 0.35647 | train_mse: 0.12707 | valid_rmsle: 0.00721 | valid_mae: 0.26675 | valid_rmse: 0.3416  | valid_mse: 0.11669 |  0:00:19s\n",
      "epoch 14 | loss: 0.15586 | train_rmsle: 0.00804 | train_mae: 0.27492 | train_rmse: 0.35383 | train_mse: 0.12519 | valid_rmsle: 0.00733 | valid_mae: 0.26475 | valid_rmse: 0.34067 | valid_mse: 0.11606 |  0:00:20s\n",
      "epoch 15 | loss: 0.14583 | train_rmsle: 0.00709 | train_mae: 0.25788 | train_rmse: 0.33269 | train_mse: 0.11068 | valid_rmsle: 0.00636 | valid_mae: 0.24563 | valid_rmse: 0.31788 | valid_mse: 0.10104 |  0:00:22s\n",
      "epoch 16 | loss: 0.13755 | train_rmsle: 0.00733 | train_mae: 0.26757 | train_rmse: 0.34015 | train_mse: 0.1157  | valid_rmsle: 0.00664 | valid_mae: 0.25625 | valid_rmse: 0.3268  | valid_mse: 0.1068  |  0:00:24s\n",
      "epoch 17 | loss: 0.12759 | train_rmsle: 0.0075  | train_mae: 0.27144 | train_rmse: 0.34413 | train_mse: 0.11843 | valid_rmsle: 0.00683 | valid_mae: 0.26124 | valid_rmse: 0.33123 | valid_mse: 0.10971 |  0:00:25s\n",
      "epoch 18 | loss: 0.12263 | train_rmsle: 0.00705 | train_mae: 0.25837 | train_rmse: 0.33158 | train_mse: 0.10995 | valid_rmsle: 0.00632 | valid_mae: 0.24593 | valid_rmse: 0.31677 | valid_mse: 0.10034 |  0:00:27s\n",
      "epoch 19 | loss: 0.12099 | train_rmsle: 0.00668 | train_mae: 0.24689 | train_rmse: 0.32082 | train_mse: 0.10293 | valid_rmsle: 0.00598 | valid_mae: 0.23352 | valid_rmse: 0.30597 | valid_mse: 0.09362 |  0:00:29s\n",
      "epoch 20 | loss: 0.11696 | train_rmsle: 0.00705 | train_mae: 0.259   | train_rmse: 0.33207 | train_mse: 0.11027 | valid_rmsle: 0.00641 | valid_mae: 0.24811 | valid_rmse: 0.31886 | valid_mse: 0.10167 |  0:00:30s\n",
      "epoch 21 | loss: 0.11287 | train_rmsle: 0.00666 | train_mae: 0.24952 | train_rmse: 0.32174 | train_mse: 0.10352 | valid_rmsle: 0.00603 | valid_mae: 0.23773 | valid_rmse: 0.30841 | valid_mse: 0.09511 |  0:00:32s\n",
      "epoch 22 | loss: 0.11005 | train_rmsle: 0.00656 | train_mae: 0.2463  | train_rmse: 0.31838 | train_mse: 0.10137 | valid_rmsle: 0.00592 | valid_mae: 0.23609 | valid_rmse: 0.30534 | valid_mse: 0.09323 |  0:00:34s\n",
      "epoch 23 | loss: 0.1094  | train_rmsle: 0.00648 | train_mae: 0.24456 | train_rmse: 0.31663 | train_mse: 0.10025 | valid_rmsle: 0.006   | valid_mae: 0.23699 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:00:35s\n",
      "epoch 24 | loss: 0.10859 | train_rmsle: 0.00648 | train_mae: 0.24412 | train_rmse: 0.3167  | train_mse: 0.1003  | valid_rmsle: 0.00595 | valid_mae: 0.23648 | valid_rmse: 0.30634 | valid_mse: 0.09384 |  0:00:37s\n",
      "epoch 25 | loss: 0.10458 | train_rmsle: 0.00648 | train_mae: 0.24638 | train_rmse: 0.31769 | train_mse: 0.10093 | valid_rmsle: 0.00598 | valid_mae: 0.23923 | valid_rmse: 0.30774 | valid_mse: 0.0947  |  0:00:39s\n",
      "epoch 26 | loss: 0.10121 | train_rmsle: 0.00635 | train_mae: 0.24174 | train_rmse: 0.31351 | train_mse: 0.09829 | valid_rmsle: 0.00586 | valid_mae: 0.23453 | valid_rmse: 0.30398 | valid_mse: 0.0924  |  0:00:40s\n",
      "epoch 27 | loss: 0.10049 | train_rmsle: 0.00625 | train_mae: 0.23896 | train_rmse: 0.31074 | train_mse: 0.09656 | valid_rmsle: 0.00579 | valid_mae: 0.23261 | valid_rmse: 0.30238 | valid_mse: 0.09144 |  0:00:42s\n",
      "epoch 28 | loss: 0.09903 | train_rmsle: 0.00625 | train_mae: 0.24157 | train_rmse: 0.31196 | train_mse: 0.09732 | valid_rmsle: 0.00589 | valid_mae: 0.23889 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:00:44s\n",
      "epoch 29 | loss: 0.09648 | train_rmsle: 0.00628 | train_mae: 0.24443 | train_rmse: 0.31373 | train_mse: 0.09843 | valid_rmsle: 0.00595 | valid_mae: 0.24189 | valid_rmse: 0.30868 | valid_mse: 0.09528 |  0:00:45s\n",
      "epoch 30 | loss: 0.09613 | train_rmsle: 0.00599 | train_mae: 0.23312 | train_rmse: 0.30413 | train_mse: 0.0925  | valid_rmsle: 0.00573 | valid_mae: 0.23418 | valid_rmse: 0.30186 | valid_mse: 0.09112 |  0:00:47s\n",
      "epoch 31 | loss: 0.09398 | train_rmsle: 0.006   | train_mae: 0.23578 | train_rmse: 0.30566 | train_mse: 0.09343 | valid_rmsle: 0.00575 | valid_mae: 0.23682 | valid_rmse: 0.3038  | valid_mse: 0.09229 |  0:00:49s\n",
      "epoch 32 | loss: 0.09328 | train_rmsle: 0.00587 | train_mae: 0.23018 | train_rmse: 0.30086 | train_mse: 0.09052 | valid_rmsle: 0.00559 | valid_mae: 0.23255 | valid_rmse: 0.29911 | valid_mse: 0.08947 |  0:00:50s\n",
      "epoch 33 | loss: 0.09289 | train_rmsle: 0.0058  | train_mae: 0.22792 | train_rmse: 0.29882 | train_mse: 0.0893  | valid_rmsle: 0.0056  | valid_mae: 0.22933 | valid_rmse: 0.29909 | valid_mse: 0.08945 |  0:00:52s\n",
      "epoch 34 | loss: 0.09356 | train_rmsle: 0.00575 | train_mae: 0.22408 | train_rmse: 0.29618 | train_mse: 0.08772 | valid_rmsle: 0.0055  | valid_mae: 0.22554 | valid_rmse: 0.29515 | valid_mse: 0.08711 |  0:00:54s\n",
      "epoch 35 | loss: 0.09019 | train_rmsle: 0.00566 | train_mae: 0.22418 | train_rmse: 0.29447 | train_mse: 0.08671 | valid_rmsle: 0.00547 | valid_mae: 0.22724 | valid_rmse: 0.29563 | valid_mse: 0.0874  |  0:00:55s\n",
      "epoch 36 | loss: 0.08969 | train_rmsle: 0.00582 | train_mae: 0.23374 | train_rmse: 0.30157 | train_mse: 0.09094 | valid_rmsle: 0.00565 | valid_mae: 0.23661 | valid_rmse: 0.30269 | valid_mse: 0.09162 |  0:00:57s\n",
      "epoch 37 | loss: 0.08878 | train_rmsle: 0.00589 | train_mae: 0.22515 | train_rmse: 0.29959 | train_mse: 0.08975 | valid_rmsle: 0.00569 | valid_mae: 0.22891 | valid_rmse: 0.30076 | valid_mse: 0.09046 |  0:00:59s\n",
      "epoch 38 | loss: 0.09122 | train_rmsle: 0.00564 | train_mae: 0.22997 | train_rmse: 0.29677 | train_mse: 0.08807 | valid_rmsle: 0.00553 | valid_mae: 0.23425 | valid_rmse: 0.29909 | valid_mse: 0.08946 |  0:01:00s\n",
      "epoch 39 | loss: 0.08675 | train_rmsle: 0.0054  | train_mae: 0.21735 | train_rmse: 0.28662 | train_mse: 0.08215 | valid_rmsle: 0.00531 | valid_mae: 0.22307 | valid_rmse: 0.29024 | valid_mse: 0.08424 |  0:01:02s\n",
      "epoch 40 | loss: 0.08523 | train_rmsle: 0.0054  | train_mae: 0.22024 | train_rmse: 0.28804 | train_mse: 0.08297 | valid_rmsle: 0.00532 | valid_mae: 0.2254  | valid_rmse: 0.29166 | valid_mse: 0.08507 |  0:01:04s\n",
      "epoch 41 | loss: 0.08505 | train_rmsle: 0.00531 | train_mae: 0.21728 | train_rmse: 0.28493 | train_mse: 0.08119 | valid_rmsle: 0.00523 | valid_mae: 0.22239 | valid_rmse: 0.28844 | valid_mse: 0.0832  |  0:01:06s\n",
      "epoch 42 | loss: 0.08382 | train_rmsle: 0.00537 | train_mae: 0.22248 | train_rmse: 0.28891 | train_mse: 0.08347 | valid_rmsle: 0.00525 | valid_mae: 0.22663 | valid_rmse: 0.29081 | valid_mse: 0.08457 |  0:01:07s\n",
      "epoch 43 | loss: 0.08247 | train_rmsle: 0.00515 | train_mae: 0.21188 | train_rmse: 0.27988 | train_mse: 0.07834 | valid_rmsle: 0.00515 | valid_mae: 0.21871 | valid_rmse: 0.28598 | valid_mse: 0.08178 |  0:01:09s\n",
      "epoch 44 | loss: 0.08373 | train_rmsle: 0.00531 | train_mae: 0.21304 | train_rmse: 0.28292 | train_mse: 0.08004 | valid_rmsle: 0.00534 | valid_mae: 0.22161 | valid_rmse: 0.29017 | valid_mse: 0.0842  |  0:01:11s\n",
      "epoch 45 | loss: 0.08177 | train_rmsle: 0.00537 | train_mae: 0.22605 | train_rmse: 0.2901  | train_mse: 0.08416 | valid_rmsle: 0.00541 | valid_mae: 0.23394 | valid_rmse: 0.29654 | valid_mse: 0.08793 |  0:01:12s\n",
      "epoch 46 | loss: 0.07971 | train_rmsle: 0.00518 | train_mae: 0.21021 | train_rmse: 0.27954 | train_mse: 0.07814 | valid_rmsle: 0.00528 | valid_mae: 0.21996 | valid_rmse: 0.28876 | valid_mse: 0.08338 |  0:01:14s\n",
      "epoch 47 | loss: 0.07961 | train_rmsle: 0.00507 | train_mae: 0.21587 | train_rmse: 0.28001 | train_mse: 0.07841 | valid_rmsle: 0.00523 | valid_mae: 0.22682 | valid_rmse: 0.29035 | valid_mse: 0.0843  |  0:01:16s\n",
      "epoch 48 | loss: 0.07978 | train_rmsle: 0.00491 | train_mae: 0.20649 | train_rmse: 0.27294 | train_mse: 0.07449 | valid_rmsle: 0.0051  | valid_mae: 0.21795 | valid_rmse: 0.28469 | valid_mse: 0.08105 |  0:01:17s\n",
      "epoch 49 | loss: 0.07923 | train_rmsle: 0.00487 | train_mae: 0.20587 | train_rmse: 0.27193 | train_mse: 0.07395 | valid_rmsle: 0.00506 | valid_mae: 0.21829 | valid_rmse: 0.2838  | valid_mse: 0.08054 |  0:01:19s\n",
      "epoch 50 | loss: 0.07797 | train_rmsle: 0.00485 | train_mae: 0.20643 | train_rmse: 0.27184 | train_mse: 0.0739  | valid_rmsle: 0.00506 | valid_mae: 0.2181  | valid_rmse: 0.28406 | valid_mse: 0.08069 |  0:01:21s\n",
      "epoch 51 | loss: 0.0765  | train_rmsle: 0.00498 | train_mae: 0.21474 | train_rmse: 0.27737 | train_mse: 0.07694 | valid_rmsle: 0.00521 | valid_mae: 0.22526 | valid_rmse: 0.28924 | valid_mse: 0.08366 |  0:01:22s\n",
      "epoch 52 | loss: 0.07529 | train_rmsle: 0.00482 | train_mae: 0.20729 | train_rmse: 0.27108 | train_mse: 0.07348 | valid_rmsle: 0.0051  | valid_mae: 0.22012 | valid_rmse: 0.28478 | valid_mse: 0.0811  |  0:01:24s\n",
      "epoch 53 | loss: 0.07689 | train_rmsle: 0.0049  | train_mae: 0.21337 | train_rmse: 0.27539 | train_mse: 0.07584 | valid_rmsle: 0.00514 | valid_mae: 0.22581 | valid_rmse: 0.28772 | valid_mse: 0.08278 |  0:01:26s\n",
      "epoch 54 | loss: 0.07901 | train_rmsle: 0.00469 | train_mae: 0.20299 | train_rmse: 0.26658 | train_mse: 0.07107 | valid_rmsle: 0.00499 | valid_mae: 0.21609 | valid_rmse: 0.28173 | valid_mse: 0.07937 |  0:01:27s\n",
      "epoch 55 | loss: 0.07481 | train_rmsle: 0.00466 | train_mae: 0.20316 | train_rmse: 0.26597 | train_mse: 0.07074 | valid_rmsle: 0.00496 | valid_mae: 0.21676 | valid_rmse: 0.28096 | valid_mse: 0.07894 |  0:01:29s\n",
      "epoch 56 | loss: 0.07273 | train_rmsle: 0.00474 | train_mae: 0.20872 | train_rmse: 0.2701  | train_mse: 0.07295 | valid_rmsle: 0.00507 | valid_mae: 0.22378 | valid_rmse: 0.28553 | valid_mse: 0.08153 |  0:01:30s\n",
      "epoch 57 | loss: 0.07349 | train_rmsle: 0.00456 | train_mae: 0.19941 | train_rmse: 0.26263 | train_mse: 0.06897 | valid_rmsle: 0.00488 | valid_mae: 0.21378 | valid_rmse: 0.2785  | valid_mse: 0.07756 |  0:01:32s\n",
      "epoch 58 | loss: 0.07119 | train_rmsle: 0.00451 | train_mae: 0.19991 | train_rmse: 0.26194 | train_mse: 0.06861 | valid_rmsle: 0.00491 | valid_mae: 0.21694 | valid_rmse: 0.2798  | valid_mse: 0.07829 |  0:01:34s\n",
      "epoch 59 | loss: 0.07296 | train_rmsle: 0.00465 | train_mae: 0.20838 | train_rmse: 0.26831 | train_mse: 0.07199 | valid_rmsle: 0.00506 | valid_mae: 0.22486 | valid_rmse: 0.28534 | valid_mse: 0.08142 |  0:01:35s\n",
      "epoch 60 | loss: 0.07131 | train_rmsle: 0.00441 | train_mae: 0.19686 | train_rmse: 0.25864 | train_mse: 0.06689 | valid_rmsle: 0.00473 | valid_mae: 0.21281 | valid_rmse: 0.2745  | valid_mse: 0.07535 |  0:01:37s\n",
      "epoch 61 | loss: 0.07101 | train_rmsle: 0.00454 | train_mae: 0.20612 | train_rmse: 0.26559 | train_mse: 0.07054 | valid_rmsle: 0.00491 | valid_mae: 0.22181 | valid_rmse: 0.28143 | valid_mse: 0.0792  |  0:01:39s\n",
      "epoch 62 | loss: 0.0695  | train_rmsle: 0.0043  | train_mae: 0.192   | train_rmse: 0.25455 | train_mse: 0.06479 | valid_rmsle: 0.00467 | valid_mae: 0.20902 | valid_rmse: 0.27219 | valid_mse: 0.07409 |  0:01:40s\n",
      "epoch 63 | loss: 0.06827 | train_rmsle: 0.0043  | train_mae: 0.19532 | train_rmse: 0.25597 | train_mse: 0.06552 | valid_rmsle: 0.00467 | valid_mae: 0.21349 | valid_rmse: 0.27388 | valid_mse: 0.07501 |  0:01:42s\n",
      "epoch 64 | loss: 0.06707 | train_rmsle: 0.00429 | train_mae: 0.1979  | train_rmse: 0.25665 | train_mse: 0.06587 | valid_rmsle: 0.00475 | valid_mae: 0.21683 | valid_rmse: 0.27692 | valid_mse: 0.07669 |  0:01:44s\n",
      "epoch 65 | loss: 0.06695 | train_rmsle: 0.00413 | train_mae: 0.19046 | train_rmse: 0.25045 | train_mse: 0.06273 | valid_rmsle: 0.00462 | valid_mae: 0.21185 | valid_rmse: 0.27191 | valid_mse: 0.07394 |  0:01:46s\n",
      "epoch 66 | loss: 0.06594 | train_rmsle: 0.00412 | train_mae: 0.19132 | train_rmse: 0.25054 | train_mse: 0.06277 | valid_rmsle: 0.00464 | valid_mae: 0.21331 | valid_rmse: 0.27321 | valid_mse: 0.07464 |  0:01:47s\n",
      "epoch 67 | loss: 0.06542 | train_rmsle: 0.00426 | train_mae: 0.18846 | train_rmse: 0.25334 | train_mse: 0.06418 | valid_rmsle: 0.0047  | valid_mae: 0.21081 | valid_rmse: 0.27497 | valid_mse: 0.07561 |  0:01:49s\n",
      "epoch 68 | loss: 0.06683 | train_rmsle: 0.00421 | train_mae: 0.19667 | train_rmse: 0.25492 | train_mse: 0.06498 | valid_rmsle: 0.00471 | valid_mae: 0.21915 | valid_rmse: 0.27689 | valid_mse: 0.07667 |  0:01:50s\n",
      "epoch 69 | loss: 0.06234 | train_rmsle: 0.0039  | train_mae: 0.18388 | train_rmse: 0.24309 | train_mse: 0.05909 | valid_rmsle: 0.0046  | valid_mae: 0.2118  | valid_rmse: 0.27225 | valid_mse: 0.07412 |  0:01:52s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 65 and best_valid_mse = 0.07394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07854032854505065 RMSE: 0.28025047465624503 R2: 0.6523322285785147 MAE: 0.22052411475059883\n",
      "=====================================\n",
      "[6/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.41126 | train_rmsle: 0.22451 | train_mae: 1.58922 | train_rmse: 1.66063 | train_mse: 2.75769 | valid_rmsle: 0.22542 | valid_mae: 1.59455 | valid_rmse: 1.66499 | valid_mse: 2.77219 |  0:00:01s\n",
      "epoch 1  | loss: 1.36441 | train_rmsle: 0.11745 | train_mae: 1.20246 | train_rmse: 1.28758 | train_mse: 1.65787 | valid_rmsle: 0.11776 | valid_mae: 1.20507 | valid_rmse: 1.29057 | valid_mse: 1.66558 |  0:00:03s\n",
      "epoch 2  | loss: 0.44066 | train_rmsle: 0.04683 | train_mae: 0.77922 | train_rmse: 0.87272 | train_mse: 0.76165 | valid_rmsle: 0.04683 | valid_mae: 0.77955 | valid_rmse: 0.87504 | valid_mse: 0.76569 |  0:00:04s\n",
      "epoch 3  | loss: 0.28356 | train_rmsle: 0.0478  | train_mae: 0.78705 | train_rmse: 0.88059 | train_mse: 0.77544 | valid_rmsle: 0.04781 | valid_mae: 0.7873  | valid_rmse: 0.88299 | valid_mse: 0.77967 |  0:00:06s\n",
      "epoch 4  | loss: 0.25629 | train_rmsle: 0.03395 | train_mae: 0.66253 | train_rmse: 0.75523 | train_mse: 0.57037 | valid_rmsle: 0.03384 | valid_mae: 0.6616  | valid_rmse: 0.75694 | valid_mse: 0.57296 |  0:00:07s\n",
      "epoch 5  | loss: 0.24272 | train_rmsle: 0.02662 | train_mae: 0.58335 | train_rmse: 0.67398 | train_mse: 0.45425 | valid_rmsle: 0.02638 | valid_mae: 0.58323 | valid_rmse: 0.67454 | valid_mse: 0.455   |  0:00:09s\n",
      "epoch 6  | loss: 0.23751 | train_rmsle: 0.01834 | train_mae: 0.47103 | train_rmse: 0.55857 | train_mse: 0.312   | valid_rmsle: 0.01796 | valid_mae: 0.47255 | valid_rmse: 0.55762 | valid_mse: 0.31094 |  0:00:10s\n",
      "epoch 7  | loss: 0.23428 | train_rmsle: 0.01919 | train_mae: 0.48458 | train_rmse: 0.57229 | train_mse: 0.32751 | valid_rmsle: 0.01882 | valid_mae: 0.48578 | valid_rmse: 0.57142 | valid_mse: 0.32652 |  0:00:11s\n",
      "epoch 8  | loss: 0.22362 | train_rmsle: 0.01696 | train_mae: 0.44789 | train_rmse: 0.53511 | train_mse: 0.28634 | valid_rmsle: 0.01657 | valid_mae: 0.44959 | valid_rmse: 0.53394 | valid_mse: 0.2851  |  0:00:13s\n",
      "epoch 9  | loss: 0.21654 | train_rmsle: 0.01421 | train_mae: 0.39191 | train_rmse: 0.48247 | train_mse: 0.23278 | valid_rmsle: 0.0137  | valid_mae: 0.39216 | valid_rmse: 0.47924 | valid_mse: 0.22967 |  0:00:14s\n",
      "epoch 10 | loss: 0.20475 | train_rmsle: 0.01323 | train_mae: 0.37904 | train_rmse: 0.46659 | train_mse: 0.2177  | valid_rmsle: 0.01266 | valid_mae: 0.37605 | valid_rmse: 0.46155 | valid_mse: 0.21303 |  0:00:15s\n",
      "epoch 11 | loss: 0.19394 | train_rmsle: 0.01114 | train_mae: 0.34095 | train_rmse: 0.42525 | train_mse: 0.18083 | valid_rmsle: 0.01056 | valid_mae: 0.33769 | valid_rmse: 0.41881 | valid_mse: 0.17541 |  0:00:17s\n",
      "epoch 12 | loss: 0.18006 | train_rmsle: 0.00905 | train_mae: 0.2994  | train_rmse: 0.38071 | train_mse: 0.14494 | valid_rmsle: 0.00822 | valid_mae: 0.28964 | valid_rmse: 0.36716 | valid_mse: 0.1348  |  0:00:18s\n",
      "epoch 13 | loss: 0.16872 | train_rmsle: 0.00802 | train_mae: 0.27838 | train_rmse: 0.35647 | train_mse: 0.12707 | valid_rmsle: 0.00721 | valid_mae: 0.26675 | valid_rmse: 0.3416  | valid_mse: 0.11669 |  0:00:20s\n",
      "epoch 14 | loss: 0.15586 | train_rmsle: 0.00804 | train_mae: 0.27492 | train_rmse: 0.35383 | train_mse: 0.12519 | valid_rmsle: 0.00733 | valid_mae: 0.26475 | valid_rmse: 0.34067 | valid_mse: 0.11606 |  0:00:22s\n",
      "epoch 15 | loss: 0.14583 | train_rmsle: 0.00709 | train_mae: 0.25788 | train_rmse: 0.33269 | train_mse: 0.11068 | valid_rmsle: 0.00636 | valid_mae: 0.24563 | valid_rmse: 0.31788 | valid_mse: 0.10104 |  0:00:24s\n",
      "epoch 16 | loss: 0.13755 | train_rmsle: 0.00733 | train_mae: 0.26757 | train_rmse: 0.34015 | train_mse: 0.1157  | valid_rmsle: 0.00664 | valid_mae: 0.25625 | valid_rmse: 0.3268  | valid_mse: 0.1068  |  0:00:25s\n",
      "epoch 17 | loss: 0.12759 | train_rmsle: 0.0075  | train_mae: 0.27144 | train_rmse: 0.34413 | train_mse: 0.11843 | valid_rmsle: 0.00683 | valid_mae: 0.26124 | valid_rmse: 0.33123 | valid_mse: 0.10971 |  0:00:27s\n",
      "epoch 18 | loss: 0.12263 | train_rmsle: 0.00705 | train_mae: 0.25837 | train_rmse: 0.33158 | train_mse: 0.10995 | valid_rmsle: 0.00632 | valid_mae: 0.24593 | valid_rmse: 0.31677 | valid_mse: 0.10034 |  0:00:28s\n",
      "epoch 19 | loss: 0.12099 | train_rmsle: 0.00668 | train_mae: 0.24689 | train_rmse: 0.32082 | train_mse: 0.10293 | valid_rmsle: 0.00598 | valid_mae: 0.23352 | valid_rmse: 0.30597 | valid_mse: 0.09362 |  0:00:30s\n",
      "epoch 20 | loss: 0.11696 | train_rmsle: 0.00705 | train_mae: 0.259   | train_rmse: 0.33207 | train_mse: 0.11027 | valid_rmsle: 0.00641 | valid_mae: 0.24811 | valid_rmse: 0.31886 | valid_mse: 0.10167 |  0:00:32s\n",
      "epoch 21 | loss: 0.11287 | train_rmsle: 0.00666 | train_mae: 0.24952 | train_rmse: 0.32174 | train_mse: 0.10352 | valid_rmsle: 0.00603 | valid_mae: 0.23773 | valid_rmse: 0.30841 | valid_mse: 0.09511 |  0:00:33s\n",
      "epoch 22 | loss: 0.11005 | train_rmsle: 0.00656 | train_mae: 0.2463  | train_rmse: 0.31838 | train_mse: 0.10137 | valid_rmsle: 0.00592 | valid_mae: 0.23609 | valid_rmse: 0.30534 | valid_mse: 0.09323 |  0:00:35s\n",
      "epoch 23 | loss: 0.1094  | train_rmsle: 0.00648 | train_mae: 0.24456 | train_rmse: 0.31663 | train_mse: 0.10025 | valid_rmsle: 0.006   | valid_mae: 0.23699 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:00:37s\n",
      "epoch 24 | loss: 0.10859 | train_rmsle: 0.00648 | train_mae: 0.24412 | train_rmse: 0.3167  | train_mse: 0.1003  | valid_rmsle: 0.00595 | valid_mae: 0.23648 | valid_rmse: 0.30634 | valid_mse: 0.09384 |  0:00:38s\n",
      "epoch 25 | loss: 0.10458 | train_rmsle: 0.00648 | train_mae: 0.24638 | train_rmse: 0.31769 | train_mse: 0.10093 | valid_rmsle: 0.00598 | valid_mae: 0.23923 | valid_rmse: 0.30774 | valid_mse: 0.0947  |  0:00:40s\n",
      "epoch 26 | loss: 0.10121 | train_rmsle: 0.00635 | train_mae: 0.24174 | train_rmse: 0.31351 | train_mse: 0.09829 | valid_rmsle: 0.00586 | valid_mae: 0.23453 | valid_rmse: 0.30398 | valid_mse: 0.0924  |  0:00:42s\n",
      "epoch 27 | loss: 0.10049 | train_rmsle: 0.00625 | train_mae: 0.23896 | train_rmse: 0.31074 | train_mse: 0.09656 | valid_rmsle: 0.00579 | valid_mae: 0.23261 | valid_rmse: 0.30238 | valid_mse: 0.09144 |  0:00:43s\n",
      "epoch 28 | loss: 0.09903 | train_rmsle: 0.00625 | train_mae: 0.24157 | train_rmse: 0.31196 | train_mse: 0.09732 | valid_rmsle: 0.00589 | valid_mae: 0.23889 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:00:45s\n",
      "epoch 29 | loss: 0.09648 | train_rmsle: 0.00628 | train_mae: 0.24443 | train_rmse: 0.31373 | train_mse: 0.09843 | valid_rmsle: 0.00595 | valid_mae: 0.24189 | valid_rmse: 0.30868 | valid_mse: 0.09528 |  0:00:47s\n",
      "epoch 30 | loss: 0.09613 | train_rmsle: 0.00599 | train_mae: 0.23312 | train_rmse: 0.30413 | train_mse: 0.0925  | valid_rmsle: 0.00573 | valid_mae: 0.23418 | valid_rmse: 0.30186 | valid_mse: 0.09112 |  0:00:48s\n",
      "epoch 31 | loss: 0.09398 | train_rmsle: 0.006   | train_mae: 0.23578 | train_rmse: 0.30566 | train_mse: 0.09343 | valid_rmsle: 0.00575 | valid_mae: 0.23682 | valid_rmse: 0.3038  | valid_mse: 0.09229 |  0:00:50s\n",
      "epoch 32 | loss: 0.09328 | train_rmsle: 0.00587 | train_mae: 0.23018 | train_rmse: 0.30086 | train_mse: 0.09052 | valid_rmsle: 0.00559 | valid_mae: 0.23255 | valid_rmse: 0.29911 | valid_mse: 0.08947 |  0:00:52s\n",
      "epoch 33 | loss: 0.09289 | train_rmsle: 0.0058  | train_mae: 0.22792 | train_rmse: 0.29882 | train_mse: 0.0893  | valid_rmsle: 0.0056  | valid_mae: 0.22933 | valid_rmse: 0.29909 | valid_mse: 0.08945 |  0:00:53s\n",
      "epoch 34 | loss: 0.09356 | train_rmsle: 0.00575 | train_mae: 0.22408 | train_rmse: 0.29618 | train_mse: 0.08772 | valid_rmsle: 0.0055  | valid_mae: 0.22554 | valid_rmse: 0.29515 | valid_mse: 0.08711 |  0:00:55s\n",
      "epoch 35 | loss: 0.09019 | train_rmsle: 0.00566 | train_mae: 0.22418 | train_rmse: 0.29447 | train_mse: 0.08671 | valid_rmsle: 0.00547 | valid_mae: 0.22724 | valid_rmse: 0.29563 | valid_mse: 0.0874  |  0:00:57s\n",
      "epoch 36 | loss: 0.08969 | train_rmsle: 0.00582 | train_mae: 0.23374 | train_rmse: 0.30157 | train_mse: 0.09094 | valid_rmsle: 0.00565 | valid_mae: 0.23661 | valid_rmse: 0.30269 | valid_mse: 0.09162 |  0:00:58s\n",
      "epoch 37 | loss: 0.08878 | train_rmsle: 0.00589 | train_mae: 0.22515 | train_rmse: 0.29959 | train_mse: 0.08975 | valid_rmsle: 0.00569 | valid_mae: 0.22891 | valid_rmse: 0.30076 | valid_mse: 0.09046 |  0:01:00s\n",
      "epoch 38 | loss: 0.09122 | train_rmsle: 0.00564 | train_mae: 0.22997 | train_rmse: 0.29677 | train_mse: 0.08807 | valid_rmsle: 0.00553 | valid_mae: 0.23425 | valid_rmse: 0.29909 | valid_mse: 0.08946 |  0:01:02s\n",
      "epoch 39 | loss: 0.08675 | train_rmsle: 0.0054  | train_mae: 0.21735 | train_rmse: 0.28662 | train_mse: 0.08215 | valid_rmsle: 0.00531 | valid_mae: 0.22307 | valid_rmse: 0.29024 | valid_mse: 0.08424 |  0:01:03s\n",
      "epoch 40 | loss: 0.08523 | train_rmsle: 0.0054  | train_mae: 0.22024 | train_rmse: 0.28804 | train_mse: 0.08297 | valid_rmsle: 0.00532 | valid_mae: 0.2254  | valid_rmse: 0.29166 | valid_mse: 0.08507 |  0:01:05s\n",
      "epoch 41 | loss: 0.08505 | train_rmsle: 0.00531 | train_mae: 0.21728 | train_rmse: 0.28493 | train_mse: 0.08119 | valid_rmsle: 0.00523 | valid_mae: 0.22239 | valid_rmse: 0.28844 | valid_mse: 0.0832  |  0:01:07s\n",
      "epoch 42 | loss: 0.08382 | train_rmsle: 0.00537 | train_mae: 0.22248 | train_rmse: 0.28891 | train_mse: 0.08347 | valid_rmsle: 0.00525 | valid_mae: 0.22663 | valid_rmse: 0.29081 | valid_mse: 0.08457 |  0:01:08s\n",
      "epoch 43 | loss: 0.08247 | train_rmsle: 0.00515 | train_mae: 0.21188 | train_rmse: 0.27988 | train_mse: 0.07834 | valid_rmsle: 0.00515 | valid_mae: 0.21871 | valid_rmse: 0.28598 | valid_mse: 0.08178 |  0:01:10s\n",
      "epoch 44 | loss: 0.08373 | train_rmsle: 0.00531 | train_mae: 0.21304 | train_rmse: 0.28292 | train_mse: 0.08004 | valid_rmsle: 0.00534 | valid_mae: 0.22161 | valid_rmse: 0.29017 | valid_mse: 0.0842  |  0:01:12s\n",
      "epoch 45 | loss: 0.08177 | train_rmsle: 0.00537 | train_mae: 0.22605 | train_rmse: 0.2901  | train_mse: 0.08416 | valid_rmsle: 0.00541 | valid_mae: 0.23394 | valid_rmse: 0.29654 | valid_mse: 0.08793 |  0:01:13s\n",
      "epoch 46 | loss: 0.07971 | train_rmsle: 0.00518 | train_mae: 0.21021 | train_rmse: 0.27954 | train_mse: 0.07814 | valid_rmsle: 0.00528 | valid_mae: 0.21996 | valid_rmse: 0.28876 | valid_mse: 0.08338 |  0:01:15s\n",
      "epoch 47 | loss: 0.07961 | train_rmsle: 0.00507 | train_mae: 0.21587 | train_rmse: 0.28001 | train_mse: 0.07841 | valid_rmsle: 0.00523 | valid_mae: 0.22682 | valid_rmse: 0.29035 | valid_mse: 0.0843  |  0:01:16s\n",
      "epoch 48 | loss: 0.07978 | train_rmsle: 0.00491 | train_mae: 0.20649 | train_rmse: 0.27294 | train_mse: 0.07449 | valid_rmsle: 0.0051  | valid_mae: 0.21795 | valid_rmse: 0.28469 | valid_mse: 0.08105 |  0:01:18s\n",
      "epoch 49 | loss: 0.07923 | train_rmsle: 0.00487 | train_mae: 0.20587 | train_rmse: 0.27193 | train_mse: 0.07395 | valid_rmsle: 0.00506 | valid_mae: 0.21829 | valid_rmse: 0.2838  | valid_mse: 0.08054 |  0:01:20s\n",
      "epoch 50 | loss: 0.07797 | train_rmsle: 0.00485 | train_mae: 0.20643 | train_rmse: 0.27184 | train_mse: 0.0739  | valid_rmsle: 0.00506 | valid_mae: 0.2181  | valid_rmse: 0.28406 | valid_mse: 0.08069 |  0:01:21s\n",
      "epoch 51 | loss: 0.0765  | train_rmsle: 0.00498 | train_mae: 0.21474 | train_rmse: 0.27737 | train_mse: 0.07694 | valid_rmsle: 0.00521 | valid_mae: 0.22526 | valid_rmse: 0.28924 | valid_mse: 0.08366 |  0:01:23s\n",
      "epoch 52 | loss: 0.07529 | train_rmsle: 0.00482 | train_mae: 0.20729 | train_rmse: 0.27108 | train_mse: 0.07348 | valid_rmsle: 0.0051  | valid_mae: 0.22012 | valid_rmse: 0.28478 | valid_mse: 0.0811  |  0:01:25s\n",
      "epoch 53 | loss: 0.07689 | train_rmsle: 0.0049  | train_mae: 0.21337 | train_rmse: 0.27539 | train_mse: 0.07584 | valid_rmsle: 0.00514 | valid_mae: 0.22581 | valid_rmse: 0.28772 | valid_mse: 0.08278 |  0:01:26s\n",
      "epoch 54 | loss: 0.07901 | train_rmsle: 0.00469 | train_mae: 0.20299 | train_rmse: 0.26658 | train_mse: 0.07107 | valid_rmsle: 0.00499 | valid_mae: 0.21609 | valid_rmse: 0.28173 | valid_mse: 0.07937 |  0:01:28s\n",
      "epoch 55 | loss: 0.07481 | train_rmsle: 0.00466 | train_mae: 0.20316 | train_rmse: 0.26597 | train_mse: 0.07074 | valid_rmsle: 0.00496 | valid_mae: 0.21676 | valid_rmse: 0.28096 | valid_mse: 0.07894 |  0:01:30s\n",
      "epoch 56 | loss: 0.07273 | train_rmsle: 0.00474 | train_mae: 0.20872 | train_rmse: 0.2701  | train_mse: 0.07295 | valid_rmsle: 0.00507 | valid_mae: 0.22378 | valid_rmse: 0.28553 | valid_mse: 0.08153 |  0:01:31s\n",
      "epoch 57 | loss: 0.07349 | train_rmsle: 0.00456 | train_mae: 0.19941 | train_rmse: 0.26263 | train_mse: 0.06897 | valid_rmsle: 0.00488 | valid_mae: 0.21378 | valid_rmse: 0.2785  | valid_mse: 0.07756 |  0:01:33s\n",
      "epoch 58 | loss: 0.07119 | train_rmsle: 0.00451 | train_mae: 0.19991 | train_rmse: 0.26194 | train_mse: 0.06861 | valid_rmsle: 0.00491 | valid_mae: 0.21694 | valid_rmse: 0.2798  | valid_mse: 0.07829 |  0:01:35s\n",
      "epoch 59 | loss: 0.07296 | train_rmsle: 0.00465 | train_mae: 0.20838 | train_rmse: 0.26831 | train_mse: 0.07199 | valid_rmsle: 0.00506 | valid_mae: 0.22486 | valid_rmse: 0.28534 | valid_mse: 0.08142 |  0:01:36s\n",
      "epoch 60 | loss: 0.07131 | train_rmsle: 0.00441 | train_mae: 0.19686 | train_rmse: 0.25864 | train_mse: 0.06689 | valid_rmsle: 0.00473 | valid_mae: 0.21281 | valid_rmse: 0.2745  | valid_mse: 0.07535 |  0:01:38s\n",
      "epoch 61 | loss: 0.07101 | train_rmsle: 0.00454 | train_mae: 0.20612 | train_rmse: 0.26559 | train_mse: 0.07054 | valid_rmsle: 0.00491 | valid_mae: 0.22181 | valid_rmse: 0.28143 | valid_mse: 0.0792  |  0:01:40s\n",
      "epoch 62 | loss: 0.0695  | train_rmsle: 0.0043  | train_mae: 0.192   | train_rmse: 0.25455 | train_mse: 0.06479 | valid_rmsle: 0.00467 | valid_mae: 0.20902 | valid_rmse: 0.27219 | valid_mse: 0.07409 |  0:01:41s\n",
      "epoch 63 | loss: 0.06827 | train_rmsle: 0.0043  | train_mae: 0.19532 | train_rmse: 0.25597 | train_mse: 0.06552 | valid_rmsle: 0.00467 | valid_mae: 0.21349 | valid_rmse: 0.27388 | valid_mse: 0.07501 |  0:01:43s\n",
      "epoch 64 | loss: 0.06707 | train_rmsle: 0.00429 | train_mae: 0.1979  | train_rmse: 0.25665 | train_mse: 0.06587 | valid_rmsle: 0.00475 | valid_mae: 0.21683 | valid_rmse: 0.27692 | valid_mse: 0.07669 |  0:01:45s\n",
      "epoch 65 | loss: 0.06695 | train_rmsle: 0.00413 | train_mae: 0.19046 | train_rmse: 0.25045 | train_mse: 0.06273 | valid_rmsle: 0.00462 | valid_mae: 0.21185 | valid_rmse: 0.27191 | valid_mse: 0.07394 |  0:01:46s\n",
      "epoch 66 | loss: 0.06594 | train_rmsle: 0.00412 | train_mae: 0.19132 | train_rmse: 0.25054 | train_mse: 0.06277 | valid_rmsle: 0.00464 | valid_mae: 0.21331 | valid_rmse: 0.27321 | valid_mse: 0.07464 |  0:01:48s\n",
      "epoch 67 | loss: 0.06542 | train_rmsle: 0.00426 | train_mae: 0.18846 | train_rmse: 0.25334 | train_mse: 0.06418 | valid_rmsle: 0.0047  | valid_mae: 0.21081 | valid_rmse: 0.27497 | valid_mse: 0.07561 |  0:01:49s\n",
      "epoch 68 | loss: 0.06683 | train_rmsle: 0.00421 | train_mae: 0.19667 | train_rmse: 0.25492 | train_mse: 0.06498 | valid_rmsle: 0.00471 | valid_mae: 0.21915 | valid_rmse: 0.27689 | valid_mse: 0.07667 |  0:01:51s\n",
      "epoch 69 | loss: 0.06234 | train_rmsle: 0.0039  | train_mae: 0.18388 | train_rmse: 0.24309 | train_mse: 0.05909 | valid_rmsle: 0.0046  | valid_mae: 0.2118  | valid_rmse: 0.27225 | valid_mse: 0.07412 |  0:01:52s\n",
      "epoch 70 | loss: 0.06212 | train_rmsle: 0.00386 | train_mae: 0.18313 | train_rmse: 0.24234 | train_mse: 0.05873 | valid_rmsle: 0.00459 | valid_mae: 0.2115  | valid_rmse: 0.27231 | valid_mse: 0.07415 |  0:01:54s\n",
      "epoch 71 | loss: 0.06204 | train_rmsle: 0.00421 | train_mae: 0.19998 | train_rmse: 0.25614 | train_mse: 0.06561 | valid_rmsle: 0.00491 | valid_mae: 0.22531 | valid_rmse: 0.28276 | valid_mse: 0.07995 |  0:01:55s\n",
      "epoch 72 | loss: 0.06589 | train_rmsle: 0.00394 | train_mae: 0.17909 | train_rmse: 0.24221 | train_mse: 0.05867 | valid_rmsle: 0.00446 | valid_mae: 0.2046  | valid_rmse: 0.26686 | valid_mse: 0.07122 |  0:01:57s\n",
      "epoch 73 | loss: 0.06185 | train_rmsle: 0.00369 | train_mae: 0.18109 | train_rmse: 0.23799 | train_mse: 0.05664 | valid_rmsle: 0.00431 | valid_mae: 0.20874 | valid_rmse: 0.26428 | valid_mse: 0.06985 |  0:01:58s\n",
      "epoch 74 | loss: 0.05853 | train_rmsle: 0.00351 | train_mae: 0.17266 | train_rmse: 0.23059 | train_mse: 0.05317 | valid_rmsle: 0.00421 | valid_mae: 0.20281 | valid_rmse: 0.26141 | valid_mse: 0.06833 |  0:02:00s\n",
      "epoch 75 | loss: 0.05865 | train_rmsle: 0.00344 | train_mae: 0.17    | train_rmse: 0.22824 | train_mse: 0.05209 | valid_rmsle: 0.00413 | valid_mae: 0.20053 | valid_rmse: 0.25885 | valid_mse: 0.06701 |  0:02:01s\n",
      "epoch 76 | loss: 0.05623 | train_rmsle: 0.00339 | train_mae: 0.1714  | train_rmse: 0.22804 | train_mse: 0.052   | valid_rmsle: 0.00397 | valid_mae: 0.19941 | valid_rmse: 0.25493 | valid_mse: 0.06499 |  0:02:03s\n",
      "epoch 77 | loss: 0.05598 | train_rmsle: 0.00337 | train_mae: 0.17431 | train_rmse: 0.22952 | train_mse: 0.05268 | valid_rmsle: 0.004   | valid_mae: 0.20248 | valid_rmse: 0.25753 | valid_mse: 0.06632 |  0:02:04s\n",
      "epoch 78 | loss: 0.05459 | train_rmsle: 0.00329 | train_mae: 0.1685  | train_rmse: 0.22492 | train_mse: 0.05059 | valid_rmsle: 0.004   | valid_mae: 0.1984  | valid_rmse: 0.25633 | valid_mse: 0.0657  |  0:02:06s\n",
      "epoch 79 | loss: 0.0535  | train_rmsle: 0.00312 | train_mae: 0.16414 | train_rmse: 0.21931 | train_mse: 0.0481  | valid_rmsle: 0.00381 | valid_mae: 0.19434 | valid_rmse: 0.25089 | valid_mse: 0.06294 |  0:02:08s\n",
      "epoch 80 | loss: 0.05065 | train_rmsle: 0.00297 | train_mae: 0.16039 | train_rmse: 0.21439 | train_mse: 0.04596 | valid_rmsle: 0.00378 | valid_mae: 0.19324 | valid_rmse: 0.25002 | valid_mse: 0.06251 |  0:02:09s\n",
      "epoch 81 | loss: 0.0517  | train_rmsle: 0.00297 | train_mae: 0.15957 | train_rmse: 0.21335 | train_mse: 0.04552 | valid_rmsle: 0.00375 | valid_mae: 0.19151 | valid_rmse: 0.24896 | valid_mse: 0.06198 |  0:02:11s\n",
      "epoch 82 | loss: 0.0501  | train_rmsle: 0.00302 | train_mae: 0.16867 | train_rmse: 0.21944 | train_mse: 0.04815 | valid_rmsle: 0.00382 | valid_mae: 0.19954 | valid_rmse: 0.25355 | valid_mse: 0.06429 |  0:02:13s\n",
      "epoch 83 | loss: 0.05231 | train_rmsle: 0.0028  | train_mae: 0.15538 | train_rmse: 0.20852 | train_mse: 0.04348 | valid_rmsle: 0.00361 | valid_mae: 0.18862 | valid_rmse: 0.24594 | valid_mse: 0.06049 |  0:02:14s\n",
      "epoch 84 | loss: 0.04694 | train_rmsle: 0.00261 | train_mae: 0.15383 | train_rmse: 0.20339 | train_mse: 0.04137 | valid_rmsle: 0.00348 | valid_mae: 0.18933 | valid_rmse: 0.24345 | valid_mse: 0.05927 |  0:02:16s\n",
      "epoch 85 | loss: 0.04553 | train_rmsle: 0.00253 | train_mae: 0.15113 | train_rmse: 0.20032 | train_mse: 0.04013 | valid_rmsle: 0.0034  | valid_mae: 0.18654 | valid_rmse: 0.2409  | valid_mse: 0.05803 |  0:02:18s\n",
      "epoch 86 | loss: 0.04421 | train_rmsle: 0.00249 | train_mae: 0.15033 | train_rmse: 0.19937 | train_mse: 0.03975 | valid_rmsle: 0.00346 | valid_mae: 0.18794 | valid_rmse: 0.24266 | valid_mse: 0.05888 |  0:02:19s\n",
      "epoch 87 | loss: 0.04391 | train_rmsle: 0.0024  | train_mae: 0.14682 | train_rmse: 0.19509 | train_mse: 0.03806 | valid_rmsle: 0.00336 | valid_mae: 0.18474 | valid_rmse: 0.23948 | valid_mse: 0.05735 |  0:02:21s\n",
      "epoch 88 | loss: 0.0433  | train_rmsle: 0.00258 | train_mae: 0.15588 | train_rmse: 0.20422 | train_mse: 0.04171 | valid_rmsle: 0.00347 | valid_mae: 0.19262 | valid_rmse: 0.24434 | valid_mse: 0.0597  |  0:02:23s\n",
      "epoch 89 | loss: 0.04316 | train_rmsle: 0.00224 | train_mae: 0.14603 | train_rmse: 0.19204 | train_mse: 0.03688 | valid_rmsle: 0.0032  | valid_mae: 0.18528 | valid_rmse: 0.23657 | valid_mse: 0.05596 |  0:02:24s\n",
      "epoch 90 | loss: 0.04234 | train_rmsle: 0.0023  | train_mae: 0.14678 | train_rmse: 0.19381 | train_mse: 0.03756 | valid_rmsle: 0.00315 | valid_mae: 0.18138 | valid_rmse: 0.235   | valid_mse: 0.05522 |  0:02:26s\n",
      "epoch 91 | loss: 0.04173 | train_rmsle: 0.00232 | train_mae: 0.14543 | train_rmse: 0.19347 | train_mse: 0.03743 | valid_rmsle: 0.00322 | valid_mae: 0.18359 | valid_rmse: 0.23764 | valid_mse: 0.05647 |  0:02:28s\n",
      "epoch 92 | loss: 0.04211 | train_rmsle: 0.0024  | train_mae: 0.15346 | train_rmse: 0.20245 | train_mse: 0.04099 | valid_rmsle: 0.00336 | valid_mae: 0.18904 | valid_rmse: 0.24559 | valid_mse: 0.06031 |  0:02:29s\n",
      "epoch 93 | loss: 0.04089 | train_rmsle: 0.00217 | train_mae: 0.14309 | train_rmse: 0.18948 | train_mse: 0.0359  | valid_rmsle: 0.00305 | valid_mae: 0.17779 | valid_rmse: 0.23119 | valid_mse: 0.05345 |  0:02:31s\n",
      "epoch 94 | loss: 0.04008 | train_rmsle: 0.00211 | train_mae: 0.14366 | train_rmse: 0.18843 | train_mse: 0.03551 | valid_rmsle: 0.00293 | valid_mae: 0.17564 | valid_rmse: 0.22667 | valid_mse: 0.05138 |  0:02:33s\n",
      "epoch 95 | loss: 0.03879 | train_rmsle: 0.0021  | train_mae: 0.14516 | train_rmse: 0.18968 | train_mse: 0.03598 | valid_rmsle: 0.00297 | valid_mae: 0.17962 | valid_rmse: 0.22927 | valid_mse: 0.05256 |  0:02:34s\n",
      "epoch 96 | loss: 0.0382  | train_rmsle: 0.00186 | train_mae: 0.13196 | train_rmse: 0.17633 | train_mse: 0.03109 | valid_rmsle: 0.0027  | valid_mae: 0.16602 | valid_rmse: 0.21805 | valid_mse: 0.04754 |  0:02:36s\n",
      "epoch 97 | loss: 0.03583 | train_rmsle: 0.00188 | train_mae: 0.13217 | train_rmse: 0.1759  | train_mse: 0.03094 | valid_rmsle: 0.00271 | valid_mae: 0.16755 | valid_rmse: 0.2184  | valid_mse: 0.0477  |  0:02:38s\n",
      "epoch 98 | loss: 0.03686 | train_rmsle: 0.00191 | train_mae: 0.13225 | train_rmse: 0.17598 | train_mse: 0.03097 | valid_rmsle: 0.00276 | valid_mae: 0.16927 | valid_rmse: 0.22004 | valid_mse: 0.04842 |  0:02:39s\n",
      "epoch 99 | loss: 0.03507 | train_rmsle: 0.00174 | train_mae: 0.12641 | train_rmse: 0.16962 | train_mse: 0.02877 | valid_rmsle: 0.00257 | valid_mae: 0.1628  | valid_rmse: 0.21322 | valid_mse: 0.04546 |  0:02:41s\n",
      "epoch 100| loss: 0.03457 | train_rmsle: 0.00165 | train_mae: 0.12362 | train_rmse: 0.16584 | train_mse: 0.0275  | valid_rmsle: 0.00253 | valid_mae: 0.16106 | valid_rmse: 0.21235 | valid_mse: 0.04509 |  0:02:43s\n",
      "epoch 101| loss: 0.03332 | train_rmsle: 0.00162 | train_mae: 0.12321 | train_rmse: 0.16507 | train_mse: 0.02725 | valid_rmsle: 0.00251 | valid_mae: 0.16108 | valid_rmse: 0.21248 | valid_mse: 0.04515 |  0:02:44s\n",
      "epoch 102| loss: 0.03374 | train_rmsle: 0.00164 | train_mae: 0.12586 | train_rmse: 0.16719 | train_mse: 0.02795 | valid_rmsle: 0.00244 | valid_mae: 0.15996 | valid_rmse: 0.20982 | valid_mse: 0.04402 |  0:02:46s\n",
      "epoch 103| loss: 0.03491 | train_rmsle: 0.00189 | train_mae: 0.1367  | train_rmse: 0.18159 | train_mse: 0.03297 | valid_rmsle: 0.0027  | valid_mae: 0.16967 | valid_rmse: 0.22318 | valid_mse: 0.04981 |  0:02:47s\n",
      "epoch 104| loss: 0.03516 | train_rmsle: 0.00156 | train_mae: 0.12062 | train_rmse: 0.16275 | train_mse: 0.02649 | valid_rmsle: 0.00234 | valid_mae: 0.15703 | valid_rmse: 0.20609 | valid_mse: 0.04247 |  0:02:48s\n",
      "epoch 105| loss: 0.03258 | train_rmsle: 0.00157 | train_mae: 0.1238  | train_rmse: 0.16487 | train_mse: 0.02718 | valid_rmsle: 0.00243 | valid_mae: 0.16143 | valid_rmse: 0.21076 | valid_mse: 0.04442 |  0:02:50s\n",
      "epoch 106| loss: 0.03176 | train_rmsle: 0.00152 | train_mae: 0.12062 | train_rmse: 0.16173 | train_mse: 0.02616 | valid_rmsle: 0.00236 | valid_mae: 0.15784 | valid_rmse: 0.20799 | valid_mse: 0.04326 |  0:02:51s\n",
      "epoch 107| loss: 0.03182 | train_rmsle: 0.00166 | train_mae: 0.12925 | train_rmse: 0.17083 | train_mse: 0.02918 | valid_rmsle: 0.00232 | valid_mae: 0.16009 | valid_rmse: 0.20634 | valid_mse: 0.04258 |  0:02:53s\n",
      "epoch 108| loss: 0.03043 | train_rmsle: 0.00147 | train_mae: 0.11882 | train_rmse: 0.15943 | train_mse: 0.02542 | valid_rmsle: 0.00216 | valid_mae: 0.15289 | valid_rmse: 0.1987  | valid_mse: 0.03948 |  0:02:54s\n",
      "epoch 109| loss: 0.03113 | train_rmsle: 0.00148 | train_mae: 0.11871 | train_rmse: 0.15816 | train_mse: 0.02501 | valid_rmsle: 0.00227 | valid_mae: 0.15512 | valid_rmse: 0.20207 | valid_mse: 0.04083 |  0:02:55s\n",
      "epoch 110| loss: 0.03071 | train_rmsle: 0.00136 | train_mae: 0.1123  | train_rmse: 0.15254 | train_mse: 0.02327 | valid_rmsle: 0.00219 | valid_mae: 0.15217 | valid_rmse: 0.20026 | valid_mse: 0.0401  |  0:02:57s\n",
      "epoch 111| loss: 0.02976 | train_rmsle: 0.0014  | train_mae: 0.11532 | train_rmse: 0.15529 | train_mse: 0.02412 | valid_rmsle: 0.00215 | valid_mae: 0.15255 | valid_rmse: 0.19847 | valid_mse: 0.03939 |  0:02:59s\n",
      "epoch 112| loss: 0.02924 | train_rmsle: 0.00158 | train_mae: 0.1279  | train_rmse: 0.16738 | train_mse: 0.02802 | valid_rmsle: 0.00232 | valid_mae: 0.16059 | valid_rmse: 0.20712 | valid_mse: 0.0429  |  0:03:00s\n",
      "epoch 113| loss: 0.02943 | train_rmsle: 0.00134 | train_mae: 0.11498 | train_rmse: 0.15343 | train_mse: 0.02354 | valid_rmsle: 0.00216 | valid_mae: 0.15294 | valid_rmse: 0.19956 | valid_mse: 0.03983 |  0:03:02s\n",
      "epoch 114| loss: 0.02932 | train_rmsle: 0.00148 | train_mae: 0.11806 | train_rmse: 0.15752 | train_mse: 0.02481 | valid_rmsle: 0.00236 | valid_mae: 0.15666 | valid_rmse: 0.2067  | valid_mse: 0.04272 |  0:03:04s\n",
      "epoch 115| loss: 0.03202 | train_rmsle: 0.00143 | train_mae: 0.12025 | train_rmse: 0.16039 | train_mse: 0.02573 | valid_rmsle: 0.00221 | valid_mae: 0.15595 | valid_rmse: 0.20331 | valid_mse: 0.04134 |  0:03:05s\n",
      "epoch 116| loss: 0.02963 | train_rmsle: 0.00128 | train_mae: 0.11102 | train_rmse: 0.14959 | train_mse: 0.02238 | valid_rmsle: 0.00206 | valid_mae: 0.14669 | valid_rmse: 0.1956  | valid_mse: 0.03826 |  0:03:07s\n",
      "epoch 117| loss: 0.02888 | train_rmsle: 0.00127 | train_mae: 0.11112 | train_rmse: 0.15042 | train_mse: 0.02263 | valid_rmsle: 0.00205 | valid_mae: 0.1488  | valid_rmse: 0.19497 | valid_mse: 0.03801 |  0:03:09s\n",
      "epoch 118| loss: 0.02728 | train_rmsle: 0.00117 | train_mae: 0.10521 | train_rmse: 0.14318 | train_mse: 0.0205  | valid_rmsle: 0.00204 | valid_mae: 0.14695 | valid_rmse: 0.19528 | valid_mse: 0.03814 |  0:03:10s\n",
      "epoch 119| loss: 0.02601 | train_rmsle: 0.00132 | train_mae: 0.11374 | train_rmse: 0.1515  | train_mse: 0.02295 | valid_rmsle: 0.00214 | valid_mae: 0.1505  | valid_rmse: 0.20009 | valid_mse: 0.04004 |  0:03:12s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 117 and best_valid_mse = 0.03801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03875474164334836 RMSE: 0.196862240268032 R2: 0.828447691666711 MAE: 0.15017869878228784\n",
      "=====================================\n",
      "[7/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.41126 | train_rmsle: 0.22451 | train_mae: 1.58922 | train_rmse: 1.66063 | train_mse: 2.75769 | valid_rmsle: 0.22542 | valid_mae: 1.59455 | valid_rmse: 1.66499 | valid_mse: 2.77219 |  0:00:01s\n",
      "epoch 1  | loss: 1.36441 | train_rmsle: 0.11745 | train_mae: 1.20246 | train_rmse: 1.28758 | train_mse: 1.65787 | valid_rmsle: 0.11776 | valid_mae: 1.20507 | valid_rmse: 1.29057 | valid_mse: 1.66558 |  0:00:03s\n",
      "epoch 2  | loss: 0.44066 | train_rmsle: 0.04683 | train_mae: 0.77922 | train_rmse: 0.87272 | train_mse: 0.76165 | valid_rmsle: 0.04683 | valid_mae: 0.77955 | valid_rmse: 0.87504 | valid_mse: 0.76569 |  0:00:04s\n",
      "epoch 3  | loss: 0.28356 | train_rmsle: 0.0478  | train_mae: 0.78705 | train_rmse: 0.88059 | train_mse: 0.77544 | valid_rmsle: 0.04781 | valid_mae: 0.7873  | valid_rmse: 0.88299 | valid_mse: 0.77967 |  0:00:06s\n",
      "epoch 4  | loss: 0.25629 | train_rmsle: 0.03395 | train_mae: 0.66253 | train_rmse: 0.75523 | train_mse: 0.57037 | valid_rmsle: 0.03384 | valid_mae: 0.6616  | valid_rmse: 0.75694 | valid_mse: 0.57296 |  0:00:08s\n",
      "epoch 5  | loss: 0.24272 | train_rmsle: 0.02662 | train_mae: 0.58335 | train_rmse: 0.67398 | train_mse: 0.45425 | valid_rmsle: 0.02638 | valid_mae: 0.58323 | valid_rmse: 0.67454 | valid_mse: 0.455   |  0:00:09s\n",
      "epoch 6  | loss: 0.23751 | train_rmsle: 0.01834 | train_mae: 0.47103 | train_rmse: 0.55857 | train_mse: 0.312   | valid_rmsle: 0.01796 | valid_mae: 0.47255 | valid_rmse: 0.55762 | valid_mse: 0.31094 |  0:00:11s\n",
      "epoch 7  | loss: 0.23428 | train_rmsle: 0.01919 | train_mae: 0.48458 | train_rmse: 0.57229 | train_mse: 0.32751 | valid_rmsle: 0.01882 | valid_mae: 0.48578 | valid_rmse: 0.57142 | valid_mse: 0.32652 |  0:00:13s\n",
      "epoch 8  | loss: 0.22362 | train_rmsle: 0.01696 | train_mae: 0.44789 | train_rmse: 0.53511 | train_mse: 0.28634 | valid_rmsle: 0.01657 | valid_mae: 0.44959 | valid_rmse: 0.53394 | valid_mse: 0.2851  |  0:00:14s\n",
      "epoch 9  | loss: 0.21654 | train_rmsle: 0.01421 | train_mae: 0.39191 | train_rmse: 0.48247 | train_mse: 0.23278 | valid_rmsle: 0.0137  | valid_mae: 0.39216 | valid_rmse: 0.47924 | valid_mse: 0.22967 |  0:00:16s\n",
      "epoch 10 | loss: 0.20475 | train_rmsle: 0.01323 | train_mae: 0.37904 | train_rmse: 0.46659 | train_mse: 0.2177  | valid_rmsle: 0.01266 | valid_mae: 0.37605 | valid_rmse: 0.46155 | valid_mse: 0.21303 |  0:00:18s\n",
      "epoch 11 | loss: 0.19394 | train_rmsle: 0.01114 | train_mae: 0.34095 | train_rmse: 0.42525 | train_mse: 0.18083 | valid_rmsle: 0.01056 | valid_mae: 0.33769 | valid_rmse: 0.41881 | valid_mse: 0.17541 |  0:00:19s\n",
      "epoch 12 | loss: 0.18006 | train_rmsle: 0.00905 | train_mae: 0.2994  | train_rmse: 0.38071 | train_mse: 0.14494 | valid_rmsle: 0.00822 | valid_mae: 0.28964 | valid_rmse: 0.36716 | valid_mse: 0.1348  |  0:00:21s\n",
      "epoch 13 | loss: 0.16872 | train_rmsle: 0.00802 | train_mae: 0.27838 | train_rmse: 0.35647 | train_mse: 0.12707 | valid_rmsle: 0.00721 | valid_mae: 0.26675 | valid_rmse: 0.3416  | valid_mse: 0.11669 |  0:00:23s\n",
      "epoch 14 | loss: 0.15586 | train_rmsle: 0.00804 | train_mae: 0.27492 | train_rmse: 0.35383 | train_mse: 0.12519 | valid_rmsle: 0.00733 | valid_mae: 0.26475 | valid_rmse: 0.34067 | valid_mse: 0.11606 |  0:00:24s\n",
      "epoch 15 | loss: 0.14583 | train_rmsle: 0.00709 | train_mae: 0.25788 | train_rmse: 0.33269 | train_mse: 0.11068 | valid_rmsle: 0.00636 | valid_mae: 0.24563 | valid_rmse: 0.31788 | valid_mse: 0.10104 |  0:00:26s\n",
      "epoch 16 | loss: 0.13755 | train_rmsle: 0.00733 | train_mae: 0.26757 | train_rmse: 0.34015 | train_mse: 0.1157  | valid_rmsle: 0.00664 | valid_mae: 0.25625 | valid_rmse: 0.3268  | valid_mse: 0.1068  |  0:00:28s\n",
      "epoch 17 | loss: 0.12759 | train_rmsle: 0.0075  | train_mae: 0.27144 | train_rmse: 0.34413 | train_mse: 0.11843 | valid_rmsle: 0.00683 | valid_mae: 0.26124 | valid_rmse: 0.33123 | valid_mse: 0.10971 |  0:00:29s\n",
      "epoch 18 | loss: 0.12263 | train_rmsle: 0.00705 | train_mae: 0.25837 | train_rmse: 0.33158 | train_mse: 0.10995 | valid_rmsle: 0.00632 | valid_mae: 0.24593 | valid_rmse: 0.31677 | valid_mse: 0.10034 |  0:00:31s\n",
      "epoch 19 | loss: 0.12099 | train_rmsle: 0.00668 | train_mae: 0.24689 | train_rmse: 0.32082 | train_mse: 0.10293 | valid_rmsle: 0.00598 | valid_mae: 0.23352 | valid_rmse: 0.30597 | valid_mse: 0.09362 |  0:00:33s\n",
      "epoch 20 | loss: 0.11696 | train_rmsle: 0.00705 | train_mae: 0.259   | train_rmse: 0.33207 | train_mse: 0.11027 | valid_rmsle: 0.00641 | valid_mae: 0.24811 | valid_rmse: 0.31886 | valid_mse: 0.10167 |  0:00:35s\n",
      "epoch 21 | loss: 0.11287 | train_rmsle: 0.00666 | train_mae: 0.24952 | train_rmse: 0.32174 | train_mse: 0.10352 | valid_rmsle: 0.00603 | valid_mae: 0.23773 | valid_rmse: 0.30841 | valid_mse: 0.09511 |  0:00:36s\n",
      "epoch 22 | loss: 0.11005 | train_rmsle: 0.00656 | train_mae: 0.2463  | train_rmse: 0.31838 | train_mse: 0.10137 | valid_rmsle: 0.00592 | valid_mae: 0.23609 | valid_rmse: 0.30534 | valid_mse: 0.09323 |  0:00:38s\n",
      "epoch 23 | loss: 0.1094  | train_rmsle: 0.00648 | train_mae: 0.24456 | train_rmse: 0.31663 | train_mse: 0.10025 | valid_rmsle: 0.006   | valid_mae: 0.23699 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:00:39s\n",
      "epoch 24 | loss: 0.10859 | train_rmsle: 0.00648 | train_mae: 0.24412 | train_rmse: 0.3167  | train_mse: 0.1003  | valid_rmsle: 0.00595 | valid_mae: 0.23648 | valid_rmse: 0.30634 | valid_mse: 0.09384 |  0:00:41s\n",
      "epoch 25 | loss: 0.10458 | train_rmsle: 0.00648 | train_mae: 0.24638 | train_rmse: 0.31769 | train_mse: 0.10093 | valid_rmsle: 0.00598 | valid_mae: 0.23923 | valid_rmse: 0.30774 | valid_mse: 0.0947  |  0:00:43s\n",
      "epoch 26 | loss: 0.10121 | train_rmsle: 0.00635 | train_mae: 0.24174 | train_rmse: 0.31351 | train_mse: 0.09829 | valid_rmsle: 0.00586 | valid_mae: 0.23453 | valid_rmse: 0.30398 | valid_mse: 0.0924  |  0:00:45s\n",
      "epoch 27 | loss: 0.10049 | train_rmsle: 0.00625 | train_mae: 0.23896 | train_rmse: 0.31074 | train_mse: 0.09656 | valid_rmsle: 0.00579 | valid_mae: 0.23261 | valid_rmse: 0.30238 | valid_mse: 0.09144 |  0:00:46s\n",
      "epoch 28 | loss: 0.09903 | train_rmsle: 0.00625 | train_mae: 0.24157 | train_rmse: 0.31196 | train_mse: 0.09732 | valid_rmsle: 0.00589 | valid_mae: 0.23889 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:00:48s\n",
      "epoch 29 | loss: 0.09648 | train_rmsle: 0.00628 | train_mae: 0.24443 | train_rmse: 0.31373 | train_mse: 0.09843 | valid_rmsle: 0.00595 | valid_mae: 0.24189 | valid_rmse: 0.30868 | valid_mse: 0.09528 |  0:00:50s\n",
      "epoch 30 | loss: 0.09613 | train_rmsle: 0.00599 | train_mae: 0.23312 | train_rmse: 0.30413 | train_mse: 0.0925  | valid_rmsle: 0.00573 | valid_mae: 0.23418 | valid_rmse: 0.30186 | valid_mse: 0.09112 |  0:00:51s\n",
      "epoch 31 | loss: 0.09398 | train_rmsle: 0.006   | train_mae: 0.23578 | train_rmse: 0.30566 | train_mse: 0.09343 | valid_rmsle: 0.00575 | valid_mae: 0.23682 | valid_rmse: 0.3038  | valid_mse: 0.09229 |  0:00:53s\n",
      "epoch 32 | loss: 0.09328 | train_rmsle: 0.00587 | train_mae: 0.23018 | train_rmse: 0.30086 | train_mse: 0.09052 | valid_rmsle: 0.00559 | valid_mae: 0.23255 | valid_rmse: 0.29911 | valid_mse: 0.08947 |  0:00:55s\n",
      "epoch 33 | loss: 0.09289 | train_rmsle: 0.0058  | train_mae: 0.22792 | train_rmse: 0.29882 | train_mse: 0.0893  | valid_rmsle: 0.0056  | valid_mae: 0.22933 | valid_rmse: 0.29909 | valid_mse: 0.08945 |  0:00:56s\n",
      "epoch 34 | loss: 0.09356 | train_rmsle: 0.00575 | train_mae: 0.22408 | train_rmse: 0.29618 | train_mse: 0.08772 | valid_rmsle: 0.0055  | valid_mae: 0.22554 | valid_rmse: 0.29515 | valid_mse: 0.08711 |  0:00:58s\n",
      "epoch 35 | loss: 0.09019 | train_rmsle: 0.00566 | train_mae: 0.22418 | train_rmse: 0.29447 | train_mse: 0.08671 | valid_rmsle: 0.00547 | valid_mae: 0.22724 | valid_rmse: 0.29563 | valid_mse: 0.0874  |  0:01:00s\n",
      "epoch 36 | loss: 0.08969 | train_rmsle: 0.00582 | train_mae: 0.23374 | train_rmse: 0.30157 | train_mse: 0.09094 | valid_rmsle: 0.00565 | valid_mae: 0.23661 | valid_rmse: 0.30269 | valid_mse: 0.09162 |  0:01:01s\n",
      "epoch 37 | loss: 0.08878 | train_rmsle: 0.00589 | train_mae: 0.22515 | train_rmse: 0.29959 | train_mse: 0.08975 | valid_rmsle: 0.00569 | valid_mae: 0.22891 | valid_rmse: 0.30076 | valid_mse: 0.09046 |  0:01:03s\n",
      "epoch 38 | loss: 0.09122 | train_rmsle: 0.00564 | train_mae: 0.22997 | train_rmse: 0.29677 | train_mse: 0.08807 | valid_rmsle: 0.00553 | valid_mae: 0.23425 | valid_rmse: 0.29909 | valid_mse: 0.08946 |  0:01:04s\n",
      "epoch 39 | loss: 0.08675 | train_rmsle: 0.0054  | train_mae: 0.21735 | train_rmse: 0.28662 | train_mse: 0.08215 | valid_rmsle: 0.00531 | valid_mae: 0.22307 | valid_rmse: 0.29024 | valid_mse: 0.08424 |  0:01:06s\n",
      "epoch 40 | loss: 0.08523 | train_rmsle: 0.0054  | train_mae: 0.22024 | train_rmse: 0.28804 | train_mse: 0.08297 | valid_rmsle: 0.00532 | valid_mae: 0.2254  | valid_rmse: 0.29166 | valid_mse: 0.08507 |  0:01:07s\n",
      "epoch 41 | loss: 0.08505 | train_rmsle: 0.00531 | train_mae: 0.21728 | train_rmse: 0.28493 | train_mse: 0.08119 | valid_rmsle: 0.00523 | valid_mae: 0.22239 | valid_rmse: 0.28844 | valid_mse: 0.0832  |  0:01:09s\n",
      "epoch 42 | loss: 0.08382 | train_rmsle: 0.00537 | train_mae: 0.22248 | train_rmse: 0.28891 | train_mse: 0.08347 | valid_rmsle: 0.00525 | valid_mae: 0.22663 | valid_rmse: 0.29081 | valid_mse: 0.08457 |  0:01:10s\n",
      "epoch 43 | loss: 0.08247 | train_rmsle: 0.00515 | train_mae: 0.21188 | train_rmse: 0.27988 | train_mse: 0.07834 | valid_rmsle: 0.00515 | valid_mae: 0.21871 | valid_rmse: 0.28598 | valid_mse: 0.08178 |  0:01:12s\n",
      "epoch 44 | loss: 0.08373 | train_rmsle: 0.00531 | train_mae: 0.21304 | train_rmse: 0.28292 | train_mse: 0.08004 | valid_rmsle: 0.00534 | valid_mae: 0.22161 | valid_rmse: 0.29017 | valid_mse: 0.0842  |  0:01:13s\n",
      "epoch 45 | loss: 0.08177 | train_rmsle: 0.00537 | train_mae: 0.22605 | train_rmse: 0.2901  | train_mse: 0.08416 | valid_rmsle: 0.00541 | valid_mae: 0.23394 | valid_rmse: 0.29654 | valid_mse: 0.08793 |  0:01:15s\n",
      "epoch 46 | loss: 0.07971 | train_rmsle: 0.00518 | train_mae: 0.21021 | train_rmse: 0.27954 | train_mse: 0.07814 | valid_rmsle: 0.00528 | valid_mae: 0.21996 | valid_rmse: 0.28876 | valid_mse: 0.08338 |  0:01:16s\n",
      "epoch 47 | loss: 0.07961 | train_rmsle: 0.00507 | train_mae: 0.21587 | train_rmse: 0.28001 | train_mse: 0.07841 | valid_rmsle: 0.00523 | valid_mae: 0.22682 | valid_rmse: 0.29035 | valid_mse: 0.0843  |  0:01:18s\n",
      "epoch 48 | loss: 0.07978 | train_rmsle: 0.00491 | train_mae: 0.20649 | train_rmse: 0.27294 | train_mse: 0.07449 | valid_rmsle: 0.0051  | valid_mae: 0.21795 | valid_rmse: 0.28469 | valid_mse: 0.08105 |  0:01:20s\n",
      "epoch 49 | loss: 0.07923 | train_rmsle: 0.00487 | train_mae: 0.20587 | train_rmse: 0.27193 | train_mse: 0.07395 | valid_rmsle: 0.00506 | valid_mae: 0.21829 | valid_rmse: 0.2838  | valid_mse: 0.08054 |  0:01:21s\n",
      "epoch 50 | loss: 0.07797 | train_rmsle: 0.00485 | train_mae: 0.20643 | train_rmse: 0.27184 | train_mse: 0.0739  | valid_rmsle: 0.00506 | valid_mae: 0.2181  | valid_rmse: 0.28406 | valid_mse: 0.08069 |  0:01:23s\n",
      "epoch 51 | loss: 0.0765  | train_rmsle: 0.00498 | train_mae: 0.21474 | train_rmse: 0.27737 | train_mse: 0.07694 | valid_rmsle: 0.00521 | valid_mae: 0.22526 | valid_rmse: 0.28924 | valid_mse: 0.08366 |  0:01:25s\n",
      "epoch 52 | loss: 0.07529 | train_rmsle: 0.00482 | train_mae: 0.20729 | train_rmse: 0.27108 | train_mse: 0.07348 | valid_rmsle: 0.0051  | valid_mae: 0.22012 | valid_rmse: 0.28478 | valid_mse: 0.0811  |  0:01:27s\n",
      "epoch 53 | loss: 0.07689 | train_rmsle: 0.0049  | train_mae: 0.21337 | train_rmse: 0.27539 | train_mse: 0.07584 | valid_rmsle: 0.00514 | valid_mae: 0.22581 | valid_rmse: 0.28772 | valid_mse: 0.08278 |  0:01:28s\n",
      "epoch 54 | loss: 0.07901 | train_rmsle: 0.00469 | train_mae: 0.20299 | train_rmse: 0.26658 | train_mse: 0.07107 | valid_rmsle: 0.00499 | valid_mae: 0.21609 | valid_rmse: 0.28173 | valid_mse: 0.07937 |  0:01:30s\n",
      "epoch 55 | loss: 0.07481 | train_rmsle: 0.00466 | train_mae: 0.20316 | train_rmse: 0.26597 | train_mse: 0.07074 | valid_rmsle: 0.00496 | valid_mae: 0.21676 | valid_rmse: 0.28096 | valid_mse: 0.07894 |  0:01:32s\n",
      "epoch 56 | loss: 0.07273 | train_rmsle: 0.00474 | train_mae: 0.20872 | train_rmse: 0.2701  | train_mse: 0.07295 | valid_rmsle: 0.00507 | valid_mae: 0.22378 | valid_rmse: 0.28553 | valid_mse: 0.08153 |  0:01:33s\n",
      "epoch 57 | loss: 0.07349 | train_rmsle: 0.00456 | train_mae: 0.19941 | train_rmse: 0.26263 | train_mse: 0.06897 | valid_rmsle: 0.00488 | valid_mae: 0.21378 | valid_rmse: 0.2785  | valid_mse: 0.07756 |  0:01:35s\n",
      "epoch 58 | loss: 0.07119 | train_rmsle: 0.00451 | train_mae: 0.19991 | train_rmse: 0.26194 | train_mse: 0.06861 | valid_rmsle: 0.00491 | valid_mae: 0.21694 | valid_rmse: 0.2798  | valid_mse: 0.07829 |  0:01:37s\n",
      "epoch 59 | loss: 0.07296 | train_rmsle: 0.00465 | train_mae: 0.20838 | train_rmse: 0.26831 | train_mse: 0.07199 | valid_rmsle: 0.00506 | valid_mae: 0.22486 | valid_rmse: 0.28534 | valid_mse: 0.08142 |  0:01:38s\n",
      "epoch 60 | loss: 0.07131 | train_rmsle: 0.00441 | train_mae: 0.19686 | train_rmse: 0.25864 | train_mse: 0.06689 | valid_rmsle: 0.00473 | valid_mae: 0.21281 | valid_rmse: 0.2745  | valid_mse: 0.07535 |  0:01:40s\n",
      "epoch 61 | loss: 0.07101 | train_rmsle: 0.00454 | train_mae: 0.20612 | train_rmse: 0.26559 | train_mse: 0.07054 | valid_rmsle: 0.00491 | valid_mae: 0.22181 | valid_rmse: 0.28143 | valid_mse: 0.0792  |  0:01:42s\n",
      "epoch 62 | loss: 0.0695  | train_rmsle: 0.0043  | train_mae: 0.192   | train_rmse: 0.25455 | train_mse: 0.06479 | valid_rmsle: 0.00467 | valid_mae: 0.20902 | valid_rmse: 0.27219 | valid_mse: 0.07409 |  0:01:43s\n",
      "epoch 63 | loss: 0.06827 | train_rmsle: 0.0043  | train_mae: 0.19532 | train_rmse: 0.25597 | train_mse: 0.06552 | valid_rmsle: 0.00467 | valid_mae: 0.21349 | valid_rmse: 0.27388 | valid_mse: 0.07501 |  0:01:45s\n",
      "epoch 64 | loss: 0.06707 | train_rmsle: 0.00429 | train_mae: 0.1979  | train_rmse: 0.25665 | train_mse: 0.06587 | valid_rmsle: 0.00475 | valid_mae: 0.21683 | valid_rmse: 0.27692 | valid_mse: 0.07669 |  0:01:47s\n",
      "epoch 65 | loss: 0.06695 | train_rmsle: 0.00413 | train_mae: 0.19046 | train_rmse: 0.25045 | train_mse: 0.06273 | valid_rmsle: 0.00462 | valid_mae: 0.21185 | valid_rmse: 0.27191 | valid_mse: 0.07394 |  0:01:48s\n",
      "epoch 66 | loss: 0.06594 | train_rmsle: 0.00412 | train_mae: 0.19132 | train_rmse: 0.25054 | train_mse: 0.06277 | valid_rmsle: 0.00464 | valid_mae: 0.21331 | valid_rmse: 0.27321 | valid_mse: 0.07464 |  0:01:50s\n",
      "epoch 67 | loss: 0.06542 | train_rmsle: 0.00426 | train_mae: 0.18846 | train_rmse: 0.25334 | train_mse: 0.06418 | valid_rmsle: 0.0047  | valid_mae: 0.21081 | valid_rmse: 0.27497 | valid_mse: 0.07561 |  0:01:52s\n",
      "epoch 68 | loss: 0.06683 | train_rmsle: 0.00421 | train_mae: 0.19667 | train_rmse: 0.25492 | train_mse: 0.06498 | valid_rmsle: 0.00471 | valid_mae: 0.21915 | valid_rmse: 0.27689 | valid_mse: 0.07667 |  0:01:53s\n",
      "epoch 69 | loss: 0.06234 | train_rmsle: 0.0039  | train_mae: 0.18388 | train_rmse: 0.24309 | train_mse: 0.05909 | valid_rmsle: 0.0046  | valid_mae: 0.2118  | valid_rmse: 0.27225 | valid_mse: 0.07412 |  0:01:55s\n",
      "epoch 70 | loss: 0.06212 | train_rmsle: 0.00386 | train_mae: 0.18313 | train_rmse: 0.24234 | train_mse: 0.05873 | valid_rmsle: 0.00459 | valid_mae: 0.2115  | valid_rmse: 0.27231 | valid_mse: 0.07415 |  0:01:56s\n",
      "epoch 71 | loss: 0.06204 | train_rmsle: 0.00421 | train_mae: 0.19998 | train_rmse: 0.25614 | train_mse: 0.06561 | valid_rmsle: 0.00491 | valid_mae: 0.22531 | valid_rmse: 0.28276 | valid_mse: 0.07995 |  0:01:57s\n",
      "epoch 72 | loss: 0.06589 | train_rmsle: 0.00394 | train_mae: 0.17909 | train_rmse: 0.24221 | train_mse: 0.05867 | valid_rmsle: 0.00446 | valid_mae: 0.2046  | valid_rmse: 0.26686 | valid_mse: 0.07122 |  0:01:59s\n",
      "epoch 73 | loss: 0.06185 | train_rmsle: 0.00369 | train_mae: 0.18109 | train_rmse: 0.23799 | train_mse: 0.05664 | valid_rmsle: 0.00431 | valid_mae: 0.20874 | valid_rmse: 0.26428 | valid_mse: 0.06985 |  0:02:00s\n",
      "epoch 74 | loss: 0.05853 | train_rmsle: 0.00351 | train_mae: 0.17266 | train_rmse: 0.23059 | train_mse: 0.05317 | valid_rmsle: 0.00421 | valid_mae: 0.20281 | valid_rmse: 0.26141 | valid_mse: 0.06833 |  0:02:02s\n",
      "epoch 75 | loss: 0.05865 | train_rmsle: 0.00344 | train_mae: 0.17    | train_rmse: 0.22824 | train_mse: 0.05209 | valid_rmsle: 0.00413 | valid_mae: 0.20053 | valid_rmse: 0.25885 | valid_mse: 0.06701 |  0:02:03s\n",
      "epoch 76 | loss: 0.05623 | train_rmsle: 0.00339 | train_mae: 0.1714  | train_rmse: 0.22804 | train_mse: 0.052   | valid_rmsle: 0.00397 | valid_mae: 0.19941 | valid_rmse: 0.25493 | valid_mse: 0.06499 |  0:02:05s\n",
      "epoch 77 | loss: 0.05598 | train_rmsle: 0.00337 | train_mae: 0.17431 | train_rmse: 0.22952 | train_mse: 0.05268 | valid_rmsle: 0.004   | valid_mae: 0.20248 | valid_rmse: 0.25753 | valid_mse: 0.06632 |  0:02:06s\n",
      "epoch 78 | loss: 0.05459 | train_rmsle: 0.00329 | train_mae: 0.1685  | train_rmse: 0.22492 | train_mse: 0.05059 | valid_rmsle: 0.004   | valid_mae: 0.1984  | valid_rmse: 0.25633 | valid_mse: 0.0657  |  0:02:08s\n",
      "epoch 79 | loss: 0.0535  | train_rmsle: 0.00312 | train_mae: 0.16414 | train_rmse: 0.21931 | train_mse: 0.0481  | valid_rmsle: 0.00381 | valid_mae: 0.19434 | valid_rmse: 0.25089 | valid_mse: 0.06294 |  0:02:10s\n",
      "epoch 80 | loss: 0.05065 | train_rmsle: 0.00297 | train_mae: 0.16039 | train_rmse: 0.21439 | train_mse: 0.04596 | valid_rmsle: 0.00378 | valid_mae: 0.19324 | valid_rmse: 0.25002 | valid_mse: 0.06251 |  0:02:11s\n",
      "epoch 81 | loss: 0.0517  | train_rmsle: 0.00297 | train_mae: 0.15957 | train_rmse: 0.21335 | train_mse: 0.04552 | valid_rmsle: 0.00375 | valid_mae: 0.19151 | valid_rmse: 0.24896 | valid_mse: 0.06198 |  0:02:13s\n",
      "epoch 82 | loss: 0.0501  | train_rmsle: 0.00302 | train_mae: 0.16867 | train_rmse: 0.21944 | train_mse: 0.04815 | valid_rmsle: 0.00382 | valid_mae: 0.19954 | valid_rmse: 0.25355 | valid_mse: 0.06429 |  0:02:15s\n",
      "epoch 83 | loss: 0.05231 | train_rmsle: 0.0028  | train_mae: 0.15538 | train_rmse: 0.20852 | train_mse: 0.04348 | valid_rmsle: 0.00361 | valid_mae: 0.18862 | valid_rmse: 0.24594 | valid_mse: 0.06049 |  0:02:16s\n",
      "epoch 84 | loss: 0.04694 | train_rmsle: 0.00261 | train_mae: 0.15383 | train_rmse: 0.20339 | train_mse: 0.04137 | valid_rmsle: 0.00348 | valid_mae: 0.18933 | valid_rmse: 0.24345 | valid_mse: 0.05927 |  0:02:18s\n",
      "epoch 85 | loss: 0.04553 | train_rmsle: 0.00253 | train_mae: 0.15113 | train_rmse: 0.20032 | train_mse: 0.04013 | valid_rmsle: 0.0034  | valid_mae: 0.18654 | valid_rmse: 0.2409  | valid_mse: 0.05803 |  0:02:20s\n",
      "epoch 86 | loss: 0.04421 | train_rmsle: 0.00249 | train_mae: 0.15033 | train_rmse: 0.19937 | train_mse: 0.03975 | valid_rmsle: 0.00346 | valid_mae: 0.18794 | valid_rmse: 0.24266 | valid_mse: 0.05888 |  0:02:21s\n",
      "epoch 87 | loss: 0.04391 | train_rmsle: 0.0024  | train_mae: 0.14682 | train_rmse: 0.19509 | train_mse: 0.03806 | valid_rmsle: 0.00336 | valid_mae: 0.18474 | valid_rmse: 0.23948 | valid_mse: 0.05735 |  0:02:23s\n",
      "epoch 88 | loss: 0.0433  | train_rmsle: 0.00258 | train_mae: 0.15588 | train_rmse: 0.20422 | train_mse: 0.04171 | valid_rmsle: 0.00347 | valid_mae: 0.19262 | valid_rmse: 0.24434 | valid_mse: 0.0597  |  0:02:24s\n",
      "epoch 89 | loss: 0.04316 | train_rmsle: 0.00224 | train_mae: 0.14603 | train_rmse: 0.19204 | train_mse: 0.03688 | valid_rmsle: 0.0032  | valid_mae: 0.18528 | valid_rmse: 0.23657 | valid_mse: 0.05596 |  0:02:26s\n",
      "epoch 90 | loss: 0.04234 | train_rmsle: 0.0023  | train_mae: 0.14678 | train_rmse: 0.19381 | train_mse: 0.03756 | valid_rmsle: 0.00315 | valid_mae: 0.18138 | valid_rmse: 0.235   | valid_mse: 0.05522 |  0:02:27s\n",
      "epoch 91 | loss: 0.04173 | train_rmsle: 0.00232 | train_mae: 0.14543 | train_rmse: 0.19347 | train_mse: 0.03743 | valid_rmsle: 0.00322 | valid_mae: 0.18359 | valid_rmse: 0.23764 | valid_mse: 0.05647 |  0:02:29s\n",
      "epoch 92 | loss: 0.04211 | train_rmsle: 0.0024  | train_mae: 0.15346 | train_rmse: 0.20245 | train_mse: 0.04099 | valid_rmsle: 0.00336 | valid_mae: 0.18904 | valid_rmse: 0.24559 | valid_mse: 0.06031 |  0:02:30s\n",
      "epoch 93 | loss: 0.04089 | train_rmsle: 0.00217 | train_mae: 0.14309 | train_rmse: 0.18948 | train_mse: 0.0359  | valid_rmsle: 0.00305 | valid_mae: 0.17779 | valid_rmse: 0.23119 | valid_mse: 0.05345 |  0:02:31s\n",
      "epoch 94 | loss: 0.04008 | train_rmsle: 0.00211 | train_mae: 0.14366 | train_rmse: 0.18843 | train_mse: 0.03551 | valid_rmsle: 0.00293 | valid_mae: 0.17564 | valid_rmse: 0.22667 | valid_mse: 0.05138 |  0:02:33s\n",
      "epoch 95 | loss: 0.03879 | train_rmsle: 0.0021  | train_mae: 0.14516 | train_rmse: 0.18968 | train_mse: 0.03598 | valid_rmsle: 0.00297 | valid_mae: 0.17962 | valid_rmse: 0.22927 | valid_mse: 0.05256 |  0:02:35s\n",
      "epoch 96 | loss: 0.0382  | train_rmsle: 0.00186 | train_mae: 0.13196 | train_rmse: 0.17633 | train_mse: 0.03109 | valid_rmsle: 0.0027  | valid_mae: 0.16602 | valid_rmse: 0.21805 | valid_mse: 0.04754 |  0:02:36s\n",
      "epoch 97 | loss: 0.03583 | train_rmsle: 0.00188 | train_mae: 0.13217 | train_rmse: 0.1759  | train_mse: 0.03094 | valid_rmsle: 0.00271 | valid_mae: 0.16755 | valid_rmse: 0.2184  | valid_mse: 0.0477  |  0:02:38s\n",
      "epoch 98 | loss: 0.03686 | train_rmsle: 0.00191 | train_mae: 0.13225 | train_rmse: 0.17598 | train_mse: 0.03097 | valid_rmsle: 0.00276 | valid_mae: 0.16927 | valid_rmse: 0.22004 | valid_mse: 0.04842 |  0:02:40s\n",
      "epoch 99 | loss: 0.03507 | train_rmsle: 0.00174 | train_mae: 0.12641 | train_rmse: 0.16962 | train_mse: 0.02877 | valid_rmsle: 0.00257 | valid_mae: 0.1628  | valid_rmse: 0.21322 | valid_mse: 0.04546 |  0:02:41s\n",
      "epoch 100| loss: 0.03457 | train_rmsle: 0.00165 | train_mae: 0.12362 | train_rmse: 0.16584 | train_mse: 0.0275  | valid_rmsle: 0.00253 | valid_mae: 0.16106 | valid_rmse: 0.21235 | valid_mse: 0.04509 |  0:02:43s\n",
      "epoch 101| loss: 0.03332 | train_rmsle: 0.00162 | train_mae: 0.12321 | train_rmse: 0.16507 | train_mse: 0.02725 | valid_rmsle: 0.00251 | valid_mae: 0.16108 | valid_rmse: 0.21248 | valid_mse: 0.04515 |  0:02:45s\n",
      "epoch 102| loss: 0.03374 | train_rmsle: 0.00164 | train_mae: 0.12586 | train_rmse: 0.16719 | train_mse: 0.02795 | valid_rmsle: 0.00244 | valid_mae: 0.15996 | valid_rmse: 0.20982 | valid_mse: 0.04402 |  0:02:46s\n",
      "epoch 103| loss: 0.03491 | train_rmsle: 0.00189 | train_mae: 0.1367  | train_rmse: 0.18159 | train_mse: 0.03297 | valid_rmsle: 0.0027  | valid_mae: 0.16967 | valid_rmse: 0.22318 | valid_mse: 0.04981 |  0:02:48s\n",
      "epoch 104| loss: 0.03516 | train_rmsle: 0.00156 | train_mae: 0.12062 | train_rmse: 0.16275 | train_mse: 0.02649 | valid_rmsle: 0.00234 | valid_mae: 0.15703 | valid_rmse: 0.20609 | valid_mse: 0.04247 |  0:02:50s\n",
      "epoch 105| loss: 0.03258 | train_rmsle: 0.00157 | train_mae: 0.1238  | train_rmse: 0.16487 | train_mse: 0.02718 | valid_rmsle: 0.00243 | valid_mae: 0.16143 | valid_rmse: 0.21076 | valid_mse: 0.04442 |  0:02:51s\n",
      "epoch 106| loss: 0.03176 | train_rmsle: 0.00152 | train_mae: 0.12062 | train_rmse: 0.16173 | train_mse: 0.02616 | valid_rmsle: 0.00236 | valid_mae: 0.15784 | valid_rmse: 0.20799 | valid_mse: 0.04326 |  0:02:53s\n",
      "epoch 107| loss: 0.03182 | train_rmsle: 0.00166 | train_mae: 0.12925 | train_rmse: 0.17083 | train_mse: 0.02918 | valid_rmsle: 0.00232 | valid_mae: 0.16009 | valid_rmse: 0.20634 | valid_mse: 0.04258 |  0:02:55s\n",
      "epoch 108| loss: 0.03043 | train_rmsle: 0.00147 | train_mae: 0.11882 | train_rmse: 0.15943 | train_mse: 0.02542 | valid_rmsle: 0.00216 | valid_mae: 0.15289 | valid_rmse: 0.1987  | valid_mse: 0.03948 |  0:02:56s\n",
      "epoch 109| loss: 0.03113 | train_rmsle: 0.00148 | train_mae: 0.11871 | train_rmse: 0.15816 | train_mse: 0.02501 | valid_rmsle: 0.00227 | valid_mae: 0.15512 | valid_rmse: 0.20207 | valid_mse: 0.04083 |  0:02:58s\n",
      "epoch 110| loss: 0.03071 | train_rmsle: 0.00136 | train_mae: 0.1123  | train_rmse: 0.15254 | train_mse: 0.02327 | valid_rmsle: 0.00219 | valid_mae: 0.15217 | valid_rmse: 0.20026 | valid_mse: 0.0401  |  0:03:00s\n",
      "epoch 111| loss: 0.02976 | train_rmsle: 0.0014  | train_mae: 0.11532 | train_rmse: 0.15529 | train_mse: 0.02412 | valid_rmsle: 0.00215 | valid_mae: 0.15255 | valid_rmse: 0.19847 | valid_mse: 0.03939 |  0:03:02s\n",
      "epoch 112| loss: 0.02924 | train_rmsle: 0.00158 | train_mae: 0.1279  | train_rmse: 0.16738 | train_mse: 0.02802 | valid_rmsle: 0.00232 | valid_mae: 0.16059 | valid_rmse: 0.20712 | valid_mse: 0.0429  |  0:03:03s\n",
      "epoch 113| loss: 0.02943 | train_rmsle: 0.00134 | train_mae: 0.11498 | train_rmse: 0.15343 | train_mse: 0.02354 | valid_rmsle: 0.00216 | valid_mae: 0.15294 | valid_rmse: 0.19956 | valid_mse: 0.03983 |  0:03:05s\n",
      "epoch 114| loss: 0.02932 | train_rmsle: 0.00148 | train_mae: 0.11806 | train_rmse: 0.15752 | train_mse: 0.02481 | valid_rmsle: 0.00236 | valid_mae: 0.15666 | valid_rmse: 0.2067  | valid_mse: 0.04272 |  0:03:07s\n",
      "epoch 115| loss: 0.03202 | train_rmsle: 0.00143 | train_mae: 0.12025 | train_rmse: 0.16039 | train_mse: 0.02573 | valid_rmsle: 0.00221 | valid_mae: 0.15595 | valid_rmse: 0.20331 | valid_mse: 0.04134 |  0:03:08s\n",
      "epoch 116| loss: 0.02963 | train_rmsle: 0.00128 | train_mae: 0.11102 | train_rmse: 0.14959 | train_mse: 0.02238 | valid_rmsle: 0.00206 | valid_mae: 0.14669 | valid_rmse: 0.1956  | valid_mse: 0.03826 |  0:03:10s\n",
      "epoch 117| loss: 0.02888 | train_rmsle: 0.00127 | train_mae: 0.11112 | train_rmse: 0.15042 | train_mse: 0.02263 | valid_rmsle: 0.00205 | valid_mae: 0.1488  | valid_rmse: 0.19497 | valid_mse: 0.03801 |  0:03:11s\n",
      "epoch 118| loss: 0.02728 | train_rmsle: 0.00117 | train_mae: 0.10521 | train_rmse: 0.14318 | train_mse: 0.0205  | valid_rmsle: 0.00204 | valid_mae: 0.14695 | valid_rmse: 0.19528 | valid_mse: 0.03814 |  0:03:13s\n",
      "epoch 119| loss: 0.02601 | train_rmsle: 0.00132 | train_mae: 0.11374 | train_rmse: 0.1515  | train_mse: 0.02295 | valid_rmsle: 0.00214 | valid_mae: 0.1505  | valid_rmse: 0.20009 | valid_mse: 0.04004 |  0:03:15s\n",
      "epoch 120| loss: 0.02724 | train_rmsle: 0.00124 | train_mae: 0.10892 | train_rmse: 0.14655 | train_mse: 0.02148 | valid_rmsle: 0.00206 | valid_mae: 0.14782 | valid_rmse: 0.19511 | valid_mse: 0.03807 |  0:03:16s\n",
      "epoch 121| loss: 0.02615 | train_rmsle: 0.00127 | train_mae: 0.11288 | train_rmse: 0.15135 | train_mse: 0.02291 | valid_rmsle: 0.00205 | valid_mae: 0.1486  | valid_rmse: 0.19599 | valid_mse: 0.03841 |  0:03:18s\n",
      "epoch 122| loss: 0.02674 | train_rmsle: 0.00125 | train_mae: 0.10964 | train_rmse: 0.1468  | train_mse: 0.02155 | valid_rmsle: 0.00193 | valid_mae: 0.14449 | valid_rmse: 0.18712 | valid_mse: 0.03501 |  0:03:19s\n",
      "epoch 123| loss: 0.02601 | train_rmsle: 0.00123 | train_mae: 0.1096  | train_rmse: 0.14769 | train_mse: 0.02181 | valid_rmsle: 0.00193 | valid_mae: 0.14455 | valid_rmse: 0.18848 | valid_mse: 0.03552 |  0:03:20s\n",
      "epoch 124| loss: 0.02418 | train_rmsle: 0.00123 | train_mae: 0.10649 | train_rmse: 0.14164 | train_mse: 0.02006 | valid_rmsle: 0.00195 | valid_mae: 0.14275 | valid_rmse: 0.18659 | valid_mse: 0.03482 |  0:03:22s\n",
      "epoch 125| loss: 0.02531 | train_rmsle: 0.00105 | train_mae: 0.1024  | train_rmse: 0.13804 | train_mse: 0.01905 | valid_rmsle: 0.00177 | valid_mae: 0.13794 | valid_rmse: 0.1816  | valid_mse: 0.03298 |  0:03:23s\n",
      "epoch 126| loss: 0.02328 | train_rmsle: 0.00142 | train_mae: 0.1161  | train_rmse: 0.14996 | train_mse: 0.02249 | valid_rmsle: 0.0022  | valid_mae: 0.1511  | valid_rmse: 0.19463 | valid_mse: 0.03788 |  0:03:25s\n",
      "epoch 127| loss: 0.0234  | train_rmsle: 0.00111 | train_mae: 0.10689 | train_rmse: 0.1445  | train_mse: 0.02088 | valid_rmsle: 0.00185 | valid_mae: 0.14138 | valid_rmse: 0.18707 | valid_mse: 0.035   |  0:03:26s\n",
      "epoch 128| loss: 0.02513 | train_rmsle: 0.0013  | train_mae: 0.11384 | train_rmse: 0.14541 | train_mse: 0.02114 | valid_rmsle: 0.00204 | valid_mae: 0.14565 | valid_rmse: 0.18975 | valid_mse: 0.03601 |  0:03:28s\n",
      "epoch 129| loss: 0.02256 | train_rmsle: 0.00092 | train_mae: 0.09455 | train_rmse: 0.12811 | train_mse: 0.01641 | valid_rmsle: 0.00171 | valid_mae: 0.13275 | valid_rmse: 0.17849 | valid_mse: 0.03186 |  0:03:29s\n",
      "epoch 130| loss: 0.0222  | train_rmsle: 0.00083 | train_mae: 0.09059 | train_rmse: 0.12349 | train_mse: 0.01525 | valid_rmsle: 0.00166 | valid_mae: 0.12955 | valid_rmse: 0.17618 | valid_mse: 0.03104 |  0:03:31s\n",
      "epoch 131| loss: 0.02102 | train_rmsle: 0.00081 | train_mae: 0.08958 | train_rmse: 0.12079 | train_mse: 0.01459 | valid_rmsle: 0.00161 | valid_mae: 0.12737 | valid_rmse: 0.1728  | valid_mse: 0.02986 |  0:03:33s\n",
      "epoch 132| loss: 0.02198 | train_rmsle: 0.00084 | train_mae: 0.09156 | train_rmse: 0.12306 | train_mse: 0.01514 | valid_rmsle: 0.00153 | valid_mae: 0.12504 | valid_rmse: 0.16905 | valid_mse: 0.02858 |  0:03:35s\n",
      "epoch 133| loss: 0.02039 | train_rmsle: 0.00084 | train_mae: 0.09387 | train_rmse: 0.12421 | train_mse: 0.01543 | valid_rmsle: 0.00158 | valid_mae: 0.12737 | valid_rmse: 0.17226 | valid_mse: 0.02967 |  0:03:36s\n",
      "epoch 134| loss: 0.01981 | train_rmsle: 0.00074 | train_mae: 0.08582 | train_rmse: 0.11639 | train_mse: 0.01355 | valid_rmsle: 0.0015  | valid_mae: 0.12218 | valid_rmse: 0.16762 | valid_mse: 0.0281  |  0:03:38s\n",
      "epoch 135| loss: 0.02048 | train_rmsle: 0.00078 | train_mae: 0.08949 | train_rmse: 0.11824 | train_mse: 0.01398 | valid_rmsle: 0.00153 | valid_mae: 0.12428 | valid_rmse: 0.16873 | valid_mse: 0.02847 |  0:03:40s\n",
      "epoch 136| loss: 0.01989 | train_rmsle: 0.00071 | train_mae: 0.08422 | train_rmse: 0.11411 | train_mse: 0.01302 | valid_rmsle: 0.00141 | valid_mae: 0.11897 | valid_rmse: 0.1627  | valid_mse: 0.02647 |  0:03:41s\n",
      "epoch 137| loss: 0.01869 | train_rmsle: 0.00101 | train_mae: 0.10566 | train_rmse: 0.13443 | train_mse: 0.01807 | valid_rmsle: 0.00168 | valid_mae: 0.13313 | valid_rmse: 0.17615 | valid_mse: 0.03103 |  0:03:43s\n",
      "epoch 138| loss: 0.01806 | train_rmsle: 0.00067 | train_mae: 0.08123 | train_rmse: 0.11063 | train_mse: 0.01224 | valid_rmsle: 0.00136 | valid_mae: 0.11646 | valid_rmse: 0.15955 | valid_mse: 0.02546 |  0:03:44s\n",
      "epoch 139| loss: 0.01785 | train_rmsle: 0.00066 | train_mae: 0.0804  | train_rmse: 0.10974 | train_mse: 0.01204 | valid_rmsle: 0.00132 | valid_mae: 0.11572 | valid_rmse: 0.15715 | valid_mse: 0.0247  |  0:03:46s\n",
      "epoch 140| loss: 0.0181  | train_rmsle: 0.00077 | train_mae: 0.08789 | train_rmse: 0.11737 | train_mse: 0.01378 | valid_rmsle: 0.00143 | valid_mae: 0.12141 | valid_rmse: 0.1638  | valid_mse: 0.02683 |  0:03:47s\n",
      "epoch 141| loss: 0.0181  | train_rmsle: 0.00113 | train_mae: 0.09323 | train_rmse: 0.13139 | train_mse: 0.01726 | valid_rmsle: 0.00202 | valid_mae: 0.12839 | valid_rmse: 0.18287 | valid_mse: 0.03344 |  0:03:48s\n",
      "epoch 142| loss: 0.01721 | train_rmsle: 0.00083 | train_mae: 0.08887 | train_rmse: 0.11743 | train_mse: 0.01379 | valid_rmsle: 0.00157 | valid_mae: 0.12356 | valid_rmse: 0.16744 | valid_mse: 0.02804 |  0:03:50s\n",
      "epoch 143| loss: 0.01794 | train_rmsle: 0.00063 | train_mae: 0.07961 | train_rmse: 0.10837 | train_mse: 0.01174 | valid_rmsle: 0.00128 | valid_mae: 0.11387 | valid_rmse: 0.15481 | valid_mse: 0.02397 |  0:03:51s\n",
      "epoch 144| loss: 0.0178  | train_rmsle: 0.0007  | train_mae: 0.08347 | train_rmse: 0.11143 | train_mse: 0.01242 | valid_rmsle: 0.00135 | valid_mae: 0.11737 | valid_rmse: 0.15781 | valid_mse: 0.0249  |  0:03:53s\n",
      "epoch 145| loss: 0.01707 | train_rmsle: 0.00091 | train_mae: 0.08454 | train_rmse: 0.12297 | train_mse: 0.01512 | valid_rmsle: 0.00131 | valid_mae: 0.11385 | valid_rmse: 0.15607 | valid_mse: 0.02436 |  0:03:55s\n",
      "epoch 146| loss: 0.01604 | train_rmsle: 0.00056 | train_mae: 0.074   | train_rmse: 0.10186 | train_mse: 0.01038 | valid_rmsle: 0.00119 | valid_mae: 0.10878 | valid_rmse: 0.15023 | valid_mse: 0.02257 |  0:03:56s\n",
      "epoch 147| loss: 0.0177  | train_rmsle: 0.00053 | train_mae: 0.07104 | train_rmse: 0.09813 | train_mse: 0.00963 | valid_rmsle: 0.00115 | valid_mae: 0.10806 | valid_rmse: 0.14774 | valid_mse: 0.02183 |  0:03:58s\n",
      "epoch 148| loss: 0.0157  | train_rmsle: 0.00072 | train_mae: 0.08605 | train_rmse: 0.11254 | train_mse: 0.01266 | valid_rmsle: 0.00134 | valid_mae: 0.11735 | valid_rmse: 0.1571  | valid_mse: 0.02468 |  0:04:00s\n",
      "epoch 149| loss: 0.01564 | train_rmsle: 0.00082 | train_mae: 0.09727 | train_rmse: 0.12233 | train_mse: 0.01496 | valid_rmsle: 0.00143 | valid_mae: 0.12619 | valid_rmse: 0.16341 | valid_mse: 0.0267  |  0:04:01s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 147 and best_valid_mse = 0.02183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.022916702590764233 RMSE: 0.15138263635821722 R2: 0.8985565878618665 MAE: 0.10926680744976741\n",
      "=====================================\n",
      "[8/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.41126 | train_rmsle: 0.22451 | train_mae: 1.58922 | train_rmse: 1.66063 | train_mse: 2.75769 | valid_rmsle: 0.22542 | valid_mae: 1.59455 | valid_rmse: 1.66499 | valid_mse: 2.77219 |  0:00:01s\n",
      "epoch 1  | loss: 1.36441 | train_rmsle: 0.11745 | train_mae: 1.20246 | train_rmse: 1.28758 | train_mse: 1.65787 | valid_rmsle: 0.11776 | valid_mae: 1.20507 | valid_rmse: 1.29057 | valid_mse: 1.66558 |  0:00:03s\n",
      "epoch 2  | loss: 0.44066 | train_rmsle: 0.04683 | train_mae: 0.77922 | train_rmse: 0.87272 | train_mse: 0.76165 | valid_rmsle: 0.04683 | valid_mae: 0.77955 | valid_rmse: 0.87504 | valid_mse: 0.76569 |  0:00:05s\n",
      "epoch 3  | loss: 0.28356 | train_rmsle: 0.0478  | train_mae: 0.78705 | train_rmse: 0.88059 | train_mse: 0.77544 | valid_rmsle: 0.04781 | valid_mae: 0.7873  | valid_rmse: 0.88299 | valid_mse: 0.77967 |  0:00:06s\n",
      "epoch 4  | loss: 0.25629 | train_rmsle: 0.03395 | train_mae: 0.66253 | train_rmse: 0.75523 | train_mse: 0.57037 | valid_rmsle: 0.03384 | valid_mae: 0.6616  | valid_rmse: 0.75694 | valid_mse: 0.57296 |  0:00:08s\n",
      "epoch 5  | loss: 0.24272 | train_rmsle: 0.02662 | train_mae: 0.58335 | train_rmse: 0.67398 | train_mse: 0.45425 | valid_rmsle: 0.02638 | valid_mae: 0.58323 | valid_rmse: 0.67454 | valid_mse: 0.455   |  0:00:10s\n",
      "epoch 6  | loss: 0.23751 | train_rmsle: 0.01834 | train_mae: 0.47103 | train_rmse: 0.55857 | train_mse: 0.312   | valid_rmsle: 0.01796 | valid_mae: 0.47255 | valid_rmse: 0.55762 | valid_mse: 0.31094 |  0:00:12s\n",
      "epoch 7  | loss: 0.23428 | train_rmsle: 0.01919 | train_mae: 0.48458 | train_rmse: 0.57229 | train_mse: 0.32751 | valid_rmsle: 0.01882 | valid_mae: 0.48578 | valid_rmse: 0.57142 | valid_mse: 0.32652 |  0:00:13s\n",
      "epoch 8  | loss: 0.22362 | train_rmsle: 0.01696 | train_mae: 0.44789 | train_rmse: 0.53511 | train_mse: 0.28634 | valid_rmsle: 0.01657 | valid_mae: 0.44959 | valid_rmse: 0.53394 | valid_mse: 0.2851  |  0:00:15s\n",
      "epoch 9  | loss: 0.21654 | train_rmsle: 0.01421 | train_mae: 0.39191 | train_rmse: 0.48247 | train_mse: 0.23278 | valid_rmsle: 0.0137  | valid_mae: 0.39216 | valid_rmse: 0.47924 | valid_mse: 0.22967 |  0:00:17s\n",
      "epoch 10 | loss: 0.20475 | train_rmsle: 0.01323 | train_mae: 0.37904 | train_rmse: 0.46659 | train_mse: 0.2177  | valid_rmsle: 0.01266 | valid_mae: 0.37605 | valid_rmse: 0.46155 | valid_mse: 0.21303 |  0:00:18s\n",
      "epoch 11 | loss: 0.19394 | train_rmsle: 0.01114 | train_mae: 0.34095 | train_rmse: 0.42525 | train_mse: 0.18083 | valid_rmsle: 0.01056 | valid_mae: 0.33769 | valid_rmse: 0.41881 | valid_mse: 0.17541 |  0:00:20s\n",
      "epoch 12 | loss: 0.18006 | train_rmsle: 0.00905 | train_mae: 0.2994  | train_rmse: 0.38071 | train_mse: 0.14494 | valid_rmsle: 0.00822 | valid_mae: 0.28964 | valid_rmse: 0.36716 | valid_mse: 0.1348  |  0:00:22s\n",
      "epoch 13 | loss: 0.16872 | train_rmsle: 0.00802 | train_mae: 0.27838 | train_rmse: 0.35647 | train_mse: 0.12707 | valid_rmsle: 0.00721 | valid_mae: 0.26675 | valid_rmse: 0.3416  | valid_mse: 0.11669 |  0:00:24s\n",
      "epoch 14 | loss: 0.15586 | train_rmsle: 0.00804 | train_mae: 0.27492 | train_rmse: 0.35383 | train_mse: 0.12519 | valid_rmsle: 0.00733 | valid_mae: 0.26475 | valid_rmse: 0.34067 | valid_mse: 0.11606 |  0:00:25s\n",
      "epoch 15 | loss: 0.14583 | train_rmsle: 0.00709 | train_mae: 0.25788 | train_rmse: 0.33269 | train_mse: 0.11068 | valid_rmsle: 0.00636 | valid_mae: 0.24563 | valid_rmse: 0.31788 | valid_mse: 0.10104 |  0:00:27s\n",
      "epoch 16 | loss: 0.13755 | train_rmsle: 0.00733 | train_mae: 0.26757 | train_rmse: 0.34015 | train_mse: 0.1157  | valid_rmsle: 0.00664 | valid_mae: 0.25625 | valid_rmse: 0.3268  | valid_mse: 0.1068  |  0:00:29s\n",
      "epoch 17 | loss: 0.12759 | train_rmsle: 0.0075  | train_mae: 0.27144 | train_rmse: 0.34413 | train_mse: 0.11843 | valid_rmsle: 0.00683 | valid_mae: 0.26124 | valid_rmse: 0.33123 | valid_mse: 0.10971 |  0:00:30s\n",
      "epoch 18 | loss: 0.12263 | train_rmsle: 0.00705 | train_mae: 0.25837 | train_rmse: 0.33158 | train_mse: 0.10995 | valid_rmsle: 0.00632 | valid_mae: 0.24593 | valid_rmse: 0.31677 | valid_mse: 0.10034 |  0:00:32s\n",
      "epoch 19 | loss: 0.12099 | train_rmsle: 0.00668 | train_mae: 0.24689 | train_rmse: 0.32082 | train_mse: 0.10293 | valid_rmsle: 0.00598 | valid_mae: 0.23352 | valid_rmse: 0.30597 | valid_mse: 0.09362 |  0:00:34s\n",
      "epoch 20 | loss: 0.11696 | train_rmsle: 0.00705 | train_mae: 0.259   | train_rmse: 0.33207 | train_mse: 0.11027 | valid_rmsle: 0.00641 | valid_mae: 0.24811 | valid_rmse: 0.31886 | valid_mse: 0.10167 |  0:00:35s\n",
      "epoch 21 | loss: 0.11287 | train_rmsle: 0.00666 | train_mae: 0.24952 | train_rmse: 0.32174 | train_mse: 0.10352 | valid_rmsle: 0.00603 | valid_mae: 0.23773 | valid_rmse: 0.30841 | valid_mse: 0.09511 |  0:00:37s\n",
      "epoch 22 | loss: 0.11005 | train_rmsle: 0.00656 | train_mae: 0.2463  | train_rmse: 0.31838 | train_mse: 0.10137 | valid_rmsle: 0.00592 | valid_mae: 0.23609 | valid_rmse: 0.30534 | valid_mse: 0.09323 |  0:00:39s\n",
      "epoch 23 | loss: 0.1094  | train_rmsle: 0.00648 | train_mae: 0.24456 | train_rmse: 0.31663 | train_mse: 0.10025 | valid_rmsle: 0.006   | valid_mae: 0.23699 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:00:41s\n",
      "epoch 24 | loss: 0.10859 | train_rmsle: 0.00648 | train_mae: 0.24412 | train_rmse: 0.3167  | train_mse: 0.1003  | valid_rmsle: 0.00595 | valid_mae: 0.23648 | valid_rmse: 0.30634 | valid_mse: 0.09384 |  0:00:42s\n",
      "epoch 25 | loss: 0.10458 | train_rmsle: 0.00648 | train_mae: 0.24638 | train_rmse: 0.31769 | train_mse: 0.10093 | valid_rmsle: 0.00598 | valid_mae: 0.23923 | valid_rmse: 0.30774 | valid_mse: 0.0947  |  0:00:44s\n",
      "epoch 26 | loss: 0.10121 | train_rmsle: 0.00635 | train_mae: 0.24174 | train_rmse: 0.31351 | train_mse: 0.09829 | valid_rmsle: 0.00586 | valid_mae: 0.23453 | valid_rmse: 0.30398 | valid_mse: 0.0924  |  0:00:46s\n",
      "epoch 27 | loss: 0.10049 | train_rmsle: 0.00625 | train_mae: 0.23896 | train_rmse: 0.31074 | train_mse: 0.09656 | valid_rmsle: 0.00579 | valid_mae: 0.23261 | valid_rmse: 0.30238 | valid_mse: 0.09144 |  0:00:47s\n",
      "epoch 28 | loss: 0.09903 | train_rmsle: 0.00625 | train_mae: 0.24157 | train_rmse: 0.31196 | train_mse: 0.09732 | valid_rmsle: 0.00589 | valid_mae: 0.23889 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:00:49s\n",
      "epoch 29 | loss: 0.09648 | train_rmsle: 0.00628 | train_mae: 0.24443 | train_rmse: 0.31373 | train_mse: 0.09843 | valid_rmsle: 0.00595 | valid_mae: 0.24189 | valid_rmse: 0.30868 | valid_mse: 0.09528 |  0:00:51s\n",
      "epoch 30 | loss: 0.09613 | train_rmsle: 0.00599 | train_mae: 0.23312 | train_rmse: 0.30413 | train_mse: 0.0925  | valid_rmsle: 0.00573 | valid_mae: 0.23418 | valid_rmse: 0.30186 | valid_mse: 0.09112 |  0:00:52s\n",
      "epoch 31 | loss: 0.09398 | train_rmsle: 0.006   | train_mae: 0.23578 | train_rmse: 0.30566 | train_mse: 0.09343 | valid_rmsle: 0.00575 | valid_mae: 0.23682 | valid_rmse: 0.3038  | valid_mse: 0.09229 |  0:00:54s\n",
      "epoch 32 | loss: 0.09328 | train_rmsle: 0.00587 | train_mae: 0.23018 | train_rmse: 0.30086 | train_mse: 0.09052 | valid_rmsle: 0.00559 | valid_mae: 0.23255 | valid_rmse: 0.29911 | valid_mse: 0.08947 |  0:00:56s\n",
      "epoch 33 | loss: 0.09289 | train_rmsle: 0.0058  | train_mae: 0.22792 | train_rmse: 0.29882 | train_mse: 0.0893  | valid_rmsle: 0.0056  | valid_mae: 0.22933 | valid_rmse: 0.29909 | valid_mse: 0.08945 |  0:00:57s\n",
      "epoch 34 | loss: 0.09356 | train_rmsle: 0.00575 | train_mae: 0.22408 | train_rmse: 0.29618 | train_mse: 0.08772 | valid_rmsle: 0.0055  | valid_mae: 0.22554 | valid_rmse: 0.29515 | valid_mse: 0.08711 |  0:00:59s\n",
      "epoch 35 | loss: 0.09019 | train_rmsle: 0.00566 | train_mae: 0.22418 | train_rmse: 0.29447 | train_mse: 0.08671 | valid_rmsle: 0.00547 | valid_mae: 0.22724 | valid_rmse: 0.29563 | valid_mse: 0.0874  |  0:01:01s\n",
      "epoch 36 | loss: 0.08969 | train_rmsle: 0.00582 | train_mae: 0.23374 | train_rmse: 0.30157 | train_mse: 0.09094 | valid_rmsle: 0.00565 | valid_mae: 0.23661 | valid_rmse: 0.30269 | valid_mse: 0.09162 |  0:01:02s\n",
      "epoch 37 | loss: 0.08878 | train_rmsle: 0.00589 | train_mae: 0.22515 | train_rmse: 0.29959 | train_mse: 0.08975 | valid_rmsle: 0.00569 | valid_mae: 0.22891 | valid_rmse: 0.30076 | valid_mse: 0.09046 |  0:01:04s\n",
      "epoch 38 | loss: 0.09122 | train_rmsle: 0.00564 | train_mae: 0.22997 | train_rmse: 0.29677 | train_mse: 0.08807 | valid_rmsle: 0.00553 | valid_mae: 0.23425 | valid_rmse: 0.29909 | valid_mse: 0.08946 |  0:01:06s\n",
      "epoch 39 | loss: 0.08675 | train_rmsle: 0.0054  | train_mae: 0.21735 | train_rmse: 0.28662 | train_mse: 0.08215 | valid_rmsle: 0.00531 | valid_mae: 0.22307 | valid_rmse: 0.29024 | valid_mse: 0.08424 |  0:01:07s\n",
      "epoch 40 | loss: 0.08523 | train_rmsle: 0.0054  | train_mae: 0.22024 | train_rmse: 0.28804 | train_mse: 0.08297 | valid_rmsle: 0.00532 | valid_mae: 0.2254  | valid_rmse: 0.29166 | valid_mse: 0.08507 |  0:01:09s\n",
      "epoch 41 | loss: 0.08505 | train_rmsle: 0.00531 | train_mae: 0.21728 | train_rmse: 0.28493 | train_mse: 0.08119 | valid_rmsle: 0.00523 | valid_mae: 0.22239 | valid_rmse: 0.28844 | valid_mse: 0.0832  |  0:01:10s\n",
      "epoch 42 | loss: 0.08382 | train_rmsle: 0.00537 | train_mae: 0.22248 | train_rmse: 0.28891 | train_mse: 0.08347 | valid_rmsle: 0.00525 | valid_mae: 0.22663 | valid_rmse: 0.29081 | valid_mse: 0.08457 |  0:01:11s\n",
      "epoch 43 | loss: 0.08247 | train_rmsle: 0.00515 | train_mae: 0.21188 | train_rmse: 0.27988 | train_mse: 0.07834 | valid_rmsle: 0.00515 | valid_mae: 0.21871 | valid_rmse: 0.28598 | valid_mse: 0.08178 |  0:01:13s\n",
      "epoch 44 | loss: 0.08373 | train_rmsle: 0.00531 | train_mae: 0.21304 | train_rmse: 0.28292 | train_mse: 0.08004 | valid_rmsle: 0.00534 | valid_mae: 0.22161 | valid_rmse: 0.29017 | valid_mse: 0.0842  |  0:01:14s\n",
      "epoch 45 | loss: 0.08177 | train_rmsle: 0.00537 | train_mae: 0.22605 | train_rmse: 0.2901  | train_mse: 0.08416 | valid_rmsle: 0.00541 | valid_mae: 0.23394 | valid_rmse: 0.29654 | valid_mse: 0.08793 |  0:01:15s\n",
      "epoch 46 | loss: 0.07971 | train_rmsle: 0.00518 | train_mae: 0.21021 | train_rmse: 0.27954 | train_mse: 0.07814 | valid_rmsle: 0.00528 | valid_mae: 0.21996 | valid_rmse: 0.28876 | valid_mse: 0.08338 |  0:01:16s\n",
      "epoch 47 | loss: 0.07961 | train_rmsle: 0.00507 | train_mae: 0.21587 | train_rmse: 0.28001 | train_mse: 0.07841 | valid_rmsle: 0.00523 | valid_mae: 0.22682 | valid_rmse: 0.29035 | valid_mse: 0.0843  |  0:01:18s\n",
      "epoch 48 | loss: 0.07978 | train_rmsle: 0.00491 | train_mae: 0.20649 | train_rmse: 0.27294 | train_mse: 0.07449 | valid_rmsle: 0.0051  | valid_mae: 0.21795 | valid_rmse: 0.28469 | valid_mse: 0.08105 |  0:01:19s\n",
      "epoch 49 | loss: 0.07923 | train_rmsle: 0.00487 | train_mae: 0.20587 | train_rmse: 0.27193 | train_mse: 0.07395 | valid_rmsle: 0.00506 | valid_mae: 0.21829 | valid_rmse: 0.2838  | valid_mse: 0.08054 |  0:01:20s\n",
      "epoch 50 | loss: 0.07797 | train_rmsle: 0.00485 | train_mae: 0.20643 | train_rmse: 0.27184 | train_mse: 0.0739  | valid_rmsle: 0.00506 | valid_mae: 0.2181  | valid_rmse: 0.28406 | valid_mse: 0.08069 |  0:01:22s\n",
      "epoch 51 | loss: 0.0765  | train_rmsle: 0.00498 | train_mae: 0.21474 | train_rmse: 0.27737 | train_mse: 0.07694 | valid_rmsle: 0.00521 | valid_mae: 0.22526 | valid_rmse: 0.28924 | valid_mse: 0.08366 |  0:01:23s\n",
      "epoch 52 | loss: 0.07529 | train_rmsle: 0.00482 | train_mae: 0.20729 | train_rmse: 0.27108 | train_mse: 0.07348 | valid_rmsle: 0.0051  | valid_mae: 0.22012 | valid_rmse: 0.28478 | valid_mse: 0.0811  |  0:01:25s\n",
      "epoch 53 | loss: 0.07689 | train_rmsle: 0.0049  | train_mae: 0.21337 | train_rmse: 0.27539 | train_mse: 0.07584 | valid_rmsle: 0.00514 | valid_mae: 0.22581 | valid_rmse: 0.28772 | valid_mse: 0.08278 |  0:01:26s\n",
      "epoch 54 | loss: 0.07901 | train_rmsle: 0.00469 | train_mae: 0.20299 | train_rmse: 0.26658 | train_mse: 0.07107 | valid_rmsle: 0.00499 | valid_mae: 0.21609 | valid_rmse: 0.28173 | valid_mse: 0.07937 |  0:01:28s\n",
      "epoch 55 | loss: 0.07481 | train_rmsle: 0.00466 | train_mae: 0.20316 | train_rmse: 0.26597 | train_mse: 0.07074 | valid_rmsle: 0.00496 | valid_mae: 0.21676 | valid_rmse: 0.28096 | valid_mse: 0.07894 |  0:01:30s\n",
      "epoch 56 | loss: 0.07273 | train_rmsle: 0.00474 | train_mae: 0.20872 | train_rmse: 0.2701  | train_mse: 0.07295 | valid_rmsle: 0.00507 | valid_mae: 0.22378 | valid_rmse: 0.28553 | valid_mse: 0.08153 |  0:01:32s\n",
      "epoch 57 | loss: 0.07349 | train_rmsle: 0.00456 | train_mae: 0.19941 | train_rmse: 0.26263 | train_mse: 0.06897 | valid_rmsle: 0.00488 | valid_mae: 0.21378 | valid_rmse: 0.2785  | valid_mse: 0.07756 |  0:01:33s\n",
      "epoch 58 | loss: 0.07119 | train_rmsle: 0.00451 | train_mae: 0.19991 | train_rmse: 0.26194 | train_mse: 0.06861 | valid_rmsle: 0.00491 | valid_mae: 0.21694 | valid_rmse: 0.2798  | valid_mse: 0.07829 |  0:01:35s\n",
      "epoch 59 | loss: 0.07296 | train_rmsle: 0.00465 | train_mae: 0.20838 | train_rmse: 0.26831 | train_mse: 0.07199 | valid_rmsle: 0.00506 | valid_mae: 0.22486 | valid_rmse: 0.28534 | valid_mse: 0.08142 |  0:01:37s\n",
      "epoch 60 | loss: 0.07131 | train_rmsle: 0.00441 | train_mae: 0.19686 | train_rmse: 0.25864 | train_mse: 0.06689 | valid_rmsle: 0.00473 | valid_mae: 0.21281 | valid_rmse: 0.2745  | valid_mse: 0.07535 |  0:01:38s\n",
      "epoch 61 | loss: 0.07101 | train_rmsle: 0.00454 | train_mae: 0.20612 | train_rmse: 0.26559 | train_mse: 0.07054 | valid_rmsle: 0.00491 | valid_mae: 0.22181 | valid_rmse: 0.28143 | valid_mse: 0.0792  |  0:01:40s\n",
      "epoch 62 | loss: 0.0695  | train_rmsle: 0.0043  | train_mae: 0.192   | train_rmse: 0.25455 | train_mse: 0.06479 | valid_rmsle: 0.00467 | valid_mae: 0.20902 | valid_rmse: 0.27219 | valid_mse: 0.07409 |  0:01:42s\n",
      "epoch 63 | loss: 0.06827 | train_rmsle: 0.0043  | train_mae: 0.19532 | train_rmse: 0.25597 | train_mse: 0.06552 | valid_rmsle: 0.00467 | valid_mae: 0.21349 | valid_rmse: 0.27388 | valid_mse: 0.07501 |  0:01:43s\n",
      "epoch 64 | loss: 0.06707 | train_rmsle: 0.00429 | train_mae: 0.1979  | train_rmse: 0.25665 | train_mse: 0.06587 | valid_rmsle: 0.00475 | valid_mae: 0.21683 | valid_rmse: 0.27692 | valid_mse: 0.07669 |  0:01:45s\n",
      "epoch 65 | loss: 0.06695 | train_rmsle: 0.00413 | train_mae: 0.19046 | train_rmse: 0.25045 | train_mse: 0.06273 | valid_rmsle: 0.00462 | valid_mae: 0.21185 | valid_rmse: 0.27191 | valid_mse: 0.07394 |  0:01:47s\n",
      "epoch 66 | loss: 0.06594 | train_rmsle: 0.00412 | train_mae: 0.19132 | train_rmse: 0.25054 | train_mse: 0.06277 | valid_rmsle: 0.00464 | valid_mae: 0.21331 | valid_rmse: 0.27321 | valid_mse: 0.07464 |  0:01:49s\n",
      "epoch 67 | loss: 0.06542 | train_rmsle: 0.00426 | train_mae: 0.18846 | train_rmse: 0.25334 | train_mse: 0.06418 | valid_rmsle: 0.0047  | valid_mae: 0.21081 | valid_rmse: 0.27497 | valid_mse: 0.07561 |  0:01:50s\n",
      "epoch 68 | loss: 0.06683 | train_rmsle: 0.00421 | train_mae: 0.19667 | train_rmse: 0.25492 | train_mse: 0.06498 | valid_rmsle: 0.00471 | valid_mae: 0.21915 | valid_rmse: 0.27689 | valid_mse: 0.07667 |  0:01:52s\n",
      "epoch 69 | loss: 0.06234 | train_rmsle: 0.0039  | train_mae: 0.18388 | train_rmse: 0.24309 | train_mse: 0.05909 | valid_rmsle: 0.0046  | valid_mae: 0.2118  | valid_rmse: 0.27225 | valid_mse: 0.07412 |  0:01:54s\n",
      "epoch 70 | loss: 0.06212 | train_rmsle: 0.00386 | train_mae: 0.18313 | train_rmse: 0.24234 | train_mse: 0.05873 | valid_rmsle: 0.00459 | valid_mae: 0.2115  | valid_rmse: 0.27231 | valid_mse: 0.07415 |  0:01:56s\n",
      "epoch 71 | loss: 0.06204 | train_rmsle: 0.00421 | train_mae: 0.19998 | train_rmse: 0.25614 | train_mse: 0.06561 | valid_rmsle: 0.00491 | valid_mae: 0.22531 | valid_rmse: 0.28276 | valid_mse: 0.07995 |  0:01:57s\n",
      "epoch 72 | loss: 0.06589 | train_rmsle: 0.00394 | train_mae: 0.17909 | train_rmse: 0.24221 | train_mse: 0.05867 | valid_rmsle: 0.00446 | valid_mae: 0.2046  | valid_rmse: 0.26686 | valid_mse: 0.07122 |  0:01:59s\n",
      "epoch 73 | loss: 0.06185 | train_rmsle: 0.00369 | train_mae: 0.18109 | train_rmse: 0.23799 | train_mse: 0.05664 | valid_rmsle: 0.00431 | valid_mae: 0.20874 | valid_rmse: 0.26428 | valid_mse: 0.06985 |  0:02:01s\n",
      "epoch 74 | loss: 0.05853 | train_rmsle: 0.00351 | train_mae: 0.17266 | train_rmse: 0.23059 | train_mse: 0.05317 | valid_rmsle: 0.00421 | valid_mae: 0.20281 | valid_rmse: 0.26141 | valid_mse: 0.06833 |  0:02:02s\n",
      "epoch 75 | loss: 0.05865 | train_rmsle: 0.00344 | train_mae: 0.17    | train_rmse: 0.22824 | train_mse: 0.05209 | valid_rmsle: 0.00413 | valid_mae: 0.20053 | valid_rmse: 0.25885 | valid_mse: 0.06701 |  0:02:04s\n",
      "epoch 76 | loss: 0.05623 | train_rmsle: 0.00339 | train_mae: 0.1714  | train_rmse: 0.22804 | train_mse: 0.052   | valid_rmsle: 0.00397 | valid_mae: 0.19941 | valid_rmse: 0.25493 | valid_mse: 0.06499 |  0:02:06s\n",
      "epoch 77 | loss: 0.05598 | train_rmsle: 0.00337 | train_mae: 0.17431 | train_rmse: 0.22952 | train_mse: 0.05268 | valid_rmsle: 0.004   | valid_mae: 0.20248 | valid_rmse: 0.25753 | valid_mse: 0.06632 |  0:02:07s\n",
      "epoch 78 | loss: 0.05459 | train_rmsle: 0.00329 | train_mae: 0.1685  | train_rmse: 0.22492 | train_mse: 0.05059 | valid_rmsle: 0.004   | valid_mae: 0.1984  | valid_rmse: 0.25633 | valid_mse: 0.0657  |  0:02:09s\n",
      "epoch 79 | loss: 0.0535  | train_rmsle: 0.00312 | train_mae: 0.16414 | train_rmse: 0.21931 | train_mse: 0.0481  | valid_rmsle: 0.00381 | valid_mae: 0.19434 | valid_rmse: 0.25089 | valid_mse: 0.06294 |  0:02:11s\n",
      "epoch 80 | loss: 0.05065 | train_rmsle: 0.00297 | train_mae: 0.16039 | train_rmse: 0.21439 | train_mse: 0.04596 | valid_rmsle: 0.00378 | valid_mae: 0.19324 | valid_rmse: 0.25002 | valid_mse: 0.06251 |  0:02:12s\n",
      "epoch 81 | loss: 0.0517  | train_rmsle: 0.00297 | train_mae: 0.15957 | train_rmse: 0.21335 | train_mse: 0.04552 | valid_rmsle: 0.00375 | valid_mae: 0.19151 | valid_rmse: 0.24896 | valid_mse: 0.06198 |  0:02:14s\n",
      "epoch 82 | loss: 0.0501  | train_rmsle: 0.00302 | train_mae: 0.16867 | train_rmse: 0.21944 | train_mse: 0.04815 | valid_rmsle: 0.00382 | valid_mae: 0.19954 | valid_rmse: 0.25355 | valid_mse: 0.06429 |  0:02:16s\n",
      "epoch 83 | loss: 0.05231 | train_rmsle: 0.0028  | train_mae: 0.15538 | train_rmse: 0.20852 | train_mse: 0.04348 | valid_rmsle: 0.00361 | valid_mae: 0.18862 | valid_rmse: 0.24594 | valid_mse: 0.06049 |  0:02:18s\n",
      "epoch 84 | loss: 0.04694 | train_rmsle: 0.00261 | train_mae: 0.15383 | train_rmse: 0.20339 | train_mse: 0.04137 | valid_rmsle: 0.00348 | valid_mae: 0.18933 | valid_rmse: 0.24345 | valid_mse: 0.05927 |  0:02:19s\n",
      "epoch 85 | loss: 0.04553 | train_rmsle: 0.00253 | train_mae: 0.15113 | train_rmse: 0.20032 | train_mse: 0.04013 | valid_rmsle: 0.0034  | valid_mae: 0.18654 | valid_rmse: 0.2409  | valid_mse: 0.05803 |  0:02:21s\n",
      "epoch 86 | loss: 0.04421 | train_rmsle: 0.00249 | train_mae: 0.15033 | train_rmse: 0.19937 | train_mse: 0.03975 | valid_rmsle: 0.00346 | valid_mae: 0.18794 | valid_rmse: 0.24266 | valid_mse: 0.05888 |  0:02:23s\n",
      "epoch 87 | loss: 0.04391 | train_rmsle: 0.0024  | train_mae: 0.14682 | train_rmse: 0.19509 | train_mse: 0.03806 | valid_rmsle: 0.00336 | valid_mae: 0.18474 | valid_rmse: 0.23948 | valid_mse: 0.05735 |  0:02:24s\n",
      "epoch 88 | loss: 0.0433  | train_rmsle: 0.00258 | train_mae: 0.15588 | train_rmse: 0.20422 | train_mse: 0.04171 | valid_rmsle: 0.00347 | valid_mae: 0.19262 | valid_rmse: 0.24434 | valid_mse: 0.0597  |  0:02:26s\n",
      "epoch 89 | loss: 0.04316 | train_rmsle: 0.00224 | train_mae: 0.14603 | train_rmse: 0.19204 | train_mse: 0.03688 | valid_rmsle: 0.0032  | valid_mae: 0.18528 | valid_rmse: 0.23657 | valid_mse: 0.05596 |  0:02:28s\n",
      "epoch 90 | loss: 0.04234 | train_rmsle: 0.0023  | train_mae: 0.14678 | train_rmse: 0.19381 | train_mse: 0.03756 | valid_rmsle: 0.00315 | valid_mae: 0.18138 | valid_rmse: 0.235   | valid_mse: 0.05522 |  0:02:29s\n",
      "epoch 91 | loss: 0.04173 | train_rmsle: 0.00232 | train_mae: 0.14543 | train_rmse: 0.19347 | train_mse: 0.03743 | valid_rmsle: 0.00322 | valid_mae: 0.18359 | valid_rmse: 0.23764 | valid_mse: 0.05647 |  0:02:31s\n",
      "epoch 92 | loss: 0.04211 | train_rmsle: 0.0024  | train_mae: 0.15346 | train_rmse: 0.20245 | train_mse: 0.04099 | valid_rmsle: 0.00336 | valid_mae: 0.18904 | valid_rmse: 0.24559 | valid_mse: 0.06031 |  0:02:33s\n",
      "epoch 93 | loss: 0.04089 | train_rmsle: 0.00217 | train_mae: 0.14309 | train_rmse: 0.18948 | train_mse: 0.0359  | valid_rmsle: 0.00305 | valid_mae: 0.17779 | valid_rmse: 0.23119 | valid_mse: 0.05345 |  0:02:34s\n",
      "epoch 94 | loss: 0.04008 | train_rmsle: 0.00211 | train_mae: 0.14366 | train_rmse: 0.18843 | train_mse: 0.03551 | valid_rmsle: 0.00293 | valid_mae: 0.17564 | valid_rmse: 0.22667 | valid_mse: 0.05138 |  0:02:36s\n",
      "epoch 95 | loss: 0.03879 | train_rmsle: 0.0021  | train_mae: 0.14516 | train_rmse: 0.18968 | train_mse: 0.03598 | valid_rmsle: 0.00297 | valid_mae: 0.17962 | valid_rmse: 0.22927 | valid_mse: 0.05256 |  0:02:38s\n",
      "epoch 96 | loss: 0.0382  | train_rmsle: 0.00186 | train_mae: 0.13196 | train_rmse: 0.17633 | train_mse: 0.03109 | valid_rmsle: 0.0027  | valid_mae: 0.16602 | valid_rmse: 0.21805 | valid_mse: 0.04754 |  0:02:39s\n",
      "epoch 97 | loss: 0.03583 | train_rmsle: 0.00188 | train_mae: 0.13217 | train_rmse: 0.1759  | train_mse: 0.03094 | valid_rmsle: 0.00271 | valid_mae: 0.16755 | valid_rmse: 0.2184  | valid_mse: 0.0477  |  0:02:41s\n",
      "epoch 98 | loss: 0.03686 | train_rmsle: 0.00191 | train_mae: 0.13225 | train_rmse: 0.17598 | train_mse: 0.03097 | valid_rmsle: 0.00276 | valid_mae: 0.16927 | valid_rmse: 0.22004 | valid_mse: 0.04842 |  0:02:43s\n",
      "epoch 99 | loss: 0.03507 | train_rmsle: 0.00174 | train_mae: 0.12641 | train_rmse: 0.16962 | train_mse: 0.02877 | valid_rmsle: 0.00257 | valid_mae: 0.1628  | valid_rmse: 0.21322 | valid_mse: 0.04546 |  0:02:44s\n",
      "epoch 100| loss: 0.03457 | train_rmsle: 0.00165 | train_mae: 0.12362 | train_rmse: 0.16584 | train_mse: 0.0275  | valid_rmsle: 0.00253 | valid_mae: 0.16106 | valid_rmse: 0.21235 | valid_mse: 0.04509 |  0:02:46s\n",
      "epoch 101| loss: 0.03332 | train_rmsle: 0.00162 | train_mae: 0.12321 | train_rmse: 0.16507 | train_mse: 0.02725 | valid_rmsle: 0.00251 | valid_mae: 0.16108 | valid_rmse: 0.21248 | valid_mse: 0.04515 |  0:02:48s\n",
      "epoch 102| loss: 0.03374 | train_rmsle: 0.00164 | train_mae: 0.12586 | train_rmse: 0.16719 | train_mse: 0.02795 | valid_rmsle: 0.00244 | valid_mae: 0.15996 | valid_rmse: 0.20982 | valid_mse: 0.04402 |  0:02:50s\n",
      "epoch 103| loss: 0.03491 | train_rmsle: 0.00189 | train_mae: 0.1367  | train_rmse: 0.18159 | train_mse: 0.03297 | valid_rmsle: 0.0027  | valid_mae: 0.16967 | valid_rmse: 0.22318 | valid_mse: 0.04981 |  0:02:51s\n",
      "epoch 104| loss: 0.03516 | train_rmsle: 0.00156 | train_mae: 0.12062 | train_rmse: 0.16275 | train_mse: 0.02649 | valid_rmsle: 0.00234 | valid_mae: 0.15703 | valid_rmse: 0.20609 | valid_mse: 0.04247 |  0:02:53s\n",
      "epoch 105| loss: 0.03258 | train_rmsle: 0.00157 | train_mae: 0.1238  | train_rmse: 0.16487 | train_mse: 0.02718 | valid_rmsle: 0.00243 | valid_mae: 0.16143 | valid_rmse: 0.21076 | valid_mse: 0.04442 |  0:02:54s\n",
      "epoch 106| loss: 0.03176 | train_rmsle: 0.00152 | train_mae: 0.12062 | train_rmse: 0.16173 | train_mse: 0.02616 | valid_rmsle: 0.00236 | valid_mae: 0.15784 | valid_rmse: 0.20799 | valid_mse: 0.04326 |  0:02:56s\n",
      "epoch 107| loss: 0.03182 | train_rmsle: 0.00166 | train_mae: 0.12925 | train_rmse: 0.17083 | train_mse: 0.02918 | valid_rmsle: 0.00232 | valid_mae: 0.16009 | valid_rmse: 0.20634 | valid_mse: 0.04258 |  0:02:58s\n",
      "epoch 108| loss: 0.03043 | train_rmsle: 0.00147 | train_mae: 0.11882 | train_rmse: 0.15943 | train_mse: 0.02542 | valid_rmsle: 0.00216 | valid_mae: 0.15289 | valid_rmse: 0.1987  | valid_mse: 0.03948 |  0:03:00s\n",
      "epoch 109| loss: 0.03113 | train_rmsle: 0.00148 | train_mae: 0.11871 | train_rmse: 0.15816 | train_mse: 0.02501 | valid_rmsle: 0.00227 | valid_mae: 0.15512 | valid_rmse: 0.20207 | valid_mse: 0.04083 |  0:03:01s\n",
      "epoch 110| loss: 0.03071 | train_rmsle: 0.00136 | train_mae: 0.1123  | train_rmse: 0.15254 | train_mse: 0.02327 | valid_rmsle: 0.00219 | valid_mae: 0.15217 | valid_rmse: 0.20026 | valid_mse: 0.0401  |  0:03:03s\n",
      "epoch 111| loss: 0.02976 | train_rmsle: 0.0014  | train_mae: 0.11532 | train_rmse: 0.15529 | train_mse: 0.02412 | valid_rmsle: 0.00215 | valid_mae: 0.15255 | valid_rmse: 0.19847 | valid_mse: 0.03939 |  0:03:05s\n",
      "epoch 112| loss: 0.02924 | train_rmsle: 0.00158 | train_mae: 0.1279  | train_rmse: 0.16738 | train_mse: 0.02802 | valid_rmsle: 0.00232 | valid_mae: 0.16059 | valid_rmse: 0.20712 | valid_mse: 0.0429  |  0:03:06s\n",
      "epoch 113| loss: 0.02943 | train_rmsle: 0.00134 | train_mae: 0.11498 | train_rmse: 0.15343 | train_mse: 0.02354 | valid_rmsle: 0.00216 | valid_mae: 0.15294 | valid_rmse: 0.19956 | valid_mse: 0.03983 |  0:03:08s\n",
      "epoch 114| loss: 0.02932 | train_rmsle: 0.00148 | train_mae: 0.11806 | train_rmse: 0.15752 | train_mse: 0.02481 | valid_rmsle: 0.00236 | valid_mae: 0.15666 | valid_rmse: 0.2067  | valid_mse: 0.04272 |  0:03:10s\n",
      "epoch 115| loss: 0.03202 | train_rmsle: 0.00143 | train_mae: 0.12025 | train_rmse: 0.16039 | train_mse: 0.02573 | valid_rmsle: 0.00221 | valid_mae: 0.15595 | valid_rmse: 0.20331 | valid_mse: 0.04134 |  0:03:11s\n",
      "epoch 116| loss: 0.02963 | train_rmsle: 0.00128 | train_mae: 0.11102 | train_rmse: 0.14959 | train_mse: 0.02238 | valid_rmsle: 0.00206 | valid_mae: 0.14669 | valid_rmse: 0.1956  | valid_mse: 0.03826 |  0:03:13s\n",
      "epoch 117| loss: 0.02888 | train_rmsle: 0.00127 | train_mae: 0.11112 | train_rmse: 0.15042 | train_mse: 0.02263 | valid_rmsle: 0.00205 | valid_mae: 0.1488  | valid_rmse: 0.19497 | valid_mse: 0.03801 |  0:03:15s\n",
      "epoch 118| loss: 0.02728 | train_rmsle: 0.00117 | train_mae: 0.10521 | train_rmse: 0.14318 | train_mse: 0.0205  | valid_rmsle: 0.00204 | valid_mae: 0.14695 | valid_rmse: 0.19528 | valid_mse: 0.03814 |  0:03:16s\n",
      "epoch 119| loss: 0.02601 | train_rmsle: 0.00132 | train_mae: 0.11374 | train_rmse: 0.1515  | train_mse: 0.02295 | valid_rmsle: 0.00214 | valid_mae: 0.1505  | valid_rmse: 0.20009 | valid_mse: 0.04004 |  0:03:18s\n",
      "epoch 120| loss: 0.02724 | train_rmsle: 0.00124 | train_mae: 0.10892 | train_rmse: 0.14655 | train_mse: 0.02148 | valid_rmsle: 0.00206 | valid_mae: 0.14782 | valid_rmse: 0.19511 | valid_mse: 0.03807 |  0:03:20s\n",
      "epoch 121| loss: 0.02615 | train_rmsle: 0.00127 | train_mae: 0.11288 | train_rmse: 0.15135 | train_mse: 0.02291 | valid_rmsle: 0.00205 | valid_mae: 0.1486  | valid_rmse: 0.19599 | valid_mse: 0.03841 |  0:03:21s\n",
      "epoch 122| loss: 0.02674 | train_rmsle: 0.00125 | train_mae: 0.10964 | train_rmse: 0.1468  | train_mse: 0.02155 | valid_rmsle: 0.00193 | valid_mae: 0.14449 | valid_rmse: 0.18712 | valid_mse: 0.03501 |  0:03:23s\n",
      "epoch 123| loss: 0.02601 | train_rmsle: 0.00123 | train_mae: 0.1096  | train_rmse: 0.14769 | train_mse: 0.02181 | valid_rmsle: 0.00193 | valid_mae: 0.14455 | valid_rmse: 0.18848 | valid_mse: 0.03552 |  0:03:25s\n",
      "epoch 124| loss: 0.02418 | train_rmsle: 0.00123 | train_mae: 0.10649 | train_rmse: 0.14164 | train_mse: 0.02006 | valid_rmsle: 0.00195 | valid_mae: 0.14275 | valid_rmse: 0.18659 | valid_mse: 0.03482 |  0:03:26s\n",
      "epoch 125| loss: 0.02531 | train_rmsle: 0.00105 | train_mae: 0.1024  | train_rmse: 0.13804 | train_mse: 0.01905 | valid_rmsle: 0.00177 | valid_mae: 0.13794 | valid_rmse: 0.1816  | valid_mse: 0.03298 |  0:03:28s\n",
      "epoch 126| loss: 0.02328 | train_rmsle: 0.00142 | train_mae: 0.1161  | train_rmse: 0.14996 | train_mse: 0.02249 | valid_rmsle: 0.0022  | valid_mae: 0.1511  | valid_rmse: 0.19463 | valid_mse: 0.03788 |  0:03:30s\n",
      "epoch 127| loss: 0.0234  | train_rmsle: 0.00111 | train_mae: 0.10689 | train_rmse: 0.1445  | train_mse: 0.02088 | valid_rmsle: 0.00185 | valid_mae: 0.14138 | valid_rmse: 0.18707 | valid_mse: 0.035   |  0:03:31s\n",
      "epoch 128| loss: 0.02513 | train_rmsle: 0.0013  | train_mae: 0.11384 | train_rmse: 0.14541 | train_mse: 0.02114 | valid_rmsle: 0.00204 | valid_mae: 0.14565 | valid_rmse: 0.18975 | valid_mse: 0.03601 |  0:03:33s\n",
      "epoch 129| loss: 0.02256 | train_rmsle: 0.00092 | train_mae: 0.09455 | train_rmse: 0.12811 | train_mse: 0.01641 | valid_rmsle: 0.00171 | valid_mae: 0.13275 | valid_rmse: 0.17849 | valid_mse: 0.03186 |  0:03:35s\n",
      "epoch 130| loss: 0.0222  | train_rmsle: 0.00083 | train_mae: 0.09059 | train_rmse: 0.12349 | train_mse: 0.01525 | valid_rmsle: 0.00166 | valid_mae: 0.12955 | valid_rmse: 0.17618 | valid_mse: 0.03104 |  0:03:36s\n",
      "epoch 131| loss: 0.02102 | train_rmsle: 0.00081 | train_mae: 0.08958 | train_rmse: 0.12079 | train_mse: 0.01459 | valid_rmsle: 0.00161 | valid_mae: 0.12737 | valid_rmse: 0.1728  | valid_mse: 0.02986 |  0:03:37s\n",
      "epoch 132| loss: 0.02198 | train_rmsle: 0.00084 | train_mae: 0.09156 | train_rmse: 0.12306 | train_mse: 0.01514 | valid_rmsle: 0.00153 | valid_mae: 0.12504 | valid_rmse: 0.16905 | valid_mse: 0.02858 |  0:03:39s\n",
      "epoch 133| loss: 0.02039 | train_rmsle: 0.00084 | train_mae: 0.09387 | train_rmse: 0.12421 | train_mse: 0.01543 | valid_rmsle: 0.00158 | valid_mae: 0.12737 | valid_rmse: 0.17226 | valid_mse: 0.02967 |  0:03:40s\n",
      "epoch 134| loss: 0.01981 | train_rmsle: 0.00074 | train_mae: 0.08582 | train_rmse: 0.11639 | train_mse: 0.01355 | valid_rmsle: 0.0015  | valid_mae: 0.12218 | valid_rmse: 0.16762 | valid_mse: 0.0281  |  0:03:42s\n",
      "epoch 135| loss: 0.02048 | train_rmsle: 0.00078 | train_mae: 0.08949 | train_rmse: 0.11824 | train_mse: 0.01398 | valid_rmsle: 0.00153 | valid_mae: 0.12428 | valid_rmse: 0.16873 | valid_mse: 0.02847 |  0:03:43s\n",
      "epoch 136| loss: 0.01989 | train_rmsle: 0.00071 | train_mae: 0.08422 | train_rmse: 0.11411 | train_mse: 0.01302 | valid_rmsle: 0.00141 | valid_mae: 0.11897 | valid_rmse: 0.1627  | valid_mse: 0.02647 |  0:03:45s\n",
      "epoch 137| loss: 0.01869 | train_rmsle: 0.00101 | train_mae: 0.10566 | train_rmse: 0.13443 | train_mse: 0.01807 | valid_rmsle: 0.00168 | valid_mae: 0.13313 | valid_rmse: 0.17615 | valid_mse: 0.03103 |  0:03:46s\n",
      "epoch 138| loss: 0.01806 | train_rmsle: 0.00067 | train_mae: 0.08123 | train_rmse: 0.11063 | train_mse: 0.01224 | valid_rmsle: 0.00136 | valid_mae: 0.11646 | valid_rmse: 0.15955 | valid_mse: 0.02546 |  0:03:48s\n",
      "epoch 139| loss: 0.01785 | train_rmsle: 0.00066 | train_mae: 0.0804  | train_rmse: 0.10974 | train_mse: 0.01204 | valid_rmsle: 0.00132 | valid_mae: 0.11572 | valid_rmse: 0.15715 | valid_mse: 0.0247  |  0:03:49s\n",
      "epoch 140| loss: 0.0181  | train_rmsle: 0.00077 | train_mae: 0.08789 | train_rmse: 0.11737 | train_mse: 0.01378 | valid_rmsle: 0.00143 | valid_mae: 0.12141 | valid_rmse: 0.1638  | valid_mse: 0.02683 |  0:03:51s\n",
      "epoch 141| loss: 0.0181  | train_rmsle: 0.00113 | train_mae: 0.09323 | train_rmse: 0.13139 | train_mse: 0.01726 | valid_rmsle: 0.00202 | valid_mae: 0.12839 | valid_rmse: 0.18287 | valid_mse: 0.03344 |  0:03:53s\n",
      "epoch 142| loss: 0.01721 | train_rmsle: 0.00083 | train_mae: 0.08887 | train_rmse: 0.11743 | train_mse: 0.01379 | valid_rmsle: 0.00157 | valid_mae: 0.12356 | valid_rmse: 0.16744 | valid_mse: 0.02804 |  0:03:54s\n",
      "epoch 143| loss: 0.01794 | train_rmsle: 0.00063 | train_mae: 0.07961 | train_rmse: 0.10837 | train_mse: 0.01174 | valid_rmsle: 0.00128 | valid_mae: 0.11387 | valid_rmse: 0.15481 | valid_mse: 0.02397 |  0:03:56s\n",
      "epoch 144| loss: 0.0178  | train_rmsle: 0.0007  | train_mae: 0.08347 | train_rmse: 0.11143 | train_mse: 0.01242 | valid_rmsle: 0.00135 | valid_mae: 0.11737 | valid_rmse: 0.15781 | valid_mse: 0.0249  |  0:03:58s\n",
      "epoch 145| loss: 0.01707 | train_rmsle: 0.00091 | train_mae: 0.08454 | train_rmse: 0.12297 | train_mse: 0.01512 | valid_rmsle: 0.00131 | valid_mae: 0.11385 | valid_rmse: 0.15607 | valid_mse: 0.02436 |  0:04:00s\n",
      "epoch 146| loss: 0.01604 | train_rmsle: 0.00056 | train_mae: 0.074   | train_rmse: 0.10186 | train_mse: 0.01038 | valid_rmsle: 0.00119 | valid_mae: 0.10878 | valid_rmse: 0.15023 | valid_mse: 0.02257 |  0:04:01s\n",
      "epoch 147| loss: 0.0177  | train_rmsle: 0.00053 | train_mae: 0.07104 | train_rmse: 0.09813 | train_mse: 0.00963 | valid_rmsle: 0.00115 | valid_mae: 0.10806 | valid_rmse: 0.14774 | valid_mse: 0.02183 |  0:04:03s\n",
      "epoch 148| loss: 0.0157  | train_rmsle: 0.00072 | train_mae: 0.08605 | train_rmse: 0.11254 | train_mse: 0.01266 | valid_rmsle: 0.00134 | valid_mae: 0.11735 | valid_rmse: 0.1571  | valid_mse: 0.02468 |  0:04:05s\n",
      "epoch 149| loss: 0.01564 | train_rmsle: 0.00082 | train_mae: 0.09727 | train_rmse: 0.12233 | train_mse: 0.01496 | valid_rmsle: 0.00143 | valid_mae: 0.12619 | valid_rmse: 0.16341 | valid_mse: 0.0267  |  0:04:06s\n",
      "epoch 150| loss: 0.01563 | train_rmsle: 0.00054 | train_mae: 0.07247 | train_rmse: 0.09948 | train_mse: 0.0099  | valid_rmsle: 0.00114 | valid_mae: 0.10618 | valid_rmse: 0.1462  | valid_mse: 0.02138 |  0:04:08s\n",
      "epoch 151| loss: 0.01592 | train_rmsle: 0.00059 | train_mae: 0.07784 | train_rmse: 0.1042  | train_mse: 0.01086 | valid_rmsle: 0.00122 | valid_mae: 0.11115 | valid_rmse: 0.15145 | valid_mse: 0.02294 |  0:04:09s\n",
      "epoch 152| loss: 0.0151  | train_rmsle: 0.00049 | train_mae: 0.06869 | train_rmse: 0.09447 | train_mse: 0.00892 | valid_rmsle: 0.00111 | valid_mae: 0.10498 | valid_rmse: 0.14499 | valid_mse: 0.02102 |  0:04:11s\n",
      "epoch 153| loss: 0.01491 | train_rmsle: 0.00051 | train_mae: 0.06902 | train_rmse: 0.09476 | train_mse: 0.00898 | valid_rmsle: 0.00116 | valid_mae: 0.10581 | valid_rmse: 0.14661 | valid_mse: 0.02149 |  0:04:12s\n",
      "epoch 154| loss: 0.01492 | train_rmsle: 0.00056 | train_mae: 0.07363 | train_rmse: 0.09901 | train_mse: 0.0098  | valid_rmsle: 0.00126 | valid_mae: 0.11023 | valid_rmse: 0.15273 | valid_mse: 0.02333 |  0:04:14s\n",
      "epoch 155| loss: 0.01492 | train_rmsle: 0.00049 | train_mae: 0.06804 | train_rmse: 0.09418 | train_mse: 0.00887 | valid_rmsle: 0.00111 | valid_mae: 0.10281 | valid_rmse: 0.14356 | valid_mse: 0.02061 |  0:04:15s\n",
      "epoch 156| loss: 0.01465 | train_rmsle: 0.00051 | train_mae: 0.07235 | train_rmse: 0.09675 | train_mse: 0.00936 | valid_rmsle: 0.00107 | valid_mae: 0.10401 | valid_rmse: 0.14214 | valid_mse: 0.0202  |  0:04:17s\n",
      "epoch 157| loss: 0.01305 | train_rmsle: 0.00059 | train_mae: 0.07565 | train_rmse: 0.10062 | train_mse: 0.01012 | valid_rmsle: 0.00114 | valid_mae: 0.10486 | valid_rmse: 0.1431  | valid_mse: 0.02048 |  0:04:18s\n",
      "epoch 158| loss: 0.01329 | train_rmsle: 0.00049 | train_mae: 0.06738 | train_rmse: 0.09156 | train_mse: 0.00838 | valid_rmsle: 0.00111 | valid_mae: 0.10248 | valid_rmse: 0.1424  | valid_mse: 0.02028 |  0:04:20s\n",
      "epoch 159| loss: 0.01447 | train_rmsle: 0.00052 | train_mae: 0.07013 | train_rmse: 0.0942  | train_mse: 0.00887 | valid_rmsle: 0.00112 | valid_mae: 0.10361 | valid_rmse: 0.14294 | valid_mse: 0.02043 |  0:04:21s\n",
      "epoch 160| loss: 0.01358 | train_rmsle: 0.00051 | train_mae: 0.06755 | train_rmse: 0.09126 | train_mse: 0.00833 | valid_rmsle: 0.00113 | valid_mae: 0.10204 | valid_rmse: 0.1424  | valid_mse: 0.02028 |  0:04:23s\n",
      "epoch 161| loss: 0.0131  | train_rmsle: 0.00046 | train_mae: 0.06665 | train_rmse: 0.08996 | train_mse: 0.00809 | valid_rmsle: 0.00104 | valid_mae: 0.09985 | valid_rmse: 0.13894 | valid_mse: 0.0193  |  0:04:24s\n",
      "epoch 162| loss: 0.01296 | train_rmsle: 0.00065 | train_mae: 0.08456 | train_rmse: 0.10524 | train_mse: 0.01108 | valid_rmsle: 0.00119 | valid_mae: 0.11014 | valid_rmse: 0.14683 | valid_mse: 0.02156 |  0:04:26s\n",
      "epoch 163| loss: 0.0156  | train_rmsle: 0.0004  | train_mae: 0.06143 | train_rmse: 0.08447 | train_mse: 0.00714 | valid_rmsle: 0.00102 | valid_mae: 0.0964  | valid_rmse: 0.13746 | valid_mse: 0.0189  |  0:04:28s\n",
      "epoch 164| loss: 0.01337 | train_rmsle: 0.00038 | train_mae: 0.06132 | train_rmse: 0.08448 | train_mse: 0.00714 | valid_rmsle: 0.00101 | valid_mae: 0.09793 | valid_rmse: 0.1375  | valid_mse: 0.01891 |  0:04:29s\n",
      "epoch 165| loss: 0.01277 | train_rmsle: 0.00037 | train_mae: 0.06013 | train_rmse: 0.0831  | train_mse: 0.00691 | valid_rmsle: 0.00097 | valid_mae: 0.09618 | valid_rmse: 0.1347  | valid_mse: 0.01814 |  0:04:31s\n",
      "epoch 166| loss: 0.01327 | train_rmsle: 0.00042 | train_mae: 0.06436 | train_rmse: 0.08678 | train_mse: 0.00753 | valid_rmsle: 0.00103 | valid_mae: 0.09867 | valid_rmse: 0.13758 | valid_mse: 0.01893 |  0:04:33s\n",
      "epoch 167| loss: 0.01441 | train_rmsle: 0.00035 | train_mae: 0.05788 | train_rmse: 0.07976 | train_mse: 0.00636 | valid_rmsle: 0.00092 | valid_mae: 0.09362 | valid_rmse: 0.1319  | valid_mse: 0.0174  |  0:04:35s\n",
      "epoch 168| loss: 0.01182 | train_rmsle: 0.00059 | train_mae: 0.08174 | train_rmse: 0.10115 | train_mse: 0.01023 | valid_rmsle: 0.00116 | valid_mae: 0.11029 | valid_rmse: 0.14572 | valid_mse: 0.02123 |  0:04:36s\n",
      "epoch 169| loss: 0.0125  | train_rmsle: 0.0005  | train_mae: 0.07247 | train_rmse: 0.0957  | train_mse: 0.00916 | valid_rmsle: 0.00111 | valid_mae: 0.10383 | valid_rmse: 0.14366 | valid_mse: 0.02064 |  0:04:38s\n",
      "epoch 170| loss: 0.01388 | train_rmsle: 0.00049 | train_mae: 0.07048 | train_rmse: 0.0924  | train_mse: 0.00854 | valid_rmsle: 0.00103 | valid_mae: 0.09946 | valid_rmse: 0.13771 | valid_mse: 0.01896 |  0:04:40s\n",
      "epoch 171| loss: 0.01263 | train_rmsle: 0.00058 | train_mae: 0.08312 | train_rmse: 0.10341 | train_mse: 0.01069 | valid_rmsle: 0.0011  | valid_mae: 0.10919 | valid_rmse: 0.14328 | valid_mse: 0.02053 |  0:04:41s\n",
      "epoch 172| loss: 0.01361 | train_rmsle: 0.00034 | train_mae: 0.0576  | train_rmse: 0.07912 | train_mse: 0.00626 | valid_rmsle: 0.00087 | valid_mae: 0.09156 | valid_rmse: 0.12719 | valid_mse: 0.01618 |  0:04:43s\n",
      "epoch 173| loss: 0.01227 | train_rmsle: 0.00038 | train_mae: 0.06239 | train_rmse: 0.08358 | train_mse: 0.00699 | valid_rmsle: 0.00094 | valid_mae: 0.09571 | valid_rmse: 0.13323 | valid_mse: 0.01775 |  0:04:45s\n",
      "epoch 174| loss: 0.01227 | train_rmsle: 0.00032 | train_mae: 0.0568  | train_rmse: 0.07622 | train_mse: 0.00581 | valid_rmsle: 0.00091 | valid_mae: 0.09298 | valid_rmse: 0.13058 | valid_mse: 0.01705 |  0:04:46s\n",
      "epoch 175| loss: 0.01124 | train_rmsle: 0.00033 | train_mae: 0.05743 | train_rmse: 0.07775 | train_mse: 0.00605 | valid_rmsle: 0.00094 | valid_mae: 0.09348 | valid_rmse: 0.13233 | valid_mse: 0.01751 |  0:04:48s\n",
      "epoch 176| loss: 0.01188 | train_rmsle: 0.00035 | train_mae: 0.05928 | train_rmse: 0.07955 | train_mse: 0.00633 | valid_rmsle: 0.00089 | valid_mae: 0.09229 | valid_rmse: 0.12844 | valid_mse: 0.0165  |  0:04:50s\n",
      "epoch 177| loss: 0.01131 | train_rmsle: 0.00048 | train_mae: 0.07526 | train_rmse: 0.0929  | train_mse: 0.00863 | valid_rmsle: 0.00103 | valid_mae: 0.10296 | valid_rmse: 0.13763 | valid_mse: 0.01894 |  0:04:51s\n",
      "epoch 178| loss: 0.01395 | train_rmsle: 0.00032 | train_mae: 0.056   | train_rmse: 0.07697 | train_mse: 0.00592 | valid_rmsle: 0.00086 | valid_mae: 0.09064 | valid_rmse: 0.12654 | valid_mse: 0.01601 |  0:04:53s\n",
      "epoch 179| loss: 0.01132 | train_rmsle: 0.00041 | train_mae: 0.06886 | train_rmse: 0.08816 | train_mse: 0.00777 | valid_rmsle: 0.00095 | valid_mae: 0.10005 | valid_rmse: 0.13325 | valid_mse: 0.01776 |  0:04:55s\n",
      "epoch 180| loss: 0.01187 | train_rmsle: 0.00056 | train_mae: 0.07594 | train_rmse: 0.09452 | train_mse: 0.00893 | valid_rmsle: 0.00109 | valid_mae: 0.10395 | valid_rmse: 0.13763 | valid_mse: 0.01894 |  0:04:56s\n",
      "epoch 181| loss: 0.01246 | train_rmsle: 0.00054 | train_mae: 0.07353 | train_rmse: 0.09698 | train_mse: 0.0094  | valid_rmsle: 0.00106 | valid_mae: 0.10066 | valid_rmse: 0.13822 | valid_mse: 0.01911 |  0:04:58s\n",
      "epoch 182| loss: 0.01321 | train_rmsle: 0.00044 | train_mae: 0.06834 | train_rmse: 0.08982 | train_mse: 0.00807 | valid_rmsle: 0.00102 | valid_mae: 0.10031 | valid_rmse: 0.13764 | valid_mse: 0.01894 |  0:05:00s\n",
      "epoch 183| loss: 0.01201 | train_rmsle: 0.00033 | train_mae: 0.05819 | train_rmse: 0.07833 | train_mse: 0.00614 | valid_rmsle: 0.00094 | valid_mae: 0.09423 | valid_rmse: 0.13189 | valid_mse: 0.0174  |  0:05:01s\n",
      "epoch 184| loss: 0.01169 | train_rmsle: 0.0005  | train_mae: 0.07391 | train_rmse: 0.09286 | train_mse: 0.00862 | valid_rmsle: 0.00106 | valid_mae: 0.10256 | valid_rmse: 0.13825 | valid_mse: 0.01911 |  0:05:03s\n",
      "epoch 185| loss: 0.01103 | train_rmsle: 0.00044 | train_mae: 0.06507 | train_rmse: 0.0846  | train_mse: 0.00716 | valid_rmsle: 0.00105 | valid_mae: 0.09756 | valid_rmse: 0.13584 | valid_mse: 0.01845 |  0:05:05s\n",
      "epoch 186| loss: 0.0117  | train_rmsle: 0.00027 | train_mae: 0.05192 | train_rmse: 0.07044 | train_mse: 0.00496 | valid_rmsle: 0.00085 | valid_mae: 0.0888  | valid_rmse: 0.12531 | valid_mse: 0.0157  |  0:05:07s\n",
      "epoch 187| loss: 0.01023 | train_rmsle: 0.00039 | train_mae: 0.05852 | train_rmse: 0.07812 | train_mse: 0.0061  | valid_rmsle: 0.00097 | valid_mae: 0.09241 | valid_rmse: 0.12989 | valid_mse: 0.01687 |  0:05:08s\n",
      "epoch 188| loss: 0.01027 | train_rmsle: 0.00028 | train_mae: 0.05213 | train_rmse: 0.07004 | train_mse: 0.00491 | valid_rmsle: 0.00087 | valid_mae: 0.08863 | valid_rmse: 0.12627 | valid_mse: 0.01594 |  0:05:10s\n",
      "epoch 189| loss: 0.01102 | train_rmsle: 0.00047 | train_mae: 0.06497 | train_rmse: 0.08393 | train_mse: 0.00704 | valid_rmsle: 0.00102 | valid_mae: 0.09518 | valid_rmse: 0.13203 | valid_mse: 0.01743 |  0:05:12s\n",
      "epoch 190| loss: 0.01033 | train_rmsle: 0.00027 | train_mae: 0.05332 | train_rmse: 0.07052 | train_mse: 0.00497 | valid_rmsle: 0.00081 | valid_mae: 0.08738 | valid_rmse: 0.12212 | valid_mse: 0.01491 |  0:05:13s\n",
      "epoch 191| loss: 0.01067 | train_rmsle: 0.00038 | train_mae: 0.06265 | train_rmse: 0.08211 | train_mse: 0.00674 | valid_rmsle: 0.00092 | valid_mae: 0.09378 | valid_rmse: 0.12944 | valid_mse: 0.01675 |  0:05:15s\n",
      "epoch 192| loss: 0.01173 | train_rmsle: 0.00046 | train_mae: 0.06618 | train_rmse: 0.08385 | train_mse: 0.00703 | valid_rmsle: 0.00099 | valid_mae: 0.09539 | valid_rmse: 0.13067 | valid_mse: 0.01707 |  0:05:17s\n",
      "epoch 193| loss: 0.0113  | train_rmsle: 0.00045 | train_mae: 0.06817 | train_rmse: 0.08522 | train_mse: 0.00726 | valid_rmsle: 0.00102 | valid_mae: 0.09817 | valid_rmse: 0.1338  | valid_mse: 0.0179  |  0:05:18s\n",
      "epoch 194| loss: 0.01037 | train_rmsle: 0.00033 | train_mae: 0.05904 | train_rmse: 0.07601 | train_mse: 0.00578 | valid_rmsle: 0.0009  | valid_mae: 0.09199 | valid_rmse: 0.12823 | valid_mse: 0.01644 |  0:05:20s\n",
      "epoch 195| loss: 0.00982 | train_rmsle: 0.00023 | train_mae: 0.0476  | train_rmse: 0.06397 | train_mse: 0.00409 | valid_rmsle: 0.00081 | valid_mae: 0.08462 | valid_rmse: 0.12225 | valid_mse: 0.01494 |  0:05:22s\n",
      "epoch 196| loss: 0.01032 | train_rmsle: 0.00048 | train_mae: 0.07821 | train_rmse: 0.09394 | train_mse: 0.00883 | valid_rmsle: 0.00103 | valid_mae: 0.10471 | valid_rmse: 0.13795 | valid_mse: 0.01903 |  0:05:23s\n",
      "epoch 197| loss: 0.01073 | train_rmsle: 0.00047 | train_mae: 0.06951 | train_rmse: 0.08722 | train_mse: 0.00761 | valid_rmsle: 0.00102 | valid_mae: 0.09883 | valid_rmse: 0.13284 | valid_mse: 0.01765 |  0:05:25s\n",
      "epoch 198| loss: 0.00986 | train_rmsle: 0.00029 | train_mae: 0.05704 | train_rmse: 0.07351 | train_mse: 0.0054  | valid_rmsle: 0.00082 | valid_mae: 0.09067 | valid_rmse: 0.1241  | valid_mse: 0.0154  |  0:05:27s\n",
      "epoch 199| loss: 0.01055 | train_rmsle: 0.00022 | train_mae: 0.048   | train_rmse: 0.06447 | train_mse: 0.00416 | valid_rmsle: 0.00077 | valid_mae: 0.08414 | valid_rmse: 0.11924 | valid_mse: 0.01422 |  0:05:28s\n",
      "epoch 200| loss: 0.01031 | train_rmsle: 0.00035 | train_mae: 0.06555 | train_rmse: 0.08142 | train_mse: 0.00663 | valid_rmsle: 0.00089 | valid_mae: 0.09579 | valid_rmse: 0.1292  | valid_mse: 0.01669 |  0:05:30s\n",
      "epoch 201| loss: 0.00996 | train_rmsle: 0.00045 | train_mae: 0.07537 | train_rmse: 0.09198 | train_mse: 0.00846 | valid_rmsle: 0.00101 | valid_mae: 0.10174 | valid_rmse: 0.13733 | valid_mse: 0.01886 |  0:05:32s\n",
      "epoch 202| loss: 0.01101 | train_rmsle: 0.0004  | train_mae: 0.05991 | train_rmse: 0.07727 | train_mse: 0.00597 | valid_rmsle: 0.00097 | valid_mae: 0.09236 | valid_rmse: 0.12868 | valid_mse: 0.01656 |  0:05:34s\n",
      "epoch 203| loss: 0.01228 | train_rmsle: 0.00024 | train_mae: 0.04891 | train_rmse: 0.06526 | train_mse: 0.00426 | valid_rmsle: 0.00082 | valid_mae: 0.08667 | valid_rmse: 0.12304 | valid_mse: 0.01514 |  0:05:35s\n",
      "epoch 204| loss: 0.00953 | train_rmsle: 0.00029 | train_mae: 0.05665 | train_rmse: 0.07227 | train_mse: 0.00522 | valid_rmsle: 0.00085 | valid_mae: 0.09089 | valid_rmse: 0.12475 | valid_mse: 0.01556 |  0:05:37s\n",
      "epoch 205| loss: 0.01049 | train_rmsle: 0.0002  | train_mae: 0.04477 | train_rmse: 0.0596  | train_mse: 0.00355 | valid_rmsle: 0.00077 | valid_mae: 0.08384 | valid_rmse: 0.11883 | valid_mse: 0.01412 |  0:05:39s\n",
      "epoch 206| loss: 0.00974 | train_rmsle: 0.00036 | train_mae: 0.06515 | train_rmse: 0.07949 | train_mse: 0.00632 | valid_rmsle: 0.0009  | valid_mae: 0.09475 | valid_rmse: 0.12788 | valid_mse: 0.01635 |  0:05:40s\n",
      "epoch 207| loss: 0.00929 | train_rmsle: 0.00057 | train_mae: 0.08688 | train_rmse: 0.10315 | train_mse: 0.01064 | valid_rmsle: 0.00112 | valid_mae: 0.11221 | valid_rmse: 0.14445 | valid_mse: 0.02087 |  0:05:42s\n",
      "epoch 208| loss: 0.00986 | train_rmsle: 0.00094 | train_mae: 0.11113 | train_rmse: 0.12643 | train_mse: 0.01598 | valid_rmsle: 0.00148 | valid_mae: 0.13007 | valid_rmse: 0.16071 | valid_mse: 0.02583 |  0:05:44s\n",
      "epoch 209| loss: 0.01057 | train_rmsle: 0.00023 | train_mae: 0.04882 | train_rmse: 0.06478 | train_mse: 0.0042  | valid_rmsle: 0.00079 | valid_mae: 0.08685 | valid_rmse: 0.12134 | valid_mse: 0.01472 |  0:05:45s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 205 and best_valid_mse = 0.01412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01380257811330343 RMSE: 0.1174843739111863 R2: 0.938901305082132 MAE: 0.08338525869056392\n",
      "=====================================\n",
      "[9/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.14894 | train_rmsle: 0.95472 | train_mae: 2.66229 | train_rmse: 2.70621 | train_mse: 7.32358 | valid_rmsle: 0.95763 | valid_mae: 2.66884 | valid_rmse: 2.71175 | valid_mse: 7.35359 |  0:00:01s\n",
      "epoch 1  | loss: 3.52886 | train_rmsle: 0.30831 | train_mae: 1.80452 | train_rmse: 1.86792 | train_mse: 3.48912 | valid_rmsle: 0.3095  | valid_mae: 1.81071 | valid_rmse: 1.87254 | valid_mse: 3.5064  |  0:00:02s\n",
      "epoch 2  | loss: 1.55188 | train_rmsle: 0.14655 | train_mae: 1.3268  | train_rmse: 1.40682 | train_mse: 1.97916 | valid_rmsle: 0.1473  | valid_mae: 1.33179 | valid_rmse: 1.41128 | valid_mse: 1.99171 |  0:00:04s\n",
      "epoch 3  | loss: 0.70925 | train_rmsle: 0.06887 | train_mae: 0.93878 | train_rmse: 1.03125 | train_mse: 1.06347 | valid_rmsle: 0.06926 | valid_mae: 0.94229 | valid_rmse: 1.03558 | valid_mse: 1.07242 |  0:00:05s\n",
      "epoch 4  | loss: 0.40886 | train_rmsle: 0.04051 | train_mae: 0.72427 | train_rmse: 0.81814 | train_mse: 0.66935 | valid_rmsle: 0.04063 | valid_mae: 0.72518 | valid_rmse: 0.8217  | valid_mse: 0.6752  |  0:00:07s\n",
      "epoch 5  | loss: 0.31605 | train_rmsle: 0.03075 | train_mae: 0.62907 | train_rmse: 0.72144 | train_mse: 0.52048 | valid_rmsle: 0.03075 | valid_mae: 0.63021 | valid_rmse: 0.72443 | valid_mse: 0.5248  |  0:00:08s\n",
      "epoch 6  | loss: 0.27925 | train_rmsle: 0.02516 | train_mae: 0.56515 | train_rmse: 0.65604 | train_mse: 0.43038 | valid_rmsle: 0.02502 | valid_mae: 0.56658 | valid_rmse: 0.65782 | valid_mse: 0.43273 |  0:00:10s\n",
      "epoch 7  | loss: 0.26245 | train_rmsle: 0.0208  | train_mae: 0.50775 | train_rmse: 0.59675 | train_mse: 0.35611 | valid_rmsle: 0.02051 | valid_mae: 0.50884 | valid_rmse: 0.59693 | valid_mse: 0.35632 |  0:00:11s\n",
      "epoch 8  | loss: 0.25001 | train_rmsle: 0.02053 | train_mae: 0.50376 | train_rmse: 0.59302 | train_mse: 0.35167 | valid_rmsle: 0.02022 | valid_mae: 0.50437 | valid_rmse: 0.59295 | valid_mse: 0.35159 |  0:00:13s\n",
      "epoch 9  | loss: 0.24403 | train_rmsle: 0.01557 | train_mae: 0.41802 | train_rmse: 0.50829 | train_mse: 0.25836 | valid_rmsle: 0.0151  | valid_mae: 0.41995 | valid_rmse: 0.50581 | valid_mse: 0.25585 |  0:00:15s\n",
      "epoch 10 | loss: 0.23693 | train_rmsle: 0.01622 | train_mae: 0.43131 | train_rmse: 0.52082 | train_mse: 0.27125 | valid_rmsle: 0.01572 | valid_mae: 0.43165 | valid_rmse: 0.51765 | valid_mse: 0.26796 |  0:00:16s\n",
      "epoch 11 | loss: 0.23232 | train_rmsle: 0.01608 | train_mae: 0.42992 | train_rmse: 0.5195  | train_mse: 0.26988 | valid_rmsle: 0.01565 | valid_mae: 0.43023 | valid_rmse: 0.51727 | valid_mse: 0.26757 |  0:00:18s\n",
      "epoch 12 | loss: 0.22978 | train_rmsle: 0.01497 | train_mae: 0.40919 | train_rmse: 0.49919 | train_mse: 0.24919 | valid_rmsle: 0.01452 | valid_mae: 0.41056 | valid_rmse: 0.49673 | valid_mse: 0.24674 |  0:00:20s\n",
      "epoch 13 | loss: 0.22859 | train_rmsle: 0.01457 | train_mae: 0.40311 | train_rmse: 0.49235 | train_mse: 0.2424  | valid_rmsle: 0.01416 | valid_mae: 0.40409 | valid_rmse: 0.49032 | valid_mse: 0.24042 |  0:00:22s\n",
      "epoch 14 | loss: 0.22318 | train_rmsle: 0.01422 | train_mae: 0.39902 | train_rmse: 0.48732 | train_mse: 0.23748 | valid_rmsle: 0.01372 | valid_mae: 0.39836 | valid_rmse: 0.48375 | valid_mse: 0.23401 |  0:00:23s\n",
      "epoch 15 | loss: 0.21981 | train_rmsle: 0.01351 | train_mae: 0.37993 | train_rmse: 0.46962 | train_mse: 0.22055 | valid_rmsle: 0.01291 | valid_mae: 0.37937 | valid_rmse: 0.46437 | valid_mse: 0.21564 |  0:00:25s\n",
      "epoch 16 | loss: 0.21685 | train_rmsle: 0.01335 | train_mae: 0.37209 | train_rmse: 0.4645  | train_mse: 0.21576 | valid_rmsle: 0.01264 | valid_mae: 0.37031 | valid_rmse: 0.45745 | valid_mse: 0.20926 |  0:00:27s\n",
      "epoch 17 | loss: 0.21433 | train_rmsle: 0.01335 | train_mae: 0.37696 | train_rmse: 0.46798 | train_mse: 0.21901 | valid_rmsle: 0.01279 | valid_mae: 0.377   | valid_rmse: 0.46301 | valid_mse: 0.21438 |  0:00:28s\n",
      "epoch 18 | loss: 0.21253 | train_rmsle: 0.01391 | train_mae: 0.3905  | train_rmse: 0.47979 | train_mse: 0.2302  | valid_rmsle: 0.01341 | valid_mae: 0.39066 | valid_rmse: 0.47666 | valid_mse: 0.2272  |  0:00:30s\n",
      "epoch 19 | loss: 0.21107 | train_rmsle: 0.01354 | train_mae: 0.38358 | train_rmse: 0.47188 | train_mse: 0.22267 | valid_rmsle: 0.01305 | valid_mae: 0.38424 | valid_rmse: 0.46818 | valid_mse: 0.21919 |  0:00:32s\n",
      "epoch 20 | loss: 0.20883 | train_rmsle: 0.01341 | train_mae: 0.38077 | train_rmse: 0.47015 | train_mse: 0.22104 | valid_rmsle: 0.01297 | valid_mae: 0.38206 | valid_rmse: 0.46722 | valid_mse: 0.21829 |  0:00:34s\n",
      "epoch 21 | loss: 0.20597 | train_rmsle: 0.01365 | train_mae: 0.38767 | train_rmse: 0.47727 | train_mse: 0.22779 | valid_rmsle: 0.01341 | valid_mae: 0.38925 | valid_rmse: 0.47761 | valid_mse: 0.22811 |  0:00:35s\n",
      "epoch 22 | loss: 0.2075  | train_rmsle: 0.01316 | train_mae: 0.37665 | train_rmse: 0.4665  | train_mse: 0.21762 | valid_rmsle: 0.01285 | valid_mae: 0.37691 | valid_rmse: 0.46526 | valid_mse: 0.21646 |  0:00:37s\n",
      "epoch 23 | loss: 0.2035  | train_rmsle: 0.013   | train_mae: 0.37563 | train_rmse: 0.46496 | train_mse: 0.21619 | valid_rmsle: 0.01292 | valid_mae: 0.37861 | valid_rmse: 0.46814 | valid_mse: 0.21916 |  0:00:39s\n",
      "epoch 24 | loss: 0.1988  | train_rmsle: 0.01264 | train_mae: 0.36296 | train_rmse: 0.45469 | train_mse: 0.20674 | valid_rmsle: 0.01226 | valid_mae: 0.36426 | valid_rmse: 0.45303 | valid_mse: 0.20523 |  0:00:41s\n",
      "epoch 25 | loss: 0.19958 | train_rmsle: 0.01248 | train_mae: 0.35944 | train_rmse: 0.45037 | train_mse: 0.20283 | valid_rmsle: 0.01235 | valid_mae: 0.36245 | valid_rmse: 0.45296 | valid_mse: 0.20517 |  0:00:42s\n",
      "epoch 26 | loss: 0.19509 | train_rmsle: 0.01242 | train_mae: 0.3553  | train_rmse: 0.44722 | train_mse: 0.2     | valid_rmsle: 0.01246 | valid_mae: 0.36422 | valid_rmse: 0.4533  | valid_mse: 0.20548 |  0:00:44s\n",
      "epoch 27 | loss: 0.1926  | train_rmsle: 0.01217 | train_mae: 0.35139 | train_rmse: 0.44336 | train_mse: 0.19656 | valid_rmsle: 0.01213 | valid_mae: 0.35812 | valid_rmse: 0.44794 | valid_mse: 0.20065 |  0:00:46s\n",
      "epoch 28 | loss: 0.19264 | train_rmsle: 0.0119  | train_mae: 0.35583 | train_rmse: 0.44222 | train_mse: 0.19556 | valid_rmsle: 0.01232 | valid_mae: 0.36346 | valid_rmse: 0.45487 | valid_mse: 0.2069  |  0:00:47s\n",
      "epoch 29 | loss: 0.18883 | train_rmsle: 0.01174 | train_mae: 0.35272 | train_rmse: 0.43963 | train_mse: 0.19328 | valid_rmsle: 0.01224 | valid_mae: 0.36446 | valid_rmse: 0.45386 | valid_mse: 0.20599 |  0:00:49s\n",
      "epoch 30 | loss: 0.18683 | train_rmsle: 0.01153 | train_mae: 0.347   | train_rmse: 0.43462 | train_mse: 0.1889  | valid_rmsle: 0.01192 | valid_mae: 0.35739 | valid_rmse: 0.44684 | valid_mse: 0.19967 |  0:00:51s\n",
      "epoch 31 | loss: 0.18553 | train_rmsle: 0.0114  | train_mae: 0.34493 | train_rmse: 0.43126 | train_mse: 0.18598 | valid_rmsle: 0.0123  | valid_mae: 0.36448 | valid_rmse: 0.45291 | valid_mse: 0.20513 |  0:00:53s\n",
      "epoch 32 | loss: 0.18187 | train_rmsle: 0.01117 | train_mae: 0.34012 | train_rmse: 0.42788 | train_mse: 0.18308 | valid_rmsle: 0.01208 | valid_mae: 0.35911 | valid_rmse: 0.45024 | valid_mse: 0.20271 |  0:00:54s\n",
      "epoch 33 | loss: 0.17885 | train_rmsle: 0.01122 | train_mae: 0.34132 | train_rmse: 0.42914 | train_mse: 0.18416 | valid_rmsle: 0.01196 | valid_mae: 0.36055 | valid_rmse: 0.44898 | valid_mse: 0.20158 |  0:00:56s\n",
      "epoch 34 | loss: 0.17912 | train_rmsle: 0.01095 | train_mae: 0.3393  | train_rmse: 0.42427 | train_mse: 0.18001 | valid_rmsle: 0.01216 | valid_mae: 0.36174 | valid_rmse: 0.45231 | valid_mse: 0.20458 |  0:00:58s\n",
      "epoch 35 | loss: 0.17623 | train_rmsle: 0.01061 | train_mae: 0.32911 | train_rmse: 0.41526 | train_mse: 0.17244 | valid_rmsle: 0.01201 | valid_mae: 0.35523 | valid_rmse: 0.44783 | valid_mse: 0.20055 |  0:01:00s\n",
      "epoch 36 | loss: 0.17318 | train_rmsle: 0.01065 | train_mae: 0.33378 | train_rmse: 0.41807 | train_mse: 0.17478 | valid_rmsle: 0.0121  | valid_mae: 0.35764 | valid_rmse: 0.44976 | valid_mse: 0.20228 |  0:01:01s\n",
      "epoch 37 | loss: 0.17188 | train_rmsle: 0.01078 | train_mae: 0.3286  | train_rmse: 0.41717 | train_mse: 0.17403 | valid_rmsle: 0.01257 | valid_mae: 0.35801 | valid_rmse: 0.45559 | valid_mse: 0.20756 |  0:01:03s\n",
      "epoch 38 | loss: 0.17294 | train_rmsle: 0.01034 | train_mae: 0.32357 | train_rmse: 0.40896 | train_mse: 0.16724 | valid_rmsle: 0.0122  | valid_mae: 0.35586 | valid_rmse: 0.44908 | valid_mse: 0.20167 |  0:01:05s\n",
      "epoch 39 | loss: 0.16984 | train_rmsle: 0.0106  | train_mae: 0.32806 | train_rmse: 0.41408 | train_mse: 0.17146 | valid_rmsle: 0.01187 | valid_mae: 0.35102 | valid_rmse: 0.44402 | valid_mse: 0.19715 |  0:01:06s\n",
      "epoch 40 | loss: 0.1668  | train_rmsle: 0.01022 | train_mae: 0.3224  | train_rmse: 0.4075  | train_mse: 0.16605 | valid_rmsle: 0.01202 | valid_mae: 0.35449 | valid_rmse: 0.44704 | valid_mse: 0.19985 |  0:01:08s\n",
      "epoch 41 | loss: 0.16825 | train_rmsle: 0.01001 | train_mae: 0.32032 | train_rmse: 0.4046  | train_mse: 0.1637  | valid_rmsle: 0.01233 | valid_mae: 0.35823 | valid_rmse: 0.45301 | valid_mse: 0.20522 |  0:01:10s\n",
      "epoch 42 | loss: 0.16814 | train_rmsle: 0.01006 | train_mae: 0.32137 | train_rmse: 0.40506 | train_mse: 0.16407 | valid_rmsle: 0.01222 | valid_mae: 0.3562  | valid_rmse: 0.45153 | valid_mse: 0.20388 |  0:01:12s\n",
      "epoch 43 | loss: 0.16468 | train_rmsle: 0.00971 | train_mae: 0.31396 | train_rmse: 0.39839 | train_mse: 0.15871 | valid_rmsle: 0.01223 | valid_mae: 0.35348 | valid_rmse: 0.45047 | valid_mse: 0.20293 |  0:01:13s\n",
      "epoch 44 | loss: 0.16413 | train_rmsle: 0.01001 | train_mae: 0.31632 | train_rmse: 0.40267 | train_mse: 0.16214 | valid_rmsle: 0.01215 | valid_mae: 0.3523  | valid_rmse: 0.44836 | valid_mse: 0.20102 |  0:01:15s\n",
      "epoch 45 | loss: 0.165   | train_rmsle: 0.00968 | train_mae: 0.31897 | train_rmse: 0.40042 | train_mse: 0.16034 | valid_rmsle: 0.01198 | valid_mae: 0.35611 | valid_rmse: 0.4484  | valid_mse: 0.20106 |  0:01:17s\n",
      "epoch 46 | loss: 0.16109 | train_rmsle: 0.00956 | train_mae: 0.31298 | train_rmse: 0.39598 | train_mse: 0.1568  | valid_rmsle: 0.01236 | valid_mae: 0.35668 | valid_rmse: 0.45416 | valid_mse: 0.20626 |  0:01:19s\n",
      "epoch 47 | loss: 0.16132 | train_rmsle: 0.00965 | train_mae: 0.31145 | train_rmse: 0.39641 | train_mse: 0.15714 | valid_rmsle: 0.01199 | valid_mae: 0.3516  | valid_rmse: 0.44708 | valid_mse: 0.19988 |  0:01:20s\n",
      "epoch 48 | loss: 0.16133 | train_rmsle: 0.00928 | train_mae: 0.31071 | train_rmse: 0.39207 | train_mse: 0.15372 | valid_rmsle: 0.01169 | valid_mae: 0.35144 | valid_rmse: 0.44348 | valid_mse: 0.19667 |  0:01:22s\n",
      "epoch 49 | loss: 0.1579  | train_rmsle: 0.00914 | train_mae: 0.30926 | train_rmse: 0.38952 | train_mse: 0.15173 | valid_rmsle: 0.01168 | valid_mae: 0.35051 | valid_rmse: 0.44343 | valid_mse: 0.19663 |  0:01:24s\n",
      "epoch 50 | loss: 0.15586 | train_rmsle: 0.0091  | train_mae: 0.30764 | train_rmse: 0.38704 | train_mse: 0.1498  | valid_rmsle: 0.01153 | valid_mae: 0.34864 | valid_rmse: 0.44014 | valid_mse: 0.19372 |  0:01:26s\n",
      "epoch 51 | loss: 0.15493 | train_rmsle: 0.00893 | train_mae: 0.30381 | train_rmse: 0.38378 | train_mse: 0.14729 | valid_rmsle: 0.01156 | valid_mae: 0.3478  | valid_rmse: 0.44063 | valid_mse: 0.19416 |  0:01:27s\n",
      "epoch 52 | loss: 0.15413 | train_rmsle: 0.00927 | train_mae: 0.30619 | train_rmse: 0.3886  | train_mse: 0.15101 | valid_rmsle: 0.01175 | valid_mae: 0.34959 | valid_rmse: 0.44283 | valid_mse: 0.1961  |  0:01:29s\n",
      "epoch 53 | loss: 0.155   | train_rmsle: 0.00909 | train_mae: 0.30542 | train_rmse: 0.38535 | train_mse: 0.14849 | valid_rmsle: 0.01137 | valid_mae: 0.34575 | valid_rmse: 0.43647 | valid_mse: 0.19051 |  0:01:31s\n",
      "epoch 54 | loss: 0.1535  | train_rmsle: 0.00876 | train_mae: 0.29811 | train_rmse: 0.37945 | train_mse: 0.14398 | valid_rmsle: 0.01172 | valid_mae: 0.34703 | valid_rmse: 0.44217 | valid_mse: 0.19552 |  0:01:32s\n",
      "epoch 55 | loss: 0.14918 | train_rmsle: 0.00864 | train_mae: 0.29621 | train_rmse: 0.37633 | train_mse: 0.14163 | valid_rmsle: 0.01169 | valid_mae: 0.34724 | valid_rmse: 0.44261 | valid_mse: 0.1959  |  0:01:34s\n",
      "epoch 56 | loss: 0.14738 | train_rmsle: 0.0085  | train_mae: 0.29549 | train_rmse: 0.374   | train_mse: 0.13988 | valid_rmsle: 0.01201 | valid_mae: 0.35152 | valid_rmse: 0.44915 | valid_mse: 0.20173 |  0:01:36s\n",
      "epoch 57 | loss: 0.14836 | train_rmsle: 0.00845 | train_mae: 0.29151 | train_rmse: 0.3714  | train_mse: 0.13794 | valid_rmsle: 0.01224 | valid_mae: 0.35174 | valid_rmse: 0.45215 | valid_mse: 0.20444 |  0:01:37s\n",
      "epoch 58 | loss: 0.14695 | train_rmsle: 0.00841 | train_mae: 0.29357 | train_rmse: 0.37169 | train_mse: 0.13815 | valid_rmsle: 0.01203 | valid_mae: 0.35049 | valid_rmse: 0.44927 | valid_mse: 0.20185 |  0:01:39s\n",
      "epoch 59 | loss: 0.14739 | train_rmsle: 0.0084  | train_mae: 0.29145 | train_rmse: 0.37133 | train_mse: 0.13788 | valid_rmsle: 0.01182 | valid_mae: 0.34713 | valid_rmse: 0.44548 | valid_mse: 0.19845 |  0:01:40s\n",
      "epoch 60 | loss: 0.14271 | train_rmsle: 0.00875 | train_mae: 0.29875 | train_rmse: 0.37748 | train_mse: 0.14249 | valid_rmsle: 0.01191 | valid_mae: 0.35106 | valid_rmse: 0.44661 | valid_mse: 0.19946 |  0:01:41s\n",
      "epoch 61 | loss: 0.14315 | train_rmsle: 0.00813 | train_mae: 0.28721 | train_rmse: 0.36483 | train_mse: 0.1331  | valid_rmsle: 0.01153 | valid_mae: 0.3409  | valid_rmse: 0.4389  | valid_mse: 0.19264 |  0:01:43s\n",
      "epoch 62 | loss: 0.13933 | train_rmsle: 0.00785 | train_mae: 0.28362 | train_rmse: 0.35989 | train_mse: 0.12952 | valid_rmsle: 0.0113  | valid_mae: 0.33915 | valid_rmse: 0.43551 | valid_mse: 0.18967 |  0:01:44s\n",
      "epoch 63 | loss: 0.13559 | train_rmsle: 0.00781 | train_mae: 0.28237 | train_rmse: 0.35931 | train_mse: 0.12911 | valid_rmsle: 0.01121 | valid_mae: 0.34056 | valid_rmse: 0.43414 | valid_mse: 0.18848 |  0:01:45s\n",
      "epoch 64 | loss: 0.13693 | train_rmsle: 0.00785 | train_mae: 0.28276 | train_rmse: 0.36042 | train_mse: 0.1299  | valid_rmsle: 0.01125 | valid_mae: 0.33735 | valid_rmse: 0.43385 | valid_mse: 0.18823 |  0:01:46s\n",
      "epoch 65 | loss: 0.13724 | train_rmsle: 0.00773 | train_mae: 0.28159 | train_rmse: 0.35748 | train_mse: 0.12779 | valid_rmsle: 0.01087 | valid_mae: 0.33393 | valid_rmse: 0.42741 | valid_mse: 0.18268 |  0:01:47s\n",
      "epoch 66 | loss: 0.1336  | train_rmsle: 0.00765 | train_mae: 0.27922 | train_rmse: 0.35534 | train_mse: 0.12627 | valid_rmsle: 0.01056 | valid_mae: 0.32675 | valid_rmse: 0.42078 | valid_mse: 0.17705 |  0:01:49s\n",
      "epoch 67 | loss: 0.13177 | train_rmsle: 0.00751 | train_mae: 0.27476 | train_rmse: 0.35227 | train_mse: 0.1241  | valid_rmsle: 0.01112 | valid_mae: 0.33349 | valid_rmse: 0.4315  | valid_mse: 0.18619 |  0:01:50s\n",
      "epoch 68 | loss: 0.13095 | train_rmsle: 0.00731 | train_mae: 0.27261 | train_rmse: 0.34804 | train_mse: 0.12113 | valid_rmsle: 0.01078 | valid_mae: 0.32938 | valid_rmse: 0.4259  | valid_mse: 0.18139 |  0:01:52s\n",
      "epoch 69 | loss: 0.12718 | train_rmsle: 0.00743 | train_mae: 0.27074 | train_rmse: 0.34809 | train_mse: 0.12117 | valid_rmsle: 0.01072 | valid_mae: 0.3269  | valid_rmse: 0.42234 | valid_mse: 0.17837 |  0:01:53s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 66 and best_valid_mse = 0.17705\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.18902853182167811 RMSE: 0.4347741158598084 R2: 0.1632435258298961 MAE: 0.3392052504540941\n",
      "=====================================\n",
      "[10/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.14894 | train_rmsle: 0.95472 | train_mae: 2.66229 | train_rmse: 2.70621 | train_mse: 7.32358 | valid_rmsle: 0.95763 | valid_mae: 2.66884 | valid_rmse: 2.71175 | valid_mse: 7.35359 |  0:00:01s\n",
      "epoch 1  | loss: 3.52886 | train_rmsle: 0.30831 | train_mae: 1.80452 | train_rmse: 1.86792 | train_mse: 3.48912 | valid_rmsle: 0.3095  | valid_mae: 1.81071 | valid_rmse: 1.87254 | valid_mse: 3.5064  |  0:00:03s\n",
      "epoch 2  | loss: 1.55188 | train_rmsle: 0.14655 | train_mae: 1.3268  | train_rmse: 1.40682 | train_mse: 1.97916 | valid_rmsle: 0.1473  | valid_mae: 1.33179 | valid_rmse: 1.41128 | valid_mse: 1.99171 |  0:00:05s\n",
      "epoch 3  | loss: 0.70925 | train_rmsle: 0.06887 | train_mae: 0.93878 | train_rmse: 1.03125 | train_mse: 1.06347 | valid_rmsle: 0.06926 | valid_mae: 0.94229 | valid_rmse: 1.03558 | valid_mse: 1.07242 |  0:00:07s\n",
      "epoch 4  | loss: 0.40886 | train_rmsle: 0.04051 | train_mae: 0.72427 | train_rmse: 0.81814 | train_mse: 0.66935 | valid_rmsle: 0.04063 | valid_mae: 0.72518 | valid_rmse: 0.8217  | valid_mse: 0.6752  |  0:00:08s\n",
      "epoch 5  | loss: 0.31605 | train_rmsle: 0.03075 | train_mae: 0.62907 | train_rmse: 0.72144 | train_mse: 0.52048 | valid_rmsle: 0.03075 | valid_mae: 0.63021 | valid_rmse: 0.72443 | valid_mse: 0.5248  |  0:00:10s\n",
      "epoch 6  | loss: 0.27925 | train_rmsle: 0.02516 | train_mae: 0.56515 | train_rmse: 0.65604 | train_mse: 0.43038 | valid_rmsle: 0.02502 | valid_mae: 0.56658 | valid_rmse: 0.65782 | valid_mse: 0.43273 |  0:00:12s\n",
      "epoch 7  | loss: 0.26245 | train_rmsle: 0.0208  | train_mae: 0.50775 | train_rmse: 0.59675 | train_mse: 0.35611 | valid_rmsle: 0.02051 | valid_mae: 0.50884 | valid_rmse: 0.59693 | valid_mse: 0.35632 |  0:00:14s\n",
      "epoch 8  | loss: 0.25001 | train_rmsle: 0.02053 | train_mae: 0.50376 | train_rmse: 0.59302 | train_mse: 0.35167 | valid_rmsle: 0.02022 | valid_mae: 0.50437 | valid_rmse: 0.59295 | valid_mse: 0.35159 |  0:00:15s\n",
      "epoch 9  | loss: 0.24403 | train_rmsle: 0.01557 | train_mae: 0.41802 | train_rmse: 0.50829 | train_mse: 0.25836 | valid_rmsle: 0.0151  | valid_mae: 0.41995 | valid_rmse: 0.50581 | valid_mse: 0.25585 |  0:00:17s\n",
      "epoch 10 | loss: 0.23693 | train_rmsle: 0.01622 | train_mae: 0.43131 | train_rmse: 0.52082 | train_mse: 0.27125 | valid_rmsle: 0.01572 | valid_mae: 0.43165 | valid_rmse: 0.51765 | valid_mse: 0.26796 |  0:00:19s\n",
      "epoch 11 | loss: 0.23232 | train_rmsle: 0.01608 | train_mae: 0.42992 | train_rmse: 0.5195  | train_mse: 0.26988 | valid_rmsle: 0.01565 | valid_mae: 0.43023 | valid_rmse: 0.51727 | valid_mse: 0.26757 |  0:00:20s\n",
      "epoch 12 | loss: 0.22978 | train_rmsle: 0.01497 | train_mae: 0.40919 | train_rmse: 0.49919 | train_mse: 0.24919 | valid_rmsle: 0.01452 | valid_mae: 0.41056 | valid_rmse: 0.49673 | valid_mse: 0.24674 |  0:00:22s\n",
      "epoch 13 | loss: 0.22859 | train_rmsle: 0.01457 | train_mae: 0.40311 | train_rmse: 0.49235 | train_mse: 0.2424  | valid_rmsle: 0.01416 | valid_mae: 0.40409 | valid_rmse: 0.49032 | valid_mse: 0.24042 |  0:00:24s\n",
      "epoch 14 | loss: 0.22318 | train_rmsle: 0.01422 | train_mae: 0.39902 | train_rmse: 0.48732 | train_mse: 0.23748 | valid_rmsle: 0.01372 | valid_mae: 0.39836 | valid_rmse: 0.48375 | valid_mse: 0.23401 |  0:00:26s\n",
      "epoch 15 | loss: 0.21981 | train_rmsle: 0.01351 | train_mae: 0.37993 | train_rmse: 0.46962 | train_mse: 0.22055 | valid_rmsle: 0.01291 | valid_mae: 0.37937 | valid_rmse: 0.46437 | valid_mse: 0.21564 |  0:00:27s\n",
      "epoch 16 | loss: 0.21685 | train_rmsle: 0.01335 | train_mae: 0.37209 | train_rmse: 0.4645  | train_mse: 0.21576 | valid_rmsle: 0.01264 | valid_mae: 0.37031 | valid_rmse: 0.45745 | valid_mse: 0.20926 |  0:00:29s\n",
      "epoch 17 | loss: 0.21433 | train_rmsle: 0.01335 | train_mae: 0.37696 | train_rmse: 0.46798 | train_mse: 0.21901 | valid_rmsle: 0.01279 | valid_mae: 0.377   | valid_rmse: 0.46301 | valid_mse: 0.21438 |  0:00:31s\n",
      "epoch 18 | loss: 0.21253 | train_rmsle: 0.01391 | train_mae: 0.3905  | train_rmse: 0.47979 | train_mse: 0.2302  | valid_rmsle: 0.01341 | valid_mae: 0.39066 | valid_rmse: 0.47666 | valid_mse: 0.2272  |  0:00:33s\n",
      "epoch 19 | loss: 0.21107 | train_rmsle: 0.01354 | train_mae: 0.38358 | train_rmse: 0.47188 | train_mse: 0.22267 | valid_rmsle: 0.01305 | valid_mae: 0.38424 | valid_rmse: 0.46818 | valid_mse: 0.21919 |  0:00:34s\n",
      "epoch 20 | loss: 0.20883 | train_rmsle: 0.01341 | train_mae: 0.38077 | train_rmse: 0.47015 | train_mse: 0.22104 | valid_rmsle: 0.01297 | valid_mae: 0.38206 | valid_rmse: 0.46722 | valid_mse: 0.21829 |  0:00:36s\n",
      "epoch 21 | loss: 0.20597 | train_rmsle: 0.01365 | train_mae: 0.38767 | train_rmse: 0.47727 | train_mse: 0.22779 | valid_rmsle: 0.01341 | valid_mae: 0.38925 | valid_rmse: 0.47761 | valid_mse: 0.22811 |  0:00:38s\n",
      "epoch 22 | loss: 0.2075  | train_rmsle: 0.01316 | train_mae: 0.37665 | train_rmse: 0.4665  | train_mse: 0.21762 | valid_rmsle: 0.01285 | valid_mae: 0.37691 | valid_rmse: 0.46526 | valid_mse: 0.21646 |  0:00:40s\n",
      "epoch 23 | loss: 0.2035  | train_rmsle: 0.013   | train_mae: 0.37563 | train_rmse: 0.46496 | train_mse: 0.21619 | valid_rmsle: 0.01292 | valid_mae: 0.37861 | valid_rmse: 0.46814 | valid_mse: 0.21916 |  0:00:41s\n",
      "epoch 24 | loss: 0.1988  | train_rmsle: 0.01264 | train_mae: 0.36296 | train_rmse: 0.45469 | train_mse: 0.20674 | valid_rmsle: 0.01226 | valid_mae: 0.36426 | valid_rmse: 0.45303 | valid_mse: 0.20523 |  0:00:43s\n",
      "epoch 25 | loss: 0.19958 | train_rmsle: 0.01248 | train_mae: 0.35944 | train_rmse: 0.45037 | train_mse: 0.20283 | valid_rmsle: 0.01235 | valid_mae: 0.36245 | valid_rmse: 0.45296 | valid_mse: 0.20517 |  0:00:45s\n",
      "epoch 26 | loss: 0.19509 | train_rmsle: 0.01242 | train_mae: 0.3553  | train_rmse: 0.44722 | train_mse: 0.2     | valid_rmsle: 0.01246 | valid_mae: 0.36422 | valid_rmse: 0.4533  | valid_mse: 0.20548 |  0:00:47s\n",
      "epoch 27 | loss: 0.1926  | train_rmsle: 0.01217 | train_mae: 0.35139 | train_rmse: 0.44336 | train_mse: 0.19656 | valid_rmsle: 0.01213 | valid_mae: 0.35812 | valid_rmse: 0.44794 | valid_mse: 0.20065 |  0:00:48s\n",
      "epoch 28 | loss: 0.19264 | train_rmsle: 0.0119  | train_mae: 0.35583 | train_rmse: 0.44222 | train_mse: 0.19556 | valid_rmsle: 0.01232 | valid_mae: 0.36346 | valid_rmse: 0.45487 | valid_mse: 0.2069  |  0:00:50s\n",
      "epoch 29 | loss: 0.18883 | train_rmsle: 0.01174 | train_mae: 0.35272 | train_rmse: 0.43963 | train_mse: 0.19328 | valid_rmsle: 0.01224 | valid_mae: 0.36446 | valid_rmse: 0.45386 | valid_mse: 0.20599 |  0:00:52s\n",
      "epoch 30 | loss: 0.18683 | train_rmsle: 0.01153 | train_mae: 0.347   | train_rmse: 0.43462 | train_mse: 0.1889  | valid_rmsle: 0.01192 | valid_mae: 0.35739 | valid_rmse: 0.44684 | valid_mse: 0.19967 |  0:00:53s\n",
      "epoch 31 | loss: 0.18553 | train_rmsle: 0.0114  | train_mae: 0.34493 | train_rmse: 0.43126 | train_mse: 0.18598 | valid_rmsle: 0.0123  | valid_mae: 0.36448 | valid_rmse: 0.45291 | valid_mse: 0.20513 |  0:00:55s\n",
      "epoch 32 | loss: 0.18187 | train_rmsle: 0.01117 | train_mae: 0.34012 | train_rmse: 0.42788 | train_mse: 0.18308 | valid_rmsle: 0.01208 | valid_mae: 0.35911 | valid_rmse: 0.45024 | valid_mse: 0.20271 |  0:00:57s\n",
      "epoch 33 | loss: 0.17885 | train_rmsle: 0.01122 | train_mae: 0.34132 | train_rmse: 0.42914 | train_mse: 0.18416 | valid_rmsle: 0.01196 | valid_mae: 0.36055 | valid_rmse: 0.44898 | valid_mse: 0.20158 |  0:00:59s\n",
      "epoch 34 | loss: 0.17912 | train_rmsle: 0.01095 | train_mae: 0.3393  | train_rmse: 0.42427 | train_mse: 0.18001 | valid_rmsle: 0.01216 | valid_mae: 0.36174 | valid_rmse: 0.45231 | valid_mse: 0.20458 |  0:01:00s\n",
      "epoch 35 | loss: 0.17623 | train_rmsle: 0.01061 | train_mae: 0.32911 | train_rmse: 0.41526 | train_mse: 0.17244 | valid_rmsle: 0.01201 | valid_mae: 0.35523 | valid_rmse: 0.44783 | valid_mse: 0.20055 |  0:01:02s\n",
      "epoch 36 | loss: 0.17318 | train_rmsle: 0.01065 | train_mae: 0.33378 | train_rmse: 0.41807 | train_mse: 0.17478 | valid_rmsle: 0.0121  | valid_mae: 0.35764 | valid_rmse: 0.44976 | valid_mse: 0.20228 |  0:01:03s\n",
      "epoch 37 | loss: 0.17188 | train_rmsle: 0.01078 | train_mae: 0.3286  | train_rmse: 0.41717 | train_mse: 0.17403 | valid_rmsle: 0.01257 | valid_mae: 0.35801 | valid_rmse: 0.45559 | valid_mse: 0.20756 |  0:01:05s\n",
      "epoch 38 | loss: 0.17294 | train_rmsle: 0.01034 | train_mae: 0.32357 | train_rmse: 0.40896 | train_mse: 0.16724 | valid_rmsle: 0.0122  | valid_mae: 0.35586 | valid_rmse: 0.44908 | valid_mse: 0.20167 |  0:01:06s\n",
      "epoch 39 | loss: 0.16984 | train_rmsle: 0.0106  | train_mae: 0.32806 | train_rmse: 0.41408 | train_mse: 0.17146 | valid_rmsle: 0.01187 | valid_mae: 0.35102 | valid_rmse: 0.44402 | valid_mse: 0.19715 |  0:01:08s\n",
      "epoch 40 | loss: 0.1668  | train_rmsle: 0.01022 | train_mae: 0.3224  | train_rmse: 0.4075  | train_mse: 0.16605 | valid_rmsle: 0.01202 | valid_mae: 0.35449 | valid_rmse: 0.44704 | valid_mse: 0.19985 |  0:01:09s\n",
      "epoch 41 | loss: 0.16825 | train_rmsle: 0.01001 | train_mae: 0.32032 | train_rmse: 0.4046  | train_mse: 0.1637  | valid_rmsle: 0.01233 | valid_mae: 0.35823 | valid_rmse: 0.45301 | valid_mse: 0.20522 |  0:01:10s\n",
      "epoch 42 | loss: 0.16814 | train_rmsle: 0.01006 | train_mae: 0.32137 | train_rmse: 0.40506 | train_mse: 0.16407 | valid_rmsle: 0.01222 | valid_mae: 0.3562  | valid_rmse: 0.45153 | valid_mse: 0.20388 |  0:01:12s\n",
      "epoch 43 | loss: 0.16468 | train_rmsle: 0.00971 | train_mae: 0.31396 | train_rmse: 0.39839 | train_mse: 0.15871 | valid_rmsle: 0.01223 | valid_mae: 0.35348 | valid_rmse: 0.45047 | valid_mse: 0.20293 |  0:01:13s\n",
      "epoch 44 | loss: 0.16413 | train_rmsle: 0.01001 | train_mae: 0.31632 | train_rmse: 0.40267 | train_mse: 0.16214 | valid_rmsle: 0.01215 | valid_mae: 0.3523  | valid_rmse: 0.44836 | valid_mse: 0.20102 |  0:01:15s\n",
      "epoch 45 | loss: 0.165   | train_rmsle: 0.00968 | train_mae: 0.31897 | train_rmse: 0.40042 | train_mse: 0.16034 | valid_rmsle: 0.01198 | valid_mae: 0.35611 | valid_rmse: 0.4484  | valid_mse: 0.20106 |  0:01:16s\n",
      "epoch 46 | loss: 0.16109 | train_rmsle: 0.00956 | train_mae: 0.31298 | train_rmse: 0.39598 | train_mse: 0.1568  | valid_rmsle: 0.01236 | valid_mae: 0.35668 | valid_rmse: 0.45416 | valid_mse: 0.20626 |  0:01:18s\n",
      "epoch 47 | loss: 0.16132 | train_rmsle: 0.00965 | train_mae: 0.31145 | train_rmse: 0.39641 | train_mse: 0.15714 | valid_rmsle: 0.01199 | valid_mae: 0.3516  | valid_rmse: 0.44708 | valid_mse: 0.19988 |  0:01:20s\n",
      "epoch 48 | loss: 0.16133 | train_rmsle: 0.00928 | train_mae: 0.31071 | train_rmse: 0.39207 | train_mse: 0.15372 | valid_rmsle: 0.01169 | valid_mae: 0.35144 | valid_rmse: 0.44348 | valid_mse: 0.19667 |  0:01:22s\n",
      "epoch 49 | loss: 0.1579  | train_rmsle: 0.00914 | train_mae: 0.30926 | train_rmse: 0.38952 | train_mse: 0.15173 | valid_rmsle: 0.01168 | valid_mae: 0.35051 | valid_rmse: 0.44343 | valid_mse: 0.19663 |  0:01:23s\n",
      "epoch 50 | loss: 0.15586 | train_rmsle: 0.0091  | train_mae: 0.30764 | train_rmse: 0.38704 | train_mse: 0.1498  | valid_rmsle: 0.01153 | valid_mae: 0.34864 | valid_rmse: 0.44014 | valid_mse: 0.19372 |  0:01:25s\n",
      "epoch 51 | loss: 0.15493 | train_rmsle: 0.00893 | train_mae: 0.30381 | train_rmse: 0.38378 | train_mse: 0.14729 | valid_rmsle: 0.01156 | valid_mae: 0.3478  | valid_rmse: 0.44063 | valid_mse: 0.19416 |  0:01:27s\n",
      "epoch 52 | loss: 0.15413 | train_rmsle: 0.00927 | train_mae: 0.30619 | train_rmse: 0.3886  | train_mse: 0.15101 | valid_rmsle: 0.01175 | valid_mae: 0.34959 | valid_rmse: 0.44283 | valid_mse: 0.1961  |  0:01:29s\n",
      "epoch 53 | loss: 0.155   | train_rmsle: 0.00909 | train_mae: 0.30542 | train_rmse: 0.38535 | train_mse: 0.14849 | valid_rmsle: 0.01137 | valid_mae: 0.34575 | valid_rmse: 0.43647 | valid_mse: 0.19051 |  0:01:30s\n",
      "epoch 54 | loss: 0.1535  | train_rmsle: 0.00876 | train_mae: 0.29811 | train_rmse: 0.37945 | train_mse: 0.14398 | valid_rmsle: 0.01172 | valid_mae: 0.34703 | valid_rmse: 0.44217 | valid_mse: 0.19552 |  0:01:32s\n",
      "epoch 55 | loss: 0.14918 | train_rmsle: 0.00864 | train_mae: 0.29621 | train_rmse: 0.37633 | train_mse: 0.14163 | valid_rmsle: 0.01169 | valid_mae: 0.34724 | valid_rmse: 0.44261 | valid_mse: 0.1959  |  0:01:34s\n",
      "epoch 56 | loss: 0.14738 | train_rmsle: 0.0085  | train_mae: 0.29549 | train_rmse: 0.374   | train_mse: 0.13988 | valid_rmsle: 0.01201 | valid_mae: 0.35152 | valid_rmse: 0.44915 | valid_mse: 0.20173 |  0:01:35s\n",
      "epoch 57 | loss: 0.14836 | train_rmsle: 0.00845 | train_mae: 0.29151 | train_rmse: 0.3714  | train_mse: 0.13794 | valid_rmsle: 0.01224 | valid_mae: 0.35174 | valid_rmse: 0.45215 | valid_mse: 0.20444 |  0:01:37s\n",
      "epoch 58 | loss: 0.14695 | train_rmsle: 0.00841 | train_mae: 0.29357 | train_rmse: 0.37169 | train_mse: 0.13815 | valid_rmsle: 0.01203 | valid_mae: 0.35049 | valid_rmse: 0.44927 | valid_mse: 0.20185 |  0:01:39s\n",
      "epoch 59 | loss: 0.14739 | train_rmsle: 0.0084  | train_mae: 0.29145 | train_rmse: 0.37133 | train_mse: 0.13788 | valid_rmsle: 0.01182 | valid_mae: 0.34713 | valid_rmse: 0.44548 | valid_mse: 0.19845 |  0:01:41s\n",
      "epoch 60 | loss: 0.14271 | train_rmsle: 0.00875 | train_mae: 0.29875 | train_rmse: 0.37748 | train_mse: 0.14249 | valid_rmsle: 0.01191 | valid_mae: 0.35106 | valid_rmse: 0.44661 | valid_mse: 0.19946 |  0:01:42s\n",
      "epoch 61 | loss: 0.14315 | train_rmsle: 0.00813 | train_mae: 0.28721 | train_rmse: 0.36483 | train_mse: 0.1331  | valid_rmsle: 0.01153 | valid_mae: 0.3409  | valid_rmse: 0.4389  | valid_mse: 0.19264 |  0:01:44s\n",
      "epoch 62 | loss: 0.13933 | train_rmsle: 0.00785 | train_mae: 0.28362 | train_rmse: 0.35989 | train_mse: 0.12952 | valid_rmsle: 0.0113  | valid_mae: 0.33915 | valid_rmse: 0.43551 | valid_mse: 0.18967 |  0:01:46s\n",
      "epoch 63 | loss: 0.13559 | train_rmsle: 0.00781 | train_mae: 0.28237 | train_rmse: 0.35931 | train_mse: 0.12911 | valid_rmsle: 0.01121 | valid_mae: 0.34056 | valid_rmse: 0.43414 | valid_mse: 0.18848 |  0:01:48s\n",
      "epoch 64 | loss: 0.13693 | train_rmsle: 0.00785 | train_mae: 0.28276 | train_rmse: 0.36042 | train_mse: 0.1299  | valid_rmsle: 0.01125 | valid_mae: 0.33735 | valid_rmse: 0.43385 | valid_mse: 0.18823 |  0:01:49s\n",
      "epoch 65 | loss: 0.13724 | train_rmsle: 0.00773 | train_mae: 0.28159 | train_rmse: 0.35748 | train_mse: 0.12779 | valid_rmsle: 0.01087 | valid_mae: 0.33393 | valid_rmse: 0.42741 | valid_mse: 0.18268 |  0:01:51s\n",
      "epoch 66 | loss: 0.1336  | train_rmsle: 0.00765 | train_mae: 0.27922 | train_rmse: 0.35534 | train_mse: 0.12627 | valid_rmsle: 0.01056 | valid_mae: 0.32675 | valid_rmse: 0.42078 | valid_mse: 0.17705 |  0:01:53s\n",
      "epoch 67 | loss: 0.13177 | train_rmsle: 0.00751 | train_mae: 0.27476 | train_rmse: 0.35227 | train_mse: 0.1241  | valid_rmsle: 0.01112 | valid_mae: 0.33349 | valid_rmse: 0.4315  | valid_mse: 0.18619 |  0:01:55s\n",
      "epoch 68 | loss: 0.13095 | train_rmsle: 0.00731 | train_mae: 0.27261 | train_rmse: 0.34804 | train_mse: 0.12113 | valid_rmsle: 0.01078 | valid_mae: 0.32938 | valid_rmse: 0.4259  | valid_mse: 0.18139 |  0:01:56s\n",
      "epoch 69 | loss: 0.12718 | train_rmsle: 0.00743 | train_mae: 0.27074 | train_rmse: 0.34809 | train_mse: 0.12117 | valid_rmsle: 0.01072 | valid_mae: 0.3269  | valid_rmse: 0.42234 | valid_mse: 0.17837 |  0:01:58s\n",
      "epoch 70 | loss: 0.12793 | train_rmsle: 0.00753 | train_mae: 0.27257 | train_rmse: 0.34911 | train_mse: 0.12188 | valid_rmsle: 0.01085 | valid_mae: 0.33123 | valid_rmse: 0.423   | valid_mse: 0.17893 |  0:02:00s\n",
      "epoch 71 | loss: 0.12504 | train_rmsle: 0.00712 | train_mae: 0.27144 | train_rmse: 0.34395 | train_mse: 0.1183  | valid_rmsle: 0.01052 | valid_mae: 0.32825 | valid_rmse: 0.41888 | valid_mse: 0.17546 |  0:02:02s\n",
      "epoch 72 | loss: 0.12495 | train_rmsle: 0.00697 | train_mae: 0.26648 | train_rmse: 0.34031 | train_mse: 0.11581 | valid_rmsle: 0.0104  | valid_mae: 0.32694 | valid_rmse: 0.41696 | valid_mse: 0.17385 |  0:02:03s\n",
      "epoch 73 | loss: 0.12364 | train_rmsle: 0.00695 | train_mae: 0.26439 | train_rmse: 0.33794 | train_mse: 0.1142  | valid_rmsle: 0.01044 | valid_mae: 0.32522 | valid_rmse: 0.41664 | valid_mse: 0.17359 |  0:02:05s\n",
      "epoch 74 | loss: 0.11995 | train_rmsle: 0.00679 | train_mae: 0.26055 | train_rmse: 0.33438 | train_mse: 0.11181 | valid_rmsle: 0.01013 | valid_mae: 0.32282 | valid_rmse: 0.41256 | valid_mse: 0.17021 |  0:02:07s\n",
      "epoch 75 | loss: 0.11793 | train_rmsle: 0.00684 | train_mae: 0.26326 | train_rmse: 0.33556 | train_mse: 0.1126  | valid_rmsle: 0.01004 | valid_mae: 0.32274 | valid_rmse: 0.41044 | valid_mse: 0.16846 |  0:02:09s\n",
      "epoch 76 | loss: 0.11774 | train_rmsle: 0.00658 | train_mae: 0.25621 | train_rmse: 0.32829 | train_mse: 0.10777 | valid_rmsle: 0.01027 | valid_mae: 0.32241 | valid_rmse: 0.4153  | valid_mse: 0.17247 |  0:02:10s\n",
      "epoch 77 | loss: 0.11598 | train_rmsle: 0.00637 | train_mae: 0.2567  | train_rmse: 0.32657 | train_mse: 0.10665 | valid_rmsle: 0.00984 | valid_mae: 0.31557 | valid_rmse: 0.40735 | valid_mse: 0.16593 |  0:02:12s\n",
      "epoch 78 | loss: 0.11277 | train_rmsle: 0.00641 | train_mae: 0.2515  | train_rmse: 0.32427 | train_mse: 0.10515 | valid_rmsle: 0.00973 | valid_mae: 0.30943 | valid_rmse: 0.40272 | valid_mse: 0.16218 |  0:02:14s\n",
      "epoch 79 | loss: 0.11017 | train_rmsle: 0.00614 | train_mae: 0.25097 | train_rmse: 0.31994 | train_mse: 0.10236 | valid_rmsle: 0.00945 | valid_mae: 0.31005 | valid_rmse: 0.39889 | valid_mse: 0.15911 |  0:02:16s\n",
      "epoch 80 | loss: 0.10672 | train_rmsle: 0.00603 | train_mae: 0.24742 | train_rmse: 0.31631 | train_mse: 0.10005 | valid_rmsle: 0.00903 | valid_mae: 0.30142 | valid_rmse: 0.39009 | valid_mse: 0.15217 |  0:02:17s\n",
      "epoch 81 | loss: 0.1059  | train_rmsle: 0.00584 | train_mae: 0.245   | train_rmse: 0.31143 | train_mse: 0.09699 | valid_rmsle: 0.00892 | valid_mae: 0.30001 | valid_rmse: 0.3882  | valid_mse: 0.1507  |  0:02:19s\n",
      "epoch 82 | loss: 0.10171 | train_rmsle: 0.00561 | train_mae: 0.23846 | train_rmse: 0.30488 | train_mse: 0.09295 | valid_rmsle: 0.00862 | valid_mae: 0.29384 | valid_rmse: 0.38087 | valid_mse: 0.14506 |  0:02:21s\n",
      "epoch 83 | loss: 0.10168 | train_rmsle: 0.00534 | train_mae: 0.23016 | train_rmse: 0.29652 | train_mse: 0.08792 | valid_rmsle: 0.00829 | valid_mae: 0.28691 | valid_rmse: 0.37422 | valid_mse: 0.14004 |  0:02:22s\n",
      "epoch 84 | loss: 0.0949  | train_rmsle: 0.0052  | train_mae: 0.22766 | train_rmse: 0.29269 | train_mse: 0.08567 | valid_rmsle: 0.00795 | valid_mae: 0.28249 | valid_rmse: 0.3658  | valid_mse: 0.13381 |  0:02:24s\n",
      "epoch 85 | loss: 0.09209 | train_rmsle: 0.00519 | train_mae: 0.23175 | train_rmse: 0.29462 | train_mse: 0.0868  | valid_rmsle: 0.00777 | valid_mae: 0.28351 | valid_rmse: 0.36337 | valid_mse: 0.13204 |  0:02:26s\n",
      "epoch 86 | loss: 0.08962 | train_rmsle: 0.00486 | train_mae: 0.2197  | train_rmse: 0.28312 | train_mse: 0.08016 | valid_rmsle: 0.00748 | valid_mae: 0.27549 | valid_rmse: 0.35585 | valid_mse: 0.12663 |  0:02:28s\n",
      "epoch 87 | loss: 0.0891  | train_rmsle: 0.00466 | train_mae: 0.21467 | train_rmse: 0.27716 | train_mse: 0.07682 | valid_rmsle: 0.00736 | valid_mae: 0.27404 | valid_rmse: 0.35325 | valid_mse: 0.12479 |  0:02:29s\n",
      "epoch 88 | loss: 0.0841  | train_rmsle: 0.0045  | train_mae: 0.2108  | train_rmse: 0.27196 | train_mse: 0.07396 | valid_rmsle: 0.00706 | valid_mae: 0.26914 | valid_rmse: 0.34656 | valid_mse: 0.1201  |  0:02:31s\n",
      "epoch 89 | loss: 0.08189 | train_rmsle: 0.00436 | train_mae: 0.20695 | train_rmse: 0.26784 | train_mse: 0.07174 | valid_rmsle: 0.00678 | valid_mae: 0.26465 | valid_rmse: 0.34069 | valid_mse: 0.11607 |  0:02:33s\n",
      "epoch 90 | loss: 0.07952 | train_rmsle: 0.0042  | train_mae: 0.20149 | train_rmse: 0.26197 | train_mse: 0.06863 | valid_rmsle: 0.00665 | valid_mae: 0.26204 | valid_rmse: 0.33741 | valid_mse: 0.11385 |  0:02:35s\n",
      "epoch 91 | loss: 0.07689 | train_rmsle: 0.0041  | train_mae: 0.19904 | train_rmse: 0.2588  | train_mse: 0.06698 | valid_rmsle: 0.00655 | valid_mae: 0.26183 | valid_rmse: 0.3351  | valid_mse: 0.11229 |  0:02:36s\n",
      "epoch 92 | loss: 0.07573 | train_rmsle: 0.00413 | train_mae: 0.20555 | train_rmse: 0.26236 | train_mse: 0.06883 | valid_rmsle: 0.00683 | valid_mae: 0.26625 | valid_rmse: 0.34297 | valid_mse: 0.11763 |  0:02:38s\n",
      "epoch 93 | loss: 0.07492 | train_rmsle: 0.00391 | train_mae: 0.19684 | train_rmse: 0.25383 | train_mse: 0.06443 | valid_rmsle: 0.00638 | valid_mae: 0.25675 | valid_rmse: 0.33077 | valid_mse: 0.10941 |  0:02:40s\n",
      "epoch 94 | loss: 0.07247 | train_rmsle: 0.00382 | train_mae: 0.19183 | train_rmse: 0.25025 | train_mse: 0.06263 | valid_rmsle: 0.00626 | valid_mae: 0.25453 | valid_rmse: 0.32774 | valid_mse: 0.10742 |  0:02:41s\n",
      "epoch 95 | loss: 0.07111 | train_rmsle: 0.00371 | train_mae: 0.18989 | train_rmse: 0.24638 | train_mse: 0.0607  | valid_rmsle: 0.00604 | valid_mae: 0.25131 | valid_rmse: 0.32294 | valid_mse: 0.10429 |  0:02:42s\n",
      "epoch 96 | loss: 0.06898 | train_rmsle: 0.00366 | train_mae: 0.1903  | train_rmse: 0.24617 | train_mse: 0.0606  | valid_rmsle: 0.00614 | valid_mae: 0.25318 | valid_rmse: 0.32649 | valid_mse: 0.1066  |  0:02:44s\n",
      "epoch 97 | loss: 0.06829 | train_rmsle: 0.00372 | train_mae: 0.18806 | train_rmse: 0.24591 | train_mse: 0.06047 | valid_rmsle: 0.00614 | valid_mae: 0.25081 | valid_rmse: 0.3261  | valid_mse: 0.10634 |  0:02:45s\n",
      "epoch 98 | loss: 0.06792 | train_rmsle: 0.00347 | train_mae: 0.18459 | train_rmse: 0.23952 | train_mse: 0.05737 | valid_rmsle: 0.00586 | valid_mae: 0.24833 | valid_rmse: 0.31891 | valid_mse: 0.10171 |  0:02:47s\n",
      "epoch 99 | loss: 0.06517 | train_rmsle: 0.00342 | train_mae: 0.18609 | train_rmse: 0.23935 | train_mse: 0.05729 | valid_rmsle: 0.0058  | valid_mae: 0.24831 | valid_rmse: 0.31843 | valid_mse: 0.1014  |  0:02:48s\n",
      "epoch 100| loss: 0.06371 | train_rmsle: 0.00327 | train_mae: 0.17871 | train_rmse: 0.2322  | train_mse: 0.05392 | valid_rmsle: 0.00562 | valid_mae: 0.24504 | valid_rmse: 0.31272 | valid_mse: 0.0978  |  0:02:49s\n",
      "epoch 101| loss: 0.06214 | train_rmsle: 0.00314 | train_mae: 0.17433 | train_rmse: 0.22762 | train_mse: 0.05181 | valid_rmsle: 0.00547 | valid_mae: 0.24268 | valid_rmse: 0.30863 | valid_mse: 0.09525 |  0:02:51s\n",
      "epoch 102| loss: 0.05972 | train_rmsle: 0.00325 | train_mae: 0.18172 | train_rmse: 0.23347 | train_mse: 0.05451 | valid_rmsle: 0.00558 | valid_mae: 0.24619 | valid_rmse: 0.31225 | valid_mse: 0.0975  |  0:02:52s\n",
      "epoch 103| loss: 0.0615  | train_rmsle: 0.00303 | train_mae: 0.17432 | train_rmse: 0.22523 | train_mse: 0.05073 | valid_rmsle: 0.00546 | valid_mae: 0.24203 | valid_rmse: 0.30835 | valid_mse: 0.09508 |  0:02:54s\n",
      "epoch 104| loss: 0.06051 | train_rmsle: 0.00287 | train_mae: 0.1663  | train_rmse: 0.21737 | train_mse: 0.04725 | valid_rmsle: 0.00515 | valid_mae: 0.2346  | valid_rmse: 0.29896 | valid_mse: 0.08938 |  0:02:56s\n",
      "epoch 105| loss: 0.05674 | train_rmsle: 0.00292 | train_mae: 0.17157 | train_rmse: 0.22195 | train_mse: 0.04926 | valid_rmsle: 0.00526 | valid_mae: 0.23787 | valid_rmse: 0.30377 | valid_mse: 0.09227 |  0:02:58s\n",
      "epoch 106| loss: 0.05521 | train_rmsle: 0.00276 | train_mae: 0.16319 | train_rmse: 0.21335 | train_mse: 0.04552 | valid_rmsle: 0.005   | valid_mae: 0.23238 | valid_rmse: 0.29542 | valid_mse: 0.08727 |  0:02:59s\n",
      "epoch 107| loss: 0.05424 | train_rmsle: 0.0027  | train_mae: 0.16127 | train_rmse: 0.2113  | train_mse: 0.04465 | valid_rmsle: 0.0049  | valid_mae: 0.23046 | valid_rmse: 0.29301 | valid_mse: 0.08585 |  0:03:01s\n",
      "epoch 108| loss: 0.05436 | train_rmsle: 0.00271 | train_mae: 0.15996 | train_rmse: 0.21084 | train_mse: 0.04445 | valid_rmsle: 0.00494 | valid_mae: 0.23159 | valid_rmse: 0.29415 | valid_mse: 0.08652 |  0:03:03s\n",
      "epoch 109| loss: 0.05435 | train_rmsle: 0.00263 | train_mae: 0.16012 | train_rmse: 0.20929 | train_mse: 0.0438  | valid_rmsle: 0.00483 | valid_mae: 0.22912 | valid_rmse: 0.29161 | valid_mse: 0.08504 |  0:03:05s\n",
      "epoch 110| loss: 0.05151 | train_rmsle: 0.00256 | train_mae: 0.15561 | train_rmse: 0.20516 | train_mse: 0.04209 | valid_rmsle: 0.00476 | valid_mae: 0.22784 | valid_rmse: 0.28901 | valid_mse: 0.08353 |  0:03:06s\n",
      "epoch 111| loss: 0.04961 | train_rmsle: 0.00267 | train_mae: 0.15547 | train_rmse: 0.20607 | train_mse: 0.04246 | valid_rmsle: 0.00488 | valid_mae: 0.22904 | valid_rmse: 0.29096 | valid_mse: 0.08466 |  0:03:08s\n",
      "epoch 112| loss: 0.04929 | train_rmsle: 0.00241 | train_mae: 0.1519  | train_rmse: 0.19966 | train_mse: 0.03987 | valid_rmsle: 0.00463 | valid_mae: 0.22517 | valid_rmse: 0.28571 | valid_mse: 0.08163 |  0:03:10s\n",
      "epoch 113| loss: 0.04828 | train_rmsle: 0.00229 | train_mae: 0.14812 | train_rmse: 0.19505 | train_mse: 0.03804 | valid_rmsle: 0.0046  | valid_mae: 0.22338 | valid_rmse: 0.2849  | valid_mse: 0.08117 |  0:03:11s\n",
      "epoch 114| loss: 0.04693 | train_rmsle: 0.00227 | train_mae: 0.14922 | train_rmse: 0.19486 | train_mse: 0.03797 | valid_rmsle: 0.00457 | valid_mae: 0.22472 | valid_rmse: 0.28424 | valid_mse: 0.0808  |  0:03:13s\n",
      "epoch 115| loss: 0.04517 | train_rmsle: 0.00213 | train_mae: 0.14281 | train_rmse: 0.18834 | train_mse: 0.03547 | valid_rmsle: 0.00446 | valid_mae: 0.219   | valid_rmse: 0.28114 | valid_mse: 0.07904 |  0:03:15s\n",
      "epoch 116| loss: 0.04574 | train_rmsle: 0.00215 | train_mae: 0.14426 | train_rmse: 0.18987 | train_mse: 0.03605 | valid_rmsle: 0.00458 | valid_mae: 0.22295 | valid_rmse: 0.2853  | valid_mse: 0.0814  |  0:03:17s\n",
      "epoch 117| loss: 0.04423 | train_rmsle: 0.00205 | train_mae: 0.13997 | train_rmse: 0.18485 | train_mse: 0.03417 | valid_rmsle: 0.00441 | valid_mae: 0.21836 | valid_rmse: 0.27874 | valid_mse: 0.0777  |  0:03:18s\n",
      "epoch 118| loss: 0.04243 | train_rmsle: 0.00201 | train_mae: 0.1387  | train_rmse: 0.18362 | train_mse: 0.03371 | valid_rmsle: 0.00442 | valid_mae: 0.218   | valid_rmse: 0.27969 | valid_mse: 0.07823 |  0:03:20s\n",
      "epoch 119| loss: 0.0418  | train_rmsle: 0.00199 | train_mae: 0.13812 | train_rmse: 0.18262 | train_mse: 0.03335 | valid_rmsle: 0.00432 | valid_mae: 0.2167  | valid_rmse: 0.2769  | valid_mse: 0.07667 |  0:03:22s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 119 and best_valid_mse = 0.07667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08144292784074936 RMSE: 0.28538207343971234 R2: 0.6394835399218801 MAE: 0.22325571691861232\n",
      "=====================================\n",
      "[11/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.14894 | train_rmsle: 0.95472 | train_mae: 2.66229 | train_rmse: 2.70621 | train_mse: 7.32358 | valid_rmsle: 0.95763 | valid_mae: 2.66884 | valid_rmse: 2.71175 | valid_mse: 7.35359 |  0:00:01s\n",
      "epoch 1  | loss: 3.52886 | train_rmsle: 0.30831 | train_mae: 1.80452 | train_rmse: 1.86792 | train_mse: 3.48912 | valid_rmsle: 0.3095  | valid_mae: 1.81071 | valid_rmse: 1.87254 | valid_mse: 3.5064  |  0:00:03s\n",
      "epoch 2  | loss: 1.55188 | train_rmsle: 0.14655 | train_mae: 1.3268  | train_rmse: 1.40682 | train_mse: 1.97916 | valid_rmsle: 0.1473  | valid_mae: 1.33179 | valid_rmse: 1.41128 | valid_mse: 1.99171 |  0:00:05s\n",
      "epoch 3  | loss: 0.70925 | train_rmsle: 0.06887 | train_mae: 0.93878 | train_rmse: 1.03125 | train_mse: 1.06347 | valid_rmsle: 0.06926 | valid_mae: 0.94229 | valid_rmse: 1.03558 | valid_mse: 1.07242 |  0:00:07s\n",
      "epoch 4  | loss: 0.40886 | train_rmsle: 0.04051 | train_mae: 0.72427 | train_rmse: 0.81814 | train_mse: 0.66935 | valid_rmsle: 0.04063 | valid_mae: 0.72518 | valid_rmse: 0.8217  | valid_mse: 0.6752  |  0:00:08s\n",
      "epoch 5  | loss: 0.31605 | train_rmsle: 0.03075 | train_mae: 0.62907 | train_rmse: 0.72144 | train_mse: 0.52048 | valid_rmsle: 0.03075 | valid_mae: 0.63021 | valid_rmse: 0.72443 | valid_mse: 0.5248  |  0:00:10s\n",
      "epoch 6  | loss: 0.27925 | train_rmsle: 0.02516 | train_mae: 0.56515 | train_rmse: 0.65604 | train_mse: 0.43038 | valid_rmsle: 0.02502 | valid_mae: 0.56658 | valid_rmse: 0.65782 | valid_mse: 0.43273 |  0:00:12s\n",
      "epoch 7  | loss: 0.26245 | train_rmsle: 0.0208  | train_mae: 0.50775 | train_rmse: 0.59675 | train_mse: 0.35611 | valid_rmsle: 0.02051 | valid_mae: 0.50884 | valid_rmse: 0.59693 | valid_mse: 0.35632 |  0:00:14s\n",
      "epoch 8  | loss: 0.25001 | train_rmsle: 0.02053 | train_mae: 0.50376 | train_rmse: 0.59302 | train_mse: 0.35167 | valid_rmsle: 0.02022 | valid_mae: 0.50437 | valid_rmse: 0.59295 | valid_mse: 0.35159 |  0:00:15s\n",
      "epoch 9  | loss: 0.24403 | train_rmsle: 0.01557 | train_mae: 0.41802 | train_rmse: 0.50829 | train_mse: 0.25836 | valid_rmsle: 0.0151  | valid_mae: 0.41995 | valid_rmse: 0.50581 | valid_mse: 0.25585 |  0:00:17s\n",
      "epoch 10 | loss: 0.23693 | train_rmsle: 0.01622 | train_mae: 0.43131 | train_rmse: 0.52082 | train_mse: 0.27125 | valid_rmsle: 0.01572 | valid_mae: 0.43165 | valid_rmse: 0.51765 | valid_mse: 0.26796 |  0:00:19s\n",
      "epoch 11 | loss: 0.23232 | train_rmsle: 0.01608 | train_mae: 0.42992 | train_rmse: 0.5195  | train_mse: 0.26988 | valid_rmsle: 0.01565 | valid_mae: 0.43023 | valid_rmse: 0.51727 | valid_mse: 0.26757 |  0:00:20s\n",
      "epoch 12 | loss: 0.22978 | train_rmsle: 0.01497 | train_mae: 0.40919 | train_rmse: 0.49919 | train_mse: 0.24919 | valid_rmsle: 0.01452 | valid_mae: 0.41056 | valid_rmse: 0.49673 | valid_mse: 0.24674 |  0:00:22s\n",
      "epoch 13 | loss: 0.22859 | train_rmsle: 0.01457 | train_mae: 0.40311 | train_rmse: 0.49235 | train_mse: 0.2424  | valid_rmsle: 0.01416 | valid_mae: 0.40409 | valid_rmse: 0.49032 | valid_mse: 0.24042 |  0:00:24s\n",
      "epoch 14 | loss: 0.22318 | train_rmsle: 0.01422 | train_mae: 0.39902 | train_rmse: 0.48732 | train_mse: 0.23748 | valid_rmsle: 0.01372 | valid_mae: 0.39836 | valid_rmse: 0.48375 | valid_mse: 0.23401 |  0:00:26s\n",
      "epoch 15 | loss: 0.21981 | train_rmsle: 0.01351 | train_mae: 0.37993 | train_rmse: 0.46962 | train_mse: 0.22055 | valid_rmsle: 0.01291 | valid_mae: 0.37937 | valid_rmse: 0.46437 | valid_mse: 0.21564 |  0:00:27s\n",
      "epoch 16 | loss: 0.21685 | train_rmsle: 0.01335 | train_mae: 0.37209 | train_rmse: 0.4645  | train_mse: 0.21576 | valid_rmsle: 0.01264 | valid_mae: 0.37031 | valid_rmse: 0.45745 | valid_mse: 0.20926 |  0:00:29s\n",
      "epoch 17 | loss: 0.21433 | train_rmsle: 0.01335 | train_mae: 0.37696 | train_rmse: 0.46798 | train_mse: 0.21901 | valid_rmsle: 0.01279 | valid_mae: 0.377   | valid_rmse: 0.46301 | valid_mse: 0.21438 |  0:00:31s\n",
      "epoch 18 | loss: 0.21253 | train_rmsle: 0.01391 | train_mae: 0.3905  | train_rmse: 0.47979 | train_mse: 0.2302  | valid_rmsle: 0.01341 | valid_mae: 0.39066 | valid_rmse: 0.47666 | valid_mse: 0.2272  |  0:00:33s\n",
      "epoch 19 | loss: 0.21107 | train_rmsle: 0.01354 | train_mae: 0.38358 | train_rmse: 0.47188 | train_mse: 0.22267 | valid_rmsle: 0.01305 | valid_mae: 0.38424 | valid_rmse: 0.46818 | valid_mse: 0.21919 |  0:00:34s\n",
      "epoch 20 | loss: 0.20883 | train_rmsle: 0.01341 | train_mae: 0.38077 | train_rmse: 0.47015 | train_mse: 0.22104 | valid_rmsle: 0.01297 | valid_mae: 0.38206 | valid_rmse: 0.46722 | valid_mse: 0.21829 |  0:00:36s\n",
      "epoch 21 | loss: 0.20597 | train_rmsle: 0.01365 | train_mae: 0.38767 | train_rmse: 0.47727 | train_mse: 0.22779 | valid_rmsle: 0.01341 | valid_mae: 0.38925 | valid_rmse: 0.47761 | valid_mse: 0.22811 |  0:00:38s\n",
      "epoch 22 | loss: 0.2075  | train_rmsle: 0.01316 | train_mae: 0.37665 | train_rmse: 0.4665  | train_mse: 0.21762 | valid_rmsle: 0.01285 | valid_mae: 0.37691 | valid_rmse: 0.46526 | valid_mse: 0.21646 |  0:00:39s\n",
      "epoch 23 | loss: 0.2035  | train_rmsle: 0.013   | train_mae: 0.37563 | train_rmse: 0.46496 | train_mse: 0.21619 | valid_rmsle: 0.01292 | valid_mae: 0.37861 | valid_rmse: 0.46814 | valid_mse: 0.21916 |  0:00:41s\n",
      "epoch 24 | loss: 0.1988  | train_rmsle: 0.01264 | train_mae: 0.36296 | train_rmse: 0.45469 | train_mse: 0.20674 | valid_rmsle: 0.01226 | valid_mae: 0.36426 | valid_rmse: 0.45303 | valid_mse: 0.20523 |  0:00:42s\n",
      "epoch 25 | loss: 0.19958 | train_rmsle: 0.01248 | train_mae: 0.35944 | train_rmse: 0.45037 | train_mse: 0.20283 | valid_rmsle: 0.01235 | valid_mae: 0.36245 | valid_rmse: 0.45296 | valid_mse: 0.20517 |  0:00:44s\n",
      "epoch 26 | loss: 0.19509 | train_rmsle: 0.01242 | train_mae: 0.3553  | train_rmse: 0.44722 | train_mse: 0.2     | valid_rmsle: 0.01246 | valid_mae: 0.36422 | valid_rmse: 0.4533  | valid_mse: 0.20548 |  0:00:45s\n",
      "epoch 27 | loss: 0.1926  | train_rmsle: 0.01217 | train_mae: 0.35139 | train_rmse: 0.44336 | train_mse: 0.19656 | valid_rmsle: 0.01213 | valid_mae: 0.35812 | valid_rmse: 0.44794 | valid_mse: 0.20065 |  0:00:46s\n",
      "epoch 28 | loss: 0.19264 | train_rmsle: 0.0119  | train_mae: 0.35583 | train_rmse: 0.44222 | train_mse: 0.19556 | valid_rmsle: 0.01232 | valid_mae: 0.36346 | valid_rmse: 0.45487 | valid_mse: 0.2069  |  0:00:48s\n",
      "epoch 29 | loss: 0.18883 | train_rmsle: 0.01174 | train_mae: 0.35272 | train_rmse: 0.43963 | train_mse: 0.19328 | valid_rmsle: 0.01224 | valid_mae: 0.36446 | valid_rmse: 0.45386 | valid_mse: 0.20599 |  0:00:49s\n",
      "epoch 30 | loss: 0.18683 | train_rmsle: 0.01153 | train_mae: 0.347   | train_rmse: 0.43462 | train_mse: 0.1889  | valid_rmsle: 0.01192 | valid_mae: 0.35739 | valid_rmse: 0.44684 | valid_mse: 0.19967 |  0:00:50s\n",
      "epoch 31 | loss: 0.18553 | train_rmsle: 0.0114  | train_mae: 0.34493 | train_rmse: 0.43126 | train_mse: 0.18598 | valid_rmsle: 0.0123  | valid_mae: 0.36448 | valid_rmse: 0.45291 | valid_mse: 0.20513 |  0:00:52s\n",
      "epoch 32 | loss: 0.18187 | train_rmsle: 0.01117 | train_mae: 0.34012 | train_rmse: 0.42788 | train_mse: 0.18308 | valid_rmsle: 0.01208 | valid_mae: 0.35911 | valid_rmse: 0.45024 | valid_mse: 0.20271 |  0:00:53s\n",
      "epoch 33 | loss: 0.17885 | train_rmsle: 0.01122 | train_mae: 0.34132 | train_rmse: 0.42914 | train_mse: 0.18416 | valid_rmsle: 0.01196 | valid_mae: 0.36055 | valid_rmse: 0.44898 | valid_mse: 0.20158 |  0:00:55s\n",
      "epoch 34 | loss: 0.17912 | train_rmsle: 0.01095 | train_mae: 0.3393  | train_rmse: 0.42427 | train_mse: 0.18001 | valid_rmsle: 0.01216 | valid_mae: 0.36174 | valid_rmse: 0.45231 | valid_mse: 0.20458 |  0:00:56s\n",
      "epoch 35 | loss: 0.17623 | train_rmsle: 0.01061 | train_mae: 0.32911 | train_rmse: 0.41526 | train_mse: 0.17244 | valid_rmsle: 0.01201 | valid_mae: 0.35523 | valid_rmse: 0.44783 | valid_mse: 0.20055 |  0:00:58s\n",
      "epoch 36 | loss: 0.17318 | train_rmsle: 0.01065 | train_mae: 0.33378 | train_rmse: 0.41807 | train_mse: 0.17478 | valid_rmsle: 0.0121  | valid_mae: 0.35764 | valid_rmse: 0.44976 | valid_mse: 0.20228 |  0:00:59s\n",
      "epoch 37 | loss: 0.17188 | train_rmsle: 0.01078 | train_mae: 0.3286  | train_rmse: 0.41717 | train_mse: 0.17403 | valid_rmsle: 0.01257 | valid_mae: 0.35801 | valid_rmse: 0.45559 | valid_mse: 0.20756 |  0:01:01s\n",
      "epoch 38 | loss: 0.17294 | train_rmsle: 0.01034 | train_mae: 0.32357 | train_rmse: 0.40896 | train_mse: 0.16724 | valid_rmsle: 0.0122  | valid_mae: 0.35586 | valid_rmse: 0.44908 | valid_mse: 0.20167 |  0:01:02s\n",
      "epoch 39 | loss: 0.16984 | train_rmsle: 0.0106  | train_mae: 0.32806 | train_rmse: 0.41408 | train_mse: 0.17146 | valid_rmsle: 0.01187 | valid_mae: 0.35102 | valid_rmse: 0.44402 | valid_mse: 0.19715 |  0:01:04s\n",
      "epoch 40 | loss: 0.1668  | train_rmsle: 0.01022 | train_mae: 0.3224  | train_rmse: 0.4075  | train_mse: 0.16605 | valid_rmsle: 0.01202 | valid_mae: 0.35449 | valid_rmse: 0.44704 | valid_mse: 0.19985 |  0:01:06s\n",
      "epoch 41 | loss: 0.16825 | train_rmsle: 0.01001 | train_mae: 0.32032 | train_rmse: 0.4046  | train_mse: 0.1637  | valid_rmsle: 0.01233 | valid_mae: 0.35823 | valid_rmse: 0.45301 | valid_mse: 0.20522 |  0:01:07s\n",
      "epoch 42 | loss: 0.16814 | train_rmsle: 0.01006 | train_mae: 0.32137 | train_rmse: 0.40506 | train_mse: 0.16407 | valid_rmsle: 0.01222 | valid_mae: 0.3562  | valid_rmse: 0.45153 | valid_mse: 0.20388 |  0:01:09s\n",
      "epoch 43 | loss: 0.16468 | train_rmsle: 0.00971 | train_mae: 0.31396 | train_rmse: 0.39839 | train_mse: 0.15871 | valid_rmsle: 0.01223 | valid_mae: 0.35348 | valid_rmse: 0.45047 | valid_mse: 0.20293 |  0:01:11s\n",
      "epoch 44 | loss: 0.16413 | train_rmsle: 0.01001 | train_mae: 0.31632 | train_rmse: 0.40267 | train_mse: 0.16214 | valid_rmsle: 0.01215 | valid_mae: 0.3523  | valid_rmse: 0.44836 | valid_mse: 0.20102 |  0:01:13s\n",
      "epoch 45 | loss: 0.165   | train_rmsle: 0.00968 | train_mae: 0.31897 | train_rmse: 0.40042 | train_mse: 0.16034 | valid_rmsle: 0.01198 | valid_mae: 0.35611 | valid_rmse: 0.4484  | valid_mse: 0.20106 |  0:01:14s\n",
      "epoch 46 | loss: 0.16109 | train_rmsle: 0.00956 | train_mae: 0.31298 | train_rmse: 0.39598 | train_mse: 0.1568  | valid_rmsle: 0.01236 | valid_mae: 0.35668 | valid_rmse: 0.45416 | valid_mse: 0.20626 |  0:01:16s\n",
      "epoch 47 | loss: 0.16132 | train_rmsle: 0.00965 | train_mae: 0.31145 | train_rmse: 0.39641 | train_mse: 0.15714 | valid_rmsle: 0.01199 | valid_mae: 0.3516  | valid_rmse: 0.44708 | valid_mse: 0.19988 |  0:01:18s\n",
      "epoch 48 | loss: 0.16133 | train_rmsle: 0.00928 | train_mae: 0.31071 | train_rmse: 0.39207 | train_mse: 0.15372 | valid_rmsle: 0.01169 | valid_mae: 0.35144 | valid_rmse: 0.44348 | valid_mse: 0.19667 |  0:01:20s\n",
      "epoch 49 | loss: 0.1579  | train_rmsle: 0.00914 | train_mae: 0.30926 | train_rmse: 0.38952 | train_mse: 0.15173 | valid_rmsle: 0.01168 | valid_mae: 0.35051 | valid_rmse: 0.44343 | valid_mse: 0.19663 |  0:01:21s\n",
      "epoch 50 | loss: 0.15586 | train_rmsle: 0.0091  | train_mae: 0.30764 | train_rmse: 0.38704 | train_mse: 0.1498  | valid_rmsle: 0.01153 | valid_mae: 0.34864 | valid_rmse: 0.44014 | valid_mse: 0.19372 |  0:01:23s\n",
      "epoch 51 | loss: 0.15493 | train_rmsle: 0.00893 | train_mae: 0.30381 | train_rmse: 0.38378 | train_mse: 0.14729 | valid_rmsle: 0.01156 | valid_mae: 0.3478  | valid_rmse: 0.44063 | valid_mse: 0.19416 |  0:01:25s\n",
      "epoch 52 | loss: 0.15413 | train_rmsle: 0.00927 | train_mae: 0.30619 | train_rmse: 0.3886  | train_mse: 0.15101 | valid_rmsle: 0.01175 | valid_mae: 0.34959 | valid_rmse: 0.44283 | valid_mse: 0.1961  |  0:01:27s\n",
      "epoch 53 | loss: 0.155   | train_rmsle: 0.00909 | train_mae: 0.30542 | train_rmse: 0.38535 | train_mse: 0.14849 | valid_rmsle: 0.01137 | valid_mae: 0.34575 | valid_rmse: 0.43647 | valid_mse: 0.19051 |  0:01:29s\n",
      "epoch 54 | loss: 0.1535  | train_rmsle: 0.00876 | train_mae: 0.29811 | train_rmse: 0.37945 | train_mse: 0.14398 | valid_rmsle: 0.01172 | valid_mae: 0.34703 | valid_rmse: 0.44217 | valid_mse: 0.19552 |  0:01:30s\n",
      "epoch 55 | loss: 0.14918 | train_rmsle: 0.00864 | train_mae: 0.29621 | train_rmse: 0.37633 | train_mse: 0.14163 | valid_rmsle: 0.01169 | valid_mae: 0.34724 | valid_rmse: 0.44261 | valid_mse: 0.1959  |  0:01:32s\n",
      "epoch 56 | loss: 0.14738 | train_rmsle: 0.0085  | train_mae: 0.29549 | train_rmse: 0.374   | train_mse: 0.13988 | valid_rmsle: 0.01201 | valid_mae: 0.35152 | valid_rmse: 0.44915 | valid_mse: 0.20173 |  0:01:34s\n",
      "epoch 57 | loss: 0.14836 | train_rmsle: 0.00845 | train_mae: 0.29151 | train_rmse: 0.3714  | train_mse: 0.13794 | valid_rmsle: 0.01224 | valid_mae: 0.35174 | valid_rmse: 0.45215 | valid_mse: 0.20444 |  0:01:36s\n",
      "epoch 58 | loss: 0.14695 | train_rmsle: 0.00841 | train_mae: 0.29357 | train_rmse: 0.37169 | train_mse: 0.13815 | valid_rmsle: 0.01203 | valid_mae: 0.35049 | valid_rmse: 0.44927 | valid_mse: 0.20185 |  0:01:37s\n",
      "epoch 59 | loss: 0.14739 | train_rmsle: 0.0084  | train_mae: 0.29145 | train_rmse: 0.37133 | train_mse: 0.13788 | valid_rmsle: 0.01182 | valid_mae: 0.34713 | valid_rmse: 0.44548 | valid_mse: 0.19845 |  0:01:39s\n",
      "epoch 60 | loss: 0.14271 | train_rmsle: 0.00875 | train_mae: 0.29875 | train_rmse: 0.37748 | train_mse: 0.14249 | valid_rmsle: 0.01191 | valid_mae: 0.35106 | valid_rmse: 0.44661 | valid_mse: 0.19946 |  0:01:41s\n",
      "epoch 61 | loss: 0.14315 | train_rmsle: 0.00813 | train_mae: 0.28721 | train_rmse: 0.36483 | train_mse: 0.1331  | valid_rmsle: 0.01153 | valid_mae: 0.3409  | valid_rmse: 0.4389  | valid_mse: 0.19264 |  0:01:43s\n",
      "epoch 62 | loss: 0.13933 | train_rmsle: 0.00785 | train_mae: 0.28362 | train_rmse: 0.35989 | train_mse: 0.12952 | valid_rmsle: 0.0113  | valid_mae: 0.33915 | valid_rmse: 0.43551 | valid_mse: 0.18967 |  0:01:44s\n",
      "epoch 63 | loss: 0.13559 | train_rmsle: 0.00781 | train_mae: 0.28237 | train_rmse: 0.35931 | train_mse: 0.12911 | valid_rmsle: 0.01121 | valid_mae: 0.34056 | valid_rmse: 0.43414 | valid_mse: 0.18848 |  0:01:46s\n",
      "epoch 64 | loss: 0.13693 | train_rmsle: 0.00785 | train_mae: 0.28276 | train_rmse: 0.36042 | train_mse: 0.1299  | valid_rmsle: 0.01125 | valid_mae: 0.33735 | valid_rmse: 0.43385 | valid_mse: 0.18823 |  0:01:48s\n",
      "epoch 65 | loss: 0.13724 | train_rmsle: 0.00773 | train_mae: 0.28159 | train_rmse: 0.35748 | train_mse: 0.12779 | valid_rmsle: 0.01087 | valid_mae: 0.33393 | valid_rmse: 0.42741 | valid_mse: 0.18268 |  0:01:50s\n",
      "epoch 66 | loss: 0.1336  | train_rmsle: 0.00765 | train_mae: 0.27922 | train_rmse: 0.35534 | train_mse: 0.12627 | valid_rmsle: 0.01056 | valid_mae: 0.32675 | valid_rmse: 0.42078 | valid_mse: 0.17705 |  0:01:51s\n",
      "epoch 67 | loss: 0.13177 | train_rmsle: 0.00751 | train_mae: 0.27476 | train_rmse: 0.35227 | train_mse: 0.1241  | valid_rmsle: 0.01112 | valid_mae: 0.33349 | valid_rmse: 0.4315  | valid_mse: 0.18619 |  0:01:53s\n",
      "epoch 68 | loss: 0.13095 | train_rmsle: 0.00731 | train_mae: 0.27261 | train_rmse: 0.34804 | train_mse: 0.12113 | valid_rmsle: 0.01078 | valid_mae: 0.32938 | valid_rmse: 0.4259  | valid_mse: 0.18139 |  0:01:55s\n",
      "epoch 69 | loss: 0.12718 | train_rmsle: 0.00743 | train_mae: 0.27074 | train_rmse: 0.34809 | train_mse: 0.12117 | valid_rmsle: 0.01072 | valid_mae: 0.3269  | valid_rmse: 0.42234 | valid_mse: 0.17837 |  0:01:57s\n",
      "epoch 70 | loss: 0.12793 | train_rmsle: 0.00753 | train_mae: 0.27257 | train_rmse: 0.34911 | train_mse: 0.12188 | valid_rmsle: 0.01085 | valid_mae: 0.33123 | valid_rmse: 0.423   | valid_mse: 0.17893 |  0:01:58s\n",
      "epoch 71 | loss: 0.12504 | train_rmsle: 0.00712 | train_mae: 0.27144 | train_rmse: 0.34395 | train_mse: 0.1183  | valid_rmsle: 0.01052 | valid_mae: 0.32825 | valid_rmse: 0.41888 | valid_mse: 0.17546 |  0:02:00s\n",
      "epoch 72 | loss: 0.12495 | train_rmsle: 0.00697 | train_mae: 0.26648 | train_rmse: 0.34031 | train_mse: 0.11581 | valid_rmsle: 0.0104  | valid_mae: 0.32694 | valid_rmse: 0.41696 | valid_mse: 0.17385 |  0:02:02s\n",
      "epoch 73 | loss: 0.12364 | train_rmsle: 0.00695 | train_mae: 0.26439 | train_rmse: 0.33794 | train_mse: 0.1142  | valid_rmsle: 0.01044 | valid_mae: 0.32522 | valid_rmse: 0.41664 | valid_mse: 0.17359 |  0:02:04s\n",
      "epoch 74 | loss: 0.11995 | train_rmsle: 0.00679 | train_mae: 0.26055 | train_rmse: 0.33438 | train_mse: 0.11181 | valid_rmsle: 0.01013 | valid_mae: 0.32282 | valid_rmse: 0.41256 | valid_mse: 0.17021 |  0:02:05s\n",
      "epoch 75 | loss: 0.11793 | train_rmsle: 0.00684 | train_mae: 0.26326 | train_rmse: 0.33556 | train_mse: 0.1126  | valid_rmsle: 0.01004 | valid_mae: 0.32274 | valid_rmse: 0.41044 | valid_mse: 0.16846 |  0:02:07s\n",
      "epoch 76 | loss: 0.11774 | train_rmsle: 0.00658 | train_mae: 0.25621 | train_rmse: 0.32829 | train_mse: 0.10777 | valid_rmsle: 0.01027 | valid_mae: 0.32241 | valid_rmse: 0.4153  | valid_mse: 0.17247 |  0:02:09s\n",
      "epoch 77 | loss: 0.11598 | train_rmsle: 0.00637 | train_mae: 0.2567  | train_rmse: 0.32657 | train_mse: 0.10665 | valid_rmsle: 0.00984 | valid_mae: 0.31557 | valid_rmse: 0.40735 | valid_mse: 0.16593 |  0:02:10s\n",
      "epoch 78 | loss: 0.11277 | train_rmsle: 0.00641 | train_mae: 0.2515  | train_rmse: 0.32427 | train_mse: 0.10515 | valid_rmsle: 0.00973 | valid_mae: 0.30943 | valid_rmse: 0.40272 | valid_mse: 0.16218 |  0:02:12s\n",
      "epoch 79 | loss: 0.11017 | train_rmsle: 0.00614 | train_mae: 0.25097 | train_rmse: 0.31994 | train_mse: 0.10236 | valid_rmsle: 0.00945 | valid_mae: 0.31005 | valid_rmse: 0.39889 | valid_mse: 0.15911 |  0:02:14s\n",
      "epoch 80 | loss: 0.10672 | train_rmsle: 0.00603 | train_mae: 0.24742 | train_rmse: 0.31631 | train_mse: 0.10005 | valid_rmsle: 0.00903 | valid_mae: 0.30142 | valid_rmse: 0.39009 | valid_mse: 0.15217 |  0:02:16s\n",
      "epoch 81 | loss: 0.1059  | train_rmsle: 0.00584 | train_mae: 0.245   | train_rmse: 0.31143 | train_mse: 0.09699 | valid_rmsle: 0.00892 | valid_mae: 0.30001 | valid_rmse: 0.3882  | valid_mse: 0.1507  |  0:02:17s\n",
      "epoch 82 | loss: 0.10171 | train_rmsle: 0.00561 | train_mae: 0.23846 | train_rmse: 0.30488 | train_mse: 0.09295 | valid_rmsle: 0.00862 | valid_mae: 0.29384 | valid_rmse: 0.38087 | valid_mse: 0.14506 |  0:02:19s\n",
      "epoch 83 | loss: 0.10168 | train_rmsle: 0.00534 | train_mae: 0.23016 | train_rmse: 0.29652 | train_mse: 0.08792 | valid_rmsle: 0.00829 | valid_mae: 0.28691 | valid_rmse: 0.37422 | valid_mse: 0.14004 |  0:02:21s\n",
      "epoch 84 | loss: 0.0949  | train_rmsle: 0.0052  | train_mae: 0.22766 | train_rmse: 0.29269 | train_mse: 0.08567 | valid_rmsle: 0.00795 | valid_mae: 0.28249 | valid_rmse: 0.3658  | valid_mse: 0.13381 |  0:02:22s\n",
      "epoch 85 | loss: 0.09209 | train_rmsle: 0.00519 | train_mae: 0.23175 | train_rmse: 0.29462 | train_mse: 0.0868  | valid_rmsle: 0.00777 | valid_mae: 0.28351 | valid_rmse: 0.36337 | valid_mse: 0.13204 |  0:02:23s\n",
      "epoch 86 | loss: 0.08962 | train_rmsle: 0.00486 | train_mae: 0.2197  | train_rmse: 0.28312 | train_mse: 0.08016 | valid_rmsle: 0.00748 | valid_mae: 0.27549 | valid_rmse: 0.35585 | valid_mse: 0.12663 |  0:02:25s\n",
      "epoch 87 | loss: 0.0891  | train_rmsle: 0.00466 | train_mae: 0.21467 | train_rmse: 0.27716 | train_mse: 0.07682 | valid_rmsle: 0.00736 | valid_mae: 0.27404 | valid_rmse: 0.35325 | valid_mse: 0.12479 |  0:02:26s\n",
      "epoch 88 | loss: 0.0841  | train_rmsle: 0.0045  | train_mae: 0.2108  | train_rmse: 0.27196 | train_mse: 0.07396 | valid_rmsle: 0.00706 | valid_mae: 0.26914 | valid_rmse: 0.34656 | valid_mse: 0.1201  |  0:02:28s\n",
      "epoch 89 | loss: 0.08189 | train_rmsle: 0.00436 | train_mae: 0.20695 | train_rmse: 0.26784 | train_mse: 0.07174 | valid_rmsle: 0.00678 | valid_mae: 0.26465 | valid_rmse: 0.34069 | valid_mse: 0.11607 |  0:02:29s\n",
      "epoch 90 | loss: 0.07952 | train_rmsle: 0.0042  | train_mae: 0.20149 | train_rmse: 0.26197 | train_mse: 0.06863 | valid_rmsle: 0.00665 | valid_mae: 0.26204 | valid_rmse: 0.33741 | valid_mse: 0.11385 |  0:02:31s\n",
      "epoch 91 | loss: 0.07689 | train_rmsle: 0.0041  | train_mae: 0.19904 | train_rmse: 0.2588  | train_mse: 0.06698 | valid_rmsle: 0.00655 | valid_mae: 0.26183 | valid_rmse: 0.3351  | valid_mse: 0.11229 |  0:02:32s\n",
      "epoch 92 | loss: 0.07573 | train_rmsle: 0.00413 | train_mae: 0.20555 | train_rmse: 0.26236 | train_mse: 0.06883 | valid_rmsle: 0.00683 | valid_mae: 0.26625 | valid_rmse: 0.34297 | valid_mse: 0.11763 |  0:02:34s\n",
      "epoch 93 | loss: 0.07492 | train_rmsle: 0.00391 | train_mae: 0.19684 | train_rmse: 0.25383 | train_mse: 0.06443 | valid_rmsle: 0.00638 | valid_mae: 0.25675 | valid_rmse: 0.33077 | valid_mse: 0.10941 |  0:02:36s\n",
      "epoch 94 | loss: 0.07247 | train_rmsle: 0.00382 | train_mae: 0.19183 | train_rmse: 0.25025 | train_mse: 0.06263 | valid_rmsle: 0.00626 | valid_mae: 0.25453 | valid_rmse: 0.32774 | valid_mse: 0.10742 |  0:02:37s\n",
      "epoch 95 | loss: 0.07111 | train_rmsle: 0.00371 | train_mae: 0.18989 | train_rmse: 0.24638 | train_mse: 0.0607  | valid_rmsle: 0.00604 | valid_mae: 0.25131 | valid_rmse: 0.32294 | valid_mse: 0.10429 |  0:02:39s\n",
      "epoch 96 | loss: 0.06898 | train_rmsle: 0.00366 | train_mae: 0.1903  | train_rmse: 0.24617 | train_mse: 0.0606  | valid_rmsle: 0.00614 | valid_mae: 0.25318 | valid_rmse: 0.32649 | valid_mse: 0.1066  |  0:02:41s\n",
      "epoch 97 | loss: 0.06829 | train_rmsle: 0.00372 | train_mae: 0.18806 | train_rmse: 0.24591 | train_mse: 0.06047 | valid_rmsle: 0.00614 | valid_mae: 0.25081 | valid_rmse: 0.3261  | valid_mse: 0.10634 |  0:02:42s\n",
      "epoch 98 | loss: 0.06792 | train_rmsle: 0.00347 | train_mae: 0.18459 | train_rmse: 0.23952 | train_mse: 0.05737 | valid_rmsle: 0.00586 | valid_mae: 0.24833 | valid_rmse: 0.31891 | valid_mse: 0.10171 |  0:02:44s\n",
      "epoch 99 | loss: 0.06517 | train_rmsle: 0.00342 | train_mae: 0.18609 | train_rmse: 0.23935 | train_mse: 0.05729 | valid_rmsle: 0.0058  | valid_mae: 0.24831 | valid_rmse: 0.31843 | valid_mse: 0.1014  |  0:02:45s\n",
      "epoch 100| loss: 0.06371 | train_rmsle: 0.00327 | train_mae: 0.17871 | train_rmse: 0.2322  | train_mse: 0.05392 | valid_rmsle: 0.00562 | valid_mae: 0.24504 | valid_rmse: 0.31272 | valid_mse: 0.0978  |  0:02:47s\n",
      "epoch 101| loss: 0.06214 | train_rmsle: 0.00314 | train_mae: 0.17433 | train_rmse: 0.22762 | train_mse: 0.05181 | valid_rmsle: 0.00547 | valid_mae: 0.24268 | valid_rmse: 0.30863 | valid_mse: 0.09525 |  0:02:48s\n",
      "epoch 102| loss: 0.05972 | train_rmsle: 0.00325 | train_mae: 0.18172 | train_rmse: 0.23347 | train_mse: 0.05451 | valid_rmsle: 0.00558 | valid_mae: 0.24619 | valid_rmse: 0.31225 | valid_mse: 0.0975  |  0:02:50s\n",
      "epoch 103| loss: 0.0615  | train_rmsle: 0.00303 | train_mae: 0.17432 | train_rmse: 0.22523 | train_mse: 0.05073 | valid_rmsle: 0.00546 | valid_mae: 0.24203 | valid_rmse: 0.30835 | valid_mse: 0.09508 |  0:02:51s\n",
      "epoch 104| loss: 0.06051 | train_rmsle: 0.00287 | train_mae: 0.1663  | train_rmse: 0.21737 | train_mse: 0.04725 | valid_rmsle: 0.00515 | valid_mae: 0.2346  | valid_rmse: 0.29896 | valid_mse: 0.08938 |  0:02:53s\n",
      "epoch 105| loss: 0.05674 | train_rmsle: 0.00292 | train_mae: 0.17157 | train_rmse: 0.22195 | train_mse: 0.04926 | valid_rmsle: 0.00526 | valid_mae: 0.23787 | valid_rmse: 0.30377 | valid_mse: 0.09227 |  0:02:55s\n",
      "epoch 106| loss: 0.05521 | train_rmsle: 0.00276 | train_mae: 0.16319 | train_rmse: 0.21335 | train_mse: 0.04552 | valid_rmsle: 0.005   | valid_mae: 0.23238 | valid_rmse: 0.29542 | valid_mse: 0.08727 |  0:02:56s\n",
      "epoch 107| loss: 0.05424 | train_rmsle: 0.0027  | train_mae: 0.16127 | train_rmse: 0.2113  | train_mse: 0.04465 | valid_rmsle: 0.0049  | valid_mae: 0.23046 | valid_rmse: 0.29301 | valid_mse: 0.08585 |  0:02:58s\n",
      "epoch 108| loss: 0.05436 | train_rmsle: 0.00271 | train_mae: 0.15996 | train_rmse: 0.21084 | train_mse: 0.04445 | valid_rmsle: 0.00494 | valid_mae: 0.23159 | valid_rmse: 0.29415 | valid_mse: 0.08652 |  0:03:00s\n",
      "epoch 109| loss: 0.05435 | train_rmsle: 0.00263 | train_mae: 0.16012 | train_rmse: 0.20929 | train_mse: 0.0438  | valid_rmsle: 0.00483 | valid_mae: 0.22912 | valid_rmse: 0.29161 | valid_mse: 0.08504 |  0:03:02s\n",
      "epoch 110| loss: 0.05151 | train_rmsle: 0.00256 | train_mae: 0.15561 | train_rmse: 0.20516 | train_mse: 0.04209 | valid_rmsle: 0.00476 | valid_mae: 0.22784 | valid_rmse: 0.28901 | valid_mse: 0.08353 |  0:03:03s\n",
      "epoch 111| loss: 0.04961 | train_rmsle: 0.00267 | train_mae: 0.15547 | train_rmse: 0.20607 | train_mse: 0.04246 | valid_rmsle: 0.00488 | valid_mae: 0.22904 | valid_rmse: 0.29096 | valid_mse: 0.08466 |  0:03:05s\n",
      "epoch 112| loss: 0.04929 | train_rmsle: 0.00241 | train_mae: 0.1519  | train_rmse: 0.19966 | train_mse: 0.03987 | valid_rmsle: 0.00463 | valid_mae: 0.22517 | valid_rmse: 0.28571 | valid_mse: 0.08163 |  0:03:07s\n",
      "epoch 113| loss: 0.04828 | train_rmsle: 0.00229 | train_mae: 0.14812 | train_rmse: 0.19505 | train_mse: 0.03804 | valid_rmsle: 0.0046  | valid_mae: 0.22338 | valid_rmse: 0.2849  | valid_mse: 0.08117 |  0:03:09s\n",
      "epoch 114| loss: 0.04693 | train_rmsle: 0.00227 | train_mae: 0.14922 | train_rmse: 0.19486 | train_mse: 0.03797 | valid_rmsle: 0.00457 | valid_mae: 0.22472 | valid_rmse: 0.28424 | valid_mse: 0.0808  |  0:03:10s\n",
      "epoch 115| loss: 0.04517 | train_rmsle: 0.00213 | train_mae: 0.14281 | train_rmse: 0.18834 | train_mse: 0.03547 | valid_rmsle: 0.00446 | valid_mae: 0.219   | valid_rmse: 0.28114 | valid_mse: 0.07904 |  0:03:12s\n",
      "epoch 116| loss: 0.04574 | train_rmsle: 0.00215 | train_mae: 0.14426 | train_rmse: 0.18987 | train_mse: 0.03605 | valid_rmsle: 0.00458 | valid_mae: 0.22295 | valid_rmse: 0.2853  | valid_mse: 0.0814  |  0:03:14s\n",
      "epoch 117| loss: 0.04423 | train_rmsle: 0.00205 | train_mae: 0.13997 | train_rmse: 0.18485 | train_mse: 0.03417 | valid_rmsle: 0.00441 | valid_mae: 0.21836 | valid_rmse: 0.27874 | valid_mse: 0.0777  |  0:03:16s\n",
      "epoch 118| loss: 0.04243 | train_rmsle: 0.00201 | train_mae: 0.1387  | train_rmse: 0.18362 | train_mse: 0.03371 | valid_rmsle: 0.00442 | valid_mae: 0.218   | valid_rmse: 0.27969 | valid_mse: 0.07823 |  0:03:17s\n",
      "epoch 119| loss: 0.0418  | train_rmsle: 0.00199 | train_mae: 0.13812 | train_rmse: 0.18262 | train_mse: 0.03335 | valid_rmsle: 0.00432 | valid_mae: 0.2167  | valid_rmse: 0.2769  | valid_mse: 0.07667 |  0:03:19s\n",
      "epoch 120| loss: 0.04338 | train_rmsle: 0.00201 | train_mae: 0.13976 | train_rmse: 0.18424 | train_mse: 0.03395 | valid_rmsle: 0.00437 | valid_mae: 0.21755 | valid_rmse: 0.2789  | valid_mse: 0.07778 |  0:03:21s\n",
      "epoch 121| loss: 0.04133 | train_rmsle: 0.00199 | train_mae: 0.13895 | train_rmse: 0.18383 | train_mse: 0.03379 | valid_rmsle: 0.00438 | valid_mae: 0.21662 | valid_rmse: 0.27879 | valid_mse: 0.07773 |  0:03:23s\n",
      "epoch 122| loss: 0.04068 | train_rmsle: 0.00185 | train_mae: 0.13286 | train_rmse: 0.17648 | train_mse: 0.03114 | valid_rmsle: 0.00421 | valid_mae: 0.21307 | valid_rmse: 0.27308 | valid_mse: 0.07457 |  0:03:24s\n",
      "epoch 123| loss: 0.0403  | train_rmsle: 0.00183 | train_mae: 0.13087 | train_rmse: 0.17427 | train_mse: 0.03037 | valid_rmsle: 0.00407 | valid_mae: 0.20983 | valid_rmse: 0.26888 | valid_mse: 0.0723  |  0:03:26s\n",
      "epoch 124| loss: 0.03902 | train_rmsle: 0.00176 | train_mae: 0.12893 | train_rmse: 0.17176 | train_mse: 0.0295  | valid_rmsle: 0.00402 | valid_mae: 0.2069  | valid_rmse: 0.26799 | valid_mse: 0.07182 |  0:03:28s\n",
      "epoch 125| loss: 0.0391  | train_rmsle: 0.00174 | train_mae: 0.12956 | train_rmse: 0.1716  | train_mse: 0.02945 | valid_rmsle: 0.00392 | valid_mae: 0.20599 | valid_rmse: 0.26519 | valid_mse: 0.07032 |  0:03:30s\n",
      "epoch 126| loss: 0.03787 | train_rmsle: 0.00168 | train_mae: 0.12484 | train_rmse: 0.16731 | train_mse: 0.02799 | valid_rmsle: 0.0039  | valid_mae: 0.2038  | valid_rmse: 0.26389 | valid_mse: 0.06964 |  0:03:31s\n",
      "epoch 127| loss: 0.03765 | train_rmsle: 0.00165 | train_mae: 0.12383 | train_rmse: 0.16593 | train_mse: 0.02753 | valid_rmsle: 0.00383 | valid_mae: 0.20251 | valid_rmse: 0.26219 | valid_mse: 0.06874 |  0:03:33s\n",
      "epoch 128| loss: 0.0366  | train_rmsle: 0.00163 | train_mae: 0.12399 | train_rmse: 0.16585 | train_mse: 0.02751 | valid_rmsle: 0.00382 | valid_mae: 0.2032  | valid_rmse: 0.26192 | valid_mse: 0.0686  |  0:03:35s\n",
      "epoch 129| loss: 0.03582 | train_rmsle: 0.00162 | train_mae: 0.1232  | train_rmse: 0.164   | train_mse: 0.0269  | valid_rmsle: 0.00379 | valid_mae: 0.20197 | valid_rmse: 0.2601  | valid_mse: 0.06765 |  0:03:37s\n",
      "epoch 130| loss: 0.03519 | train_rmsle: 0.00157 | train_mae: 0.12293 | train_rmse: 0.16325 | train_mse: 0.02665 | valid_rmsle: 0.00372 | valid_mae: 0.20092 | valid_rmse: 0.25928 | valid_mse: 0.06723 |  0:03:38s\n",
      "epoch 131| loss: 0.03423 | train_rmsle: 0.00149 | train_mae: 0.11779 | train_rmse: 0.15762 | train_mse: 0.02484 | valid_rmsle: 0.00373 | valid_mae: 0.1991  | valid_rmse: 0.25961 | valid_mse: 0.0674  |  0:03:40s\n",
      "epoch 132| loss: 0.03502 | train_rmsle: 0.00153 | train_mae: 0.11891 | train_rmse: 0.15952 | train_mse: 0.02545 | valid_rmsle: 0.00367 | valid_mae: 0.19579 | valid_rmse: 0.25741 | valid_mse: 0.06626 |  0:03:42s\n",
      "epoch 133| loss: 0.03312 | train_rmsle: 0.00142 | train_mae: 0.11509 | train_rmse: 0.15381 | train_mse: 0.02366 | valid_rmsle: 0.00356 | valid_mae: 0.19273 | valid_rmse: 0.25324 | valid_mse: 0.06413 |  0:03:44s\n",
      "epoch 134| loss: 0.03292 | train_rmsle: 0.00138 | train_mae: 0.11378 | train_rmse: 0.15252 | train_mse: 0.02326 | valid_rmsle: 0.00358 | valid_mae: 0.19462 | valid_rmse: 0.25417 | valid_mse: 0.0646  |  0:03:45s\n",
      "epoch 135| loss: 0.03258 | train_rmsle: 0.00138 | train_mae: 0.11309 | train_rmse: 0.15146 | train_mse: 0.02294 | valid_rmsle: 0.0035  | valid_mae: 0.19253 | valid_rmse: 0.25153 | valid_mse: 0.06327 |  0:03:47s\n",
      "epoch 136| loss: 0.03154 | train_rmsle: 0.00136 | train_mae: 0.11273 | train_rmse: 0.15079 | train_mse: 0.02274 | valid_rmsle: 0.00357 | valid_mae: 0.1933  | valid_rmse: 0.25474 | valid_mse: 0.06489 |  0:03:49s\n",
      "epoch 137| loss: 0.03217 | train_rmsle: 0.00141 | train_mae: 0.11623 | train_rmse: 0.15395 | train_mse: 0.0237  | valid_rmsle: 0.00363 | valid_mae: 0.19577 | valid_rmse: 0.25688 | valid_mse: 0.06599 |  0:03:51s\n",
      "epoch 138| loss: 0.03201 | train_rmsle: 0.00143 | train_mae: 0.11675 | train_rmse: 0.15632 | train_mse: 0.02444 | valid_rmsle: 0.00335 | valid_mae: 0.18841 | valid_rmse: 0.24606 | valid_mse: 0.06054 |  0:03:52s\n",
      "epoch 139| loss: 0.03349 | train_rmsle: 0.00143 | train_mae: 0.11811 | train_rmse: 0.15762 | train_mse: 0.02484 | valid_rmsle: 0.00322 | valid_mae: 0.1844  | valid_rmse: 0.24242 | valid_mse: 0.05877 |  0:03:54s\n",
      "epoch 140| loss: 0.03255 | train_rmsle: 0.00137 | train_mae: 0.11487 | train_rmse: 0.15354 | train_mse: 0.02357 | valid_rmsle: 0.00328 | valid_mae: 0.18468 | valid_rmse: 0.24627 | valid_mse: 0.06065 |  0:03:56s\n",
      "epoch 141| loss: 0.03222 | train_rmsle: 0.00137 | train_mae: 0.11573 | train_rmse: 0.15324 | train_mse: 0.02348 | valid_rmsle: 0.00338 | valid_mae: 0.18762 | valid_rmse: 0.24891 | valid_mse: 0.06195 |  0:03:58s\n",
      "epoch 142| loss: 0.03126 | train_rmsle: 0.00134 | train_mae: 0.114   | train_rmse: 0.15233 | train_mse: 0.0232  | valid_rmsle: 0.00334 | valid_mae: 0.18456 | valid_rmse: 0.24582 | valid_mse: 0.06043 |  0:03:59s\n",
      "epoch 143| loss: 0.03064 | train_rmsle: 0.00127 | train_mae: 0.10983 | train_rmse: 0.14665 | train_mse: 0.02151 | valid_rmsle: 0.00318 | valid_mae: 0.18083 | valid_rmse: 0.24052 | valid_mse: 0.05785 |  0:04:01s\n",
      "epoch 144| loss: 0.03152 | train_rmsle: 0.00129 | train_mae: 0.11011 | train_rmse: 0.1468  | train_mse: 0.02155 | valid_rmsle: 0.00312 | valid_mae: 0.17854 | valid_rmse: 0.23707 | valid_mse: 0.0562  |  0:04:03s\n",
      "epoch 145| loss: 0.02961 | train_rmsle: 0.00124 | train_mae: 0.10895 | train_rmse: 0.14564 | train_mse: 0.02121 | valid_rmsle: 0.00307 | valid_mae: 0.17848 | valid_rmse: 0.23621 | valid_mse: 0.0558  |  0:04:04s\n",
      "epoch 146| loss: 0.02946 | train_rmsle: 0.00121 | train_mae: 0.10684 | train_rmse: 0.14287 | train_mse: 0.02041 | valid_rmsle: 0.0031  | valid_mae: 0.17903 | valid_rmse: 0.23695 | valid_mse: 0.05615 |  0:04:06s\n",
      "epoch 147| loss: 0.02875 | train_rmsle: 0.00127 | train_mae: 0.11328 | train_rmse: 0.14865 | train_mse: 0.0221  | valid_rmsle: 0.00331 | valid_mae: 0.18741 | valid_rmse: 0.24622 | valid_mse: 0.06063 |  0:04:07s\n",
      "epoch 148| loss: 0.02941 | train_rmsle: 0.00116 | train_mae: 0.1054  | train_rmse: 0.1408  | train_mse: 0.01982 | valid_rmsle: 0.00321 | valid_mae: 0.18151 | valid_rmse: 0.24081 | valid_mse: 0.05799 |  0:04:09s\n",
      "epoch 149| loss: 0.02802 | train_rmsle: 0.0011  | train_mae: 0.1025  | train_rmse: 0.13721 | train_mse: 0.01883 | valid_rmsle: 0.0031  | valid_mae: 0.17646 | valid_rmse: 0.23684 | valid_mse: 0.05609 |  0:04:10s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 145 and best_valid_mse = 0.0558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.058816835231693135 RMSE: 0.24252182423792942 R2: 0.7396405336484162 MAE: 0.19051031131824384\n",
      "=====================================\n",
      "[12/108] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 9.14894 | train_rmsle: 0.95472 | train_mae: 2.66229 | train_rmse: 2.70621 | train_mse: 7.32358 | valid_rmsle: 0.95763 | valid_mae: 2.66884 | valid_rmse: 2.71175 | valid_mse: 7.35359 |  0:00:01s\n",
      "epoch 1  | loss: 3.52886 | train_rmsle: 0.30831 | train_mae: 1.80452 | train_rmse: 1.86792 | train_mse: 3.48912 | valid_rmsle: 0.3095  | valid_mae: 1.81071 | valid_rmse: 1.87254 | valid_mse: 3.5064  |  0:00:03s\n",
      "epoch 2  | loss: 1.55188 | train_rmsle: 0.14655 | train_mae: 1.3268  | train_rmse: 1.40682 | train_mse: 1.97916 | valid_rmsle: 0.1473  | valid_mae: 1.33179 | valid_rmse: 1.41128 | valid_mse: 1.99171 |  0:00:05s\n",
      "epoch 3  | loss: 0.70925 | train_rmsle: 0.06887 | train_mae: 0.93878 | train_rmse: 1.03125 | train_mse: 1.06347 | valid_rmsle: 0.06926 | valid_mae: 0.94229 | valid_rmse: 1.03558 | valid_mse: 1.07242 |  0:00:06s\n",
      "epoch 4  | loss: 0.40886 | train_rmsle: 0.04051 | train_mae: 0.72427 | train_rmse: 0.81814 | train_mse: 0.66935 | valid_rmsle: 0.04063 | valid_mae: 0.72518 | valid_rmse: 0.8217  | valid_mse: 0.6752  |  0:00:08s\n",
      "epoch 5  | loss: 0.31605 | train_rmsle: 0.03075 | train_mae: 0.62907 | train_rmse: 0.72144 | train_mse: 0.52048 | valid_rmsle: 0.03075 | valid_mae: 0.63021 | valid_rmse: 0.72443 | valid_mse: 0.5248  |  0:00:10s\n",
      "epoch 6  | loss: 0.27925 | train_rmsle: 0.02516 | train_mae: 0.56515 | train_rmse: 0.65604 | train_mse: 0.43038 | valid_rmsle: 0.02502 | valid_mae: 0.56658 | valid_rmse: 0.65782 | valid_mse: 0.43273 |  0:00:12s\n",
      "epoch 7  | loss: 0.26245 | train_rmsle: 0.0208  | train_mae: 0.50775 | train_rmse: 0.59675 | train_mse: 0.35611 | valid_rmsle: 0.02051 | valid_mae: 0.50884 | valid_rmse: 0.59693 | valid_mse: 0.35632 |  0:00:13s\n",
      "epoch 8  | loss: 0.25001 | train_rmsle: 0.02053 | train_mae: 0.50376 | train_rmse: 0.59302 | train_mse: 0.35167 | valid_rmsle: 0.02022 | valid_mae: 0.50437 | valid_rmse: 0.59295 | valid_mse: 0.35159 |  0:00:15s\n",
      "epoch 9  | loss: 0.24403 | train_rmsle: 0.01557 | train_mae: 0.41802 | train_rmse: 0.50829 | train_mse: 0.25836 | valid_rmsle: 0.0151  | valid_mae: 0.41995 | valid_rmse: 0.50581 | valid_mse: 0.25585 |  0:00:17s\n",
      "epoch 10 | loss: 0.23693 | train_rmsle: 0.01622 | train_mae: 0.43131 | train_rmse: 0.52082 | train_mse: 0.27125 | valid_rmsle: 0.01572 | valid_mae: 0.43165 | valid_rmse: 0.51765 | valid_mse: 0.26796 |  0:00:19s\n",
      "epoch 11 | loss: 0.23232 | train_rmsle: 0.01608 | train_mae: 0.42992 | train_rmse: 0.5195  | train_mse: 0.26988 | valid_rmsle: 0.01565 | valid_mae: 0.43023 | valid_rmse: 0.51727 | valid_mse: 0.26757 |  0:00:20s\n",
      "epoch 12 | loss: 0.22978 | train_rmsle: 0.01497 | train_mae: 0.40919 | train_rmse: 0.49919 | train_mse: 0.24919 | valid_rmsle: 0.01452 | valid_mae: 0.41056 | valid_rmse: 0.49673 | valid_mse: 0.24674 |  0:00:22s\n",
      "epoch 13 | loss: 0.22859 | train_rmsle: 0.01457 | train_mae: 0.40311 | train_rmse: 0.49235 | train_mse: 0.2424  | valid_rmsle: 0.01416 | valid_mae: 0.40409 | valid_rmse: 0.49032 | valid_mse: 0.24042 |  0:00:24s\n",
      "epoch 14 | loss: 0.22318 | train_rmsle: 0.01422 | train_mae: 0.39902 | train_rmse: 0.48732 | train_mse: 0.23748 | valid_rmsle: 0.01372 | valid_mae: 0.39836 | valid_rmse: 0.48375 | valid_mse: 0.23401 |  0:00:26s\n",
      "epoch 15 | loss: 0.21981 | train_rmsle: 0.01351 | train_mae: 0.37993 | train_rmse: 0.46962 | train_mse: 0.22055 | valid_rmsle: 0.01291 | valid_mae: 0.37937 | valid_rmse: 0.46437 | valid_mse: 0.21564 |  0:00:27s\n",
      "epoch 16 | loss: 0.21685 | train_rmsle: 0.01335 | train_mae: 0.37209 | train_rmse: 0.4645  | train_mse: 0.21576 | valid_rmsle: 0.01264 | valid_mae: 0.37031 | valid_rmse: 0.45745 | valid_mse: 0.20926 |  0:00:29s\n",
      "epoch 17 | loss: 0.21433 | train_rmsle: 0.01335 | train_mae: 0.37696 | train_rmse: 0.46798 | train_mse: 0.21901 | valid_rmsle: 0.01279 | valid_mae: 0.377   | valid_rmse: 0.46301 | valid_mse: 0.21438 |  0:00:31s\n",
      "epoch 18 | loss: 0.21253 | train_rmsle: 0.01391 | train_mae: 0.3905  | train_rmse: 0.47979 | train_mse: 0.2302  | valid_rmsle: 0.01341 | valid_mae: 0.39066 | valid_rmse: 0.47666 | valid_mse: 0.2272  |  0:00:33s\n",
      "epoch 19 | loss: 0.21107 | train_rmsle: 0.01354 | train_mae: 0.38358 | train_rmse: 0.47188 | train_mse: 0.22267 | valid_rmsle: 0.01305 | valid_mae: 0.38424 | valid_rmse: 0.46818 | valid_mse: 0.21919 |  0:00:34s\n",
      "epoch 20 | loss: 0.20883 | train_rmsle: 0.01341 | train_mae: 0.38077 | train_rmse: 0.47015 | train_mse: 0.22104 | valid_rmsle: 0.01297 | valid_mae: 0.38206 | valid_rmse: 0.46722 | valid_mse: 0.21829 |  0:00:36s\n",
      "epoch 21 | loss: 0.20597 | train_rmsle: 0.01365 | train_mae: 0.38767 | train_rmse: 0.47727 | train_mse: 0.22779 | valid_rmsle: 0.01341 | valid_mae: 0.38925 | valid_rmse: 0.47761 | valid_mse: 0.22811 |  0:00:38s\n",
      "epoch 22 | loss: 0.2075  | train_rmsle: 0.01316 | train_mae: 0.37665 | train_rmse: 0.4665  | train_mse: 0.21762 | valid_rmsle: 0.01285 | valid_mae: 0.37691 | valid_rmse: 0.46526 | valid_mse: 0.21646 |  0:00:39s\n",
      "epoch 23 | loss: 0.2035  | train_rmsle: 0.013   | train_mae: 0.37563 | train_rmse: 0.46496 | train_mse: 0.21619 | valid_rmsle: 0.01292 | valid_mae: 0.37861 | valid_rmse: 0.46814 | valid_mse: 0.21916 |  0:00:41s\n",
      "epoch 24 | loss: 0.1988  | train_rmsle: 0.01264 | train_mae: 0.36296 | train_rmse: 0.45469 | train_mse: 0.20674 | valid_rmsle: 0.01226 | valid_mae: 0.36426 | valid_rmse: 0.45303 | valid_mse: 0.20523 |  0:00:43s\n",
      "epoch 25 | loss: 0.19958 | train_rmsle: 0.01248 | train_mae: 0.35944 | train_rmse: 0.45037 | train_mse: 0.20283 | valid_rmsle: 0.01235 | valid_mae: 0.36245 | valid_rmse: 0.45296 | valid_mse: 0.20517 |  0:00:44s\n",
      "epoch 26 | loss: 0.19509 | train_rmsle: 0.01242 | train_mae: 0.3553  | train_rmse: 0.44722 | train_mse: 0.2     | valid_rmsle: 0.01246 | valid_mae: 0.36422 | valid_rmse: 0.4533  | valid_mse: 0.20548 |  0:00:46s\n",
      "epoch 27 | loss: 0.1926  | train_rmsle: 0.01217 | train_mae: 0.35139 | train_rmse: 0.44336 | train_mse: 0.19656 | valid_rmsle: 0.01213 | valid_mae: 0.35812 | valid_rmse: 0.44794 | valid_mse: 0.20065 |  0:00:48s\n",
      "epoch 28 | loss: 0.19264 | train_rmsle: 0.0119  | train_mae: 0.35583 | train_rmse: 0.44222 | train_mse: 0.19556 | valid_rmsle: 0.01232 | valid_mae: 0.36346 | valid_rmse: 0.45487 | valid_mse: 0.2069  |  0:00:50s\n",
      "epoch 29 | loss: 0.18883 | train_rmsle: 0.01174 | train_mae: 0.35272 | train_rmse: 0.43963 | train_mse: 0.19328 | valid_rmsle: 0.01224 | valid_mae: 0.36446 | valid_rmse: 0.45386 | valid_mse: 0.20599 |  0:00:51s\n",
      "epoch 30 | loss: 0.18683 | train_rmsle: 0.01153 | train_mae: 0.347   | train_rmse: 0.43462 | train_mse: 0.1889  | valid_rmsle: 0.01192 | valid_mae: 0.35739 | valid_rmse: 0.44684 | valid_mse: 0.19967 |  0:00:53s\n",
      "epoch 31 | loss: 0.18553 | train_rmsle: 0.0114  | train_mae: 0.34493 | train_rmse: 0.43126 | train_mse: 0.18598 | valid_rmsle: 0.0123  | valid_mae: 0.36448 | valid_rmse: 0.45291 | valid_mse: 0.20513 |  0:00:55s\n",
      "epoch 32 | loss: 0.18187 | train_rmsle: 0.01117 | train_mae: 0.34012 | train_rmse: 0.42788 | train_mse: 0.18308 | valid_rmsle: 0.01208 | valid_mae: 0.35911 | valid_rmse: 0.45024 | valid_mse: 0.20271 |  0:00:56s\n",
      "epoch 33 | loss: 0.17885 | train_rmsle: 0.01122 | train_mae: 0.34132 | train_rmse: 0.42914 | train_mse: 0.18416 | valid_rmsle: 0.01196 | valid_mae: 0.36055 | valid_rmse: 0.44898 | valid_mse: 0.20158 |  0:00:58s\n",
      "epoch 34 | loss: 0.17912 | train_rmsle: 0.01095 | train_mae: 0.3393  | train_rmse: 0.42427 | train_mse: 0.18001 | valid_rmsle: 0.01216 | valid_mae: 0.36174 | valid_rmse: 0.45231 | valid_mse: 0.20458 |  0:01:00s\n",
      "epoch 35 | loss: 0.17623 | train_rmsle: 0.01061 | train_mae: 0.32911 | train_rmse: 0.41526 | train_mse: 0.17244 | valid_rmsle: 0.01201 | valid_mae: 0.35523 | valid_rmse: 0.44783 | valid_mse: 0.20055 |  0:01:02s\n",
      "epoch 36 | loss: 0.17318 | train_rmsle: 0.01065 | train_mae: 0.33378 | train_rmse: 0.41807 | train_mse: 0.17478 | valid_rmsle: 0.0121  | valid_mae: 0.35764 | valid_rmse: 0.44976 | valid_mse: 0.20228 |  0:01:03s\n",
      "epoch 37 | loss: 0.17188 | train_rmsle: 0.01078 | train_mae: 0.3286  | train_rmse: 0.41717 | train_mse: 0.17403 | valid_rmsle: 0.01257 | valid_mae: 0.35801 | valid_rmse: 0.45559 | valid_mse: 0.20756 |  0:01:05s\n",
      "epoch 38 | loss: 0.17294 | train_rmsle: 0.01034 | train_mae: 0.32357 | train_rmse: 0.40896 | train_mse: 0.16724 | valid_rmsle: 0.0122  | valid_mae: 0.35586 | valid_rmse: 0.44908 | valid_mse: 0.20167 |  0:01:07s\n",
      "epoch 39 | loss: 0.16984 | train_rmsle: 0.0106  | train_mae: 0.32806 | train_rmse: 0.41408 | train_mse: 0.17146 | valid_rmsle: 0.01187 | valid_mae: 0.35102 | valid_rmse: 0.44402 | valid_mse: 0.19715 |  0:01:09s\n",
      "epoch 40 | loss: 0.1668  | train_rmsle: 0.01022 | train_mae: 0.3224  | train_rmse: 0.4075  | train_mse: 0.16605 | valid_rmsle: 0.01202 | valid_mae: 0.35449 | valid_rmse: 0.44704 | valid_mse: 0.19985 |  0:01:10s\n",
      "epoch 41 | loss: 0.16825 | train_rmsle: 0.01001 | train_mae: 0.32032 | train_rmse: 0.4046  | train_mse: 0.1637  | valid_rmsle: 0.01233 | valid_mae: 0.35823 | valid_rmse: 0.45301 | valid_mse: 0.20522 |  0:01:12s\n",
      "epoch 42 | loss: 0.16814 | train_rmsle: 0.01006 | train_mae: 0.32137 | train_rmse: 0.40506 | train_mse: 0.16407 | valid_rmsle: 0.01222 | valid_mae: 0.3562  | valid_rmse: 0.45153 | valid_mse: 0.20388 |  0:01:13s\n",
      "epoch 43 | loss: 0.16468 | train_rmsle: 0.00971 | train_mae: 0.31396 | train_rmse: 0.39839 | train_mse: 0.15871 | valid_rmsle: 0.01223 | valid_mae: 0.35348 | valid_rmse: 0.45047 | valid_mse: 0.20293 |  0:01:15s\n",
      "epoch 44 | loss: 0.16413 | train_rmsle: 0.01001 | train_mae: 0.31632 | train_rmse: 0.40267 | train_mse: 0.16214 | valid_rmsle: 0.01215 | valid_mae: 0.3523  | valid_rmse: 0.44836 | valid_mse: 0.20102 |  0:01:16s\n",
      "epoch 45 | loss: 0.165   | train_rmsle: 0.00968 | train_mae: 0.31897 | train_rmse: 0.40042 | train_mse: 0.16034 | valid_rmsle: 0.01198 | valid_mae: 0.35611 | valid_rmse: 0.4484  | valid_mse: 0.20106 |  0:01:18s\n",
      "epoch 46 | loss: 0.16109 | train_rmsle: 0.00956 | train_mae: 0.31298 | train_rmse: 0.39598 | train_mse: 0.1568  | valid_rmsle: 0.01236 | valid_mae: 0.35668 | valid_rmse: 0.45416 | valid_mse: 0.20626 |  0:01:20s\n",
      "epoch 47 | loss: 0.16132 | train_rmsle: 0.00965 | train_mae: 0.31145 | train_rmse: 0.39641 | train_mse: 0.15714 | valid_rmsle: 0.01199 | valid_mae: 0.3516  | valid_rmse: 0.44708 | valid_mse: 0.19988 |  0:01:21s\n",
      "epoch 48 | loss: 0.16133 | train_rmsle: 0.00928 | train_mae: 0.31071 | train_rmse: 0.39207 | train_mse: 0.15372 | valid_rmsle: 0.01169 | valid_mae: 0.35144 | valid_rmse: 0.44348 | valid_mse: 0.19667 |  0:01:22s\n",
      "epoch 49 | loss: 0.1579  | train_rmsle: 0.00914 | train_mae: 0.30926 | train_rmse: 0.38952 | train_mse: 0.15173 | valid_rmsle: 0.01168 | valid_mae: 0.35051 | valid_rmse: 0.44343 | valid_mse: 0.19663 |  0:01:24s\n",
      "epoch 50 | loss: 0.15586 | train_rmsle: 0.0091  | train_mae: 0.30764 | train_rmse: 0.38704 | train_mse: 0.1498  | valid_rmsle: 0.01153 | valid_mae: 0.34864 | valid_rmse: 0.44014 | valid_mse: 0.19372 |  0:01:25s\n",
      "epoch 51 | loss: 0.15493 | train_rmsle: 0.00893 | train_mae: 0.30381 | train_rmse: 0.38378 | train_mse: 0.14729 | valid_rmsle: 0.01156 | valid_mae: 0.3478  | valid_rmse: 0.44063 | valid_mse: 0.19416 |  0:01:27s\n",
      "epoch 52 | loss: 0.15413 | train_rmsle: 0.00927 | train_mae: 0.30619 | train_rmse: 0.3886  | train_mse: 0.15101 | valid_rmsle: 0.01175 | valid_mae: 0.34959 | valid_rmse: 0.44283 | valid_mse: 0.1961  |  0:01:28s\n",
      "epoch 53 | loss: 0.155   | train_rmsle: 0.00909 | train_mae: 0.30542 | train_rmse: 0.38535 | train_mse: 0.14849 | valid_rmsle: 0.01137 | valid_mae: 0.34575 | valid_rmse: 0.43647 | valid_mse: 0.19051 |  0:01:29s\n",
      "epoch 54 | loss: 0.1535  | train_rmsle: 0.00876 | train_mae: 0.29811 | train_rmse: 0.37945 | train_mse: 0.14398 | valid_rmsle: 0.01172 | valid_mae: 0.34703 | valid_rmse: 0.44217 | valid_mse: 0.19552 |  0:01:31s\n",
      "epoch 55 | loss: 0.14918 | train_rmsle: 0.00864 | train_mae: 0.29621 | train_rmse: 0.37633 | train_mse: 0.14163 | valid_rmsle: 0.01169 | valid_mae: 0.34724 | valid_rmse: 0.44261 | valid_mse: 0.1959  |  0:01:32s\n",
      "epoch 56 | loss: 0.14738 | train_rmsle: 0.0085  | train_mae: 0.29549 | train_rmse: 0.374   | train_mse: 0.13988 | valid_rmsle: 0.01201 | valid_mae: 0.35152 | valid_rmse: 0.44915 | valid_mse: 0.20173 |  0:01:34s\n",
      "epoch 57 | loss: 0.14836 | train_rmsle: 0.00845 | train_mae: 0.29151 | train_rmse: 0.3714  | train_mse: 0.13794 | valid_rmsle: 0.01224 | valid_mae: 0.35174 | valid_rmse: 0.45215 | valid_mse: 0.20444 |  0:01:35s\n",
      "epoch 58 | loss: 0.14695 | train_rmsle: 0.00841 | train_mae: 0.29357 | train_rmse: 0.37169 | train_mse: 0.13815 | valid_rmsle: 0.01203 | valid_mae: 0.35049 | valid_rmse: 0.44927 | valid_mse: 0.20185 |  0:01:37s\n",
      "epoch 59 | loss: 0.14739 | train_rmsle: 0.0084  | train_mae: 0.29145 | train_rmse: 0.37133 | train_mse: 0.13788 | valid_rmsle: 0.01182 | valid_mae: 0.34713 | valid_rmse: 0.44548 | valid_mse: 0.19845 |  0:01:39s\n",
      "epoch 60 | loss: 0.14271 | train_rmsle: 0.00875 | train_mae: 0.29875 | train_rmse: 0.37748 | train_mse: 0.14249 | valid_rmsle: 0.01191 | valid_mae: 0.35106 | valid_rmse: 0.44661 | valid_mse: 0.19946 |  0:01:40s\n",
      "epoch 61 | loss: 0.14315 | train_rmsle: 0.00813 | train_mae: 0.28721 | train_rmse: 0.36483 | train_mse: 0.1331  | valid_rmsle: 0.01153 | valid_mae: 0.3409  | valid_rmse: 0.4389  | valid_mse: 0.19264 |  0:01:42s\n",
      "epoch 62 | loss: 0.13933 | train_rmsle: 0.00785 | train_mae: 0.28362 | train_rmse: 0.35989 | train_mse: 0.12952 | valid_rmsle: 0.0113  | valid_mae: 0.33915 | valid_rmse: 0.43551 | valid_mse: 0.18967 |  0:01:44s\n",
      "epoch 63 | loss: 0.13559 | train_rmsle: 0.00781 | train_mae: 0.28237 | train_rmse: 0.35931 | train_mse: 0.12911 | valid_rmsle: 0.01121 | valid_mae: 0.34056 | valid_rmse: 0.43414 | valid_mse: 0.18848 |  0:01:46s\n",
      "epoch 64 | loss: 0.13693 | train_rmsle: 0.00785 | train_mae: 0.28276 | train_rmse: 0.36042 | train_mse: 0.1299  | valid_rmsle: 0.01125 | valid_mae: 0.33735 | valid_rmse: 0.43385 | valid_mse: 0.18823 |  0:01:47s\n",
      "epoch 65 | loss: 0.13724 | train_rmsle: 0.00773 | train_mae: 0.28159 | train_rmse: 0.35748 | train_mse: 0.12779 | valid_rmsle: 0.01087 | valid_mae: 0.33393 | valid_rmse: 0.42741 | valid_mse: 0.18268 |  0:01:49s\n",
      "epoch 66 | loss: 0.1336  | train_rmsle: 0.00765 | train_mae: 0.27922 | train_rmse: 0.35534 | train_mse: 0.12627 | valid_rmsle: 0.01056 | valid_mae: 0.32675 | valid_rmse: 0.42078 | valid_mse: 0.17705 |  0:01:51s\n",
      "epoch 67 | loss: 0.13177 | train_rmsle: 0.00751 | train_mae: 0.27476 | train_rmse: 0.35227 | train_mse: 0.1241  | valid_rmsle: 0.01112 | valid_mae: 0.33349 | valid_rmse: 0.4315  | valid_mse: 0.18619 |  0:01:53s\n",
      "epoch 68 | loss: 0.13095 | train_rmsle: 0.00731 | train_mae: 0.27261 | train_rmse: 0.34804 | train_mse: 0.12113 | valid_rmsle: 0.01078 | valid_mae: 0.32938 | valid_rmse: 0.4259  | valid_mse: 0.18139 |  0:01:54s\n",
      "epoch 69 | loss: 0.12718 | train_rmsle: 0.00743 | train_mae: 0.27074 | train_rmse: 0.34809 | train_mse: 0.12117 | valid_rmsle: 0.01072 | valid_mae: 0.3269  | valid_rmse: 0.42234 | valid_mse: 0.17837 |  0:01:56s\n",
      "epoch 70 | loss: 0.12793 | train_rmsle: 0.00753 | train_mae: 0.27257 | train_rmse: 0.34911 | train_mse: 0.12188 | valid_rmsle: 0.01085 | valid_mae: 0.33123 | valid_rmse: 0.423   | valid_mse: 0.17893 |  0:01:58s\n",
      "epoch 71 | loss: 0.12504 | train_rmsle: 0.00712 | train_mae: 0.27144 | train_rmse: 0.34395 | train_mse: 0.1183  | valid_rmsle: 0.01052 | valid_mae: 0.32825 | valid_rmse: 0.41888 | valid_mse: 0.17546 |  0:01:59s\n",
      "epoch 72 | loss: 0.12495 | train_rmsle: 0.00697 | train_mae: 0.26648 | train_rmse: 0.34031 | train_mse: 0.11581 | valid_rmsle: 0.0104  | valid_mae: 0.32694 | valid_rmse: 0.41696 | valid_mse: 0.17385 |  0:02:01s\n",
      "epoch 73 | loss: 0.12364 | train_rmsle: 0.00695 | train_mae: 0.26439 | train_rmse: 0.33794 | train_mse: 0.1142  | valid_rmsle: 0.01044 | valid_mae: 0.32522 | valid_rmse: 0.41664 | valid_mse: 0.17359 |  0:02:03s\n",
      "epoch 74 | loss: 0.11995 | train_rmsle: 0.00679 | train_mae: 0.26055 | train_rmse: 0.33438 | train_mse: 0.11181 | valid_rmsle: 0.01013 | valid_mae: 0.32282 | valid_rmse: 0.41256 | valid_mse: 0.17021 |  0:02:05s\n",
      "epoch 75 | loss: 0.11793 | train_rmsle: 0.00684 | train_mae: 0.26326 | train_rmse: 0.33556 | train_mse: 0.1126  | valid_rmsle: 0.01004 | valid_mae: 0.32274 | valid_rmse: 0.41044 | valid_mse: 0.16846 |  0:02:07s\n",
      "epoch 76 | loss: 0.11774 | train_rmsle: 0.00658 | train_mae: 0.25621 | train_rmse: 0.32829 | train_mse: 0.10777 | valid_rmsle: 0.01027 | valid_mae: 0.32241 | valid_rmse: 0.4153  | valid_mse: 0.17247 |  0:02:08s\n",
      "epoch 77 | loss: 0.11598 | train_rmsle: 0.00637 | train_mae: 0.2567  | train_rmse: 0.32657 | train_mse: 0.10665 | valid_rmsle: 0.00984 | valid_mae: 0.31557 | valid_rmse: 0.40735 | valid_mse: 0.16593 |  0:02:10s\n",
      "epoch 78 | loss: 0.11277 | train_rmsle: 0.00641 | train_mae: 0.2515  | train_rmse: 0.32427 | train_mse: 0.10515 | valid_rmsle: 0.00973 | valid_mae: 0.30943 | valid_rmse: 0.40272 | valid_mse: 0.16218 |  0:02:12s\n",
      "epoch 79 | loss: 0.11017 | train_rmsle: 0.00614 | train_mae: 0.25097 | train_rmse: 0.31994 | train_mse: 0.10236 | valid_rmsle: 0.00945 | valid_mae: 0.31005 | valid_rmse: 0.39889 | valid_mse: 0.15911 |  0:02:14s\n",
      "epoch 80 | loss: 0.10672 | train_rmsle: 0.00603 | train_mae: 0.24742 | train_rmse: 0.31631 | train_mse: 0.10005 | valid_rmsle: 0.00903 | valid_mae: 0.30142 | valid_rmse: 0.39009 | valid_mse: 0.15217 |  0:02:15s\n",
      "epoch 81 | loss: 0.1059  | train_rmsle: 0.00584 | train_mae: 0.245   | train_rmse: 0.31143 | train_mse: 0.09699 | valid_rmsle: 0.00892 | valid_mae: 0.30001 | valid_rmse: 0.3882  | valid_mse: 0.1507  |  0:02:17s\n",
      "epoch 82 | loss: 0.10171 | train_rmsle: 0.00561 | train_mae: 0.23846 | train_rmse: 0.30488 | train_mse: 0.09295 | valid_rmsle: 0.00862 | valid_mae: 0.29384 | valid_rmse: 0.38087 | valid_mse: 0.14506 |  0:02:19s\n",
      "epoch 83 | loss: 0.10168 | train_rmsle: 0.00534 | train_mae: 0.23016 | train_rmse: 0.29652 | train_mse: 0.08792 | valid_rmsle: 0.00829 | valid_mae: 0.28691 | valid_rmse: 0.37422 | valid_mse: 0.14004 |  0:02:21s\n",
      "epoch 84 | loss: 0.0949  | train_rmsle: 0.0052  | train_mae: 0.22766 | train_rmse: 0.29269 | train_mse: 0.08567 | valid_rmsle: 0.00795 | valid_mae: 0.28249 | valid_rmse: 0.3658  | valid_mse: 0.13381 |  0:02:22s\n",
      "epoch 85 | loss: 0.09209 | train_rmsle: 0.00519 | train_mae: 0.23175 | train_rmse: 0.29462 | train_mse: 0.0868  | valid_rmsle: 0.00777 | valid_mae: 0.28351 | valid_rmse: 0.36337 | valid_mse: 0.13204 |  0:02:24s\n",
      "epoch 86 | loss: 0.08962 | train_rmsle: 0.00486 | train_mae: 0.2197  | train_rmse: 0.28312 | train_mse: 0.08016 | valid_rmsle: 0.00748 | valid_mae: 0.27549 | valid_rmse: 0.35585 | valid_mse: 0.12663 |  0:02:26s\n",
      "epoch 87 | loss: 0.0891  | train_rmsle: 0.00466 | train_mae: 0.21467 | train_rmse: 0.27716 | train_mse: 0.07682 | valid_rmsle: 0.00736 | valid_mae: 0.27404 | valid_rmse: 0.35325 | valid_mse: 0.12479 |  0:02:28s\n",
      "epoch 88 | loss: 0.0841  | train_rmsle: 0.0045  | train_mae: 0.2108  | train_rmse: 0.27196 | train_mse: 0.07396 | valid_rmsle: 0.00706 | valid_mae: 0.26914 | valid_rmse: 0.34656 | valid_mse: 0.1201  |  0:02:29s\n",
      "epoch 89 | loss: 0.08189 | train_rmsle: 0.00436 | train_mae: 0.20695 | train_rmse: 0.26784 | train_mse: 0.07174 | valid_rmsle: 0.00678 | valid_mae: 0.26465 | valid_rmse: 0.34069 | valid_mse: 0.11607 |  0:02:31s\n",
      "epoch 90 | loss: 0.07952 | train_rmsle: 0.0042  | train_mae: 0.20149 | train_rmse: 0.26197 | train_mse: 0.06863 | valid_rmsle: 0.00665 | valid_mae: 0.26204 | valid_rmse: 0.33741 | valid_mse: 0.11385 |  0:02:33s\n",
      "epoch 91 | loss: 0.07689 | train_rmsle: 0.0041  | train_mae: 0.19904 | train_rmse: 0.2588  | train_mse: 0.06698 | valid_rmsle: 0.00655 | valid_mae: 0.26183 | valid_rmse: 0.3351  | valid_mse: 0.11229 |  0:02:35s\n",
      "epoch 92 | loss: 0.07573 | train_rmsle: 0.00413 | train_mae: 0.20555 | train_rmse: 0.26236 | train_mse: 0.06883 | valid_rmsle: 0.00683 | valid_mae: 0.26625 | valid_rmse: 0.34297 | valid_mse: 0.11763 |  0:02:36s\n",
      "epoch 93 | loss: 0.07492 | train_rmsle: 0.00391 | train_mae: 0.19684 | train_rmse: 0.25383 | train_mse: 0.06443 | valid_rmsle: 0.00638 | valid_mae: 0.25675 | valid_rmse: 0.33077 | valid_mse: 0.10941 |  0:02:38s\n",
      "epoch 94 | loss: 0.07247 | train_rmsle: 0.00382 | train_mae: 0.19183 | train_rmse: 0.25025 | train_mse: 0.06263 | valid_rmsle: 0.00626 | valid_mae: 0.25453 | valid_rmse: 0.32774 | valid_mse: 0.10742 |  0:02:40s\n",
      "epoch 95 | loss: 0.07111 | train_rmsle: 0.00371 | train_mae: 0.18989 | train_rmse: 0.24638 | train_mse: 0.0607  | valid_rmsle: 0.00604 | valid_mae: 0.25131 | valid_rmse: 0.32294 | valid_mse: 0.10429 |  0:02:42s\n",
      "epoch 96 | loss: 0.06898 | train_rmsle: 0.00366 | train_mae: 0.1903  | train_rmse: 0.24617 | train_mse: 0.0606  | valid_rmsle: 0.00614 | valid_mae: 0.25318 | valid_rmse: 0.32649 | valid_mse: 0.1066  |  0:02:43s\n",
      "epoch 97 | loss: 0.06829 | train_rmsle: 0.00372 | train_mae: 0.18806 | train_rmse: 0.24591 | train_mse: 0.06047 | valid_rmsle: 0.00614 | valid_mae: 0.25081 | valid_rmse: 0.3261  | valid_mse: 0.10634 |  0:02:45s\n",
      "epoch 98 | loss: 0.06792 | train_rmsle: 0.00347 | train_mae: 0.18459 | train_rmse: 0.23952 | train_mse: 0.05737 | valid_rmsle: 0.00586 | valid_mae: 0.24833 | valid_rmse: 0.31891 | valid_mse: 0.10171 |  0:02:47s\n",
      "epoch 99 | loss: 0.06517 | train_rmsle: 0.00342 | train_mae: 0.18609 | train_rmse: 0.23935 | train_mse: 0.05729 | valid_rmsle: 0.0058  | valid_mae: 0.24831 | valid_rmse: 0.31843 | valid_mse: 0.1014  |  0:02:48s\n",
      "epoch 100| loss: 0.06371 | train_rmsle: 0.00327 | train_mae: 0.17871 | train_rmse: 0.2322  | train_mse: 0.05392 | valid_rmsle: 0.00562 | valid_mae: 0.24504 | valid_rmse: 0.31272 | valid_mse: 0.0978  |  0:02:50s\n",
      "epoch 101| loss: 0.06214 | train_rmsle: 0.00314 | train_mae: 0.17433 | train_rmse: 0.22762 | train_mse: 0.05181 | valid_rmsle: 0.00547 | valid_mae: 0.24268 | valid_rmse: 0.30863 | valid_mse: 0.09525 |  0:02:52s\n",
      "epoch 102| loss: 0.05972 | train_rmsle: 0.00325 | train_mae: 0.18172 | train_rmse: 0.23347 | train_mse: 0.05451 | valid_rmsle: 0.00558 | valid_mae: 0.24619 | valid_rmse: 0.31225 | valid_mse: 0.0975  |  0:02:53s\n",
      "epoch 103| loss: 0.0615  | train_rmsle: 0.00303 | train_mae: 0.17432 | train_rmse: 0.22523 | train_mse: 0.05073 | valid_rmsle: 0.00546 | valid_mae: 0.24203 | valid_rmse: 0.30835 | valid_mse: 0.09508 |  0:02:55s\n",
      "epoch 104| loss: 0.06051 | train_rmsle: 0.00287 | train_mae: 0.1663  | train_rmse: 0.21737 | train_mse: 0.04725 | valid_rmsle: 0.00515 | valid_mae: 0.2346  | valid_rmse: 0.29896 | valid_mse: 0.08938 |  0:02:57s\n",
      "epoch 105| loss: 0.05674 | train_rmsle: 0.00292 | train_mae: 0.17157 | train_rmse: 0.22195 | train_mse: 0.04926 | valid_rmsle: 0.00526 | valid_mae: 0.23787 | valid_rmse: 0.30377 | valid_mse: 0.09227 |  0:02:59s\n",
      "epoch 106| loss: 0.05521 | train_rmsle: 0.00276 | train_mae: 0.16319 | train_rmse: 0.21335 | train_mse: 0.04552 | valid_rmsle: 0.005   | valid_mae: 0.23238 | valid_rmse: 0.29542 | valid_mse: 0.08727 |  0:03:00s\n",
      "epoch 107| loss: 0.05424 | train_rmsle: 0.0027  | train_mae: 0.16127 | train_rmse: 0.2113  | train_mse: 0.04465 | valid_rmsle: 0.0049  | valid_mae: 0.23046 | valid_rmse: 0.29301 | valid_mse: 0.08585 |  0:03:02s\n",
      "epoch 108| loss: 0.05436 | train_rmsle: 0.00271 | train_mae: 0.15996 | train_rmse: 0.21084 | train_mse: 0.04445 | valid_rmsle: 0.00494 | valid_mae: 0.23159 | valid_rmse: 0.29415 | valid_mse: 0.08652 |  0:03:04s\n",
      "epoch 109| loss: 0.05435 | train_rmsle: 0.00263 | train_mae: 0.16012 | train_rmse: 0.20929 | train_mse: 0.0438  | valid_rmsle: 0.00483 | valid_mae: 0.22912 | valid_rmse: 0.29161 | valid_mse: 0.08504 |  0:03:05s\n",
      "epoch 110| loss: 0.05151 | train_rmsle: 0.00256 | train_mae: 0.15561 | train_rmse: 0.20516 | train_mse: 0.04209 | valid_rmsle: 0.00476 | valid_mae: 0.22784 | valid_rmse: 0.28901 | valid_mse: 0.08353 |  0:03:07s\n",
      "epoch 111| loss: 0.04961 | train_rmsle: 0.00267 | train_mae: 0.15547 | train_rmse: 0.20607 | train_mse: 0.04246 | valid_rmsle: 0.00488 | valid_mae: 0.22904 | valid_rmse: 0.29096 | valid_mse: 0.08466 |  0:03:09s\n",
      "epoch 112| loss: 0.04929 | train_rmsle: 0.00241 | train_mae: 0.1519  | train_rmse: 0.19966 | train_mse: 0.03987 | valid_rmsle: 0.00463 | valid_mae: 0.22517 | valid_rmse: 0.28571 | valid_mse: 0.08163 |  0:03:10s\n",
      "epoch 113| loss: 0.04828 | train_rmsle: 0.00229 | train_mae: 0.14812 | train_rmse: 0.19505 | train_mse: 0.03804 | valid_rmsle: 0.0046  | valid_mae: 0.22338 | valid_rmse: 0.2849  | valid_mse: 0.08117 |  0:03:12s\n",
      "epoch 114| loss: 0.04693 | train_rmsle: 0.00227 | train_mae: 0.14922 | train_rmse: 0.19486 | train_mse: 0.03797 | valid_rmsle: 0.00457 | valid_mae: 0.22472 | valid_rmse: 0.28424 | valid_mse: 0.0808  |  0:03:13s\n",
      "epoch 115| loss: 0.04517 | train_rmsle: 0.00213 | train_mae: 0.14281 | train_rmse: 0.18834 | train_mse: 0.03547 | valid_rmsle: 0.00446 | valid_mae: 0.219   | valid_rmse: 0.28114 | valid_mse: 0.07904 |  0:03:15s\n",
      "epoch 116| loss: 0.04574 | train_rmsle: 0.00215 | train_mae: 0.14426 | train_rmse: 0.18987 | train_mse: 0.03605 | valid_rmsle: 0.00458 | valid_mae: 0.22295 | valid_rmse: 0.2853  | valid_mse: 0.0814  |  0:03:16s\n",
      "epoch 117| loss: 0.04423 | train_rmsle: 0.00205 | train_mae: 0.13997 | train_rmse: 0.18485 | train_mse: 0.03417 | valid_rmsle: 0.00441 | valid_mae: 0.21836 | valid_rmse: 0.27874 | valid_mse: 0.0777  |  0:03:18s\n",
      "epoch 118| loss: 0.04243 | train_rmsle: 0.00201 | train_mae: 0.1387  | train_rmse: 0.18362 | train_mse: 0.03371 | valid_rmsle: 0.00442 | valid_mae: 0.218   | valid_rmse: 0.27969 | valid_mse: 0.07823 |  0:03:19s\n",
      "epoch 119| loss: 0.0418  | train_rmsle: 0.00199 | train_mae: 0.13812 | train_rmse: 0.18262 | train_mse: 0.03335 | valid_rmsle: 0.00432 | valid_mae: 0.2167  | valid_rmse: 0.2769  | valid_mse: 0.07667 |  0:03:20s\n",
      "epoch 120| loss: 0.04338 | train_rmsle: 0.00201 | train_mae: 0.13976 | train_rmse: 0.18424 | train_mse: 0.03395 | valid_rmsle: 0.00437 | valid_mae: 0.21755 | valid_rmse: 0.2789  | valid_mse: 0.07778 |  0:03:22s\n",
      "epoch 121| loss: 0.04133 | train_rmsle: 0.00199 | train_mae: 0.13895 | train_rmse: 0.18383 | train_mse: 0.03379 | valid_rmsle: 0.00438 | valid_mae: 0.21662 | valid_rmse: 0.27879 | valid_mse: 0.07773 |  0:03:23s\n",
      "epoch 122| loss: 0.04068 | train_rmsle: 0.00185 | train_mae: 0.13286 | train_rmse: 0.17648 | train_mse: 0.03114 | valid_rmsle: 0.00421 | valid_mae: 0.21307 | valid_rmse: 0.27308 | valid_mse: 0.07457 |  0:03:25s\n",
      "epoch 123| loss: 0.0403  | train_rmsle: 0.00183 | train_mae: 0.13087 | train_rmse: 0.17427 | train_mse: 0.03037 | valid_rmsle: 0.00407 | valid_mae: 0.20983 | valid_rmse: 0.26888 | valid_mse: 0.0723  |  0:03:27s\n",
      "epoch 124| loss: 0.03902 | train_rmsle: 0.00176 | train_mae: 0.12893 | train_rmse: 0.17176 | train_mse: 0.0295  | valid_rmsle: 0.00402 | valid_mae: 0.2069  | valid_rmse: 0.26799 | valid_mse: 0.07182 |  0:03:29s\n",
      "epoch 125| loss: 0.0391  | train_rmsle: 0.00174 | train_mae: 0.12956 | train_rmse: 0.1716  | train_mse: 0.02945 | valid_rmsle: 0.00392 | valid_mae: 0.20599 | valid_rmse: 0.26519 | valid_mse: 0.07032 |  0:03:30s\n",
      "epoch 126| loss: 0.03787 | train_rmsle: 0.00168 | train_mae: 0.12484 | train_rmse: 0.16731 | train_mse: 0.02799 | valid_rmsle: 0.0039  | valid_mae: 0.2038  | valid_rmse: 0.26389 | valid_mse: 0.06964 |  0:03:32s\n",
      "epoch 127| loss: 0.03765 | train_rmsle: 0.00165 | train_mae: 0.12383 | train_rmse: 0.16593 | train_mse: 0.02753 | valid_rmsle: 0.00383 | valid_mae: 0.20251 | valid_rmse: 0.26219 | valid_mse: 0.06874 |  0:03:34s\n",
      "epoch 128| loss: 0.0366  | train_rmsle: 0.00163 | train_mae: 0.12399 | train_rmse: 0.16585 | train_mse: 0.02751 | valid_rmsle: 0.00382 | valid_mae: 0.2032  | valid_rmse: 0.26192 | valid_mse: 0.0686  |  0:03:35s\n",
      "epoch 129| loss: 0.03582 | train_rmsle: 0.00162 | train_mae: 0.1232  | train_rmse: 0.164   | train_mse: 0.0269  | valid_rmsle: 0.00379 | valid_mae: 0.20197 | valid_rmse: 0.2601  | valid_mse: 0.06765 |  0:03:37s\n",
      "epoch 130| loss: 0.03519 | train_rmsle: 0.00157 | train_mae: 0.12293 | train_rmse: 0.16325 | train_mse: 0.02665 | valid_rmsle: 0.00372 | valid_mae: 0.20092 | valid_rmse: 0.25928 | valid_mse: 0.06723 |  0:03:39s\n",
      "epoch 131| loss: 0.03423 | train_rmsle: 0.00149 | train_mae: 0.11779 | train_rmse: 0.15762 | train_mse: 0.02484 | valid_rmsle: 0.00373 | valid_mae: 0.1991  | valid_rmse: 0.25961 | valid_mse: 0.0674  |  0:03:40s\n",
      "epoch 132| loss: 0.03502 | train_rmsle: 0.00153 | train_mae: 0.11891 | train_rmse: 0.15952 | train_mse: 0.02545 | valid_rmsle: 0.00367 | valid_mae: 0.19579 | valid_rmse: 0.25741 | valid_mse: 0.06626 |  0:03:42s\n",
      "epoch 133| loss: 0.03312 | train_rmsle: 0.00142 | train_mae: 0.11509 | train_rmse: 0.15381 | train_mse: 0.02366 | valid_rmsle: 0.00356 | valid_mae: 0.19273 | valid_rmse: 0.25324 | valid_mse: 0.06413 |  0:03:44s\n",
      "epoch 134| loss: 0.03292 | train_rmsle: 0.00138 | train_mae: 0.11378 | train_rmse: 0.15252 | train_mse: 0.02326 | valid_rmsle: 0.00358 | valid_mae: 0.19462 | valid_rmse: 0.25417 | valid_mse: 0.0646  |  0:03:45s\n",
      "epoch 135| loss: 0.03258 | train_rmsle: 0.00138 | train_mae: 0.11309 | train_rmse: 0.15146 | train_mse: 0.02294 | valid_rmsle: 0.0035  | valid_mae: 0.19253 | valid_rmse: 0.25153 | valid_mse: 0.06327 |  0:03:47s\n",
      "epoch 136| loss: 0.03154 | train_rmsle: 0.00136 | train_mae: 0.11273 | train_rmse: 0.15079 | train_mse: 0.02274 | valid_rmsle: 0.00357 | valid_mae: 0.1933  | valid_rmse: 0.25474 | valid_mse: 0.06489 |  0:03:49s\n",
      "epoch 137| loss: 0.03217 | train_rmsle: 0.00141 | train_mae: 0.11623 | train_rmse: 0.15395 | train_mse: 0.0237  | valid_rmsle: 0.00363 | valid_mae: 0.19577 | valid_rmse: 0.25688 | valid_mse: 0.06599 |  0:03:50s\n",
      "epoch 138| loss: 0.03201 | train_rmsle: 0.00143 | train_mae: 0.11675 | train_rmse: 0.15632 | train_mse: 0.02444 | valid_rmsle: 0.00335 | valid_mae: 0.18841 | valid_rmse: 0.24606 | valid_mse: 0.06054 |  0:03:52s\n",
      "epoch 139| loss: 0.03349 | train_rmsle: 0.00143 | train_mae: 0.11811 | train_rmse: 0.15762 | train_mse: 0.02484 | valid_rmsle: 0.00322 | valid_mae: 0.1844  | valid_rmse: 0.24242 | valid_mse: 0.05877 |  0:03:54s\n",
      "epoch 140| loss: 0.03255 | train_rmsle: 0.00137 | train_mae: 0.11487 | train_rmse: 0.15354 | train_mse: 0.02357 | valid_rmsle: 0.00328 | valid_mae: 0.18468 | valid_rmse: 0.24627 | valid_mse: 0.06065 |  0:03:55s\n",
      "epoch 141| loss: 0.03222 | train_rmsle: 0.00137 | train_mae: 0.11573 | train_rmse: 0.15324 | train_mse: 0.02348 | valid_rmsle: 0.00338 | valid_mae: 0.18762 | valid_rmse: 0.24891 | valid_mse: 0.06195 |  0:03:57s\n",
      "epoch 142| loss: 0.03126 | train_rmsle: 0.00134 | train_mae: 0.114   | train_rmse: 0.15233 | train_mse: 0.0232  | valid_rmsle: 0.00334 | valid_mae: 0.18456 | valid_rmse: 0.24582 | valid_mse: 0.06043 |  0:03:59s\n",
      "epoch 143| loss: 0.03064 | train_rmsle: 0.00127 | train_mae: 0.10983 | train_rmse: 0.14665 | train_mse: 0.02151 | valid_rmsle: 0.00318 | valid_mae: 0.18083 | valid_rmse: 0.24052 | valid_mse: 0.05785 |  0:04:01s\n",
      "epoch 144| loss: 0.03152 | train_rmsle: 0.00129 | train_mae: 0.11011 | train_rmse: 0.1468  | train_mse: 0.02155 | valid_rmsle: 0.00312 | valid_mae: 0.17854 | valid_rmse: 0.23707 | valid_mse: 0.0562  |  0:04:02s\n",
      "epoch 145| loss: 0.02961 | train_rmsle: 0.00124 | train_mae: 0.10895 | train_rmse: 0.14564 | train_mse: 0.02121 | valid_rmsle: 0.00307 | valid_mae: 0.17848 | valid_rmse: 0.23621 | valid_mse: 0.0558  |  0:04:04s\n",
      "epoch 146| loss: 0.02946 | train_rmsle: 0.00121 | train_mae: 0.10684 | train_rmse: 0.14287 | train_mse: 0.02041 | valid_rmsle: 0.0031  | valid_mae: 0.17903 | valid_rmse: 0.23695 | valid_mse: 0.05615 |  0:04:06s\n",
      "epoch 147| loss: 0.02875 | train_rmsle: 0.00127 | train_mae: 0.11328 | train_rmse: 0.14865 | train_mse: 0.0221  | valid_rmsle: 0.00331 | valid_mae: 0.18741 | valid_rmse: 0.24622 | valid_mse: 0.06063 |  0:04:07s\n",
      "epoch 148| loss: 0.02941 | train_rmsle: 0.00116 | train_mae: 0.1054  | train_rmse: 0.1408  | train_mse: 0.01982 | valid_rmsle: 0.00321 | valid_mae: 0.18151 | valid_rmse: 0.24081 | valid_mse: 0.05799 |  0:04:09s\n",
      "epoch 149| loss: 0.02802 | train_rmsle: 0.0011  | train_mae: 0.1025  | train_rmse: 0.13721 | train_mse: 0.01883 | valid_rmsle: 0.0031  | valid_mae: 0.17646 | valid_rmse: 0.23684 | valid_mse: 0.05609 |  0:04:11s\n",
      "epoch 150| loss: 0.02768 | train_rmsle: 0.00108 | train_mae: 0.10259 | train_rmse: 0.13607 | train_mse: 0.01852 | valid_rmsle: 0.00316 | valid_mae: 0.17806 | valid_rmse: 0.23917 | valid_mse: 0.0572  |  0:04:12s\n",
      "epoch 151| loss: 0.02757 | train_rmsle: 0.00112 | train_mae: 0.10428 | train_rmse: 0.13914 | train_mse: 0.01936 | valid_rmsle: 0.00321 | valid_mae: 0.18033 | valid_rmse: 0.24112 | valid_mse: 0.05814 |  0:04:14s\n",
      "epoch 152| loss: 0.02697 | train_rmsle: 0.00103 | train_mae: 0.09939 | train_rmse: 0.13339 | train_mse: 0.01779 | valid_rmsle: 0.00299 | valid_mae: 0.17569 | valid_rmse: 0.23334 | valid_mse: 0.05445 |  0:04:16s\n",
      "epoch 153| loss: 0.02699 | train_rmsle: 0.00102 | train_mae: 0.09937 | train_rmse: 0.13304 | train_mse: 0.0177  | valid_rmsle: 0.00304 | valid_mae: 0.17524 | valid_rmse: 0.23524 | valid_mse: 0.05534 |  0:04:17s\n",
      "epoch 154| loss: 0.02577 | train_rmsle: 0.00099 | train_mae: 0.09666 | train_rmse: 0.12953 | train_mse: 0.01678 | valid_rmsle: 0.00295 | valid_mae: 0.17242 | valid_rmse: 0.23154 | valid_mse: 0.05361 |  0:04:19s\n",
      "epoch 155| loss: 0.02797 | train_rmsle: 0.00122 | train_mae: 0.1114  | train_rmse: 0.14471 | train_mse: 0.02094 | valid_rmsle: 0.00312 | valid_mae: 0.17737 | valid_rmse: 0.23848 | valid_mse: 0.05687 |  0:04:21s\n",
      "epoch 156| loss: 0.027   | train_rmsle: 0.00096 | train_mae: 0.09486 | train_rmse: 0.12763 | train_mse: 0.01629 | valid_rmsle: 0.00289 | valid_mae: 0.17083 | valid_rmse: 0.22923 | valid_mse: 0.05255 |  0:04:22s\n",
      "epoch 157| loss: 0.02455 | train_rmsle: 0.00099 | train_mae: 0.09626 | train_rmse: 0.12925 | train_mse: 0.0167  | valid_rmsle: 0.00293 | valid_mae: 0.17122 | valid_rmse: 0.23072 | valid_mse: 0.05323 |  0:04:24s\n",
      "epoch 158| loss: 0.02525 | train_rmsle: 0.00096 | train_mae: 0.09467 | train_rmse: 0.12794 | train_mse: 0.01637 | valid_rmsle: 0.00289 | valid_mae: 0.17019 | valid_rmse: 0.22956 | valid_mse: 0.0527  |  0:04:26s\n",
      "epoch 159| loss: 0.02667 | train_rmsle: 0.00094 | train_mae: 0.09371 | train_rmse: 0.12697 | train_mse: 0.01612 | valid_rmsle: 0.00287 | valid_mae: 0.16834 | valid_rmse: 0.2279  | valid_mse: 0.05194 |  0:04:27s\n",
      "epoch 160| loss: 0.02615 | train_rmsle: 0.00097 | train_mae: 0.09549 | train_rmse: 0.12858 | train_mse: 0.01653 | valid_rmsle: 0.00283 | valid_mae: 0.16778 | valid_rmse: 0.22668 | valid_mse: 0.05138 |  0:04:29s\n",
      "epoch 161| loss: 0.02584 | train_rmsle: 0.00093 | train_mae: 0.09374 | train_rmse: 0.12663 | train_mse: 0.01604 | valid_rmsle: 0.00285 | valid_mae: 0.16868 | valid_rmse: 0.22792 | valid_mse: 0.05195 |  0:04:31s\n",
      "epoch 162| loss: 0.02467 | train_rmsle: 0.00093 | train_mae: 0.09378 | train_rmse: 0.12601 | train_mse: 0.01588 | valid_rmsle: 0.00279 | valid_mae: 0.16708 | valid_rmse: 0.2264  | valid_mse: 0.05126 |  0:04:32s\n",
      "epoch 163| loss: 0.02485 | train_rmsle: 0.00089 | train_mae: 0.09122 | train_rmse: 0.12333 | train_mse: 0.01521 | valid_rmsle: 0.00287 | valid_mae: 0.16596 | valid_rmse: 0.22725 | valid_mse: 0.05164 |  0:04:34s\n",
      "epoch 164| loss: 0.02405 | train_rmsle: 0.00097 | train_mae: 0.09564 | train_rmse: 0.12735 | train_mse: 0.01622 | valid_rmsle: 0.00269 | valid_mae: 0.16607 | valid_rmse: 0.22203 | valid_mse: 0.0493  |  0:04:36s\n",
      "epoch 165| loss: 0.02501 | train_rmsle: 0.00111 | train_mae: 0.10526 | train_rmse: 0.14105 | train_mse: 0.01989 | valid_rmsle: 0.00295 | valid_mae: 0.16961 | valid_rmse: 0.23105 | valid_mse: 0.05338 |  0:04:37s\n",
      "epoch 166| loss: 0.02562 | train_rmsle: 0.00104 | train_mae: 0.10076 | train_rmse: 0.13615 | train_mse: 0.01854 | valid_rmsle: 0.00283 | valid_mae: 0.16522 | valid_rmse: 0.22589 | valid_mse: 0.05102 |  0:04:39s\n",
      "epoch 167| loss: 0.0256  | train_rmsle: 0.00098 | train_mae: 0.09824 | train_rmse: 0.13175 | train_mse: 0.01736 | valid_rmsle: 0.00271 | valid_mae: 0.16484 | valid_rmse: 0.22197 | valid_mse: 0.04927 |  0:04:40s\n",
      "epoch 168| loss: 0.02537 | train_rmsle: 0.00099 | train_mae: 0.10003 | train_rmse: 0.13168 | train_mse: 0.01734 | valid_rmsle: 0.00267 | valid_mae: 0.16598 | valid_rmse: 0.22014 | valid_mse: 0.04846 |  0:04:42s\n",
      "epoch 169| loss: 0.02407 | train_rmsle: 0.00096 | train_mae: 0.09655 | train_rmse: 0.12834 | train_mse: 0.01647 | valid_rmsle: 0.00256 | valid_mae: 0.16155 | valid_rmse: 0.2154  | valid_mse: 0.0464  |  0:04:44s\n",
      "epoch 170| loss: 0.0242  | train_rmsle: 0.00084 | train_mae: 0.09015 | train_rmse: 0.12131 | train_mse: 0.01472 | valid_rmsle: 0.00244 | valid_mae: 0.15775 | valid_rmse: 0.21113 | valid_mse: 0.04457 |  0:04:45s\n",
      "epoch 171| loss: 0.02296 | train_rmsle: 0.00102 | train_mae: 0.10295 | train_rmse: 0.13343 | train_mse: 0.0178  | valid_rmsle: 0.00262 | valid_mae: 0.16617 | valid_rmse: 0.21815 | valid_mse: 0.04759 |  0:04:47s\n",
      "epoch 172| loss: 0.02263 | train_rmsle: 0.00081 | train_mae: 0.08861 | train_rmse: 0.11833 | train_mse: 0.014   | valid_rmsle: 0.00242 | valid_mae: 0.15812 | valid_rmse: 0.20975 | valid_mse: 0.044   |  0:04:48s\n",
      "epoch 173| loss: 0.02142 | train_rmsle: 0.00081 | train_mae: 0.08851 | train_rmse: 0.11855 | train_mse: 0.01405 | valid_rmsle: 0.00232 | valid_mae: 0.15582 | valid_rmse: 0.20643 | valid_mse: 0.04261 |  0:04:49s\n",
      "epoch 174| loss: 0.02253 | train_rmsle: 0.00081 | train_mae: 0.08785 | train_rmse: 0.11884 | train_mse: 0.01412 | valid_rmsle: 0.0024  | valid_mae: 0.15594 | valid_rmse: 0.20847 | valid_mse: 0.04346 |  0:04:50s\n",
      "epoch 175| loss: 0.02235 | train_rmsle: 0.00078 | train_mae: 0.08588 | train_rmse: 0.11574 | train_mse: 0.01339 | valid_rmsle: 0.00246 | valid_mae: 0.15326 | valid_rmse: 0.20736 | valid_mse: 0.043   |  0:04:51s\n",
      "epoch 176| loss: 0.02216 | train_rmsle: 0.00074 | train_mae: 0.08479 | train_rmse: 0.11331 | train_mse: 0.01284 | valid_rmsle: 0.0024  | valid_mae: 0.15197 | valid_rmse: 0.2059  | valid_mse: 0.0424  |  0:04:53s\n",
      "epoch 177| loss: 0.02274 | train_rmsle: 0.00074 | train_mae: 0.08455 | train_rmse: 0.11316 | train_mse: 0.0128  | valid_rmsle: 0.00235 | valid_mae: 0.15341 | valid_rmse: 0.20556 | valid_mse: 0.04226 |  0:04:54s\n",
      "epoch 178| loss: 0.02081 | train_rmsle: 0.00077 | train_mae: 0.08831 | train_rmse: 0.11614 | train_mse: 0.01349 | valid_rmsle: 0.00235 | valid_mae: 0.15532 | valid_rmse: 0.20714 | valid_mse: 0.04291 |  0:04:55s\n",
      "epoch 179| loss: 0.02084 | train_rmsle: 0.0007  | train_mae: 0.08298 | train_rmse: 0.11097 | train_mse: 0.01231 | valid_rmsle: 0.00236 | valid_mae: 0.15194 | valid_rmse: 0.20656 | valid_mse: 0.04267 |  0:04:56s\n",
      "epoch 180| loss: 0.02046 | train_rmsle: 0.0008  | train_mae: 0.09022 | train_rmse: 0.11796 | train_mse: 0.01392 | valid_rmsle: 0.00249 | valid_mae: 0.15691 | valid_rmse: 0.21124 | valid_mse: 0.04462 |  0:04:58s\n",
      "epoch 181| loss: 0.01975 | train_rmsle: 0.00067 | train_mae: 0.08098 | train_rmse: 0.10821 | train_mse: 0.01171 | valid_rmsle: 0.00236 | valid_mae: 0.15132 | valid_rmse: 0.20565 | valid_mse: 0.04229 |  0:04:59s\n",
      "epoch 182| loss: 0.01933 | train_rmsle: 0.00072 | train_mae: 0.08526 | train_rmse: 0.11203 | train_mse: 0.01255 | valid_rmsle: 0.00239 | valid_mae: 0.15411 | valid_rmse: 0.2079  | valid_mse: 0.04322 |  0:05:01s\n",
      "epoch 183| loss: 0.01933 | train_rmsle: 0.00063 | train_mae: 0.07792 | train_rmse: 0.10474 | train_mse: 0.01097 | valid_rmsle: 0.00231 | valid_mae: 0.14945 | valid_rmse: 0.20349 | valid_mse: 0.04141 |  0:05:02s\n",
      "epoch 184| loss: 0.01931 | train_rmsle: 0.00065 | train_mae: 0.0797  | train_rmse: 0.10602 | train_mse: 0.01124 | valid_rmsle: 0.00222 | valid_mae: 0.15055 | valid_rmse: 0.20073 | valid_mse: 0.04029 |  0:05:04s\n",
      "epoch 185| loss: 0.0193  | train_rmsle: 0.00063 | train_mae: 0.0776  | train_rmse: 0.10445 | train_mse: 0.01091 | valid_rmsle: 0.0023  | valid_mae: 0.14985 | valid_rmse: 0.20251 | valid_mse: 0.04101 |  0:05:06s\n",
      "epoch 186| loss: 0.01876 | train_rmsle: 0.00062 | train_mae: 0.0772  | train_rmse: 0.10348 | train_mse: 0.01071 | valid_rmsle: 0.00226 | valid_mae: 0.15126 | valid_rmse: 0.20255 | valid_mse: 0.04103 |  0:05:07s\n",
      "epoch 187| loss: 0.01879 | train_rmsle: 0.00065 | train_mae: 0.07929 | train_rmse: 0.10694 | train_mse: 0.01144 | valid_rmsle: 0.00225 | valid_mae: 0.14922 | valid_rmse: 0.20146 | valid_mse: 0.04058 |  0:05:09s\n",
      "epoch 188| loss: 0.01835 | train_rmsle: 0.00064 | train_mae: 0.07909 | train_rmse: 0.1068  | train_mse: 0.01141 | valid_rmsle: 0.00228 | valid_mae: 0.14959 | valid_rmse: 0.20269 | valid_mse: 0.04108 |  0:05:11s\n",
      "epoch 189| loss: 0.01965 | train_rmsle: 0.00063 | train_mae: 0.07793 | train_rmse: 0.10425 | train_mse: 0.01087 | valid_rmsle: 0.00222 | valid_mae: 0.15023 | valid_rmse: 0.20028 | valid_mse: 0.04011 |  0:05:12s\n",
      "epoch 190| loss: 0.01902 | train_rmsle: 0.00064 | train_mae: 0.07884 | train_rmse: 0.10522 | train_mse: 0.01107 | valid_rmsle: 0.00218 | valid_mae: 0.15021 | valid_rmse: 0.19965 | valid_mse: 0.03986 |  0:05:14s\n",
      "epoch 191| loss: 0.01946 | train_rmsle: 0.00061 | train_mae: 0.07568 | train_rmse: 0.10222 | train_mse: 0.01045 | valid_rmsle: 0.00213 | valid_mae: 0.1482  | valid_rmse: 0.1969  | valid_mse: 0.03877 |  0:05:15s\n",
      "epoch 192| loss: 0.01924 | train_rmsle: 0.00071 | train_mae: 0.08627 | train_rmse: 0.11331 | train_mse: 0.01284 | valid_rmsle: 0.00223 | valid_mae: 0.15133 | valid_rmse: 0.20224 | valid_mse: 0.0409  |  0:05:17s\n",
      "epoch 193| loss: 0.01844 | train_rmsle: 0.00063 | train_mae: 0.07974 | train_rmse: 0.10572 | train_mse: 0.01118 | valid_rmsle: 0.00217 | valid_mae: 0.1488  | valid_rmse: 0.19888 | valid_mse: 0.03956 |  0:05:19s\n",
      "epoch 194| loss: 0.01871 | train_rmsle: 0.00074 | train_mae: 0.08833 | train_rmse: 0.11652 | train_mse: 0.01358 | valid_rmsle: 0.0023  | valid_mae: 0.15264 | valid_rmse: 0.20513 | valid_mse: 0.04208 |  0:05:20s\n",
      "epoch 195| loss: 0.01789 | train_rmsle: 0.00063 | train_mae: 0.07861 | train_rmse: 0.10446 | train_mse: 0.01091 | valid_rmsle: 0.00208 | valid_mae: 0.14612 | valid_rmse: 0.19501 | valid_mse: 0.03803 |  0:05:22s\n",
      "epoch 196| loss: 0.01763 | train_rmsle: 0.00062 | train_mae: 0.07872 | train_rmse: 0.10412 | train_mse: 0.01084 | valid_rmsle: 0.00204 | valid_mae: 0.14689 | valid_rmse: 0.19391 | valid_mse: 0.0376  |  0:05:24s\n",
      "epoch 197| loss: 0.01782 | train_rmsle: 0.00056 | train_mae: 0.07508 | train_rmse: 0.10019 | train_mse: 0.01004 | valid_rmsle: 0.002   | valid_mae: 0.14492 | valid_rmse: 0.19149 | valid_mse: 0.03667 |  0:05:25s\n",
      "epoch 198| loss: 0.01728 | train_rmsle: 0.00057 | train_mae: 0.07561 | train_rmse: 0.10093 | train_mse: 0.01019 | valid_rmsle: 0.00201 | valid_mae: 0.14564 | valid_rmse: 0.19288 | valid_mse: 0.0372  |  0:05:27s\n",
      "epoch 199| loss: 0.01784 | train_rmsle: 0.00065 | train_mae: 0.07971 | train_rmse: 0.10688 | train_mse: 0.01142 | valid_rmsle: 0.00219 | valid_mae: 0.14908 | valid_rmse: 0.19952 | valid_mse: 0.03981 |  0:05:29s\n",
      "epoch 200| loss: 0.01789 | train_rmsle: 0.00061 | train_mae: 0.07546 | train_rmse: 0.10133 | train_mse: 0.01027 | valid_rmsle: 0.0021  | valid_mae: 0.14589 | valid_rmse: 0.19464 | valid_mse: 0.03788 |  0:05:30s\n",
      "epoch 201| loss: 0.0195  | train_rmsle: 0.00066 | train_mae: 0.08144 | train_rmse: 0.10781 | train_mse: 0.01162 | valid_rmsle: 0.00217 | valid_mae: 0.14876 | valid_rmse: 0.20018 | valid_mse: 0.04007 |  0:05:32s\n",
      "epoch 202| loss: 0.01915 | train_rmsle: 0.00054 | train_mae: 0.07236 | train_rmse: 0.09705 | train_mse: 0.00942 | valid_rmsle: 0.00206 | valid_mae: 0.14375 | valid_rmse: 0.19477 | valid_mse: 0.03794 |  0:05:34s\n",
      "epoch 203| loss: 0.01811 | train_rmsle: 0.00057 | train_mae: 0.07524 | train_rmse: 0.09931 | train_mse: 0.00986 | valid_rmsle: 0.00216 | valid_mae: 0.14741 | valid_rmse: 0.19786 | valid_mse: 0.03915 |  0:05:35s\n",
      "epoch 204| loss: 0.017   | train_rmsle: 0.00056 | train_mae: 0.07375 | train_rmse: 0.09812 | train_mse: 0.00963 | valid_rmsle: 0.0021  | valid_mae: 0.14419 | valid_rmse: 0.19517 | valid_mse: 0.03809 |  0:05:37s\n",
      "epoch 205| loss: 0.01752 | train_rmsle: 0.00057 | train_mae: 0.07249 | train_rmse: 0.09787 | train_mse: 0.00958 | valid_rmsle: 0.00208 | valid_mae: 0.14373 | valid_rmse: 0.19416 | valid_mse: 0.0377  |  0:05:38s\n",
      "epoch 206| loss: 0.01701 | train_rmsle: 0.00056 | train_mae: 0.07473 | train_rmse: 0.09934 | train_mse: 0.00987 | valid_rmsle: 0.00212 | valid_mae: 0.14603 | valid_rmse: 0.19671 | valid_mse: 0.0387  |  0:05:40s\n",
      "epoch 207| loss: 0.01618 | train_rmsle: 0.00049 | train_mae: 0.06889 | train_rmse: 0.09238 | train_mse: 0.00853 | valid_rmsle: 0.00201 | valid_mae: 0.1424  | valid_rmse: 0.1921  | valid_mse: 0.0369  |  0:05:42s\n",
      "epoch 208| loss: 0.01703 | train_rmsle: 0.00056 | train_mae: 0.07392 | train_rmse: 0.09795 | train_mse: 0.00959 | valid_rmsle: 0.00211 | valid_mae: 0.14566 | valid_rmse: 0.19599 | valid_mse: 0.03841 |  0:05:43s\n",
      "epoch 209| loss: 0.01827 | train_rmsle: 0.00057 | train_mae: 0.07412 | train_rmse: 0.09826 | train_mse: 0.00966 | valid_rmsle: 0.00208 | valid_mae: 0.14376 | valid_rmse: 0.19418 | valid_mse: 0.03771 |  0:05:45s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 197 and best_valid_mse = 0.03667\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.04218665423335448 RMSE: 0.20539390018536208 R2: 0.8132559370104215 MAE: 0.15455524757591127\n",
      "=====================================\n",
      "[13/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 10.88991| train_rmsle: 0.03334 | train_mae: 0.65619 | train_rmse: 0.74873 | train_mse: 0.56059 | valid_rmsle: 0.03321 | valid_mae: 0.65516 | valid_rmse: 0.75035 | valid_mse: 0.56302 |  0:00:02s\n",
      "epoch 1  | loss: 1.16347 | train_rmsle: 0.14564 | train_mae: 1.32357 | train_rmse: 1.40381 | train_mse: 1.97068 | valid_rmsle: 0.14622 | valid_mae: 1.32668 | valid_rmse: 1.40779 | valid_mse: 1.98186 |  0:00:04s\n",
      "epoch 2  | loss: 0.34321 | train_rmsle: 0.07447 | train_mae: 0.97562 | train_rmse: 1.06619 | train_mse: 1.13676 | valid_rmsle: 0.0748  | valid_mae: 0.97781 | valid_rmse: 1.07005 | valid_mse: 1.14501 |  0:00:06s\n",
      "epoch 3  | loss: 0.24591 | train_rmsle: 0.08121 | train_mae: 1.01607 | train_rmse: 1.10582 | train_mse: 1.22284 | valid_rmsle: 0.08153 | valid_mae: 1.01846 | valid_rmse: 1.10943 | valid_mse: 1.23084 |  0:00:08s\n",
      "epoch 4  | loss: 0.16366 | train_rmsle: 0.02909 | train_mae: 0.60051 | train_rmse: 0.66983 | train_mse: 0.44867 | valid_rmsle: 0.02744 | valid_mae: 0.58262 | valid_rmse: 0.6518  | valid_mse: 0.42484 |  0:00:11s\n",
      "epoch 5  | loss: 0.13542 | train_rmsle: 0.0283  | train_mae: 0.55554 | train_rmse: 0.64546 | train_mse: 0.41662 | valid_rmsle: 0.02659 | valid_mae: 0.5357  | valid_rmse: 0.62695 | valid_mse: 0.39307 |  0:00:13s\n",
      "epoch 6  | loss: 0.13319 | train_rmsle: 0.02749 | train_mae: 0.5243  | train_rmse: 0.62972 | train_mse: 0.39655 | valid_rmsle: 0.02588 | valid_mae: 0.50459 | valid_rmse: 0.61186 | valid_mse: 0.37437 |  0:00:15s\n",
      "epoch 7  | loss: 0.12193 | train_rmsle: 0.02055 | train_mae: 0.45147 | train_rmse: 0.55232 | train_mse: 0.30506 | valid_rmsle: 0.01915 | valid_mae: 0.43308 | valid_rmse: 0.53449 | valid_mse: 0.28568 |  0:00:17s\n",
      "epoch 8  | loss: 0.11401 | train_rmsle: 0.01554 | train_mae: 0.39761 | train_rmse: 0.48733 | train_mse: 0.23749 | valid_rmsle: 0.01431 | valid_mae: 0.38062 | valid_rmse: 0.46947 | valid_mse: 0.2204  |  0:00:20s\n",
      "epoch 9  | loss: 0.11333 | train_rmsle: 0.0136  | train_mae: 0.38835 | train_rmse: 0.46346 | train_mse: 0.21479 | valid_rmsle: 0.01245 | valid_mae: 0.3721  | valid_rmse: 0.44605 | valid_mse: 0.19896 |  0:00:22s\n",
      "epoch 10 | loss: 0.12385 | train_rmsle: 0.00843 | train_mae: 0.28766 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.00756 | valid_mae: 0.27142 | valid_rmse: 0.34621 | valid_mse: 0.11986 |  0:00:24s\n",
      "epoch 11 | loss: 0.11103 | train_rmsle: 0.00983 | train_mae: 0.31417 | train_rmse: 0.39195 | train_mse: 0.15363 | valid_rmsle: 0.0089  | valid_mae: 0.29841 | valid_rmse: 0.3753  | valid_mse: 0.14085 |  0:00:26s\n",
      "epoch 12 | loss: 0.10807 | train_rmsle: 0.00808 | train_mae: 0.27871 | train_rmse: 0.35413 | train_mse: 0.12541 | valid_rmsle: 0.00728 | valid_mae: 0.26379 | valid_rmse: 0.339   | valid_mse: 0.11492 |  0:00:28s\n",
      "epoch 13 | loss: 0.10585 | train_rmsle: 0.00699 | train_mae: 0.25324 | train_rmse: 0.32693 | train_mse: 0.10688 | valid_rmsle: 0.00631 | valid_mae: 0.23867 | valid_rmse: 0.31394 | valid_mse: 0.09856 |  0:00:31s\n",
      "epoch 14 | loss: 0.10518 | train_rmsle: 0.00696 | train_mae: 0.25405 | train_rmse: 0.32672 | train_mse: 0.10675 | valid_rmsle: 0.00626 | valid_mae: 0.23933 | valid_rmse: 0.31317 | valid_mse: 0.09808 |  0:00:33s\n",
      "epoch 15 | loss: 0.10232 | train_rmsle: 0.00695 | train_mae: 0.25129 | train_rmse: 0.32568 | train_mse: 0.10607 | valid_rmsle: 0.0063  | valid_mae: 0.2378  | valid_rmse: 0.31327 | valid_mse: 0.09814 |  0:00:35s\n",
      "epoch 16 | loss: 0.10341 | train_rmsle: 0.0069  | train_mae: 0.24912 | train_rmse: 0.32397 | train_mse: 0.10496 | valid_rmsle: 0.00627 | valid_mae: 0.2362  | valid_rmse: 0.31212 | valid_mse: 0.09742 |  0:00:37s\n",
      "epoch 17 | loss: 0.10114 | train_rmsle: 0.00736 | train_mae: 0.26651 | train_rmse: 0.33782 | train_mse: 0.11412 | valid_rmsle: 0.00659 | valid_mae: 0.25121 | valid_rmse: 0.32291 | valid_mse: 0.10427 |  0:00:39s\n",
      "epoch 18 | loss: 0.11089 | train_rmsle: 0.00668 | train_mae: 0.24067 | train_rmse: 0.31677 | train_mse: 0.10034 | valid_rmsle: 0.00611 | valid_mae: 0.2314  | valid_rmse: 0.30659 | valid_mse: 0.094   |  0:00:42s\n",
      "epoch 19 | loss: 0.10189 | train_rmsle: 0.00725 | train_mae: 0.26778 | train_rmse: 0.33647 | train_mse: 0.11321 | valid_rmsle: 0.00654 | valid_mae: 0.25385 | valid_rmse: 0.32264 | valid_mse: 0.10409 |  0:00:44s\n",
      "epoch 20 | loss: 0.10196 | train_rmsle: 0.00673 | train_mae: 0.24652 | train_rmse: 0.3195  | train_mse: 0.10208 | valid_rmsle: 0.0061  | valid_mae: 0.23491 | valid_rmse: 0.30742 | valid_mse: 0.09451 |  0:00:46s\n",
      "epoch 21 | loss: 0.10181 | train_rmsle: 0.00667 | train_mae: 0.24336 | train_rmse: 0.31711 | train_mse: 0.10056 | valid_rmsle: 0.00608 | valid_mae: 0.23237 | valid_rmse: 0.30595 | valid_mse: 0.0936  |  0:00:48s\n",
      "epoch 22 | loss: 0.09871 | train_rmsle: 0.00663 | train_mae: 0.24007 | train_rmse: 0.31509 | train_mse: 0.09928 | valid_rmsle: 0.00604 | valid_mae: 0.23015 | valid_rmse: 0.30418 | valid_mse: 0.09252 |  0:00:50s\n",
      "epoch 23 | loss: 0.10021 | train_rmsle: 0.00677 | train_mae: 0.24867 | train_rmse: 0.32042 | train_mse: 0.10267 | valid_rmsle: 0.00616 | valid_mae: 0.23762 | valid_rmse: 0.30879 | valid_mse: 0.09535 |  0:00:52s\n",
      "epoch 24 | loss: 0.09895 | train_rmsle: 0.00673 | train_mae: 0.24276 | train_rmse: 0.31708 | train_mse: 0.10054 | valid_rmsle: 0.00613 | valid_mae: 0.23376 | valid_rmse: 0.30599 | valid_mse: 0.09363 |  0:00:53s\n",
      "epoch 25 | loss: 0.10029 | train_rmsle: 0.00662 | train_mae: 0.24132 | train_rmse: 0.31519 | train_mse: 0.09934 | valid_rmsle: 0.00606 | valid_mae: 0.2316  | valid_rmse: 0.30485 | valid_mse: 0.09293 |  0:00:55s\n",
      "epoch 26 | loss: 0.09756 | train_rmsle: 0.00674 | train_mae: 0.24925 | train_rmse: 0.3207  | train_mse: 0.10285 | valid_rmsle: 0.00618 | valid_mae: 0.23865 | valid_rmse: 0.31019 | valid_mse: 0.09621 |  0:00:57s\n",
      "epoch 27 | loss: 0.1011  | train_rmsle: 0.0068  | train_mae: 0.25004 | train_rmse: 0.32219 | train_mse: 0.10381 | valid_rmsle: 0.0062  | valid_mae: 0.23919 | valid_rmse: 0.31102 | valid_mse: 0.09673 |  0:00:59s\n",
      "epoch 28 | loss: 0.10585 | train_rmsle: 0.00772 | train_mae: 0.28269 | train_rmse: 0.35015 | train_mse: 0.12261 | valid_rmsle: 0.00704 | valid_mae: 0.26917 | valid_rmse: 0.33725 | valid_mse: 0.11374 |  0:01:01s\n",
      "epoch 29 | loss: 0.10732 | train_rmsle: 0.00657 | train_mae: 0.241   | train_rmse: 0.31437 | train_mse: 0.09883 | valid_rmsle: 0.00608 | valid_mae: 0.23264 | valid_rmse: 0.30605 | valid_mse: 0.09366 |  0:01:04s\n",
      "epoch 30 | loss: 0.10317 | train_rmsle: 0.00666 | train_mae: 0.23701 | train_rmse: 0.31477 | train_mse: 0.09908 | valid_rmsle: 0.00626 | valid_mae: 0.23286 | valid_rmse: 0.30937 | valid_mse: 0.09571 |  0:01:06s\n",
      "epoch 31 | loss: 0.09896 | train_rmsle: 0.00648 | train_mae: 0.23675 | train_rmse: 0.3114  | train_mse: 0.09697 | valid_rmsle: 0.00611 | valid_mae: 0.23127 | valid_rmse: 0.30626 | valid_mse: 0.0938  |  0:01:08s\n",
      "epoch 32 | loss: 0.09843 | train_rmsle: 0.00678 | train_mae: 0.23738 | train_rmse: 0.31736 | train_mse: 0.10071 | valid_rmsle: 0.00645 | valid_mae: 0.23646 | valid_rmse: 0.31437 | valid_mse: 0.09883 |  0:01:10s\n",
      "epoch 33 | loss: 0.10175 | train_rmsle: 0.00647 | train_mae: 0.23647 | train_rmse: 0.31145 | train_mse: 0.097   | valid_rmsle: 0.00614 | valid_mae: 0.23229 | valid_rmse: 0.30751 | valid_mse: 0.09456 |  0:01:12s\n",
      "epoch 34 | loss: 0.0991  | train_rmsle: 0.00647 | train_mae: 0.23736 | train_rmse: 0.31145 | train_mse: 0.097   | valid_rmsle: 0.0061  | valid_mae: 0.23273 | valid_rmse: 0.30661 | valid_mse: 0.09401 |  0:01:14s\n",
      "epoch 35 | loss: 0.09886 | train_rmsle: 0.00661 | train_mae: 0.23728 | train_rmse: 0.31373 | train_mse: 0.09843 | valid_rmsle: 0.00633 | valid_mae: 0.23329 | valid_rmse: 0.31061 | valid_mse: 0.09648 |  0:01:17s\n",
      "epoch 36 | loss: 0.09735 | train_rmsle: 0.00659 | train_mae: 0.23379 | train_rmse: 0.31219 | train_mse: 0.09746 | valid_rmsle: 0.00628 | valid_mae: 0.23274 | valid_rmse: 0.30966 | valid_mse: 0.09589 |  0:01:19s\n",
      "epoch 37 | loss: 0.10085 | train_rmsle: 0.00644 | train_mae: 0.23694 | train_rmse: 0.31128 | train_mse: 0.0969  | valid_rmsle: 0.00626 | valid_mae: 0.23597 | valid_rmse: 0.31198 | valid_mse: 0.09733 |  0:01:21s\n",
      "epoch 38 | loss: 0.10905 | train_rmsle: 0.00674 | train_mae: 0.25389 | train_rmse: 0.32306 | train_mse: 0.10437 | valid_rmsle: 0.00645 | valid_mae: 0.24905 | valid_rmse: 0.31958 | valid_mse: 0.10213 |  0:01:23s\n",
      "epoch 39 | loss: 0.09784 | train_rmsle: 0.00633 | train_mae: 0.23784 | train_rmse: 0.30924 | train_mse: 0.09563 | valid_rmsle: 0.00614 | valid_mae: 0.23612 | valid_rmse: 0.30875 | valid_mse: 0.09533 |  0:01:25s\n",
      "epoch 40 | loss: 0.09559 | train_rmsle: 0.00696 | train_mae: 0.23782 | train_rmse: 0.3206  | train_mse: 0.10278 | valid_rmsle: 0.00687 | valid_mae: 0.2429  | valid_rmse: 0.32401 | valid_mse: 0.10498 |  0:01:28s\n",
      "epoch 41 | loss: 0.09642 | train_rmsle: 0.00617 | train_mae: 0.23009 | train_rmse: 0.30351 | train_mse: 0.09212 | valid_rmsle: 0.00611 | valid_mae: 0.23247 | valid_rmse: 0.30669 | valid_mse: 0.09406 |  0:01:30s\n",
      "epoch 42 | loss: 0.09394 | train_rmsle: 0.00616 | train_mae: 0.23106 | train_rmse: 0.30365 | train_mse: 0.09221 | valid_rmsle: 0.00601 | valid_mae: 0.2322  | valid_rmse: 0.30434 | valid_mse: 0.09262 |  0:01:32s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.09252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09989644712509797 RMSE: 0.31606399213624126 R2: 0.5577969205338182 MAE: 0.24058353504254723\n",
      "=====================================\n",
      "[14/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 10.88991| train_rmsle: 0.03334 | train_mae: 0.65619 | train_rmse: 0.74873 | train_mse: 0.56059 | valid_rmsle: 0.03321 | valid_mae: 0.65516 | valid_rmse: 0.75035 | valid_mse: 0.56302 |  0:00:02s\n",
      "epoch 1  | loss: 1.16347 | train_rmsle: 0.14564 | train_mae: 1.32357 | train_rmse: 1.40381 | train_mse: 1.97068 | valid_rmsle: 0.14622 | valid_mae: 1.32668 | valid_rmse: 1.40779 | valid_mse: 1.98186 |  0:00:04s\n",
      "epoch 2  | loss: 0.34321 | train_rmsle: 0.07447 | train_mae: 0.97562 | train_rmse: 1.06619 | train_mse: 1.13676 | valid_rmsle: 0.0748  | valid_mae: 0.97781 | valid_rmse: 1.07005 | valid_mse: 1.14501 |  0:00:06s\n",
      "epoch 3  | loss: 0.24591 | train_rmsle: 0.08121 | train_mae: 1.01607 | train_rmse: 1.10582 | train_mse: 1.22284 | valid_rmsle: 0.08153 | valid_mae: 1.01846 | valid_rmse: 1.10943 | valid_mse: 1.23084 |  0:00:08s\n",
      "epoch 4  | loss: 0.16366 | train_rmsle: 0.02909 | train_mae: 0.60051 | train_rmse: 0.66983 | train_mse: 0.44867 | valid_rmsle: 0.02744 | valid_mae: 0.58262 | valid_rmse: 0.6518  | valid_mse: 0.42484 |  0:00:11s\n",
      "epoch 5  | loss: 0.13542 | train_rmsle: 0.0283  | train_mae: 0.55554 | train_rmse: 0.64546 | train_mse: 0.41662 | valid_rmsle: 0.02659 | valid_mae: 0.5357  | valid_rmse: 0.62695 | valid_mse: 0.39307 |  0:00:13s\n",
      "epoch 6  | loss: 0.13319 | train_rmsle: 0.02749 | train_mae: 0.5243  | train_rmse: 0.62972 | train_mse: 0.39655 | valid_rmsle: 0.02588 | valid_mae: 0.50459 | valid_rmse: 0.61186 | valid_mse: 0.37437 |  0:00:15s\n",
      "epoch 7  | loss: 0.12193 | train_rmsle: 0.02055 | train_mae: 0.45147 | train_rmse: 0.55232 | train_mse: 0.30506 | valid_rmsle: 0.01915 | valid_mae: 0.43308 | valid_rmse: 0.53449 | valid_mse: 0.28568 |  0:00:17s\n",
      "epoch 8  | loss: 0.11401 | train_rmsle: 0.01554 | train_mae: 0.39761 | train_rmse: 0.48733 | train_mse: 0.23749 | valid_rmsle: 0.01431 | valid_mae: 0.38062 | valid_rmse: 0.46947 | valid_mse: 0.2204  |  0:00:19s\n",
      "epoch 9  | loss: 0.11333 | train_rmsle: 0.0136  | train_mae: 0.38835 | train_rmse: 0.46346 | train_mse: 0.21479 | valid_rmsle: 0.01245 | valid_mae: 0.3721  | valid_rmse: 0.44605 | valid_mse: 0.19896 |  0:00:22s\n",
      "epoch 10 | loss: 0.12385 | train_rmsle: 0.00843 | train_mae: 0.28766 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.00756 | valid_mae: 0.27142 | valid_rmse: 0.34621 | valid_mse: 0.11986 |  0:00:24s\n",
      "epoch 11 | loss: 0.11103 | train_rmsle: 0.00983 | train_mae: 0.31417 | train_rmse: 0.39195 | train_mse: 0.15363 | valid_rmsle: 0.0089  | valid_mae: 0.29841 | valid_rmse: 0.3753  | valid_mse: 0.14085 |  0:00:26s\n",
      "epoch 12 | loss: 0.10807 | train_rmsle: 0.00808 | train_mae: 0.27871 | train_rmse: 0.35413 | train_mse: 0.12541 | valid_rmsle: 0.00728 | valid_mae: 0.26379 | valid_rmse: 0.339   | valid_mse: 0.11492 |  0:00:28s\n",
      "epoch 13 | loss: 0.10585 | train_rmsle: 0.00699 | train_mae: 0.25324 | train_rmse: 0.32693 | train_mse: 0.10688 | valid_rmsle: 0.00631 | valid_mae: 0.23867 | valid_rmse: 0.31394 | valid_mse: 0.09856 |  0:00:31s\n",
      "epoch 14 | loss: 0.10518 | train_rmsle: 0.00696 | train_mae: 0.25405 | train_rmse: 0.32672 | train_mse: 0.10675 | valid_rmsle: 0.00626 | valid_mae: 0.23933 | valid_rmse: 0.31317 | valid_mse: 0.09808 |  0:00:33s\n",
      "epoch 15 | loss: 0.10232 | train_rmsle: 0.00695 | train_mae: 0.25129 | train_rmse: 0.32568 | train_mse: 0.10607 | valid_rmsle: 0.0063  | valid_mae: 0.2378  | valid_rmse: 0.31327 | valid_mse: 0.09814 |  0:00:35s\n",
      "epoch 16 | loss: 0.10341 | train_rmsle: 0.0069  | train_mae: 0.24912 | train_rmse: 0.32397 | train_mse: 0.10496 | valid_rmsle: 0.00627 | valid_mae: 0.2362  | valid_rmse: 0.31212 | valid_mse: 0.09742 |  0:00:37s\n",
      "epoch 17 | loss: 0.10114 | train_rmsle: 0.00736 | train_mae: 0.26651 | train_rmse: 0.33782 | train_mse: 0.11412 | valid_rmsle: 0.00659 | valid_mae: 0.25121 | valid_rmse: 0.32291 | valid_mse: 0.10427 |  0:00:39s\n",
      "epoch 18 | loss: 0.11089 | train_rmsle: 0.00668 | train_mae: 0.24067 | train_rmse: 0.31677 | train_mse: 0.10034 | valid_rmsle: 0.00611 | valid_mae: 0.2314  | valid_rmse: 0.30659 | valid_mse: 0.094   |  0:00:42s\n",
      "epoch 19 | loss: 0.10189 | train_rmsle: 0.00725 | train_mae: 0.26778 | train_rmse: 0.33647 | train_mse: 0.11321 | valid_rmsle: 0.00654 | valid_mae: 0.25385 | valid_rmse: 0.32264 | valid_mse: 0.10409 |  0:00:44s\n",
      "epoch 20 | loss: 0.10196 | train_rmsle: 0.00673 | train_mae: 0.24652 | train_rmse: 0.3195  | train_mse: 0.10208 | valid_rmsle: 0.0061  | valid_mae: 0.23491 | valid_rmse: 0.30742 | valid_mse: 0.09451 |  0:00:46s\n",
      "epoch 21 | loss: 0.10181 | train_rmsle: 0.00667 | train_mae: 0.24336 | train_rmse: 0.31711 | train_mse: 0.10056 | valid_rmsle: 0.00608 | valid_mae: 0.23237 | valid_rmse: 0.30595 | valid_mse: 0.0936  |  0:00:48s\n",
      "epoch 22 | loss: 0.09871 | train_rmsle: 0.00663 | train_mae: 0.24007 | train_rmse: 0.31509 | train_mse: 0.09928 | valid_rmsle: 0.00604 | valid_mae: 0.23015 | valid_rmse: 0.30418 | valid_mse: 0.09252 |  0:00:51s\n",
      "epoch 23 | loss: 0.10021 | train_rmsle: 0.00677 | train_mae: 0.24867 | train_rmse: 0.32042 | train_mse: 0.10267 | valid_rmsle: 0.00616 | valid_mae: 0.23762 | valid_rmse: 0.30879 | valid_mse: 0.09535 |  0:00:53s\n",
      "epoch 24 | loss: 0.09895 | train_rmsle: 0.00673 | train_mae: 0.24276 | train_rmse: 0.31708 | train_mse: 0.10054 | valid_rmsle: 0.00613 | valid_mae: 0.23376 | valid_rmse: 0.30599 | valid_mse: 0.09363 |  0:00:55s\n",
      "epoch 25 | loss: 0.10029 | train_rmsle: 0.00662 | train_mae: 0.24132 | train_rmse: 0.31519 | train_mse: 0.09934 | valid_rmsle: 0.00606 | valid_mae: 0.2316  | valid_rmse: 0.30485 | valid_mse: 0.09293 |  0:00:57s\n",
      "epoch 26 | loss: 0.09756 | train_rmsle: 0.00674 | train_mae: 0.24925 | train_rmse: 0.3207  | train_mse: 0.10285 | valid_rmsle: 0.00618 | valid_mae: 0.23865 | valid_rmse: 0.31019 | valid_mse: 0.09621 |  0:00:59s\n",
      "epoch 27 | loss: 0.1011  | train_rmsle: 0.0068  | train_mae: 0.25004 | train_rmse: 0.32219 | train_mse: 0.10381 | valid_rmsle: 0.0062  | valid_mae: 0.23919 | valid_rmse: 0.31102 | valid_mse: 0.09673 |  0:01:01s\n",
      "epoch 28 | loss: 0.10585 | train_rmsle: 0.00772 | train_mae: 0.28269 | train_rmse: 0.35015 | train_mse: 0.12261 | valid_rmsle: 0.00704 | valid_mae: 0.26917 | valid_rmse: 0.33725 | valid_mse: 0.11374 |  0:01:03s\n",
      "epoch 29 | loss: 0.10732 | train_rmsle: 0.00657 | train_mae: 0.241   | train_rmse: 0.31437 | train_mse: 0.09883 | valid_rmsle: 0.00608 | valid_mae: 0.23264 | valid_rmse: 0.30605 | valid_mse: 0.09366 |  0:01:05s\n",
      "epoch 30 | loss: 0.10317 | train_rmsle: 0.00666 | train_mae: 0.23701 | train_rmse: 0.31477 | train_mse: 0.09908 | valid_rmsle: 0.00626 | valid_mae: 0.23286 | valid_rmse: 0.30937 | valid_mse: 0.09571 |  0:01:07s\n",
      "epoch 31 | loss: 0.09896 | train_rmsle: 0.00648 | train_mae: 0.23675 | train_rmse: 0.3114  | train_mse: 0.09697 | valid_rmsle: 0.00611 | valid_mae: 0.23127 | valid_rmse: 0.30626 | valid_mse: 0.0938  |  0:01:09s\n",
      "epoch 32 | loss: 0.09843 | train_rmsle: 0.00678 | train_mae: 0.23738 | train_rmse: 0.31736 | train_mse: 0.10071 | valid_rmsle: 0.00645 | valid_mae: 0.23646 | valid_rmse: 0.31437 | valid_mse: 0.09883 |  0:01:11s\n",
      "epoch 33 | loss: 0.10175 | train_rmsle: 0.00647 | train_mae: 0.23647 | train_rmse: 0.31145 | train_mse: 0.097   | valid_rmsle: 0.00614 | valid_mae: 0.23229 | valid_rmse: 0.30751 | valid_mse: 0.09456 |  0:01:13s\n",
      "epoch 34 | loss: 0.0991  | train_rmsle: 0.00647 | train_mae: 0.23736 | train_rmse: 0.31145 | train_mse: 0.097   | valid_rmsle: 0.0061  | valid_mae: 0.23273 | valid_rmse: 0.30661 | valid_mse: 0.09401 |  0:01:16s\n",
      "epoch 35 | loss: 0.09886 | train_rmsle: 0.00661 | train_mae: 0.23728 | train_rmse: 0.31373 | train_mse: 0.09843 | valid_rmsle: 0.00633 | valid_mae: 0.23329 | valid_rmse: 0.31061 | valid_mse: 0.09648 |  0:01:18s\n",
      "epoch 36 | loss: 0.09735 | train_rmsle: 0.00659 | train_mae: 0.23379 | train_rmse: 0.31219 | train_mse: 0.09746 | valid_rmsle: 0.00628 | valid_mae: 0.23274 | valid_rmse: 0.30966 | valid_mse: 0.09589 |  0:01:20s\n",
      "epoch 37 | loss: 0.10085 | train_rmsle: 0.00644 | train_mae: 0.23694 | train_rmse: 0.31128 | train_mse: 0.0969  | valid_rmsle: 0.00626 | valid_mae: 0.23597 | valid_rmse: 0.31198 | valid_mse: 0.09733 |  0:01:23s\n",
      "epoch 38 | loss: 0.10905 | train_rmsle: 0.00674 | train_mae: 0.25389 | train_rmse: 0.32306 | train_mse: 0.10437 | valid_rmsle: 0.00645 | valid_mae: 0.24905 | valid_rmse: 0.31958 | valid_mse: 0.10213 |  0:01:25s\n",
      "epoch 39 | loss: 0.09784 | train_rmsle: 0.00633 | train_mae: 0.23784 | train_rmse: 0.30924 | train_mse: 0.09563 | valid_rmsle: 0.00614 | valid_mae: 0.23612 | valid_rmse: 0.30875 | valid_mse: 0.09533 |  0:01:27s\n",
      "epoch 40 | loss: 0.09559 | train_rmsle: 0.00696 | train_mae: 0.23782 | train_rmse: 0.3206  | train_mse: 0.10278 | valid_rmsle: 0.00687 | valid_mae: 0.2429  | valid_rmse: 0.32401 | valid_mse: 0.10498 |  0:01:29s\n",
      "epoch 41 | loss: 0.09642 | train_rmsle: 0.00617 | train_mae: 0.23009 | train_rmse: 0.30351 | train_mse: 0.09212 | valid_rmsle: 0.00611 | valid_mae: 0.23247 | valid_rmse: 0.30669 | valid_mse: 0.09406 |  0:01:32s\n",
      "epoch 42 | loss: 0.09394 | train_rmsle: 0.00616 | train_mae: 0.23106 | train_rmse: 0.30365 | train_mse: 0.09221 | valid_rmsle: 0.00601 | valid_mae: 0.2322  | valid_rmse: 0.30434 | valid_mse: 0.09262 |  0:01:34s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.09252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09989644712509797 RMSE: 0.31606399213624126 R2: 0.5577969205338182 MAE: 0.24058353504254723\n",
      "=====================================\n",
      "[15/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 10.88991| train_rmsle: 0.03334 | train_mae: 0.65619 | train_rmse: 0.74873 | train_mse: 0.56059 | valid_rmsle: 0.03321 | valid_mae: 0.65516 | valid_rmse: 0.75035 | valid_mse: 0.56302 |  0:00:02s\n",
      "epoch 1  | loss: 1.16347 | train_rmsle: 0.14564 | train_mae: 1.32357 | train_rmse: 1.40381 | train_mse: 1.97068 | valid_rmsle: 0.14622 | valid_mae: 1.32668 | valid_rmse: 1.40779 | valid_mse: 1.98186 |  0:00:03s\n",
      "epoch 2  | loss: 0.34321 | train_rmsle: 0.07447 | train_mae: 0.97562 | train_rmse: 1.06619 | train_mse: 1.13676 | valid_rmsle: 0.0748  | valid_mae: 0.97781 | valid_rmse: 1.07005 | valid_mse: 1.14501 |  0:00:06s\n",
      "epoch 3  | loss: 0.24591 | train_rmsle: 0.08121 | train_mae: 1.01607 | train_rmse: 1.10582 | train_mse: 1.22284 | valid_rmsle: 0.08153 | valid_mae: 1.01846 | valid_rmse: 1.10943 | valid_mse: 1.23084 |  0:00:08s\n",
      "epoch 4  | loss: 0.16366 | train_rmsle: 0.02909 | train_mae: 0.60051 | train_rmse: 0.66983 | train_mse: 0.44867 | valid_rmsle: 0.02744 | valid_mae: 0.58262 | valid_rmse: 0.6518  | valid_mse: 0.42484 |  0:00:10s\n",
      "epoch 5  | loss: 0.13542 | train_rmsle: 0.0283  | train_mae: 0.55554 | train_rmse: 0.64546 | train_mse: 0.41662 | valid_rmsle: 0.02659 | valid_mae: 0.5357  | valid_rmse: 0.62695 | valid_mse: 0.39307 |  0:00:12s\n",
      "epoch 6  | loss: 0.13319 | train_rmsle: 0.02749 | train_mae: 0.5243  | train_rmse: 0.62972 | train_mse: 0.39655 | valid_rmsle: 0.02588 | valid_mae: 0.50459 | valid_rmse: 0.61186 | valid_mse: 0.37437 |  0:00:14s\n",
      "epoch 7  | loss: 0.12193 | train_rmsle: 0.02055 | train_mae: 0.45147 | train_rmse: 0.55232 | train_mse: 0.30506 | valid_rmsle: 0.01915 | valid_mae: 0.43308 | valid_rmse: 0.53449 | valid_mse: 0.28568 |  0:00:17s\n",
      "epoch 8  | loss: 0.11401 | train_rmsle: 0.01554 | train_mae: 0.39761 | train_rmse: 0.48733 | train_mse: 0.23749 | valid_rmsle: 0.01431 | valid_mae: 0.38062 | valid_rmse: 0.46947 | valid_mse: 0.2204  |  0:00:19s\n",
      "epoch 9  | loss: 0.11333 | train_rmsle: 0.0136  | train_mae: 0.38835 | train_rmse: 0.46346 | train_mse: 0.21479 | valid_rmsle: 0.01245 | valid_mae: 0.3721  | valid_rmse: 0.44605 | valid_mse: 0.19896 |  0:00:21s\n",
      "epoch 10 | loss: 0.12385 | train_rmsle: 0.00843 | train_mae: 0.28766 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.00756 | valid_mae: 0.27142 | valid_rmse: 0.34621 | valid_mse: 0.11986 |  0:00:24s\n",
      "epoch 11 | loss: 0.11103 | train_rmsle: 0.00983 | train_mae: 0.31417 | train_rmse: 0.39195 | train_mse: 0.15363 | valid_rmsle: 0.0089  | valid_mae: 0.29841 | valid_rmse: 0.3753  | valid_mse: 0.14085 |  0:00:26s\n",
      "epoch 12 | loss: 0.10807 | train_rmsle: 0.00808 | train_mae: 0.27871 | train_rmse: 0.35413 | train_mse: 0.12541 | valid_rmsle: 0.00728 | valid_mae: 0.26379 | valid_rmse: 0.339   | valid_mse: 0.11492 |  0:00:28s\n",
      "epoch 13 | loss: 0.10585 | train_rmsle: 0.00699 | train_mae: 0.25324 | train_rmse: 0.32693 | train_mse: 0.10688 | valid_rmsle: 0.00631 | valid_mae: 0.23867 | valid_rmse: 0.31394 | valid_mse: 0.09856 |  0:00:30s\n",
      "epoch 14 | loss: 0.10518 | train_rmsle: 0.00696 | train_mae: 0.25405 | train_rmse: 0.32672 | train_mse: 0.10675 | valid_rmsle: 0.00626 | valid_mae: 0.23933 | valid_rmse: 0.31317 | valid_mse: 0.09808 |  0:00:33s\n",
      "epoch 15 | loss: 0.10232 | train_rmsle: 0.00695 | train_mae: 0.25129 | train_rmse: 0.32568 | train_mse: 0.10607 | valid_rmsle: 0.0063  | valid_mae: 0.2378  | valid_rmse: 0.31327 | valid_mse: 0.09814 |  0:00:35s\n",
      "epoch 16 | loss: 0.10341 | train_rmsle: 0.0069  | train_mae: 0.24912 | train_rmse: 0.32397 | train_mse: 0.10496 | valid_rmsle: 0.00627 | valid_mae: 0.2362  | valid_rmse: 0.31212 | valid_mse: 0.09742 |  0:00:37s\n",
      "epoch 17 | loss: 0.10114 | train_rmsle: 0.00736 | train_mae: 0.26651 | train_rmse: 0.33782 | train_mse: 0.11412 | valid_rmsle: 0.00659 | valid_mae: 0.25121 | valid_rmse: 0.32291 | valid_mse: 0.10427 |  0:00:40s\n",
      "epoch 18 | loss: 0.11089 | train_rmsle: 0.00668 | train_mae: 0.24067 | train_rmse: 0.31677 | train_mse: 0.10034 | valid_rmsle: 0.00611 | valid_mae: 0.2314  | valid_rmse: 0.30659 | valid_mse: 0.094   |  0:00:42s\n",
      "epoch 19 | loss: 0.10189 | train_rmsle: 0.00725 | train_mae: 0.26778 | train_rmse: 0.33647 | train_mse: 0.11321 | valid_rmsle: 0.00654 | valid_mae: 0.25385 | valid_rmse: 0.32264 | valid_mse: 0.10409 |  0:00:44s\n",
      "epoch 20 | loss: 0.10196 | train_rmsle: 0.00673 | train_mae: 0.24652 | train_rmse: 0.3195  | train_mse: 0.10208 | valid_rmsle: 0.0061  | valid_mae: 0.23491 | valid_rmse: 0.30742 | valid_mse: 0.09451 |  0:00:47s\n",
      "epoch 21 | loss: 0.10181 | train_rmsle: 0.00667 | train_mae: 0.24336 | train_rmse: 0.31711 | train_mse: 0.10056 | valid_rmsle: 0.00608 | valid_mae: 0.23237 | valid_rmse: 0.30595 | valid_mse: 0.0936  |  0:00:49s\n",
      "epoch 22 | loss: 0.09871 | train_rmsle: 0.00663 | train_mae: 0.24007 | train_rmse: 0.31509 | train_mse: 0.09928 | valid_rmsle: 0.00604 | valid_mae: 0.23015 | valid_rmse: 0.30418 | valid_mse: 0.09252 |  0:00:51s\n",
      "epoch 23 | loss: 0.10021 | train_rmsle: 0.00677 | train_mae: 0.24867 | train_rmse: 0.32042 | train_mse: 0.10267 | valid_rmsle: 0.00616 | valid_mae: 0.23762 | valid_rmse: 0.30879 | valid_mse: 0.09535 |  0:00:54s\n",
      "epoch 24 | loss: 0.09895 | train_rmsle: 0.00673 | train_mae: 0.24276 | train_rmse: 0.31708 | train_mse: 0.10054 | valid_rmsle: 0.00613 | valid_mae: 0.23376 | valid_rmse: 0.30599 | valid_mse: 0.09363 |  0:00:56s\n",
      "epoch 25 | loss: 0.10029 | train_rmsle: 0.00662 | train_mae: 0.24132 | train_rmse: 0.31519 | train_mse: 0.09934 | valid_rmsle: 0.00606 | valid_mae: 0.2316  | valid_rmse: 0.30485 | valid_mse: 0.09293 |  0:00:58s\n",
      "epoch 26 | loss: 0.09756 | train_rmsle: 0.00674 | train_mae: 0.24925 | train_rmse: 0.3207  | train_mse: 0.10285 | valid_rmsle: 0.00618 | valid_mae: 0.23865 | valid_rmse: 0.31019 | valid_mse: 0.09621 |  0:01:00s\n",
      "epoch 27 | loss: 0.1011  | train_rmsle: 0.0068  | train_mae: 0.25004 | train_rmse: 0.32219 | train_mse: 0.10381 | valid_rmsle: 0.0062  | valid_mae: 0.23919 | valid_rmse: 0.31102 | valid_mse: 0.09673 |  0:01:03s\n",
      "epoch 28 | loss: 0.10585 | train_rmsle: 0.00772 | train_mae: 0.28269 | train_rmse: 0.35015 | train_mse: 0.12261 | valid_rmsle: 0.00704 | valid_mae: 0.26917 | valid_rmse: 0.33725 | valid_mse: 0.11374 |  0:01:05s\n",
      "epoch 29 | loss: 0.10732 | train_rmsle: 0.00657 | train_mae: 0.241   | train_rmse: 0.31437 | train_mse: 0.09883 | valid_rmsle: 0.00608 | valid_mae: 0.23264 | valid_rmse: 0.30605 | valid_mse: 0.09366 |  0:01:07s\n",
      "epoch 30 | loss: 0.10317 | train_rmsle: 0.00666 | train_mae: 0.23701 | train_rmse: 0.31477 | train_mse: 0.09908 | valid_rmsle: 0.00626 | valid_mae: 0.23286 | valid_rmse: 0.30937 | valid_mse: 0.09571 |  0:01:10s\n",
      "epoch 31 | loss: 0.09896 | train_rmsle: 0.00648 | train_mae: 0.23675 | train_rmse: 0.3114  | train_mse: 0.09697 | valid_rmsle: 0.00611 | valid_mae: 0.23127 | valid_rmse: 0.30626 | valid_mse: 0.0938  |  0:01:12s\n",
      "epoch 32 | loss: 0.09843 | train_rmsle: 0.00678 | train_mae: 0.23738 | train_rmse: 0.31736 | train_mse: 0.10071 | valid_rmsle: 0.00645 | valid_mae: 0.23646 | valid_rmse: 0.31437 | valid_mse: 0.09883 |  0:01:14s\n",
      "epoch 33 | loss: 0.10175 | train_rmsle: 0.00647 | train_mae: 0.23647 | train_rmse: 0.31145 | train_mse: 0.097   | valid_rmsle: 0.00614 | valid_mae: 0.23229 | valid_rmse: 0.30751 | valid_mse: 0.09456 |  0:01:15s\n",
      "epoch 34 | loss: 0.0991  | train_rmsle: 0.00647 | train_mae: 0.23736 | train_rmse: 0.31145 | train_mse: 0.097   | valid_rmsle: 0.0061  | valid_mae: 0.23273 | valid_rmse: 0.30661 | valid_mse: 0.09401 |  0:01:17s\n",
      "epoch 35 | loss: 0.09886 | train_rmsle: 0.00661 | train_mae: 0.23728 | train_rmse: 0.31373 | train_mse: 0.09843 | valid_rmsle: 0.00633 | valid_mae: 0.23329 | valid_rmse: 0.31061 | valid_mse: 0.09648 |  0:01:19s\n",
      "epoch 36 | loss: 0.09735 | train_rmsle: 0.00659 | train_mae: 0.23379 | train_rmse: 0.31219 | train_mse: 0.09746 | valid_rmsle: 0.00628 | valid_mae: 0.23274 | valid_rmse: 0.30966 | valid_mse: 0.09589 |  0:01:21s\n",
      "epoch 37 | loss: 0.10085 | train_rmsle: 0.00644 | train_mae: 0.23694 | train_rmse: 0.31128 | train_mse: 0.0969  | valid_rmsle: 0.00626 | valid_mae: 0.23597 | valid_rmse: 0.31198 | valid_mse: 0.09733 |  0:01:23s\n",
      "epoch 38 | loss: 0.10905 | train_rmsle: 0.00674 | train_mae: 0.25389 | train_rmse: 0.32306 | train_mse: 0.10437 | valid_rmsle: 0.00645 | valid_mae: 0.24905 | valid_rmse: 0.31958 | valid_mse: 0.10213 |  0:01:26s\n",
      "epoch 39 | loss: 0.09784 | train_rmsle: 0.00633 | train_mae: 0.23784 | train_rmse: 0.30924 | train_mse: 0.09563 | valid_rmsle: 0.00614 | valid_mae: 0.23612 | valid_rmse: 0.30875 | valid_mse: 0.09533 |  0:01:28s\n",
      "epoch 40 | loss: 0.09559 | train_rmsle: 0.00696 | train_mae: 0.23782 | train_rmse: 0.3206  | train_mse: 0.10278 | valid_rmsle: 0.00687 | valid_mae: 0.2429  | valid_rmse: 0.32401 | valid_mse: 0.10498 |  0:01:30s\n",
      "epoch 41 | loss: 0.09642 | train_rmsle: 0.00617 | train_mae: 0.23009 | train_rmse: 0.30351 | train_mse: 0.09212 | valid_rmsle: 0.00611 | valid_mae: 0.23247 | valid_rmse: 0.30669 | valid_mse: 0.09406 |  0:01:32s\n",
      "epoch 42 | loss: 0.09394 | train_rmsle: 0.00616 | train_mae: 0.23106 | train_rmse: 0.30365 | train_mse: 0.09221 | valid_rmsle: 0.00601 | valid_mae: 0.2322  | valid_rmse: 0.30434 | valid_mse: 0.09262 |  0:01:34s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.09252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09989644712509797 RMSE: 0.31606399213624126 R2: 0.5577969205338182 MAE: 0.24058353504254723\n",
      "=====================================\n",
      "[16/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 10.88991| train_rmsle: 0.03334 | train_mae: 0.65619 | train_rmse: 0.74873 | train_mse: 0.56059 | valid_rmsle: 0.03321 | valid_mae: 0.65516 | valid_rmse: 0.75035 | valid_mse: 0.56302 |  0:00:02s\n",
      "epoch 1  | loss: 1.16347 | train_rmsle: 0.14564 | train_mae: 1.32357 | train_rmse: 1.40381 | train_mse: 1.97068 | valid_rmsle: 0.14622 | valid_mae: 1.32668 | valid_rmse: 1.40779 | valid_mse: 1.98186 |  0:00:04s\n",
      "epoch 2  | loss: 0.34321 | train_rmsle: 0.07447 | train_mae: 0.97562 | train_rmse: 1.06619 | train_mse: 1.13676 | valid_rmsle: 0.0748  | valid_mae: 0.97781 | valid_rmse: 1.07005 | valid_mse: 1.14501 |  0:00:06s\n",
      "epoch 3  | loss: 0.24591 | train_rmsle: 0.08121 | train_mae: 1.01607 | train_rmse: 1.10582 | train_mse: 1.22284 | valid_rmsle: 0.08153 | valid_mae: 1.01846 | valid_rmse: 1.10943 | valid_mse: 1.23084 |  0:00:08s\n",
      "epoch 4  | loss: 0.16366 | train_rmsle: 0.02909 | train_mae: 0.60051 | train_rmse: 0.66983 | train_mse: 0.44867 | valid_rmsle: 0.02744 | valid_mae: 0.58262 | valid_rmse: 0.6518  | valid_mse: 0.42484 |  0:00:10s\n",
      "epoch 5  | loss: 0.13542 | train_rmsle: 0.0283  | train_mae: 0.55554 | train_rmse: 0.64546 | train_mse: 0.41662 | valid_rmsle: 0.02659 | valid_mae: 0.5357  | valid_rmse: 0.62695 | valid_mse: 0.39307 |  0:00:12s\n",
      "epoch 6  | loss: 0.13319 | train_rmsle: 0.02749 | train_mae: 0.5243  | train_rmse: 0.62972 | train_mse: 0.39655 | valid_rmsle: 0.02588 | valid_mae: 0.50459 | valid_rmse: 0.61186 | valid_mse: 0.37437 |  0:00:15s\n",
      "epoch 7  | loss: 0.12193 | train_rmsle: 0.02055 | train_mae: 0.45147 | train_rmse: 0.55232 | train_mse: 0.30506 | valid_rmsle: 0.01915 | valid_mae: 0.43308 | valid_rmse: 0.53449 | valid_mse: 0.28568 |  0:00:17s\n",
      "epoch 8  | loss: 0.11401 | train_rmsle: 0.01554 | train_mae: 0.39761 | train_rmse: 0.48733 | train_mse: 0.23749 | valid_rmsle: 0.01431 | valid_mae: 0.38062 | valid_rmse: 0.46947 | valid_mse: 0.2204  |  0:00:19s\n",
      "epoch 9  | loss: 0.11333 | train_rmsle: 0.0136  | train_mae: 0.38835 | train_rmse: 0.46346 | train_mse: 0.21479 | valid_rmsle: 0.01245 | valid_mae: 0.3721  | valid_rmse: 0.44605 | valid_mse: 0.19896 |  0:00:22s\n",
      "epoch 10 | loss: 0.12385 | train_rmsle: 0.00843 | train_mae: 0.28766 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.00756 | valid_mae: 0.27142 | valid_rmse: 0.34621 | valid_mse: 0.11986 |  0:00:24s\n",
      "epoch 11 | loss: 0.11103 | train_rmsle: 0.00983 | train_mae: 0.31417 | train_rmse: 0.39195 | train_mse: 0.15363 | valid_rmsle: 0.0089  | valid_mae: 0.29841 | valid_rmse: 0.3753  | valid_mse: 0.14085 |  0:00:26s\n",
      "epoch 12 | loss: 0.10807 | train_rmsle: 0.00808 | train_mae: 0.27871 | train_rmse: 0.35413 | train_mse: 0.12541 | valid_rmsle: 0.00728 | valid_mae: 0.26379 | valid_rmse: 0.339   | valid_mse: 0.11492 |  0:00:28s\n",
      "epoch 13 | loss: 0.10585 | train_rmsle: 0.00699 | train_mae: 0.25324 | train_rmse: 0.32693 | train_mse: 0.10688 | valid_rmsle: 0.00631 | valid_mae: 0.23867 | valid_rmse: 0.31394 | valid_mse: 0.09856 |  0:00:30s\n",
      "epoch 14 | loss: 0.10518 | train_rmsle: 0.00696 | train_mae: 0.25405 | train_rmse: 0.32672 | train_mse: 0.10675 | valid_rmsle: 0.00626 | valid_mae: 0.23933 | valid_rmse: 0.31317 | valid_mse: 0.09808 |  0:00:32s\n",
      "epoch 15 | loss: 0.10232 | train_rmsle: 0.00695 | train_mae: 0.25129 | train_rmse: 0.32568 | train_mse: 0.10607 | valid_rmsle: 0.0063  | valid_mae: 0.2378  | valid_rmse: 0.31327 | valid_mse: 0.09814 |  0:00:34s\n",
      "epoch 16 | loss: 0.10341 | train_rmsle: 0.0069  | train_mae: 0.24912 | train_rmse: 0.32397 | train_mse: 0.10496 | valid_rmsle: 0.00627 | valid_mae: 0.2362  | valid_rmse: 0.31212 | valid_mse: 0.09742 |  0:00:36s\n",
      "epoch 17 | loss: 0.10114 | train_rmsle: 0.00736 | train_mae: 0.26651 | train_rmse: 0.33782 | train_mse: 0.11412 | valid_rmsle: 0.00659 | valid_mae: 0.25121 | valid_rmse: 0.32291 | valid_mse: 0.10427 |  0:00:38s\n",
      "epoch 18 | loss: 0.11089 | train_rmsle: 0.00668 | train_mae: 0.24067 | train_rmse: 0.31677 | train_mse: 0.10034 | valid_rmsle: 0.00611 | valid_mae: 0.2314  | valid_rmse: 0.30659 | valid_mse: 0.094   |  0:00:40s\n",
      "epoch 19 | loss: 0.10189 | train_rmsle: 0.00725 | train_mae: 0.26778 | train_rmse: 0.33647 | train_mse: 0.11321 | valid_rmsle: 0.00654 | valid_mae: 0.25385 | valid_rmse: 0.32264 | valid_mse: 0.10409 |  0:00:43s\n",
      "epoch 20 | loss: 0.10196 | train_rmsle: 0.00673 | train_mae: 0.24652 | train_rmse: 0.3195  | train_mse: 0.10208 | valid_rmsle: 0.0061  | valid_mae: 0.23491 | valid_rmse: 0.30742 | valid_mse: 0.09451 |  0:00:45s\n",
      "epoch 21 | loss: 0.10181 | train_rmsle: 0.00667 | train_mae: 0.24336 | train_rmse: 0.31711 | train_mse: 0.10056 | valid_rmsle: 0.00608 | valid_mae: 0.23237 | valid_rmse: 0.30595 | valid_mse: 0.0936  |  0:00:47s\n",
      "epoch 22 | loss: 0.09871 | train_rmsle: 0.00663 | train_mae: 0.24007 | train_rmse: 0.31509 | train_mse: 0.09928 | valid_rmsle: 0.00604 | valid_mae: 0.23015 | valid_rmse: 0.30418 | valid_mse: 0.09252 |  0:00:50s\n",
      "epoch 23 | loss: 0.10021 | train_rmsle: 0.00677 | train_mae: 0.24867 | train_rmse: 0.32042 | train_mse: 0.10267 | valid_rmsle: 0.00616 | valid_mae: 0.23762 | valid_rmse: 0.30879 | valid_mse: 0.09535 |  0:00:52s\n",
      "epoch 24 | loss: 0.09895 | train_rmsle: 0.00673 | train_mae: 0.24276 | train_rmse: 0.31708 | train_mse: 0.10054 | valid_rmsle: 0.00613 | valid_mae: 0.23376 | valid_rmse: 0.30599 | valid_mse: 0.09363 |  0:00:54s\n",
      "epoch 25 | loss: 0.10029 | train_rmsle: 0.00662 | train_mae: 0.24132 | train_rmse: 0.31519 | train_mse: 0.09934 | valid_rmsle: 0.00606 | valid_mae: 0.2316  | valid_rmse: 0.30485 | valid_mse: 0.09293 |  0:00:56s\n",
      "epoch 26 | loss: 0.09756 | train_rmsle: 0.00674 | train_mae: 0.24925 | train_rmse: 0.3207  | train_mse: 0.10285 | valid_rmsle: 0.00618 | valid_mae: 0.23865 | valid_rmse: 0.31019 | valid_mse: 0.09621 |  0:00:59s\n",
      "epoch 27 | loss: 0.1011  | train_rmsle: 0.0068  | train_mae: 0.25004 | train_rmse: 0.32219 | train_mse: 0.10381 | valid_rmsle: 0.0062  | valid_mae: 0.23919 | valid_rmse: 0.31102 | valid_mse: 0.09673 |  0:01:01s\n",
      "epoch 28 | loss: 0.10585 | train_rmsle: 0.00772 | train_mae: 0.28269 | train_rmse: 0.35015 | train_mse: 0.12261 | valid_rmsle: 0.00704 | valid_mae: 0.26917 | valid_rmse: 0.33725 | valid_mse: 0.11374 |  0:01:03s\n",
      "epoch 29 | loss: 0.10732 | train_rmsle: 0.00657 | train_mae: 0.241   | train_rmse: 0.31437 | train_mse: 0.09883 | valid_rmsle: 0.00608 | valid_mae: 0.23264 | valid_rmse: 0.30605 | valid_mse: 0.09366 |  0:01:05s\n",
      "epoch 30 | loss: 0.10317 | train_rmsle: 0.00666 | train_mae: 0.23701 | train_rmse: 0.31477 | train_mse: 0.09908 | valid_rmsle: 0.00626 | valid_mae: 0.23286 | valid_rmse: 0.30937 | valid_mse: 0.09571 |  0:01:08s\n",
      "epoch 31 | loss: 0.09896 | train_rmsle: 0.00648 | train_mae: 0.23675 | train_rmse: 0.3114  | train_mse: 0.09697 | valid_rmsle: 0.00611 | valid_mae: 0.23127 | valid_rmse: 0.30626 | valid_mse: 0.0938  |  0:01:10s\n",
      "epoch 32 | loss: 0.09843 | train_rmsle: 0.00678 | train_mae: 0.23738 | train_rmse: 0.31736 | train_mse: 0.10071 | valid_rmsle: 0.00645 | valid_mae: 0.23646 | valid_rmse: 0.31437 | valid_mse: 0.09883 |  0:01:12s\n",
      "epoch 33 | loss: 0.10175 | train_rmsle: 0.00647 | train_mae: 0.23647 | train_rmse: 0.31145 | train_mse: 0.097   | valid_rmsle: 0.00614 | valid_mae: 0.23229 | valid_rmse: 0.30751 | valid_mse: 0.09456 |  0:01:14s\n",
      "epoch 34 | loss: 0.0991  | train_rmsle: 0.00647 | train_mae: 0.23736 | train_rmse: 0.31145 | train_mse: 0.097   | valid_rmsle: 0.0061  | valid_mae: 0.23273 | valid_rmse: 0.30661 | valid_mse: 0.09401 |  0:01:17s\n",
      "epoch 35 | loss: 0.09886 | train_rmsle: 0.00661 | train_mae: 0.23728 | train_rmse: 0.31373 | train_mse: 0.09843 | valid_rmsle: 0.00633 | valid_mae: 0.23329 | valid_rmse: 0.31061 | valid_mse: 0.09648 |  0:01:19s\n",
      "epoch 36 | loss: 0.09735 | train_rmsle: 0.00659 | train_mae: 0.23379 | train_rmse: 0.31219 | train_mse: 0.09746 | valid_rmsle: 0.00628 | valid_mae: 0.23274 | valid_rmse: 0.30966 | valid_mse: 0.09589 |  0:01:21s\n",
      "epoch 37 | loss: 0.10085 | train_rmsle: 0.00644 | train_mae: 0.23694 | train_rmse: 0.31128 | train_mse: 0.0969  | valid_rmsle: 0.00626 | valid_mae: 0.23597 | valid_rmse: 0.31198 | valid_mse: 0.09733 |  0:01:23s\n",
      "epoch 38 | loss: 0.10905 | train_rmsle: 0.00674 | train_mae: 0.25389 | train_rmse: 0.32306 | train_mse: 0.10437 | valid_rmsle: 0.00645 | valid_mae: 0.24905 | valid_rmse: 0.31958 | valid_mse: 0.10213 |  0:01:26s\n",
      "epoch 39 | loss: 0.09784 | train_rmsle: 0.00633 | train_mae: 0.23784 | train_rmse: 0.30924 | train_mse: 0.09563 | valid_rmsle: 0.00614 | valid_mae: 0.23612 | valid_rmse: 0.30875 | valid_mse: 0.09533 |  0:01:28s\n",
      "epoch 40 | loss: 0.09559 | train_rmsle: 0.00696 | train_mae: 0.23782 | train_rmse: 0.3206  | train_mse: 0.10278 | valid_rmsle: 0.00687 | valid_mae: 0.2429  | valid_rmse: 0.32401 | valid_mse: 0.10498 |  0:01:30s\n",
      "epoch 41 | loss: 0.09642 | train_rmsle: 0.00617 | train_mae: 0.23009 | train_rmse: 0.30351 | train_mse: 0.09212 | valid_rmsle: 0.00611 | valid_mae: 0.23247 | valid_rmse: 0.30669 | valid_mse: 0.09406 |  0:01:32s\n",
      "epoch 42 | loss: 0.09394 | train_rmsle: 0.00616 | train_mae: 0.23106 | train_rmse: 0.30365 | train_mse: 0.09221 | valid_rmsle: 0.00601 | valid_mae: 0.2322  | valid_rmse: 0.30434 | valid_mse: 0.09262 |  0:01:35s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.09252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09989644712509797 RMSE: 0.31606399213624126 R2: 0.5577969205338182 MAE: 0.24058353504254723\n",
      "=====================================\n",
      "[17/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 18.40649| train_rmsle: 0.74473 | train_mae: 2.46611 | train_rmse: 2.51319 | train_mse: 6.31614 | valid_rmsle: 0.74818 | valid_mae: 2.47364 | valid_rmse: 2.51966 | valid_mse: 6.34869 |  0:00:02s\n",
      "epoch 1  | loss: 3.16101 | train_rmsle: 0.10384 | train_mae: 1.12551 | train_rmse: 1.21901 | train_mse: 1.48598 | valid_rmsle: 0.10584 | valid_mae: 1.13536 | valid_rmse: 1.23073 | valid_mse: 1.5147  |  0:00:04s\n",
      "epoch 2  | loss: 0.94953 | train_rmsle: 0.09335 | train_mae: 1.08376 | train_rmse: 1.17197 | train_mse: 1.37352 | valid_rmsle: 0.09385 | valid_mae: 1.08719 | valid_rmse: 1.17629 | valid_mse: 1.38365 |  0:00:06s\n",
      "epoch 3  | loss: 0.35927 | train_rmsle: 0.05685 | train_mae: 0.85698 | train_rmse: 0.94992 | train_mse: 0.90235 | valid_rmsle: 0.05703 | valid_mae: 0.85868 | valid_rmse: 0.95328 | valid_mse: 0.90873 |  0:00:09s\n",
      "epoch 4  | loss: 0.27682 | train_rmsle: 0.03676 | train_mae: 0.69035 | train_rmse: 0.78314 | train_mse: 0.61331 | valid_rmsle: 0.03671 | valid_mae: 0.6899  | valid_rmse: 0.78533 | valid_mse: 0.61675 |  0:00:11s\n",
      "epoch 5  | loss: 0.25201 | train_rmsle: 0.03296 | train_mae: 0.65262 | train_rmse: 0.745   | train_mse: 0.55503 | valid_rmsle: 0.03295 | valid_mae: 0.65288 | valid_rmse: 0.74783 | valid_mse: 0.55926 |  0:00:13s\n",
      "epoch 6  | loss: 0.24619 | train_rmsle: 0.02504 | train_mae: 0.56403 | train_rmse: 0.65457 | train_mse: 0.42846 | valid_rmsle: 0.02502 | valid_mae: 0.56636 | valid_rmse: 0.65786 | valid_mse: 0.43278 |  0:00:15s\n",
      "epoch 7  | loss: 0.23282 | train_rmsle: 0.02589 | train_mae: 0.57427 | train_rmse: 0.66507 | train_mse: 0.44232 | valid_rmsle: 0.02583 | valid_mae: 0.57527 | valid_rmse: 0.66793 | valid_mse: 0.44613 |  0:00:18s\n",
      "epoch 8  | loss: 0.23759 | train_rmsle: 0.01724 | train_mae: 0.45275 | train_rmse: 0.54045 | train_mse: 0.29209 | valid_rmsle: 0.01704 | valid_mae: 0.45603 | valid_rmse: 0.54242 | valid_mse: 0.29422 |  0:00:20s\n",
      "epoch 9  | loss: 0.23296 | train_rmsle: 0.01691 | train_mae: 0.44677 | train_rmse: 0.53456 | train_mse: 0.28575 | valid_rmsle: 0.01656 | valid_mae: 0.44888 | valid_rmse: 0.53426 | valid_mse: 0.28543 |  0:00:22s\n",
      "epoch 10 | loss: 0.23056 | train_rmsle: 0.01526 | train_mae: 0.41281 | train_rmse: 0.50251 | train_mse: 0.25252 | valid_rmsle: 0.01477 | valid_mae: 0.41399 | valid_rmse: 0.49995 | valid_mse: 0.24995 |  0:00:24s\n",
      "epoch 11 | loss: 0.22731 | train_rmsle: 0.01623 | train_mae: 0.43325 | train_rmse: 0.5218  | train_mse: 0.27227 | valid_rmsle: 0.01582 | valid_mae: 0.43585 | valid_rmse: 0.52064 | valid_mse: 0.27107 |  0:00:26s\n",
      "epoch 12 | loss: 0.23197 | train_rmsle: 0.01529 | train_mae: 0.41324 | train_rmse: 0.50301 | train_mse: 0.25302 | valid_rmsle: 0.01492 | valid_mae: 0.41621 | valid_rmse: 0.50236 | valid_mse: 0.25237 |  0:00:29s\n",
      "epoch 13 | loss: 0.23244 | train_rmsle: 0.01713 | train_mae: 0.45021 | train_rmse: 0.53815 | train_mse: 0.2896  | valid_rmsle: 0.01688 | valid_mae: 0.45367 | valid_rmse: 0.53929 | valid_mse: 0.29084 |  0:00:31s\n",
      "epoch 14 | loss: 0.22451 | train_rmsle: 0.01595 | train_mae: 0.4276  | train_rmse: 0.51654 | train_mse: 0.26682 | valid_rmsle: 0.01557 | valid_mae: 0.43034 | valid_rmse: 0.51589 | valid_mse: 0.26614 |  0:00:33s\n",
      "epoch 15 | loss: 0.22343 | train_rmsle: 0.01703 | train_mae: 0.44828 | train_rmse: 0.53643 | train_mse: 0.28775 | valid_rmsle: 0.0167  | valid_mae: 0.45076 | valid_rmse: 0.53631 | valid_mse: 0.28763 |  0:00:35s\n",
      "epoch 16 | loss: 0.22522 | train_rmsle: 0.01546 | train_mae: 0.41755 | train_rmse: 0.50651 | train_mse: 0.25655 | valid_rmsle: 0.01522 | valid_mae: 0.42111 | valid_rmse: 0.50804 | valid_mse: 0.2581  |  0:00:37s\n",
      "epoch 17 | loss: 0.22159 | train_rmsle: 0.01506 | train_mae: 0.40628 | train_rmse: 0.4976  | train_mse: 0.2476  | valid_rmsle: 0.01463 | valid_mae: 0.4086  | valid_rmse: 0.4964  | valid_mse: 0.24641 |  0:00:39s\n",
      "epoch 18 | loss: 0.22513 | train_rmsle: 0.01452 | train_mae: 0.38157 | train_rmse: 0.48121 | train_mse: 0.23157 | valid_rmsle: 0.01384 | valid_mae: 0.38324 | valid_rmse: 0.47551 | valid_mse: 0.22611 |  0:00:41s\n",
      "epoch 19 | loss: 0.22235 | train_rmsle: 0.0149  | train_mae: 0.4036  | train_rmse: 0.49509 | train_mse: 0.24511 | valid_rmsle: 0.01452 | valid_mae: 0.40843 | valid_rmse: 0.49474 | valid_mse: 0.24477 |  0:00:43s\n",
      "epoch 20 | loss: 0.21773 | train_rmsle: 0.01444 | train_mae: 0.38724 | train_rmse: 0.48267 | train_mse: 0.23297 | valid_rmsle: 0.01386 | valid_mae: 0.39047 | valid_rmse: 0.47891 | valid_mse: 0.22935 |  0:00:45s\n",
      "epoch 21 | loss: 0.2175  | train_rmsle: 0.01445 | train_mae: 0.39258 | train_rmse: 0.4847  | train_mse: 0.23493 | valid_rmsle: 0.01393 | valid_mae: 0.39593 | valid_rmse: 0.4824  | valid_mse: 0.23271 |  0:00:47s\n",
      "epoch 22 | loss: 0.21689 | train_rmsle: 0.01488 | train_mae: 0.40581 | train_rmse: 0.49567 | train_mse: 0.24569 | valid_rmsle: 0.01452 | valid_mae: 0.41107 | valid_rmse: 0.49582 | valid_mse: 0.24584 |  0:00:49s\n",
      "epoch 23 | loss: 0.21691 | train_rmsle: 0.01465 | train_mae: 0.40002 | train_rmse: 0.4907  | train_mse: 0.24078 | valid_rmsle: 0.01431 | valid_mae: 0.40553 | valid_rmse: 0.49114 | valid_mse: 0.24122 |  0:00:51s\n",
      "epoch 24 | loss: 0.2183  | train_rmsle: 0.01429 | train_mae: 0.3879  | train_rmse: 0.48102 | train_mse: 0.23138 | valid_rmsle: 0.01391 | valid_mae: 0.39119 | valid_rmse: 0.48042 | valid_mse: 0.23081 |  0:00:53s\n",
      "epoch 25 | loss: 0.21654 | train_rmsle: 0.01422 | train_mae: 0.38377 | train_rmse: 0.47882 | train_mse: 0.22927 | valid_rmsle: 0.01372 | valid_mae: 0.38799 | valid_rmse: 0.47624 | valid_mse: 0.22681 |  0:00:55s\n",
      "epoch 26 | loss: 0.21728 | train_rmsle: 0.01429 | train_mae: 0.38807 | train_rmse: 0.48112 | train_mse: 0.23147 | valid_rmsle: 0.01381 | valid_mae: 0.39493 | valid_rmse: 0.47907 | valid_mse: 0.22951 |  0:00:57s\n",
      "epoch 27 | loss: 0.21793 | train_rmsle: 0.01444 | train_mae: 0.39379 | train_rmse: 0.48599 | train_mse: 0.23619 | valid_rmsle: 0.01393 | valid_mae: 0.39854 | valid_rmse: 0.48314 | valid_mse: 0.23342 |  0:00:59s\n",
      "epoch 28 | loss: 0.21985 | train_rmsle: 0.01417 | train_mae: 0.38331 | train_rmse: 0.47851 | train_mse: 0.22897 | valid_rmsle: 0.01342 | valid_mae: 0.38391 | valid_rmse: 0.47099 | valid_mse: 0.22183 |  0:01:01s\n",
      "epoch 29 | loss: 0.21419 | train_rmsle: 0.0144  | train_mae: 0.3903  | train_rmse: 0.48409 | train_mse: 0.23435 | valid_rmsle: 0.01382 | valid_mae: 0.39332 | valid_rmse: 0.47991 | valid_mse: 0.23032 |  0:01:03s\n",
      "epoch 30 | loss: 0.21735 | train_rmsle: 0.0143  | train_mae: 0.37134 | train_rmse: 0.47504 | train_mse: 0.22567 | valid_rmsle: 0.01382 | valid_mae: 0.37734 | valid_rmse: 0.47284 | valid_mse: 0.22358 |  0:01:05s\n",
      "epoch 31 | loss: 0.21584 | train_rmsle: 0.01409 | train_mae: 0.38024 | train_rmse: 0.47616 | train_mse: 0.22673 | valid_rmsle: 0.01351 | valid_mae: 0.38349 | valid_rmse: 0.47188 | valid_mse: 0.22267 |  0:01:07s\n",
      "epoch 32 | loss: 0.21672 | train_rmsle: 0.01403 | train_mae: 0.3725  | train_rmse: 0.47219 | train_mse: 0.22296 | valid_rmsle: 0.01347 | valid_mae: 0.37828 | valid_rmse: 0.46881 | valid_mse: 0.21978 |  0:01:10s\n",
      "epoch 33 | loss: 0.2168  | train_rmsle: 0.01398 | train_mae: 0.37941 | train_rmse: 0.47426 | train_mse: 0.22492 | valid_rmsle: 0.01345 | valid_mae: 0.38328 | valid_rmse: 0.47127 | valid_mse: 0.2221  |  0:01:12s\n",
      "epoch 34 | loss: 0.21412 | train_rmsle: 0.01396 | train_mae: 0.37546 | train_rmse: 0.47245 | train_mse: 0.22321 | valid_rmsle: 0.01345 | valid_mae: 0.37844 | valid_rmse: 0.46957 | valid_mse: 0.22049 |  0:01:14s\n",
      "epoch 35 | loss: 0.21282 | train_rmsle: 0.01385 | train_mae: 0.37451 | train_rmse: 0.47073 | train_mse: 0.22159 | valid_rmsle: 0.01362 | valid_mae: 0.38237 | valid_rmse: 0.473   | valid_mse: 0.22373 |  0:01:16s\n",
      "epoch 36 | loss: 0.21138 | train_rmsle: 0.0139  | train_mae: 0.36871 | train_rmse: 0.4693  | train_mse: 0.22024 | valid_rmsle: 0.01369 | valid_mae: 0.37925 | valid_rmse: 0.47224 | valid_mse: 0.22301 |  0:01:18s\n",
      "epoch 37 | loss: 0.21057 | train_rmsle: 0.01378 | train_mae: 0.36951 | train_rmse: 0.4682  | train_mse: 0.21921 | valid_rmsle: 0.01364 | valid_mae: 0.38023 | valid_rmse: 0.47219 | valid_mse: 0.22296 |  0:01:21s\n",
      "epoch 38 | loss: 0.21967 | train_rmsle: 0.01386 | train_mae: 0.38121 | train_rmse: 0.47394 | train_mse: 0.22462 | valid_rmsle: 0.01385 | valid_mae: 0.39249 | valid_rmse: 0.48008 | valid_mse: 0.23048 |  0:01:23s\n",
      "epoch 39 | loss: 0.21312 | train_rmsle: 0.0139  | train_mae: 0.36725 | train_rmse: 0.46883 | train_mse: 0.2198  | valid_rmsle: 0.01358 | valid_mae: 0.37569 | valid_rmse: 0.46974 | valid_mse: 0.22066 |  0:01:25s\n",
      "epoch 40 | loss: 0.21503 | train_rmsle: 0.01387 | train_mae: 0.37027 | train_rmse: 0.46922 | train_mse: 0.22017 | valid_rmsle: 0.01361 | valid_mae: 0.37908 | valid_rmse: 0.4714  | valid_mse: 0.22221 |  0:01:27s\n",
      "epoch 41 | loss: 0.21488 | train_rmsle: 0.01451 | train_mae: 0.36953 | train_rmse: 0.47725 | train_mse: 0.22776 | valid_rmsle: 0.01413 | valid_mae: 0.37662 | valid_rmse: 0.47722 | valid_mse: 0.22774 |  0:01:29s\n",
      "epoch 42 | loss: 0.21617 | train_rmsle: 0.01393 | train_mae: 0.38107 | train_rmse: 0.47458 | train_mse: 0.22522 | valid_rmsle: 0.01351 | valid_mae: 0.38673 | valid_rmse: 0.47317 | valid_mse: 0.22389 |  0:01:31s\n",
      "epoch 43 | loss: 0.2131  | train_rmsle: 0.01367 | train_mae: 0.37254 | train_rmse: 0.46808 | train_mse: 0.2191  | valid_rmsle: 0.01335 | valid_mae: 0.3797  | valid_rmse: 0.4687  | valid_mse: 0.21968 |  0:01:34s\n",
      "epoch 44 | loss: 0.21284 | train_rmsle: 0.01395 | train_mae: 0.36903 | train_rmse: 0.47012 | train_mse: 0.22101 | valid_rmsle: 0.01344 | valid_mae: 0.37333 | valid_rmse: 0.46826 | valid_mse: 0.21927 |  0:01:36s\n",
      "epoch 45 | loss: 0.21254 | train_rmsle: 0.01445 | train_mae: 0.36756 | train_rmse: 0.47657 | train_mse: 0.22712 | valid_rmsle: 0.014   | valid_mae: 0.37775 | valid_rmse: 0.47577 | valid_mse: 0.22636 |  0:01:38s\n",
      "epoch 46 | loss: 0.21705 | train_rmsle: 0.01381 | train_mae: 0.36817 | train_rmse: 0.46798 | train_mse: 0.219   | valid_rmsle: 0.01343 | valid_mae: 0.37522 | valid_rmse: 0.46788 | valid_mse: 0.21891 |  0:01:40s\n",
      "epoch 47 | loss: 0.21267 | train_rmsle: 0.01391 | train_mae: 0.38065 | train_rmse: 0.47394 | train_mse: 0.22462 | valid_rmsle: 0.01354 | valid_mae: 0.38589 | valid_rmse: 0.47475 | valid_mse: 0.22539 |  0:01:42s\n",
      "epoch 48 | loss: 0.21098 | train_rmsle: 0.01383 | train_mae: 0.36872 | train_rmse: 0.46851 | train_mse: 0.2195  | valid_rmsle: 0.01355 | valid_mae: 0.37666 | valid_rmse: 0.47157 | valid_mse: 0.22238 |  0:01:44s\n",
      "epoch 49 | loss: 0.21046 | train_rmsle: 0.01392 | train_mae: 0.36901 | train_rmse: 0.46968 | train_mse: 0.2206  | valid_rmsle: 0.01346 | valid_mae: 0.37396 | valid_rmse: 0.46829 | valid_mse: 0.21929 |  0:01:47s\n",
      "epoch 50 | loss: 0.21225 | train_rmsle: 0.01382 | train_mae: 0.37095 | train_rmse: 0.46925 | train_mse: 0.22019 | valid_rmsle: 0.01318 | valid_mae: 0.37171 | valid_rmse: 0.46403 | valid_mse: 0.21532 |  0:01:49s\n",
      "epoch 51 | loss: 0.21199 | train_rmsle: 0.01384 | train_mae: 0.36938 | train_rmse: 0.46907 | train_mse: 0.22002 | valid_rmsle: 0.01333 | valid_mae: 0.37492 | valid_rmse: 0.46615 | valid_mse: 0.2173  |  0:01:51s\n",
      "epoch 52 | loss: 0.2101  | train_rmsle: 0.01369 | train_mae: 0.37718 | train_rmse: 0.47023 | train_mse: 0.22112 | valid_rmsle: 0.01333 | valid_mae: 0.38349 | valid_rmse: 0.46957 | valid_mse: 0.22049 |  0:01:53s\n",
      "epoch 53 | loss: 0.211   | train_rmsle: 0.01371 | train_mae: 0.36381 | train_rmse: 0.46497 | train_mse: 0.2162  | valid_rmsle: 0.0131  | valid_mae: 0.36666 | valid_rmse: 0.46049 | valid_mse: 0.21205 |  0:01:55s\n",
      "epoch 54 | loss: 0.21062 | train_rmsle: 0.01349 | train_mae: 0.37369 | train_rmse: 0.4662  | train_mse: 0.21734 | valid_rmsle: 0.01293 | valid_mae: 0.37651 | valid_rmse: 0.46154 | valid_mse: 0.21302 |  0:01:58s\n",
      "epoch 55 | loss: 0.20799 | train_rmsle: 0.01354 | train_mae: 0.36237 | train_rmse: 0.46225 | train_mse: 0.21367 | valid_rmsle: 0.01311 | valid_mae: 0.36751 | valid_rmse: 0.46008 | valid_mse: 0.21167 |  0:02:00s\n",
      "epoch 56 | loss: 0.20463 | train_rmsle: 0.01336 | train_mae: 0.36158 | train_rmse: 0.45995 | train_mse: 0.21155 | valid_rmsle: 0.01298 | valid_mae: 0.37059 | valid_rmse: 0.45956 | valid_mse: 0.2112  |  0:02:02s\n",
      "epoch 57 | loss: 0.20452 | train_rmsle: 0.01335 | train_mae: 0.36127 | train_rmse: 0.46008 | train_mse: 0.21168 | valid_rmsle: 0.01276 | valid_mae: 0.36724 | valid_rmse: 0.4558  | valid_mse: 0.20776 |  0:02:04s\n",
      "epoch 58 | loss: 0.20483 | train_rmsle: 0.0133  | train_mae: 0.36111 | train_rmse: 0.45903 | train_mse: 0.2107  | valid_rmsle: 0.01262 | valid_mae: 0.36283 | valid_rmse: 0.45201 | valid_mse: 0.20431 |  0:02:06s\n",
      "epoch 59 | loss: 0.2024  | train_rmsle: 0.01318 | train_mae: 0.3583  | train_rmse: 0.45653 | train_mse: 0.20842 | valid_rmsle: 0.01255 | valid_mae: 0.36149 | valid_rmse: 0.45102 | valid_mse: 0.20342 |  0:02:09s\n",
      "epoch 60 | loss: 0.19945 | train_rmsle: 0.01314 | train_mae: 0.35406 | train_rmse: 0.45457 | train_mse: 0.20663 | valid_rmsle: 0.01249 | valid_mae: 0.35923 | valid_rmse: 0.44858 | valid_mse: 0.20122 |  0:02:11s\n",
      "epoch 61 | loss: 0.19521 | train_rmsle: 0.0128  | train_mae: 0.35494 | train_rmse: 0.45054 | train_mse: 0.20299 | valid_rmsle: 0.0122  | valid_mae: 0.36026 | valid_rmse: 0.4458  | valid_mse: 0.19874 |  0:02:13s\n",
      "epoch 62 | loss: 0.19295 | train_rmsle: 0.0125  | train_mae: 0.35426 | train_rmse: 0.44653 | train_mse: 0.19939 | valid_rmsle: 0.01194 | valid_mae: 0.35829 | valid_rmse: 0.44196 | valid_mse: 0.19533 |  0:02:15s\n",
      "epoch 63 | loss: 0.18876 | train_rmsle: 0.01209 | train_mae: 0.34368 | train_rmse: 0.43736 | train_mse: 0.19128 | valid_rmsle: 0.01162 | valid_mae: 0.35022 | valid_rmse: 0.43483 | valid_mse: 0.18908 |  0:02:17s\n",
      "epoch 64 | loss: 0.18218 | train_rmsle: 0.01186 | train_mae: 0.33487 | train_rmse: 0.43083 | train_mse: 0.18562 | valid_rmsle: 0.0114  | valid_mae: 0.34271 | valid_rmse: 0.42903 | valid_mse: 0.18407 |  0:02:19s\n",
      "epoch 65 | loss: 0.179   | train_rmsle: 0.01153 | train_mae: 0.32602 | train_rmse: 0.42343 | train_mse: 0.17929 | valid_rmsle: 0.01099 | valid_mae: 0.33216 | valid_rmse: 0.41947 | valid_mse: 0.17595 |  0:02:22s\n",
      "epoch 66 | loss: 0.17206 | train_rmsle: 0.01133 | train_mae: 0.31841 | train_rmse: 0.41801 | train_mse: 0.17473 | valid_rmsle: 0.01086 | valid_mae: 0.32376 | valid_rmse: 0.41533 | valid_mse: 0.1725  |  0:02:24s\n",
      "epoch 67 | loss: 0.16765 | train_rmsle: 0.01055 | train_mae: 0.32669 | train_rmse: 0.41028 | train_mse: 0.16833 | valid_rmsle: 0.0105  | valid_mae: 0.33596 | valid_rmse: 0.41408 | valid_mse: 0.17146 |  0:02:26s\n",
      "epoch 68 | loss: 0.16003 | train_rmsle: 0.01039 | train_mae: 0.30441 | train_rmse: 0.3999  | train_mse: 0.15992 | valid_rmsle: 0.01032 | valid_mae: 0.31642 | valid_rmse: 0.40517 | valid_mse: 0.16416 |  0:02:28s\n",
      "epoch 69 | loss: 0.15267 | train_rmsle: 0.0099  | train_mae: 0.31389 | train_rmse: 0.39615 | train_mse: 0.15693 | valid_rmsle: 0.00993 | valid_mae: 0.32312 | valid_rmse: 0.40205 | valid_mse: 0.16164 |  0:02:30s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.16164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1664952632366941 RMSE: 0.40803831099137505 R2: 0.26298962336868503 MAE: 0.32375105058541354\n",
      "=====================================\n",
      "[18/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 18.40649| train_rmsle: 0.74473 | train_mae: 2.46611 | train_rmse: 2.51319 | train_mse: 6.31614 | valid_rmsle: 0.74818 | valid_mae: 2.47364 | valid_rmse: 2.51966 | valid_mse: 6.34869 |  0:00:02s\n",
      "epoch 1  | loss: 3.16101 | train_rmsle: 0.10384 | train_mae: 1.12551 | train_rmse: 1.21901 | train_mse: 1.48598 | valid_rmsle: 0.10584 | valid_mae: 1.13536 | valid_rmse: 1.23073 | valid_mse: 1.5147  |  0:00:04s\n",
      "epoch 2  | loss: 0.94953 | train_rmsle: 0.09335 | train_mae: 1.08376 | train_rmse: 1.17197 | train_mse: 1.37352 | valid_rmsle: 0.09385 | valid_mae: 1.08719 | valid_rmse: 1.17629 | valid_mse: 1.38365 |  0:00:06s\n",
      "epoch 3  | loss: 0.35927 | train_rmsle: 0.05685 | train_mae: 0.85698 | train_rmse: 0.94992 | train_mse: 0.90235 | valid_rmsle: 0.05703 | valid_mae: 0.85868 | valid_rmse: 0.95328 | valid_mse: 0.90873 |  0:00:08s\n",
      "epoch 4  | loss: 0.27682 | train_rmsle: 0.03676 | train_mae: 0.69035 | train_rmse: 0.78314 | train_mse: 0.61331 | valid_rmsle: 0.03671 | valid_mae: 0.6899  | valid_rmse: 0.78533 | valid_mse: 0.61675 |  0:00:10s\n",
      "epoch 5  | loss: 0.25201 | train_rmsle: 0.03296 | train_mae: 0.65262 | train_rmse: 0.745   | train_mse: 0.55503 | valid_rmsle: 0.03295 | valid_mae: 0.65288 | valid_rmse: 0.74783 | valid_mse: 0.55926 |  0:00:13s\n",
      "epoch 6  | loss: 0.24619 | train_rmsle: 0.02504 | train_mae: 0.56403 | train_rmse: 0.65457 | train_mse: 0.42846 | valid_rmsle: 0.02502 | valid_mae: 0.56636 | valid_rmse: 0.65786 | valid_mse: 0.43278 |  0:00:15s\n",
      "epoch 7  | loss: 0.23282 | train_rmsle: 0.02589 | train_mae: 0.57427 | train_rmse: 0.66507 | train_mse: 0.44232 | valid_rmsle: 0.02583 | valid_mae: 0.57527 | valid_rmse: 0.66793 | valid_mse: 0.44613 |  0:00:17s\n",
      "epoch 8  | loss: 0.23759 | train_rmsle: 0.01724 | train_mae: 0.45275 | train_rmse: 0.54045 | train_mse: 0.29209 | valid_rmsle: 0.01704 | valid_mae: 0.45603 | valid_rmse: 0.54242 | valid_mse: 0.29422 |  0:00:19s\n",
      "epoch 9  | loss: 0.23296 | train_rmsle: 0.01691 | train_mae: 0.44677 | train_rmse: 0.53456 | train_mse: 0.28575 | valid_rmsle: 0.01656 | valid_mae: 0.44888 | valid_rmse: 0.53426 | valid_mse: 0.28543 |  0:00:21s\n",
      "epoch 10 | loss: 0.23056 | train_rmsle: 0.01526 | train_mae: 0.41281 | train_rmse: 0.50251 | train_mse: 0.25252 | valid_rmsle: 0.01477 | valid_mae: 0.41399 | valid_rmse: 0.49995 | valid_mse: 0.24995 |  0:00:24s\n",
      "epoch 11 | loss: 0.22731 | train_rmsle: 0.01623 | train_mae: 0.43325 | train_rmse: 0.5218  | train_mse: 0.27227 | valid_rmsle: 0.01582 | valid_mae: 0.43585 | valid_rmse: 0.52064 | valid_mse: 0.27107 |  0:00:26s\n",
      "epoch 12 | loss: 0.23197 | train_rmsle: 0.01529 | train_mae: 0.41324 | train_rmse: 0.50301 | train_mse: 0.25302 | valid_rmsle: 0.01492 | valid_mae: 0.41621 | valid_rmse: 0.50236 | valid_mse: 0.25237 |  0:00:28s\n",
      "epoch 13 | loss: 0.23244 | train_rmsle: 0.01713 | train_mae: 0.45021 | train_rmse: 0.53815 | train_mse: 0.2896  | valid_rmsle: 0.01688 | valid_mae: 0.45367 | valid_rmse: 0.53929 | valid_mse: 0.29084 |  0:00:30s\n",
      "epoch 14 | loss: 0.22451 | train_rmsle: 0.01595 | train_mae: 0.4276  | train_rmse: 0.51654 | train_mse: 0.26682 | valid_rmsle: 0.01557 | valid_mae: 0.43034 | valid_rmse: 0.51589 | valid_mse: 0.26614 |  0:00:32s\n",
      "epoch 15 | loss: 0.22343 | train_rmsle: 0.01703 | train_mae: 0.44828 | train_rmse: 0.53643 | train_mse: 0.28775 | valid_rmsle: 0.0167  | valid_mae: 0.45076 | valid_rmse: 0.53631 | valid_mse: 0.28763 |  0:00:34s\n",
      "epoch 16 | loss: 0.22522 | train_rmsle: 0.01546 | train_mae: 0.41755 | train_rmse: 0.50651 | train_mse: 0.25655 | valid_rmsle: 0.01522 | valid_mae: 0.42111 | valid_rmse: 0.50804 | valid_mse: 0.2581  |  0:00:37s\n",
      "epoch 17 | loss: 0.22159 | train_rmsle: 0.01506 | train_mae: 0.40628 | train_rmse: 0.4976  | train_mse: 0.2476  | valid_rmsle: 0.01463 | valid_mae: 0.4086  | valid_rmse: 0.4964  | valid_mse: 0.24641 |  0:00:39s\n",
      "epoch 18 | loss: 0.22513 | train_rmsle: 0.01452 | train_mae: 0.38157 | train_rmse: 0.48121 | train_mse: 0.23157 | valid_rmsle: 0.01384 | valid_mae: 0.38324 | valid_rmse: 0.47551 | valid_mse: 0.22611 |  0:00:41s\n",
      "epoch 19 | loss: 0.22235 | train_rmsle: 0.0149  | train_mae: 0.4036  | train_rmse: 0.49509 | train_mse: 0.24511 | valid_rmsle: 0.01452 | valid_mae: 0.40843 | valid_rmse: 0.49474 | valid_mse: 0.24477 |  0:00:43s\n",
      "epoch 20 | loss: 0.21773 | train_rmsle: 0.01444 | train_mae: 0.38724 | train_rmse: 0.48267 | train_mse: 0.23297 | valid_rmsle: 0.01386 | valid_mae: 0.39047 | valid_rmse: 0.47891 | valid_mse: 0.22935 |  0:00:45s\n",
      "epoch 21 | loss: 0.2175  | train_rmsle: 0.01445 | train_mae: 0.39258 | train_rmse: 0.4847  | train_mse: 0.23493 | valid_rmsle: 0.01393 | valid_mae: 0.39593 | valid_rmse: 0.4824  | valid_mse: 0.23271 |  0:00:47s\n",
      "epoch 22 | loss: 0.21689 | train_rmsle: 0.01488 | train_mae: 0.40581 | train_rmse: 0.49567 | train_mse: 0.24569 | valid_rmsle: 0.01452 | valid_mae: 0.41107 | valid_rmse: 0.49582 | valid_mse: 0.24584 |  0:00:49s\n",
      "epoch 23 | loss: 0.21691 | train_rmsle: 0.01465 | train_mae: 0.40002 | train_rmse: 0.4907  | train_mse: 0.24078 | valid_rmsle: 0.01431 | valid_mae: 0.40553 | valid_rmse: 0.49114 | valid_mse: 0.24122 |  0:00:51s\n",
      "epoch 24 | loss: 0.2183  | train_rmsle: 0.01429 | train_mae: 0.3879  | train_rmse: 0.48102 | train_mse: 0.23138 | valid_rmsle: 0.01391 | valid_mae: 0.39119 | valid_rmse: 0.48042 | valid_mse: 0.23081 |  0:00:53s\n",
      "epoch 25 | loss: 0.21654 | train_rmsle: 0.01422 | train_mae: 0.38377 | train_rmse: 0.47882 | train_mse: 0.22927 | valid_rmsle: 0.01372 | valid_mae: 0.38799 | valid_rmse: 0.47624 | valid_mse: 0.22681 |  0:00:54s\n",
      "epoch 26 | loss: 0.21728 | train_rmsle: 0.01429 | train_mae: 0.38807 | train_rmse: 0.48112 | train_mse: 0.23147 | valid_rmsle: 0.01381 | valid_mae: 0.39493 | valid_rmse: 0.47907 | valid_mse: 0.22951 |  0:00:57s\n",
      "epoch 27 | loss: 0.21793 | train_rmsle: 0.01444 | train_mae: 0.39379 | train_rmse: 0.48599 | train_mse: 0.23619 | valid_rmsle: 0.01393 | valid_mae: 0.39854 | valid_rmse: 0.48314 | valid_mse: 0.23342 |  0:00:59s\n",
      "epoch 28 | loss: 0.21985 | train_rmsle: 0.01417 | train_mae: 0.38331 | train_rmse: 0.47851 | train_mse: 0.22897 | valid_rmsle: 0.01342 | valid_mae: 0.38391 | valid_rmse: 0.47099 | valid_mse: 0.22183 |  0:01:01s\n",
      "epoch 29 | loss: 0.21419 | train_rmsle: 0.0144  | train_mae: 0.3903  | train_rmse: 0.48409 | train_mse: 0.23435 | valid_rmsle: 0.01382 | valid_mae: 0.39332 | valid_rmse: 0.47991 | valid_mse: 0.23032 |  0:01:03s\n",
      "epoch 30 | loss: 0.21735 | train_rmsle: 0.0143  | train_mae: 0.37134 | train_rmse: 0.47504 | train_mse: 0.22567 | valid_rmsle: 0.01382 | valid_mae: 0.37734 | valid_rmse: 0.47284 | valid_mse: 0.22358 |  0:01:05s\n",
      "epoch 31 | loss: 0.21584 | train_rmsle: 0.01409 | train_mae: 0.38024 | train_rmse: 0.47616 | train_mse: 0.22673 | valid_rmsle: 0.01351 | valid_mae: 0.38349 | valid_rmse: 0.47188 | valid_mse: 0.22267 |  0:01:08s\n",
      "epoch 32 | loss: 0.21672 | train_rmsle: 0.01403 | train_mae: 0.3725  | train_rmse: 0.47219 | train_mse: 0.22296 | valid_rmsle: 0.01347 | valid_mae: 0.37828 | valid_rmse: 0.46881 | valid_mse: 0.21978 |  0:01:10s\n",
      "epoch 33 | loss: 0.2168  | train_rmsle: 0.01398 | train_mae: 0.37941 | train_rmse: 0.47426 | train_mse: 0.22492 | valid_rmsle: 0.01345 | valid_mae: 0.38328 | valid_rmse: 0.47127 | valid_mse: 0.2221  |  0:01:12s\n",
      "epoch 34 | loss: 0.21412 | train_rmsle: 0.01396 | train_mae: 0.37546 | train_rmse: 0.47245 | train_mse: 0.22321 | valid_rmsle: 0.01345 | valid_mae: 0.37844 | valid_rmse: 0.46957 | valid_mse: 0.22049 |  0:01:14s\n",
      "epoch 35 | loss: 0.21282 | train_rmsle: 0.01385 | train_mae: 0.37451 | train_rmse: 0.47073 | train_mse: 0.22159 | valid_rmsle: 0.01362 | valid_mae: 0.38237 | valid_rmse: 0.473   | valid_mse: 0.22373 |  0:01:16s\n",
      "epoch 36 | loss: 0.21138 | train_rmsle: 0.0139  | train_mae: 0.36871 | train_rmse: 0.4693  | train_mse: 0.22024 | valid_rmsle: 0.01369 | valid_mae: 0.37925 | valid_rmse: 0.47224 | valid_mse: 0.22301 |  0:01:19s\n",
      "epoch 37 | loss: 0.21057 | train_rmsle: 0.01378 | train_mae: 0.36951 | train_rmse: 0.4682  | train_mse: 0.21921 | valid_rmsle: 0.01364 | valid_mae: 0.38023 | valid_rmse: 0.47219 | valid_mse: 0.22296 |  0:01:21s\n",
      "epoch 38 | loss: 0.21967 | train_rmsle: 0.01386 | train_mae: 0.38121 | train_rmse: 0.47394 | train_mse: 0.22462 | valid_rmsle: 0.01385 | valid_mae: 0.39249 | valid_rmse: 0.48008 | valid_mse: 0.23048 |  0:01:23s\n",
      "epoch 39 | loss: 0.21312 | train_rmsle: 0.0139  | train_mae: 0.36725 | train_rmse: 0.46883 | train_mse: 0.2198  | valid_rmsle: 0.01358 | valid_mae: 0.37569 | valid_rmse: 0.46974 | valid_mse: 0.22066 |  0:01:25s\n",
      "epoch 40 | loss: 0.21503 | train_rmsle: 0.01387 | train_mae: 0.37027 | train_rmse: 0.46922 | train_mse: 0.22017 | valid_rmsle: 0.01361 | valid_mae: 0.37908 | valid_rmse: 0.4714  | valid_mse: 0.22221 |  0:01:27s\n",
      "epoch 41 | loss: 0.21488 | train_rmsle: 0.01451 | train_mae: 0.36953 | train_rmse: 0.47725 | train_mse: 0.22776 | valid_rmsle: 0.01413 | valid_mae: 0.37662 | valid_rmse: 0.47722 | valid_mse: 0.22774 |  0:01:30s\n",
      "epoch 42 | loss: 0.21617 | train_rmsle: 0.01393 | train_mae: 0.38107 | train_rmse: 0.47458 | train_mse: 0.22522 | valid_rmsle: 0.01351 | valid_mae: 0.38673 | valid_rmse: 0.47317 | valid_mse: 0.22389 |  0:01:32s\n",
      "epoch 43 | loss: 0.2131  | train_rmsle: 0.01367 | train_mae: 0.37254 | train_rmse: 0.46808 | train_mse: 0.2191  | valid_rmsle: 0.01335 | valid_mae: 0.3797  | valid_rmse: 0.4687  | valid_mse: 0.21968 |  0:01:34s\n",
      "epoch 44 | loss: 0.21284 | train_rmsle: 0.01395 | train_mae: 0.36903 | train_rmse: 0.47012 | train_mse: 0.22101 | valid_rmsle: 0.01344 | valid_mae: 0.37333 | valid_rmse: 0.46826 | valid_mse: 0.21927 |  0:01:36s\n",
      "epoch 45 | loss: 0.21254 | train_rmsle: 0.01445 | train_mae: 0.36756 | train_rmse: 0.47657 | train_mse: 0.22712 | valid_rmsle: 0.014   | valid_mae: 0.37775 | valid_rmse: 0.47577 | valid_mse: 0.22636 |  0:01:38s\n",
      "epoch 46 | loss: 0.21705 | train_rmsle: 0.01381 | train_mae: 0.36817 | train_rmse: 0.46798 | train_mse: 0.219   | valid_rmsle: 0.01343 | valid_mae: 0.37522 | valid_rmse: 0.46788 | valid_mse: 0.21891 |  0:01:40s\n",
      "epoch 47 | loss: 0.21267 | train_rmsle: 0.01391 | train_mae: 0.38065 | train_rmse: 0.47394 | train_mse: 0.22462 | valid_rmsle: 0.01354 | valid_mae: 0.38589 | valid_rmse: 0.47475 | valid_mse: 0.22539 |  0:01:42s\n",
      "epoch 48 | loss: 0.21098 | train_rmsle: 0.01383 | train_mae: 0.36872 | train_rmse: 0.46851 | train_mse: 0.2195  | valid_rmsle: 0.01355 | valid_mae: 0.37666 | valid_rmse: 0.47157 | valid_mse: 0.22238 |  0:01:44s\n",
      "epoch 49 | loss: 0.21046 | train_rmsle: 0.01392 | train_mae: 0.36901 | train_rmse: 0.46968 | train_mse: 0.2206  | valid_rmsle: 0.01346 | valid_mae: 0.37396 | valid_rmse: 0.46829 | valid_mse: 0.21929 |  0:01:46s\n",
      "epoch 50 | loss: 0.21225 | train_rmsle: 0.01382 | train_mae: 0.37095 | train_rmse: 0.46925 | train_mse: 0.22019 | valid_rmsle: 0.01318 | valid_mae: 0.37171 | valid_rmse: 0.46403 | valid_mse: 0.21532 |  0:01:48s\n",
      "epoch 51 | loss: 0.21199 | train_rmsle: 0.01384 | train_mae: 0.36938 | train_rmse: 0.46907 | train_mse: 0.22002 | valid_rmsle: 0.01333 | valid_mae: 0.37492 | valid_rmse: 0.46615 | valid_mse: 0.2173  |  0:01:50s\n",
      "epoch 52 | loss: 0.2101  | train_rmsle: 0.01369 | train_mae: 0.37718 | train_rmse: 0.47023 | train_mse: 0.22112 | valid_rmsle: 0.01333 | valid_mae: 0.38349 | valid_rmse: 0.46957 | valid_mse: 0.22049 |  0:01:52s\n",
      "epoch 53 | loss: 0.211   | train_rmsle: 0.01371 | train_mae: 0.36381 | train_rmse: 0.46497 | train_mse: 0.2162  | valid_rmsle: 0.0131  | valid_mae: 0.36666 | valid_rmse: 0.46049 | valid_mse: 0.21205 |  0:01:54s\n",
      "epoch 54 | loss: 0.21062 | train_rmsle: 0.01349 | train_mae: 0.37369 | train_rmse: 0.4662  | train_mse: 0.21734 | valid_rmsle: 0.01293 | valid_mae: 0.37651 | valid_rmse: 0.46154 | valid_mse: 0.21302 |  0:01:57s\n",
      "epoch 55 | loss: 0.20799 | train_rmsle: 0.01354 | train_mae: 0.36237 | train_rmse: 0.46225 | train_mse: 0.21367 | valid_rmsle: 0.01311 | valid_mae: 0.36751 | valid_rmse: 0.46008 | valid_mse: 0.21167 |  0:01:59s\n",
      "epoch 56 | loss: 0.20463 | train_rmsle: 0.01336 | train_mae: 0.36158 | train_rmse: 0.45995 | train_mse: 0.21155 | valid_rmsle: 0.01298 | valid_mae: 0.37059 | valid_rmse: 0.45956 | valid_mse: 0.2112  |  0:02:01s\n",
      "epoch 57 | loss: 0.20452 | train_rmsle: 0.01335 | train_mae: 0.36127 | train_rmse: 0.46008 | train_mse: 0.21168 | valid_rmsle: 0.01276 | valid_mae: 0.36724 | valid_rmse: 0.4558  | valid_mse: 0.20776 |  0:02:03s\n",
      "epoch 58 | loss: 0.20483 | train_rmsle: 0.0133  | train_mae: 0.36111 | train_rmse: 0.45903 | train_mse: 0.2107  | valid_rmsle: 0.01262 | valid_mae: 0.36283 | valid_rmse: 0.45201 | valid_mse: 0.20431 |  0:02:05s\n",
      "epoch 59 | loss: 0.2024  | train_rmsle: 0.01318 | train_mae: 0.3583  | train_rmse: 0.45653 | train_mse: 0.20842 | valid_rmsle: 0.01255 | valid_mae: 0.36149 | valid_rmse: 0.45102 | valid_mse: 0.20342 |  0:02:08s\n",
      "epoch 60 | loss: 0.19945 | train_rmsle: 0.01314 | train_mae: 0.35406 | train_rmse: 0.45457 | train_mse: 0.20663 | valid_rmsle: 0.01249 | valid_mae: 0.35923 | valid_rmse: 0.44858 | valid_mse: 0.20122 |  0:02:10s\n",
      "epoch 61 | loss: 0.19521 | train_rmsle: 0.0128  | train_mae: 0.35494 | train_rmse: 0.45054 | train_mse: 0.20299 | valid_rmsle: 0.0122  | valid_mae: 0.36026 | valid_rmse: 0.4458  | valid_mse: 0.19874 |  0:02:12s\n",
      "epoch 62 | loss: 0.19295 | train_rmsle: 0.0125  | train_mae: 0.35426 | train_rmse: 0.44653 | train_mse: 0.19939 | valid_rmsle: 0.01194 | valid_mae: 0.35829 | valid_rmse: 0.44196 | valid_mse: 0.19533 |  0:02:14s\n",
      "epoch 63 | loss: 0.18876 | train_rmsle: 0.01209 | train_mae: 0.34368 | train_rmse: 0.43736 | train_mse: 0.19128 | valid_rmsle: 0.01162 | valid_mae: 0.35022 | valid_rmse: 0.43483 | valid_mse: 0.18908 |  0:02:16s\n",
      "epoch 64 | loss: 0.18218 | train_rmsle: 0.01186 | train_mae: 0.33487 | train_rmse: 0.43083 | train_mse: 0.18562 | valid_rmsle: 0.0114  | valid_mae: 0.34271 | valid_rmse: 0.42903 | valid_mse: 0.18407 |  0:02:19s\n",
      "epoch 65 | loss: 0.179   | train_rmsle: 0.01153 | train_mae: 0.32602 | train_rmse: 0.42343 | train_mse: 0.17929 | valid_rmsle: 0.01099 | valid_mae: 0.33216 | valid_rmse: 0.41947 | valid_mse: 0.17595 |  0:02:21s\n",
      "epoch 66 | loss: 0.17206 | train_rmsle: 0.01133 | train_mae: 0.31841 | train_rmse: 0.41801 | train_mse: 0.17473 | valid_rmsle: 0.01086 | valid_mae: 0.32376 | valid_rmse: 0.41533 | valid_mse: 0.1725  |  0:02:23s\n",
      "epoch 67 | loss: 0.16765 | train_rmsle: 0.01055 | train_mae: 0.32669 | train_rmse: 0.41028 | train_mse: 0.16833 | valid_rmsle: 0.0105  | valid_mae: 0.33596 | valid_rmse: 0.41408 | valid_mse: 0.17146 |  0:02:25s\n",
      "epoch 68 | loss: 0.16003 | train_rmsle: 0.01039 | train_mae: 0.30441 | train_rmse: 0.3999  | train_mse: 0.15992 | valid_rmsle: 0.01032 | valid_mae: 0.31642 | valid_rmse: 0.40517 | valid_mse: 0.16416 |  0:02:27s\n",
      "epoch 69 | loss: 0.15267 | train_rmsle: 0.0099  | train_mae: 0.31389 | train_rmse: 0.39615 | train_mse: 0.15693 | valid_rmsle: 0.00993 | valid_mae: 0.32312 | valid_rmse: 0.40205 | valid_mse: 0.16164 |  0:02:30s\n",
      "epoch 70 | loss: 0.14334 | train_rmsle: 0.00919 | train_mae: 0.28929 | train_rmse: 0.37663 | train_mse: 0.14185 | valid_rmsle: 0.00931 | valid_mae: 0.30156 | valid_rmse: 0.38566 | valid_mse: 0.14873 |  0:02:32s\n",
      "epoch 71 | loss: 0.1363  | train_rmsle: 0.00914 | train_mae: 0.29877 | train_rmse: 0.37876 | train_mse: 0.14346 | valid_rmsle: 0.00931 | valid_mae: 0.31098 | valid_rmse: 0.38871 | valid_mse: 0.1511  |  0:02:34s\n",
      "epoch 72 | loss: 0.13297 | train_rmsle: 0.00843 | train_mae: 0.2771  | train_rmse: 0.35982 | train_mse: 0.12947 | valid_rmsle: 0.00853 | valid_mae: 0.29088 | valid_rmse: 0.3696  | valid_mse: 0.13661 |  0:02:36s\n",
      "epoch 73 | loss: 0.12586 | train_rmsle: 0.00804 | train_mae: 0.27706 | train_rmse: 0.35395 | train_mse: 0.12528 | valid_rmsle: 0.00806 | valid_mae: 0.28858 | valid_rmse: 0.3615  | valid_mse: 0.13068 |  0:02:38s\n",
      "epoch 74 | loss: 0.11749 | train_rmsle: 0.0078  | train_mae: 0.27545 | train_rmse: 0.35013 | train_mse: 0.12259 | valid_rmsle: 0.00795 | valid_mae: 0.28944 | valid_rmse: 0.36089 | valid_mse: 0.13024 |  0:02:41s\n",
      "epoch 75 | loss: 0.11264 | train_rmsle: 0.00722 | train_mae: 0.26024 | train_rmse: 0.33457 | train_mse: 0.11193 | valid_rmsle: 0.00737 | valid_mae: 0.27392 | valid_rmse: 0.34572 | valid_mse: 0.11952 |  0:02:43s\n",
      "epoch 76 | loss: 0.10627 | train_rmsle: 0.00708 | train_mae: 0.26289 | train_rmse: 0.3338  | train_mse: 0.11142 | valid_rmsle: 0.00728 | valid_mae: 0.27738 | valid_rmse: 0.34637 | valid_mse: 0.11997 |  0:02:45s\n",
      "epoch 77 | loss: 0.10041 | train_rmsle: 0.00645 | train_mae: 0.24561 | train_rmse: 0.31586 | train_mse: 0.09977 | valid_rmsle: 0.00666 | valid_mae: 0.26133 | valid_rmse: 0.32918 | valid_mse: 0.10836 |  0:02:47s\n",
      "epoch 78 | loss: 0.09423 | train_rmsle: 0.00602 | train_mae: 0.23639 | train_rmse: 0.30509 | train_mse: 0.09308 | valid_rmsle: 0.00626 | valid_mae: 0.25136 | valid_rmse: 0.31916 | valid_mse: 0.10186 |  0:02:49s\n",
      "epoch 79 | loss: 0.08849 | train_rmsle: 0.00563 | train_mae: 0.22794 | train_rmse: 0.29546 | train_mse: 0.0873  | valid_rmsle: 0.00587 | valid_mae: 0.24229 | valid_rmse: 0.30946 | valid_mse: 0.09576 |  0:02:51s\n",
      "epoch 80 | loss: 0.0836  | train_rmsle: 0.00525 | train_mae: 0.21719 | train_rmse: 0.28396 | train_mse: 0.08063 | valid_rmsle: 0.00562 | valid_mae: 0.23566 | valid_rmse: 0.3024  | valid_mse: 0.09145 |  0:02:53s\n",
      "epoch 81 | loss: 0.08249 | train_rmsle: 0.005   | train_mae: 0.21227 | train_rmse: 0.27739 | train_mse: 0.07694 | valid_rmsle: 0.0055  | valid_mae: 0.23298 | valid_rmse: 0.29799 | valid_mse: 0.0888  |  0:02:55s\n",
      "epoch 82 | loss: 0.07851 | train_rmsle: 0.00507 | train_mae: 0.21409 | train_rmse: 0.27917 | train_mse: 0.07794 | valid_rmsle: 0.00566 | valid_mae: 0.23315 | valid_rmse: 0.3017  | valid_mse: 0.09102 |  0:02:57s\n",
      "epoch 83 | loss: 0.07421 | train_rmsle: 0.00456 | train_mae: 0.20802 | train_rmse: 0.26846 | train_mse: 0.07207 | valid_rmsle: 0.00517 | valid_mae: 0.22994 | valid_rmse: 0.29149 | valid_mse: 0.08497 |  0:02:59s\n",
      "epoch 84 | loss: 0.07188 | train_rmsle: 0.0049  | train_mae: 0.20978 | train_rmse: 0.27354 | train_mse: 0.07482 | valid_rmsle: 0.00545 | valid_mae: 0.2301  | valid_rmse: 0.29513 | valid_mse: 0.0871  |  0:03:01s\n",
      "epoch 85 | loss: 0.06724 | train_rmsle: 0.00462 | train_mae: 0.20634 | train_rmse: 0.26727 | train_mse: 0.07143 | valid_rmsle: 0.00513 | valid_mae: 0.22428 | valid_rmse: 0.28694 | valid_mse: 0.08233 |  0:03:03s\n",
      "epoch 86 | loss: 0.06185 | train_rmsle: 0.00377 | train_mae: 0.19178 | train_rmse: 0.2454  | train_mse: 0.06022 | valid_rmsle: 0.00438 | valid_mae: 0.2124  | valid_rmse: 0.26907 | valid_mse: 0.0724  |  0:03:05s\n",
      "epoch 87 | loss: 0.05716 | train_rmsle: 0.00353 | train_mae: 0.18334 | train_rmse: 0.23627 | train_mse: 0.05582 | valid_rmsle: 0.00407 | valid_mae: 0.20172 | valid_rmse: 0.25852 | valid_mse: 0.06683 |  0:03:08s\n",
      "epoch 88 | loss: 0.05356 | train_rmsle: 0.00288 | train_mae: 0.17163 | train_rmse: 0.21896 | train_mse: 0.04794 | valid_rmsle: 0.00357 | valid_mae: 0.19348 | valid_rmse: 0.24552 | valid_mse: 0.06028 |  0:03:10s\n",
      "epoch 89 | loss: 0.05405 | train_rmsle: 0.00375 | train_mae: 0.19538 | train_rmse: 0.24609 | train_mse: 0.06056 | valid_rmsle: 0.00465 | valid_mae: 0.21787 | valid_rmse: 0.27463 | valid_mse: 0.07542 |  0:03:12s\n",
      "epoch 90 | loss: 0.05172 | train_rmsle: 0.00268 | train_mae: 0.16649 | train_rmse: 0.21268 | train_mse: 0.04523 | valid_rmsle: 0.00322 | valid_mae: 0.18427 | valid_rmse: 0.23488 | valid_mse: 0.05517 |  0:03:14s\n",
      "epoch 91 | loss: 0.04688 | train_rmsle: 0.00257 | train_mae: 0.16186 | train_rmse: 0.20678 | train_mse: 0.04276 | valid_rmsle: 0.00311 | valid_mae: 0.1796  | valid_rmse: 0.23062 | valid_mse: 0.05319 |  0:03:16s\n",
      "epoch 92 | loss: 0.04905 | train_rmsle: 0.00283 | train_mae: 0.16818 | train_rmse: 0.21404 | train_mse: 0.04581 | valid_rmsle: 0.00357 | valid_mae: 0.18876 | valid_rmse: 0.24248 | valid_mse: 0.0588  |  0:03:19s\n",
      "epoch 93 | loss: 0.0482  | train_rmsle: 0.00259 | train_mae: 0.16617 | train_rmse: 0.21248 | train_mse: 0.04515 | valid_rmsle: 0.00309 | valid_mae: 0.18235 | valid_rmse: 0.23375 | valid_mse: 0.05464 |  0:03:21s\n",
      "epoch 94 | loss: 0.046   | train_rmsle: 0.00253 | train_mae: 0.16371 | train_rmse: 0.21041 | train_mse: 0.04427 | valid_rmsle: 0.0031  | valid_mae: 0.18343 | valid_rmse: 0.2355  | valid_mse: 0.05546 |  0:03:23s\n",
      "epoch 95 | loss: 0.04478 | train_rmsle: 0.00229 | train_mae: 0.15871 | train_rmse: 0.20056 | train_mse: 0.04022 | valid_rmsle: 0.00276 | valid_mae: 0.17417 | valid_rmse: 0.22159 | valid_mse: 0.0491  |  0:03:25s\n",
      "epoch 96 | loss: 0.04051 | train_rmsle: 0.00202 | train_mae: 0.14813 | train_rmse: 0.18822 | train_mse: 0.03543 | valid_rmsle: 0.00248 | valid_mae: 0.16339 | valid_rmse: 0.2092  | valid_mse: 0.04377 |  0:03:27s\n",
      "epoch 97 | loss: 0.039   | train_rmsle: 0.00191 | train_mae: 0.14317 | train_rmse: 0.18297 | train_mse: 0.03348 | valid_rmsle: 0.00232 | valid_mae: 0.15772 | valid_rmse: 0.20297 | valid_mse: 0.0412  |  0:03:29s\n",
      "epoch 98 | loss: 0.03698 | train_rmsle: 0.00198 | train_mae: 0.14632 | train_rmse: 0.18585 | train_mse: 0.03454 | valid_rmsle: 0.0024  | valid_mae: 0.15889 | valid_rmse: 0.20437 | valid_mse: 0.04177 |  0:03:31s\n",
      "epoch 99 | loss: 0.03635 | train_rmsle: 0.00185 | train_mae: 0.14283 | train_rmse: 0.18177 | train_mse: 0.03304 | valid_rmsle: 0.00223 | valid_mae: 0.15526 | valid_rmse: 0.19996 | valid_mse: 0.03998 |  0:03:33s\n",
      "epoch 100| loss: 0.03646 | train_rmsle: 0.00163 | train_mae: 0.13171 | train_rmse: 0.16912 | train_mse: 0.0286  | valid_rmsle: 0.00207 | valid_mae: 0.14691 | valid_rmse: 0.19204 | valid_mse: 0.03688 |  0:03:34s\n",
      "epoch 101| loss: 0.0326  | train_rmsle: 0.00177 | train_mae: 0.14022 | train_rmse: 0.17823 | train_mse: 0.03177 | valid_rmsle: 0.00217 | valid_mae: 0.15345 | valid_rmse: 0.19748 | valid_mse: 0.039   |  0:03:36s\n",
      "epoch 102| loss: 0.0327  | train_rmsle: 0.0015  | train_mae: 0.12714 | train_rmse: 0.16318 | train_mse: 0.02663 | valid_rmsle: 0.00192 | valid_mae: 0.14243 | valid_rmse: 0.18529 | valid_mse: 0.03433 |  0:03:39s\n",
      "epoch 103| loss: 0.03171 | train_rmsle: 0.00142 | train_mae: 0.12379 | train_rmse: 0.15881 | train_mse: 0.02522 | valid_rmsle: 0.00184 | valid_mae: 0.13898 | valid_rmse: 0.18117 | valid_mse: 0.03282 |  0:03:41s\n",
      "epoch 104| loss: 0.03275 | train_rmsle: 0.00194 | train_mae: 0.14463 | train_rmse: 0.18033 | train_mse: 0.03252 | valid_rmsle: 0.00236 | valid_mae: 0.15827 | valid_rmse: 0.19971 | valid_mse: 0.03989 |  0:03:43s\n",
      "epoch 105| loss: 0.03039 | train_rmsle: 0.00127 | train_mae: 0.11721 | train_rmse: 0.15065 | train_mse: 0.0227  | valid_rmsle: 0.00171 | valid_mae: 0.13346 | valid_rmse: 0.17512 | valid_mse: 0.03067 |  0:03:45s\n",
      "epoch 106| loss: 0.02715 | train_rmsle: 0.00132 | train_mae: 0.1211  | train_rmse: 0.15486 | train_mse: 0.02398 | valid_rmsle: 0.00176 | valid_mae: 0.13786 | valid_rmse: 0.17889 | valid_mse: 0.032   |  0:03:47s\n",
      "epoch 107| loss: 0.02849 | train_rmsle: 0.00133 | train_mae: 0.12188 | train_rmse: 0.15511 | train_mse: 0.02406 | valid_rmsle: 0.00176 | valid_mae: 0.1379  | valid_rmse: 0.17864 | valid_mse: 0.03191 |  0:03:50s\n",
      "epoch 108| loss: 0.02866 | train_rmsle: 0.00125 | train_mae: 0.11512 | train_rmse: 0.14889 | train_mse: 0.02217 | valid_rmsle: 0.00165 | valid_mae: 0.12994 | valid_rmse: 0.1711  | valid_mse: 0.02927 |  0:03:52s\n",
      "epoch 109| loss: 0.02645 | train_rmsle: 0.00122 | train_mae: 0.11425 | train_rmse: 0.14692 | train_mse: 0.02159 | valid_rmsle: 0.00159 | valid_mae: 0.12802 | valid_rmse: 0.1684  | valid_mse: 0.02836 |  0:03:54s\n",
      "epoch 110| loss: 0.02611 | train_rmsle: 0.00122 | train_mae: 0.11555 | train_rmse: 0.14714 | train_mse: 0.02165 | valid_rmsle: 0.00162 | valid_mae: 0.12941 | valid_rmse: 0.16916 | valid_mse: 0.02862 |  0:03:56s\n",
      "epoch 111| loss: 0.02548 | train_rmsle: 0.00146 | train_mae: 0.13006 | train_rmse: 0.16305 | train_mse: 0.02659 | valid_rmsle: 0.00182 | valid_mae: 0.14171 | valid_rmse: 0.18128 | valid_mse: 0.03286 |  0:03:58s\n",
      "epoch 112| loss: 0.02857 | train_rmsle: 0.00111 | train_mae: 0.1093  | train_rmse: 0.14114 | train_mse: 0.01992 | valid_rmsle: 0.00152 | valid_mae: 0.12443 | valid_rmse: 0.16454 | valid_mse: 0.02707 |  0:04:00s\n",
      "epoch 113| loss: 0.02765 | train_rmsle: 0.00133 | train_mae: 0.12207 | train_rmse: 0.15591 | train_mse: 0.02431 | valid_rmsle: 0.00169 | valid_mae: 0.13575 | valid_rmse: 0.17463 | valid_mse: 0.0305  |  0:04:03s\n",
      "epoch 114| loss: 0.02561 | train_rmsle: 0.0012  | train_mae: 0.11221 | train_rmse: 0.14388 | train_mse: 0.0207  | valid_rmsle: 0.00155 | valid_mae: 0.12751 | valid_rmse: 0.16498 | valid_mse: 0.02722 |  0:04:05s\n",
      "epoch 115| loss: 0.02477 | train_rmsle: 0.00112 | train_mae: 0.10918 | train_rmse: 0.14072 | train_mse: 0.0198  | valid_rmsle: 0.00149 | valid_mae: 0.1241  | valid_rmse: 0.16311 | valid_mse: 0.02661 |  0:04:07s\n",
      "epoch 116| loss: 0.02424 | train_rmsle: 0.00099 | train_mae: 0.10399 | train_rmse: 0.13387 | train_mse: 0.01792 | valid_rmsle: 0.00139 | valid_mae: 0.1209  | valid_rmse: 0.15811 | valid_mse: 0.025   |  0:04:09s\n",
      "epoch 117| loss: 0.02472 | train_rmsle: 0.00095 | train_mae: 0.10162 | train_rmse: 0.13166 | train_mse: 0.01733 | valid_rmsle: 0.0013  | valid_mae: 0.11671 | valid_rmse: 0.15411 | valid_mse: 0.02375 |  0:04:12s\n",
      "epoch 118| loss: 0.02213 | train_rmsle: 0.00106 | train_mae: 0.10999 | train_rmse: 0.13998 | train_mse: 0.01959 | valid_rmsle: 0.00142 | valid_mae: 0.1252  | valid_rmse: 0.16151 | valid_mse: 0.02608 |  0:04:14s\n",
      "epoch 119| loss: 0.02078 | train_rmsle: 0.00122 | train_mae: 0.11578 | train_rmse: 0.14486 | train_mse: 0.02098 | valid_rmsle: 0.0016  | valid_mae: 0.13093 | valid_rmse: 0.16618 | valid_mse: 0.02762 |  0:04:16s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 117 and best_valid_mse = 0.02375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.023125964946856405 RMSE: 0.15207223595007868 R2: 0.8976302640441193 MAE: 0.11689933836019716\n",
      "=====================================\n",
      "[19/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 18.40649| train_rmsle: 0.74473 | train_mae: 2.46611 | train_rmse: 2.51319 | train_mse: 6.31614 | valid_rmsle: 0.74818 | valid_mae: 2.47364 | valid_rmse: 2.51966 | valid_mse: 6.34869 |  0:00:02s\n",
      "epoch 1  | loss: 3.16101 | train_rmsle: 0.10384 | train_mae: 1.12551 | train_rmse: 1.21901 | train_mse: 1.48598 | valid_rmsle: 0.10584 | valid_mae: 1.13536 | valid_rmse: 1.23073 | valid_mse: 1.5147  |  0:00:04s\n",
      "epoch 2  | loss: 0.94953 | train_rmsle: 0.09335 | train_mae: 1.08376 | train_rmse: 1.17197 | train_mse: 1.37352 | valid_rmsle: 0.09385 | valid_mae: 1.08719 | valid_rmse: 1.17629 | valid_mse: 1.38365 |  0:00:06s\n",
      "epoch 3  | loss: 0.35927 | train_rmsle: 0.05685 | train_mae: 0.85698 | train_rmse: 0.94992 | train_mse: 0.90235 | valid_rmsle: 0.05703 | valid_mae: 0.85868 | valid_rmse: 0.95328 | valid_mse: 0.90873 |  0:00:08s\n",
      "epoch 4  | loss: 0.27682 | train_rmsle: 0.03676 | train_mae: 0.69035 | train_rmse: 0.78314 | train_mse: 0.61331 | valid_rmsle: 0.03671 | valid_mae: 0.6899  | valid_rmse: 0.78533 | valid_mse: 0.61675 |  0:00:11s\n",
      "epoch 5  | loss: 0.25201 | train_rmsle: 0.03296 | train_mae: 0.65262 | train_rmse: 0.745   | train_mse: 0.55503 | valid_rmsle: 0.03295 | valid_mae: 0.65288 | valid_rmse: 0.74783 | valid_mse: 0.55926 |  0:00:13s\n",
      "epoch 6  | loss: 0.24619 | train_rmsle: 0.02504 | train_mae: 0.56403 | train_rmse: 0.65457 | train_mse: 0.42846 | valid_rmsle: 0.02502 | valid_mae: 0.56636 | valid_rmse: 0.65786 | valid_mse: 0.43278 |  0:00:15s\n",
      "epoch 7  | loss: 0.23282 | train_rmsle: 0.02589 | train_mae: 0.57427 | train_rmse: 0.66507 | train_mse: 0.44232 | valid_rmsle: 0.02583 | valid_mae: 0.57527 | valid_rmse: 0.66793 | valid_mse: 0.44613 |  0:00:17s\n",
      "epoch 8  | loss: 0.23759 | train_rmsle: 0.01724 | train_mae: 0.45275 | train_rmse: 0.54045 | train_mse: 0.29209 | valid_rmsle: 0.01704 | valid_mae: 0.45603 | valid_rmse: 0.54242 | valid_mse: 0.29422 |  0:00:19s\n",
      "epoch 9  | loss: 0.23296 | train_rmsle: 0.01691 | train_mae: 0.44677 | train_rmse: 0.53456 | train_mse: 0.28575 | valid_rmsle: 0.01656 | valid_mae: 0.44888 | valid_rmse: 0.53426 | valid_mse: 0.28543 |  0:00:22s\n",
      "epoch 10 | loss: 0.23056 | train_rmsle: 0.01526 | train_mae: 0.41281 | train_rmse: 0.50251 | train_mse: 0.25252 | valid_rmsle: 0.01477 | valid_mae: 0.41399 | valid_rmse: 0.49995 | valid_mse: 0.24995 |  0:00:24s\n",
      "epoch 11 | loss: 0.22731 | train_rmsle: 0.01623 | train_mae: 0.43325 | train_rmse: 0.5218  | train_mse: 0.27227 | valid_rmsle: 0.01582 | valid_mae: 0.43585 | valid_rmse: 0.52064 | valid_mse: 0.27107 |  0:00:26s\n",
      "epoch 12 | loss: 0.23197 | train_rmsle: 0.01529 | train_mae: 0.41324 | train_rmse: 0.50301 | train_mse: 0.25302 | valid_rmsle: 0.01492 | valid_mae: 0.41621 | valid_rmse: 0.50236 | valid_mse: 0.25237 |  0:00:28s\n",
      "epoch 13 | loss: 0.23244 | train_rmsle: 0.01713 | train_mae: 0.45021 | train_rmse: 0.53815 | train_mse: 0.2896  | valid_rmsle: 0.01688 | valid_mae: 0.45367 | valid_rmse: 0.53929 | valid_mse: 0.29084 |  0:00:30s\n",
      "epoch 14 | loss: 0.22451 | train_rmsle: 0.01595 | train_mae: 0.4276  | train_rmse: 0.51654 | train_mse: 0.26682 | valid_rmsle: 0.01557 | valid_mae: 0.43034 | valid_rmse: 0.51589 | valid_mse: 0.26614 |  0:00:33s\n",
      "epoch 15 | loss: 0.22343 | train_rmsle: 0.01703 | train_mae: 0.44828 | train_rmse: 0.53643 | train_mse: 0.28775 | valid_rmsle: 0.0167  | valid_mae: 0.45076 | valid_rmse: 0.53631 | valid_mse: 0.28763 |  0:00:35s\n",
      "epoch 16 | loss: 0.22522 | train_rmsle: 0.01546 | train_mae: 0.41755 | train_rmse: 0.50651 | train_mse: 0.25655 | valid_rmsle: 0.01522 | valid_mae: 0.42111 | valid_rmse: 0.50804 | valid_mse: 0.2581  |  0:00:37s\n",
      "epoch 17 | loss: 0.22159 | train_rmsle: 0.01506 | train_mae: 0.40628 | train_rmse: 0.4976  | train_mse: 0.2476  | valid_rmsle: 0.01463 | valid_mae: 0.4086  | valid_rmse: 0.4964  | valid_mse: 0.24641 |  0:00:39s\n",
      "epoch 18 | loss: 0.22513 | train_rmsle: 0.01452 | train_mae: 0.38157 | train_rmse: 0.48121 | train_mse: 0.23157 | valid_rmsle: 0.01384 | valid_mae: 0.38324 | valid_rmse: 0.47551 | valid_mse: 0.22611 |  0:00:41s\n",
      "epoch 19 | loss: 0.22235 | train_rmsle: 0.0149  | train_mae: 0.4036  | train_rmse: 0.49509 | train_mse: 0.24511 | valid_rmsle: 0.01452 | valid_mae: 0.40843 | valid_rmse: 0.49474 | valid_mse: 0.24477 |  0:00:44s\n",
      "epoch 20 | loss: 0.21773 | train_rmsle: 0.01444 | train_mae: 0.38724 | train_rmse: 0.48267 | train_mse: 0.23297 | valid_rmsle: 0.01386 | valid_mae: 0.39047 | valid_rmse: 0.47891 | valid_mse: 0.22935 |  0:00:46s\n",
      "epoch 21 | loss: 0.2175  | train_rmsle: 0.01445 | train_mae: 0.39258 | train_rmse: 0.4847  | train_mse: 0.23493 | valid_rmsle: 0.01393 | valid_mae: 0.39593 | valid_rmse: 0.4824  | valid_mse: 0.23271 |  0:00:48s\n",
      "epoch 22 | loss: 0.21689 | train_rmsle: 0.01488 | train_mae: 0.40581 | train_rmse: 0.49567 | train_mse: 0.24569 | valid_rmsle: 0.01452 | valid_mae: 0.41107 | valid_rmse: 0.49582 | valid_mse: 0.24584 |  0:00:50s\n",
      "epoch 23 | loss: 0.21691 | train_rmsle: 0.01465 | train_mae: 0.40002 | train_rmse: 0.4907  | train_mse: 0.24078 | valid_rmsle: 0.01431 | valid_mae: 0.40553 | valid_rmse: 0.49114 | valid_mse: 0.24122 |  0:00:52s\n",
      "epoch 24 | loss: 0.2183  | train_rmsle: 0.01429 | train_mae: 0.3879  | train_rmse: 0.48102 | train_mse: 0.23138 | valid_rmsle: 0.01391 | valid_mae: 0.39119 | valid_rmse: 0.48042 | valid_mse: 0.23081 |  0:00:54s\n",
      "epoch 25 | loss: 0.21654 | train_rmsle: 0.01422 | train_mae: 0.38377 | train_rmse: 0.47882 | train_mse: 0.22927 | valid_rmsle: 0.01372 | valid_mae: 0.38799 | valid_rmse: 0.47624 | valid_mse: 0.22681 |  0:00:56s\n",
      "epoch 26 | loss: 0.21728 | train_rmsle: 0.01429 | train_mae: 0.38807 | train_rmse: 0.48112 | train_mse: 0.23147 | valid_rmsle: 0.01381 | valid_mae: 0.39493 | valid_rmse: 0.47907 | valid_mse: 0.22951 |  0:00:58s\n",
      "epoch 27 | loss: 0.21793 | train_rmsle: 0.01444 | train_mae: 0.39379 | train_rmse: 0.48599 | train_mse: 0.23619 | valid_rmsle: 0.01393 | valid_mae: 0.39854 | valid_rmse: 0.48314 | valid_mse: 0.23342 |  0:01:00s\n",
      "epoch 28 | loss: 0.21985 | train_rmsle: 0.01417 | train_mae: 0.38331 | train_rmse: 0.47851 | train_mse: 0.22897 | valid_rmsle: 0.01342 | valid_mae: 0.38391 | valid_rmse: 0.47099 | valid_mse: 0.22183 |  0:01:02s\n",
      "epoch 29 | loss: 0.21419 | train_rmsle: 0.0144  | train_mae: 0.3903  | train_rmse: 0.48409 | train_mse: 0.23435 | valid_rmsle: 0.01382 | valid_mae: 0.39332 | valid_rmse: 0.47991 | valid_mse: 0.23032 |  0:01:04s\n",
      "epoch 30 | loss: 0.21735 | train_rmsle: 0.0143  | train_mae: 0.37134 | train_rmse: 0.47504 | train_mse: 0.22567 | valid_rmsle: 0.01382 | valid_mae: 0.37734 | valid_rmse: 0.47284 | valid_mse: 0.22358 |  0:01:06s\n",
      "epoch 31 | loss: 0.21584 | train_rmsle: 0.01409 | train_mae: 0.38024 | train_rmse: 0.47616 | train_mse: 0.22673 | valid_rmsle: 0.01351 | valid_mae: 0.38349 | valid_rmse: 0.47188 | valid_mse: 0.22267 |  0:01:08s\n",
      "epoch 32 | loss: 0.21672 | train_rmsle: 0.01403 | train_mae: 0.3725  | train_rmse: 0.47219 | train_mse: 0.22296 | valid_rmsle: 0.01347 | valid_mae: 0.37828 | valid_rmse: 0.46881 | valid_mse: 0.21978 |  0:01:09s\n",
      "epoch 33 | loss: 0.2168  | train_rmsle: 0.01398 | train_mae: 0.37941 | train_rmse: 0.47426 | train_mse: 0.22492 | valid_rmsle: 0.01345 | valid_mae: 0.38328 | valid_rmse: 0.47127 | valid_mse: 0.2221  |  0:01:11s\n",
      "epoch 34 | loss: 0.21412 | train_rmsle: 0.01396 | train_mae: 0.37546 | train_rmse: 0.47245 | train_mse: 0.22321 | valid_rmsle: 0.01345 | valid_mae: 0.37844 | valid_rmse: 0.46957 | valid_mse: 0.22049 |  0:01:13s\n",
      "epoch 35 | loss: 0.21282 | train_rmsle: 0.01385 | train_mae: 0.37451 | train_rmse: 0.47073 | train_mse: 0.22159 | valid_rmsle: 0.01362 | valid_mae: 0.38237 | valid_rmse: 0.473   | valid_mse: 0.22373 |  0:01:15s\n",
      "epoch 36 | loss: 0.21138 | train_rmsle: 0.0139  | train_mae: 0.36871 | train_rmse: 0.4693  | train_mse: 0.22024 | valid_rmsle: 0.01369 | valid_mae: 0.37925 | valid_rmse: 0.47224 | valid_mse: 0.22301 |  0:01:17s\n",
      "epoch 37 | loss: 0.21057 | train_rmsle: 0.01378 | train_mae: 0.36951 | train_rmse: 0.4682  | train_mse: 0.21921 | valid_rmsle: 0.01364 | valid_mae: 0.38023 | valid_rmse: 0.47219 | valid_mse: 0.22296 |  0:01:19s\n",
      "epoch 38 | loss: 0.21967 | train_rmsle: 0.01386 | train_mae: 0.38121 | train_rmse: 0.47394 | train_mse: 0.22462 | valid_rmsle: 0.01385 | valid_mae: 0.39249 | valid_rmse: 0.48008 | valid_mse: 0.23048 |  0:01:22s\n",
      "epoch 39 | loss: 0.21312 | train_rmsle: 0.0139  | train_mae: 0.36725 | train_rmse: 0.46883 | train_mse: 0.2198  | valid_rmsle: 0.01358 | valid_mae: 0.37569 | valid_rmse: 0.46974 | valid_mse: 0.22066 |  0:01:24s\n",
      "epoch 40 | loss: 0.21503 | train_rmsle: 0.01387 | train_mae: 0.37027 | train_rmse: 0.46922 | train_mse: 0.22017 | valid_rmsle: 0.01361 | valid_mae: 0.37908 | valid_rmse: 0.4714  | valid_mse: 0.22221 |  0:01:26s\n",
      "epoch 41 | loss: 0.21488 | train_rmsle: 0.01451 | train_mae: 0.36953 | train_rmse: 0.47725 | train_mse: 0.22776 | valid_rmsle: 0.01413 | valid_mae: 0.37662 | valid_rmse: 0.47722 | valid_mse: 0.22774 |  0:01:28s\n",
      "epoch 42 | loss: 0.21617 | train_rmsle: 0.01393 | train_mae: 0.38107 | train_rmse: 0.47458 | train_mse: 0.22522 | valid_rmsle: 0.01351 | valid_mae: 0.38673 | valid_rmse: 0.47317 | valid_mse: 0.22389 |  0:01:31s\n",
      "epoch 43 | loss: 0.2131  | train_rmsle: 0.01367 | train_mae: 0.37254 | train_rmse: 0.46808 | train_mse: 0.2191  | valid_rmsle: 0.01335 | valid_mae: 0.3797  | valid_rmse: 0.4687  | valid_mse: 0.21968 |  0:01:33s\n",
      "epoch 44 | loss: 0.21284 | train_rmsle: 0.01395 | train_mae: 0.36903 | train_rmse: 0.47012 | train_mse: 0.22101 | valid_rmsle: 0.01344 | valid_mae: 0.37333 | valid_rmse: 0.46826 | valid_mse: 0.21927 |  0:01:35s\n",
      "epoch 45 | loss: 0.21254 | train_rmsle: 0.01445 | train_mae: 0.36756 | train_rmse: 0.47657 | train_mse: 0.22712 | valid_rmsle: 0.014   | valid_mae: 0.37775 | valid_rmse: 0.47577 | valid_mse: 0.22636 |  0:01:37s\n",
      "epoch 46 | loss: 0.21705 | train_rmsle: 0.01381 | train_mae: 0.36817 | train_rmse: 0.46798 | train_mse: 0.219   | valid_rmsle: 0.01343 | valid_mae: 0.37522 | valid_rmse: 0.46788 | valid_mse: 0.21891 |  0:01:39s\n",
      "epoch 47 | loss: 0.21267 | train_rmsle: 0.01391 | train_mae: 0.38065 | train_rmse: 0.47394 | train_mse: 0.22462 | valid_rmsle: 0.01354 | valid_mae: 0.38589 | valid_rmse: 0.47475 | valid_mse: 0.22539 |  0:01:42s\n",
      "epoch 48 | loss: 0.21098 | train_rmsle: 0.01383 | train_mae: 0.36872 | train_rmse: 0.46851 | train_mse: 0.2195  | valid_rmsle: 0.01355 | valid_mae: 0.37666 | valid_rmse: 0.47157 | valid_mse: 0.22238 |  0:01:44s\n",
      "epoch 49 | loss: 0.21046 | train_rmsle: 0.01392 | train_mae: 0.36901 | train_rmse: 0.46968 | train_mse: 0.2206  | valid_rmsle: 0.01346 | valid_mae: 0.37396 | valid_rmse: 0.46829 | valid_mse: 0.21929 |  0:01:46s\n",
      "epoch 50 | loss: 0.21225 | train_rmsle: 0.01382 | train_mae: 0.37095 | train_rmse: 0.46925 | train_mse: 0.22019 | valid_rmsle: 0.01318 | valid_mae: 0.37171 | valid_rmse: 0.46403 | valid_mse: 0.21532 |  0:01:48s\n",
      "epoch 51 | loss: 0.21199 | train_rmsle: 0.01384 | train_mae: 0.36938 | train_rmse: 0.46907 | train_mse: 0.22002 | valid_rmsle: 0.01333 | valid_mae: 0.37492 | valid_rmse: 0.46615 | valid_mse: 0.2173  |  0:01:50s\n",
      "epoch 52 | loss: 0.2101  | train_rmsle: 0.01369 | train_mae: 0.37718 | train_rmse: 0.47023 | train_mse: 0.22112 | valid_rmsle: 0.01333 | valid_mae: 0.38349 | valid_rmse: 0.46957 | valid_mse: 0.22049 |  0:01:53s\n",
      "epoch 53 | loss: 0.211   | train_rmsle: 0.01371 | train_mae: 0.36381 | train_rmse: 0.46497 | train_mse: 0.2162  | valid_rmsle: 0.0131  | valid_mae: 0.36666 | valid_rmse: 0.46049 | valid_mse: 0.21205 |  0:01:55s\n",
      "epoch 54 | loss: 0.21062 | train_rmsle: 0.01349 | train_mae: 0.37369 | train_rmse: 0.4662  | train_mse: 0.21734 | valid_rmsle: 0.01293 | valid_mae: 0.37651 | valid_rmse: 0.46154 | valid_mse: 0.21302 |  0:01:57s\n",
      "epoch 55 | loss: 0.20799 | train_rmsle: 0.01354 | train_mae: 0.36237 | train_rmse: 0.46225 | train_mse: 0.21367 | valid_rmsle: 0.01311 | valid_mae: 0.36751 | valid_rmse: 0.46008 | valid_mse: 0.21167 |  0:01:59s\n",
      "epoch 56 | loss: 0.20463 | train_rmsle: 0.01336 | train_mae: 0.36158 | train_rmse: 0.45995 | train_mse: 0.21155 | valid_rmsle: 0.01298 | valid_mae: 0.37059 | valid_rmse: 0.45956 | valid_mse: 0.2112  |  0:02:01s\n",
      "epoch 57 | loss: 0.20452 | train_rmsle: 0.01335 | train_mae: 0.36127 | train_rmse: 0.46008 | train_mse: 0.21168 | valid_rmsle: 0.01276 | valid_mae: 0.36724 | valid_rmse: 0.4558  | valid_mse: 0.20776 |  0:02:04s\n",
      "epoch 58 | loss: 0.20483 | train_rmsle: 0.0133  | train_mae: 0.36111 | train_rmse: 0.45903 | train_mse: 0.2107  | valid_rmsle: 0.01262 | valid_mae: 0.36283 | valid_rmse: 0.45201 | valid_mse: 0.20431 |  0:02:06s\n",
      "epoch 59 | loss: 0.2024  | train_rmsle: 0.01318 | train_mae: 0.3583  | train_rmse: 0.45653 | train_mse: 0.20842 | valid_rmsle: 0.01255 | valid_mae: 0.36149 | valid_rmse: 0.45102 | valid_mse: 0.20342 |  0:02:08s\n",
      "epoch 60 | loss: 0.19945 | train_rmsle: 0.01314 | train_mae: 0.35406 | train_rmse: 0.45457 | train_mse: 0.20663 | valid_rmsle: 0.01249 | valid_mae: 0.35923 | valid_rmse: 0.44858 | valid_mse: 0.20122 |  0:02:10s\n",
      "epoch 61 | loss: 0.19521 | train_rmsle: 0.0128  | train_mae: 0.35494 | train_rmse: 0.45054 | train_mse: 0.20299 | valid_rmsle: 0.0122  | valid_mae: 0.36026 | valid_rmse: 0.4458  | valid_mse: 0.19874 |  0:02:12s\n",
      "epoch 62 | loss: 0.19295 | train_rmsle: 0.0125  | train_mae: 0.35426 | train_rmse: 0.44653 | train_mse: 0.19939 | valid_rmsle: 0.01194 | valid_mae: 0.35829 | valid_rmse: 0.44196 | valid_mse: 0.19533 |  0:02:15s\n",
      "epoch 63 | loss: 0.18876 | train_rmsle: 0.01209 | train_mae: 0.34368 | train_rmse: 0.43736 | train_mse: 0.19128 | valid_rmsle: 0.01162 | valid_mae: 0.35022 | valid_rmse: 0.43483 | valid_mse: 0.18908 |  0:02:17s\n",
      "epoch 64 | loss: 0.18218 | train_rmsle: 0.01186 | train_mae: 0.33487 | train_rmse: 0.43083 | train_mse: 0.18562 | valid_rmsle: 0.0114  | valid_mae: 0.34271 | valid_rmse: 0.42903 | valid_mse: 0.18407 |  0:02:19s\n",
      "epoch 65 | loss: 0.179   | train_rmsle: 0.01153 | train_mae: 0.32602 | train_rmse: 0.42343 | train_mse: 0.17929 | valid_rmsle: 0.01099 | valid_mae: 0.33216 | valid_rmse: 0.41947 | valid_mse: 0.17595 |  0:02:21s\n",
      "epoch 66 | loss: 0.17206 | train_rmsle: 0.01133 | train_mae: 0.31841 | train_rmse: 0.41801 | train_mse: 0.17473 | valid_rmsle: 0.01086 | valid_mae: 0.32376 | valid_rmse: 0.41533 | valid_mse: 0.1725  |  0:02:23s\n",
      "epoch 67 | loss: 0.16765 | train_rmsle: 0.01055 | train_mae: 0.32669 | train_rmse: 0.41028 | train_mse: 0.16833 | valid_rmsle: 0.0105  | valid_mae: 0.33596 | valid_rmse: 0.41408 | valid_mse: 0.17146 |  0:02:26s\n",
      "epoch 68 | loss: 0.16003 | train_rmsle: 0.01039 | train_mae: 0.30441 | train_rmse: 0.3999  | train_mse: 0.15992 | valid_rmsle: 0.01032 | valid_mae: 0.31642 | valid_rmse: 0.40517 | valid_mse: 0.16416 |  0:02:28s\n",
      "epoch 69 | loss: 0.15267 | train_rmsle: 0.0099  | train_mae: 0.31389 | train_rmse: 0.39615 | train_mse: 0.15693 | valid_rmsle: 0.00993 | valid_mae: 0.32312 | valid_rmse: 0.40205 | valid_mse: 0.16164 |  0:02:30s\n",
      "epoch 70 | loss: 0.14334 | train_rmsle: 0.00919 | train_mae: 0.28929 | train_rmse: 0.37663 | train_mse: 0.14185 | valid_rmsle: 0.00931 | valid_mae: 0.30156 | valid_rmse: 0.38566 | valid_mse: 0.14873 |  0:02:32s\n",
      "epoch 71 | loss: 0.1363  | train_rmsle: 0.00914 | train_mae: 0.29877 | train_rmse: 0.37876 | train_mse: 0.14346 | valid_rmsle: 0.00931 | valid_mae: 0.31098 | valid_rmse: 0.38871 | valid_mse: 0.1511  |  0:02:34s\n",
      "epoch 72 | loss: 0.13297 | train_rmsle: 0.00843 | train_mae: 0.2771  | train_rmse: 0.35982 | train_mse: 0.12947 | valid_rmsle: 0.00853 | valid_mae: 0.29088 | valid_rmse: 0.3696  | valid_mse: 0.13661 |  0:02:36s\n",
      "epoch 73 | loss: 0.12586 | train_rmsle: 0.00804 | train_mae: 0.27706 | train_rmse: 0.35395 | train_mse: 0.12528 | valid_rmsle: 0.00806 | valid_mae: 0.28858 | valid_rmse: 0.3615  | valid_mse: 0.13068 |  0:02:38s\n",
      "epoch 74 | loss: 0.11749 | train_rmsle: 0.0078  | train_mae: 0.27545 | train_rmse: 0.35013 | train_mse: 0.12259 | valid_rmsle: 0.00795 | valid_mae: 0.28944 | valid_rmse: 0.36089 | valid_mse: 0.13024 |  0:02:40s\n",
      "epoch 75 | loss: 0.11264 | train_rmsle: 0.00722 | train_mae: 0.26024 | train_rmse: 0.33457 | train_mse: 0.11193 | valid_rmsle: 0.00737 | valid_mae: 0.27392 | valid_rmse: 0.34572 | valid_mse: 0.11952 |  0:02:42s\n",
      "epoch 76 | loss: 0.10627 | train_rmsle: 0.00708 | train_mae: 0.26289 | train_rmse: 0.3338  | train_mse: 0.11142 | valid_rmsle: 0.00728 | valid_mae: 0.27738 | valid_rmse: 0.34637 | valid_mse: 0.11997 |  0:02:44s\n",
      "epoch 77 | loss: 0.10041 | train_rmsle: 0.00645 | train_mae: 0.24561 | train_rmse: 0.31586 | train_mse: 0.09977 | valid_rmsle: 0.00666 | valid_mae: 0.26133 | valid_rmse: 0.32918 | valid_mse: 0.10836 |  0:02:46s\n",
      "epoch 78 | loss: 0.09423 | train_rmsle: 0.00602 | train_mae: 0.23639 | train_rmse: 0.30509 | train_mse: 0.09308 | valid_rmsle: 0.00626 | valid_mae: 0.25136 | valid_rmse: 0.31916 | valid_mse: 0.10186 |  0:02:48s\n",
      "epoch 79 | loss: 0.08849 | train_rmsle: 0.00563 | train_mae: 0.22794 | train_rmse: 0.29546 | train_mse: 0.0873  | valid_rmsle: 0.00587 | valid_mae: 0.24229 | valid_rmse: 0.30946 | valid_mse: 0.09576 |  0:02:50s\n",
      "epoch 80 | loss: 0.0836  | train_rmsle: 0.00525 | train_mae: 0.21719 | train_rmse: 0.28396 | train_mse: 0.08063 | valid_rmsle: 0.00562 | valid_mae: 0.23566 | valid_rmse: 0.3024  | valid_mse: 0.09145 |  0:02:53s\n",
      "epoch 81 | loss: 0.08249 | train_rmsle: 0.005   | train_mae: 0.21227 | train_rmse: 0.27739 | train_mse: 0.07694 | valid_rmsle: 0.0055  | valid_mae: 0.23298 | valid_rmse: 0.29799 | valid_mse: 0.0888  |  0:02:55s\n",
      "epoch 82 | loss: 0.07851 | train_rmsle: 0.00507 | train_mae: 0.21409 | train_rmse: 0.27917 | train_mse: 0.07794 | valid_rmsle: 0.00566 | valid_mae: 0.23315 | valid_rmse: 0.3017  | valid_mse: 0.09102 |  0:02:57s\n",
      "epoch 83 | loss: 0.07421 | train_rmsle: 0.00456 | train_mae: 0.20802 | train_rmse: 0.26846 | train_mse: 0.07207 | valid_rmsle: 0.00517 | valid_mae: 0.22994 | valid_rmse: 0.29149 | valid_mse: 0.08497 |  0:02:59s\n",
      "epoch 84 | loss: 0.07188 | train_rmsle: 0.0049  | train_mae: 0.20978 | train_rmse: 0.27354 | train_mse: 0.07482 | valid_rmsle: 0.00545 | valid_mae: 0.2301  | valid_rmse: 0.29513 | valid_mse: 0.0871  |  0:03:01s\n",
      "epoch 85 | loss: 0.06724 | train_rmsle: 0.00462 | train_mae: 0.20634 | train_rmse: 0.26727 | train_mse: 0.07143 | valid_rmsle: 0.00513 | valid_mae: 0.22428 | valid_rmse: 0.28694 | valid_mse: 0.08233 |  0:03:04s\n",
      "epoch 86 | loss: 0.06185 | train_rmsle: 0.00377 | train_mae: 0.19178 | train_rmse: 0.2454  | train_mse: 0.06022 | valid_rmsle: 0.00438 | valid_mae: 0.2124  | valid_rmse: 0.26907 | valid_mse: 0.0724  |  0:03:06s\n",
      "epoch 87 | loss: 0.05716 | train_rmsle: 0.00353 | train_mae: 0.18334 | train_rmse: 0.23627 | train_mse: 0.05582 | valid_rmsle: 0.00407 | valid_mae: 0.20172 | valid_rmse: 0.25852 | valid_mse: 0.06683 |  0:03:08s\n",
      "epoch 88 | loss: 0.05356 | train_rmsle: 0.00288 | train_mae: 0.17163 | train_rmse: 0.21896 | train_mse: 0.04794 | valid_rmsle: 0.00357 | valid_mae: 0.19348 | valid_rmse: 0.24552 | valid_mse: 0.06028 |  0:03:10s\n",
      "epoch 89 | loss: 0.05405 | train_rmsle: 0.00375 | train_mae: 0.19538 | train_rmse: 0.24609 | train_mse: 0.06056 | valid_rmsle: 0.00465 | valid_mae: 0.21787 | valid_rmse: 0.27463 | valid_mse: 0.07542 |  0:03:12s\n",
      "epoch 90 | loss: 0.05172 | train_rmsle: 0.00268 | train_mae: 0.16649 | train_rmse: 0.21268 | train_mse: 0.04523 | valid_rmsle: 0.00322 | valid_mae: 0.18427 | valid_rmse: 0.23488 | valid_mse: 0.05517 |  0:03:15s\n",
      "epoch 91 | loss: 0.04688 | train_rmsle: 0.00257 | train_mae: 0.16186 | train_rmse: 0.20678 | train_mse: 0.04276 | valid_rmsle: 0.00311 | valid_mae: 0.1796  | valid_rmse: 0.23062 | valid_mse: 0.05319 |  0:03:17s\n",
      "epoch 92 | loss: 0.04905 | train_rmsle: 0.00283 | train_mae: 0.16818 | train_rmse: 0.21404 | train_mse: 0.04581 | valid_rmsle: 0.00357 | valid_mae: 0.18876 | valid_rmse: 0.24248 | valid_mse: 0.0588  |  0:03:19s\n",
      "epoch 93 | loss: 0.0482  | train_rmsle: 0.00259 | train_mae: 0.16617 | train_rmse: 0.21248 | train_mse: 0.04515 | valid_rmsle: 0.00309 | valid_mae: 0.18235 | valid_rmse: 0.23375 | valid_mse: 0.05464 |  0:03:21s\n",
      "epoch 94 | loss: 0.046   | train_rmsle: 0.00253 | train_mae: 0.16371 | train_rmse: 0.21041 | train_mse: 0.04427 | valid_rmsle: 0.0031  | valid_mae: 0.18343 | valid_rmse: 0.2355  | valid_mse: 0.05546 |  0:03:23s\n",
      "epoch 95 | loss: 0.04478 | train_rmsle: 0.00229 | train_mae: 0.15871 | train_rmse: 0.20056 | train_mse: 0.04022 | valid_rmsle: 0.00276 | valid_mae: 0.17417 | valid_rmse: 0.22159 | valid_mse: 0.0491  |  0:03:25s\n",
      "epoch 96 | loss: 0.04051 | train_rmsle: 0.00202 | train_mae: 0.14813 | train_rmse: 0.18822 | train_mse: 0.03543 | valid_rmsle: 0.00248 | valid_mae: 0.16339 | valid_rmse: 0.2092  | valid_mse: 0.04377 |  0:03:27s\n",
      "epoch 97 | loss: 0.039   | train_rmsle: 0.00191 | train_mae: 0.14317 | train_rmse: 0.18297 | train_mse: 0.03348 | valid_rmsle: 0.00232 | valid_mae: 0.15772 | valid_rmse: 0.20297 | valid_mse: 0.0412  |  0:03:29s\n",
      "epoch 98 | loss: 0.03698 | train_rmsle: 0.00198 | train_mae: 0.14632 | train_rmse: 0.18585 | train_mse: 0.03454 | valid_rmsle: 0.0024  | valid_mae: 0.15889 | valid_rmse: 0.20437 | valid_mse: 0.04177 |  0:03:31s\n",
      "epoch 99 | loss: 0.03635 | train_rmsle: 0.00185 | train_mae: 0.14283 | train_rmse: 0.18177 | train_mse: 0.03304 | valid_rmsle: 0.00223 | valid_mae: 0.15526 | valid_rmse: 0.19996 | valid_mse: 0.03998 |  0:03:32s\n",
      "epoch 100| loss: 0.03646 | train_rmsle: 0.00163 | train_mae: 0.13171 | train_rmse: 0.16912 | train_mse: 0.0286  | valid_rmsle: 0.00207 | valid_mae: 0.14691 | valid_rmse: 0.19204 | valid_mse: 0.03688 |  0:03:35s\n",
      "epoch 101| loss: 0.0326  | train_rmsle: 0.00177 | train_mae: 0.14022 | train_rmse: 0.17823 | train_mse: 0.03177 | valid_rmsle: 0.00217 | valid_mae: 0.15345 | valid_rmse: 0.19748 | valid_mse: 0.039   |  0:03:37s\n",
      "epoch 102| loss: 0.0327  | train_rmsle: 0.0015  | train_mae: 0.12714 | train_rmse: 0.16318 | train_mse: 0.02663 | valid_rmsle: 0.00192 | valid_mae: 0.14243 | valid_rmse: 0.18529 | valid_mse: 0.03433 |  0:03:39s\n",
      "epoch 103| loss: 0.03171 | train_rmsle: 0.00142 | train_mae: 0.12379 | train_rmse: 0.15881 | train_mse: 0.02522 | valid_rmsle: 0.00184 | valid_mae: 0.13898 | valid_rmse: 0.18117 | valid_mse: 0.03282 |  0:03:41s\n",
      "epoch 104| loss: 0.03275 | train_rmsle: 0.00194 | train_mae: 0.14463 | train_rmse: 0.18033 | train_mse: 0.03252 | valid_rmsle: 0.00236 | valid_mae: 0.15827 | valid_rmse: 0.19971 | valid_mse: 0.03989 |  0:03:43s\n",
      "epoch 105| loss: 0.03039 | train_rmsle: 0.00127 | train_mae: 0.11721 | train_rmse: 0.15065 | train_mse: 0.0227  | valid_rmsle: 0.00171 | valid_mae: 0.13346 | valid_rmse: 0.17512 | valid_mse: 0.03067 |  0:03:45s\n",
      "epoch 106| loss: 0.02715 | train_rmsle: 0.00132 | train_mae: 0.1211  | train_rmse: 0.15486 | train_mse: 0.02398 | valid_rmsle: 0.00176 | valid_mae: 0.13786 | valid_rmse: 0.17889 | valid_mse: 0.032   |  0:03:47s\n",
      "epoch 107| loss: 0.02849 | train_rmsle: 0.00133 | train_mae: 0.12188 | train_rmse: 0.15511 | train_mse: 0.02406 | valid_rmsle: 0.00176 | valid_mae: 0.1379  | valid_rmse: 0.17864 | valid_mse: 0.03191 |  0:03:49s\n",
      "epoch 108| loss: 0.02866 | train_rmsle: 0.00125 | train_mae: 0.11512 | train_rmse: 0.14889 | train_mse: 0.02217 | valid_rmsle: 0.00165 | valid_mae: 0.12994 | valid_rmse: 0.1711  | valid_mse: 0.02927 |  0:03:51s\n",
      "epoch 109| loss: 0.02645 | train_rmsle: 0.00122 | train_mae: 0.11425 | train_rmse: 0.14692 | train_mse: 0.02159 | valid_rmsle: 0.00159 | valid_mae: 0.12802 | valid_rmse: 0.1684  | valid_mse: 0.02836 |  0:03:53s\n",
      "epoch 110| loss: 0.02611 | train_rmsle: 0.00122 | train_mae: 0.11555 | train_rmse: 0.14714 | train_mse: 0.02165 | valid_rmsle: 0.00162 | valid_mae: 0.12941 | valid_rmse: 0.16916 | valid_mse: 0.02862 |  0:03:55s\n",
      "epoch 111| loss: 0.02548 | train_rmsle: 0.00146 | train_mae: 0.13006 | train_rmse: 0.16305 | train_mse: 0.02659 | valid_rmsle: 0.00182 | valid_mae: 0.14171 | valid_rmse: 0.18128 | valid_mse: 0.03286 |  0:03:58s\n",
      "epoch 112| loss: 0.02857 | train_rmsle: 0.00111 | train_mae: 0.1093  | train_rmse: 0.14114 | train_mse: 0.01992 | valid_rmsle: 0.00152 | valid_mae: 0.12443 | valid_rmse: 0.16454 | valid_mse: 0.02707 |  0:04:00s\n",
      "epoch 113| loss: 0.02765 | train_rmsle: 0.00133 | train_mae: 0.12207 | train_rmse: 0.15591 | train_mse: 0.02431 | valid_rmsle: 0.00169 | valid_mae: 0.13575 | valid_rmse: 0.17463 | valid_mse: 0.0305  |  0:04:02s\n",
      "epoch 114| loss: 0.02561 | train_rmsle: 0.0012  | train_mae: 0.11221 | train_rmse: 0.14388 | train_mse: 0.0207  | valid_rmsle: 0.00155 | valid_mae: 0.12751 | valid_rmse: 0.16498 | valid_mse: 0.02722 |  0:04:04s\n",
      "epoch 115| loss: 0.02477 | train_rmsle: 0.00112 | train_mae: 0.10918 | train_rmse: 0.14072 | train_mse: 0.0198  | valid_rmsle: 0.00149 | valid_mae: 0.1241  | valid_rmse: 0.16311 | valid_mse: 0.02661 |  0:04:07s\n",
      "epoch 116| loss: 0.02424 | train_rmsle: 0.00099 | train_mae: 0.10399 | train_rmse: 0.13387 | train_mse: 0.01792 | valid_rmsle: 0.00139 | valid_mae: 0.1209  | valid_rmse: 0.15811 | valid_mse: 0.025   |  0:04:09s\n",
      "epoch 117| loss: 0.02472 | train_rmsle: 0.00095 | train_mae: 0.10162 | train_rmse: 0.13166 | train_mse: 0.01733 | valid_rmsle: 0.0013  | valid_mae: 0.11671 | valid_rmse: 0.15411 | valid_mse: 0.02375 |  0:04:11s\n",
      "epoch 118| loss: 0.02213 | train_rmsle: 0.00106 | train_mae: 0.10999 | train_rmse: 0.13998 | train_mse: 0.01959 | valid_rmsle: 0.00142 | valid_mae: 0.1252  | valid_rmse: 0.16151 | valid_mse: 0.02608 |  0:04:14s\n",
      "epoch 119| loss: 0.02078 | train_rmsle: 0.00122 | train_mae: 0.11578 | train_rmse: 0.14486 | train_mse: 0.02098 | valid_rmsle: 0.0016  | valid_mae: 0.13093 | valid_rmse: 0.16618 | valid_mse: 0.02762 |  0:04:16s\n",
      "epoch 120| loss: 0.02421 | train_rmsle: 0.00096 | train_mae: 0.10175 | train_rmse: 0.13162 | train_mse: 0.01732 | valid_rmsle: 0.00137 | valid_mae: 0.11932 | valid_rmse: 0.15638 | valid_mse: 0.02445 |  0:04:18s\n",
      "epoch 121| loss: 0.02137 | train_rmsle: 0.00087 | train_mae: 0.09646 | train_rmse: 0.12584 | train_mse: 0.01584 | valid_rmsle: 0.00123 | valid_mae: 0.11231 | valid_rmse: 0.14941 | valid_mse: 0.02232 |  0:04:20s\n",
      "epoch 122| loss: 0.02301 | train_rmsle: 0.00096 | train_mae: 0.10441 | train_rmse: 0.13413 | train_mse: 0.01799 | valid_rmsle: 0.0013  | valid_mae: 0.1193  | valid_rmse: 0.15427 | valid_mse: 0.0238  |  0:04:22s\n",
      "epoch 123| loss: 0.02014 | train_rmsle: 0.00088 | train_mae: 0.09905 | train_rmse: 0.12743 | train_mse: 0.01624 | valid_rmsle: 0.00122 | valid_mae: 0.11504 | valid_rmse: 0.14919 | valid_mse: 0.02226 |  0:04:25s\n",
      "epoch 124| loss: 0.01989 | train_rmsle: 0.00098 | train_mae: 0.10007 | train_rmse: 0.12901 | train_mse: 0.01664 | valid_rmsle: 0.00129 | valid_mae: 0.11436 | valid_rmse: 0.14963 | valid_mse: 0.02239 |  0:04:27s\n",
      "epoch 125| loss: 0.02044 | train_rmsle: 0.00089 | train_mae: 0.10008 | train_rmse: 0.12831 | train_mse: 0.01646 | valid_rmsle: 0.00122 | valid_mae: 0.11409 | valid_rmse: 0.14927 | valid_mse: 0.02228 |  0:04:29s\n",
      "epoch 126| loss: 0.02048 | train_rmsle: 0.00102 | train_mae: 0.10537 | train_rmse: 0.13274 | train_mse: 0.01762 | valid_rmsle: 0.00136 | valid_mae: 0.11871 | valid_rmse: 0.15342 | valid_mse: 0.02354 |  0:04:32s\n",
      "epoch 127| loss: 0.01821 | train_rmsle: 0.00072 | train_mae: 0.0884  | train_rmse: 0.11572 | train_mse: 0.01339 | valid_rmsle: 0.00106 | valid_mae: 0.10419 | valid_rmse: 0.13933 | valid_mse: 0.01941 |  0:04:34s\n",
      "epoch 128| loss: 0.01952 | train_rmsle: 0.0008  | train_mae: 0.0937  | train_rmse: 0.12173 | train_mse: 0.01482 | valid_rmsle: 0.00113 | valid_mae: 0.10879 | valid_rmse: 0.14386 | valid_mse: 0.02069 |  0:04:36s\n",
      "epoch 129| loss: 0.01847 | train_rmsle: 0.00071 | train_mae: 0.08724 | train_rmse: 0.11383 | train_mse: 0.01296 | valid_rmsle: 0.00106 | valid_mae: 0.1035  | valid_rmse: 0.13869 | valid_mse: 0.01924 |  0:04:39s\n",
      "epoch 130| loss: 0.01889 | train_rmsle: 0.00067 | train_mae: 0.08545 | train_rmse: 0.1116  | train_mse: 0.01246 | valid_rmsle: 0.00101 | valid_mae: 0.10199 | valid_rmse: 0.13625 | valid_mse: 0.01856 |  0:04:41s\n",
      "epoch 131| loss: 0.01839 | train_rmsle: 0.0009  | train_mae: 0.09641 | train_rmse: 0.12364 | train_mse: 0.01529 | valid_rmsle: 0.00121 | valid_mae: 0.11101 | valid_rmse: 0.14522 | valid_mse: 0.02109 |  0:04:43s\n",
      "epoch 132| loss: 0.01922 | train_rmsle: 0.0012  | train_mae: 0.11174 | train_rmse: 0.1389  | train_mse: 0.01929 | valid_rmsle: 0.00151 | valid_mae: 0.12605 | valid_rmse: 0.15719 | valid_mse: 0.02471 |  0:04:45s\n",
      "epoch 133| loss: 0.01859 | train_rmsle: 0.00068 | train_mae: 0.08622 | train_rmse: 0.11171 | train_mse: 0.01248 | valid_rmsle: 0.00097 | valid_mae: 0.10089 | valid_rmse: 0.13306 | valid_mse: 0.01771 |  0:04:47s\n",
      "epoch 134| loss: 0.01703 | train_rmsle: 0.00077 | train_mae: 0.09278 | train_rmse: 0.11788 | train_mse: 0.0139  | valid_rmsle: 0.00107 | valid_mae: 0.107   | valid_rmse: 0.13805 | valid_mse: 0.01906 |  0:04:50s\n",
      "epoch 135| loss: 0.01779 | train_rmsle: 0.00065 | train_mae: 0.08371 | train_rmse: 0.10888 | train_mse: 0.01185 | valid_rmsle: 0.00094 | valid_mae: 0.09827 | valid_rmse: 0.13009 | valid_mse: 0.01692 |  0:04:52s\n",
      "epoch 136| loss: 0.01795 | train_rmsle: 0.0009  | train_mae: 0.09849 | train_rmse: 0.12355 | train_mse: 0.01526 | valid_rmsle: 0.00119 | valid_mae: 0.11206 | valid_rmse: 0.1428  | valid_mse: 0.02039 |  0:04:54s\n",
      "epoch 137| loss: 0.01787 | train_rmsle: 0.00067 | train_mae: 0.08611 | train_rmse: 0.11116 | train_mse: 0.01236 | valid_rmsle: 0.00094 | valid_mae: 0.09903 | valid_rmse: 0.13051 | valid_mse: 0.01703 |  0:04:56s\n",
      "epoch 138| loss: 0.01765 | train_rmsle: 0.00072 | train_mae: 0.08682 | train_rmse: 0.11258 | train_mse: 0.01268 | valid_rmsle: 0.00097 | valid_mae: 0.1     | valid_rmse: 0.13184 | valid_mse: 0.01738 |  0:04:58s\n",
      "epoch 139| loss: 0.01758 | train_rmsle: 0.00074 | train_mae: 0.09055 | train_rmse: 0.11631 | train_mse: 0.01353 | valid_rmsle: 0.00101 | valid_mae: 0.10328 | valid_rmse: 0.13531 | valid_mse: 0.01831 |  0:05:00s\n",
      "epoch 140| loss: 0.01593 | train_rmsle: 0.0006  | train_mae: 0.08003 | train_rmse: 0.10462 | train_mse: 0.01094 | valid_rmsle: 0.00088 | valid_mae: 0.09529 | valid_rmse: 0.12625 | valid_mse: 0.01594 |  0:05:03s\n",
      "epoch 141| loss: 0.01616 | train_rmsle: 0.00077 | train_mae: 0.09183 | train_rmse: 0.11609 | train_mse: 0.01348 | valid_rmsle: 0.00103 | valid_mae: 0.10548 | valid_rmse: 0.13463 | valid_mse: 0.01812 |  0:05:05s\n",
      "epoch 142| loss: 0.017   | train_rmsle: 0.00064 | train_mae: 0.08143 | train_rmse: 0.10578 | train_mse: 0.01119 | valid_rmsle: 0.0009  | valid_mae: 0.09639 | valid_rmse: 0.12648 | valid_mse: 0.016   |  0:05:07s\n",
      "epoch 143| loss: 0.01719 | train_rmsle: 0.0007  | train_mae: 0.08869 | train_rmse: 0.11257 | train_mse: 0.01267 | valid_rmsle: 0.00098 | valid_mae: 0.10255 | valid_rmse: 0.13226 | valid_mse: 0.01749 |  0:05:09s\n",
      "epoch 144| loss: 0.01692 | train_rmsle: 0.00062 | train_mae: 0.08249 | train_rmse: 0.10797 | train_mse: 0.01166 | valid_rmsle: 0.00088 | valid_mae: 0.09672 | valid_rmse: 0.1277  | valid_mse: 0.01631 |  0:05:11s\n",
      "epoch 145| loss: 0.0183  | train_rmsle: 0.00063 | train_mae: 0.08235 | train_rmse: 0.10694 | train_mse: 0.01144 | valid_rmsle: 0.00087 | valid_mae: 0.09479 | valid_rmse: 0.1257  | valid_mse: 0.0158  |  0:05:13s\n",
      "epoch 146| loss: 0.01644 | train_rmsle: 0.00086 | train_mae: 0.09498 | train_rmse: 0.12025 | train_mse: 0.01446 | valid_rmsle: 0.0011  | valid_mae: 0.1067  | valid_rmse: 0.13694 | valid_mse: 0.01875 |  0:05:15s\n",
      "epoch 147| loss: 0.01661 | train_rmsle: 0.00083 | train_mae: 0.09425 | train_rmse: 0.11908 | train_mse: 0.01418 | valid_rmsle: 0.0011  | valid_mae: 0.10639 | valid_rmse: 0.13831 | valid_mse: 0.01913 |  0:05:17s\n",
      "epoch 148| loss: 0.01893 | train_rmsle: 0.0009  | train_mae: 0.10464 | train_rmse: 0.1297  | train_mse: 0.01682 | valid_rmsle: 0.00114 | valid_mae: 0.11582 | valid_rmse: 0.14575 | valid_mse: 0.02124 |  0:05:19s\n",
      "epoch 149| loss: 0.01623 | train_rmsle: 0.0007  | train_mae: 0.08733 | train_rmse: 0.11093 | train_mse: 0.01231 | valid_rmsle: 0.00093 | valid_mae: 0.09943 | valid_rmse: 0.12875 | valid_mse: 0.01658 |  0:05:21s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 145 and best_valid_mse = 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.016600589654245802 RMSE: 0.12884327554919506 R2: 0.9265155861161991 MAE: 0.0986151309788559\n",
      "=====================================\n",
      "[20/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 18.40649| train_rmsle: 0.74473 | train_mae: 2.46611 | train_rmse: 2.51319 | train_mse: 6.31614 | valid_rmsle: 0.74818 | valid_mae: 2.47364 | valid_rmse: 2.51966 | valid_mse: 6.34869 |  0:00:02s\n",
      "epoch 1  | loss: 3.16101 | train_rmsle: 0.10384 | train_mae: 1.12551 | train_rmse: 1.21901 | train_mse: 1.48598 | valid_rmsle: 0.10584 | valid_mae: 1.13536 | valid_rmse: 1.23073 | valid_mse: 1.5147  |  0:00:04s\n",
      "epoch 2  | loss: 0.94953 | train_rmsle: 0.09335 | train_mae: 1.08376 | train_rmse: 1.17197 | train_mse: 1.37352 | valid_rmsle: 0.09385 | valid_mae: 1.08719 | valid_rmse: 1.17629 | valid_mse: 1.38365 |  0:00:06s\n",
      "epoch 3  | loss: 0.35927 | train_rmsle: 0.05685 | train_mae: 0.85698 | train_rmse: 0.94992 | train_mse: 0.90235 | valid_rmsle: 0.05703 | valid_mae: 0.85868 | valid_rmse: 0.95328 | valid_mse: 0.90873 |  0:00:08s\n",
      "epoch 4  | loss: 0.27682 | train_rmsle: 0.03676 | train_mae: 0.69035 | train_rmse: 0.78314 | train_mse: 0.61331 | valid_rmsle: 0.03671 | valid_mae: 0.6899  | valid_rmse: 0.78533 | valid_mse: 0.61675 |  0:00:10s\n",
      "epoch 5  | loss: 0.25201 | train_rmsle: 0.03296 | train_mae: 0.65262 | train_rmse: 0.745   | train_mse: 0.55503 | valid_rmsle: 0.03295 | valid_mae: 0.65288 | valid_rmse: 0.74783 | valid_mse: 0.55926 |  0:00:12s\n",
      "epoch 6  | loss: 0.24619 | train_rmsle: 0.02504 | train_mae: 0.56403 | train_rmse: 0.65457 | train_mse: 0.42846 | valid_rmsle: 0.02502 | valid_mae: 0.56636 | valid_rmse: 0.65786 | valid_mse: 0.43278 |  0:00:13s\n",
      "epoch 7  | loss: 0.23282 | train_rmsle: 0.02589 | train_mae: 0.57427 | train_rmse: 0.66507 | train_mse: 0.44232 | valid_rmsle: 0.02583 | valid_mae: 0.57527 | valid_rmse: 0.66793 | valid_mse: 0.44613 |  0:00:15s\n",
      "epoch 8  | loss: 0.23759 | train_rmsle: 0.01724 | train_mae: 0.45275 | train_rmse: 0.54045 | train_mse: 0.29209 | valid_rmsle: 0.01704 | valid_mae: 0.45603 | valid_rmse: 0.54242 | valid_mse: 0.29422 |  0:00:17s\n",
      "epoch 9  | loss: 0.23296 | train_rmsle: 0.01691 | train_mae: 0.44677 | train_rmse: 0.53456 | train_mse: 0.28575 | valid_rmsle: 0.01656 | valid_mae: 0.44888 | valid_rmse: 0.53426 | valid_mse: 0.28543 |  0:00:19s\n",
      "epoch 10 | loss: 0.23056 | train_rmsle: 0.01526 | train_mae: 0.41281 | train_rmse: 0.50251 | train_mse: 0.25252 | valid_rmsle: 0.01477 | valid_mae: 0.41399 | valid_rmse: 0.49995 | valid_mse: 0.24995 |  0:00:22s\n",
      "epoch 11 | loss: 0.22731 | train_rmsle: 0.01623 | train_mae: 0.43325 | train_rmse: 0.5218  | train_mse: 0.27227 | valid_rmsle: 0.01582 | valid_mae: 0.43585 | valid_rmse: 0.52064 | valid_mse: 0.27107 |  0:00:24s\n",
      "epoch 12 | loss: 0.23197 | train_rmsle: 0.01529 | train_mae: 0.41324 | train_rmse: 0.50301 | train_mse: 0.25302 | valid_rmsle: 0.01492 | valid_mae: 0.41621 | valid_rmse: 0.50236 | valid_mse: 0.25237 |  0:00:26s\n",
      "epoch 13 | loss: 0.23244 | train_rmsle: 0.01713 | train_mae: 0.45021 | train_rmse: 0.53815 | train_mse: 0.2896  | valid_rmsle: 0.01688 | valid_mae: 0.45367 | valid_rmse: 0.53929 | valid_mse: 0.29084 |  0:00:28s\n",
      "epoch 14 | loss: 0.22451 | train_rmsle: 0.01595 | train_mae: 0.4276  | train_rmse: 0.51654 | train_mse: 0.26682 | valid_rmsle: 0.01557 | valid_mae: 0.43034 | valid_rmse: 0.51589 | valid_mse: 0.26614 |  0:00:30s\n",
      "epoch 15 | loss: 0.22343 | train_rmsle: 0.01703 | train_mae: 0.44828 | train_rmse: 0.53643 | train_mse: 0.28775 | valid_rmsle: 0.0167  | valid_mae: 0.45076 | valid_rmse: 0.53631 | valid_mse: 0.28763 |  0:00:33s\n",
      "epoch 16 | loss: 0.22522 | train_rmsle: 0.01546 | train_mae: 0.41755 | train_rmse: 0.50651 | train_mse: 0.25655 | valid_rmsle: 0.01522 | valid_mae: 0.42111 | valid_rmse: 0.50804 | valid_mse: 0.2581  |  0:00:35s\n",
      "epoch 17 | loss: 0.22159 | train_rmsle: 0.01506 | train_mae: 0.40628 | train_rmse: 0.4976  | train_mse: 0.2476  | valid_rmsle: 0.01463 | valid_mae: 0.4086  | valid_rmse: 0.4964  | valid_mse: 0.24641 |  0:00:37s\n",
      "epoch 18 | loss: 0.22513 | train_rmsle: 0.01452 | train_mae: 0.38157 | train_rmse: 0.48121 | train_mse: 0.23157 | valid_rmsle: 0.01384 | valid_mae: 0.38324 | valid_rmse: 0.47551 | valid_mse: 0.22611 |  0:00:39s\n",
      "epoch 19 | loss: 0.22235 | train_rmsle: 0.0149  | train_mae: 0.4036  | train_rmse: 0.49509 | train_mse: 0.24511 | valid_rmsle: 0.01452 | valid_mae: 0.40843 | valid_rmse: 0.49474 | valid_mse: 0.24477 |  0:00:42s\n",
      "epoch 20 | loss: 0.21773 | train_rmsle: 0.01444 | train_mae: 0.38724 | train_rmse: 0.48267 | train_mse: 0.23297 | valid_rmsle: 0.01386 | valid_mae: 0.39047 | valid_rmse: 0.47891 | valid_mse: 0.22935 |  0:00:44s\n",
      "epoch 21 | loss: 0.2175  | train_rmsle: 0.01445 | train_mae: 0.39258 | train_rmse: 0.4847  | train_mse: 0.23493 | valid_rmsle: 0.01393 | valid_mae: 0.39593 | valid_rmse: 0.4824  | valid_mse: 0.23271 |  0:00:46s\n",
      "epoch 22 | loss: 0.21689 | train_rmsle: 0.01488 | train_mae: 0.40581 | train_rmse: 0.49567 | train_mse: 0.24569 | valid_rmsle: 0.01452 | valid_mae: 0.41107 | valid_rmse: 0.49582 | valid_mse: 0.24584 |  0:00:48s\n",
      "epoch 23 | loss: 0.21691 | train_rmsle: 0.01465 | train_mae: 0.40002 | train_rmse: 0.4907  | train_mse: 0.24078 | valid_rmsle: 0.01431 | valid_mae: 0.40553 | valid_rmse: 0.49114 | valid_mse: 0.24122 |  0:00:50s\n",
      "epoch 24 | loss: 0.2183  | train_rmsle: 0.01429 | train_mae: 0.3879  | train_rmse: 0.48102 | train_mse: 0.23138 | valid_rmsle: 0.01391 | valid_mae: 0.39119 | valid_rmse: 0.48042 | valid_mse: 0.23081 |  0:00:52s\n",
      "epoch 25 | loss: 0.21654 | train_rmsle: 0.01422 | train_mae: 0.38377 | train_rmse: 0.47882 | train_mse: 0.22927 | valid_rmsle: 0.01372 | valid_mae: 0.38799 | valid_rmse: 0.47624 | valid_mse: 0.22681 |  0:00:55s\n",
      "epoch 26 | loss: 0.21728 | train_rmsle: 0.01429 | train_mae: 0.38807 | train_rmse: 0.48112 | train_mse: 0.23147 | valid_rmsle: 0.01381 | valid_mae: 0.39493 | valid_rmse: 0.47907 | valid_mse: 0.22951 |  0:00:57s\n",
      "epoch 27 | loss: 0.21793 | train_rmsle: 0.01444 | train_mae: 0.39379 | train_rmse: 0.48599 | train_mse: 0.23619 | valid_rmsle: 0.01393 | valid_mae: 0.39854 | valid_rmse: 0.48314 | valid_mse: 0.23342 |  0:00:59s\n",
      "epoch 28 | loss: 0.21985 | train_rmsle: 0.01417 | train_mae: 0.38331 | train_rmse: 0.47851 | train_mse: 0.22897 | valid_rmsle: 0.01342 | valid_mae: 0.38391 | valid_rmse: 0.47099 | valid_mse: 0.22183 |  0:01:01s\n",
      "epoch 29 | loss: 0.21419 | train_rmsle: 0.0144  | train_mae: 0.3903  | train_rmse: 0.48409 | train_mse: 0.23435 | valid_rmsle: 0.01382 | valid_mae: 0.39332 | valid_rmse: 0.47991 | valid_mse: 0.23032 |  0:01:03s\n",
      "epoch 30 | loss: 0.21735 | train_rmsle: 0.0143  | train_mae: 0.37134 | train_rmse: 0.47504 | train_mse: 0.22567 | valid_rmsle: 0.01382 | valid_mae: 0.37734 | valid_rmse: 0.47284 | valid_mse: 0.22358 |  0:01:05s\n",
      "epoch 31 | loss: 0.21584 | train_rmsle: 0.01409 | train_mae: 0.38024 | train_rmse: 0.47616 | train_mse: 0.22673 | valid_rmsle: 0.01351 | valid_mae: 0.38349 | valid_rmse: 0.47188 | valid_mse: 0.22267 |  0:01:07s\n",
      "epoch 32 | loss: 0.21672 | train_rmsle: 0.01403 | train_mae: 0.3725  | train_rmse: 0.47219 | train_mse: 0.22296 | valid_rmsle: 0.01347 | valid_mae: 0.37828 | valid_rmse: 0.46881 | valid_mse: 0.21978 |  0:01:09s\n",
      "epoch 33 | loss: 0.2168  | train_rmsle: 0.01398 | train_mae: 0.37941 | train_rmse: 0.47426 | train_mse: 0.22492 | valid_rmsle: 0.01345 | valid_mae: 0.38328 | valid_rmse: 0.47127 | valid_mse: 0.2221  |  0:01:11s\n",
      "epoch 34 | loss: 0.21412 | train_rmsle: 0.01396 | train_mae: 0.37546 | train_rmse: 0.47245 | train_mse: 0.22321 | valid_rmsle: 0.01345 | valid_mae: 0.37844 | valid_rmse: 0.46957 | valid_mse: 0.22049 |  0:01:13s\n",
      "epoch 35 | loss: 0.21282 | train_rmsle: 0.01385 | train_mae: 0.37451 | train_rmse: 0.47073 | train_mse: 0.22159 | valid_rmsle: 0.01362 | valid_mae: 0.38237 | valid_rmse: 0.473   | valid_mse: 0.22373 |  0:01:15s\n",
      "epoch 36 | loss: 0.21138 | train_rmsle: 0.0139  | train_mae: 0.36871 | train_rmse: 0.4693  | train_mse: 0.22024 | valid_rmsle: 0.01369 | valid_mae: 0.37925 | valid_rmse: 0.47224 | valid_mse: 0.22301 |  0:01:17s\n",
      "epoch 37 | loss: 0.21057 | train_rmsle: 0.01378 | train_mae: 0.36951 | train_rmse: 0.4682  | train_mse: 0.21921 | valid_rmsle: 0.01364 | valid_mae: 0.38023 | valid_rmse: 0.47219 | valid_mse: 0.22296 |  0:01:19s\n",
      "epoch 38 | loss: 0.21967 | train_rmsle: 0.01386 | train_mae: 0.38121 | train_rmse: 0.47394 | train_mse: 0.22462 | valid_rmsle: 0.01385 | valid_mae: 0.39249 | valid_rmse: 0.48008 | valid_mse: 0.23048 |  0:01:22s\n",
      "epoch 39 | loss: 0.21312 | train_rmsle: 0.0139  | train_mae: 0.36725 | train_rmse: 0.46883 | train_mse: 0.2198  | valid_rmsle: 0.01358 | valid_mae: 0.37569 | valid_rmse: 0.46974 | valid_mse: 0.22066 |  0:01:24s\n",
      "epoch 40 | loss: 0.21503 | train_rmsle: 0.01387 | train_mae: 0.37027 | train_rmse: 0.46922 | train_mse: 0.22017 | valid_rmsle: 0.01361 | valid_mae: 0.37908 | valid_rmse: 0.4714  | valid_mse: 0.22221 |  0:01:26s\n",
      "epoch 41 | loss: 0.21488 | train_rmsle: 0.01451 | train_mae: 0.36953 | train_rmse: 0.47725 | train_mse: 0.22776 | valid_rmsle: 0.01413 | valid_mae: 0.37662 | valid_rmse: 0.47722 | valid_mse: 0.22774 |  0:01:28s\n",
      "epoch 42 | loss: 0.21617 | train_rmsle: 0.01393 | train_mae: 0.38107 | train_rmse: 0.47458 | train_mse: 0.22522 | valid_rmsle: 0.01351 | valid_mae: 0.38673 | valid_rmse: 0.47317 | valid_mse: 0.22389 |  0:01:30s\n",
      "epoch 43 | loss: 0.2131  | train_rmsle: 0.01367 | train_mae: 0.37254 | train_rmse: 0.46808 | train_mse: 0.2191  | valid_rmsle: 0.01335 | valid_mae: 0.3797  | valid_rmse: 0.4687  | valid_mse: 0.21968 |  0:01:33s\n",
      "epoch 44 | loss: 0.21284 | train_rmsle: 0.01395 | train_mae: 0.36903 | train_rmse: 0.47012 | train_mse: 0.22101 | valid_rmsle: 0.01344 | valid_mae: 0.37333 | valid_rmse: 0.46826 | valid_mse: 0.21927 |  0:01:35s\n",
      "epoch 45 | loss: 0.21254 | train_rmsle: 0.01445 | train_mae: 0.36756 | train_rmse: 0.47657 | train_mse: 0.22712 | valid_rmsle: 0.014   | valid_mae: 0.37775 | valid_rmse: 0.47577 | valid_mse: 0.22636 |  0:01:37s\n",
      "epoch 46 | loss: 0.21705 | train_rmsle: 0.01381 | train_mae: 0.36817 | train_rmse: 0.46798 | train_mse: 0.219   | valid_rmsle: 0.01343 | valid_mae: 0.37522 | valid_rmse: 0.46788 | valid_mse: 0.21891 |  0:01:39s\n",
      "epoch 47 | loss: 0.21267 | train_rmsle: 0.01391 | train_mae: 0.38065 | train_rmse: 0.47394 | train_mse: 0.22462 | valid_rmsle: 0.01354 | valid_mae: 0.38589 | valid_rmse: 0.47475 | valid_mse: 0.22539 |  0:01:41s\n",
      "epoch 48 | loss: 0.21098 | train_rmsle: 0.01383 | train_mae: 0.36872 | train_rmse: 0.46851 | train_mse: 0.2195  | valid_rmsle: 0.01355 | valid_mae: 0.37666 | valid_rmse: 0.47157 | valid_mse: 0.22238 |  0:01:44s\n",
      "epoch 49 | loss: 0.21046 | train_rmsle: 0.01392 | train_mae: 0.36901 | train_rmse: 0.46968 | train_mse: 0.2206  | valid_rmsle: 0.01346 | valid_mae: 0.37396 | valid_rmse: 0.46829 | valid_mse: 0.21929 |  0:01:46s\n",
      "epoch 50 | loss: 0.21225 | train_rmsle: 0.01382 | train_mae: 0.37095 | train_rmse: 0.46925 | train_mse: 0.22019 | valid_rmsle: 0.01318 | valid_mae: 0.37171 | valid_rmse: 0.46403 | valid_mse: 0.21532 |  0:01:48s\n",
      "epoch 51 | loss: 0.21199 | train_rmsle: 0.01384 | train_mae: 0.36938 | train_rmse: 0.46907 | train_mse: 0.22002 | valid_rmsle: 0.01333 | valid_mae: 0.37492 | valid_rmse: 0.46615 | valid_mse: 0.2173  |  0:01:50s\n",
      "epoch 52 | loss: 0.2101  | train_rmsle: 0.01369 | train_mae: 0.37718 | train_rmse: 0.47023 | train_mse: 0.22112 | valid_rmsle: 0.01333 | valid_mae: 0.38349 | valid_rmse: 0.46957 | valid_mse: 0.22049 |  0:01:52s\n",
      "epoch 53 | loss: 0.211   | train_rmsle: 0.01371 | train_mae: 0.36381 | train_rmse: 0.46497 | train_mse: 0.2162  | valid_rmsle: 0.0131  | valid_mae: 0.36666 | valid_rmse: 0.46049 | valid_mse: 0.21205 |  0:01:54s\n",
      "epoch 54 | loss: 0.21062 | train_rmsle: 0.01349 | train_mae: 0.37369 | train_rmse: 0.4662  | train_mse: 0.21734 | valid_rmsle: 0.01293 | valid_mae: 0.37651 | valid_rmse: 0.46154 | valid_mse: 0.21302 |  0:01:57s\n",
      "epoch 55 | loss: 0.20799 | train_rmsle: 0.01354 | train_mae: 0.36237 | train_rmse: 0.46225 | train_mse: 0.21367 | valid_rmsle: 0.01311 | valid_mae: 0.36751 | valid_rmse: 0.46008 | valid_mse: 0.21167 |  0:01:59s\n",
      "epoch 56 | loss: 0.20463 | train_rmsle: 0.01336 | train_mae: 0.36158 | train_rmse: 0.45995 | train_mse: 0.21155 | valid_rmsle: 0.01298 | valid_mae: 0.37059 | valid_rmse: 0.45956 | valid_mse: 0.2112  |  0:02:01s\n",
      "epoch 57 | loss: 0.20452 | train_rmsle: 0.01335 | train_mae: 0.36127 | train_rmse: 0.46008 | train_mse: 0.21168 | valid_rmsle: 0.01276 | valid_mae: 0.36724 | valid_rmse: 0.4558  | valid_mse: 0.20776 |  0:02:03s\n",
      "epoch 58 | loss: 0.20483 | train_rmsle: 0.0133  | train_mae: 0.36111 | train_rmse: 0.45903 | train_mse: 0.2107  | valid_rmsle: 0.01262 | valid_mae: 0.36283 | valid_rmse: 0.45201 | valid_mse: 0.20431 |  0:02:05s\n",
      "epoch 59 | loss: 0.2024  | train_rmsle: 0.01318 | train_mae: 0.3583  | train_rmse: 0.45653 | train_mse: 0.20842 | valid_rmsle: 0.01255 | valid_mae: 0.36149 | valid_rmse: 0.45102 | valid_mse: 0.20342 |  0:02:08s\n",
      "epoch 60 | loss: 0.19945 | train_rmsle: 0.01314 | train_mae: 0.35406 | train_rmse: 0.45457 | train_mse: 0.20663 | valid_rmsle: 0.01249 | valid_mae: 0.35923 | valid_rmse: 0.44858 | valid_mse: 0.20122 |  0:02:10s\n",
      "epoch 61 | loss: 0.19521 | train_rmsle: 0.0128  | train_mae: 0.35494 | train_rmse: 0.45054 | train_mse: 0.20299 | valid_rmsle: 0.0122  | valid_mae: 0.36026 | valid_rmse: 0.4458  | valid_mse: 0.19874 |  0:02:12s\n",
      "epoch 62 | loss: 0.19295 | train_rmsle: 0.0125  | train_mae: 0.35426 | train_rmse: 0.44653 | train_mse: 0.19939 | valid_rmsle: 0.01194 | valid_mae: 0.35829 | valid_rmse: 0.44196 | valid_mse: 0.19533 |  0:02:14s\n",
      "epoch 63 | loss: 0.18876 | train_rmsle: 0.01209 | train_mae: 0.34368 | train_rmse: 0.43736 | train_mse: 0.19128 | valid_rmsle: 0.01162 | valid_mae: 0.35022 | valid_rmse: 0.43483 | valid_mse: 0.18908 |  0:02:16s\n",
      "epoch 64 | loss: 0.18218 | train_rmsle: 0.01186 | train_mae: 0.33487 | train_rmse: 0.43083 | train_mse: 0.18562 | valid_rmsle: 0.0114  | valid_mae: 0.34271 | valid_rmse: 0.42903 | valid_mse: 0.18407 |  0:02:18s\n",
      "epoch 65 | loss: 0.179   | train_rmsle: 0.01153 | train_mae: 0.32602 | train_rmse: 0.42343 | train_mse: 0.17929 | valid_rmsle: 0.01099 | valid_mae: 0.33216 | valid_rmse: 0.41947 | valid_mse: 0.17595 |  0:02:21s\n",
      "epoch 66 | loss: 0.17206 | train_rmsle: 0.01133 | train_mae: 0.31841 | train_rmse: 0.41801 | train_mse: 0.17473 | valid_rmsle: 0.01086 | valid_mae: 0.32376 | valid_rmse: 0.41533 | valid_mse: 0.1725  |  0:02:23s\n",
      "epoch 67 | loss: 0.16765 | train_rmsle: 0.01055 | train_mae: 0.32669 | train_rmse: 0.41028 | train_mse: 0.16833 | valid_rmsle: 0.0105  | valid_mae: 0.33596 | valid_rmse: 0.41408 | valid_mse: 0.17146 |  0:02:25s\n",
      "epoch 68 | loss: 0.16003 | train_rmsle: 0.01039 | train_mae: 0.30441 | train_rmse: 0.3999  | train_mse: 0.15992 | valid_rmsle: 0.01032 | valid_mae: 0.31642 | valid_rmse: 0.40517 | valid_mse: 0.16416 |  0:02:27s\n",
      "epoch 69 | loss: 0.15267 | train_rmsle: 0.0099  | train_mae: 0.31389 | train_rmse: 0.39615 | train_mse: 0.15693 | valid_rmsle: 0.00993 | valid_mae: 0.32312 | valid_rmse: 0.40205 | valid_mse: 0.16164 |  0:02:29s\n",
      "epoch 70 | loss: 0.14334 | train_rmsle: 0.00919 | train_mae: 0.28929 | train_rmse: 0.37663 | train_mse: 0.14185 | valid_rmsle: 0.00931 | valid_mae: 0.30156 | valid_rmse: 0.38566 | valid_mse: 0.14873 |  0:02:31s\n",
      "epoch 71 | loss: 0.1363  | train_rmsle: 0.00914 | train_mae: 0.29877 | train_rmse: 0.37876 | train_mse: 0.14346 | valid_rmsle: 0.00931 | valid_mae: 0.31098 | valid_rmse: 0.38871 | valid_mse: 0.1511  |  0:02:32s\n",
      "epoch 72 | loss: 0.13297 | train_rmsle: 0.00843 | train_mae: 0.2771  | train_rmse: 0.35982 | train_mse: 0.12947 | valid_rmsle: 0.00853 | valid_mae: 0.29088 | valid_rmse: 0.3696  | valid_mse: 0.13661 |  0:02:34s\n",
      "epoch 73 | loss: 0.12586 | train_rmsle: 0.00804 | train_mae: 0.27706 | train_rmse: 0.35395 | train_mse: 0.12528 | valid_rmsle: 0.00806 | valid_mae: 0.28858 | valid_rmse: 0.3615  | valid_mse: 0.13068 |  0:02:36s\n",
      "epoch 74 | loss: 0.11749 | train_rmsle: 0.0078  | train_mae: 0.27545 | train_rmse: 0.35013 | train_mse: 0.12259 | valid_rmsle: 0.00795 | valid_mae: 0.28944 | valid_rmse: 0.36089 | valid_mse: 0.13024 |  0:02:37s\n",
      "epoch 75 | loss: 0.11264 | train_rmsle: 0.00722 | train_mae: 0.26024 | train_rmse: 0.33457 | train_mse: 0.11193 | valid_rmsle: 0.00737 | valid_mae: 0.27392 | valid_rmse: 0.34572 | valid_mse: 0.11952 |  0:02:39s\n",
      "epoch 76 | loss: 0.10627 | train_rmsle: 0.00708 | train_mae: 0.26289 | train_rmse: 0.3338  | train_mse: 0.11142 | valid_rmsle: 0.00728 | valid_mae: 0.27738 | valid_rmse: 0.34637 | valid_mse: 0.11997 |  0:02:41s\n",
      "epoch 77 | loss: 0.10041 | train_rmsle: 0.00645 | train_mae: 0.24561 | train_rmse: 0.31586 | train_mse: 0.09977 | valid_rmsle: 0.00666 | valid_mae: 0.26133 | valid_rmse: 0.32918 | valid_mse: 0.10836 |  0:02:43s\n",
      "epoch 78 | loss: 0.09423 | train_rmsle: 0.00602 | train_mae: 0.23639 | train_rmse: 0.30509 | train_mse: 0.09308 | valid_rmsle: 0.00626 | valid_mae: 0.25136 | valid_rmse: 0.31916 | valid_mse: 0.10186 |  0:02:45s\n",
      "epoch 79 | loss: 0.08849 | train_rmsle: 0.00563 | train_mae: 0.22794 | train_rmse: 0.29546 | train_mse: 0.0873  | valid_rmsle: 0.00587 | valid_mae: 0.24229 | valid_rmse: 0.30946 | valid_mse: 0.09576 |  0:02:47s\n",
      "epoch 80 | loss: 0.0836  | train_rmsle: 0.00525 | train_mae: 0.21719 | train_rmse: 0.28396 | train_mse: 0.08063 | valid_rmsle: 0.00562 | valid_mae: 0.23566 | valid_rmse: 0.3024  | valid_mse: 0.09145 |  0:02:50s\n",
      "epoch 81 | loss: 0.08249 | train_rmsle: 0.005   | train_mae: 0.21227 | train_rmse: 0.27739 | train_mse: 0.07694 | valid_rmsle: 0.0055  | valid_mae: 0.23298 | valid_rmse: 0.29799 | valid_mse: 0.0888  |  0:02:52s\n",
      "epoch 82 | loss: 0.07851 | train_rmsle: 0.00507 | train_mae: 0.21409 | train_rmse: 0.27917 | train_mse: 0.07794 | valid_rmsle: 0.00566 | valid_mae: 0.23315 | valid_rmse: 0.3017  | valid_mse: 0.09102 |  0:02:54s\n",
      "epoch 83 | loss: 0.07421 | train_rmsle: 0.00456 | train_mae: 0.20802 | train_rmse: 0.26846 | train_mse: 0.07207 | valid_rmsle: 0.00517 | valid_mae: 0.22994 | valid_rmse: 0.29149 | valid_mse: 0.08497 |  0:02:56s\n",
      "epoch 84 | loss: 0.07188 | train_rmsle: 0.0049  | train_mae: 0.20978 | train_rmse: 0.27354 | train_mse: 0.07482 | valid_rmsle: 0.00545 | valid_mae: 0.2301  | valid_rmse: 0.29513 | valid_mse: 0.0871  |  0:02:59s\n",
      "epoch 85 | loss: 0.06724 | train_rmsle: 0.00462 | train_mae: 0.20634 | train_rmse: 0.26727 | train_mse: 0.07143 | valid_rmsle: 0.00513 | valid_mae: 0.22428 | valid_rmse: 0.28694 | valid_mse: 0.08233 |  0:03:01s\n",
      "epoch 86 | loss: 0.06185 | train_rmsle: 0.00377 | train_mae: 0.19178 | train_rmse: 0.2454  | train_mse: 0.06022 | valid_rmsle: 0.00438 | valid_mae: 0.2124  | valid_rmse: 0.26907 | valid_mse: 0.0724  |  0:03:03s\n",
      "epoch 87 | loss: 0.05716 | train_rmsle: 0.00353 | train_mae: 0.18334 | train_rmse: 0.23627 | train_mse: 0.05582 | valid_rmsle: 0.00407 | valid_mae: 0.20172 | valid_rmse: 0.25852 | valid_mse: 0.06683 |  0:03:05s\n",
      "epoch 88 | loss: 0.05356 | train_rmsle: 0.00288 | train_mae: 0.17163 | train_rmse: 0.21896 | train_mse: 0.04794 | valid_rmsle: 0.00357 | valid_mae: 0.19348 | valid_rmse: 0.24552 | valid_mse: 0.06028 |  0:03:08s\n",
      "epoch 89 | loss: 0.05405 | train_rmsle: 0.00375 | train_mae: 0.19538 | train_rmse: 0.24609 | train_mse: 0.06056 | valid_rmsle: 0.00465 | valid_mae: 0.21787 | valid_rmse: 0.27463 | valid_mse: 0.07542 |  0:03:10s\n",
      "epoch 90 | loss: 0.05172 | train_rmsle: 0.00268 | train_mae: 0.16649 | train_rmse: 0.21268 | train_mse: 0.04523 | valid_rmsle: 0.00322 | valid_mae: 0.18427 | valid_rmse: 0.23488 | valid_mse: 0.05517 |  0:03:12s\n",
      "epoch 91 | loss: 0.04688 | train_rmsle: 0.00257 | train_mae: 0.16186 | train_rmse: 0.20678 | train_mse: 0.04276 | valid_rmsle: 0.00311 | valid_mae: 0.1796  | valid_rmse: 0.23062 | valid_mse: 0.05319 |  0:03:14s\n",
      "epoch 92 | loss: 0.04905 | train_rmsle: 0.00283 | train_mae: 0.16818 | train_rmse: 0.21404 | train_mse: 0.04581 | valid_rmsle: 0.00357 | valid_mae: 0.18876 | valid_rmse: 0.24248 | valid_mse: 0.0588  |  0:03:17s\n",
      "epoch 93 | loss: 0.0482  | train_rmsle: 0.00259 | train_mae: 0.16617 | train_rmse: 0.21248 | train_mse: 0.04515 | valid_rmsle: 0.00309 | valid_mae: 0.18235 | valid_rmse: 0.23375 | valid_mse: 0.05464 |  0:03:19s\n",
      "epoch 94 | loss: 0.046   | train_rmsle: 0.00253 | train_mae: 0.16371 | train_rmse: 0.21041 | train_mse: 0.04427 | valid_rmsle: 0.0031  | valid_mae: 0.18343 | valid_rmse: 0.2355  | valid_mse: 0.05546 |  0:03:21s\n",
      "epoch 95 | loss: 0.04478 | train_rmsle: 0.00229 | train_mae: 0.15871 | train_rmse: 0.20056 | train_mse: 0.04022 | valid_rmsle: 0.00276 | valid_mae: 0.17417 | valid_rmse: 0.22159 | valid_mse: 0.0491  |  0:03:24s\n",
      "epoch 96 | loss: 0.04051 | train_rmsle: 0.00202 | train_mae: 0.14813 | train_rmse: 0.18822 | train_mse: 0.03543 | valid_rmsle: 0.00248 | valid_mae: 0.16339 | valid_rmse: 0.2092  | valid_mse: 0.04377 |  0:03:26s\n",
      "epoch 97 | loss: 0.039   | train_rmsle: 0.00191 | train_mae: 0.14317 | train_rmse: 0.18297 | train_mse: 0.03348 | valid_rmsle: 0.00232 | valid_mae: 0.15772 | valid_rmse: 0.20297 | valid_mse: 0.0412  |  0:03:28s\n",
      "epoch 98 | loss: 0.03698 | train_rmsle: 0.00198 | train_mae: 0.14632 | train_rmse: 0.18585 | train_mse: 0.03454 | valid_rmsle: 0.0024  | valid_mae: 0.15889 | valid_rmse: 0.20437 | valid_mse: 0.04177 |  0:03:30s\n",
      "epoch 99 | loss: 0.03635 | train_rmsle: 0.00185 | train_mae: 0.14283 | train_rmse: 0.18177 | train_mse: 0.03304 | valid_rmsle: 0.00223 | valid_mae: 0.15526 | valid_rmse: 0.19996 | valid_mse: 0.03998 |  0:03:33s\n",
      "epoch 100| loss: 0.03646 | train_rmsle: 0.00163 | train_mae: 0.13171 | train_rmse: 0.16912 | train_mse: 0.0286  | valid_rmsle: 0.00207 | valid_mae: 0.14691 | valid_rmse: 0.19204 | valid_mse: 0.03688 |  0:03:35s\n",
      "epoch 101| loss: 0.0326  | train_rmsle: 0.00177 | train_mae: 0.14022 | train_rmse: 0.17823 | train_mse: 0.03177 | valid_rmsle: 0.00217 | valid_mae: 0.15345 | valid_rmse: 0.19748 | valid_mse: 0.039   |  0:03:37s\n",
      "epoch 102| loss: 0.0327  | train_rmsle: 0.0015  | train_mae: 0.12714 | train_rmse: 0.16318 | train_mse: 0.02663 | valid_rmsle: 0.00192 | valid_mae: 0.14243 | valid_rmse: 0.18529 | valid_mse: 0.03433 |  0:03:39s\n",
      "epoch 103| loss: 0.03171 | train_rmsle: 0.00142 | train_mae: 0.12379 | train_rmse: 0.15881 | train_mse: 0.02522 | valid_rmsle: 0.00184 | valid_mae: 0.13898 | valid_rmse: 0.18117 | valid_mse: 0.03282 |  0:03:42s\n",
      "epoch 104| loss: 0.03275 | train_rmsle: 0.00194 | train_mae: 0.14463 | train_rmse: 0.18033 | train_mse: 0.03252 | valid_rmsle: 0.00236 | valid_mae: 0.15827 | valid_rmse: 0.19971 | valid_mse: 0.03989 |  0:03:44s\n",
      "epoch 105| loss: 0.03039 | train_rmsle: 0.00127 | train_mae: 0.11721 | train_rmse: 0.15065 | train_mse: 0.0227  | valid_rmsle: 0.00171 | valid_mae: 0.13346 | valid_rmse: 0.17512 | valid_mse: 0.03067 |  0:03:46s\n",
      "epoch 106| loss: 0.02715 | train_rmsle: 0.00132 | train_mae: 0.1211  | train_rmse: 0.15486 | train_mse: 0.02398 | valid_rmsle: 0.00176 | valid_mae: 0.13786 | valid_rmse: 0.17889 | valid_mse: 0.032   |  0:03:49s\n",
      "epoch 107| loss: 0.02849 | train_rmsle: 0.00133 | train_mae: 0.12188 | train_rmse: 0.15511 | train_mse: 0.02406 | valid_rmsle: 0.00176 | valid_mae: 0.1379  | valid_rmse: 0.17864 | valid_mse: 0.03191 |  0:03:51s\n",
      "epoch 108| loss: 0.02866 | train_rmsle: 0.00125 | train_mae: 0.11512 | train_rmse: 0.14889 | train_mse: 0.02217 | valid_rmsle: 0.00165 | valid_mae: 0.12994 | valid_rmse: 0.1711  | valid_mse: 0.02927 |  0:03:53s\n",
      "epoch 109| loss: 0.02645 | train_rmsle: 0.00122 | train_mae: 0.11425 | train_rmse: 0.14692 | train_mse: 0.02159 | valid_rmsle: 0.00159 | valid_mae: 0.12802 | valid_rmse: 0.1684  | valid_mse: 0.02836 |  0:03:55s\n",
      "epoch 110| loss: 0.02611 | train_rmsle: 0.00122 | train_mae: 0.11555 | train_rmse: 0.14714 | train_mse: 0.02165 | valid_rmsle: 0.00162 | valid_mae: 0.12941 | valid_rmse: 0.16916 | valid_mse: 0.02862 |  0:03:57s\n",
      "epoch 111| loss: 0.02548 | train_rmsle: 0.00146 | train_mae: 0.13006 | train_rmse: 0.16305 | train_mse: 0.02659 | valid_rmsle: 0.00182 | valid_mae: 0.14171 | valid_rmse: 0.18128 | valid_mse: 0.03286 |  0:03:59s\n",
      "epoch 112| loss: 0.02857 | train_rmsle: 0.00111 | train_mae: 0.1093  | train_rmse: 0.14114 | train_mse: 0.01992 | valid_rmsle: 0.00152 | valid_mae: 0.12443 | valid_rmse: 0.16454 | valid_mse: 0.02707 |  0:04:01s\n",
      "epoch 113| loss: 0.02765 | train_rmsle: 0.00133 | train_mae: 0.12207 | train_rmse: 0.15591 | train_mse: 0.02431 | valid_rmsle: 0.00169 | valid_mae: 0.13575 | valid_rmse: 0.17463 | valid_mse: 0.0305  |  0:04:03s\n",
      "epoch 114| loss: 0.02561 | train_rmsle: 0.0012  | train_mae: 0.11221 | train_rmse: 0.14388 | train_mse: 0.0207  | valid_rmsle: 0.00155 | valid_mae: 0.12751 | valid_rmse: 0.16498 | valid_mse: 0.02722 |  0:04:05s\n",
      "epoch 115| loss: 0.02477 | train_rmsle: 0.00112 | train_mae: 0.10918 | train_rmse: 0.14072 | train_mse: 0.0198  | valid_rmsle: 0.00149 | valid_mae: 0.1241  | valid_rmse: 0.16311 | valid_mse: 0.02661 |  0:04:07s\n",
      "epoch 116| loss: 0.02424 | train_rmsle: 0.00099 | train_mae: 0.10399 | train_rmse: 0.13387 | train_mse: 0.01792 | valid_rmsle: 0.00139 | valid_mae: 0.1209  | valid_rmse: 0.15811 | valid_mse: 0.025   |  0:04:09s\n",
      "epoch 117| loss: 0.02472 | train_rmsle: 0.00095 | train_mae: 0.10162 | train_rmse: 0.13166 | train_mse: 0.01733 | valid_rmsle: 0.0013  | valid_mae: 0.11671 | valid_rmse: 0.15411 | valid_mse: 0.02375 |  0:04:12s\n",
      "epoch 118| loss: 0.02213 | train_rmsle: 0.00106 | train_mae: 0.10999 | train_rmse: 0.13998 | train_mse: 0.01959 | valid_rmsle: 0.00142 | valid_mae: 0.1252  | valid_rmse: 0.16151 | valid_mse: 0.02608 |  0:04:14s\n",
      "epoch 119| loss: 0.02078 | train_rmsle: 0.00122 | train_mae: 0.11578 | train_rmse: 0.14486 | train_mse: 0.02098 | valid_rmsle: 0.0016  | valid_mae: 0.13093 | valid_rmse: 0.16618 | valid_mse: 0.02762 |  0:04:16s\n",
      "epoch 120| loss: 0.02421 | train_rmsle: 0.00096 | train_mae: 0.10175 | train_rmse: 0.13162 | train_mse: 0.01732 | valid_rmsle: 0.00137 | valid_mae: 0.11932 | valid_rmse: 0.15638 | valid_mse: 0.02445 |  0:04:19s\n",
      "epoch 121| loss: 0.02137 | train_rmsle: 0.00087 | train_mae: 0.09646 | train_rmse: 0.12584 | train_mse: 0.01584 | valid_rmsle: 0.00123 | valid_mae: 0.11231 | valid_rmse: 0.14941 | valid_mse: 0.02232 |  0:04:21s\n",
      "epoch 122| loss: 0.02301 | train_rmsle: 0.00096 | train_mae: 0.10441 | train_rmse: 0.13413 | train_mse: 0.01799 | valid_rmsle: 0.0013  | valid_mae: 0.1193  | valid_rmse: 0.15427 | valid_mse: 0.0238  |  0:04:23s\n",
      "epoch 123| loss: 0.02014 | train_rmsle: 0.00088 | train_mae: 0.09905 | train_rmse: 0.12743 | train_mse: 0.01624 | valid_rmsle: 0.00122 | valid_mae: 0.11504 | valid_rmse: 0.14919 | valid_mse: 0.02226 |  0:04:25s\n",
      "epoch 124| loss: 0.01989 | train_rmsle: 0.00098 | train_mae: 0.10007 | train_rmse: 0.12901 | train_mse: 0.01664 | valid_rmsle: 0.00129 | valid_mae: 0.11436 | valid_rmse: 0.14963 | valid_mse: 0.02239 |  0:04:27s\n",
      "epoch 125| loss: 0.02044 | train_rmsle: 0.00089 | train_mae: 0.10008 | train_rmse: 0.12831 | train_mse: 0.01646 | valid_rmsle: 0.00122 | valid_mae: 0.11409 | valid_rmse: 0.14927 | valid_mse: 0.02228 |  0:04:30s\n",
      "epoch 126| loss: 0.02048 | train_rmsle: 0.00102 | train_mae: 0.10537 | train_rmse: 0.13274 | train_mse: 0.01762 | valid_rmsle: 0.00136 | valid_mae: 0.11871 | valid_rmse: 0.15342 | valid_mse: 0.02354 |  0:04:32s\n",
      "epoch 127| loss: 0.01821 | train_rmsle: 0.00072 | train_mae: 0.0884  | train_rmse: 0.11572 | train_mse: 0.01339 | valid_rmsle: 0.00106 | valid_mae: 0.10419 | valid_rmse: 0.13933 | valid_mse: 0.01941 |  0:04:34s\n",
      "epoch 128| loss: 0.01952 | train_rmsle: 0.0008  | train_mae: 0.0937  | train_rmse: 0.12173 | train_mse: 0.01482 | valid_rmsle: 0.00113 | valid_mae: 0.10879 | valid_rmse: 0.14386 | valid_mse: 0.02069 |  0:04:37s\n",
      "epoch 129| loss: 0.01847 | train_rmsle: 0.00071 | train_mae: 0.08724 | train_rmse: 0.11383 | train_mse: 0.01296 | valid_rmsle: 0.00106 | valid_mae: 0.1035  | valid_rmse: 0.13869 | valid_mse: 0.01924 |  0:04:39s\n",
      "epoch 130| loss: 0.01889 | train_rmsle: 0.00067 | train_mae: 0.08545 | train_rmse: 0.1116  | train_mse: 0.01246 | valid_rmsle: 0.00101 | valid_mae: 0.10199 | valid_rmse: 0.13625 | valid_mse: 0.01856 |  0:04:41s\n",
      "epoch 131| loss: 0.01839 | train_rmsle: 0.0009  | train_mae: 0.09641 | train_rmse: 0.12364 | train_mse: 0.01529 | valid_rmsle: 0.00121 | valid_mae: 0.11101 | valid_rmse: 0.14522 | valid_mse: 0.02109 |  0:04:43s\n",
      "epoch 132| loss: 0.01922 | train_rmsle: 0.0012  | train_mae: 0.11174 | train_rmse: 0.1389  | train_mse: 0.01929 | valid_rmsle: 0.00151 | valid_mae: 0.12605 | valid_rmse: 0.15719 | valid_mse: 0.02471 |  0:04:45s\n",
      "epoch 133| loss: 0.01859 | train_rmsle: 0.00068 | train_mae: 0.08622 | train_rmse: 0.11171 | train_mse: 0.01248 | valid_rmsle: 0.00097 | valid_mae: 0.10089 | valid_rmse: 0.13306 | valid_mse: 0.01771 |  0:04:47s\n",
      "epoch 134| loss: 0.01703 | train_rmsle: 0.00077 | train_mae: 0.09278 | train_rmse: 0.11788 | train_mse: 0.0139  | valid_rmsle: 0.00107 | valid_mae: 0.107   | valid_rmse: 0.13805 | valid_mse: 0.01906 |  0:04:49s\n",
      "epoch 135| loss: 0.01779 | train_rmsle: 0.00065 | train_mae: 0.08371 | train_rmse: 0.10888 | train_mse: 0.01185 | valid_rmsle: 0.00094 | valid_mae: 0.09827 | valid_rmse: 0.13009 | valid_mse: 0.01692 |  0:04:51s\n",
      "epoch 136| loss: 0.01795 | train_rmsle: 0.0009  | train_mae: 0.09849 | train_rmse: 0.12355 | train_mse: 0.01526 | valid_rmsle: 0.00119 | valid_mae: 0.11206 | valid_rmse: 0.1428  | valid_mse: 0.02039 |  0:04:53s\n",
      "epoch 137| loss: 0.01787 | train_rmsle: 0.00067 | train_mae: 0.08611 | train_rmse: 0.11116 | train_mse: 0.01236 | valid_rmsle: 0.00094 | valid_mae: 0.09903 | valid_rmse: 0.13051 | valid_mse: 0.01703 |  0:04:55s\n",
      "epoch 138| loss: 0.01765 | train_rmsle: 0.00072 | train_mae: 0.08682 | train_rmse: 0.11258 | train_mse: 0.01268 | valid_rmsle: 0.00097 | valid_mae: 0.1     | valid_rmse: 0.13184 | valid_mse: 0.01738 |  0:04:57s\n",
      "epoch 139| loss: 0.01758 | train_rmsle: 0.00074 | train_mae: 0.09055 | train_rmse: 0.11631 | train_mse: 0.01353 | valid_rmsle: 0.00101 | valid_mae: 0.10328 | valid_rmse: 0.13531 | valid_mse: 0.01831 |  0:04:59s\n",
      "epoch 140| loss: 0.01593 | train_rmsle: 0.0006  | train_mae: 0.08003 | train_rmse: 0.10462 | train_mse: 0.01094 | valid_rmsle: 0.00088 | valid_mae: 0.09529 | valid_rmse: 0.12625 | valid_mse: 0.01594 |  0:05:01s\n",
      "epoch 141| loss: 0.01616 | train_rmsle: 0.00077 | train_mae: 0.09183 | train_rmse: 0.11609 | train_mse: 0.01348 | valid_rmsle: 0.00103 | valid_mae: 0.10548 | valid_rmse: 0.13463 | valid_mse: 0.01812 |  0:05:03s\n",
      "epoch 142| loss: 0.017   | train_rmsle: 0.00064 | train_mae: 0.08143 | train_rmse: 0.10578 | train_mse: 0.01119 | valid_rmsle: 0.0009  | valid_mae: 0.09639 | valid_rmse: 0.12648 | valid_mse: 0.016   |  0:05:06s\n",
      "epoch 143| loss: 0.01719 | train_rmsle: 0.0007  | train_mae: 0.08869 | train_rmse: 0.11257 | train_mse: 0.01267 | valid_rmsle: 0.00098 | valid_mae: 0.10255 | valid_rmse: 0.13226 | valid_mse: 0.01749 |  0:05:08s\n",
      "epoch 144| loss: 0.01692 | train_rmsle: 0.00062 | train_mae: 0.08249 | train_rmse: 0.10797 | train_mse: 0.01166 | valid_rmsle: 0.00088 | valid_mae: 0.09672 | valid_rmse: 0.1277  | valid_mse: 0.01631 |  0:05:10s\n",
      "epoch 145| loss: 0.0183  | train_rmsle: 0.00063 | train_mae: 0.08235 | train_rmse: 0.10694 | train_mse: 0.01144 | valid_rmsle: 0.00087 | valid_mae: 0.09479 | valid_rmse: 0.1257  | valid_mse: 0.0158  |  0:05:12s\n",
      "epoch 146| loss: 0.01644 | train_rmsle: 0.00086 | train_mae: 0.09498 | train_rmse: 0.12025 | train_mse: 0.01446 | valid_rmsle: 0.0011  | valid_mae: 0.1067  | valid_rmse: 0.13694 | valid_mse: 0.01875 |  0:05:14s\n",
      "epoch 147| loss: 0.01661 | train_rmsle: 0.00083 | train_mae: 0.09425 | train_rmse: 0.11908 | train_mse: 0.01418 | valid_rmsle: 0.0011  | valid_mae: 0.10639 | valid_rmse: 0.13831 | valid_mse: 0.01913 |  0:05:16s\n",
      "epoch 148| loss: 0.01893 | train_rmsle: 0.0009  | train_mae: 0.10464 | train_rmse: 0.1297  | train_mse: 0.01682 | valid_rmsle: 0.00114 | valid_mae: 0.11582 | valid_rmse: 0.14575 | valid_mse: 0.02124 |  0:05:18s\n",
      "epoch 149| loss: 0.01623 | train_rmsle: 0.0007  | train_mae: 0.08733 | train_rmse: 0.11093 | train_mse: 0.01231 | valid_rmsle: 0.00093 | valid_mae: 0.09943 | valid_rmse: 0.12875 | valid_mse: 0.01658 |  0:05:21s\n",
      "epoch 150| loss: 0.01716 | train_rmsle: 0.00108 | train_mae: 0.10629 | train_rmse: 0.13407 | train_mse: 0.01798 | valid_rmsle: 0.00132 | valid_mae: 0.1163  | valid_rmse: 0.15049 | valid_mse: 0.02265 |  0:05:23s\n",
      "epoch 151| loss: 0.02006 | train_rmsle: 0.00065 | train_mae: 0.08209 | train_rmse: 0.10638 | train_mse: 0.01132 | valid_rmsle: 0.00091 | valid_mae: 0.09567 | valid_rmse: 0.12635 | valid_mse: 0.01597 |  0:05:25s\n",
      "epoch 152| loss: 0.0154  | train_rmsle: 0.00053 | train_mae: 0.07542 | train_rmse: 0.09847 | train_mse: 0.0097  | valid_rmsle: 0.00079 | valid_mae: 0.08923 | valid_rmse: 0.11958 | valid_mse: 0.0143  |  0:05:27s\n",
      "epoch 153| loss: 0.01437 | train_rmsle: 0.00056 | train_mae: 0.07859 | train_rmse: 0.10196 | train_mse: 0.0104  | valid_rmsle: 0.00084 | valid_mae: 0.09299 | valid_rmse: 0.12397 | valid_mse: 0.01537 |  0:05:29s\n",
      "epoch 154| loss: 0.01579 | train_rmsle: 0.00057 | train_mae: 0.07875 | train_rmse: 0.10214 | train_mse: 0.01043 | valid_rmsle: 0.00082 | valid_mae: 0.09087 | valid_rmse: 0.12279 | valid_mse: 0.01508 |  0:05:31s\n",
      "epoch 155| loss: 0.01541 | train_rmsle: 0.00054 | train_mae: 0.07605 | train_rmse: 0.09819 | train_mse: 0.00964 | valid_rmsle: 0.00081 | valid_mae: 0.09046 | valid_rmse: 0.1206  | valid_mse: 0.01454 |  0:05:34s\n",
      "epoch 156| loss: 0.01462 | train_rmsle: 0.00086 | train_mae: 0.09943 | train_rmse: 0.12199 | train_mse: 0.01488 | valid_rmsle: 0.00114 | valid_mae: 0.11269 | valid_rmse: 0.14083 | valid_mse: 0.01983 |  0:05:36s\n",
      "epoch 157| loss: 0.01628 | train_rmsle: 0.00057 | train_mae: 0.07582 | train_rmse: 0.10264 | train_mse: 0.01053 | valid_rmsle: 0.0008  | valid_mae: 0.08942 | valid_rmse: 0.12033 | valid_mse: 0.01448 |  0:05:38s\n",
      "epoch 158| loss: 0.0147  | train_rmsle: 0.00059 | train_mae: 0.08069 | train_rmse: 0.10415 | train_mse: 0.01085 | valid_rmsle: 0.00083 | valid_mae: 0.09547 | valid_rmse: 0.12406 | valid_mse: 0.01539 |  0:05:40s\n",
      "epoch 159| loss: 0.01558 | train_rmsle: 0.0007  | train_mae: 0.08486 | train_rmse: 0.10818 | train_mse: 0.0117  | valid_rmsle: 0.00098 | valid_mae: 0.09914 | valid_rmse: 0.12918 | valid_mse: 0.01669 |  0:05:42s\n",
      "epoch 160| loss: 0.01569 | train_rmsle: 0.00075 | train_mae: 0.08575 | train_rmse: 0.11117 | train_mse: 0.01236 | valid_rmsle: 0.00099 | valid_mae: 0.0988  | valid_rmse: 0.12887 | valid_mse: 0.01661 |  0:05:44s\n",
      "epoch 161| loss: 0.01501 | train_rmsle: 0.00072 | train_mae: 0.08613 | train_rmse: 0.111   | train_mse: 0.01232 | valid_rmsle: 0.00093 | valid_mae: 0.09852 | valid_rmse: 0.12752 | valid_mse: 0.01626 |  0:05:47s\n",
      "epoch 162| loss: 0.01605 | train_rmsle: 0.00053 | train_mae: 0.07505 | train_rmse: 0.09783 | train_mse: 0.00957 | valid_rmsle: 0.00071 | valid_mae: 0.08762 | valid_rmse: 0.11393 | valid_mse: 0.01298 |  0:05:49s\n",
      "epoch 163| loss: 0.01548 | train_rmsle: 0.00073 | train_mae: 0.08891 | train_rmse: 0.11236 | train_mse: 0.01263 | valid_rmsle: 0.00095 | valid_mae: 0.10159 | valid_rmse: 0.12863 | valid_mse: 0.01654 |  0:05:51s\n",
      "epoch 164| loss: 0.01421 | train_rmsle: 0.00049 | train_mae: 0.07278 | train_rmse: 0.09477 | train_mse: 0.00898 | valid_rmsle: 0.00068 | valid_mae: 0.08567 | valid_rmse: 0.11212 | valid_mse: 0.01257 |  0:05:53s\n",
      "epoch 165| loss: 0.01468 | train_rmsle: 0.00058 | train_mae: 0.07678 | train_rmse: 0.10025 | train_mse: 0.01005 | valid_rmsle: 0.00075 | valid_mae: 0.0874  | valid_rmse: 0.11482 | valid_mse: 0.01318 |  0:05:55s\n",
      "epoch 166| loss: 0.0138  | train_rmsle: 0.00058 | train_mae: 0.0793  | train_rmse: 0.10219 | train_mse: 0.01044 | valid_rmsle: 0.0008  | valid_mae: 0.09152 | valid_rmse: 0.11953 | valid_mse: 0.01429 |  0:05:57s\n",
      "epoch 167| loss: 0.01395 | train_rmsle: 0.00046 | train_mae: 0.07041 | train_rmse: 0.09223 | train_mse: 0.00851 | valid_rmsle: 0.00066 | valid_mae: 0.08351 | valid_rmse: 0.10985 | valid_mse: 0.01207 |  0:05:59s\n",
      "epoch 168| loss: 0.01443 | train_rmsle: 0.00081 | train_mae: 0.09451 | train_rmse: 0.11685 | train_mse: 0.01365 | valid_rmsle: 0.00103 | valid_mae: 0.1064  | valid_rmse: 0.13318 | valid_mse: 0.01774 |  0:06:02s\n",
      "epoch 169| loss: 0.01351 | train_rmsle: 0.00062 | train_mae: 0.08425 | train_rmse: 0.1061  | train_mse: 0.01126 | valid_rmsle: 0.00082 | valid_mae: 0.09618 | valid_rmse: 0.12186 | valid_mse: 0.01485 |  0:06:04s\n",
      "epoch 170| loss: 0.01382 | train_rmsle: 0.00046 | train_mae: 0.07035 | train_rmse: 0.0907  | train_mse: 0.00823 | valid_rmsle: 0.00064 | valid_mae: 0.08248 | valid_rmse: 0.1068  | valid_mse: 0.01141 |  0:06:06s\n",
      "epoch 171| loss: 0.01275 | train_rmsle: 0.00058 | train_mae: 0.07879 | train_rmse: 0.09909 | train_mse: 0.00982 | valid_rmsle: 0.00075 | valid_mae: 0.08976 | valid_rmse: 0.11377 | valid_mse: 0.01294 |  0:06:08s\n",
      "epoch 172| loss: 0.01397 | train_rmsle: 0.0005  | train_mae: 0.07238 | train_rmse: 0.09309 | train_mse: 0.00867 | valid_rmsle: 0.00067 | valid_mae: 0.08468 | valid_rmse: 0.10891 | valid_mse: 0.01186 |  0:06:10s\n",
      "epoch 173| loss: 0.01281 | train_rmsle: 0.00056 | train_mae: 0.07721 | train_rmse: 0.09952 | train_mse: 0.0099  | valid_rmsle: 0.00072 | valid_mae: 0.08679 | valid_rmse: 0.11317 | valid_mse: 0.01281 |  0:06:11s\n",
      "epoch 174| loss: 0.01416 | train_rmsle: 0.0005  | train_mae: 0.07424 | train_rmse: 0.09468 | train_mse: 0.00896 | valid_rmsle: 0.00066 | valid_mae: 0.08514 | valid_rmse: 0.10899 | valid_mse: 0.01188 |  0:06:13s\n",
      "epoch 175| loss: 0.01397 | train_rmsle: 0.00051 | train_mae: 0.07152 | train_rmse: 0.09185 | train_mse: 0.00844 | valid_rmsle: 0.00067 | valid_mae: 0.08286 | valid_rmse: 0.10668 | valid_mse: 0.01138 |  0:06:15s\n",
      "epoch 176| loss: 0.01413 | train_rmsle: 0.00051 | train_mae: 0.07659 | train_rmse: 0.09753 | train_mse: 0.00951 | valid_rmsle: 0.00068 | valid_mae: 0.08715 | valid_rmse: 0.11172 | valid_mse: 0.01248 |  0:06:17s\n",
      "epoch 177| loss: 0.01393 | train_rmsle: 0.00045 | train_mae: 0.0706  | train_rmse: 0.09049 | train_mse: 0.00819 | valid_rmsle: 0.00061 | valid_mae: 0.08182 | valid_rmse: 0.10511 | valid_mse: 0.01105 |  0:06:19s\n",
      "epoch 178| loss: 0.01196 | train_rmsle: 0.00045 | train_mae: 0.07109 | train_rmse: 0.09039 | train_mse: 0.00817 | valid_rmsle: 0.00062 | valid_mae: 0.08243 | valid_rmse: 0.1065  | valid_mse: 0.01134 |  0:06:21s\n",
      "epoch 179| loss: 0.01203 | train_rmsle: 0.00056 | train_mae: 0.0727  | train_rmse: 0.09443 | train_mse: 0.00892 | valid_rmsle: 0.00069 | valid_mae: 0.08434 | valid_rmse: 0.10761 | valid_mse: 0.01158 |  0:06:23s\n",
      "epoch 180| loss: 0.01372 | train_rmsle: 0.0006  | train_mae: 0.08367 | train_rmse: 0.10332 | train_mse: 0.01068 | valid_rmsle: 0.00077 | valid_mae: 0.09413 | valid_rmse: 0.11727 | valid_mse: 0.01375 |  0:06:26s\n",
      "epoch 181| loss: 0.01221 | train_rmsle: 0.00058 | train_mae: 0.07575 | train_rmse: 0.09634 | train_mse: 0.00928 | valid_rmsle: 0.00073 | valid_mae: 0.08576 | valid_rmse: 0.11101 | valid_mse: 0.01232 |  0:06:28s\n",
      "epoch 182| loss: 0.01191 | train_rmsle: 0.0008  | train_mae: 0.09499 | train_rmse: 0.11463 | train_mse: 0.01314 | valid_rmsle: 0.00099 | valid_mae: 0.10553 | valid_rmse: 0.12845 | valid_mse: 0.0165  |  0:06:30s\n",
      "epoch 183| loss: 0.01366 | train_rmsle: 0.00055 | train_mae: 0.07346 | train_rmse: 0.09354 | train_mse: 0.00875 | valid_rmsle: 0.00073 | valid_mae: 0.08536 | valid_rmse: 0.10956 | valid_mse: 0.012   |  0:06:32s\n",
      "epoch 184| loss: 0.01243 | train_rmsle: 0.00046 | train_mae: 0.07142 | train_rmse: 0.09033 | train_mse: 0.00816 | valid_rmsle: 0.00064 | valid_mae: 0.08338 | valid_rmse: 0.10642 | valid_mse: 0.01133 |  0:06:34s\n",
      "epoch 185| loss: 0.0117  | train_rmsle: 0.00044 | train_mae: 0.06654 | train_rmse: 0.08563 | train_mse: 0.00733 | valid_rmsle: 0.00062 | valid_mae: 0.07882 | valid_rmse: 0.10272 | valid_mse: 0.01055 |  0:06:36s\n",
      "epoch 186| loss: 0.01161 | train_rmsle: 0.00036 | train_mae: 0.06393 | train_rmse: 0.08208 | train_mse: 0.00674 | valid_rmsle: 0.00054 | valid_mae: 0.07568 | valid_rmse: 0.09896 | valid_mse: 0.00979 |  0:06:39s\n",
      "epoch 187| loss: 0.01082 | train_rmsle: 0.00035 | train_mae: 0.06102 | train_rmse: 0.07884 | train_mse: 0.00621 | valid_rmsle: 0.00052 | valid_mae: 0.07295 | valid_rmse: 0.09648 | valid_mse: 0.00931 |  0:06:41s\n",
      "epoch 188| loss: 0.01054 | train_rmsle: 0.00035 | train_mae: 0.0601  | train_rmse: 0.07778 | train_mse: 0.00605 | valid_rmsle: 0.00052 | valid_mae: 0.07184 | valid_rmse: 0.09497 | valid_mse: 0.00902 |  0:06:43s\n",
      "epoch 189| loss: 0.01205 | train_rmsle: 0.00042 | train_mae: 0.06897 | train_rmse: 0.08843 | train_mse: 0.00782 | valid_rmsle: 0.0006  | valid_mae: 0.07902 | valid_rmse: 0.10478 | valid_mse: 0.01098 |  0:06:45s\n",
      "epoch 190| loss: 0.01272 | train_rmsle: 0.00039 | train_mae: 0.06644 | train_rmse: 0.08448 | train_mse: 0.00714 | valid_rmsle: 0.00056 | valid_mae: 0.07835 | valid_rmse: 0.10062 | valid_mse: 0.01012 |  0:06:47s\n",
      "epoch 191| loss: 0.0117  | train_rmsle: 0.00075 | train_mae: 0.08895 | train_rmse: 0.10919 | train_mse: 0.01192 | valid_rmsle: 0.0009  | valid_mae: 0.09781 | valid_rmse: 0.12152 | valid_mse: 0.01477 |  0:06:49s\n",
      "epoch 192| loss: 0.01178 | train_rmsle: 0.0005  | train_mae: 0.07542 | train_rmse: 0.09463 | train_mse: 0.00896 | valid_rmsle: 0.00065 | valid_mae: 0.08477 | valid_rmse: 0.10812 | valid_mse: 0.01169 |  0:06:52s\n",
      "epoch 193| loss: 0.01171 | train_rmsle: 0.00037 | train_mae: 0.0627  | train_rmse: 0.08027 | train_mse: 0.00644 | valid_rmsle: 0.00052 | valid_mae: 0.07483 | valid_rmse: 0.09634 | valid_mse: 0.00928 |  0:06:54s\n",
      "epoch 194| loss: 0.01225 | train_rmsle: 0.00066 | train_mae: 0.07746 | train_rmse: 0.09851 | train_mse: 0.0097  | valid_rmsle: 0.00077 | valid_mae: 0.08675 | valid_rmse: 0.10958 | valid_mse: 0.01201 |  0:06:56s\n",
      "epoch 195| loss: 0.01205 | train_rmsle: 0.00052 | train_mae: 0.07839 | train_rmse: 0.09753 | train_mse: 0.00951 | valid_rmsle: 0.00065 | valid_mae: 0.08645 | valid_rmse: 0.10837 | valid_mse: 0.01174 |  0:06:58s\n",
      "epoch 196| loss: 0.01689 | train_rmsle: 0.00081 | train_mae: 0.09101 | train_rmse: 0.11287 | train_mse: 0.01274 | valid_rmsle: 0.00096 | valid_mae: 0.09865 | valid_rmse: 0.12486 | valid_mse: 0.01559 |  0:07:00s\n",
      "epoch 197| loss: 0.01631 | train_rmsle: 0.00054 | train_mae: 0.07556 | train_rmse: 0.09549 | train_mse: 0.00912 | valid_rmsle: 0.0007  | valid_mae: 0.08503 | valid_rmse: 0.10986 | valid_mse: 0.01207 |  0:07:02s\n",
      "epoch 198| loss: 0.01484 | train_rmsle: 0.0006  | train_mae: 0.08548 | train_rmse: 0.10439 | train_mse: 0.0109  | valid_rmsle: 0.00075 | valid_mae: 0.09459 | valid_rmse: 0.1158  | valid_mse: 0.01341 |  0:07:04s\n",
      "epoch 199| loss: 0.0131  | train_rmsle: 0.00061 | train_mae: 0.0804  | train_rmse: 0.09991 | train_mse: 0.00998 | valid_rmsle: 0.00078 | valid_mae: 0.08906 | valid_rmse: 0.11425 | valid_mse: 0.01305 |  0:07:07s\n",
      "epoch 200| loss: 0.01484 | train_rmsle: 0.00035 | train_mae: 0.06114 | train_rmse: 0.0787  | train_mse: 0.00619 | valid_rmsle: 0.00049 | valid_mae: 0.07093 | valid_rmse: 0.09299 | valid_mse: 0.00865 |  0:07:09s\n",
      "epoch 201| loss: 0.01353 | train_rmsle: 0.00118 | train_mae: 0.10041 | train_rmse: 0.12679 | train_mse: 0.01608 | valid_rmsle: 0.00135 | valid_mae: 0.1098  | valid_rmse: 0.13837 | valid_mse: 0.01915 |  0:07:11s\n",
      "epoch 202| loss: 0.01153 | train_rmsle: 0.00034 | train_mae: 0.05991 | train_rmse: 0.07771 | train_mse: 0.00604 | valid_rmsle: 0.00049 | valid_mae: 0.07092 | valid_rmse: 0.09283 | valid_mse: 0.00862 |  0:07:13s\n",
      "epoch 203| loss: 0.01149 | train_rmsle: 0.00034 | train_mae: 0.05948 | train_rmse: 0.07723 | train_mse: 0.00596 | valid_rmsle: 0.00049 | valid_mae: 0.07062 | valid_rmse: 0.09224 | valid_mse: 0.00851 |  0:07:15s\n",
      "epoch 204| loss: 0.01248 | train_rmsle: 0.00034 | train_mae: 0.05965 | train_rmse: 0.07672 | train_mse: 0.00589 | valid_rmsle: 0.0005  | valid_mae: 0.07116 | valid_rmse: 0.09289 | valid_mse: 0.00863 |  0:07:17s\n",
      "epoch 205| loss: 0.01183 | train_rmsle: 0.00057 | train_mae: 0.08489 | train_rmse: 0.10363 | train_mse: 0.01074 | valid_rmsle: 0.00073 | valid_mae: 0.09348 | valid_rmse: 0.11578 | valid_mse: 0.0134  |  0:07:20s\n",
      "epoch 206| loss: 0.01343 | train_rmsle: 0.0004  | train_mae: 0.06556 | train_rmse: 0.08379 | train_mse: 0.00702 | valid_rmsle: 0.00056 | valid_mae: 0.07558 | valid_rmse: 0.09902 | valid_mse: 0.00981 |  0:07:22s\n",
      "epoch 207| loss: 0.01234 | train_rmsle: 0.00046 | train_mae: 0.07198 | train_rmse: 0.08963 | train_mse: 0.00803 | valid_rmsle: 0.00061 | valid_mae: 0.08156 | valid_rmse: 0.10246 | valid_mse: 0.0105  |  0:07:24s\n",
      "epoch 208| loss: 0.01031 | train_rmsle: 0.0005  | train_mae: 0.06982 | train_rmse: 0.08827 | train_mse: 0.00779 | valid_rmsle: 0.00064 | valid_mae: 0.0785  | valid_rmse: 0.10039 | valid_mse: 0.01008 |  0:07:26s\n",
      "epoch 209| loss: 0.01086 | train_rmsle: 0.00042 | train_mae: 0.06922 | train_rmse: 0.08662 | train_mse: 0.0075  | valid_rmsle: 0.00055 | valid_mae: 0.07717 | valid_rmse: 0.09871 | valid_mse: 0.00974 |  0:07:28s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 203 and best_valid_mse = 0.00851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009798249498806961 RMSE: 0.09898610760509255 R2: 0.9566269249163133 MAE: 0.07300380915554663\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_5_0.01_210.pt.zip\n",
      "New best model: 512_8_5_0.01_210 with r2: 0.9566269249163133\n",
      "[21/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 23.87105| train_rmsle: 1.46931 | train_mae: 3.00112 | train_rmse: 3.0401  | train_mse: 9.2422  | valid_rmsle: 1.47335 | valid_mae: 3.0078  | valid_rmse: 3.0459  | valid_mse: 9.2775  |  0:00:01s\n",
      "epoch 1  | loss: 9.37664 | train_rmsle: 0.58366 | train_mae: 2.27296 | train_rmse: 2.32412 | train_mse: 5.40155 | valid_rmsle: 0.58901 | valid_mae: 2.28367 | valid_rmse: 2.33394 | valid_mse: 5.44726 |  0:00:03s\n",
      "epoch 2  | loss: 3.23701 | train_rmsle: 0.19684 | train_mae: 1.47679 | train_rmse: 1.56402 | train_mse: 2.44617 | valid_rmsle: 0.20211 | valid_mae: 1.49607 | valid_rmse: 1.58277 | valid_mse: 2.50516 |  0:00:06s\n",
      "epoch 3  | loss: 1.64334 | train_rmsle: 0.13566 | train_mae: 1.24751 | train_rmse: 1.34824 | train_mse: 1.81775 | valid_rmsle: 0.14039 | valid_mae: 1.26658 | valid_rmse: 1.36929 | valid_mse: 1.87495 |  0:00:08s\n",
      "epoch 4  | loss: 0.95577 | train_rmsle: 0.08449 | train_mae: 1.02033 | train_rmse: 1.11957 | train_mse: 1.25344 | valid_rmsle: 0.08667 | valid_mae: 1.03124 | valid_rmse: 1.13343 | valid_mse: 1.28467 |  0:00:10s\n",
      "epoch 5  | loss: 0.54314 | train_rmsle: 0.05601 | train_mae: 0.84774 | train_rmse: 0.94298 | train_mse: 0.88921 | valid_rmsle: 0.05663 | valid_mae: 0.85228 | valid_rmse: 0.9496  | valid_mse: 0.90174 |  0:00:12s\n",
      "epoch 6  | loss: 0.39209 | train_rmsle: 0.03465 | train_mae: 0.66669 | train_rmse: 0.76163 | train_mse: 0.58008 | valid_rmsle: 0.03501 | valid_mae: 0.66993 | valid_rmse: 0.76797 | valid_mse: 0.58978 |  0:00:14s\n",
      "epoch 7  | loss: 0.32665 | train_rmsle: 0.02515 | train_mae: 0.56484 | train_rmse: 0.65552 | train_mse: 0.42971 | valid_rmsle: 0.02522 | valid_mae: 0.56799 | valid_rmse: 0.66004 | valid_mse: 0.43565 |  0:00:16s\n",
      "epoch 8  | loss: 0.29269 | train_rmsle: 0.02366 | train_mae: 0.54703 | train_rmse: 0.63654 | train_mse: 0.40518 | valid_rmsle: 0.02366 | valid_mae: 0.54951 | valid_rmse: 0.64037 | valid_mse: 0.41007 |  0:00:19s\n",
      "epoch 9  | loss: 0.27782 | train_rmsle: 0.01856 | train_mae: 0.47465 | train_rmse: 0.56235 | train_mse: 0.31623 | valid_rmsle: 0.01833 | valid_mae: 0.47722 | valid_rmse: 0.5637  | valid_mse: 0.31776 |  0:00:21s\n",
      "epoch 10 | loss: 0.25865 | train_rmsle: 0.0177  | train_mae: 0.45994 | train_rmse: 0.5481  | train_mse: 0.30042 | valid_rmsle: 0.01752 | valid_mae: 0.46449 | valid_rmse: 0.55056 | valid_mse: 0.30311 |  0:00:23s\n",
      "epoch 11 | loss: 0.25482 | train_rmsle: 0.01807 | train_mae: 0.46626 | train_rmse: 0.55462 | train_mse: 0.3076  | valid_rmsle: 0.01792 | valid_mae: 0.47033 | valid_rmse: 0.55743 | valid_mse: 0.31073 |  0:00:25s\n",
      "epoch 12 | loss: 0.24327 | train_rmsle: 0.01711 | train_mae: 0.44936 | train_rmse: 0.53793 | train_mse: 0.28937 | valid_rmsle: 0.01675 | valid_mae: 0.45234 | valid_rmse: 0.53766 | valid_mse: 0.28908 |  0:00:27s\n",
      "epoch 13 | loss: 0.23802 | train_rmsle: 0.01787 | train_mae: 0.46242 | train_rmse: 0.55139 | train_mse: 0.30403 | valid_rmsle: 0.01771 | valid_mae: 0.4663  | valid_rmse: 0.55422 | valid_mse: 0.30716 |  0:00:29s\n",
      "epoch 14 | loss: 0.23799 | train_rmsle: 0.01767 | train_mae: 0.45975 | train_rmse: 0.5481  | train_mse: 0.30041 | valid_rmsle: 0.01751 | valid_mae: 0.46398 | valid_rmse: 0.55068 | valid_mse: 0.30325 |  0:00:32s\n",
      "epoch 15 | loss: 0.23697 | train_rmsle: 0.01761 | train_mae: 0.45921 | train_rmse: 0.54719 | train_mse: 0.29941 | valid_rmsle: 0.01739 | valid_mae: 0.46252 | valid_rmse: 0.54871 | valid_mse: 0.30109 |  0:00:33s\n",
      "epoch 16 | loss: 0.23191 | train_rmsle: 0.01649 | train_mae: 0.4388  | train_rmse: 0.52751 | train_mse: 0.27827 | valid_rmsle: 0.01624 | valid_mae: 0.44209 | valid_rmse: 0.52902 | valid_mse: 0.27986 |  0:00:35s\n",
      "epoch 17 | loss: 0.22973 | train_rmsle: 0.01504 | train_mae: 0.40922 | train_rmse: 0.49896 | train_mse: 0.24896 | valid_rmsle: 0.01473 | valid_mae: 0.41209 | valid_rmse: 0.49944 | valid_mse: 0.24944 |  0:00:37s\n",
      "epoch 18 | loss: 0.22745 | train_rmsle: 0.01471 | train_mae: 0.40235 | train_rmse: 0.49212 | train_mse: 0.24218 | valid_rmsle: 0.01432 | valid_mae: 0.40437 | valid_rmse: 0.4915  | valid_mse: 0.24157 |  0:00:39s\n",
      "epoch 19 | loss: 0.22743 | train_rmsle: 0.01486 | train_mae: 0.40558 | train_rmse: 0.49535 | train_mse: 0.24537 | valid_rmsle: 0.01473 | valid_mae: 0.41076 | valid_rmse: 0.49922 | valid_mse: 0.24922 |  0:00:41s\n",
      "epoch 20 | loss: 0.22173 | train_rmsle: 0.01505 | train_mae: 0.41119 | train_rmse: 0.49981 | train_mse: 0.24981 | valid_rmsle: 0.015   | valid_mae: 0.41673 | valid_rmse: 0.50477 | valid_mse: 0.25479 |  0:00:43s\n",
      "epoch 21 | loss: 0.22406 | train_rmsle: 0.01456 | train_mae: 0.39936 | train_rmse: 0.48903 | train_mse: 0.23915 | valid_rmsle: 0.01441 | valid_mae: 0.40593 | valid_rmse: 0.49219 | valid_mse: 0.24225 |  0:00:45s\n",
      "epoch 22 | loss: 0.2177  | train_rmsle: 0.01467 | train_mae: 0.40184 | train_rmse: 0.49171 | train_mse: 0.24178 | valid_rmsle: 0.01468 | valid_mae: 0.41047 | valid_rmse: 0.49734 | valid_mse: 0.24734 |  0:00:47s\n",
      "epoch 23 | loss: 0.21942 | train_rmsle: 0.01436 | train_mae: 0.39495 | train_rmse: 0.4851  | train_mse: 0.23532 | valid_rmsle: 0.0141  | valid_mae: 0.39971 | valid_rmse: 0.48644 | valid_mse: 0.23662 |  0:00:50s\n",
      "epoch 24 | loss: 0.22249 | train_rmsle: 0.01404 | train_mae: 0.3862  | train_rmse: 0.47747 | train_mse: 0.22798 | valid_rmsle: 0.01382 | valid_mae: 0.39325 | valid_rmse: 0.4793  | valid_mse: 0.22973 |  0:00:52s\n",
      "epoch 25 | loss: 0.22166 | train_rmsle: 0.0141  | train_mae: 0.38502 | train_rmse: 0.47752 | train_mse: 0.22802 | valid_rmsle: 0.01359 | valid_mae: 0.38754 | valid_rmse: 0.47484 | valid_mse: 0.22547 |  0:00:54s\n",
      "epoch 26 | loss: 0.21837 | train_rmsle: 0.01388 | train_mae: 0.3786  | train_rmse: 0.47235 | train_mse: 0.22312 | valid_rmsle: 0.01357 | valid_mae: 0.38464 | valid_rmse: 0.47326 | valid_mse: 0.22397 |  0:00:56s\n",
      "epoch 27 | loss: 0.21933 | train_rmsle: 0.01385 | train_mae: 0.38042 | train_rmse: 0.47284 | train_mse: 0.22358 | valid_rmsle: 0.01313 | valid_mae: 0.37931 | valid_rmse: 0.46611 | valid_mse: 0.21725 |  0:00:58s\n",
      "epoch 28 | loss: 0.21618 | train_rmsle: 0.01408 | train_mae: 0.38873 | train_rmse: 0.47951 | train_mse: 0.22993 | valid_rmsle: 0.01396 | valid_mae: 0.39475 | valid_rmse: 0.48367 | valid_mse: 0.23394 |  0:01:01s\n",
      "epoch 29 | loss: 0.21373 | train_rmsle: 0.01385 | train_mae: 0.37552 | train_rmse: 0.47099 | train_mse: 0.22184 | valid_rmsle: 0.01328 | valid_mae: 0.3786  | valid_rmse: 0.46743 | valid_mse: 0.21849 |  0:01:03s\n",
      "epoch 30 | loss: 0.21279 | train_rmsle: 0.01388 | train_mae: 0.36903 | train_rmse: 0.46864 | train_mse: 0.21962 | valid_rmsle: 0.01322 | valid_mae: 0.37126 | valid_rmse: 0.46307 | valid_mse: 0.21443 |  0:01:05s\n",
      "epoch 31 | loss: 0.21294 | train_rmsle: 0.01389 | train_mae: 0.37265 | train_rmse: 0.46993 | train_mse: 0.22083 | valid_rmsle: 0.0132  | valid_mae: 0.37207 | valid_rmse: 0.46414 | valid_mse: 0.21543 |  0:01:07s\n",
      "epoch 32 | loss: 0.21274 | train_rmsle: 0.01369 | train_mae: 0.37372 | train_rmse: 0.46804 | train_mse: 0.21906 | valid_rmsle: 0.01315 | valid_mae: 0.37599 | valid_rmse: 0.46502 | valid_mse: 0.21625 |  0:01:09s\n",
      "epoch 33 | loss: 0.21139 | train_rmsle: 0.0137  | train_mae: 0.3784  | train_rmse: 0.47004 | train_mse: 0.22094 | valid_rmsle: 0.01331 | valid_mae: 0.37949 | valid_rmse: 0.46903 | valid_mse: 0.21999 |  0:01:11s\n",
      "epoch 34 | loss: 0.21515 | train_rmsle: 0.01412 | train_mae: 0.39308 | train_rmse: 0.48193 | train_mse: 0.23225 | valid_rmsle: 0.01418 | valid_mae: 0.40326 | valid_rmse: 0.48881 | valid_mse: 0.23893 |  0:01:13s\n",
      "epoch 35 | loss: 0.21029 | train_rmsle: 0.01365 | train_mae: 0.38122 | train_rmse: 0.47079 | train_mse: 0.22164 | valid_rmsle: 0.01368 | valid_mae: 0.38901 | valid_rmse: 0.47677 | valid_mse: 0.22731 |  0:01:16s\n",
      "epoch 36 | loss: 0.20944 | train_rmsle: 0.0136  | train_mae: 0.37429 | train_rmse: 0.46703 | train_mse: 0.21812 | valid_rmsle: 0.01373 | valid_mae: 0.38435 | valid_rmse: 0.47494 | valid_mse: 0.22557 |  0:01:18s\n",
      "epoch 37 | loss: 0.20952 | train_rmsle: 0.01367 | train_mae: 0.36881 | train_rmse: 0.46551 | train_mse: 0.2167  | valid_rmsle: 0.01352 | valid_mae: 0.37324 | valid_rmse: 0.46933 | valid_mse: 0.22027 |  0:01:20s\n",
      "epoch 38 | loss: 0.21083 | train_rmsle: 0.01346 | train_mae: 0.37106 | train_rmse: 0.46437 | train_mse: 0.21564 | valid_rmsle: 0.01333 | valid_mae: 0.37924 | valid_rmse: 0.46813 | valid_mse: 0.21914 |  0:01:22s\n",
      "epoch 39 | loss: 0.20835 | train_rmsle: 0.01347 | train_mae: 0.37112 | train_rmse: 0.46426 | train_mse: 0.21553 | valid_rmsle: 0.01337 | valid_mae: 0.37862 | valid_rmse: 0.46871 | valid_mse: 0.21969 |  0:01:24s\n",
      "epoch 40 | loss: 0.21063 | train_rmsle: 0.01342 | train_mae: 0.37238 | train_rmse: 0.46422 | train_mse: 0.2155  | valid_rmsle: 0.01347 | valid_mae: 0.37935 | valid_rmse: 0.47106 | valid_mse: 0.2219  |  0:01:26s\n",
      "epoch 41 | loss: 0.2056  | train_rmsle: 0.01336 | train_mae: 0.36758 | train_rmse: 0.46153 | train_mse: 0.21301 | valid_rmsle: 0.01328 | valid_mae: 0.37681 | valid_rmse: 0.4666  | valid_mse: 0.21771 |  0:01:28s\n",
      "epoch 42 | loss: 0.20512 | train_rmsle: 0.01342 | train_mae: 0.37453 | train_rmse: 0.46548 | train_mse: 0.21667 | valid_rmsle: 0.0135  | valid_mae: 0.38489 | valid_rmse: 0.4734  | valid_mse: 0.2241  |  0:01:31s\n",
      "epoch 43 | loss: 0.20514 | train_rmsle: 0.01332 | train_mae: 0.37252 | train_rmse: 0.46334 | train_mse: 0.21468 | valid_rmsle: 0.01333 | valid_mae: 0.38132 | valid_rmse: 0.46983 | valid_mse: 0.22074 |  0:01:33s\n",
      "epoch 44 | loss: 0.20477 | train_rmsle: 0.01336 | train_mae: 0.36869 | train_rmse: 0.46179 | train_mse: 0.21325 | valid_rmsle: 0.01332 | valid_mae: 0.37688 | valid_rmse: 0.4677  | valid_mse: 0.21875 |  0:01:35s\n",
      "epoch 45 | loss: 0.20601 | train_rmsle: 0.01332 | train_mae: 0.36436 | train_rmse: 0.45978 | train_mse: 0.2114  | valid_rmsle: 0.0131  | valid_mae: 0.36933 | valid_rmse: 0.46249 | valid_mse: 0.2139  |  0:01:37s\n",
      "epoch 46 | loss: 0.20401 | train_rmsle: 0.01339 | train_mae: 0.36471 | train_rmse: 0.46078 | train_mse: 0.21231 | valid_rmsle: 0.0132  | valid_mae: 0.37259 | valid_rmse: 0.46347 | valid_mse: 0.2148  |  0:01:39s\n",
      "epoch 47 | loss: 0.20373 | train_rmsle: 0.01322 | train_mae: 0.36794 | train_rmse: 0.46009 | train_mse: 0.21168 | valid_rmsle: 0.01296 | valid_mae: 0.37414 | valid_rmse: 0.4615  | valid_mse: 0.21298 |  0:01:41s\n",
      "epoch 48 | loss: 0.2023  | train_rmsle: 0.01312 | train_mae: 0.36525 | train_rmse: 0.45799 | train_mse: 0.20975 | valid_rmsle: 0.01307 | valid_mae: 0.3759  | valid_rmse: 0.4635  | valid_mse: 0.21483 |  0:01:44s\n",
      "epoch 49 | loss: 0.20077 | train_rmsle: 0.01312 | train_mae: 0.36203 | train_rmse: 0.45615 | train_mse: 0.20807 | valid_rmsle: 0.01296 | valid_mae: 0.37185 | valid_rmse: 0.46017 | valid_mse: 0.21175 |  0:01:46s\n",
      "epoch 50 | loss: 0.20252 | train_rmsle: 0.0131  | train_mae: 0.36498 | train_rmse: 0.45724 | train_mse: 0.20907 | valid_rmsle: 0.0131  | valid_mae: 0.37481 | valid_rmse: 0.46315 | valid_mse: 0.21451 |  0:01:48s\n",
      "epoch 51 | loss: 0.20178 | train_rmsle: 0.01301 | train_mae: 0.36115 | train_rmse: 0.45455 | train_mse: 0.20662 | valid_rmsle: 0.01313 | valid_mae: 0.37261 | valid_rmse: 0.46299 | valid_mse: 0.21436 |  0:01:50s\n",
      "epoch 52 | loss: 0.20091 | train_rmsle: 0.01301 | train_mae: 0.36363 | train_rmse: 0.45558 | train_mse: 0.20755 | valid_rmsle: 0.01306 | valid_mae: 0.37322 | valid_rmse: 0.46275 | valid_mse: 0.21413 |  0:01:52s\n",
      "epoch 53 | loss: 0.20146 | train_rmsle: 0.013   | train_mae: 0.35819 | train_rmse: 0.45296 | train_mse: 0.20517 | valid_rmsle: 0.01322 | valid_mae: 0.37243 | valid_rmse: 0.46428 | valid_mse: 0.21556 |  0:01:54s\n",
      "epoch 54 | loss: 0.20211 | train_rmsle: 0.01282 | train_mae: 0.35918 | train_rmse: 0.45141 | train_mse: 0.20377 | valid_rmsle: 0.01298 | valid_mae: 0.37122 | valid_rmse: 0.46127 | valid_mse: 0.21277 |  0:01:57s\n",
      "epoch 55 | loss: 0.19994 | train_rmsle: 0.01291 | train_mae: 0.35888 | train_rmse: 0.45211 | train_mse: 0.20441 | valid_rmsle: 0.01308 | valid_mae: 0.3685  | valid_rmse: 0.46191 | valid_mse: 0.21336 |  0:01:59s\n",
      "epoch 56 | loss: 0.19781 | train_rmsle: 0.01281 | train_mae: 0.35844 | train_rmse: 0.45084 | train_mse: 0.20326 | valid_rmsle: 0.01306 | valid_mae: 0.37136 | valid_rmse: 0.46218 | valid_mse: 0.21361 |  0:02:01s\n",
      "epoch 57 | loss: 0.19753 | train_rmsle: 0.01272 | train_mae: 0.36018 | train_rmse: 0.45058 | train_mse: 0.20302 | valid_rmsle: 0.01302 | valid_mae: 0.37183 | valid_rmse: 0.4621  | valid_mse: 0.21354 |  0:02:03s\n",
      "epoch 58 | loss: 0.19819 | train_rmsle: 0.01295 | train_mae: 0.35788 | train_rmse: 0.45231 | train_mse: 0.20459 | valid_rmsle: 0.013   | valid_mae: 0.36758 | valid_rmse: 0.45974 | valid_mse: 0.21136 |  0:02:05s\n",
      "epoch 59 | loss: 0.19582 | train_rmsle: 0.01278 | train_mae: 0.36029 | train_rmse: 0.45143 | train_mse: 0.20379 | valid_rmsle: 0.01291 | valid_mae: 0.36905 | valid_rmse: 0.46011 | valid_mse: 0.21171 |  0:02:07s\n",
      "epoch 60 | loss: 0.19712 | train_rmsle: 0.01298 | train_mae: 0.35828 | train_rmse: 0.4528  | train_mse: 0.20503 | valid_rmsle: 0.013   | valid_mae: 0.36626 | valid_rmse: 0.45924 | valid_mse: 0.2109  |  0:02:09s\n",
      "epoch 61 | loss: 0.19678 | train_rmsle: 0.01283 | train_mae: 0.35862 | train_rmse: 0.45145 | train_mse: 0.2038  | valid_rmsle: 0.0129  | valid_mae: 0.36825 | valid_rmse: 0.4589  | valid_mse: 0.21059 |  0:02:12s\n",
      "epoch 62 | loss: 0.19803 | train_rmsle: 0.0128  | train_mae: 0.35683 | train_rmse: 0.44998 | train_mse: 0.20248 | valid_rmsle: 0.01278 | valid_mae: 0.3645  | valid_rmse: 0.456   | valid_mse: 0.20794 |  0:02:14s\n",
      "epoch 63 | loss: 0.19616 | train_rmsle: 0.01283 | train_mae: 0.35558 | train_rmse: 0.44989 | train_mse: 0.2024  | valid_rmsle: 0.01302 | valid_mae: 0.36708 | valid_rmse: 0.45951 | valid_mse: 0.21115 |  0:02:16s\n",
      "epoch 64 | loss: 0.19716 | train_rmsle: 0.01281 | train_mae: 0.35846 | train_rmse: 0.45095 | train_mse: 0.20335 | valid_rmsle: 0.01297 | valid_mae: 0.36686 | valid_rmse: 0.45922 | valid_mse: 0.21088 |  0:02:18s\n",
      "epoch 65 | loss: 0.19869 | train_rmsle: 0.01274 | train_mae: 0.35741 | train_rmse: 0.44956 | train_mse: 0.2021  | valid_rmsle: 0.01305 | valid_mae: 0.3695  | valid_rmse: 0.46178 | valid_mse: 0.21324 |  0:02:20s\n",
      "epoch 66 | loss: 0.19705 | train_rmsle: 0.01257 | train_mae: 0.35729 | train_rmse: 0.44764 | train_mse: 0.20038 | valid_rmsle: 0.0129  | valid_mae: 0.36984 | valid_rmse: 0.45948 | valid_mse: 0.21112 |  0:02:22s\n",
      "epoch 67 | loss: 0.19452 | train_rmsle: 0.01281 | train_mae: 0.35337 | train_rmse: 0.44871 | train_mse: 0.20134 | valid_rmsle: 0.01316 | valid_mae: 0.36791 | valid_rmse: 0.46152 | valid_mse: 0.213   |  0:02:24s\n",
      "epoch 68 | loss: 0.19377 | train_rmsle: 0.01281 | train_mae: 0.35352 | train_rmse: 0.4487  | train_mse: 0.20133 | valid_rmsle: 0.01327 | valid_mae: 0.36904 | valid_rmse: 0.46315 | valid_mse: 0.21451 |  0:02:27s\n",
      "epoch 69 | loss: 0.19221 | train_rmsle: 0.0124  | train_mae: 0.35469 | train_rmse: 0.44461 | train_mse: 0.19768 | valid_rmsle: 0.01293 | valid_mae: 0.36958 | valid_rmse: 0.46021 | valid_mse: 0.21179 |  0:02:29s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 62 and best_valid_mse = 0.20794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.20373257517181387 RMSE: 0.45136745027949665 R2: 0.0981543916598715 MAE: 0.3559388069339075\n",
      "=====================================\n",
      "[22/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 23.87105| train_rmsle: 1.46931 | train_mae: 3.00112 | train_rmse: 3.0401  | train_mse: 9.2422  | valid_rmsle: 1.47335 | valid_mae: 3.0078  | valid_rmse: 3.0459  | valid_mse: 9.2775  |  0:00:01s\n",
      "epoch 1  | loss: 9.37664 | train_rmsle: 0.58366 | train_mae: 2.27296 | train_rmse: 2.32412 | train_mse: 5.40155 | valid_rmsle: 0.58901 | valid_mae: 2.28367 | valid_rmse: 2.33394 | valid_mse: 5.44726 |  0:00:03s\n",
      "epoch 2  | loss: 3.23701 | train_rmsle: 0.19684 | train_mae: 1.47679 | train_rmse: 1.56402 | train_mse: 2.44617 | valid_rmsle: 0.20211 | valid_mae: 1.49607 | valid_rmse: 1.58277 | valid_mse: 2.50516 |  0:00:04s\n",
      "epoch 3  | loss: 1.64334 | train_rmsle: 0.13566 | train_mae: 1.24751 | train_rmse: 1.34824 | train_mse: 1.81775 | valid_rmsle: 0.14039 | valid_mae: 1.26658 | valid_rmse: 1.36929 | valid_mse: 1.87495 |  0:00:06s\n",
      "epoch 4  | loss: 0.95577 | train_rmsle: 0.08449 | train_mae: 1.02033 | train_rmse: 1.11957 | train_mse: 1.25344 | valid_rmsle: 0.08667 | valid_mae: 1.03124 | valid_rmse: 1.13343 | valid_mse: 1.28467 |  0:00:08s\n",
      "epoch 5  | loss: 0.54314 | train_rmsle: 0.05601 | train_mae: 0.84774 | train_rmse: 0.94298 | train_mse: 0.88921 | valid_rmsle: 0.05663 | valid_mae: 0.85228 | valid_rmse: 0.9496  | valid_mse: 0.90174 |  0:00:10s\n",
      "epoch 6  | loss: 0.39209 | train_rmsle: 0.03465 | train_mae: 0.66669 | train_rmse: 0.76163 | train_mse: 0.58008 | valid_rmsle: 0.03501 | valid_mae: 0.66993 | valid_rmse: 0.76797 | valid_mse: 0.58978 |  0:00:12s\n",
      "epoch 7  | loss: 0.32665 | train_rmsle: 0.02515 | train_mae: 0.56484 | train_rmse: 0.65552 | train_mse: 0.42971 | valid_rmsle: 0.02522 | valid_mae: 0.56799 | valid_rmse: 0.66004 | valid_mse: 0.43565 |  0:00:14s\n",
      "epoch 8  | loss: 0.29269 | train_rmsle: 0.02366 | train_mae: 0.54703 | train_rmse: 0.63654 | train_mse: 0.40518 | valid_rmsle: 0.02366 | valid_mae: 0.54951 | valid_rmse: 0.64037 | valid_mse: 0.41007 |  0:00:16s\n",
      "epoch 9  | loss: 0.27782 | train_rmsle: 0.01856 | train_mae: 0.47465 | train_rmse: 0.56235 | train_mse: 0.31623 | valid_rmsle: 0.01833 | valid_mae: 0.47722 | valid_rmse: 0.5637  | valid_mse: 0.31776 |  0:00:18s\n",
      "epoch 10 | loss: 0.25865 | train_rmsle: 0.0177  | train_mae: 0.45994 | train_rmse: 0.5481  | train_mse: 0.30042 | valid_rmsle: 0.01752 | valid_mae: 0.46449 | valid_rmse: 0.55056 | valid_mse: 0.30311 |  0:00:20s\n",
      "epoch 11 | loss: 0.25482 | train_rmsle: 0.01807 | train_mae: 0.46626 | train_rmse: 0.55462 | train_mse: 0.3076  | valid_rmsle: 0.01792 | valid_mae: 0.47033 | valid_rmse: 0.55743 | valid_mse: 0.31073 |  0:00:23s\n",
      "epoch 12 | loss: 0.24327 | train_rmsle: 0.01711 | train_mae: 0.44936 | train_rmse: 0.53793 | train_mse: 0.28937 | valid_rmsle: 0.01675 | valid_mae: 0.45234 | valid_rmse: 0.53766 | valid_mse: 0.28908 |  0:00:25s\n",
      "epoch 13 | loss: 0.23802 | train_rmsle: 0.01787 | train_mae: 0.46242 | train_rmse: 0.55139 | train_mse: 0.30403 | valid_rmsle: 0.01771 | valid_mae: 0.4663  | valid_rmse: 0.55422 | valid_mse: 0.30716 |  0:00:27s\n",
      "epoch 14 | loss: 0.23799 | train_rmsle: 0.01767 | train_mae: 0.45975 | train_rmse: 0.5481  | train_mse: 0.30041 | valid_rmsle: 0.01751 | valid_mae: 0.46398 | valid_rmse: 0.55068 | valid_mse: 0.30325 |  0:00:29s\n",
      "epoch 15 | loss: 0.23697 | train_rmsle: 0.01761 | train_mae: 0.45921 | train_rmse: 0.54719 | train_mse: 0.29941 | valid_rmsle: 0.01739 | valid_mae: 0.46252 | valid_rmse: 0.54871 | valid_mse: 0.30109 |  0:00:31s\n",
      "epoch 16 | loss: 0.23191 | train_rmsle: 0.01649 | train_mae: 0.4388  | train_rmse: 0.52751 | train_mse: 0.27827 | valid_rmsle: 0.01624 | valid_mae: 0.44209 | valid_rmse: 0.52902 | valid_mse: 0.27986 |  0:00:33s\n",
      "epoch 17 | loss: 0.22973 | train_rmsle: 0.01504 | train_mae: 0.40922 | train_rmse: 0.49896 | train_mse: 0.24896 | valid_rmsle: 0.01473 | valid_mae: 0.41209 | valid_rmse: 0.49944 | valid_mse: 0.24944 |  0:00:35s\n",
      "epoch 18 | loss: 0.22745 | train_rmsle: 0.01471 | train_mae: 0.40235 | train_rmse: 0.49212 | train_mse: 0.24218 | valid_rmsle: 0.01432 | valid_mae: 0.40437 | valid_rmse: 0.4915  | valid_mse: 0.24157 |  0:00:38s\n",
      "epoch 19 | loss: 0.22743 | train_rmsle: 0.01486 | train_mae: 0.40558 | train_rmse: 0.49535 | train_mse: 0.24537 | valid_rmsle: 0.01473 | valid_mae: 0.41076 | valid_rmse: 0.49922 | valid_mse: 0.24922 |  0:00:40s\n",
      "epoch 20 | loss: 0.22173 | train_rmsle: 0.01505 | train_mae: 0.41119 | train_rmse: 0.49981 | train_mse: 0.24981 | valid_rmsle: 0.015   | valid_mae: 0.41673 | valid_rmse: 0.50477 | valid_mse: 0.25479 |  0:00:42s\n",
      "epoch 21 | loss: 0.22406 | train_rmsle: 0.01456 | train_mae: 0.39936 | train_rmse: 0.48903 | train_mse: 0.23915 | valid_rmsle: 0.01441 | valid_mae: 0.40593 | valid_rmse: 0.49219 | valid_mse: 0.24225 |  0:00:44s\n",
      "epoch 22 | loss: 0.2177  | train_rmsle: 0.01467 | train_mae: 0.40184 | train_rmse: 0.49171 | train_mse: 0.24178 | valid_rmsle: 0.01468 | valid_mae: 0.41047 | valid_rmse: 0.49734 | valid_mse: 0.24734 |  0:00:46s\n",
      "epoch 23 | loss: 0.21942 | train_rmsle: 0.01436 | train_mae: 0.39495 | train_rmse: 0.4851  | train_mse: 0.23532 | valid_rmsle: 0.0141  | valid_mae: 0.39971 | valid_rmse: 0.48644 | valid_mse: 0.23662 |  0:00:48s\n",
      "epoch 24 | loss: 0.22249 | train_rmsle: 0.01404 | train_mae: 0.3862  | train_rmse: 0.47747 | train_mse: 0.22798 | valid_rmsle: 0.01382 | valid_mae: 0.39325 | valid_rmse: 0.4793  | valid_mse: 0.22973 |  0:00:51s\n",
      "epoch 25 | loss: 0.22166 | train_rmsle: 0.0141  | train_mae: 0.38502 | train_rmse: 0.47752 | train_mse: 0.22802 | valid_rmsle: 0.01359 | valid_mae: 0.38754 | valid_rmse: 0.47484 | valid_mse: 0.22547 |  0:00:53s\n",
      "epoch 26 | loss: 0.21837 | train_rmsle: 0.01388 | train_mae: 0.3786  | train_rmse: 0.47235 | train_mse: 0.22312 | valid_rmsle: 0.01357 | valid_mae: 0.38464 | valid_rmse: 0.47326 | valid_mse: 0.22397 |  0:00:55s\n",
      "epoch 27 | loss: 0.21933 | train_rmsle: 0.01385 | train_mae: 0.38042 | train_rmse: 0.47284 | train_mse: 0.22358 | valid_rmsle: 0.01313 | valid_mae: 0.37931 | valid_rmse: 0.46611 | valid_mse: 0.21725 |  0:00:57s\n",
      "epoch 28 | loss: 0.21618 | train_rmsle: 0.01408 | train_mae: 0.38873 | train_rmse: 0.47951 | train_mse: 0.22993 | valid_rmsle: 0.01396 | valid_mae: 0.39475 | valid_rmse: 0.48367 | valid_mse: 0.23394 |  0:00:59s\n",
      "epoch 29 | loss: 0.21373 | train_rmsle: 0.01385 | train_mae: 0.37552 | train_rmse: 0.47099 | train_mse: 0.22184 | valid_rmsle: 0.01328 | valid_mae: 0.3786  | valid_rmse: 0.46743 | valid_mse: 0.21849 |  0:01:01s\n",
      "epoch 30 | loss: 0.21279 | train_rmsle: 0.01388 | train_mae: 0.36903 | train_rmse: 0.46864 | train_mse: 0.21962 | valid_rmsle: 0.01322 | valid_mae: 0.37126 | valid_rmse: 0.46307 | valid_mse: 0.21443 |  0:01:03s\n",
      "epoch 31 | loss: 0.21294 | train_rmsle: 0.01389 | train_mae: 0.37265 | train_rmse: 0.46993 | train_mse: 0.22083 | valid_rmsle: 0.0132  | valid_mae: 0.37207 | valid_rmse: 0.46414 | valid_mse: 0.21543 |  0:01:06s\n",
      "epoch 32 | loss: 0.21274 | train_rmsle: 0.01369 | train_mae: 0.37372 | train_rmse: 0.46804 | train_mse: 0.21906 | valid_rmsle: 0.01315 | valid_mae: 0.37599 | valid_rmse: 0.46502 | valid_mse: 0.21625 |  0:01:08s\n",
      "epoch 33 | loss: 0.21139 | train_rmsle: 0.0137  | train_mae: 0.3784  | train_rmse: 0.47004 | train_mse: 0.22094 | valid_rmsle: 0.01331 | valid_mae: 0.37949 | valid_rmse: 0.46903 | valid_mse: 0.21999 |  0:01:10s\n",
      "epoch 34 | loss: 0.21515 | train_rmsle: 0.01412 | train_mae: 0.39308 | train_rmse: 0.48193 | train_mse: 0.23225 | valid_rmsle: 0.01418 | valid_mae: 0.40326 | valid_rmse: 0.48881 | valid_mse: 0.23893 |  0:01:12s\n",
      "epoch 35 | loss: 0.21029 | train_rmsle: 0.01365 | train_mae: 0.38122 | train_rmse: 0.47079 | train_mse: 0.22164 | valid_rmsle: 0.01368 | valid_mae: 0.38901 | valid_rmse: 0.47677 | valid_mse: 0.22731 |  0:01:14s\n",
      "epoch 36 | loss: 0.20944 | train_rmsle: 0.0136  | train_mae: 0.37429 | train_rmse: 0.46703 | train_mse: 0.21812 | valid_rmsle: 0.01373 | valid_mae: 0.38435 | valid_rmse: 0.47494 | valid_mse: 0.22557 |  0:01:16s\n",
      "epoch 37 | loss: 0.20952 | train_rmsle: 0.01367 | train_mae: 0.36881 | train_rmse: 0.46551 | train_mse: 0.2167  | valid_rmsle: 0.01352 | valid_mae: 0.37324 | valid_rmse: 0.46933 | valid_mse: 0.22027 |  0:01:18s\n",
      "epoch 38 | loss: 0.21083 | train_rmsle: 0.01346 | train_mae: 0.37106 | train_rmse: 0.46437 | train_mse: 0.21564 | valid_rmsle: 0.01333 | valid_mae: 0.37924 | valid_rmse: 0.46813 | valid_mse: 0.21914 |  0:01:20s\n",
      "epoch 39 | loss: 0.20835 | train_rmsle: 0.01347 | train_mae: 0.37112 | train_rmse: 0.46426 | train_mse: 0.21553 | valid_rmsle: 0.01337 | valid_mae: 0.37862 | valid_rmse: 0.46871 | valid_mse: 0.21969 |  0:01:22s\n",
      "epoch 40 | loss: 0.21063 | train_rmsle: 0.01342 | train_mae: 0.37238 | train_rmse: 0.46422 | train_mse: 0.2155  | valid_rmsle: 0.01347 | valid_mae: 0.37935 | valid_rmse: 0.47106 | valid_mse: 0.2219  |  0:01:24s\n",
      "epoch 41 | loss: 0.2056  | train_rmsle: 0.01336 | train_mae: 0.36758 | train_rmse: 0.46153 | train_mse: 0.21301 | valid_rmsle: 0.01328 | valid_mae: 0.37681 | valid_rmse: 0.4666  | valid_mse: 0.21771 |  0:01:26s\n",
      "epoch 42 | loss: 0.20512 | train_rmsle: 0.01342 | train_mae: 0.37453 | train_rmse: 0.46548 | train_mse: 0.21667 | valid_rmsle: 0.0135  | valid_mae: 0.38489 | valid_rmse: 0.4734  | valid_mse: 0.2241  |  0:01:28s\n",
      "epoch 43 | loss: 0.20514 | train_rmsle: 0.01332 | train_mae: 0.37252 | train_rmse: 0.46334 | train_mse: 0.21468 | valid_rmsle: 0.01333 | valid_mae: 0.38132 | valid_rmse: 0.46983 | valid_mse: 0.22074 |  0:01:30s\n",
      "epoch 44 | loss: 0.20477 | train_rmsle: 0.01336 | train_mae: 0.36869 | train_rmse: 0.46179 | train_mse: 0.21325 | valid_rmsle: 0.01332 | valid_mae: 0.37688 | valid_rmse: 0.4677  | valid_mse: 0.21875 |  0:01:32s\n",
      "epoch 45 | loss: 0.20601 | train_rmsle: 0.01332 | train_mae: 0.36436 | train_rmse: 0.45978 | train_mse: 0.2114  | valid_rmsle: 0.0131  | valid_mae: 0.36933 | valid_rmse: 0.46249 | valid_mse: 0.2139  |  0:01:34s\n",
      "epoch 46 | loss: 0.20401 | train_rmsle: 0.01339 | train_mae: 0.36471 | train_rmse: 0.46078 | train_mse: 0.21231 | valid_rmsle: 0.0132  | valid_mae: 0.37259 | valid_rmse: 0.46347 | valid_mse: 0.2148  |  0:01:36s\n",
      "epoch 47 | loss: 0.20373 | train_rmsle: 0.01322 | train_mae: 0.36794 | train_rmse: 0.46009 | train_mse: 0.21168 | valid_rmsle: 0.01296 | valid_mae: 0.37414 | valid_rmse: 0.4615  | valid_mse: 0.21298 |  0:01:38s\n",
      "epoch 48 | loss: 0.2023  | train_rmsle: 0.01312 | train_mae: 0.36525 | train_rmse: 0.45799 | train_mse: 0.20975 | valid_rmsle: 0.01307 | valid_mae: 0.3759  | valid_rmse: 0.4635  | valid_mse: 0.21483 |  0:01:41s\n",
      "epoch 49 | loss: 0.20077 | train_rmsle: 0.01312 | train_mae: 0.36203 | train_rmse: 0.45615 | train_mse: 0.20807 | valid_rmsle: 0.01296 | valid_mae: 0.37185 | valid_rmse: 0.46017 | valid_mse: 0.21175 |  0:01:43s\n",
      "epoch 50 | loss: 0.20252 | train_rmsle: 0.0131  | train_mae: 0.36498 | train_rmse: 0.45724 | train_mse: 0.20907 | valid_rmsle: 0.0131  | valid_mae: 0.37481 | valid_rmse: 0.46315 | valid_mse: 0.21451 |  0:01:45s\n",
      "epoch 51 | loss: 0.20178 | train_rmsle: 0.01301 | train_mae: 0.36115 | train_rmse: 0.45455 | train_mse: 0.20662 | valid_rmsle: 0.01313 | valid_mae: 0.37261 | valid_rmse: 0.46299 | valid_mse: 0.21436 |  0:01:47s\n",
      "epoch 52 | loss: 0.20091 | train_rmsle: 0.01301 | train_mae: 0.36363 | train_rmse: 0.45558 | train_mse: 0.20755 | valid_rmsle: 0.01306 | valid_mae: 0.37322 | valid_rmse: 0.46275 | valid_mse: 0.21413 |  0:01:49s\n",
      "epoch 53 | loss: 0.20146 | train_rmsle: 0.013   | train_mae: 0.35819 | train_rmse: 0.45296 | train_mse: 0.20517 | valid_rmsle: 0.01322 | valid_mae: 0.37243 | valid_rmse: 0.46428 | valid_mse: 0.21556 |  0:01:51s\n",
      "epoch 54 | loss: 0.20211 | train_rmsle: 0.01282 | train_mae: 0.35918 | train_rmse: 0.45141 | train_mse: 0.20377 | valid_rmsle: 0.01298 | valid_mae: 0.37122 | valid_rmse: 0.46127 | valid_mse: 0.21277 |  0:01:54s\n",
      "epoch 55 | loss: 0.19994 | train_rmsle: 0.01291 | train_mae: 0.35888 | train_rmse: 0.45211 | train_mse: 0.20441 | valid_rmsle: 0.01308 | valid_mae: 0.3685  | valid_rmse: 0.46191 | valid_mse: 0.21336 |  0:01:56s\n",
      "epoch 56 | loss: 0.19781 | train_rmsle: 0.01281 | train_mae: 0.35844 | train_rmse: 0.45084 | train_mse: 0.20326 | valid_rmsle: 0.01306 | valid_mae: 0.37136 | valid_rmse: 0.46218 | valid_mse: 0.21361 |  0:01:58s\n",
      "epoch 57 | loss: 0.19753 | train_rmsle: 0.01272 | train_mae: 0.36018 | train_rmse: 0.45058 | train_mse: 0.20302 | valid_rmsle: 0.01302 | valid_mae: 0.37183 | valid_rmse: 0.4621  | valid_mse: 0.21354 |  0:02:00s\n",
      "epoch 58 | loss: 0.19819 | train_rmsle: 0.01295 | train_mae: 0.35788 | train_rmse: 0.45231 | train_mse: 0.20459 | valid_rmsle: 0.013   | valid_mae: 0.36758 | valid_rmse: 0.45974 | valid_mse: 0.21136 |  0:02:02s\n",
      "epoch 59 | loss: 0.19582 | train_rmsle: 0.01278 | train_mae: 0.36029 | train_rmse: 0.45143 | train_mse: 0.20379 | valid_rmsle: 0.01291 | valid_mae: 0.36905 | valid_rmse: 0.46011 | valid_mse: 0.21171 |  0:02:04s\n",
      "epoch 60 | loss: 0.19712 | train_rmsle: 0.01298 | train_mae: 0.35828 | train_rmse: 0.4528  | train_mse: 0.20503 | valid_rmsle: 0.013   | valid_mae: 0.36626 | valid_rmse: 0.45924 | valid_mse: 0.2109  |  0:02:07s\n",
      "epoch 61 | loss: 0.19678 | train_rmsle: 0.01283 | train_mae: 0.35862 | train_rmse: 0.45145 | train_mse: 0.2038  | valid_rmsle: 0.0129  | valid_mae: 0.36825 | valid_rmse: 0.4589  | valid_mse: 0.21059 |  0:02:09s\n",
      "epoch 62 | loss: 0.19803 | train_rmsle: 0.0128  | train_mae: 0.35683 | train_rmse: 0.44998 | train_mse: 0.20248 | valid_rmsle: 0.01278 | valid_mae: 0.3645  | valid_rmse: 0.456   | valid_mse: 0.20794 |  0:02:11s\n",
      "epoch 63 | loss: 0.19616 | train_rmsle: 0.01283 | train_mae: 0.35558 | train_rmse: 0.44989 | train_mse: 0.2024  | valid_rmsle: 0.01302 | valid_mae: 0.36708 | valid_rmse: 0.45951 | valid_mse: 0.21115 |  0:02:13s\n",
      "epoch 64 | loss: 0.19716 | train_rmsle: 0.01281 | train_mae: 0.35846 | train_rmse: 0.45095 | train_mse: 0.20335 | valid_rmsle: 0.01297 | valid_mae: 0.36686 | valid_rmse: 0.45922 | valid_mse: 0.21088 |  0:02:15s\n",
      "epoch 65 | loss: 0.19869 | train_rmsle: 0.01274 | train_mae: 0.35741 | train_rmse: 0.44956 | train_mse: 0.2021  | valid_rmsle: 0.01305 | valid_mae: 0.3695  | valid_rmse: 0.46178 | valid_mse: 0.21324 |  0:02:17s\n",
      "epoch 66 | loss: 0.19705 | train_rmsle: 0.01257 | train_mae: 0.35729 | train_rmse: 0.44764 | train_mse: 0.20038 | valid_rmsle: 0.0129  | valid_mae: 0.36984 | valid_rmse: 0.45948 | valid_mse: 0.21112 |  0:02:19s\n",
      "epoch 67 | loss: 0.19452 | train_rmsle: 0.01281 | train_mae: 0.35337 | train_rmse: 0.44871 | train_mse: 0.20134 | valid_rmsle: 0.01316 | valid_mae: 0.36791 | valid_rmse: 0.46152 | valid_mse: 0.213   |  0:02:21s\n",
      "epoch 68 | loss: 0.19377 | train_rmsle: 0.01281 | train_mae: 0.35352 | train_rmse: 0.4487  | train_mse: 0.20133 | valid_rmsle: 0.01327 | valid_mae: 0.36904 | valid_rmse: 0.46315 | valid_mse: 0.21451 |  0:02:24s\n",
      "epoch 69 | loss: 0.19221 | train_rmsle: 0.0124  | train_mae: 0.35469 | train_rmse: 0.44461 | train_mse: 0.19768 | valid_rmsle: 0.01293 | valid_mae: 0.36958 | valid_rmse: 0.46021 | valid_mse: 0.21179 |  0:02:26s\n",
      "epoch 70 | loss: 0.1937  | train_rmsle: 0.01278 | train_mae: 0.35152 | train_rmse: 0.44769 | train_mse: 0.20042 | valid_rmsle: 0.01292 | valid_mae: 0.36269 | valid_rmse: 0.45646 | valid_mse: 0.20836 |  0:02:28s\n",
      "epoch 71 | loss: 0.18942 | train_rmsle: 0.01243 | train_mae: 0.35224 | train_rmse: 0.44393 | train_mse: 0.19707 | valid_rmsle: 0.01275 | valid_mae: 0.36622 | valid_rmse: 0.45634 | valid_mse: 0.20825 |  0:02:30s\n",
      "epoch 72 | loss: 0.19268 | train_rmsle: 0.0123  | train_mae: 0.35363 | train_rmse: 0.44293 | train_mse: 0.19619 | valid_rmsle: 0.01266 | valid_mae: 0.36828 | valid_rmse: 0.45602 | valid_mse: 0.20795 |  0:02:32s\n",
      "epoch 73 | loss: 0.19138 | train_rmsle: 0.01245 | train_mae: 0.35175 | train_rmse: 0.44359 | train_mse: 0.19677 | valid_rmsle: 0.0126  | valid_mae: 0.36395 | valid_rmse: 0.45334 | valid_mse: 0.20552 |  0:02:34s\n",
      "epoch 74 | loss: 0.19108 | train_rmsle: 0.01232 | train_mae: 0.35417 | train_rmse: 0.4433  | train_mse: 0.19651 | valid_rmsle: 0.01252 | valid_mae: 0.36738 | valid_rmse: 0.45397 | valid_mse: 0.20609 |  0:02:37s\n",
      "epoch 75 | loss: 0.19228 | train_rmsle: 0.01222 | train_mae: 0.35337 | train_rmse: 0.44164 | train_mse: 0.19505 | valid_rmsle: 0.01248 | valid_mae: 0.36816 | valid_rmse: 0.45296 | valid_mse: 0.20518 |  0:02:39s\n",
      "epoch 76 | loss: 0.18984 | train_rmsle: 0.01223 | train_mae: 0.3536  | train_rmse: 0.44245 | train_mse: 0.19576 | valid_rmsle: 0.0123  | valid_mae: 0.36607 | valid_rmse: 0.45051 | valid_mse: 0.20296 |  0:02:41s\n",
      "epoch 77 | loss: 0.18969 | train_rmsle: 0.01225 | train_mae: 0.35257 | train_rmse: 0.44228 | train_mse: 0.19561 | valid_rmsle: 0.0124  | valid_mae: 0.3668  | valid_rmse: 0.45168 | valid_mse: 0.20402 |  0:02:43s\n",
      "epoch 78 | loss: 0.18784 | train_rmsle: 0.01209 | train_mae: 0.35153 | train_rmse: 0.43969 | train_mse: 0.19333 | valid_rmsle: 0.01232 | valid_mae: 0.3643  | valid_rmse: 0.45029 | valid_mse: 0.20276 |  0:02:45s\n",
      "epoch 79 | loss: 0.18744 | train_rmsle: 0.01198 | train_mae: 0.35265 | train_rmse: 0.43949 | train_mse: 0.19315 | valid_rmsle: 0.0125  | valid_mae: 0.36877 | valid_rmse: 0.45512 | valid_mse: 0.20713 |  0:02:47s\n",
      "epoch 80 | loss: 0.18728 | train_rmsle: 0.01199 | train_mae: 0.34738 | train_rmse: 0.43679 | train_mse: 0.19079 | valid_rmsle: 0.01238 | valid_mae: 0.36274 | valid_rmse: 0.45049 | valid_mse: 0.20294 |  0:02:50s\n",
      "epoch 81 | loss: 0.18812 | train_rmsle: 0.0119  | train_mae: 0.34759 | train_rmse: 0.4357  | train_mse: 0.18983 | valid_rmsle: 0.01247 | valid_mae: 0.36406 | valid_rmse: 0.45207 | valid_mse: 0.20437 |  0:02:52s\n",
      "epoch 82 | loss: 0.18684 | train_rmsle: 0.01188 | train_mae: 0.35057 | train_rmse: 0.43713 | train_mse: 0.19108 | valid_rmsle: 0.01236 | valid_mae: 0.36352 | valid_rmse: 0.45097 | valid_mse: 0.20337 |  0:02:54s\n",
      "epoch 83 | loss: 0.18482 | train_rmsle: 0.01183 | train_mae: 0.34862 | train_rmse: 0.43552 | train_mse: 0.18967 | valid_rmsle: 0.01231 | valid_mae: 0.36272 | valid_rmse: 0.45018 | valid_mse: 0.20266 |  0:02:56s\n",
      "epoch 84 | loss: 0.18364 | train_rmsle: 0.01165 | train_mae: 0.34751 | train_rmse: 0.43293 | train_mse: 0.18743 | valid_rmsle: 0.01214 | valid_mae: 0.35805 | valid_rmse: 0.4465  | valid_mse: 0.19936 |  0:02:58s\n",
      "epoch 85 | loss: 0.18338 | train_rmsle: 0.01157 | train_mae: 0.3443  | train_rmse: 0.43048 | train_mse: 0.18531 | valid_rmsle: 0.01209 | valid_mae: 0.35916 | valid_rmse: 0.44521 | valid_mse: 0.19821 |  0:03:00s\n",
      "epoch 86 | loss: 0.18067 | train_rmsle: 0.01142 | train_mae: 0.34168 | train_rmse: 0.42789 | train_mse: 0.18309 | valid_rmsle: 0.01207 | valid_mae: 0.35887 | valid_rmse: 0.44516 | valid_mse: 0.19817 |  0:03:01s\n",
      "epoch 87 | loss: 0.18006 | train_rmsle: 0.01149 | train_mae: 0.33813 | train_rmse: 0.42646 | train_mse: 0.18187 | valid_rmsle: 0.01222 | valid_mae: 0.3566  | valid_rmse: 0.44553 | valid_mse: 0.1985  |  0:03:03s\n",
      "epoch 88 | loss: 0.17813 | train_rmsle: 0.01147 | train_mae: 0.33949 | train_rmse: 0.42662 | train_mse: 0.18201 | valid_rmsle: 0.01235 | valid_mae: 0.36034 | valid_rmse: 0.44921 | valid_mse: 0.20179 |  0:03:05s\n",
      "epoch 89 | loss: 0.17835 | train_rmsle: 0.01119 | train_mae: 0.33821 | train_rmse: 0.42327 | train_mse: 0.17916 | valid_rmsle: 0.01206 | valid_mae: 0.35873 | valid_rmse: 0.44542 | valid_mse: 0.1984  |  0:03:07s\n",
      "epoch 90 | loss: 0.17774 | train_rmsle: 0.01116 | train_mae: 0.33621 | train_rmse: 0.42198 | train_mse: 0.17807 | valid_rmsle: 0.01229 | valid_mae: 0.35975 | valid_rmse: 0.449   | valid_mse: 0.2016  |  0:03:09s\n",
      "epoch 91 | loss: 0.1755  | train_rmsle: 0.01119 | train_mae: 0.33491 | train_rmse: 0.42156 | train_mse: 0.17771 | valid_rmsle: 0.01238 | valid_mae: 0.35953 | valid_rmse: 0.44938 | valid_mse: 0.20195 |  0:03:11s\n",
      "epoch 92 | loss: 0.17473 | train_rmsle: 0.01115 | train_mae: 0.33331 | train_rmse: 0.42051 | train_mse: 0.17683 | valid_rmsle: 0.01254 | valid_mae: 0.36154 | valid_rmse: 0.45249 | valid_mse: 0.20475 |  0:03:13s\n",
      "epoch 93 | loss: 0.17499 | train_rmsle: 0.01082 | train_mae: 0.33114 | train_rmse: 0.41612 | train_mse: 0.17315 | valid_rmsle: 0.01232 | valid_mae: 0.36293 | valid_rmse: 0.45042 | valid_mse: 0.20288 |  0:03:15s\n",
      "epoch 94 | loss: 0.17284 | train_rmsle: 0.01109 | train_mae: 0.3311  | train_rmse: 0.41872 | train_mse: 0.17532 | valid_rmsle: 0.01247 | valid_mae: 0.35997 | valid_rmse: 0.45071 | valid_mse: 0.20314 |  0:03:18s\n",
      "epoch 95 | loss: 0.17163 | train_rmsle: 0.01075 | train_mae: 0.32879 | train_rmse: 0.4142  | train_mse: 0.17156 | valid_rmsle: 0.01226 | valid_mae: 0.35691 | valid_rmse: 0.4479  | valid_mse: 0.20062 |  0:03:20s\n",
      "epoch 96 | loss: 0.17241 | train_rmsle: 0.0106  | train_mae: 0.331   | train_rmse: 0.41392 | train_mse: 0.17133 | valid_rmsle: 0.0122  | valid_mae: 0.35988 | valid_rmse: 0.44894 | valid_mse: 0.20154 |  0:03:22s\n",
      "epoch 97 | loss: 0.16968 | train_rmsle: 0.01065 | train_mae: 0.32775 | train_rmse: 0.41272 | train_mse: 0.17033 | valid_rmsle: 0.01214 | valid_mae: 0.35741 | valid_rmse: 0.44653 | valid_mse: 0.19939 |  0:03:23s\n",
      "epoch 98 | loss: 0.16835 | train_rmsle: 0.01049 | train_mae: 0.32542 | train_rmse: 0.40991 | train_mse: 0.16803 | valid_rmsle: 0.01222 | valid_mae: 0.35764 | valid_rmse: 0.44823 | valid_mse: 0.20091 |  0:03:25s\n",
      "epoch 99 | loss: 0.16564 | train_rmsle: 0.01054 | train_mae: 0.3227  | train_rmse: 0.40872 | train_mse: 0.16705 | valid_rmsle: 0.0124  | valid_mae: 0.35627 | valid_rmse: 0.4498  | valid_mse: 0.20232 |  0:03:27s\n",
      "epoch 100| loss: 0.16447 | train_rmsle: 0.01012 | train_mae: 0.32081 | train_rmse: 0.40297 | train_mse: 0.16239 | valid_rmsle: 0.01211 | valid_mae: 0.35782 | valid_rmse: 0.4467  | valid_mse: 0.19954 |  0:03:29s\n",
      "epoch 101| loss: 0.16329 | train_rmsle: 0.0103  | train_mae: 0.31993 | train_rmse: 0.4048  | train_mse: 0.16386 | valid_rmsle: 0.01236 | valid_mae: 0.35649 | valid_rmse: 0.45034 | valid_mse: 0.2028  |  0:03:31s\n",
      "epoch 102| loss: 0.16374 | train_rmsle: 0.00999 | train_mae: 0.31605 | train_rmse: 0.39962 | train_mse: 0.15969 | valid_rmsle: 0.0123  | valid_mae: 0.3573  | valid_rmse: 0.44947 | valid_mse: 0.20202 |  0:03:33s\n",
      "epoch 103| loss: 0.16037 | train_rmsle: 0.00971 | train_mae: 0.31293 | train_rmse: 0.39485 | train_mse: 0.15591 | valid_rmsle: 0.01228 | valid_mae: 0.35699 | valid_rmse: 0.44957 | valid_mse: 0.20211 |  0:03:35s\n",
      "epoch 104| loss: 0.15922 | train_rmsle: 0.00965 | train_mae: 0.31143 | train_rmse: 0.39352 | train_mse: 0.15486 | valid_rmsle: 0.01223 | valid_mae: 0.35575 | valid_rmse: 0.44807 | valid_mse: 0.20076 |  0:03:37s\n",
      "epoch 105| loss: 0.15818 | train_rmsle: 0.0095  | train_mae: 0.31053 | train_rmse: 0.39198 | train_mse: 0.15365 | valid_rmsle: 0.01231 | valid_mae: 0.35956 | valid_rmse: 0.45134 | valid_mse: 0.20371 |  0:03:40s\n",
      "epoch 106| loss: 0.15689 | train_rmsle: 0.00945 | train_mae: 0.30732 | train_rmse: 0.38944 | train_mse: 0.15166 | valid_rmsle: 0.01221 | valid_mae: 0.3558  | valid_rmse: 0.44809 | valid_mse: 0.20078 |  0:03:42s\n",
      "\n",
      "Early stopping occurred at epoch 106 with best_epoch = 86 and best_valid_mse = 0.19817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.20005528598113087 RMSE: 0.44727540283490985 R2: 0.11443233397919528 MAE: 0.35543614762657344\n",
      "=====================================\n",
      "[23/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 23.87105| train_rmsle: 1.46931 | train_mae: 3.00112 | train_rmse: 3.0401  | train_mse: 9.2422  | valid_rmsle: 1.47335 | valid_mae: 3.0078  | valid_rmse: 3.0459  | valid_mse: 9.2775  |  0:00:02s\n",
      "epoch 1  | loss: 9.37664 | train_rmsle: 0.58366 | train_mae: 2.27296 | train_rmse: 2.32412 | train_mse: 5.40155 | valid_rmsle: 0.58901 | valid_mae: 2.28367 | valid_rmse: 2.33394 | valid_mse: 5.44726 |  0:00:04s\n",
      "epoch 2  | loss: 3.23701 | train_rmsle: 0.19684 | train_mae: 1.47679 | train_rmse: 1.56402 | train_mse: 2.44617 | valid_rmsle: 0.20211 | valid_mae: 1.49607 | valid_rmse: 1.58277 | valid_mse: 2.50516 |  0:00:06s\n",
      "epoch 3  | loss: 1.64334 | train_rmsle: 0.13566 | train_mae: 1.24751 | train_rmse: 1.34824 | train_mse: 1.81775 | valid_rmsle: 0.14039 | valid_mae: 1.26658 | valid_rmse: 1.36929 | valid_mse: 1.87495 |  0:00:08s\n",
      "epoch 4  | loss: 0.95577 | train_rmsle: 0.08449 | train_mae: 1.02033 | train_rmse: 1.11957 | train_mse: 1.25344 | valid_rmsle: 0.08667 | valid_mae: 1.03124 | valid_rmse: 1.13343 | valid_mse: 1.28467 |  0:00:11s\n",
      "epoch 5  | loss: 0.54314 | train_rmsle: 0.05601 | train_mae: 0.84774 | train_rmse: 0.94298 | train_mse: 0.88921 | valid_rmsle: 0.05663 | valid_mae: 0.85228 | valid_rmse: 0.9496  | valid_mse: 0.90174 |  0:00:13s\n",
      "epoch 6  | loss: 0.39209 | train_rmsle: 0.03465 | train_mae: 0.66669 | train_rmse: 0.76163 | train_mse: 0.58008 | valid_rmsle: 0.03501 | valid_mae: 0.66993 | valid_rmse: 0.76797 | valid_mse: 0.58978 |  0:00:15s\n",
      "epoch 7  | loss: 0.32665 | train_rmsle: 0.02515 | train_mae: 0.56484 | train_rmse: 0.65552 | train_mse: 0.42971 | valid_rmsle: 0.02522 | valid_mae: 0.56799 | valid_rmse: 0.66004 | valid_mse: 0.43565 |  0:00:17s\n",
      "epoch 8  | loss: 0.29269 | train_rmsle: 0.02366 | train_mae: 0.54703 | train_rmse: 0.63654 | train_mse: 0.40518 | valid_rmsle: 0.02366 | valid_mae: 0.54951 | valid_rmse: 0.64037 | valid_mse: 0.41007 |  0:00:19s\n",
      "epoch 9  | loss: 0.27782 | train_rmsle: 0.01856 | train_mae: 0.47465 | train_rmse: 0.56235 | train_mse: 0.31623 | valid_rmsle: 0.01833 | valid_mae: 0.47722 | valid_rmse: 0.5637  | valid_mse: 0.31776 |  0:00:22s\n",
      "epoch 10 | loss: 0.25865 | train_rmsle: 0.0177  | train_mae: 0.45994 | train_rmse: 0.5481  | train_mse: 0.30042 | valid_rmsle: 0.01752 | valid_mae: 0.46449 | valid_rmse: 0.55056 | valid_mse: 0.30311 |  0:00:24s\n",
      "epoch 11 | loss: 0.25482 | train_rmsle: 0.01807 | train_mae: 0.46626 | train_rmse: 0.55462 | train_mse: 0.3076  | valid_rmsle: 0.01792 | valid_mae: 0.47033 | valid_rmse: 0.55743 | valid_mse: 0.31073 |  0:00:26s\n",
      "epoch 12 | loss: 0.24327 | train_rmsle: 0.01711 | train_mae: 0.44936 | train_rmse: 0.53793 | train_mse: 0.28937 | valid_rmsle: 0.01675 | valid_mae: 0.45234 | valid_rmse: 0.53766 | valid_mse: 0.28908 |  0:00:28s\n",
      "epoch 13 | loss: 0.23802 | train_rmsle: 0.01787 | train_mae: 0.46242 | train_rmse: 0.55139 | train_mse: 0.30403 | valid_rmsle: 0.01771 | valid_mae: 0.4663  | valid_rmse: 0.55422 | valid_mse: 0.30716 |  0:00:30s\n",
      "epoch 14 | loss: 0.23799 | train_rmsle: 0.01767 | train_mae: 0.45975 | train_rmse: 0.5481  | train_mse: 0.30041 | valid_rmsle: 0.01751 | valid_mae: 0.46398 | valid_rmse: 0.55068 | valid_mse: 0.30325 |  0:00:33s\n",
      "epoch 15 | loss: 0.23697 | train_rmsle: 0.01761 | train_mae: 0.45921 | train_rmse: 0.54719 | train_mse: 0.29941 | valid_rmsle: 0.01739 | valid_mae: 0.46252 | valid_rmse: 0.54871 | valid_mse: 0.30109 |  0:00:35s\n",
      "epoch 16 | loss: 0.23191 | train_rmsle: 0.01649 | train_mae: 0.4388  | train_rmse: 0.52751 | train_mse: 0.27827 | valid_rmsle: 0.01624 | valid_mae: 0.44209 | valid_rmse: 0.52902 | valid_mse: 0.27986 |  0:00:37s\n",
      "epoch 17 | loss: 0.22973 | train_rmsle: 0.01504 | train_mae: 0.40922 | train_rmse: 0.49896 | train_mse: 0.24896 | valid_rmsle: 0.01473 | valid_mae: 0.41209 | valid_rmse: 0.49944 | valid_mse: 0.24944 |  0:00:39s\n",
      "epoch 18 | loss: 0.22745 | train_rmsle: 0.01471 | train_mae: 0.40235 | train_rmse: 0.49212 | train_mse: 0.24218 | valid_rmsle: 0.01432 | valid_mae: 0.40437 | valid_rmse: 0.4915  | valid_mse: 0.24157 |  0:00:41s\n",
      "epoch 19 | loss: 0.22743 | train_rmsle: 0.01486 | train_mae: 0.40558 | train_rmse: 0.49535 | train_mse: 0.24537 | valid_rmsle: 0.01473 | valid_mae: 0.41076 | valid_rmse: 0.49922 | valid_mse: 0.24922 |  0:00:43s\n",
      "epoch 20 | loss: 0.22173 | train_rmsle: 0.01505 | train_mae: 0.41119 | train_rmse: 0.49981 | train_mse: 0.24981 | valid_rmsle: 0.015   | valid_mae: 0.41673 | valid_rmse: 0.50477 | valid_mse: 0.25479 |  0:00:45s\n",
      "epoch 21 | loss: 0.22406 | train_rmsle: 0.01456 | train_mae: 0.39936 | train_rmse: 0.48903 | train_mse: 0.23915 | valid_rmsle: 0.01441 | valid_mae: 0.40593 | valid_rmse: 0.49219 | valid_mse: 0.24225 |  0:00:48s\n",
      "epoch 22 | loss: 0.2177  | train_rmsle: 0.01467 | train_mae: 0.40184 | train_rmse: 0.49171 | train_mse: 0.24178 | valid_rmsle: 0.01468 | valid_mae: 0.41047 | valid_rmse: 0.49734 | valid_mse: 0.24734 |  0:00:50s\n",
      "epoch 23 | loss: 0.21942 | train_rmsle: 0.01436 | train_mae: 0.39495 | train_rmse: 0.4851  | train_mse: 0.23532 | valid_rmsle: 0.0141  | valid_mae: 0.39971 | valid_rmse: 0.48644 | valid_mse: 0.23662 |  0:00:52s\n",
      "epoch 24 | loss: 0.22249 | train_rmsle: 0.01404 | train_mae: 0.3862  | train_rmse: 0.47747 | train_mse: 0.22798 | valid_rmsle: 0.01382 | valid_mae: 0.39325 | valid_rmse: 0.4793  | valid_mse: 0.22973 |  0:00:54s\n",
      "epoch 25 | loss: 0.22166 | train_rmsle: 0.0141  | train_mae: 0.38502 | train_rmse: 0.47752 | train_mse: 0.22802 | valid_rmsle: 0.01359 | valid_mae: 0.38754 | valid_rmse: 0.47484 | valid_mse: 0.22547 |  0:00:56s\n",
      "epoch 26 | loss: 0.21837 | train_rmsle: 0.01388 | train_mae: 0.3786  | train_rmse: 0.47235 | train_mse: 0.22312 | valid_rmsle: 0.01357 | valid_mae: 0.38464 | valid_rmse: 0.47326 | valid_mse: 0.22397 |  0:00:58s\n",
      "epoch 27 | loss: 0.21933 | train_rmsle: 0.01385 | train_mae: 0.38042 | train_rmse: 0.47284 | train_mse: 0.22358 | valid_rmsle: 0.01313 | valid_mae: 0.37931 | valid_rmse: 0.46611 | valid_mse: 0.21725 |  0:01:00s\n",
      "epoch 28 | loss: 0.21618 | train_rmsle: 0.01408 | train_mae: 0.38873 | train_rmse: 0.47951 | train_mse: 0.22993 | valid_rmsle: 0.01396 | valid_mae: 0.39475 | valid_rmse: 0.48367 | valid_mse: 0.23394 |  0:01:02s\n",
      "epoch 29 | loss: 0.21373 | train_rmsle: 0.01385 | train_mae: 0.37552 | train_rmse: 0.47099 | train_mse: 0.22184 | valid_rmsle: 0.01328 | valid_mae: 0.3786  | valid_rmse: 0.46743 | valid_mse: 0.21849 |  0:01:04s\n",
      "epoch 30 | loss: 0.21279 | train_rmsle: 0.01388 | train_mae: 0.36903 | train_rmse: 0.46864 | train_mse: 0.21962 | valid_rmsle: 0.01322 | valid_mae: 0.37126 | valid_rmse: 0.46307 | valid_mse: 0.21443 |  0:01:06s\n",
      "epoch 31 | loss: 0.21294 | train_rmsle: 0.01389 | train_mae: 0.37265 | train_rmse: 0.46993 | train_mse: 0.22083 | valid_rmsle: 0.0132  | valid_mae: 0.37207 | valid_rmse: 0.46414 | valid_mse: 0.21543 |  0:01:08s\n",
      "epoch 32 | loss: 0.21274 | train_rmsle: 0.01369 | train_mae: 0.37372 | train_rmse: 0.46804 | train_mse: 0.21906 | valid_rmsle: 0.01315 | valid_mae: 0.37599 | valid_rmse: 0.46502 | valid_mse: 0.21625 |  0:01:10s\n",
      "epoch 33 | loss: 0.21139 | train_rmsle: 0.0137  | train_mae: 0.3784  | train_rmse: 0.47004 | train_mse: 0.22094 | valid_rmsle: 0.01331 | valid_mae: 0.37949 | valid_rmse: 0.46903 | valid_mse: 0.21999 |  0:01:12s\n",
      "epoch 34 | loss: 0.21515 | train_rmsle: 0.01412 | train_mae: 0.39308 | train_rmse: 0.48193 | train_mse: 0.23225 | valid_rmsle: 0.01418 | valid_mae: 0.40326 | valid_rmse: 0.48881 | valid_mse: 0.23893 |  0:01:14s\n",
      "epoch 35 | loss: 0.21029 | train_rmsle: 0.01365 | train_mae: 0.38122 | train_rmse: 0.47079 | train_mse: 0.22164 | valid_rmsle: 0.01368 | valid_mae: 0.38901 | valid_rmse: 0.47677 | valid_mse: 0.22731 |  0:01:16s\n",
      "epoch 36 | loss: 0.20944 | train_rmsle: 0.0136  | train_mae: 0.37429 | train_rmse: 0.46703 | train_mse: 0.21812 | valid_rmsle: 0.01373 | valid_mae: 0.38435 | valid_rmse: 0.47494 | valid_mse: 0.22557 |  0:01:18s\n",
      "epoch 37 | loss: 0.20952 | train_rmsle: 0.01367 | train_mae: 0.36881 | train_rmse: 0.46551 | train_mse: 0.2167  | valid_rmsle: 0.01352 | valid_mae: 0.37324 | valid_rmse: 0.46933 | valid_mse: 0.22027 |  0:01:20s\n",
      "epoch 38 | loss: 0.21083 | train_rmsle: 0.01346 | train_mae: 0.37106 | train_rmse: 0.46437 | train_mse: 0.21564 | valid_rmsle: 0.01333 | valid_mae: 0.37924 | valid_rmse: 0.46813 | valid_mse: 0.21914 |  0:01:22s\n",
      "epoch 39 | loss: 0.20835 | train_rmsle: 0.01347 | train_mae: 0.37112 | train_rmse: 0.46426 | train_mse: 0.21553 | valid_rmsle: 0.01337 | valid_mae: 0.37862 | valid_rmse: 0.46871 | valid_mse: 0.21969 |  0:01:24s\n",
      "epoch 40 | loss: 0.21063 | train_rmsle: 0.01342 | train_mae: 0.37238 | train_rmse: 0.46422 | train_mse: 0.2155  | valid_rmsle: 0.01347 | valid_mae: 0.37935 | valid_rmse: 0.47106 | valid_mse: 0.2219  |  0:01:26s\n",
      "epoch 41 | loss: 0.2056  | train_rmsle: 0.01336 | train_mae: 0.36758 | train_rmse: 0.46153 | train_mse: 0.21301 | valid_rmsle: 0.01328 | valid_mae: 0.37681 | valid_rmse: 0.4666  | valid_mse: 0.21771 |  0:01:28s\n",
      "epoch 42 | loss: 0.20512 | train_rmsle: 0.01342 | train_mae: 0.37453 | train_rmse: 0.46548 | train_mse: 0.21667 | valid_rmsle: 0.0135  | valid_mae: 0.38489 | valid_rmse: 0.4734  | valid_mse: 0.2241  |  0:01:30s\n",
      "epoch 43 | loss: 0.20514 | train_rmsle: 0.01332 | train_mae: 0.37252 | train_rmse: 0.46334 | train_mse: 0.21468 | valid_rmsle: 0.01333 | valid_mae: 0.38132 | valid_rmse: 0.46983 | valid_mse: 0.22074 |  0:01:32s\n",
      "epoch 44 | loss: 0.20477 | train_rmsle: 0.01336 | train_mae: 0.36869 | train_rmse: 0.46179 | train_mse: 0.21325 | valid_rmsle: 0.01332 | valid_mae: 0.37688 | valid_rmse: 0.4677  | valid_mse: 0.21875 |  0:01:34s\n",
      "epoch 45 | loss: 0.20601 | train_rmsle: 0.01332 | train_mae: 0.36436 | train_rmse: 0.45978 | train_mse: 0.2114  | valid_rmsle: 0.0131  | valid_mae: 0.36933 | valid_rmse: 0.46249 | valid_mse: 0.2139  |  0:01:36s\n",
      "epoch 46 | loss: 0.20401 | train_rmsle: 0.01339 | train_mae: 0.36471 | train_rmse: 0.46078 | train_mse: 0.21231 | valid_rmsle: 0.0132  | valid_mae: 0.37259 | valid_rmse: 0.46347 | valid_mse: 0.2148  |  0:01:38s\n",
      "epoch 47 | loss: 0.20373 | train_rmsle: 0.01322 | train_mae: 0.36794 | train_rmse: 0.46009 | train_mse: 0.21168 | valid_rmsle: 0.01296 | valid_mae: 0.37414 | valid_rmse: 0.4615  | valid_mse: 0.21298 |  0:01:40s\n",
      "epoch 48 | loss: 0.2023  | train_rmsle: 0.01312 | train_mae: 0.36525 | train_rmse: 0.45799 | train_mse: 0.20975 | valid_rmsle: 0.01307 | valid_mae: 0.3759  | valid_rmse: 0.4635  | valid_mse: 0.21483 |  0:01:43s\n",
      "epoch 49 | loss: 0.20077 | train_rmsle: 0.01312 | train_mae: 0.36203 | train_rmse: 0.45615 | train_mse: 0.20807 | valid_rmsle: 0.01296 | valid_mae: 0.37185 | valid_rmse: 0.46017 | valid_mse: 0.21175 |  0:01:45s\n",
      "epoch 50 | loss: 0.20252 | train_rmsle: 0.0131  | train_mae: 0.36498 | train_rmse: 0.45724 | train_mse: 0.20907 | valid_rmsle: 0.0131  | valid_mae: 0.37481 | valid_rmse: 0.46315 | valid_mse: 0.21451 |  0:01:47s\n",
      "epoch 51 | loss: 0.20178 | train_rmsle: 0.01301 | train_mae: 0.36115 | train_rmse: 0.45455 | train_mse: 0.20662 | valid_rmsle: 0.01313 | valid_mae: 0.37261 | valid_rmse: 0.46299 | valid_mse: 0.21436 |  0:01:49s\n",
      "epoch 52 | loss: 0.20091 | train_rmsle: 0.01301 | train_mae: 0.36363 | train_rmse: 0.45558 | train_mse: 0.20755 | valid_rmsle: 0.01306 | valid_mae: 0.37322 | valid_rmse: 0.46275 | valid_mse: 0.21413 |  0:01:51s\n",
      "epoch 53 | loss: 0.20146 | train_rmsle: 0.013   | train_mae: 0.35819 | train_rmse: 0.45296 | train_mse: 0.20517 | valid_rmsle: 0.01322 | valid_mae: 0.37243 | valid_rmse: 0.46428 | valid_mse: 0.21556 |  0:01:53s\n",
      "epoch 54 | loss: 0.20211 | train_rmsle: 0.01282 | train_mae: 0.35918 | train_rmse: 0.45141 | train_mse: 0.20377 | valid_rmsle: 0.01298 | valid_mae: 0.37122 | valid_rmse: 0.46127 | valid_mse: 0.21277 |  0:01:56s\n",
      "epoch 55 | loss: 0.19994 | train_rmsle: 0.01291 | train_mae: 0.35888 | train_rmse: 0.45211 | train_mse: 0.20441 | valid_rmsle: 0.01308 | valid_mae: 0.3685  | valid_rmse: 0.46191 | valid_mse: 0.21336 |  0:01:58s\n",
      "epoch 56 | loss: 0.19781 | train_rmsle: 0.01281 | train_mae: 0.35844 | train_rmse: 0.45084 | train_mse: 0.20326 | valid_rmsle: 0.01306 | valid_mae: 0.37136 | valid_rmse: 0.46218 | valid_mse: 0.21361 |  0:02:00s\n",
      "epoch 57 | loss: 0.19753 | train_rmsle: 0.01272 | train_mae: 0.36018 | train_rmse: 0.45058 | train_mse: 0.20302 | valid_rmsle: 0.01302 | valid_mae: 0.37183 | valid_rmse: 0.4621  | valid_mse: 0.21354 |  0:02:02s\n",
      "epoch 58 | loss: 0.19819 | train_rmsle: 0.01295 | train_mae: 0.35788 | train_rmse: 0.45231 | train_mse: 0.20459 | valid_rmsle: 0.013   | valid_mae: 0.36758 | valid_rmse: 0.45974 | valid_mse: 0.21136 |  0:02:04s\n",
      "epoch 59 | loss: 0.19582 | train_rmsle: 0.01278 | train_mae: 0.36029 | train_rmse: 0.45143 | train_mse: 0.20379 | valid_rmsle: 0.01291 | valid_mae: 0.36905 | valid_rmse: 0.46011 | valid_mse: 0.21171 |  0:02:06s\n",
      "epoch 60 | loss: 0.19712 | train_rmsle: 0.01298 | train_mae: 0.35828 | train_rmse: 0.4528  | train_mse: 0.20503 | valid_rmsle: 0.013   | valid_mae: 0.36626 | valid_rmse: 0.45924 | valid_mse: 0.2109  |  0:02:08s\n",
      "epoch 61 | loss: 0.19678 | train_rmsle: 0.01283 | train_mae: 0.35862 | train_rmse: 0.45145 | train_mse: 0.2038  | valid_rmsle: 0.0129  | valid_mae: 0.36825 | valid_rmse: 0.4589  | valid_mse: 0.21059 |  0:02:11s\n",
      "epoch 62 | loss: 0.19803 | train_rmsle: 0.0128  | train_mae: 0.35683 | train_rmse: 0.44998 | train_mse: 0.20248 | valid_rmsle: 0.01278 | valid_mae: 0.3645  | valid_rmse: 0.456   | valid_mse: 0.20794 |  0:02:13s\n",
      "epoch 63 | loss: 0.19616 | train_rmsle: 0.01283 | train_mae: 0.35558 | train_rmse: 0.44989 | train_mse: 0.2024  | valid_rmsle: 0.01302 | valid_mae: 0.36708 | valid_rmse: 0.45951 | valid_mse: 0.21115 |  0:02:15s\n",
      "epoch 64 | loss: 0.19716 | train_rmsle: 0.01281 | train_mae: 0.35846 | train_rmse: 0.45095 | train_mse: 0.20335 | valid_rmsle: 0.01297 | valid_mae: 0.36686 | valid_rmse: 0.45922 | valid_mse: 0.21088 |  0:02:17s\n",
      "epoch 65 | loss: 0.19869 | train_rmsle: 0.01274 | train_mae: 0.35741 | train_rmse: 0.44956 | train_mse: 0.2021  | valid_rmsle: 0.01305 | valid_mae: 0.3695  | valid_rmse: 0.46178 | valid_mse: 0.21324 |  0:02:19s\n",
      "epoch 66 | loss: 0.19705 | train_rmsle: 0.01257 | train_mae: 0.35729 | train_rmse: 0.44764 | train_mse: 0.20038 | valid_rmsle: 0.0129  | valid_mae: 0.36984 | valid_rmse: 0.45948 | valid_mse: 0.21112 |  0:02:21s\n",
      "epoch 67 | loss: 0.19452 | train_rmsle: 0.01281 | train_mae: 0.35337 | train_rmse: 0.44871 | train_mse: 0.20134 | valid_rmsle: 0.01316 | valid_mae: 0.36791 | valid_rmse: 0.46152 | valid_mse: 0.213   |  0:02:24s\n",
      "epoch 68 | loss: 0.19377 | train_rmsle: 0.01281 | train_mae: 0.35352 | train_rmse: 0.4487  | train_mse: 0.20133 | valid_rmsle: 0.01327 | valid_mae: 0.36904 | valid_rmse: 0.46315 | valid_mse: 0.21451 |  0:02:26s\n",
      "epoch 69 | loss: 0.19221 | train_rmsle: 0.0124  | train_mae: 0.35469 | train_rmse: 0.44461 | train_mse: 0.19768 | valid_rmsle: 0.01293 | valid_mae: 0.36958 | valid_rmse: 0.46021 | valid_mse: 0.21179 |  0:02:28s\n",
      "epoch 70 | loss: 0.1937  | train_rmsle: 0.01278 | train_mae: 0.35152 | train_rmse: 0.44769 | train_mse: 0.20042 | valid_rmsle: 0.01292 | valid_mae: 0.36269 | valid_rmse: 0.45646 | valid_mse: 0.20836 |  0:02:30s\n",
      "epoch 71 | loss: 0.18942 | train_rmsle: 0.01243 | train_mae: 0.35224 | train_rmse: 0.44393 | train_mse: 0.19707 | valid_rmsle: 0.01275 | valid_mae: 0.36622 | valid_rmse: 0.45634 | valid_mse: 0.20825 |  0:02:32s\n",
      "epoch 72 | loss: 0.19268 | train_rmsle: 0.0123  | train_mae: 0.35363 | train_rmse: 0.44293 | train_mse: 0.19619 | valid_rmsle: 0.01266 | valid_mae: 0.36828 | valid_rmse: 0.45602 | valid_mse: 0.20795 |  0:02:34s\n",
      "epoch 73 | loss: 0.19138 | train_rmsle: 0.01245 | train_mae: 0.35175 | train_rmse: 0.44359 | train_mse: 0.19677 | valid_rmsle: 0.0126  | valid_mae: 0.36395 | valid_rmse: 0.45334 | valid_mse: 0.20552 |  0:02:37s\n",
      "epoch 74 | loss: 0.19108 | train_rmsle: 0.01232 | train_mae: 0.35417 | train_rmse: 0.4433  | train_mse: 0.19651 | valid_rmsle: 0.01252 | valid_mae: 0.36738 | valid_rmse: 0.45397 | valid_mse: 0.20609 |  0:02:39s\n",
      "epoch 75 | loss: 0.19228 | train_rmsle: 0.01222 | train_mae: 0.35337 | train_rmse: 0.44164 | train_mse: 0.19505 | valid_rmsle: 0.01248 | valid_mae: 0.36816 | valid_rmse: 0.45296 | valid_mse: 0.20518 |  0:02:41s\n",
      "epoch 76 | loss: 0.18984 | train_rmsle: 0.01223 | train_mae: 0.3536  | train_rmse: 0.44245 | train_mse: 0.19576 | valid_rmsle: 0.0123  | valid_mae: 0.36607 | valid_rmse: 0.45051 | valid_mse: 0.20296 |  0:02:43s\n",
      "epoch 77 | loss: 0.18969 | train_rmsle: 0.01225 | train_mae: 0.35257 | train_rmse: 0.44228 | train_mse: 0.19561 | valid_rmsle: 0.0124  | valid_mae: 0.3668  | valid_rmse: 0.45168 | valid_mse: 0.20402 |  0:02:45s\n",
      "epoch 78 | loss: 0.18784 | train_rmsle: 0.01209 | train_mae: 0.35153 | train_rmse: 0.43969 | train_mse: 0.19333 | valid_rmsle: 0.01232 | valid_mae: 0.3643  | valid_rmse: 0.45029 | valid_mse: 0.20276 |  0:02:47s\n",
      "epoch 79 | loss: 0.18744 | train_rmsle: 0.01198 | train_mae: 0.35265 | train_rmse: 0.43949 | train_mse: 0.19315 | valid_rmsle: 0.0125  | valid_mae: 0.36877 | valid_rmse: 0.45512 | valid_mse: 0.20713 |  0:02:50s\n",
      "epoch 80 | loss: 0.18728 | train_rmsle: 0.01199 | train_mae: 0.34738 | train_rmse: 0.43679 | train_mse: 0.19079 | valid_rmsle: 0.01238 | valid_mae: 0.36274 | valid_rmse: 0.45049 | valid_mse: 0.20294 |  0:02:52s\n",
      "epoch 81 | loss: 0.18812 | train_rmsle: 0.0119  | train_mae: 0.34759 | train_rmse: 0.4357  | train_mse: 0.18983 | valid_rmsle: 0.01247 | valid_mae: 0.36406 | valid_rmse: 0.45207 | valid_mse: 0.20437 |  0:02:54s\n",
      "epoch 82 | loss: 0.18684 | train_rmsle: 0.01188 | train_mae: 0.35057 | train_rmse: 0.43713 | train_mse: 0.19108 | valid_rmsle: 0.01236 | valid_mae: 0.36352 | valid_rmse: 0.45097 | valid_mse: 0.20337 |  0:02:56s\n",
      "epoch 83 | loss: 0.18482 | train_rmsle: 0.01183 | train_mae: 0.34862 | train_rmse: 0.43552 | train_mse: 0.18967 | valid_rmsle: 0.01231 | valid_mae: 0.36272 | valid_rmse: 0.45018 | valid_mse: 0.20266 |  0:02:58s\n",
      "epoch 84 | loss: 0.18364 | train_rmsle: 0.01165 | train_mae: 0.34751 | train_rmse: 0.43293 | train_mse: 0.18743 | valid_rmsle: 0.01214 | valid_mae: 0.35805 | valid_rmse: 0.4465  | valid_mse: 0.19936 |  0:03:01s\n",
      "epoch 85 | loss: 0.18338 | train_rmsle: 0.01157 | train_mae: 0.3443  | train_rmse: 0.43048 | train_mse: 0.18531 | valid_rmsle: 0.01209 | valid_mae: 0.35916 | valid_rmse: 0.44521 | valid_mse: 0.19821 |  0:03:03s\n",
      "epoch 86 | loss: 0.18067 | train_rmsle: 0.01142 | train_mae: 0.34168 | train_rmse: 0.42789 | train_mse: 0.18309 | valid_rmsle: 0.01207 | valid_mae: 0.35887 | valid_rmse: 0.44516 | valid_mse: 0.19817 |  0:03:05s\n",
      "epoch 87 | loss: 0.18006 | train_rmsle: 0.01149 | train_mae: 0.33813 | train_rmse: 0.42646 | train_mse: 0.18187 | valid_rmsle: 0.01222 | valid_mae: 0.3566  | valid_rmse: 0.44553 | valid_mse: 0.1985  |  0:03:07s\n",
      "epoch 88 | loss: 0.17813 | train_rmsle: 0.01147 | train_mae: 0.33949 | train_rmse: 0.42662 | train_mse: 0.18201 | valid_rmsle: 0.01235 | valid_mae: 0.36034 | valid_rmse: 0.44921 | valid_mse: 0.20179 |  0:03:09s\n",
      "epoch 89 | loss: 0.17835 | train_rmsle: 0.01119 | train_mae: 0.33821 | train_rmse: 0.42327 | train_mse: 0.17916 | valid_rmsle: 0.01206 | valid_mae: 0.35873 | valid_rmse: 0.44542 | valid_mse: 0.1984  |  0:03:11s\n",
      "epoch 90 | loss: 0.17774 | train_rmsle: 0.01116 | train_mae: 0.33621 | train_rmse: 0.42198 | train_mse: 0.17807 | valid_rmsle: 0.01229 | valid_mae: 0.35975 | valid_rmse: 0.449   | valid_mse: 0.2016  |  0:03:14s\n",
      "epoch 91 | loss: 0.1755  | train_rmsle: 0.01119 | train_mae: 0.33491 | train_rmse: 0.42156 | train_mse: 0.17771 | valid_rmsle: 0.01238 | valid_mae: 0.35953 | valid_rmse: 0.44938 | valid_mse: 0.20195 |  0:03:16s\n",
      "epoch 92 | loss: 0.17473 | train_rmsle: 0.01115 | train_mae: 0.33331 | train_rmse: 0.42051 | train_mse: 0.17683 | valid_rmsle: 0.01254 | valid_mae: 0.36154 | valid_rmse: 0.45249 | valid_mse: 0.20475 |  0:03:18s\n",
      "epoch 93 | loss: 0.17499 | train_rmsle: 0.01082 | train_mae: 0.33114 | train_rmse: 0.41612 | train_mse: 0.17315 | valid_rmsle: 0.01232 | valid_mae: 0.36293 | valid_rmse: 0.45042 | valid_mse: 0.20288 |  0:03:20s\n",
      "epoch 94 | loss: 0.17284 | train_rmsle: 0.01109 | train_mae: 0.3311  | train_rmse: 0.41872 | train_mse: 0.17532 | valid_rmsle: 0.01247 | valid_mae: 0.35997 | valid_rmse: 0.45071 | valid_mse: 0.20314 |  0:03:22s\n",
      "epoch 95 | loss: 0.17163 | train_rmsle: 0.01075 | train_mae: 0.32879 | train_rmse: 0.4142  | train_mse: 0.17156 | valid_rmsle: 0.01226 | valid_mae: 0.35691 | valid_rmse: 0.4479  | valid_mse: 0.20062 |  0:03:24s\n",
      "epoch 96 | loss: 0.17241 | train_rmsle: 0.0106  | train_mae: 0.331   | train_rmse: 0.41392 | train_mse: 0.17133 | valid_rmsle: 0.0122  | valid_mae: 0.35988 | valid_rmse: 0.44894 | valid_mse: 0.20154 |  0:03:26s\n",
      "epoch 97 | loss: 0.16968 | train_rmsle: 0.01065 | train_mae: 0.32775 | train_rmse: 0.41272 | train_mse: 0.17033 | valid_rmsle: 0.01214 | valid_mae: 0.35741 | valid_rmse: 0.44653 | valid_mse: 0.19939 |  0:03:28s\n",
      "epoch 98 | loss: 0.16835 | train_rmsle: 0.01049 | train_mae: 0.32542 | train_rmse: 0.40991 | train_mse: 0.16803 | valid_rmsle: 0.01222 | valid_mae: 0.35764 | valid_rmse: 0.44823 | valid_mse: 0.20091 |  0:03:30s\n",
      "epoch 99 | loss: 0.16564 | train_rmsle: 0.01054 | train_mae: 0.3227  | train_rmse: 0.40872 | train_mse: 0.16705 | valid_rmsle: 0.0124  | valid_mae: 0.35627 | valid_rmse: 0.4498  | valid_mse: 0.20232 |  0:03:31s\n",
      "epoch 100| loss: 0.16447 | train_rmsle: 0.01012 | train_mae: 0.32081 | train_rmse: 0.40297 | train_mse: 0.16239 | valid_rmsle: 0.01211 | valid_mae: 0.35782 | valid_rmse: 0.4467  | valid_mse: 0.19954 |  0:03:33s\n",
      "epoch 101| loss: 0.16329 | train_rmsle: 0.0103  | train_mae: 0.31993 | train_rmse: 0.4048  | train_mse: 0.16386 | valid_rmsle: 0.01236 | valid_mae: 0.35649 | valid_rmse: 0.45034 | valid_mse: 0.2028  |  0:03:35s\n",
      "epoch 102| loss: 0.16374 | train_rmsle: 0.00999 | train_mae: 0.31605 | train_rmse: 0.39962 | train_mse: 0.15969 | valid_rmsle: 0.0123  | valid_mae: 0.3573  | valid_rmse: 0.44947 | valid_mse: 0.20202 |  0:03:38s\n",
      "epoch 103| loss: 0.16037 | train_rmsle: 0.00971 | train_mae: 0.31293 | train_rmse: 0.39485 | train_mse: 0.15591 | valid_rmsle: 0.01228 | valid_mae: 0.35699 | valid_rmse: 0.44957 | valid_mse: 0.20211 |  0:03:40s\n",
      "epoch 104| loss: 0.15922 | train_rmsle: 0.00965 | train_mae: 0.31143 | train_rmse: 0.39352 | train_mse: 0.15486 | valid_rmsle: 0.01223 | valid_mae: 0.35575 | valid_rmse: 0.44807 | valid_mse: 0.20076 |  0:03:42s\n",
      "epoch 105| loss: 0.15818 | train_rmsle: 0.0095  | train_mae: 0.31053 | train_rmse: 0.39198 | train_mse: 0.15365 | valid_rmsle: 0.01231 | valid_mae: 0.35956 | valid_rmse: 0.45134 | valid_mse: 0.20371 |  0:03:44s\n",
      "epoch 106| loss: 0.15689 | train_rmsle: 0.00945 | train_mae: 0.30732 | train_rmse: 0.38944 | train_mse: 0.15166 | valid_rmsle: 0.01221 | valid_mae: 0.3558  | valid_rmse: 0.44809 | valid_mse: 0.20078 |  0:03:46s\n",
      "\n",
      "Early stopping occurred at epoch 106 with best_epoch = 86 and best_valid_mse = 0.19817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.20005528598113087 RMSE: 0.44727540283490985 R2: 0.11443233397919528 MAE: 0.35543614762657344\n",
      "=====================================\n",
      "[24/108] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 23.87105| train_rmsle: 1.46931 | train_mae: 3.00112 | train_rmse: 3.0401  | train_mse: 9.2422  | valid_rmsle: 1.47335 | valid_mae: 3.0078  | valid_rmse: 3.0459  | valid_mse: 9.2775  |  0:00:02s\n",
      "epoch 1  | loss: 9.37664 | train_rmsle: 0.58366 | train_mae: 2.27296 | train_rmse: 2.32412 | train_mse: 5.40155 | valid_rmsle: 0.58901 | valid_mae: 2.28367 | valid_rmse: 2.33394 | valid_mse: 5.44726 |  0:00:04s\n",
      "epoch 2  | loss: 3.23701 | train_rmsle: 0.19684 | train_mae: 1.47679 | train_rmse: 1.56402 | train_mse: 2.44617 | valid_rmsle: 0.20211 | valid_mae: 1.49607 | valid_rmse: 1.58277 | valid_mse: 2.50516 |  0:00:06s\n",
      "epoch 3  | loss: 1.64334 | train_rmsle: 0.13566 | train_mae: 1.24751 | train_rmse: 1.34824 | train_mse: 1.81775 | valid_rmsle: 0.14039 | valid_mae: 1.26658 | valid_rmse: 1.36929 | valid_mse: 1.87495 |  0:00:08s\n",
      "epoch 4  | loss: 0.95577 | train_rmsle: 0.08449 | train_mae: 1.02033 | train_rmse: 1.11957 | train_mse: 1.25344 | valid_rmsle: 0.08667 | valid_mae: 1.03124 | valid_rmse: 1.13343 | valid_mse: 1.28467 |  0:00:10s\n",
      "epoch 5  | loss: 0.54314 | train_rmsle: 0.05601 | train_mae: 0.84774 | train_rmse: 0.94298 | train_mse: 0.88921 | valid_rmsle: 0.05663 | valid_mae: 0.85228 | valid_rmse: 0.9496  | valid_mse: 0.90174 |  0:00:13s\n",
      "epoch 6  | loss: 0.39209 | train_rmsle: 0.03465 | train_mae: 0.66669 | train_rmse: 0.76163 | train_mse: 0.58008 | valid_rmsle: 0.03501 | valid_mae: 0.66993 | valid_rmse: 0.76797 | valid_mse: 0.58978 |  0:00:15s\n",
      "epoch 7  | loss: 0.32665 | train_rmsle: 0.02515 | train_mae: 0.56484 | train_rmse: 0.65552 | train_mse: 0.42971 | valid_rmsle: 0.02522 | valid_mae: 0.56799 | valid_rmse: 0.66004 | valid_mse: 0.43565 |  0:00:17s\n",
      "epoch 8  | loss: 0.29269 | train_rmsle: 0.02366 | train_mae: 0.54703 | train_rmse: 0.63654 | train_mse: 0.40518 | valid_rmsle: 0.02366 | valid_mae: 0.54951 | valid_rmse: 0.64037 | valid_mse: 0.41007 |  0:00:19s\n",
      "epoch 9  | loss: 0.27782 | train_rmsle: 0.01856 | train_mae: 0.47465 | train_rmse: 0.56235 | train_mse: 0.31623 | valid_rmsle: 0.01833 | valid_mae: 0.47722 | valid_rmse: 0.5637  | valid_mse: 0.31776 |  0:00:21s\n",
      "epoch 10 | loss: 0.25865 | train_rmsle: 0.0177  | train_mae: 0.45994 | train_rmse: 0.5481  | train_mse: 0.30042 | valid_rmsle: 0.01752 | valid_mae: 0.46449 | valid_rmse: 0.55056 | valid_mse: 0.30311 |  0:00:23s\n",
      "epoch 11 | loss: 0.25482 | train_rmsle: 0.01807 | train_mae: 0.46626 | train_rmse: 0.55462 | train_mse: 0.3076  | valid_rmsle: 0.01792 | valid_mae: 0.47033 | valid_rmse: 0.55743 | valid_mse: 0.31073 |  0:00:24s\n",
      "epoch 12 | loss: 0.24327 | train_rmsle: 0.01711 | train_mae: 0.44936 | train_rmse: 0.53793 | train_mse: 0.28937 | valid_rmsle: 0.01675 | valid_mae: 0.45234 | valid_rmse: 0.53766 | valid_mse: 0.28908 |  0:00:26s\n",
      "epoch 13 | loss: 0.23802 | train_rmsle: 0.01787 | train_mae: 0.46242 | train_rmse: 0.55139 | train_mse: 0.30403 | valid_rmsle: 0.01771 | valid_mae: 0.4663  | valid_rmse: 0.55422 | valid_mse: 0.30716 |  0:00:28s\n",
      "epoch 14 | loss: 0.23799 | train_rmsle: 0.01767 | train_mae: 0.45975 | train_rmse: 0.5481  | train_mse: 0.30041 | valid_rmsle: 0.01751 | valid_mae: 0.46398 | valid_rmse: 0.55068 | valid_mse: 0.30325 |  0:00:30s\n",
      "epoch 15 | loss: 0.23697 | train_rmsle: 0.01761 | train_mae: 0.45921 | train_rmse: 0.54719 | train_mse: 0.29941 | valid_rmsle: 0.01739 | valid_mae: 0.46252 | valid_rmse: 0.54871 | valid_mse: 0.30109 |  0:00:32s\n",
      "epoch 16 | loss: 0.23191 | train_rmsle: 0.01649 | train_mae: 0.4388  | train_rmse: 0.52751 | train_mse: 0.27827 | valid_rmsle: 0.01624 | valid_mae: 0.44209 | valid_rmse: 0.52902 | valid_mse: 0.27986 |  0:00:34s\n",
      "epoch 17 | loss: 0.22973 | train_rmsle: 0.01504 | train_mae: 0.40922 | train_rmse: 0.49896 | train_mse: 0.24896 | valid_rmsle: 0.01473 | valid_mae: 0.41209 | valid_rmse: 0.49944 | valid_mse: 0.24944 |  0:00:37s\n",
      "epoch 18 | loss: 0.22745 | train_rmsle: 0.01471 | train_mae: 0.40235 | train_rmse: 0.49212 | train_mse: 0.24218 | valid_rmsle: 0.01432 | valid_mae: 0.40437 | valid_rmse: 0.4915  | valid_mse: 0.24157 |  0:00:39s\n",
      "epoch 19 | loss: 0.22743 | train_rmsle: 0.01486 | train_mae: 0.40558 | train_rmse: 0.49535 | train_mse: 0.24537 | valid_rmsle: 0.01473 | valid_mae: 0.41076 | valid_rmse: 0.49922 | valid_mse: 0.24922 |  0:00:40s\n",
      "epoch 20 | loss: 0.22173 | train_rmsle: 0.01505 | train_mae: 0.41119 | train_rmse: 0.49981 | train_mse: 0.24981 | valid_rmsle: 0.015   | valid_mae: 0.41673 | valid_rmse: 0.50477 | valid_mse: 0.25479 |  0:00:42s\n",
      "epoch 21 | loss: 0.22406 | train_rmsle: 0.01456 | train_mae: 0.39936 | train_rmse: 0.48903 | train_mse: 0.23915 | valid_rmsle: 0.01441 | valid_mae: 0.40593 | valid_rmse: 0.49219 | valid_mse: 0.24225 |  0:00:44s\n",
      "epoch 22 | loss: 0.2177  | train_rmsle: 0.01467 | train_mae: 0.40184 | train_rmse: 0.49171 | train_mse: 0.24178 | valid_rmsle: 0.01468 | valid_mae: 0.41047 | valid_rmse: 0.49734 | valid_mse: 0.24734 |  0:00:46s\n",
      "epoch 23 | loss: 0.21942 | train_rmsle: 0.01436 | train_mae: 0.39495 | train_rmse: 0.4851  | train_mse: 0.23532 | valid_rmsle: 0.0141  | valid_mae: 0.39971 | valid_rmse: 0.48644 | valid_mse: 0.23662 |  0:00:48s\n",
      "epoch 24 | loss: 0.22249 | train_rmsle: 0.01404 | train_mae: 0.3862  | train_rmse: 0.47747 | train_mse: 0.22798 | valid_rmsle: 0.01382 | valid_mae: 0.39325 | valid_rmse: 0.4793  | valid_mse: 0.22973 |  0:00:50s\n",
      "epoch 25 | loss: 0.22166 | train_rmsle: 0.0141  | train_mae: 0.38502 | train_rmse: 0.47752 | train_mse: 0.22802 | valid_rmsle: 0.01359 | valid_mae: 0.38754 | valid_rmse: 0.47484 | valid_mse: 0.22547 |  0:00:52s\n",
      "epoch 26 | loss: 0.21837 | train_rmsle: 0.01388 | train_mae: 0.3786  | train_rmse: 0.47235 | train_mse: 0.22312 | valid_rmsle: 0.01357 | valid_mae: 0.38464 | valid_rmse: 0.47326 | valid_mse: 0.22397 |  0:00:54s\n",
      "epoch 27 | loss: 0.21933 | train_rmsle: 0.01385 | train_mae: 0.38042 | train_rmse: 0.47284 | train_mse: 0.22358 | valid_rmsle: 0.01313 | valid_mae: 0.37931 | valid_rmse: 0.46611 | valid_mse: 0.21725 |  0:00:56s\n",
      "epoch 28 | loss: 0.21618 | train_rmsle: 0.01408 | train_mae: 0.38873 | train_rmse: 0.47951 | train_mse: 0.22993 | valid_rmsle: 0.01396 | valid_mae: 0.39475 | valid_rmse: 0.48367 | valid_mse: 0.23394 |  0:00:58s\n",
      "epoch 29 | loss: 0.21373 | train_rmsle: 0.01385 | train_mae: 0.37552 | train_rmse: 0.47099 | train_mse: 0.22184 | valid_rmsle: 0.01328 | valid_mae: 0.3786  | valid_rmse: 0.46743 | valid_mse: 0.21849 |  0:01:01s\n",
      "epoch 30 | loss: 0.21279 | train_rmsle: 0.01388 | train_mae: 0.36903 | train_rmse: 0.46864 | train_mse: 0.21962 | valid_rmsle: 0.01322 | valid_mae: 0.37126 | valid_rmse: 0.46307 | valid_mse: 0.21443 |  0:01:03s\n",
      "epoch 31 | loss: 0.21294 | train_rmsle: 0.01389 | train_mae: 0.37265 | train_rmse: 0.46993 | train_mse: 0.22083 | valid_rmsle: 0.0132  | valid_mae: 0.37207 | valid_rmse: 0.46414 | valid_mse: 0.21543 |  0:01:05s\n",
      "epoch 32 | loss: 0.21274 | train_rmsle: 0.01369 | train_mae: 0.37372 | train_rmse: 0.46804 | train_mse: 0.21906 | valid_rmsle: 0.01315 | valid_mae: 0.37599 | valid_rmse: 0.46502 | valid_mse: 0.21625 |  0:01:07s\n",
      "epoch 33 | loss: 0.21139 | train_rmsle: 0.0137  | train_mae: 0.3784  | train_rmse: 0.47004 | train_mse: 0.22094 | valid_rmsle: 0.01331 | valid_mae: 0.37949 | valid_rmse: 0.46903 | valid_mse: 0.21999 |  0:01:09s\n",
      "epoch 34 | loss: 0.21515 | train_rmsle: 0.01412 | train_mae: 0.39308 | train_rmse: 0.48193 | train_mse: 0.23225 | valid_rmsle: 0.01418 | valid_mae: 0.40326 | valid_rmse: 0.48881 | valid_mse: 0.23893 |  0:01:11s\n",
      "epoch 35 | loss: 0.21029 | train_rmsle: 0.01365 | train_mae: 0.38122 | train_rmse: 0.47079 | train_mse: 0.22164 | valid_rmsle: 0.01368 | valid_mae: 0.38901 | valid_rmse: 0.47677 | valid_mse: 0.22731 |  0:01:14s\n",
      "epoch 36 | loss: 0.20944 | train_rmsle: 0.0136  | train_mae: 0.37429 | train_rmse: 0.46703 | train_mse: 0.21812 | valid_rmsle: 0.01373 | valid_mae: 0.38435 | valid_rmse: 0.47494 | valid_mse: 0.22557 |  0:01:16s\n",
      "epoch 37 | loss: 0.20952 | train_rmsle: 0.01367 | train_mae: 0.36881 | train_rmse: 0.46551 | train_mse: 0.2167  | valid_rmsle: 0.01352 | valid_mae: 0.37324 | valid_rmse: 0.46933 | valid_mse: 0.22027 |  0:01:18s\n",
      "epoch 38 | loss: 0.21083 | train_rmsle: 0.01346 | train_mae: 0.37106 | train_rmse: 0.46437 | train_mse: 0.21564 | valid_rmsle: 0.01333 | valid_mae: 0.37924 | valid_rmse: 0.46813 | valid_mse: 0.21914 |  0:01:20s\n",
      "epoch 39 | loss: 0.20835 | train_rmsle: 0.01347 | train_mae: 0.37112 | train_rmse: 0.46426 | train_mse: 0.21553 | valid_rmsle: 0.01337 | valid_mae: 0.37862 | valid_rmse: 0.46871 | valid_mse: 0.21969 |  0:01:22s\n",
      "epoch 40 | loss: 0.21063 | train_rmsle: 0.01342 | train_mae: 0.37238 | train_rmse: 0.46422 | train_mse: 0.2155  | valid_rmsle: 0.01347 | valid_mae: 0.37935 | valid_rmse: 0.47106 | valid_mse: 0.2219  |  0:01:24s\n",
      "epoch 41 | loss: 0.2056  | train_rmsle: 0.01336 | train_mae: 0.36758 | train_rmse: 0.46153 | train_mse: 0.21301 | valid_rmsle: 0.01328 | valid_mae: 0.37681 | valid_rmse: 0.4666  | valid_mse: 0.21771 |  0:01:27s\n",
      "epoch 42 | loss: 0.20512 | train_rmsle: 0.01342 | train_mae: 0.37453 | train_rmse: 0.46548 | train_mse: 0.21667 | valid_rmsle: 0.0135  | valid_mae: 0.38489 | valid_rmse: 0.4734  | valid_mse: 0.2241  |  0:01:29s\n",
      "epoch 43 | loss: 0.20514 | train_rmsle: 0.01332 | train_mae: 0.37252 | train_rmse: 0.46334 | train_mse: 0.21468 | valid_rmsle: 0.01333 | valid_mae: 0.38132 | valid_rmse: 0.46983 | valid_mse: 0.22074 |  0:01:31s\n",
      "epoch 44 | loss: 0.20477 | train_rmsle: 0.01336 | train_mae: 0.36869 | train_rmse: 0.46179 | train_mse: 0.21325 | valid_rmsle: 0.01332 | valid_mae: 0.37688 | valid_rmse: 0.4677  | valid_mse: 0.21875 |  0:01:33s\n",
      "epoch 45 | loss: 0.20601 | train_rmsle: 0.01332 | train_mae: 0.36436 | train_rmse: 0.45978 | train_mse: 0.2114  | valid_rmsle: 0.0131  | valid_mae: 0.36933 | valid_rmse: 0.46249 | valid_mse: 0.2139  |  0:01:35s\n",
      "epoch 46 | loss: 0.20401 | train_rmsle: 0.01339 | train_mae: 0.36471 | train_rmse: 0.46078 | train_mse: 0.21231 | valid_rmsle: 0.0132  | valid_mae: 0.37259 | valid_rmse: 0.46347 | valid_mse: 0.2148  |  0:01:37s\n",
      "epoch 47 | loss: 0.20373 | train_rmsle: 0.01322 | train_mae: 0.36794 | train_rmse: 0.46009 | train_mse: 0.21168 | valid_rmsle: 0.01296 | valid_mae: 0.37414 | valid_rmse: 0.4615  | valid_mse: 0.21298 |  0:01:40s\n",
      "epoch 48 | loss: 0.2023  | train_rmsle: 0.01312 | train_mae: 0.36525 | train_rmse: 0.45799 | train_mse: 0.20975 | valid_rmsle: 0.01307 | valid_mae: 0.3759  | valid_rmse: 0.4635  | valid_mse: 0.21483 |  0:01:42s\n",
      "epoch 49 | loss: 0.20077 | train_rmsle: 0.01312 | train_mae: 0.36203 | train_rmse: 0.45615 | train_mse: 0.20807 | valid_rmsle: 0.01296 | valid_mae: 0.37185 | valid_rmse: 0.46017 | valid_mse: 0.21175 |  0:01:44s\n",
      "epoch 50 | loss: 0.20252 | train_rmsle: 0.0131  | train_mae: 0.36498 | train_rmse: 0.45724 | train_mse: 0.20907 | valid_rmsle: 0.0131  | valid_mae: 0.37481 | valid_rmse: 0.46315 | valid_mse: 0.21451 |  0:01:46s\n",
      "epoch 51 | loss: 0.20178 | train_rmsle: 0.01301 | train_mae: 0.36115 | train_rmse: 0.45455 | train_mse: 0.20662 | valid_rmsle: 0.01313 | valid_mae: 0.37261 | valid_rmse: 0.46299 | valid_mse: 0.21436 |  0:01:48s\n",
      "epoch 52 | loss: 0.20091 | train_rmsle: 0.01301 | train_mae: 0.36363 | train_rmse: 0.45558 | train_mse: 0.20755 | valid_rmsle: 0.01306 | valid_mae: 0.37322 | valid_rmse: 0.46275 | valid_mse: 0.21413 |  0:01:51s\n",
      "epoch 53 | loss: 0.20146 | train_rmsle: 0.013   | train_mae: 0.35819 | train_rmse: 0.45296 | train_mse: 0.20517 | valid_rmsle: 0.01322 | valid_mae: 0.37243 | valid_rmse: 0.46428 | valid_mse: 0.21556 |  0:01:53s\n",
      "epoch 54 | loss: 0.20211 | train_rmsle: 0.01282 | train_mae: 0.35918 | train_rmse: 0.45141 | train_mse: 0.20377 | valid_rmsle: 0.01298 | valid_mae: 0.37122 | valid_rmse: 0.46127 | valid_mse: 0.21277 |  0:01:55s\n",
      "epoch 55 | loss: 0.19994 | train_rmsle: 0.01291 | train_mae: 0.35888 | train_rmse: 0.45211 | train_mse: 0.20441 | valid_rmsle: 0.01308 | valid_mae: 0.3685  | valid_rmse: 0.46191 | valid_mse: 0.21336 |  0:01:57s\n",
      "epoch 56 | loss: 0.19781 | train_rmsle: 0.01281 | train_mae: 0.35844 | train_rmse: 0.45084 | train_mse: 0.20326 | valid_rmsle: 0.01306 | valid_mae: 0.37136 | valid_rmse: 0.46218 | valid_mse: 0.21361 |  0:01:59s\n",
      "epoch 57 | loss: 0.19753 | train_rmsle: 0.01272 | train_mae: 0.36018 | train_rmse: 0.45058 | train_mse: 0.20302 | valid_rmsle: 0.01302 | valid_mae: 0.37183 | valid_rmse: 0.4621  | valid_mse: 0.21354 |  0:02:01s\n",
      "epoch 58 | loss: 0.19819 | train_rmsle: 0.01295 | train_mae: 0.35788 | train_rmse: 0.45231 | train_mse: 0.20459 | valid_rmsle: 0.013   | valid_mae: 0.36758 | valid_rmse: 0.45974 | valid_mse: 0.21136 |  0:02:03s\n",
      "epoch 59 | loss: 0.19582 | train_rmsle: 0.01278 | train_mae: 0.36029 | train_rmse: 0.45143 | train_mse: 0.20379 | valid_rmsle: 0.01291 | valid_mae: 0.36905 | valid_rmse: 0.46011 | valid_mse: 0.21171 |  0:02:06s\n",
      "epoch 60 | loss: 0.19712 | train_rmsle: 0.01298 | train_mae: 0.35828 | train_rmse: 0.4528  | train_mse: 0.20503 | valid_rmsle: 0.013   | valid_mae: 0.36626 | valid_rmse: 0.45924 | valid_mse: 0.2109  |  0:02:08s\n",
      "epoch 61 | loss: 0.19678 | train_rmsle: 0.01283 | train_mae: 0.35862 | train_rmse: 0.45145 | train_mse: 0.2038  | valid_rmsle: 0.0129  | valid_mae: 0.36825 | valid_rmse: 0.4589  | valid_mse: 0.21059 |  0:02:10s\n",
      "epoch 62 | loss: 0.19803 | train_rmsle: 0.0128  | train_mae: 0.35683 | train_rmse: 0.44998 | train_mse: 0.20248 | valid_rmsle: 0.01278 | valid_mae: 0.3645  | valid_rmse: 0.456   | valid_mse: 0.20794 |  0:02:12s\n",
      "epoch 63 | loss: 0.19616 | train_rmsle: 0.01283 | train_mae: 0.35558 | train_rmse: 0.44989 | train_mse: 0.2024  | valid_rmsle: 0.01302 | valid_mae: 0.36708 | valid_rmse: 0.45951 | valid_mse: 0.21115 |  0:02:14s\n",
      "epoch 64 | loss: 0.19716 | train_rmsle: 0.01281 | train_mae: 0.35846 | train_rmse: 0.45095 | train_mse: 0.20335 | valid_rmsle: 0.01297 | valid_mae: 0.36686 | valid_rmse: 0.45922 | valid_mse: 0.21088 |  0:02:16s\n",
      "epoch 65 | loss: 0.19869 | train_rmsle: 0.01274 | train_mae: 0.35741 | train_rmse: 0.44956 | train_mse: 0.2021  | valid_rmsle: 0.01305 | valid_mae: 0.3695  | valid_rmse: 0.46178 | valid_mse: 0.21324 |  0:02:19s\n",
      "epoch 66 | loss: 0.19705 | train_rmsle: 0.01257 | train_mae: 0.35729 | train_rmse: 0.44764 | train_mse: 0.20038 | valid_rmsle: 0.0129  | valid_mae: 0.36984 | valid_rmse: 0.45948 | valid_mse: 0.21112 |  0:02:21s\n",
      "epoch 67 | loss: 0.19452 | train_rmsle: 0.01281 | train_mae: 0.35337 | train_rmse: 0.44871 | train_mse: 0.20134 | valid_rmsle: 0.01316 | valid_mae: 0.36791 | valid_rmse: 0.46152 | valid_mse: 0.213   |  0:02:23s\n",
      "epoch 68 | loss: 0.19377 | train_rmsle: 0.01281 | train_mae: 0.35352 | train_rmse: 0.4487  | train_mse: 0.20133 | valid_rmsle: 0.01327 | valid_mae: 0.36904 | valid_rmse: 0.46315 | valid_mse: 0.21451 |  0:02:25s\n",
      "epoch 69 | loss: 0.19221 | train_rmsle: 0.0124  | train_mae: 0.35469 | train_rmse: 0.44461 | train_mse: 0.19768 | valid_rmsle: 0.01293 | valid_mae: 0.36958 | valid_rmse: 0.46021 | valid_mse: 0.21179 |  0:02:27s\n",
      "epoch 70 | loss: 0.1937  | train_rmsle: 0.01278 | train_mae: 0.35152 | train_rmse: 0.44769 | train_mse: 0.20042 | valid_rmsle: 0.01292 | valid_mae: 0.36269 | valid_rmse: 0.45646 | valid_mse: 0.20836 |  0:02:29s\n",
      "epoch 71 | loss: 0.18942 | train_rmsle: 0.01243 | train_mae: 0.35224 | train_rmse: 0.44393 | train_mse: 0.19707 | valid_rmsle: 0.01275 | valid_mae: 0.36622 | valid_rmse: 0.45634 | valid_mse: 0.20825 |  0:02:31s\n",
      "epoch 72 | loss: 0.19268 | train_rmsle: 0.0123  | train_mae: 0.35363 | train_rmse: 0.44293 | train_mse: 0.19619 | valid_rmsle: 0.01266 | valid_mae: 0.36828 | valid_rmse: 0.45602 | valid_mse: 0.20795 |  0:02:33s\n",
      "epoch 73 | loss: 0.19138 | train_rmsle: 0.01245 | train_mae: 0.35175 | train_rmse: 0.44359 | train_mse: 0.19677 | valid_rmsle: 0.0126  | valid_mae: 0.36395 | valid_rmse: 0.45334 | valid_mse: 0.20552 |  0:02:36s\n",
      "epoch 74 | loss: 0.19108 | train_rmsle: 0.01232 | train_mae: 0.35417 | train_rmse: 0.4433  | train_mse: 0.19651 | valid_rmsle: 0.01252 | valid_mae: 0.36738 | valid_rmse: 0.45397 | valid_mse: 0.20609 |  0:02:38s\n",
      "epoch 75 | loss: 0.19228 | train_rmsle: 0.01222 | train_mae: 0.35337 | train_rmse: 0.44164 | train_mse: 0.19505 | valid_rmsle: 0.01248 | valid_mae: 0.36816 | valid_rmse: 0.45296 | valid_mse: 0.20518 |  0:02:40s\n",
      "epoch 76 | loss: 0.18984 | train_rmsle: 0.01223 | train_mae: 0.3536  | train_rmse: 0.44245 | train_mse: 0.19576 | valid_rmsle: 0.0123  | valid_mae: 0.36607 | valid_rmse: 0.45051 | valid_mse: 0.20296 |  0:02:42s\n",
      "epoch 77 | loss: 0.18969 | train_rmsle: 0.01225 | train_mae: 0.35257 | train_rmse: 0.44228 | train_mse: 0.19561 | valid_rmsle: 0.0124  | valid_mae: 0.3668  | valid_rmse: 0.45168 | valid_mse: 0.20402 |  0:02:44s\n",
      "epoch 78 | loss: 0.18784 | train_rmsle: 0.01209 | train_mae: 0.35153 | train_rmse: 0.43969 | train_mse: 0.19333 | valid_rmsle: 0.01232 | valid_mae: 0.3643  | valid_rmse: 0.45029 | valid_mse: 0.20276 |  0:02:46s\n",
      "epoch 79 | loss: 0.18744 | train_rmsle: 0.01198 | train_mae: 0.35265 | train_rmse: 0.43949 | train_mse: 0.19315 | valid_rmsle: 0.0125  | valid_mae: 0.36877 | valid_rmse: 0.45512 | valid_mse: 0.20713 |  0:02:48s\n",
      "epoch 80 | loss: 0.18728 | train_rmsle: 0.01199 | train_mae: 0.34738 | train_rmse: 0.43679 | train_mse: 0.19079 | valid_rmsle: 0.01238 | valid_mae: 0.36274 | valid_rmse: 0.45049 | valid_mse: 0.20294 |  0:02:50s\n",
      "epoch 81 | loss: 0.18812 | train_rmsle: 0.0119  | train_mae: 0.34759 | train_rmse: 0.4357  | train_mse: 0.18983 | valid_rmsle: 0.01247 | valid_mae: 0.36406 | valid_rmse: 0.45207 | valid_mse: 0.20437 |  0:02:52s\n",
      "epoch 82 | loss: 0.18684 | train_rmsle: 0.01188 | train_mae: 0.35057 | train_rmse: 0.43713 | train_mse: 0.19108 | valid_rmsle: 0.01236 | valid_mae: 0.36352 | valid_rmse: 0.45097 | valid_mse: 0.20337 |  0:02:54s\n",
      "epoch 83 | loss: 0.18482 | train_rmsle: 0.01183 | train_mae: 0.34862 | train_rmse: 0.43552 | train_mse: 0.18967 | valid_rmsle: 0.01231 | valid_mae: 0.36272 | valid_rmse: 0.45018 | valid_mse: 0.20266 |  0:02:56s\n",
      "epoch 84 | loss: 0.18364 | train_rmsle: 0.01165 | train_mae: 0.34751 | train_rmse: 0.43293 | train_mse: 0.18743 | valid_rmsle: 0.01214 | valid_mae: 0.35805 | valid_rmse: 0.4465  | valid_mse: 0.19936 |  0:02:58s\n",
      "epoch 85 | loss: 0.18338 | train_rmsle: 0.01157 | train_mae: 0.3443  | train_rmse: 0.43048 | train_mse: 0.18531 | valid_rmsle: 0.01209 | valid_mae: 0.35916 | valid_rmse: 0.44521 | valid_mse: 0.19821 |  0:03:00s\n",
      "epoch 86 | loss: 0.18067 | train_rmsle: 0.01142 | train_mae: 0.34168 | train_rmse: 0.42789 | train_mse: 0.18309 | valid_rmsle: 0.01207 | valid_mae: 0.35887 | valid_rmse: 0.44516 | valid_mse: 0.19817 |  0:03:02s\n",
      "epoch 87 | loss: 0.18006 | train_rmsle: 0.01149 | train_mae: 0.33813 | train_rmse: 0.42646 | train_mse: 0.18187 | valid_rmsle: 0.01222 | valid_mae: 0.3566  | valid_rmse: 0.44553 | valid_mse: 0.1985  |  0:03:04s\n",
      "epoch 88 | loss: 0.17813 | train_rmsle: 0.01147 | train_mae: 0.33949 | train_rmse: 0.42662 | train_mse: 0.18201 | valid_rmsle: 0.01235 | valid_mae: 0.36034 | valid_rmse: 0.44921 | valid_mse: 0.20179 |  0:03:06s\n",
      "epoch 89 | loss: 0.17835 | train_rmsle: 0.01119 | train_mae: 0.33821 | train_rmse: 0.42327 | train_mse: 0.17916 | valid_rmsle: 0.01206 | valid_mae: 0.35873 | valid_rmse: 0.44542 | valid_mse: 0.1984  |  0:03:08s\n",
      "epoch 90 | loss: 0.17774 | train_rmsle: 0.01116 | train_mae: 0.33621 | train_rmse: 0.42198 | train_mse: 0.17807 | valid_rmsle: 0.01229 | valid_mae: 0.35975 | valid_rmse: 0.449   | valid_mse: 0.2016  |  0:03:10s\n",
      "epoch 91 | loss: 0.1755  | train_rmsle: 0.01119 | train_mae: 0.33491 | train_rmse: 0.42156 | train_mse: 0.17771 | valid_rmsle: 0.01238 | valid_mae: 0.35953 | valid_rmse: 0.44938 | valid_mse: 0.20195 |  0:03:13s\n",
      "epoch 92 | loss: 0.17473 | train_rmsle: 0.01115 | train_mae: 0.33331 | train_rmse: 0.42051 | train_mse: 0.17683 | valid_rmsle: 0.01254 | valid_mae: 0.36154 | valid_rmse: 0.45249 | valid_mse: 0.20475 |  0:03:15s\n",
      "epoch 93 | loss: 0.17499 | train_rmsle: 0.01082 | train_mae: 0.33114 | train_rmse: 0.41612 | train_mse: 0.17315 | valid_rmsle: 0.01232 | valid_mae: 0.36293 | valid_rmse: 0.45042 | valid_mse: 0.20288 |  0:03:17s\n",
      "epoch 94 | loss: 0.17284 | train_rmsle: 0.01109 | train_mae: 0.3311  | train_rmse: 0.41872 | train_mse: 0.17532 | valid_rmsle: 0.01247 | valid_mae: 0.35997 | valid_rmse: 0.45071 | valid_mse: 0.20314 |  0:03:19s\n",
      "epoch 95 | loss: 0.17163 | train_rmsle: 0.01075 | train_mae: 0.32879 | train_rmse: 0.4142  | train_mse: 0.17156 | valid_rmsle: 0.01226 | valid_mae: 0.35691 | valid_rmse: 0.4479  | valid_mse: 0.20062 |  0:03:21s\n",
      "epoch 96 | loss: 0.17241 | train_rmsle: 0.0106  | train_mae: 0.331   | train_rmse: 0.41392 | train_mse: 0.17133 | valid_rmsle: 0.0122  | valid_mae: 0.35988 | valid_rmse: 0.44894 | valid_mse: 0.20154 |  0:03:23s\n",
      "epoch 97 | loss: 0.16968 | train_rmsle: 0.01065 | train_mae: 0.32775 | train_rmse: 0.41272 | train_mse: 0.17033 | valid_rmsle: 0.01214 | valid_mae: 0.35741 | valid_rmse: 0.44653 | valid_mse: 0.19939 |  0:03:25s\n",
      "epoch 98 | loss: 0.16835 | train_rmsle: 0.01049 | train_mae: 0.32542 | train_rmse: 0.40991 | train_mse: 0.16803 | valid_rmsle: 0.01222 | valid_mae: 0.35764 | valid_rmse: 0.44823 | valid_mse: 0.20091 |  0:03:28s\n",
      "epoch 99 | loss: 0.16564 | train_rmsle: 0.01054 | train_mae: 0.3227  | train_rmse: 0.40872 | train_mse: 0.16705 | valid_rmsle: 0.0124  | valid_mae: 0.35627 | valid_rmse: 0.4498  | valid_mse: 0.20232 |  0:03:30s\n",
      "epoch 100| loss: 0.16447 | train_rmsle: 0.01012 | train_mae: 0.32081 | train_rmse: 0.40297 | train_mse: 0.16239 | valid_rmsle: 0.01211 | valid_mae: 0.35782 | valid_rmse: 0.4467  | valid_mse: 0.19954 |  0:03:32s\n",
      "epoch 101| loss: 0.16329 | train_rmsle: 0.0103  | train_mae: 0.31993 | train_rmse: 0.4048  | train_mse: 0.16386 | valid_rmsle: 0.01236 | valid_mae: 0.35649 | valid_rmse: 0.45034 | valid_mse: 0.2028  |  0:03:34s\n",
      "epoch 102| loss: 0.16374 | train_rmsle: 0.00999 | train_mae: 0.31605 | train_rmse: 0.39962 | train_mse: 0.15969 | valid_rmsle: 0.0123  | valid_mae: 0.3573  | valid_rmse: 0.44947 | valid_mse: 0.20202 |  0:03:36s\n",
      "epoch 103| loss: 0.16037 | train_rmsle: 0.00971 | train_mae: 0.31293 | train_rmse: 0.39485 | train_mse: 0.15591 | valid_rmsle: 0.01228 | valid_mae: 0.35699 | valid_rmse: 0.44957 | valid_mse: 0.20211 |  0:03:38s\n",
      "epoch 104| loss: 0.15922 | train_rmsle: 0.00965 | train_mae: 0.31143 | train_rmse: 0.39352 | train_mse: 0.15486 | valid_rmsle: 0.01223 | valid_mae: 0.35575 | valid_rmse: 0.44807 | valid_mse: 0.20076 |  0:03:40s\n",
      "epoch 105| loss: 0.15818 | train_rmsle: 0.0095  | train_mae: 0.31053 | train_rmse: 0.39198 | train_mse: 0.15365 | valid_rmsle: 0.01231 | valid_mae: 0.35956 | valid_rmse: 0.45134 | valid_mse: 0.20371 |  0:03:43s\n",
      "epoch 106| loss: 0.15689 | train_rmsle: 0.00945 | train_mae: 0.30732 | train_rmse: 0.38944 | train_mse: 0.15166 | valid_rmsle: 0.01221 | valid_mae: 0.3558  | valid_rmse: 0.44809 | valid_mse: 0.20078 |  0:03:45s\n",
      "\n",
      "Early stopping occurred at epoch 106 with best_epoch = 86 and best_valid_mse = 0.19817\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.20005528598113087 RMSE: 0.44727540283490985 R2: 0.11443233397919528 MAE: 0.35543614762657344\n",
      "=====================================\n",
      "[25/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.5006  | train_rmsle: 0.38629 | train_mae: 1.96568 | train_rmse: 2.02437 | train_mse: 4.09809 | valid_rmsle: 0.38778 | valid_mae: 1.97191 | valid_rmse: 2.02933 | valid_mse: 4.11816 |  0:00:02s\n",
      "epoch 1  | loss: 0.81048 | train_rmsle: 0.07202 | train_mae: 0.95955 | train_rmse: 1.05119 | train_mse: 1.10501 | valid_rmsle: 0.07222 | valid_mae: 0.96167 | valid_rmse: 1.05433 | valid_mse: 1.11161 |  0:00:05s\n",
      "epoch 2  | loss: 0.30723 | train_rmsle: 0.02493 | train_mae: 0.56295 | train_rmse: 0.65304 | train_mse: 0.42646 | valid_rmsle: 0.02471 | valid_mae: 0.56362 | valid_rmse: 0.65391 | valid_mse: 0.4276  |  0:00:07s\n",
      "epoch 3  | loss: 0.27624 | train_rmsle: 0.03998 | train_mae: 0.72044 | train_rmse: 0.81339 | train_mse: 0.6616  | valid_rmsle: 0.03997 | valid_mae: 0.7205  | valid_rmse: 0.81571 | valid_mse: 0.66538 |  0:00:10s\n",
      "epoch 4  | loss: 0.25353 | train_rmsle: 0.03248 | train_mae: 0.64806 | train_rmse: 0.74008 | train_mse: 0.54771 | valid_rmsle: 0.0324  | valid_mae: 0.64786 | valid_rmse: 0.74208 | valid_mse: 0.55069 |  0:00:12s\n",
      "epoch 5  | loss: 0.28372 | train_rmsle: 0.01704 | train_mae: 0.44881 | train_rmse: 0.53646 | train_mse: 0.28779 | valid_rmsle: 0.01658 | valid_mae: 0.44936 | valid_rmse: 0.53414 | valid_mse: 0.28531 |  0:00:14s\n",
      "epoch 6  | loss: 0.2924  | train_rmsle: 0.03551 | train_mae: 0.67831 | train_rmse: 0.77068 | train_mse: 0.59395 | valid_rmsle: 0.03539 | valid_mae: 0.67741 | valid_rmse: 0.7723  | valid_mse: 0.59644 |  0:00:16s\n",
      "epoch 7  | loss: 0.29245 | train_rmsle: 0.02764 | train_mae: 0.59474 | train_rmse: 0.68597 | train_mse: 0.47055 | valid_rmsle: 0.02737 | valid_mae: 0.59448 | valid_rmse: 0.686   | valid_mse: 0.4706  |  0:00:19s\n",
      "epoch 8  | loss: 0.24724 | train_rmsle: 0.01757 | train_mae: 0.4579  | train_rmse: 0.54558 | train_mse: 0.29766 | valid_rmsle: 0.01707 | valid_mae: 0.45862 | valid_rmse: 0.54272 | valid_mse: 0.29455 |  0:00:21s\n",
      "epoch 9  | loss: 0.23568 | train_rmsle: 0.01849 | train_mae: 0.47328 | train_rmse: 0.56097 | train_mse: 0.31469 | valid_rmsle: 0.01814 | valid_mae: 0.47516 | valid_rmse: 0.56028 | valid_mse: 0.31391 |  0:00:24s\n",
      "epoch 10 | loss: 0.2298  | train_rmsle: 0.02123 | train_mae: 0.51433 | train_rmse: 0.60291 | train_mse: 0.3635  | valid_rmsle: 0.02089 | valid_mae: 0.51613 | valid_rmse: 0.60232 | valid_mse: 0.36279 |  0:00:27s\n",
      "epoch 11 | loss: 0.22932 | train_rmsle: 0.01558 | train_mae: 0.41838 | train_rmse: 0.50832 | train_mse: 0.25839 | valid_rmsle: 0.01503 | valid_mae: 0.41841 | valid_rmse: 0.50436 | valid_mse: 0.25438 |  0:00:29s\n",
      "epoch 12 | loss: 0.23527 | train_rmsle: 0.01642 | train_mae: 0.4362  | train_rmse: 0.52485 | train_mse: 0.27547 | valid_rmsle: 0.01594 | valid_mae: 0.43771 | valid_rmse: 0.52204 | valid_mse: 0.27252 |  0:00:32s\n",
      "epoch 13 | loss: 0.22838 | train_rmsle: 0.01685 | train_mae: 0.4438  | train_rmse: 0.53254 | train_mse: 0.2836  | valid_rmsle: 0.01651 | valid_mae: 0.44807 | valid_rmse: 0.53202 | valid_mse: 0.28305 |  0:00:35s\n",
      "epoch 14 | loss: 0.22595 | train_rmsle: 0.01495 | train_mae: 0.40206 | train_rmse: 0.49437 | train_mse: 0.2444  | valid_rmsle: 0.01448 | valid_mae: 0.40408 | valid_rmse: 0.49196 | valid_mse: 0.24203 |  0:00:38s\n",
      "epoch 15 | loss: 0.22644 | train_rmsle: 0.01603 | train_mae: 0.42888 | train_rmse: 0.51771 | train_mse: 0.26802 | valid_rmsle: 0.01557 | valid_mae: 0.43061 | valid_rmse: 0.51533 | valid_mse: 0.26557 |  0:00:40s\n",
      "epoch 16 | loss: 0.22733 | train_rmsle: 0.01479 | train_mae: 0.39802 | train_rmse: 0.49088 | train_mse: 0.24096 | valid_rmsle: 0.01423 | valid_mae: 0.39765 | valid_rmse: 0.48655 | valid_mse: 0.23673 |  0:00:43s\n",
      "epoch 17 | loss: 0.22782 | train_rmsle: 0.01453 | train_mae: 0.38362 | train_rmse: 0.48205 | train_mse: 0.23237 | valid_rmsle: 0.01398 | valid_mae: 0.38435 | valid_rmse: 0.47784 | valid_mse: 0.22833 |  0:00:46s\n",
      "epoch 18 | loss: 0.23185 | train_rmsle: 0.01606 | train_mae: 0.43001 | train_rmse: 0.51843 | train_mse: 0.26877 | valid_rmsle: 0.01569 | valid_mae: 0.43287 | valid_rmse: 0.51732 | valid_mse: 0.26762 |  0:00:49s\n",
      "epoch 19 | loss: 0.22639 | train_rmsle: 0.01464 | train_mae: 0.38854 | train_rmse: 0.48512 | train_mse: 0.23534 | valid_rmsle: 0.01409 | valid_mae: 0.38904 | valid_rmse: 0.48116 | valid_mse: 0.23152 |  0:00:51s\n",
      "epoch 20 | loss: 0.2294  | train_rmsle: 0.01483 | train_mae: 0.39746 | train_rmse: 0.49113 | train_mse: 0.24121 | valid_rmsle: 0.01427 | valid_mae: 0.39842 | valid_rmse: 0.48701 | valid_mse: 0.23717 |  0:00:54s\n",
      "epoch 21 | loss: 0.2239  | train_rmsle: 0.01553 | train_mae: 0.41829 | train_rmse: 0.50783 | train_mse: 0.2579  | valid_rmsle: 0.01503 | valid_mae: 0.41957 | valid_rmse: 0.50492 | valid_mse: 0.25494 |  0:00:57s\n",
      "epoch 22 | loss: 0.2237  | train_rmsle: 0.01488 | train_mae: 0.4027  | train_rmse: 0.49411 | train_mse: 0.24414 | valid_rmsle: 0.01415 | valid_mae: 0.40152 | valid_rmse: 0.487   | valid_mse: 0.23717 |  0:00:59s\n",
      "epoch 23 | loss: 0.22021 | train_rmsle: 0.01451 | train_mae: 0.39184 | train_rmse: 0.48539 | train_mse: 0.23561 | valid_rmsle: 0.01395 | valid_mae: 0.39196 | valid_rmse: 0.4812  | valid_mse: 0.23156 |  0:01:02s\n",
      "epoch 24 | loss: 0.22364 | train_rmsle: 0.01446 | train_mae: 0.38856 | train_rmse: 0.48348 | train_mse: 0.23376 | valid_rmsle: 0.01413 | valid_mae: 0.39265 | valid_rmse: 0.48305 | valid_mse: 0.23334 |  0:01:05s\n",
      "epoch 25 | loss: 0.222   | train_rmsle: 0.01527 | train_mae: 0.41375 | train_rmse: 0.50319 | train_mse: 0.25321 | valid_rmsle: 0.01484 | valid_mae: 0.41515 | valid_rmse: 0.50111 | valid_mse: 0.25111 |  0:01:07s\n",
      "epoch 26 | loss: 0.22127 | train_rmsle: 0.01468 | train_mae: 0.39934 | train_rmse: 0.49027 | train_mse: 0.24036 | valid_rmsle: 0.01434 | valid_mae: 0.40176 | valid_rmse: 0.48971 | valid_mse: 0.23982 |  0:01:10s\n",
      "epoch 27 | loss: 0.22465 | train_rmsle: 0.01473 | train_mae: 0.40141 | train_rmse: 0.49183 | train_mse: 0.2419  | valid_rmsle: 0.01423 | valid_mae: 0.40018 | valid_rmse: 0.4883  | valid_mse: 0.23843 |  0:01:13s\n",
      "epoch 28 | loss: 0.22679 | train_rmsle: 0.01501 | train_mae: 0.37329 | train_rmse: 0.48485 | train_mse: 0.23508 | valid_rmsle: 0.01439 | valid_mae: 0.37352 | valid_rmse: 0.47968 | valid_mse: 0.2301  |  0:01:15s\n",
      "epoch 29 | loss: 0.2306  | train_rmsle: 0.01418 | train_mae: 0.38343 | train_rmse: 0.47752 | train_mse: 0.22802 | valid_rmsle: 0.01376 | valid_mae: 0.38382 | valid_rmse: 0.47545 | valid_mse: 0.22605 |  0:01:18s\n",
      "epoch 30 | loss: 0.218   | train_rmsle: 0.01403 | train_mae: 0.38369 | train_rmse: 0.4762  | train_mse: 0.22677 | valid_rmsle: 0.01368 | valid_mae: 0.38653 | valid_rmse: 0.47564 | valid_mse: 0.22623 |  0:01:21s\n",
      "epoch 31 | loss: 0.21493 | train_rmsle: 0.01429 | train_mae: 0.39493 | train_rmse: 0.48428 | train_mse: 0.23453 | valid_rmsle: 0.01393 | valid_mae: 0.39565 | valid_rmse: 0.4837  | valid_mse: 0.23397 |  0:01:24s\n",
      "epoch 32 | loss: 0.20927 | train_rmsle: 0.01341 | train_mae: 0.36677 | train_rmse: 0.4619  | train_mse: 0.21335 | valid_rmsle: 0.01296 | valid_mae: 0.3683  | valid_rmse: 0.4599  | valid_mse: 0.21151 |  0:01:26s\n",
      "epoch 33 | loss: 0.20775 | train_rmsle: 0.01362 | train_mae: 0.36264 | train_rmse: 0.46338 | train_mse: 0.21472 | valid_rmsle: 0.01311 | valid_mae: 0.36166 | valid_rmse: 0.46024 | valid_mse: 0.21183 |  0:01:28s\n",
      "epoch 34 | loss: 0.2018  | train_rmsle: 0.01327 | train_mae: 0.36491 | train_rmse: 0.45987 | train_mse: 0.21148 | valid_rmsle: 0.01267 | valid_mae: 0.36272 | valid_rmse: 0.45458 | valid_mse: 0.20664 |  0:01:30s\n",
      "epoch 35 | loss: 0.20129 | train_rmsle: 0.01335 | train_mae: 0.36058 | train_rmse: 0.46048 | train_mse: 0.21205 | valid_rmsle: 0.01251 | valid_mae: 0.35891 | valid_rmse: 0.45118 | valid_mse: 0.20356 |  0:01:33s\n",
      "epoch 36 | loss: 0.19472 | train_rmsle: 0.01259 | train_mae: 0.36116 | train_rmse: 0.4499  | train_mse: 0.20241 | valid_rmsle: 0.01233 | valid_mae: 0.36556 | valid_rmse: 0.4507  | valid_mse: 0.20313 |  0:01:35s\n",
      "epoch 37 | loss: 0.18858 | train_rmsle: 0.01251 | train_mae: 0.36537 | train_rmse: 0.45056 | train_mse: 0.203   | valid_rmsle: 0.01248 | valid_mae: 0.37344 | valid_rmse: 0.4554  | valid_mse: 0.20739 |  0:01:37s\n",
      "epoch 38 | loss: 0.17795 | train_rmsle: 0.01132 | train_mae: 0.32307 | train_rmse: 0.41909 | train_mse: 0.17564 | valid_rmsle: 0.01147 | valid_mae: 0.33184 | valid_rmse: 0.42822 | valid_mse: 0.18337 |  0:01:40s\n",
      "epoch 39 | loss: 0.16349 | train_rmsle: 0.01067 | train_mae: 0.31433 | train_rmse: 0.40714 | train_mse: 0.16576 | valid_rmsle: 0.01057 | valid_mae: 0.32321 | valid_rmse: 0.41174 | valid_mse: 0.16953 |  0:01:43s\n",
      "epoch 40 | loss: 0.15527 | train_rmsle: 0.0103  | train_mae: 0.30181 | train_rmse: 0.39766 | train_mse: 0.15813 | valid_rmsle: 0.00993 | valid_mae: 0.30696 | valid_rmse: 0.39673 | valid_mse: 0.1574  |  0:01:45s\n",
      "epoch 41 | loss: 0.14482 | train_rmsle: 0.00939 | train_mae: 0.29849 | train_rmse: 0.38213 | train_mse: 0.14602 | valid_rmsle: 0.00907 | valid_mae: 0.30254 | valid_rmse: 0.38152 | valid_mse: 0.14556 |  0:01:48s\n",
      "epoch 42 | loss: 0.13982 | train_rmsle: 0.00922 | train_mae: 0.28231 | train_rmse: 0.37396 | train_mse: 0.13985 | valid_rmsle: 0.00885 | valid_mae: 0.28759 | valid_rmse: 0.37246 | valid_mse: 0.13873 |  0:01:51s\n",
      "epoch 43 | loss: 0.1355  | train_rmsle: 0.00877 | train_mae: 0.28611 | train_rmse: 0.36816 | train_mse: 0.13554 | valid_rmsle: 0.00847 | valid_mae: 0.29286 | valid_rmse: 0.36886 | valid_mse: 0.13606 |  0:01:54s\n",
      "epoch 44 | loss: 0.13126 | train_rmsle: 0.0087  | train_mae: 0.28634 | train_rmse: 0.36778 | train_mse: 0.13526 | valid_rmsle: 0.00856 | valid_mae: 0.29473 | valid_rmse: 0.37205 | valid_mse: 0.13842 |  0:01:56s\n",
      "epoch 45 | loss: 0.12411 | train_rmsle: 0.00824 | train_mae: 0.27152 | train_rmse: 0.35514 | train_mse: 0.12613 | valid_rmsle: 0.00822 | valid_mae: 0.28295 | valid_rmse: 0.36135 | valid_mse: 0.13057 |  0:01:59s\n",
      "epoch 46 | loss: 0.11818 | train_rmsle: 0.00761 | train_mae: 0.25635 | train_rmse: 0.33799 | train_mse: 0.11423 | valid_rmsle: 0.00737 | valid_mae: 0.26307 | valid_rmse: 0.33932 | valid_mse: 0.11514 |  0:02:02s\n",
      "epoch 47 | loss: 0.11027 | train_rmsle: 0.00732 | train_mae: 0.24795 | train_rmse: 0.32994 | train_mse: 0.10886 | valid_rmsle: 0.00715 | valid_mae: 0.2536  | valid_rmse: 0.33268 | valid_mse: 0.11067 |  0:02:04s\n",
      "epoch 48 | loss: 0.10688 | train_rmsle: 0.0068  | train_mae: 0.24236 | train_rmse: 0.31892 | train_mse: 0.10171 | valid_rmsle: 0.00671 | valid_mae: 0.24912 | valid_rmse: 0.32324 | valid_mse: 0.10448 |  0:02:07s\n",
      "epoch 49 | loss: 0.10101 | train_rmsle: 0.00649 | train_mae: 0.23764 | train_rmse: 0.31176 | train_mse: 0.0972  | valid_rmsle: 0.00631 | valid_mae: 0.24224 | valid_rmse: 0.31325 | valid_mse: 0.09813 |  0:02:10s\n",
      "epoch 50 | loss: 0.09457 | train_rmsle: 0.00612 | train_mae: 0.2304  | train_rmse: 0.30245 | train_mse: 0.09148 | valid_rmsle: 0.0059  | valid_mae: 0.23596 | valid_rmse: 0.30256 | valid_mse: 0.09154 |  0:02:12s\n",
      "epoch 51 | loss: 0.09014 | train_rmsle: 0.00632 | train_mae: 0.24788 | train_rmse: 0.31385 | train_mse: 0.0985  | valid_rmsle: 0.0063  | valid_mae: 0.25824 | valid_rmse: 0.3182  | valid_mse: 0.10125 |  0:02:15s\n",
      "epoch 52 | loss: 0.09301 | train_rmsle: 0.00699 | train_mae: 0.24861 | train_rmse: 0.32658 | train_mse: 0.10666 | valid_rmsle: 0.00692 | valid_mae: 0.255   | valid_rmse: 0.33138 | valid_mse: 0.10981 |  0:02:18s\n",
      "epoch 53 | loss: 0.08836 | train_rmsle: 0.00555 | train_mae: 0.21444 | train_rmse: 0.28624 | train_mse: 0.08193 | valid_rmsle: 0.00552 | valid_mae: 0.22204 | valid_rmse: 0.29161 | valid_mse: 0.08504 |  0:02:20s\n",
      "epoch 54 | loss: 0.0802  | train_rmsle: 0.00512 | train_mae: 0.20469 | train_rmse: 0.27443 | train_mse: 0.07531 | valid_rmsle: 0.00524 | valid_mae: 0.2161  | valid_rmse: 0.28332 | valid_mse: 0.08027 |  0:02:23s\n",
      "epoch 55 | loss: 0.07663 | train_rmsle: 0.00515 | train_mae: 0.20694 | train_rmse: 0.27553 | train_mse: 0.07592 | valid_rmsle: 0.00531 | valid_mae: 0.21631 | valid_rmse: 0.28588 | valid_mse: 0.08173 |  0:02:26s\n",
      "epoch 56 | loss: 0.06764 | train_rmsle: 0.00449 | train_mae: 0.19452 | train_rmse: 0.25784 | train_mse: 0.06648 | valid_rmsle: 0.00473 | valid_mae: 0.20917 | valid_rmse: 0.27098 | valid_mse: 0.07343 |  0:02:29s\n",
      "epoch 57 | loss: 0.06548 | train_rmsle: 0.00408 | train_mae: 0.18572 | train_rmse: 0.24674 | train_mse: 0.06088 | valid_rmsle: 0.00439 | valid_mae: 0.20084 | valid_rmse: 0.2612  | valid_mse: 0.06822 |  0:02:31s\n",
      "epoch 58 | loss: 0.06261 | train_rmsle: 0.00393 | train_mae: 0.18119 | train_rmse: 0.24081 | train_mse: 0.05799 | valid_rmsle: 0.00428 | valid_mae: 0.19724 | valid_rmse: 0.25791 | valid_mse: 0.06652 |  0:02:34s\n",
      "epoch 59 | loss: 0.05532 | train_rmsle: 0.00356 | train_mae: 0.17174 | train_rmse: 0.22865 | train_mse: 0.05228 | valid_rmsle: 0.00372 | valid_mae: 0.18292 | valid_rmse: 0.2401  | valid_mse: 0.05765 |  0:02:37s\n",
      "epoch 60 | loss: 0.05406 | train_rmsle: 0.00355 | train_mae: 0.17381 | train_rmse: 0.22992 | train_mse: 0.05286 | valid_rmsle: 0.00375 | valid_mae: 0.18618 | valid_rmse: 0.24138 | valid_mse: 0.05826 |  0:02:39s\n",
      "epoch 61 | loss: 0.05543 | train_rmsle: 0.00329 | train_mae: 0.16722 | train_rmse: 0.22143 | train_mse: 0.04903 | valid_rmsle: 0.00351 | valid_mae: 0.1807  | valid_rmse: 0.23404 | valid_mse: 0.05477 |  0:02:42s\n",
      "epoch 62 | loss: 0.04808 | train_rmsle: 0.00282 | train_mae: 0.15349 | train_rmse: 0.20468 | train_mse: 0.04189 | valid_rmsle: 0.00291 | valid_mae: 0.16525 | valid_rmse: 0.21383 | valid_mse: 0.04572 |  0:02:45s\n",
      "epoch 63 | loss: 0.04301 | train_rmsle: 0.00286 | train_mae: 0.15236 | train_rmse: 0.20395 | train_mse: 0.04159 | valid_rmsle: 0.00294 | valid_mae: 0.16218 | valid_rmse: 0.21323 | valid_mse: 0.04547 |  0:02:47s\n",
      "epoch 64 | loss: 0.03849 | train_rmsle: 0.00244 | train_mae: 0.14111 | train_rmse: 0.18898 | train_mse: 0.03571 | valid_rmsle: 0.00251 | valid_mae: 0.14962 | valid_rmse: 0.19693 | valid_mse: 0.03878 |  0:02:50s\n",
      "epoch 65 | loss: 0.03674 | train_rmsle: 0.00216 | train_mae: 0.13248 | train_rmse: 0.17779 | train_mse: 0.03161 | valid_rmsle: 0.00219 | valid_mae: 0.14014 | valid_rmse: 0.18315 | valid_mse: 0.03354 |  0:02:53s\n",
      "epoch 66 | loss: 0.03336 | train_rmsle: 0.00216 | train_mae: 0.12948 | train_rmse: 0.17584 | train_mse: 0.03092 | valid_rmsle: 0.00214 | valid_mae: 0.13529 | valid_rmse: 0.17902 | valid_mse: 0.03205 |  0:02:55s\n",
      "epoch 67 | loss: 0.02985 | train_rmsle: 0.00192 | train_mae: 0.12252 | train_rmse: 0.1662  | train_mse: 0.02762 | valid_rmsle: 0.00187 | valid_mae: 0.12943 | valid_rmse: 0.1683  | valid_mse: 0.02832 |  0:02:58s\n",
      "epoch 68 | loss: 0.03111 | train_rmsle: 0.00216 | train_mae: 0.13348 | train_rmse: 0.17723 | train_mse: 0.03141 | valid_rmsle: 0.00205 | valid_mae: 0.13614 | valid_rmse: 0.17701 | valid_mse: 0.03133 |  0:03:01s\n",
      "epoch 69 | loss: 0.03104 | train_rmsle: 0.00188 | train_mae: 0.12885 | train_rmse: 0.1698  | train_mse: 0.02883 | valid_rmsle: 0.0019  | valid_mae: 0.13567 | valid_rmse: 0.17447 | valid_mse: 0.03044 |  0:03:03s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_valid_mse = 0.02832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.035824932902846975 RMSE: 0.189274755059535 R2: 0.8414168260511824 MAE: 0.14122447899747048\n",
      "=====================================\n",
      "[26/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.5006  | train_rmsle: 0.38629 | train_mae: 1.96568 | train_rmse: 2.02437 | train_mse: 4.09809 | valid_rmsle: 0.38778 | valid_mae: 1.97191 | valid_rmse: 2.02933 | valid_mse: 4.11816 |  0:00:02s\n",
      "epoch 1  | loss: 0.81048 | train_rmsle: 0.07202 | train_mae: 0.95955 | train_rmse: 1.05119 | train_mse: 1.10501 | valid_rmsle: 0.07222 | valid_mae: 0.96167 | valid_rmse: 1.05433 | valid_mse: 1.11161 |  0:00:05s\n",
      "epoch 2  | loss: 0.30723 | train_rmsle: 0.02493 | train_mae: 0.56295 | train_rmse: 0.65304 | train_mse: 0.42646 | valid_rmsle: 0.02471 | valid_mae: 0.56362 | valid_rmse: 0.65391 | valid_mse: 0.4276  |  0:00:08s\n",
      "epoch 3  | loss: 0.27624 | train_rmsle: 0.03998 | train_mae: 0.72044 | train_rmse: 0.81339 | train_mse: 0.6616  | valid_rmsle: 0.03997 | valid_mae: 0.7205  | valid_rmse: 0.81571 | valid_mse: 0.66538 |  0:00:10s\n",
      "epoch 4  | loss: 0.25353 | train_rmsle: 0.03248 | train_mae: 0.64806 | train_rmse: 0.74008 | train_mse: 0.54771 | valid_rmsle: 0.0324  | valid_mae: 0.64786 | valid_rmse: 0.74208 | valid_mse: 0.55069 |  0:00:13s\n",
      "epoch 5  | loss: 0.28372 | train_rmsle: 0.01704 | train_mae: 0.44881 | train_rmse: 0.53646 | train_mse: 0.28779 | valid_rmsle: 0.01658 | valid_mae: 0.44936 | valid_rmse: 0.53414 | valid_mse: 0.28531 |  0:00:16s\n",
      "epoch 6  | loss: 0.2924  | train_rmsle: 0.03551 | train_mae: 0.67831 | train_rmse: 0.77068 | train_mse: 0.59395 | valid_rmsle: 0.03539 | valid_mae: 0.67741 | valid_rmse: 0.7723  | valid_mse: 0.59644 |  0:00:18s\n",
      "epoch 7  | loss: 0.29245 | train_rmsle: 0.02764 | train_mae: 0.59474 | train_rmse: 0.68597 | train_mse: 0.47055 | valid_rmsle: 0.02737 | valid_mae: 0.59448 | valid_rmse: 0.686   | valid_mse: 0.4706  |  0:00:21s\n",
      "epoch 8  | loss: 0.24724 | train_rmsle: 0.01757 | train_mae: 0.4579  | train_rmse: 0.54558 | train_mse: 0.29766 | valid_rmsle: 0.01707 | valid_mae: 0.45862 | valid_rmse: 0.54272 | valid_mse: 0.29455 |  0:00:24s\n",
      "epoch 9  | loss: 0.23568 | train_rmsle: 0.01849 | train_mae: 0.47328 | train_rmse: 0.56097 | train_mse: 0.31469 | valid_rmsle: 0.01814 | valid_mae: 0.47516 | valid_rmse: 0.56028 | valid_mse: 0.31391 |  0:00:26s\n",
      "epoch 10 | loss: 0.2298  | train_rmsle: 0.02123 | train_mae: 0.51433 | train_rmse: 0.60291 | train_mse: 0.3635  | valid_rmsle: 0.02089 | valid_mae: 0.51613 | valid_rmse: 0.60232 | valid_mse: 0.36279 |  0:00:29s\n",
      "epoch 11 | loss: 0.22932 | train_rmsle: 0.01558 | train_mae: 0.41838 | train_rmse: 0.50832 | train_mse: 0.25839 | valid_rmsle: 0.01503 | valid_mae: 0.41841 | valid_rmse: 0.50436 | valid_mse: 0.25438 |  0:00:32s\n",
      "epoch 12 | loss: 0.23527 | train_rmsle: 0.01642 | train_mae: 0.4362  | train_rmse: 0.52485 | train_mse: 0.27547 | valid_rmsle: 0.01594 | valid_mae: 0.43771 | valid_rmse: 0.52204 | valid_mse: 0.27252 |  0:00:35s\n",
      "epoch 13 | loss: 0.22838 | train_rmsle: 0.01685 | train_mae: 0.4438  | train_rmse: 0.53254 | train_mse: 0.2836  | valid_rmsle: 0.01651 | valid_mae: 0.44807 | valid_rmse: 0.53202 | valid_mse: 0.28305 |  0:00:37s\n",
      "epoch 14 | loss: 0.22595 | train_rmsle: 0.01495 | train_mae: 0.40206 | train_rmse: 0.49437 | train_mse: 0.2444  | valid_rmsle: 0.01448 | valid_mae: 0.40408 | valid_rmse: 0.49196 | valid_mse: 0.24203 |  0:00:39s\n",
      "epoch 15 | loss: 0.22644 | train_rmsle: 0.01603 | train_mae: 0.42888 | train_rmse: 0.51771 | train_mse: 0.26802 | valid_rmsle: 0.01557 | valid_mae: 0.43061 | valid_rmse: 0.51533 | valid_mse: 0.26557 |  0:00:42s\n",
      "epoch 16 | loss: 0.22733 | train_rmsle: 0.01479 | train_mae: 0.39802 | train_rmse: 0.49088 | train_mse: 0.24096 | valid_rmsle: 0.01423 | valid_mae: 0.39765 | valid_rmse: 0.48655 | valid_mse: 0.23673 |  0:00:44s\n",
      "epoch 17 | loss: 0.22782 | train_rmsle: 0.01453 | train_mae: 0.38362 | train_rmse: 0.48205 | train_mse: 0.23237 | valid_rmsle: 0.01398 | valid_mae: 0.38435 | valid_rmse: 0.47784 | valid_mse: 0.22833 |  0:00:46s\n",
      "epoch 18 | loss: 0.23185 | train_rmsle: 0.01606 | train_mae: 0.43001 | train_rmse: 0.51843 | train_mse: 0.26877 | valid_rmsle: 0.01569 | valid_mae: 0.43287 | valid_rmse: 0.51732 | valid_mse: 0.26762 |  0:00:49s\n",
      "epoch 19 | loss: 0.22639 | train_rmsle: 0.01464 | train_mae: 0.38854 | train_rmse: 0.48512 | train_mse: 0.23534 | valid_rmsle: 0.01409 | valid_mae: 0.38904 | valid_rmse: 0.48116 | valid_mse: 0.23152 |  0:00:51s\n",
      "epoch 20 | loss: 0.2294  | train_rmsle: 0.01483 | train_mae: 0.39746 | train_rmse: 0.49113 | train_mse: 0.24121 | valid_rmsle: 0.01427 | valid_mae: 0.39842 | valid_rmse: 0.48701 | valid_mse: 0.23717 |  0:00:54s\n",
      "epoch 21 | loss: 0.2239  | train_rmsle: 0.01553 | train_mae: 0.41829 | train_rmse: 0.50783 | train_mse: 0.2579  | valid_rmsle: 0.01503 | valid_mae: 0.41957 | valid_rmse: 0.50492 | valid_mse: 0.25494 |  0:00:57s\n",
      "epoch 22 | loss: 0.2237  | train_rmsle: 0.01488 | train_mae: 0.4027  | train_rmse: 0.49411 | train_mse: 0.24414 | valid_rmsle: 0.01415 | valid_mae: 0.40152 | valid_rmse: 0.487   | valid_mse: 0.23717 |  0:00:59s\n",
      "epoch 23 | loss: 0.22021 | train_rmsle: 0.01451 | train_mae: 0.39184 | train_rmse: 0.48539 | train_mse: 0.23561 | valid_rmsle: 0.01395 | valid_mae: 0.39196 | valid_rmse: 0.4812  | valid_mse: 0.23156 |  0:01:02s\n",
      "epoch 24 | loss: 0.22364 | train_rmsle: 0.01446 | train_mae: 0.38856 | train_rmse: 0.48348 | train_mse: 0.23376 | valid_rmsle: 0.01413 | valid_mae: 0.39265 | valid_rmse: 0.48305 | valid_mse: 0.23334 |  0:01:05s\n",
      "epoch 25 | loss: 0.222   | train_rmsle: 0.01527 | train_mae: 0.41375 | train_rmse: 0.50319 | train_mse: 0.25321 | valid_rmsle: 0.01484 | valid_mae: 0.41515 | valid_rmse: 0.50111 | valid_mse: 0.25111 |  0:01:07s\n",
      "epoch 26 | loss: 0.22127 | train_rmsle: 0.01468 | train_mae: 0.39934 | train_rmse: 0.49027 | train_mse: 0.24036 | valid_rmsle: 0.01434 | valid_mae: 0.40176 | valid_rmse: 0.48971 | valid_mse: 0.23982 |  0:01:10s\n",
      "epoch 27 | loss: 0.22465 | train_rmsle: 0.01473 | train_mae: 0.40141 | train_rmse: 0.49183 | train_mse: 0.2419  | valid_rmsle: 0.01423 | valid_mae: 0.40018 | valid_rmse: 0.4883  | valid_mse: 0.23843 |  0:01:12s\n",
      "epoch 28 | loss: 0.22679 | train_rmsle: 0.01501 | train_mae: 0.37329 | train_rmse: 0.48485 | train_mse: 0.23508 | valid_rmsle: 0.01439 | valid_mae: 0.37352 | valid_rmse: 0.47968 | valid_mse: 0.2301  |  0:01:15s\n",
      "epoch 29 | loss: 0.2306  | train_rmsle: 0.01418 | train_mae: 0.38343 | train_rmse: 0.47752 | train_mse: 0.22802 | valid_rmsle: 0.01376 | valid_mae: 0.38382 | valid_rmse: 0.47545 | valid_mse: 0.22605 |  0:01:18s\n",
      "epoch 30 | loss: 0.218   | train_rmsle: 0.01403 | train_mae: 0.38369 | train_rmse: 0.4762  | train_mse: 0.22677 | valid_rmsle: 0.01368 | valid_mae: 0.38653 | valid_rmse: 0.47564 | valid_mse: 0.22623 |  0:01:20s\n",
      "epoch 31 | loss: 0.21493 | train_rmsle: 0.01429 | train_mae: 0.39493 | train_rmse: 0.48428 | train_mse: 0.23453 | valid_rmsle: 0.01393 | valid_mae: 0.39565 | valid_rmse: 0.4837  | valid_mse: 0.23397 |  0:01:23s\n",
      "epoch 32 | loss: 0.20927 | train_rmsle: 0.01341 | train_mae: 0.36677 | train_rmse: 0.4619  | train_mse: 0.21335 | valid_rmsle: 0.01296 | valid_mae: 0.3683  | valid_rmse: 0.4599  | valid_mse: 0.21151 |  0:01:26s\n",
      "epoch 33 | loss: 0.20775 | train_rmsle: 0.01362 | train_mae: 0.36264 | train_rmse: 0.46338 | train_mse: 0.21472 | valid_rmsle: 0.01311 | valid_mae: 0.36166 | valid_rmse: 0.46024 | valid_mse: 0.21183 |  0:01:28s\n",
      "epoch 34 | loss: 0.2018  | train_rmsle: 0.01327 | train_mae: 0.36491 | train_rmse: 0.45987 | train_mse: 0.21148 | valid_rmsle: 0.01267 | valid_mae: 0.36272 | valid_rmse: 0.45458 | valid_mse: 0.20664 |  0:01:31s\n",
      "epoch 35 | loss: 0.20129 | train_rmsle: 0.01335 | train_mae: 0.36058 | train_rmse: 0.46048 | train_mse: 0.21205 | valid_rmsle: 0.01251 | valid_mae: 0.35891 | valid_rmse: 0.45118 | valid_mse: 0.20356 |  0:01:34s\n",
      "epoch 36 | loss: 0.19472 | train_rmsle: 0.01259 | train_mae: 0.36116 | train_rmse: 0.4499  | train_mse: 0.20241 | valid_rmsle: 0.01233 | valid_mae: 0.36556 | valid_rmse: 0.4507  | valid_mse: 0.20313 |  0:01:36s\n",
      "epoch 37 | loss: 0.18858 | train_rmsle: 0.01251 | train_mae: 0.36537 | train_rmse: 0.45056 | train_mse: 0.203   | valid_rmsle: 0.01248 | valid_mae: 0.37344 | valid_rmse: 0.4554  | valid_mse: 0.20739 |  0:01:38s\n",
      "epoch 38 | loss: 0.17795 | train_rmsle: 0.01132 | train_mae: 0.32307 | train_rmse: 0.41909 | train_mse: 0.17564 | valid_rmsle: 0.01147 | valid_mae: 0.33184 | valid_rmse: 0.42822 | valid_mse: 0.18337 |  0:01:41s\n",
      "epoch 39 | loss: 0.16349 | train_rmsle: 0.01067 | train_mae: 0.31433 | train_rmse: 0.40714 | train_mse: 0.16576 | valid_rmsle: 0.01057 | valid_mae: 0.32321 | valid_rmse: 0.41174 | valid_mse: 0.16953 |  0:01:43s\n",
      "epoch 40 | loss: 0.15527 | train_rmsle: 0.0103  | train_mae: 0.30181 | train_rmse: 0.39766 | train_mse: 0.15813 | valid_rmsle: 0.00993 | valid_mae: 0.30696 | valid_rmse: 0.39673 | valid_mse: 0.1574  |  0:01:45s\n",
      "epoch 41 | loss: 0.14482 | train_rmsle: 0.00939 | train_mae: 0.29849 | train_rmse: 0.38213 | train_mse: 0.14602 | valid_rmsle: 0.00907 | valid_mae: 0.30254 | valid_rmse: 0.38152 | valid_mse: 0.14556 |  0:01:47s\n",
      "epoch 42 | loss: 0.13982 | train_rmsle: 0.00922 | train_mae: 0.28231 | train_rmse: 0.37396 | train_mse: 0.13985 | valid_rmsle: 0.00885 | valid_mae: 0.28759 | valid_rmse: 0.37246 | valid_mse: 0.13873 |  0:01:50s\n",
      "epoch 43 | loss: 0.1355  | train_rmsle: 0.00877 | train_mae: 0.28611 | train_rmse: 0.36816 | train_mse: 0.13554 | valid_rmsle: 0.00847 | valid_mae: 0.29286 | valid_rmse: 0.36886 | valid_mse: 0.13606 |  0:01:53s\n",
      "epoch 44 | loss: 0.13126 | train_rmsle: 0.0087  | train_mae: 0.28634 | train_rmse: 0.36778 | train_mse: 0.13526 | valid_rmsle: 0.00856 | valid_mae: 0.29473 | valid_rmse: 0.37205 | valid_mse: 0.13842 |  0:01:55s\n",
      "epoch 45 | loss: 0.12411 | train_rmsle: 0.00824 | train_mae: 0.27152 | train_rmse: 0.35514 | train_mse: 0.12613 | valid_rmsle: 0.00822 | valid_mae: 0.28295 | valid_rmse: 0.36135 | valid_mse: 0.13057 |  0:01:58s\n",
      "epoch 46 | loss: 0.11818 | train_rmsle: 0.00761 | train_mae: 0.25635 | train_rmse: 0.33799 | train_mse: 0.11423 | valid_rmsle: 0.00737 | valid_mae: 0.26307 | valid_rmse: 0.33932 | valid_mse: 0.11514 |  0:02:00s\n",
      "epoch 47 | loss: 0.11027 | train_rmsle: 0.00732 | train_mae: 0.24795 | train_rmse: 0.32994 | train_mse: 0.10886 | valid_rmsle: 0.00715 | valid_mae: 0.2536  | valid_rmse: 0.33268 | valid_mse: 0.11067 |  0:02:03s\n",
      "epoch 48 | loss: 0.10688 | train_rmsle: 0.0068  | train_mae: 0.24236 | train_rmse: 0.31892 | train_mse: 0.10171 | valid_rmsle: 0.00671 | valid_mae: 0.24912 | valid_rmse: 0.32324 | valid_mse: 0.10448 |  0:02:05s\n",
      "epoch 49 | loss: 0.10101 | train_rmsle: 0.00649 | train_mae: 0.23764 | train_rmse: 0.31176 | train_mse: 0.0972  | valid_rmsle: 0.00631 | valid_mae: 0.24224 | valid_rmse: 0.31325 | valid_mse: 0.09813 |  0:02:07s\n",
      "epoch 50 | loss: 0.09457 | train_rmsle: 0.00612 | train_mae: 0.2304  | train_rmse: 0.30245 | train_mse: 0.09148 | valid_rmsle: 0.0059  | valid_mae: 0.23596 | valid_rmse: 0.30256 | valid_mse: 0.09154 |  0:02:10s\n",
      "epoch 51 | loss: 0.09014 | train_rmsle: 0.00632 | train_mae: 0.24788 | train_rmse: 0.31385 | train_mse: 0.0985  | valid_rmsle: 0.0063  | valid_mae: 0.25824 | valid_rmse: 0.3182  | valid_mse: 0.10125 |  0:02:13s\n",
      "epoch 52 | loss: 0.09301 | train_rmsle: 0.00699 | train_mae: 0.24861 | train_rmse: 0.32658 | train_mse: 0.10666 | valid_rmsle: 0.00692 | valid_mae: 0.255   | valid_rmse: 0.33138 | valid_mse: 0.10981 |  0:02:15s\n",
      "epoch 53 | loss: 0.08836 | train_rmsle: 0.00555 | train_mae: 0.21444 | train_rmse: 0.28624 | train_mse: 0.08193 | valid_rmsle: 0.00552 | valid_mae: 0.22204 | valid_rmse: 0.29161 | valid_mse: 0.08504 |  0:02:18s\n",
      "epoch 54 | loss: 0.0802  | train_rmsle: 0.00512 | train_mae: 0.20469 | train_rmse: 0.27443 | train_mse: 0.07531 | valid_rmsle: 0.00524 | valid_mae: 0.2161  | valid_rmse: 0.28332 | valid_mse: 0.08027 |  0:02:21s\n",
      "epoch 55 | loss: 0.07663 | train_rmsle: 0.00515 | train_mae: 0.20694 | train_rmse: 0.27553 | train_mse: 0.07592 | valid_rmsle: 0.00531 | valid_mae: 0.21631 | valid_rmse: 0.28588 | valid_mse: 0.08173 |  0:02:23s\n",
      "epoch 56 | loss: 0.06764 | train_rmsle: 0.00449 | train_mae: 0.19452 | train_rmse: 0.25784 | train_mse: 0.06648 | valid_rmsle: 0.00473 | valid_mae: 0.20917 | valid_rmse: 0.27098 | valid_mse: 0.07343 |  0:02:26s\n",
      "epoch 57 | loss: 0.06548 | train_rmsle: 0.00408 | train_mae: 0.18572 | train_rmse: 0.24674 | train_mse: 0.06088 | valid_rmsle: 0.00439 | valid_mae: 0.20084 | valid_rmse: 0.2612  | valid_mse: 0.06822 |  0:02:29s\n",
      "epoch 58 | loss: 0.06261 | train_rmsle: 0.00393 | train_mae: 0.18119 | train_rmse: 0.24081 | train_mse: 0.05799 | valid_rmsle: 0.00428 | valid_mae: 0.19724 | valid_rmse: 0.25791 | valid_mse: 0.06652 |  0:02:31s\n",
      "epoch 59 | loss: 0.05532 | train_rmsle: 0.00356 | train_mae: 0.17174 | train_rmse: 0.22865 | train_mse: 0.05228 | valid_rmsle: 0.00372 | valid_mae: 0.18292 | valid_rmse: 0.2401  | valid_mse: 0.05765 |  0:02:34s\n",
      "epoch 60 | loss: 0.05406 | train_rmsle: 0.00355 | train_mae: 0.17381 | train_rmse: 0.22992 | train_mse: 0.05286 | valid_rmsle: 0.00375 | valid_mae: 0.18618 | valid_rmse: 0.24138 | valid_mse: 0.05826 |  0:02:37s\n",
      "epoch 61 | loss: 0.05543 | train_rmsle: 0.00329 | train_mae: 0.16722 | train_rmse: 0.22143 | train_mse: 0.04903 | valid_rmsle: 0.00351 | valid_mae: 0.1807  | valid_rmse: 0.23404 | valid_mse: 0.05477 |  0:02:39s\n",
      "epoch 62 | loss: 0.04808 | train_rmsle: 0.00282 | train_mae: 0.15349 | train_rmse: 0.20468 | train_mse: 0.04189 | valid_rmsle: 0.00291 | valid_mae: 0.16525 | valid_rmse: 0.21383 | valid_mse: 0.04572 |  0:02:42s\n",
      "epoch 63 | loss: 0.04301 | train_rmsle: 0.00286 | train_mae: 0.15236 | train_rmse: 0.20395 | train_mse: 0.04159 | valid_rmsle: 0.00294 | valid_mae: 0.16218 | valid_rmse: 0.21323 | valid_mse: 0.04547 |  0:02:45s\n",
      "epoch 64 | loss: 0.03849 | train_rmsle: 0.00244 | train_mae: 0.14111 | train_rmse: 0.18898 | train_mse: 0.03571 | valid_rmsle: 0.00251 | valid_mae: 0.14962 | valid_rmse: 0.19693 | valid_mse: 0.03878 |  0:02:48s\n",
      "epoch 65 | loss: 0.03674 | train_rmsle: 0.00216 | train_mae: 0.13248 | train_rmse: 0.17779 | train_mse: 0.03161 | valid_rmsle: 0.00219 | valid_mae: 0.14014 | valid_rmse: 0.18315 | valid_mse: 0.03354 |  0:02:50s\n",
      "epoch 66 | loss: 0.03336 | train_rmsle: 0.00216 | train_mae: 0.12948 | train_rmse: 0.17584 | train_mse: 0.03092 | valid_rmsle: 0.00214 | valid_mae: 0.13529 | valid_rmse: 0.17902 | valid_mse: 0.03205 |  0:02:53s\n",
      "epoch 67 | loss: 0.02985 | train_rmsle: 0.00192 | train_mae: 0.12252 | train_rmse: 0.1662  | train_mse: 0.02762 | valid_rmsle: 0.00187 | valid_mae: 0.12943 | valid_rmse: 0.1683  | valid_mse: 0.02832 |  0:02:56s\n",
      "epoch 68 | loss: 0.03111 | train_rmsle: 0.00216 | train_mae: 0.13348 | train_rmse: 0.17723 | train_mse: 0.03141 | valid_rmsle: 0.00205 | valid_mae: 0.13614 | valid_rmse: 0.17701 | valid_mse: 0.03133 |  0:02:58s\n",
      "epoch 69 | loss: 0.03104 | train_rmsle: 0.00188 | train_mae: 0.12885 | train_rmse: 0.1698  | train_mse: 0.02883 | valid_rmsle: 0.0019  | valid_mae: 0.13567 | valid_rmse: 0.17447 | valid_mse: 0.03044 |  0:03:01s\n",
      "epoch 70 | loss: 0.02975 | train_rmsle: 0.00211 | train_mae: 0.13847 | train_rmse: 0.17907 | train_mse: 0.03206 | valid_rmsle: 0.00207 | valid_mae: 0.14328 | valid_rmse: 0.18128 | valid_mse: 0.03286 |  0:03:04s\n",
      "epoch 71 | loss: 0.03262 | train_rmsle: 0.00177 | train_mae: 0.1194  | train_rmse: 0.15954 | train_mse: 0.02545 | valid_rmsle: 0.00168 | valid_mae: 0.12279 | valid_rmse: 0.15968 | valid_mse: 0.0255  |  0:03:06s\n",
      "epoch 72 | loss: 0.02628 | train_rmsle: 0.00196 | train_mae: 0.13301 | train_rmse: 0.17139 | train_mse: 0.02937 | valid_rmsle: 0.00198 | valid_mae: 0.13709 | valid_rmse: 0.17553 | valid_mse: 0.03081 |  0:03:09s\n",
      "epoch 73 | loss: 0.02461 | train_rmsle: 0.00147 | train_mae: 0.11334 | train_rmse: 0.14825 | train_mse: 0.02198 | valid_rmsle: 0.0015  | valid_mae: 0.11926 | valid_rmse: 0.15314 | valid_mse: 0.02345 |  0:03:11s\n",
      "epoch 74 | loss: 0.02133 | train_rmsle: 0.0018  | train_mae: 0.11523 | train_rmse: 0.15988 | train_mse: 0.02556 | valid_rmsle: 0.00179 | valid_mae: 0.1192  | valid_rmse: 0.16299 | valid_mse: 0.02657 |  0:03:14s\n",
      "epoch 75 | loss: 0.02257 | train_rmsle: 0.00151 | train_mae: 0.11256 | train_rmse: 0.15004 | train_mse: 0.02251 | valid_rmsle: 0.0016  | valid_mae: 0.11776 | valid_rmse: 0.15687 | valid_mse: 0.02461 |  0:03:16s\n",
      "epoch 76 | loss: 0.02286 | train_rmsle: 0.00165 | train_mae: 0.13599 | train_rmse: 0.16725 | train_mse: 0.02797 | valid_rmsle: 0.00169 | valid_mae: 0.14182 | valid_rmse: 0.17178 | valid_mse: 0.02951 |  0:03:18s\n",
      "epoch 77 | loss: 0.02379 | train_rmsle: 0.00111 | train_mae: 0.09618 | train_rmse: 0.12796 | train_mse: 0.01637 | valid_rmsle: 0.00114 | valid_mae: 0.10319 | valid_rmse: 0.13359 | valid_mse: 0.01785 |  0:03:20s\n",
      "epoch 78 | loss: 0.01931 | train_rmsle: 0.00105 | train_mae: 0.09144 | train_rmse: 0.12261 | train_mse: 0.01503 | valid_rmsle: 0.00106 | valid_mae: 0.09571 | valid_rmse: 0.1277  | valid_mse: 0.01631 |  0:03:22s\n",
      "epoch 79 | loss: 0.0199  | train_rmsle: 0.00123 | train_mae: 0.09902 | train_rmse: 0.13283 | train_mse: 0.01764 | valid_rmsle: 0.00124 | valid_mae: 0.10435 | valid_rmse: 0.13782 | valid_mse: 0.019   |  0:03:24s\n",
      "epoch 80 | loss: 0.0166  | train_rmsle: 0.00088 | train_mae: 0.08713 | train_rmse: 0.11605 | train_mse: 0.01347 | valid_rmsle: 0.00101 | valid_mae: 0.0958  | valid_rmse: 0.12636 | valid_mse: 0.01597 |  0:03:27s\n",
      "epoch 81 | loss: 0.0181  | train_rmsle: 0.00129 | train_mae: 0.10571 | train_rmse: 0.13708 | train_mse: 0.01879 | valid_rmsle: 0.00126 | valid_mae: 0.10968 | valid_rmse: 0.13914 | valid_mse: 0.01936 |  0:03:29s\n",
      "epoch 82 | loss: 0.02088 | train_rmsle: 0.00142 | train_mae: 0.10962 | train_rmse: 0.14253 | train_mse: 0.02031 | valid_rmsle: 0.00142 | valid_mae: 0.11247 | valid_rmse: 0.14579 | valid_mse: 0.02126 |  0:03:32s\n",
      "epoch 83 | loss: 0.02001 | train_rmsle: 0.00085 | train_mae: 0.08822 | train_rmse: 0.11547 | train_mse: 0.01333 | valid_rmsle: 0.00093 | valid_mae: 0.0944  | valid_rmse: 0.12257 | valid_mse: 0.01502 |  0:03:34s\n",
      "epoch 84 | loss: 0.02087 | train_rmsle: 0.00131 | train_mae: 0.1185  | train_rmse: 0.15093 | train_mse: 0.02278 | valid_rmsle: 0.00145 | valid_mae: 0.12422 | valid_rmse: 0.15859 | valid_mse: 0.02515 |  0:03:37s\n",
      "epoch 85 | loss: 0.0201  | train_rmsle: 0.00182 | train_mae: 0.14885 | train_rmse: 0.17896 | train_mse: 0.03203 | valid_rmsle: 0.00198 | valid_mae: 0.15467 | valid_rmse: 0.18512 | valid_mse: 0.03427 |  0:03:40s\n",
      "epoch 86 | loss: 0.0226  | train_rmsle: 0.00146 | train_mae: 0.13072 | train_rmse: 0.16188 | train_mse: 0.02621 | valid_rmsle: 0.00158 | valid_mae: 0.13725 | valid_rmse: 0.16799 | valid_mse: 0.02822 |  0:03:42s\n",
      "epoch 87 | loss: 0.02137 | train_rmsle: 0.00097 | train_mae: 0.09689 | train_rmse: 0.12588 | train_mse: 0.01585 | valid_rmsle: 0.00111 | valid_mae: 0.10367 | valid_rmse: 0.13474 | valid_mse: 0.01815 |  0:03:45s\n",
      "epoch 88 | loss: 0.01896 | train_rmsle: 0.00086 | train_mae: 0.08733 | train_rmse: 0.11676 | train_mse: 0.01363 | valid_rmsle: 0.00095 | valid_mae: 0.09277 | valid_rmse: 0.12405 | valid_mse: 0.01539 |  0:03:48s\n",
      "epoch 89 | loss: 0.01749 | train_rmsle: 0.00088 | train_mae: 0.08744 | train_rmse: 0.11586 | train_mse: 0.01342 | valid_rmsle: 0.00093 | valid_mae: 0.09235 | valid_rmse: 0.12176 | valid_mse: 0.01483 |  0:03:51s\n",
      "epoch 90 | loss: 0.01584 | train_rmsle: 0.00074 | train_mae: 0.08637 | train_rmse: 0.11332 | train_mse: 0.01284 | valid_rmsle: 0.0009  | valid_mae: 0.09471 | valid_rmse: 0.12478 | valid_mse: 0.01557 |  0:03:53s\n",
      "epoch 91 | loss: 0.01657 | train_rmsle: 0.00068 | train_mae: 0.07749 | train_rmse: 0.10257 | train_mse: 0.01052 | valid_rmsle: 0.00075 | valid_mae: 0.08401 | valid_rmse: 0.10997 | valid_mse: 0.01209 |  0:03:56s\n",
      "epoch 92 | loss: 0.01725 | train_rmsle: 0.00071 | train_mae: 0.07545 | train_rmse: 0.10183 | train_mse: 0.01037 | valid_rmsle: 0.00074 | valid_mae: 0.08071 | valid_rmse: 0.108   | valid_mse: 0.01166 |  0:03:59s\n",
      "epoch 93 | loss: 0.01444 | train_rmsle: 0.00051 | train_mae: 0.0687  | train_rmse: 0.09075 | train_mse: 0.00824 | valid_rmsle: 0.00059 | valid_mae: 0.07612 | valid_rmse: 0.09893 | valid_mse: 0.00979 |  0:04:01s\n",
      "epoch 94 | loss: 0.01506 | train_rmsle: 0.00096 | train_mae: 0.10995 | train_rmse: 0.13142 | train_mse: 0.01727 | valid_rmsle: 0.00106 | valid_mae: 0.11533 | valid_rmse: 0.13821 | valid_mse: 0.0191  |  0:04:04s\n",
      "epoch 95 | loss: 0.01786 | train_rmsle: 0.00055 | train_mae: 0.07421 | train_rmse: 0.09633 | train_mse: 0.00928 | valid_rmsle: 0.00066 | valid_mae: 0.08042 | valid_rmse: 0.1058  | valid_mse: 0.01119 |  0:04:07s\n",
      "epoch 96 | loss: 0.01357 | train_rmsle: 0.00175 | train_mae: 0.0957  | train_rmse: 0.17275 | train_mse: 0.02984 | valid_rmsle: 0.00243 | valid_mae: 0.10613 | valid_rmse: 0.20133 | valid_mse: 0.04053 |  0:04:09s\n",
      "epoch 97 | loss: 0.01302 | train_rmsle: 0.00075 | train_mae: 0.08929 | train_rmse: 0.11033 | train_mse: 0.01217 | valid_rmsle: 0.00088 | valid_mae: 0.09609 | valid_rmse: 0.11976 | valid_mse: 0.01434 |  0:04:12s\n",
      "epoch 98 | loss: 0.0127  | train_rmsle: 0.00079 | train_mae: 0.07296 | train_rmse: 0.10218 | train_mse: 0.01044 | valid_rmsle: 0.00078 | valid_mae: 0.07759 | valid_rmse: 0.10609 | valid_mse: 0.01125 |  0:04:15s\n",
      "epoch 99 | loss: 0.0129  | train_rmsle: 0.00062 | train_mae: 0.0815  | train_rmse: 0.10205 | train_mse: 0.01041 | valid_rmsle: 0.00069 | valid_mae: 0.08679 | valid_rmse: 0.10892 | valid_mse: 0.01186 |  0:04:17s\n",
      "epoch 100| loss: 0.01197 | train_rmsle: 0.00043 | train_mae: 0.06619 | train_rmse: 0.08511 | train_mse: 0.00724 | valid_rmsle: 0.00053 | valid_mae: 0.07256 | valid_rmse: 0.0951  | valid_mse: 0.00904 |  0:04:20s\n",
      "epoch 101| loss: 0.01156 | train_rmsle: 0.00054 | train_mae: 0.07154 | train_rmse: 0.09226 | train_mse: 0.00851 | valid_rmsle: 0.00062 | valid_mae: 0.07755 | valid_rmse: 0.10064 | valid_mse: 0.01013 |  0:04:23s\n",
      "epoch 102| loss: 0.01348 | train_rmsle: 0.00059 | train_mae: 0.08123 | train_rmse: 0.1017  | train_mse: 0.01034 | valid_rmsle: 0.00068 | valid_mae: 0.08624 | valid_rmse: 0.10981 | valid_mse: 0.01206 |  0:04:25s\n",
      "epoch 103| loss: 0.01456 | train_rmsle: 0.00052 | train_mae: 0.07016 | train_rmse: 0.0915  | train_mse: 0.00837 | valid_rmsle: 0.00059 | valid_mae: 0.07592 | valid_rmse: 0.0997  | valid_mse: 0.00994 |  0:04:28s\n",
      "epoch 104| loss: 0.01619 | train_rmsle: 0.00054 | train_mae: 0.07406 | train_rmse: 0.095   | train_mse: 0.00903 | valid_rmsle: 0.00065 | valid_mae: 0.08142 | valid_rmse: 0.10537 | valid_mse: 0.0111  |  0:04:31s\n",
      "epoch 105| loss: 0.01377 | train_rmsle: 0.00067 | train_mae: 0.08006 | train_rmse: 0.10283 | train_mse: 0.01057 | valid_rmsle: 0.00085 | valid_mae: 0.08653 | valid_rmse: 0.11431 | valid_mse: 0.01307 |  0:04:33s\n",
      "epoch 106| loss: 0.01101 | train_rmsle: 0.00042 | train_mae: 0.06397 | train_rmse: 0.08253 | train_mse: 0.00681 | valid_rmsle: 0.00053 | valid_mae: 0.07174 | valid_rmse: 0.09304 | valid_mse: 0.00866 |  0:04:36s\n",
      "epoch 107| loss: 0.01174 | train_rmsle: 0.0004  | train_mae: 0.06317 | train_rmse: 0.08354 | train_mse: 0.00698 | valid_rmsle: 0.00048 | valid_mae: 0.06929 | valid_rmse: 0.0913  | valid_mse: 0.00834 |  0:04:39s\n",
      "epoch 108| loss: 0.01245 | train_rmsle: 0.00041 | train_mae: 0.06276 | train_rmse: 0.08214 | train_mse: 0.00675 | valid_rmsle: 0.00051 | valid_mae: 0.07085 | valid_rmse: 0.09188 | valid_mse: 0.00844 |  0:04:41s\n",
      "epoch 109| loss: 0.01353 | train_rmsle: 0.00043 | train_mae: 0.06436 | train_rmse: 0.08314 | train_mse: 0.00691 | valid_rmsle: 0.00054 | valid_mae: 0.07158 | valid_rmse: 0.09278 | valid_mse: 0.00861 |  0:04:43s\n",
      "epoch 110| loss: 0.01188 | train_rmsle: 0.00067 | train_mae: 0.08439 | train_rmse: 0.10415 | train_mse: 0.01085 | valid_rmsle: 0.00079 | valid_mae: 0.0898  | valid_rmse: 0.11242 | valid_mse: 0.01264 |  0:04:46s\n",
      "epoch 111| loss: 0.01276 | train_rmsle: 0.00141 | train_mae: 0.13216 | train_rmse: 0.15908 | train_mse: 0.02531 | valid_rmsle: 0.00166 | valid_mae: 0.14165 | valid_rmse: 0.17093 | valid_mse: 0.02922 |  0:04:48s\n",
      "epoch 112| loss: 0.01662 | train_rmsle: 0.00091 | train_mae: 0.10362 | train_rmse: 0.129   | train_mse: 0.01664 | valid_rmsle: 0.00108 | valid_mae: 0.11256 | valid_rmse: 0.14047 | valid_mse: 0.01973 |  0:04:50s\n",
      "epoch 113| loss: 0.01589 | train_rmsle: 0.00066 | train_mae: 0.08174 | train_rmse: 0.10375 | train_mse: 0.01076 | valid_rmsle: 0.0008  | valid_mae: 0.08943 | valid_rmse: 0.11427 | valid_mse: 0.01306 |  0:04:53s\n",
      "epoch 114| loss: 0.0163  | train_rmsle: 0.00054 | train_mae: 0.07447 | train_rmse: 0.09593 | train_mse: 0.0092  | valid_rmsle: 0.00068 | valid_mae: 0.08211 | valid_rmse: 0.10663 | valid_mse: 0.01137 |  0:04:56s\n",
      "epoch 115| loss: 0.01206 | train_rmsle: 0.00059 | train_mae: 0.07337 | train_rmse: 0.09441 | train_mse: 0.00891 | valid_rmsle: 0.00069 | valid_mae: 0.07917 | valid_rmse: 0.10262 | valid_mse: 0.01053 |  0:04:58s\n",
      "epoch 116| loss: 0.01415 | train_rmsle: 0.00087 | train_mae: 0.09352 | train_rmse: 0.11867 | train_mse: 0.01408 | valid_rmsle: 0.00098 | valid_mae: 0.10108 | valid_rmse: 0.12698 | valid_mse: 0.01612 |  0:05:01s\n",
      "epoch 117| loss: 0.01416 | train_rmsle: 0.00087 | train_mae: 0.09896 | train_rmse: 0.12323 | train_mse: 0.01518 | valid_rmsle: 0.00102 | valid_mae: 0.10554 | valid_rmse: 0.13257 | valid_mse: 0.01757 |  0:05:04s\n",
      "epoch 118| loss: 0.01468 | train_rmsle: 0.00057 | train_mae: 0.0714  | train_rmse: 0.09239 | train_mse: 0.00854 | valid_rmsle: 0.00064 | valid_mae: 0.07851 | valid_rmse: 0.10075 | valid_mse: 0.01015 |  0:05:06s\n",
      "epoch 119| loss: 0.01782 | train_rmsle: 0.00064 | train_mae: 0.08202 | train_rmse: 0.10239 | train_mse: 0.01048 | valid_rmsle: 0.00075 | valid_mae: 0.08855 | valid_rmse: 0.11141 | valid_mse: 0.01241 |  0:05:09s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 107 and best_valid_mse = 0.00834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009675581572380524 RMSE: 0.09836453411865745 R2: 0.9571699285603725 MAE: 0.07256054381110555\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_7_0.02_120.pt.zip\n",
      "New best model: 512_8_7_0.02_120 with r2: 0.9571699285603725\n",
      "[27/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.5006  | train_rmsle: 0.38629 | train_mae: 1.96568 | train_rmse: 2.02437 | train_mse: 4.09809 | valid_rmsle: 0.38778 | valid_mae: 1.97191 | valid_rmse: 2.02933 | valid_mse: 4.11816 |  0:00:02s\n",
      "epoch 1  | loss: 0.81048 | train_rmsle: 0.07202 | train_mae: 0.95955 | train_rmse: 1.05119 | train_mse: 1.10501 | valid_rmsle: 0.07222 | valid_mae: 0.96167 | valid_rmse: 1.05433 | valid_mse: 1.11161 |  0:00:05s\n",
      "epoch 2  | loss: 0.30723 | train_rmsle: 0.02493 | train_mae: 0.56295 | train_rmse: 0.65304 | train_mse: 0.42646 | valid_rmsle: 0.02471 | valid_mae: 0.56362 | valid_rmse: 0.65391 | valid_mse: 0.4276  |  0:00:08s\n",
      "epoch 3  | loss: 0.27624 | train_rmsle: 0.03998 | train_mae: 0.72044 | train_rmse: 0.81339 | train_mse: 0.6616  | valid_rmsle: 0.03997 | valid_mae: 0.7205  | valid_rmse: 0.81571 | valid_mse: 0.66538 |  0:00:10s\n",
      "epoch 4  | loss: 0.25353 | train_rmsle: 0.03248 | train_mae: 0.64806 | train_rmse: 0.74008 | train_mse: 0.54771 | valid_rmsle: 0.0324  | valid_mae: 0.64786 | valid_rmse: 0.74208 | valid_mse: 0.55069 |  0:00:13s\n",
      "epoch 5  | loss: 0.28372 | train_rmsle: 0.01704 | train_mae: 0.44881 | train_rmse: 0.53646 | train_mse: 0.28779 | valid_rmsle: 0.01658 | valid_mae: 0.44936 | valid_rmse: 0.53414 | valid_mse: 0.28531 |  0:00:15s\n",
      "epoch 6  | loss: 0.2924  | train_rmsle: 0.03551 | train_mae: 0.67831 | train_rmse: 0.77068 | train_mse: 0.59395 | valid_rmsle: 0.03539 | valid_mae: 0.67741 | valid_rmse: 0.7723  | valid_mse: 0.59644 |  0:00:17s\n",
      "epoch 7  | loss: 0.29245 | train_rmsle: 0.02764 | train_mae: 0.59474 | train_rmse: 0.68597 | train_mse: 0.47055 | valid_rmsle: 0.02737 | valid_mae: 0.59448 | valid_rmse: 0.686   | valid_mse: 0.4706  |  0:00:19s\n",
      "epoch 8  | loss: 0.24724 | train_rmsle: 0.01757 | train_mae: 0.4579  | train_rmse: 0.54558 | train_mse: 0.29766 | valid_rmsle: 0.01707 | valid_mae: 0.45862 | valid_rmse: 0.54272 | valid_mse: 0.29455 |  0:00:21s\n",
      "epoch 9  | loss: 0.23568 | train_rmsle: 0.01849 | train_mae: 0.47328 | train_rmse: 0.56097 | train_mse: 0.31469 | valid_rmsle: 0.01814 | valid_mae: 0.47516 | valid_rmse: 0.56028 | valid_mse: 0.31391 |  0:00:24s\n",
      "epoch 10 | loss: 0.2298  | train_rmsle: 0.02123 | train_mae: 0.51433 | train_rmse: 0.60291 | train_mse: 0.3635  | valid_rmsle: 0.02089 | valid_mae: 0.51613 | valid_rmse: 0.60232 | valid_mse: 0.36279 |  0:00:27s\n",
      "epoch 11 | loss: 0.22932 | train_rmsle: 0.01558 | train_mae: 0.41838 | train_rmse: 0.50832 | train_mse: 0.25839 | valid_rmsle: 0.01503 | valid_mae: 0.41841 | valid_rmse: 0.50436 | valid_mse: 0.25438 |  0:00:29s\n",
      "epoch 12 | loss: 0.23527 | train_rmsle: 0.01642 | train_mae: 0.4362  | train_rmse: 0.52485 | train_mse: 0.27547 | valid_rmsle: 0.01594 | valid_mae: 0.43771 | valid_rmse: 0.52204 | valid_mse: 0.27252 |  0:00:32s\n",
      "epoch 13 | loss: 0.22838 | train_rmsle: 0.01685 | train_mae: 0.4438  | train_rmse: 0.53254 | train_mse: 0.2836  | valid_rmsle: 0.01651 | valid_mae: 0.44807 | valid_rmse: 0.53202 | valid_mse: 0.28305 |  0:00:34s\n",
      "epoch 14 | loss: 0.22595 | train_rmsle: 0.01495 | train_mae: 0.40206 | train_rmse: 0.49437 | train_mse: 0.2444  | valid_rmsle: 0.01448 | valid_mae: 0.40408 | valid_rmse: 0.49196 | valid_mse: 0.24203 |  0:00:37s\n",
      "epoch 15 | loss: 0.22644 | train_rmsle: 0.01603 | train_mae: 0.42888 | train_rmse: 0.51771 | train_mse: 0.26802 | valid_rmsle: 0.01557 | valid_mae: 0.43061 | valid_rmse: 0.51533 | valid_mse: 0.26557 |  0:00:39s\n",
      "epoch 16 | loss: 0.22733 | train_rmsle: 0.01479 | train_mae: 0.39802 | train_rmse: 0.49088 | train_mse: 0.24096 | valid_rmsle: 0.01423 | valid_mae: 0.39765 | valid_rmse: 0.48655 | valid_mse: 0.23673 |  0:00:41s\n",
      "epoch 17 | loss: 0.22782 | train_rmsle: 0.01453 | train_mae: 0.38362 | train_rmse: 0.48205 | train_mse: 0.23237 | valid_rmsle: 0.01398 | valid_mae: 0.38435 | valid_rmse: 0.47784 | valid_mse: 0.22833 |  0:00:44s\n",
      "epoch 18 | loss: 0.23185 | train_rmsle: 0.01606 | train_mae: 0.43001 | train_rmse: 0.51843 | train_mse: 0.26877 | valid_rmsle: 0.01569 | valid_mae: 0.43287 | valid_rmse: 0.51732 | valid_mse: 0.26762 |  0:00:47s\n",
      "epoch 19 | loss: 0.22639 | train_rmsle: 0.01464 | train_mae: 0.38854 | train_rmse: 0.48512 | train_mse: 0.23534 | valid_rmsle: 0.01409 | valid_mae: 0.38904 | valid_rmse: 0.48116 | valid_mse: 0.23152 |  0:00:49s\n",
      "epoch 20 | loss: 0.2294  | train_rmsle: 0.01483 | train_mae: 0.39746 | train_rmse: 0.49113 | train_mse: 0.24121 | valid_rmsle: 0.01427 | valid_mae: 0.39842 | valid_rmse: 0.48701 | valid_mse: 0.23717 |  0:00:52s\n",
      "epoch 21 | loss: 0.2239  | train_rmsle: 0.01553 | train_mae: 0.41829 | train_rmse: 0.50783 | train_mse: 0.2579  | valid_rmsle: 0.01503 | valid_mae: 0.41957 | valid_rmse: 0.50492 | valid_mse: 0.25494 |  0:00:55s\n",
      "epoch 22 | loss: 0.2237  | train_rmsle: 0.01488 | train_mae: 0.4027  | train_rmse: 0.49411 | train_mse: 0.24414 | valid_rmsle: 0.01415 | valid_mae: 0.40152 | valid_rmse: 0.487   | valid_mse: 0.23717 |  0:00:57s\n",
      "epoch 23 | loss: 0.22021 | train_rmsle: 0.01451 | train_mae: 0.39184 | train_rmse: 0.48539 | train_mse: 0.23561 | valid_rmsle: 0.01395 | valid_mae: 0.39196 | valid_rmse: 0.4812  | valid_mse: 0.23156 |  0:01:00s\n",
      "epoch 24 | loss: 0.22364 | train_rmsle: 0.01446 | train_mae: 0.38856 | train_rmse: 0.48348 | train_mse: 0.23376 | valid_rmsle: 0.01413 | valid_mae: 0.39265 | valid_rmse: 0.48305 | valid_mse: 0.23334 |  0:01:03s\n",
      "epoch 25 | loss: 0.222   | train_rmsle: 0.01527 | train_mae: 0.41375 | train_rmse: 0.50319 | train_mse: 0.25321 | valid_rmsle: 0.01484 | valid_mae: 0.41515 | valid_rmse: 0.50111 | valid_mse: 0.25111 |  0:01:05s\n",
      "epoch 26 | loss: 0.22127 | train_rmsle: 0.01468 | train_mae: 0.39934 | train_rmse: 0.49027 | train_mse: 0.24036 | valid_rmsle: 0.01434 | valid_mae: 0.40176 | valid_rmse: 0.48971 | valid_mse: 0.23982 |  0:01:08s\n",
      "epoch 27 | loss: 0.22465 | train_rmsle: 0.01473 | train_mae: 0.40141 | train_rmse: 0.49183 | train_mse: 0.2419  | valid_rmsle: 0.01423 | valid_mae: 0.40018 | valid_rmse: 0.4883  | valid_mse: 0.23843 |  0:01:11s\n",
      "epoch 28 | loss: 0.22679 | train_rmsle: 0.01501 | train_mae: 0.37329 | train_rmse: 0.48485 | train_mse: 0.23508 | valid_rmsle: 0.01439 | valid_mae: 0.37352 | valid_rmse: 0.47968 | valid_mse: 0.2301  |  0:01:13s\n",
      "epoch 29 | loss: 0.2306  | train_rmsle: 0.01418 | train_mae: 0.38343 | train_rmse: 0.47752 | train_mse: 0.22802 | valid_rmsle: 0.01376 | valid_mae: 0.38382 | valid_rmse: 0.47545 | valid_mse: 0.22605 |  0:01:16s\n",
      "epoch 30 | loss: 0.218   | train_rmsle: 0.01403 | train_mae: 0.38369 | train_rmse: 0.4762  | train_mse: 0.22677 | valid_rmsle: 0.01368 | valid_mae: 0.38653 | valid_rmse: 0.47564 | valid_mse: 0.22623 |  0:01:19s\n",
      "epoch 31 | loss: 0.21493 | train_rmsle: 0.01429 | train_mae: 0.39493 | train_rmse: 0.48428 | train_mse: 0.23453 | valid_rmsle: 0.01393 | valid_mae: 0.39565 | valid_rmse: 0.4837  | valid_mse: 0.23397 |  0:01:22s\n",
      "epoch 32 | loss: 0.20927 | train_rmsle: 0.01341 | train_mae: 0.36677 | train_rmse: 0.4619  | train_mse: 0.21335 | valid_rmsle: 0.01296 | valid_mae: 0.3683  | valid_rmse: 0.4599  | valid_mse: 0.21151 |  0:01:24s\n",
      "epoch 33 | loss: 0.20775 | train_rmsle: 0.01362 | train_mae: 0.36264 | train_rmse: 0.46338 | train_mse: 0.21472 | valid_rmsle: 0.01311 | valid_mae: 0.36166 | valid_rmse: 0.46024 | valid_mse: 0.21183 |  0:01:27s\n",
      "epoch 34 | loss: 0.2018  | train_rmsle: 0.01327 | train_mae: 0.36491 | train_rmse: 0.45987 | train_mse: 0.21148 | valid_rmsle: 0.01267 | valid_mae: 0.36272 | valid_rmse: 0.45458 | valid_mse: 0.20664 |  0:01:30s\n",
      "epoch 35 | loss: 0.20129 | train_rmsle: 0.01335 | train_mae: 0.36058 | train_rmse: 0.46048 | train_mse: 0.21205 | valid_rmsle: 0.01251 | valid_mae: 0.35891 | valid_rmse: 0.45118 | valid_mse: 0.20356 |  0:01:32s\n",
      "epoch 36 | loss: 0.19472 | train_rmsle: 0.01259 | train_mae: 0.36116 | train_rmse: 0.4499  | train_mse: 0.20241 | valid_rmsle: 0.01233 | valid_mae: 0.36556 | valid_rmse: 0.4507  | valid_mse: 0.20313 |  0:01:35s\n",
      "epoch 37 | loss: 0.18858 | train_rmsle: 0.01251 | train_mae: 0.36537 | train_rmse: 0.45056 | train_mse: 0.203   | valid_rmsle: 0.01248 | valid_mae: 0.37344 | valid_rmse: 0.4554  | valid_mse: 0.20739 |  0:01:38s\n",
      "epoch 38 | loss: 0.17795 | train_rmsle: 0.01132 | train_mae: 0.32307 | train_rmse: 0.41909 | train_mse: 0.17564 | valid_rmsle: 0.01147 | valid_mae: 0.33184 | valid_rmse: 0.42822 | valid_mse: 0.18337 |  0:01:40s\n",
      "epoch 39 | loss: 0.16349 | train_rmsle: 0.01067 | train_mae: 0.31433 | train_rmse: 0.40714 | train_mse: 0.16576 | valid_rmsle: 0.01057 | valid_mae: 0.32321 | valid_rmse: 0.41174 | valid_mse: 0.16953 |  0:01:43s\n",
      "epoch 40 | loss: 0.15527 | train_rmsle: 0.0103  | train_mae: 0.30181 | train_rmse: 0.39766 | train_mse: 0.15813 | valid_rmsle: 0.00993 | valid_mae: 0.30696 | valid_rmse: 0.39673 | valid_mse: 0.1574  |  0:01:46s\n",
      "epoch 41 | loss: 0.14482 | train_rmsle: 0.00939 | train_mae: 0.29849 | train_rmse: 0.38213 | train_mse: 0.14602 | valid_rmsle: 0.00907 | valid_mae: 0.30254 | valid_rmse: 0.38152 | valid_mse: 0.14556 |  0:01:49s\n",
      "epoch 42 | loss: 0.13982 | train_rmsle: 0.00922 | train_mae: 0.28231 | train_rmse: 0.37396 | train_mse: 0.13985 | valid_rmsle: 0.00885 | valid_mae: 0.28759 | valid_rmse: 0.37246 | valid_mse: 0.13873 |  0:01:51s\n",
      "epoch 43 | loss: 0.1355  | train_rmsle: 0.00877 | train_mae: 0.28611 | train_rmse: 0.36816 | train_mse: 0.13554 | valid_rmsle: 0.00847 | valid_mae: 0.29286 | valid_rmse: 0.36886 | valid_mse: 0.13606 |  0:01:54s\n",
      "epoch 44 | loss: 0.13126 | train_rmsle: 0.0087  | train_mae: 0.28634 | train_rmse: 0.36778 | train_mse: 0.13526 | valid_rmsle: 0.00856 | valid_mae: 0.29473 | valid_rmse: 0.37205 | valid_mse: 0.13842 |  0:01:57s\n",
      "epoch 45 | loss: 0.12411 | train_rmsle: 0.00824 | train_mae: 0.27152 | train_rmse: 0.35514 | train_mse: 0.12613 | valid_rmsle: 0.00822 | valid_mae: 0.28295 | valid_rmse: 0.36135 | valid_mse: 0.13057 |  0:01:59s\n",
      "epoch 46 | loss: 0.11818 | train_rmsle: 0.00761 | train_mae: 0.25635 | train_rmse: 0.33799 | train_mse: 0.11423 | valid_rmsle: 0.00737 | valid_mae: 0.26307 | valid_rmse: 0.33932 | valid_mse: 0.11514 |  0:02:01s\n",
      "epoch 47 | loss: 0.11027 | train_rmsle: 0.00732 | train_mae: 0.24795 | train_rmse: 0.32994 | train_mse: 0.10886 | valid_rmsle: 0.00715 | valid_mae: 0.2536  | valid_rmse: 0.33268 | valid_mse: 0.11067 |  0:02:04s\n",
      "epoch 48 | loss: 0.10688 | train_rmsle: 0.0068  | train_mae: 0.24236 | train_rmse: 0.31892 | train_mse: 0.10171 | valid_rmsle: 0.00671 | valid_mae: 0.24912 | valid_rmse: 0.32324 | valid_mse: 0.10448 |  0:02:06s\n",
      "epoch 49 | loss: 0.10101 | train_rmsle: 0.00649 | train_mae: 0.23764 | train_rmse: 0.31176 | train_mse: 0.0972  | valid_rmsle: 0.00631 | valid_mae: 0.24224 | valid_rmse: 0.31325 | valid_mse: 0.09813 |  0:02:09s\n",
      "epoch 50 | loss: 0.09457 | train_rmsle: 0.00612 | train_mae: 0.2304  | train_rmse: 0.30245 | train_mse: 0.09148 | valid_rmsle: 0.0059  | valid_mae: 0.23596 | valid_rmse: 0.30256 | valid_mse: 0.09154 |  0:02:11s\n",
      "epoch 51 | loss: 0.09014 | train_rmsle: 0.00632 | train_mae: 0.24788 | train_rmse: 0.31385 | train_mse: 0.0985  | valid_rmsle: 0.0063  | valid_mae: 0.25824 | valid_rmse: 0.3182  | valid_mse: 0.10125 |  0:02:14s\n",
      "epoch 52 | loss: 0.09301 | train_rmsle: 0.00699 | train_mae: 0.24861 | train_rmse: 0.32658 | train_mse: 0.10666 | valid_rmsle: 0.00692 | valid_mae: 0.255   | valid_rmse: 0.33138 | valid_mse: 0.10981 |  0:02:17s\n",
      "epoch 53 | loss: 0.08836 | train_rmsle: 0.00555 | train_mae: 0.21444 | train_rmse: 0.28624 | train_mse: 0.08193 | valid_rmsle: 0.00552 | valid_mae: 0.22204 | valid_rmse: 0.29161 | valid_mse: 0.08504 |  0:02:19s\n",
      "epoch 54 | loss: 0.0802  | train_rmsle: 0.00512 | train_mae: 0.20469 | train_rmse: 0.27443 | train_mse: 0.07531 | valid_rmsle: 0.00524 | valid_mae: 0.2161  | valid_rmse: 0.28332 | valid_mse: 0.08027 |  0:02:22s\n",
      "epoch 55 | loss: 0.07663 | train_rmsle: 0.00515 | train_mae: 0.20694 | train_rmse: 0.27553 | train_mse: 0.07592 | valid_rmsle: 0.00531 | valid_mae: 0.21631 | valid_rmse: 0.28588 | valid_mse: 0.08173 |  0:02:25s\n",
      "epoch 56 | loss: 0.06764 | train_rmsle: 0.00449 | train_mae: 0.19452 | train_rmse: 0.25784 | train_mse: 0.06648 | valid_rmsle: 0.00473 | valid_mae: 0.20917 | valid_rmse: 0.27098 | valid_mse: 0.07343 |  0:02:27s\n",
      "epoch 57 | loss: 0.06548 | train_rmsle: 0.00408 | train_mae: 0.18572 | train_rmse: 0.24674 | train_mse: 0.06088 | valid_rmsle: 0.00439 | valid_mae: 0.20084 | valid_rmse: 0.2612  | valid_mse: 0.06822 |  0:02:30s\n",
      "epoch 58 | loss: 0.06261 | train_rmsle: 0.00393 | train_mae: 0.18119 | train_rmse: 0.24081 | train_mse: 0.05799 | valid_rmsle: 0.00428 | valid_mae: 0.19724 | valid_rmse: 0.25791 | valid_mse: 0.06652 |  0:02:33s\n",
      "epoch 59 | loss: 0.05532 | train_rmsle: 0.00356 | train_mae: 0.17174 | train_rmse: 0.22865 | train_mse: 0.05228 | valid_rmsle: 0.00372 | valid_mae: 0.18292 | valid_rmse: 0.2401  | valid_mse: 0.05765 |  0:02:35s\n",
      "epoch 60 | loss: 0.05406 | train_rmsle: 0.00355 | train_mae: 0.17381 | train_rmse: 0.22992 | train_mse: 0.05286 | valid_rmsle: 0.00375 | valid_mae: 0.18618 | valid_rmse: 0.24138 | valid_mse: 0.05826 |  0:02:38s\n",
      "epoch 61 | loss: 0.05543 | train_rmsle: 0.00329 | train_mae: 0.16722 | train_rmse: 0.22143 | train_mse: 0.04903 | valid_rmsle: 0.00351 | valid_mae: 0.1807  | valid_rmse: 0.23404 | valid_mse: 0.05477 |  0:02:41s\n",
      "epoch 62 | loss: 0.04808 | train_rmsle: 0.00282 | train_mae: 0.15349 | train_rmse: 0.20468 | train_mse: 0.04189 | valid_rmsle: 0.00291 | valid_mae: 0.16525 | valid_rmse: 0.21383 | valid_mse: 0.04572 |  0:02:43s\n",
      "epoch 63 | loss: 0.04301 | train_rmsle: 0.00286 | train_mae: 0.15236 | train_rmse: 0.20395 | train_mse: 0.04159 | valid_rmsle: 0.00294 | valid_mae: 0.16218 | valid_rmse: 0.21323 | valid_mse: 0.04547 |  0:02:46s\n",
      "epoch 64 | loss: 0.03849 | train_rmsle: 0.00244 | train_mae: 0.14111 | train_rmse: 0.18898 | train_mse: 0.03571 | valid_rmsle: 0.00251 | valid_mae: 0.14962 | valid_rmse: 0.19693 | valid_mse: 0.03878 |  0:02:49s\n",
      "epoch 65 | loss: 0.03674 | train_rmsle: 0.00216 | train_mae: 0.13248 | train_rmse: 0.17779 | train_mse: 0.03161 | valid_rmsle: 0.00219 | valid_mae: 0.14014 | valid_rmse: 0.18315 | valid_mse: 0.03354 |  0:02:52s\n",
      "epoch 66 | loss: 0.03336 | train_rmsle: 0.00216 | train_mae: 0.12948 | train_rmse: 0.17584 | train_mse: 0.03092 | valid_rmsle: 0.00214 | valid_mae: 0.13529 | valid_rmse: 0.17902 | valid_mse: 0.03205 |  0:02:54s\n",
      "epoch 67 | loss: 0.02985 | train_rmsle: 0.00192 | train_mae: 0.12252 | train_rmse: 0.1662  | train_mse: 0.02762 | valid_rmsle: 0.00187 | valid_mae: 0.12943 | valid_rmse: 0.1683  | valid_mse: 0.02832 |  0:02:57s\n",
      "epoch 68 | loss: 0.03111 | train_rmsle: 0.00216 | train_mae: 0.13348 | train_rmse: 0.17723 | train_mse: 0.03141 | valid_rmsle: 0.00205 | valid_mae: 0.13614 | valid_rmse: 0.17701 | valid_mse: 0.03133 |  0:03:00s\n",
      "epoch 69 | loss: 0.03104 | train_rmsle: 0.00188 | train_mae: 0.12885 | train_rmse: 0.1698  | train_mse: 0.02883 | valid_rmsle: 0.0019  | valid_mae: 0.13567 | valid_rmse: 0.17447 | valid_mse: 0.03044 |  0:03:02s\n",
      "epoch 70 | loss: 0.02975 | train_rmsle: 0.00211 | train_mae: 0.13847 | train_rmse: 0.17907 | train_mse: 0.03206 | valid_rmsle: 0.00207 | valid_mae: 0.14328 | valid_rmse: 0.18128 | valid_mse: 0.03286 |  0:03:05s\n",
      "epoch 71 | loss: 0.03262 | train_rmsle: 0.00177 | train_mae: 0.1194  | train_rmse: 0.15954 | train_mse: 0.02545 | valid_rmsle: 0.00168 | valid_mae: 0.12279 | valid_rmse: 0.15968 | valid_mse: 0.0255  |  0:03:08s\n",
      "epoch 72 | loss: 0.02628 | train_rmsle: 0.00196 | train_mae: 0.13301 | train_rmse: 0.17139 | train_mse: 0.02937 | valid_rmsle: 0.00198 | valid_mae: 0.13709 | valid_rmse: 0.17553 | valid_mse: 0.03081 |  0:03:10s\n",
      "epoch 73 | loss: 0.02461 | train_rmsle: 0.00147 | train_mae: 0.11334 | train_rmse: 0.14825 | train_mse: 0.02198 | valid_rmsle: 0.0015  | valid_mae: 0.11926 | valid_rmse: 0.15314 | valid_mse: 0.02345 |  0:03:13s\n",
      "epoch 74 | loss: 0.02133 | train_rmsle: 0.0018  | train_mae: 0.11523 | train_rmse: 0.15988 | train_mse: 0.02556 | valid_rmsle: 0.00179 | valid_mae: 0.1192  | valid_rmse: 0.16299 | valid_mse: 0.02657 |  0:03:16s\n",
      "epoch 75 | loss: 0.02257 | train_rmsle: 0.00151 | train_mae: 0.11256 | train_rmse: 0.15004 | train_mse: 0.02251 | valid_rmsle: 0.0016  | valid_mae: 0.11776 | valid_rmse: 0.15687 | valid_mse: 0.02461 |  0:03:18s\n",
      "epoch 76 | loss: 0.02286 | train_rmsle: 0.00165 | train_mae: 0.13599 | train_rmse: 0.16725 | train_mse: 0.02797 | valid_rmsle: 0.00169 | valid_mae: 0.14182 | valid_rmse: 0.17178 | valid_mse: 0.02951 |  0:03:20s\n",
      "epoch 77 | loss: 0.02379 | train_rmsle: 0.00111 | train_mae: 0.09618 | train_rmse: 0.12796 | train_mse: 0.01637 | valid_rmsle: 0.00114 | valid_mae: 0.10319 | valid_rmse: 0.13359 | valid_mse: 0.01785 |  0:03:22s\n",
      "epoch 78 | loss: 0.01931 | train_rmsle: 0.00105 | train_mae: 0.09144 | train_rmse: 0.12261 | train_mse: 0.01503 | valid_rmsle: 0.00106 | valid_mae: 0.09571 | valid_rmse: 0.1277  | valid_mse: 0.01631 |  0:03:24s\n",
      "epoch 79 | loss: 0.0199  | train_rmsle: 0.00123 | train_mae: 0.09902 | train_rmse: 0.13283 | train_mse: 0.01764 | valid_rmsle: 0.00124 | valid_mae: 0.10435 | valid_rmse: 0.13782 | valid_mse: 0.019   |  0:03:26s\n",
      "epoch 80 | loss: 0.0166  | train_rmsle: 0.00088 | train_mae: 0.08713 | train_rmse: 0.11605 | train_mse: 0.01347 | valid_rmsle: 0.00101 | valid_mae: 0.0958  | valid_rmse: 0.12636 | valid_mse: 0.01597 |  0:03:28s\n",
      "epoch 81 | loss: 0.0181  | train_rmsle: 0.00129 | train_mae: 0.10571 | train_rmse: 0.13708 | train_mse: 0.01879 | valid_rmsle: 0.00126 | valid_mae: 0.10968 | valid_rmse: 0.13914 | valid_mse: 0.01936 |  0:03:31s\n",
      "epoch 82 | loss: 0.02088 | train_rmsle: 0.00142 | train_mae: 0.10962 | train_rmse: 0.14253 | train_mse: 0.02031 | valid_rmsle: 0.00142 | valid_mae: 0.11247 | valid_rmse: 0.14579 | valid_mse: 0.02126 |  0:03:33s\n",
      "epoch 83 | loss: 0.02001 | train_rmsle: 0.00085 | train_mae: 0.08822 | train_rmse: 0.11547 | train_mse: 0.01333 | valid_rmsle: 0.00093 | valid_mae: 0.0944  | valid_rmse: 0.12257 | valid_mse: 0.01502 |  0:03:36s\n",
      "epoch 84 | loss: 0.02087 | train_rmsle: 0.00131 | train_mae: 0.1185  | train_rmse: 0.15093 | train_mse: 0.02278 | valid_rmsle: 0.00145 | valid_mae: 0.12422 | valid_rmse: 0.15859 | valid_mse: 0.02515 |  0:03:38s\n",
      "epoch 85 | loss: 0.0201  | train_rmsle: 0.00182 | train_mae: 0.14885 | train_rmse: 0.17896 | train_mse: 0.03203 | valid_rmsle: 0.00198 | valid_mae: 0.15467 | valid_rmse: 0.18512 | valid_mse: 0.03427 |  0:03:41s\n",
      "epoch 86 | loss: 0.0226  | train_rmsle: 0.00146 | train_mae: 0.13072 | train_rmse: 0.16188 | train_mse: 0.02621 | valid_rmsle: 0.00158 | valid_mae: 0.13725 | valid_rmse: 0.16799 | valid_mse: 0.02822 |  0:03:44s\n",
      "epoch 87 | loss: 0.02137 | train_rmsle: 0.00097 | train_mae: 0.09689 | train_rmse: 0.12588 | train_mse: 0.01585 | valid_rmsle: 0.00111 | valid_mae: 0.10367 | valid_rmse: 0.13474 | valid_mse: 0.01815 |  0:03:46s\n",
      "epoch 88 | loss: 0.01896 | train_rmsle: 0.00086 | train_mae: 0.08733 | train_rmse: 0.11676 | train_mse: 0.01363 | valid_rmsle: 0.00095 | valid_mae: 0.09277 | valid_rmse: 0.12405 | valid_mse: 0.01539 |  0:03:49s\n",
      "epoch 89 | loss: 0.01749 | train_rmsle: 0.00088 | train_mae: 0.08744 | train_rmse: 0.11586 | train_mse: 0.01342 | valid_rmsle: 0.00093 | valid_mae: 0.09235 | valid_rmse: 0.12176 | valid_mse: 0.01483 |  0:03:52s\n",
      "epoch 90 | loss: 0.01584 | train_rmsle: 0.00074 | train_mae: 0.08637 | train_rmse: 0.11332 | train_mse: 0.01284 | valid_rmsle: 0.0009  | valid_mae: 0.09471 | valid_rmse: 0.12478 | valid_mse: 0.01557 |  0:03:54s\n",
      "epoch 91 | loss: 0.01657 | train_rmsle: 0.00068 | train_mae: 0.07749 | train_rmse: 0.10257 | train_mse: 0.01052 | valid_rmsle: 0.00075 | valid_mae: 0.08401 | valid_rmse: 0.10997 | valid_mse: 0.01209 |  0:03:57s\n",
      "epoch 92 | loss: 0.01725 | train_rmsle: 0.00071 | train_mae: 0.07545 | train_rmse: 0.10183 | train_mse: 0.01037 | valid_rmsle: 0.00074 | valid_mae: 0.08071 | valid_rmse: 0.108   | valid_mse: 0.01166 |  0:04:00s\n",
      "epoch 93 | loss: 0.01444 | train_rmsle: 0.00051 | train_mae: 0.0687  | train_rmse: 0.09075 | train_mse: 0.00824 | valid_rmsle: 0.00059 | valid_mae: 0.07612 | valid_rmse: 0.09893 | valid_mse: 0.00979 |  0:04:02s\n",
      "epoch 94 | loss: 0.01506 | train_rmsle: 0.00096 | train_mae: 0.10995 | train_rmse: 0.13142 | train_mse: 0.01727 | valid_rmsle: 0.00106 | valid_mae: 0.11533 | valid_rmse: 0.13821 | valid_mse: 0.0191  |  0:04:05s\n",
      "epoch 95 | loss: 0.01786 | train_rmsle: 0.00055 | train_mae: 0.07421 | train_rmse: 0.09633 | train_mse: 0.00928 | valid_rmsle: 0.00066 | valid_mae: 0.08042 | valid_rmse: 0.1058  | valid_mse: 0.01119 |  0:04:08s\n",
      "epoch 96 | loss: 0.01357 | train_rmsle: 0.00175 | train_mae: 0.0957  | train_rmse: 0.17275 | train_mse: 0.02984 | valid_rmsle: 0.00243 | valid_mae: 0.10613 | valid_rmse: 0.20133 | valid_mse: 0.04053 |  0:04:11s\n",
      "epoch 97 | loss: 0.01302 | train_rmsle: 0.00075 | train_mae: 0.08929 | train_rmse: 0.11033 | train_mse: 0.01217 | valid_rmsle: 0.00088 | valid_mae: 0.09609 | valid_rmse: 0.11976 | valid_mse: 0.01434 |  0:04:13s\n",
      "epoch 98 | loss: 0.0127  | train_rmsle: 0.00079 | train_mae: 0.07296 | train_rmse: 0.10218 | train_mse: 0.01044 | valid_rmsle: 0.00078 | valid_mae: 0.07759 | valid_rmse: 0.10609 | valid_mse: 0.01125 |  0:04:16s\n",
      "epoch 99 | loss: 0.0129  | train_rmsle: 0.00062 | train_mae: 0.0815  | train_rmse: 0.10205 | train_mse: 0.01041 | valid_rmsle: 0.00069 | valid_mae: 0.08679 | valid_rmse: 0.10892 | valid_mse: 0.01186 |  0:04:19s\n",
      "epoch 100| loss: 0.01197 | train_rmsle: 0.00043 | train_mae: 0.06619 | train_rmse: 0.08511 | train_mse: 0.00724 | valid_rmsle: 0.00053 | valid_mae: 0.07256 | valid_rmse: 0.0951  | valid_mse: 0.00904 |  0:04:21s\n",
      "epoch 101| loss: 0.01156 | train_rmsle: 0.00054 | train_mae: 0.07154 | train_rmse: 0.09226 | train_mse: 0.00851 | valid_rmsle: 0.00062 | valid_mae: 0.07755 | valid_rmse: 0.10064 | valid_mse: 0.01013 |  0:04:24s\n",
      "epoch 102| loss: 0.01348 | train_rmsle: 0.00059 | train_mae: 0.08123 | train_rmse: 0.1017  | train_mse: 0.01034 | valid_rmsle: 0.00068 | valid_mae: 0.08624 | valid_rmse: 0.10981 | valid_mse: 0.01206 |  0:04:27s\n",
      "epoch 103| loss: 0.01456 | train_rmsle: 0.00052 | train_mae: 0.07016 | train_rmse: 0.0915  | train_mse: 0.00837 | valid_rmsle: 0.00059 | valid_mae: 0.07592 | valid_rmse: 0.0997  | valid_mse: 0.00994 |  0:04:29s\n",
      "epoch 104| loss: 0.01619 | train_rmsle: 0.00054 | train_mae: 0.07406 | train_rmse: 0.095   | train_mse: 0.00903 | valid_rmsle: 0.00065 | valid_mae: 0.08142 | valid_rmse: 0.10537 | valid_mse: 0.0111  |  0:04:32s\n",
      "epoch 105| loss: 0.01377 | train_rmsle: 0.00067 | train_mae: 0.08006 | train_rmse: 0.10283 | train_mse: 0.01057 | valid_rmsle: 0.00085 | valid_mae: 0.08653 | valid_rmse: 0.11431 | valid_mse: 0.01307 |  0:04:35s\n",
      "epoch 106| loss: 0.01101 | train_rmsle: 0.00042 | train_mae: 0.06397 | train_rmse: 0.08253 | train_mse: 0.00681 | valid_rmsle: 0.00053 | valid_mae: 0.07174 | valid_rmse: 0.09304 | valid_mse: 0.00866 |  0:04:38s\n",
      "epoch 107| loss: 0.01174 | train_rmsle: 0.0004  | train_mae: 0.06317 | train_rmse: 0.08354 | train_mse: 0.00698 | valid_rmsle: 0.00048 | valid_mae: 0.06929 | valid_rmse: 0.0913  | valid_mse: 0.00834 |  0:04:40s\n",
      "epoch 108| loss: 0.01245 | train_rmsle: 0.00041 | train_mae: 0.06276 | train_rmse: 0.08214 | train_mse: 0.00675 | valid_rmsle: 0.00051 | valid_mae: 0.07085 | valid_rmse: 0.09188 | valid_mse: 0.00844 |  0:04:43s\n",
      "epoch 109| loss: 0.01353 | train_rmsle: 0.00043 | train_mae: 0.06436 | train_rmse: 0.08314 | train_mse: 0.00691 | valid_rmsle: 0.00054 | valid_mae: 0.07158 | valid_rmse: 0.09278 | valid_mse: 0.00861 |  0:04:46s\n",
      "epoch 110| loss: 0.01188 | train_rmsle: 0.00067 | train_mae: 0.08439 | train_rmse: 0.10415 | train_mse: 0.01085 | valid_rmsle: 0.00079 | valid_mae: 0.0898  | valid_rmse: 0.11242 | valid_mse: 0.01264 |  0:04:48s\n",
      "epoch 111| loss: 0.01276 | train_rmsle: 0.00141 | train_mae: 0.13216 | train_rmse: 0.15908 | train_mse: 0.02531 | valid_rmsle: 0.00166 | valid_mae: 0.14165 | valid_rmse: 0.17093 | valid_mse: 0.02922 |  0:04:51s\n",
      "epoch 112| loss: 0.01662 | train_rmsle: 0.00091 | train_mae: 0.10362 | train_rmse: 0.129   | train_mse: 0.01664 | valid_rmsle: 0.00108 | valid_mae: 0.11256 | valid_rmse: 0.14047 | valid_mse: 0.01973 |  0:04:53s\n",
      "epoch 113| loss: 0.01589 | train_rmsle: 0.00066 | train_mae: 0.08174 | train_rmse: 0.10375 | train_mse: 0.01076 | valid_rmsle: 0.0008  | valid_mae: 0.08943 | valid_rmse: 0.11427 | valid_mse: 0.01306 |  0:04:55s\n",
      "epoch 114| loss: 0.0163  | train_rmsle: 0.00054 | train_mae: 0.07447 | train_rmse: 0.09593 | train_mse: 0.0092  | valid_rmsle: 0.00068 | valid_mae: 0.08211 | valid_rmse: 0.10663 | valid_mse: 0.01137 |  0:04:58s\n",
      "epoch 115| loss: 0.01206 | train_rmsle: 0.00059 | train_mae: 0.07337 | train_rmse: 0.09441 | train_mse: 0.00891 | valid_rmsle: 0.00069 | valid_mae: 0.07917 | valid_rmse: 0.10262 | valid_mse: 0.01053 |  0:05:00s\n",
      "epoch 116| loss: 0.01415 | train_rmsle: 0.00087 | train_mae: 0.09352 | train_rmse: 0.11867 | train_mse: 0.01408 | valid_rmsle: 0.00098 | valid_mae: 0.10108 | valid_rmse: 0.12698 | valid_mse: 0.01612 |  0:05:03s\n",
      "epoch 117| loss: 0.01416 | train_rmsle: 0.00087 | train_mae: 0.09896 | train_rmse: 0.12323 | train_mse: 0.01518 | valid_rmsle: 0.00102 | valid_mae: 0.10554 | valid_rmse: 0.13257 | valid_mse: 0.01757 |  0:05:06s\n",
      "epoch 118| loss: 0.01468 | train_rmsle: 0.00057 | train_mae: 0.0714  | train_rmse: 0.09239 | train_mse: 0.00854 | valid_rmsle: 0.00064 | valid_mae: 0.07851 | valid_rmse: 0.10075 | valid_mse: 0.01015 |  0:05:08s\n",
      "epoch 119| loss: 0.01782 | train_rmsle: 0.00064 | train_mae: 0.08202 | train_rmse: 0.10239 | train_mse: 0.01048 | valid_rmsle: 0.00075 | valid_mae: 0.08855 | valid_rmse: 0.11141 | valid_mse: 0.01241 |  0:05:11s\n",
      "epoch 120| loss: 0.0148  | train_rmsle: 0.00159 | train_mae: 0.10239 | train_rmse: 0.13969 | train_mse: 0.01951 | valid_rmsle: 0.00175 | valid_mae: 0.11162 | valid_rmse: 0.1494  | valid_mse: 0.02232 |  0:05:14s\n",
      "epoch 121| loss: 0.01294 | train_rmsle: 0.00311 | train_mae: 0.19023 | train_rmse: 0.21458 | train_mse: 0.04604 | valid_rmsle: 0.00345 | valid_mae: 0.19471 | valid_rmse: 0.22386 | valid_mse: 0.05011 |  0:05:16s\n",
      "epoch 122| loss: 0.01865 | train_rmsle: 0.00114 | train_mae: 0.08781 | train_rmse: 0.12169 | train_mse: 0.01481 | valid_rmsle: 0.00123 | valid_mae: 0.09595 | valid_rmse: 0.13168 | valid_mse: 0.01734 |  0:05:19s\n",
      "epoch 123| loss: 0.01541 | train_rmsle: 0.00103 | train_mae: 0.10819 | train_rmse: 0.13383 | train_mse: 0.01791 | valid_rmsle: 0.00123 | valid_mae: 0.11933 | valid_rmse: 0.14861 | valid_mse: 0.02208 |  0:05:22s\n",
      "epoch 124| loss: 0.01529 | train_rmsle: 0.00096 | train_mae: 0.09954 | train_rmse: 0.12772 | train_mse: 0.01631 | valid_rmsle: 0.00135 | valid_mae: 0.1121  | valid_rmse: 0.15059 | valid_mse: 0.02268 |  0:05:24s\n",
      "epoch 125| loss: 0.01504 | train_rmsle: 0.00078 | train_mae: 0.0913  | train_rmse: 0.1142  | train_mse: 0.01304 | valid_rmsle: 0.00095 | valid_mae: 0.10259 | valid_rmse: 0.12868 | valid_mse: 0.01656 |  0:05:27s\n",
      "epoch 126| loss: 0.01367 | train_rmsle: 0.00067 | train_mae: 0.08019 | train_rmse: 0.10259 | train_mse: 0.01052 | valid_rmsle: 0.00084 | valid_mae: 0.08945 | valid_rmse: 0.11624 | valid_mse: 0.01351 |  0:05:30s\n",
      "epoch 127| loss: 0.01403 | train_rmsle: 0.00093 | train_mae: 0.08725 | train_rmse: 0.11541 | train_mse: 0.01332 | valid_rmsle: 0.00113 | valid_mae: 0.09665 | valid_rmse: 0.12723 | valid_mse: 0.01619 |  0:05:32s\n",
      "\n",
      "Early stopping occurred at epoch 127 with best_epoch = 107 and best_valid_mse = 0.00834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009675581572380524 RMSE: 0.09836453411865745 R2: 0.9571699285603725 MAE: 0.07256054381110555\n",
      "=====================================\n",
      "[28/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.5006  | train_rmsle: 0.38629 | train_mae: 1.96568 | train_rmse: 2.02437 | train_mse: 4.09809 | valid_rmsle: 0.38778 | valid_mae: 1.97191 | valid_rmse: 2.02933 | valid_mse: 4.11816 |  0:00:02s\n",
      "epoch 1  | loss: 0.81048 | train_rmsle: 0.07202 | train_mae: 0.95955 | train_rmse: 1.05119 | train_mse: 1.10501 | valid_rmsle: 0.07222 | valid_mae: 0.96167 | valid_rmse: 1.05433 | valid_mse: 1.11161 |  0:00:05s\n",
      "epoch 2  | loss: 0.30723 | train_rmsle: 0.02493 | train_mae: 0.56295 | train_rmse: 0.65304 | train_mse: 0.42646 | valid_rmsle: 0.02471 | valid_mae: 0.56362 | valid_rmse: 0.65391 | valid_mse: 0.4276  |  0:00:07s\n",
      "epoch 3  | loss: 0.27624 | train_rmsle: 0.03998 | train_mae: 0.72044 | train_rmse: 0.81339 | train_mse: 0.6616  | valid_rmsle: 0.03997 | valid_mae: 0.7205  | valid_rmse: 0.81571 | valid_mse: 0.66538 |  0:00:10s\n",
      "epoch 4  | loss: 0.25353 | train_rmsle: 0.03248 | train_mae: 0.64806 | train_rmse: 0.74008 | train_mse: 0.54771 | valid_rmsle: 0.0324  | valid_mae: 0.64786 | valid_rmse: 0.74208 | valid_mse: 0.55069 |  0:00:13s\n",
      "epoch 5  | loss: 0.28372 | train_rmsle: 0.01704 | train_mae: 0.44881 | train_rmse: 0.53646 | train_mse: 0.28779 | valid_rmsle: 0.01658 | valid_mae: 0.44936 | valid_rmse: 0.53414 | valid_mse: 0.28531 |  0:00:15s\n",
      "epoch 6  | loss: 0.2924  | train_rmsle: 0.03551 | train_mae: 0.67831 | train_rmse: 0.77068 | train_mse: 0.59395 | valid_rmsle: 0.03539 | valid_mae: 0.67741 | valid_rmse: 0.7723  | valid_mse: 0.59644 |  0:00:18s\n",
      "epoch 7  | loss: 0.29245 | train_rmsle: 0.02764 | train_mae: 0.59474 | train_rmse: 0.68597 | train_mse: 0.47055 | valid_rmsle: 0.02737 | valid_mae: 0.59448 | valid_rmse: 0.686   | valid_mse: 0.4706  |  0:00:21s\n",
      "epoch 8  | loss: 0.24724 | train_rmsle: 0.01757 | train_mae: 0.4579  | train_rmse: 0.54558 | train_mse: 0.29766 | valid_rmsle: 0.01707 | valid_mae: 0.45862 | valid_rmse: 0.54272 | valid_mse: 0.29455 |  0:00:23s\n",
      "epoch 9  | loss: 0.23568 | train_rmsle: 0.01849 | train_mae: 0.47328 | train_rmse: 0.56097 | train_mse: 0.31469 | valid_rmsle: 0.01814 | valid_mae: 0.47516 | valid_rmse: 0.56028 | valid_mse: 0.31391 |  0:00:26s\n",
      "epoch 10 | loss: 0.2298  | train_rmsle: 0.02123 | train_mae: 0.51433 | train_rmse: 0.60291 | train_mse: 0.3635  | valid_rmsle: 0.02089 | valid_mae: 0.51613 | valid_rmse: 0.60232 | valid_mse: 0.36279 |  0:00:28s\n",
      "epoch 11 | loss: 0.22932 | train_rmsle: 0.01558 | train_mae: 0.41838 | train_rmse: 0.50832 | train_mse: 0.25839 | valid_rmsle: 0.01503 | valid_mae: 0.41841 | valid_rmse: 0.50436 | valid_mse: 0.25438 |  0:00:30s\n",
      "epoch 12 | loss: 0.23527 | train_rmsle: 0.01642 | train_mae: 0.4362  | train_rmse: 0.52485 | train_mse: 0.27547 | valid_rmsle: 0.01594 | valid_mae: 0.43771 | valid_rmse: 0.52204 | valid_mse: 0.27252 |  0:00:33s\n",
      "epoch 13 | loss: 0.22838 | train_rmsle: 0.01685 | train_mae: 0.4438  | train_rmse: 0.53254 | train_mse: 0.2836  | valid_rmsle: 0.01651 | valid_mae: 0.44807 | valid_rmse: 0.53202 | valid_mse: 0.28305 |  0:00:36s\n",
      "epoch 14 | loss: 0.22595 | train_rmsle: 0.01495 | train_mae: 0.40206 | train_rmse: 0.49437 | train_mse: 0.2444  | valid_rmsle: 0.01448 | valid_mae: 0.40408 | valid_rmse: 0.49196 | valid_mse: 0.24203 |  0:00:38s\n",
      "epoch 15 | loss: 0.22644 | train_rmsle: 0.01603 | train_mae: 0.42888 | train_rmse: 0.51771 | train_mse: 0.26802 | valid_rmsle: 0.01557 | valid_mae: 0.43061 | valid_rmse: 0.51533 | valid_mse: 0.26557 |  0:00:41s\n",
      "epoch 16 | loss: 0.22733 | train_rmsle: 0.01479 | train_mae: 0.39802 | train_rmse: 0.49088 | train_mse: 0.24096 | valid_rmsle: 0.01423 | valid_mae: 0.39765 | valid_rmse: 0.48655 | valid_mse: 0.23673 |  0:00:44s\n",
      "epoch 17 | loss: 0.22782 | train_rmsle: 0.01453 | train_mae: 0.38362 | train_rmse: 0.48205 | train_mse: 0.23237 | valid_rmsle: 0.01398 | valid_mae: 0.38435 | valid_rmse: 0.47784 | valid_mse: 0.22833 |  0:00:46s\n",
      "epoch 18 | loss: 0.23185 | train_rmsle: 0.01606 | train_mae: 0.43001 | train_rmse: 0.51843 | train_mse: 0.26877 | valid_rmsle: 0.01569 | valid_mae: 0.43287 | valid_rmse: 0.51732 | valid_mse: 0.26762 |  0:00:49s\n",
      "epoch 19 | loss: 0.22639 | train_rmsle: 0.01464 | train_mae: 0.38854 | train_rmse: 0.48512 | train_mse: 0.23534 | valid_rmsle: 0.01409 | valid_mae: 0.38904 | valid_rmse: 0.48116 | valid_mse: 0.23152 |  0:00:52s\n",
      "epoch 20 | loss: 0.2294  | train_rmsle: 0.01483 | train_mae: 0.39746 | train_rmse: 0.49113 | train_mse: 0.24121 | valid_rmsle: 0.01427 | valid_mae: 0.39842 | valid_rmse: 0.48701 | valid_mse: 0.23717 |  0:00:54s\n",
      "epoch 21 | loss: 0.2239  | train_rmsle: 0.01553 | train_mae: 0.41829 | train_rmse: 0.50783 | train_mse: 0.2579  | valid_rmsle: 0.01503 | valid_mae: 0.41957 | valid_rmse: 0.50492 | valid_mse: 0.25494 |  0:00:57s\n",
      "epoch 22 | loss: 0.2237  | train_rmsle: 0.01488 | train_mae: 0.4027  | train_rmse: 0.49411 | train_mse: 0.24414 | valid_rmsle: 0.01415 | valid_mae: 0.40152 | valid_rmse: 0.487   | valid_mse: 0.23717 |  0:01:00s\n",
      "epoch 23 | loss: 0.22021 | train_rmsle: 0.01451 | train_mae: 0.39184 | train_rmse: 0.48539 | train_mse: 0.23561 | valid_rmsle: 0.01395 | valid_mae: 0.39196 | valid_rmse: 0.4812  | valid_mse: 0.23156 |  0:01:02s\n",
      "epoch 24 | loss: 0.22364 | train_rmsle: 0.01446 | train_mae: 0.38856 | train_rmse: 0.48348 | train_mse: 0.23376 | valid_rmsle: 0.01413 | valid_mae: 0.39265 | valid_rmse: 0.48305 | valid_mse: 0.23334 |  0:01:05s\n",
      "epoch 25 | loss: 0.222   | train_rmsle: 0.01527 | train_mae: 0.41375 | train_rmse: 0.50319 | train_mse: 0.25321 | valid_rmsle: 0.01484 | valid_mae: 0.41515 | valid_rmse: 0.50111 | valid_mse: 0.25111 |  0:01:08s\n",
      "epoch 26 | loss: 0.22127 | train_rmsle: 0.01468 | train_mae: 0.39934 | train_rmse: 0.49027 | train_mse: 0.24036 | valid_rmsle: 0.01434 | valid_mae: 0.40176 | valid_rmse: 0.48971 | valid_mse: 0.23982 |  0:01:11s\n",
      "epoch 27 | loss: 0.22465 | train_rmsle: 0.01473 | train_mae: 0.40141 | train_rmse: 0.49183 | train_mse: 0.2419  | valid_rmsle: 0.01423 | valid_mae: 0.40018 | valid_rmse: 0.4883  | valid_mse: 0.23843 |  0:01:13s\n",
      "epoch 28 | loss: 0.22679 | train_rmsle: 0.01501 | train_mae: 0.37329 | train_rmse: 0.48485 | train_mse: 0.23508 | valid_rmsle: 0.01439 | valid_mae: 0.37352 | valid_rmse: 0.47968 | valid_mse: 0.2301  |  0:01:16s\n",
      "epoch 29 | loss: 0.2306  | train_rmsle: 0.01418 | train_mae: 0.38343 | train_rmse: 0.47752 | train_mse: 0.22802 | valid_rmsle: 0.01376 | valid_mae: 0.38382 | valid_rmse: 0.47545 | valid_mse: 0.22605 |  0:01:19s\n",
      "epoch 30 | loss: 0.218   | train_rmsle: 0.01403 | train_mae: 0.38369 | train_rmse: 0.4762  | train_mse: 0.22677 | valid_rmsle: 0.01368 | valid_mae: 0.38653 | valid_rmse: 0.47564 | valid_mse: 0.22623 |  0:01:21s\n",
      "epoch 31 | loss: 0.21493 | train_rmsle: 0.01429 | train_mae: 0.39493 | train_rmse: 0.48428 | train_mse: 0.23453 | valid_rmsle: 0.01393 | valid_mae: 0.39565 | valid_rmse: 0.4837  | valid_mse: 0.23397 |  0:01:24s\n",
      "epoch 32 | loss: 0.20927 | train_rmsle: 0.01341 | train_mae: 0.36677 | train_rmse: 0.4619  | train_mse: 0.21335 | valid_rmsle: 0.01296 | valid_mae: 0.3683  | valid_rmse: 0.4599  | valid_mse: 0.21151 |  0:01:27s\n",
      "epoch 33 | loss: 0.20775 | train_rmsle: 0.01362 | train_mae: 0.36264 | train_rmse: 0.46338 | train_mse: 0.21472 | valid_rmsle: 0.01311 | valid_mae: 0.36166 | valid_rmse: 0.46024 | valid_mse: 0.21183 |  0:01:29s\n",
      "epoch 34 | loss: 0.2018  | train_rmsle: 0.01327 | train_mae: 0.36491 | train_rmse: 0.45987 | train_mse: 0.21148 | valid_rmsle: 0.01267 | valid_mae: 0.36272 | valid_rmse: 0.45458 | valid_mse: 0.20664 |  0:01:32s\n",
      "epoch 35 | loss: 0.20129 | train_rmsle: 0.01335 | train_mae: 0.36058 | train_rmse: 0.46048 | train_mse: 0.21205 | valid_rmsle: 0.01251 | valid_mae: 0.35891 | valid_rmse: 0.45118 | valid_mse: 0.20356 |  0:01:35s\n",
      "epoch 36 | loss: 0.19472 | train_rmsle: 0.01259 | train_mae: 0.36116 | train_rmse: 0.4499  | train_mse: 0.20241 | valid_rmsle: 0.01233 | valid_mae: 0.36556 | valid_rmse: 0.4507  | valid_mse: 0.20313 |  0:01:37s\n",
      "epoch 37 | loss: 0.18858 | train_rmsle: 0.01251 | train_mae: 0.36537 | train_rmse: 0.45056 | train_mse: 0.203   | valid_rmsle: 0.01248 | valid_mae: 0.37344 | valid_rmse: 0.4554  | valid_mse: 0.20739 |  0:01:39s\n",
      "epoch 38 | loss: 0.17795 | train_rmsle: 0.01132 | train_mae: 0.32307 | train_rmse: 0.41909 | train_mse: 0.17564 | valid_rmsle: 0.01147 | valid_mae: 0.33184 | valid_rmse: 0.42822 | valid_mse: 0.18337 |  0:01:41s\n",
      "epoch 39 | loss: 0.16349 | train_rmsle: 0.01067 | train_mae: 0.31433 | train_rmse: 0.40714 | train_mse: 0.16576 | valid_rmsle: 0.01057 | valid_mae: 0.32321 | valid_rmse: 0.41174 | valid_mse: 0.16953 |  0:01:44s\n",
      "epoch 40 | loss: 0.15527 | train_rmsle: 0.0103  | train_mae: 0.30181 | train_rmse: 0.39766 | train_mse: 0.15813 | valid_rmsle: 0.00993 | valid_mae: 0.30696 | valid_rmse: 0.39673 | valid_mse: 0.1574  |  0:01:46s\n",
      "epoch 41 | loss: 0.14482 | train_rmsle: 0.00939 | train_mae: 0.29849 | train_rmse: 0.38213 | train_mse: 0.14602 | valid_rmsle: 0.00907 | valid_mae: 0.30254 | valid_rmse: 0.38152 | valid_mse: 0.14556 |  0:01:48s\n",
      "epoch 42 | loss: 0.13982 | train_rmsle: 0.00922 | train_mae: 0.28231 | train_rmse: 0.37396 | train_mse: 0.13985 | valid_rmsle: 0.00885 | valid_mae: 0.28759 | valid_rmse: 0.37246 | valid_mse: 0.13873 |  0:01:50s\n",
      "epoch 43 | loss: 0.1355  | train_rmsle: 0.00877 | train_mae: 0.28611 | train_rmse: 0.36816 | train_mse: 0.13554 | valid_rmsle: 0.00847 | valid_mae: 0.29286 | valid_rmse: 0.36886 | valid_mse: 0.13606 |  0:01:52s\n",
      "epoch 44 | loss: 0.13126 | train_rmsle: 0.0087  | train_mae: 0.28634 | train_rmse: 0.36778 | train_mse: 0.13526 | valid_rmsle: 0.00856 | valid_mae: 0.29473 | valid_rmse: 0.37205 | valid_mse: 0.13842 |  0:01:55s\n",
      "epoch 45 | loss: 0.12411 | train_rmsle: 0.00824 | train_mae: 0.27152 | train_rmse: 0.35514 | train_mse: 0.12613 | valid_rmsle: 0.00822 | valid_mae: 0.28295 | valid_rmse: 0.36135 | valid_mse: 0.13057 |  0:01:57s\n",
      "epoch 46 | loss: 0.11818 | train_rmsle: 0.00761 | train_mae: 0.25635 | train_rmse: 0.33799 | train_mse: 0.11423 | valid_rmsle: 0.00737 | valid_mae: 0.26307 | valid_rmse: 0.33932 | valid_mse: 0.11514 |  0:02:00s\n",
      "epoch 47 | loss: 0.11027 | train_rmsle: 0.00732 | train_mae: 0.24795 | train_rmse: 0.32994 | train_mse: 0.10886 | valid_rmsle: 0.00715 | valid_mae: 0.2536  | valid_rmse: 0.33268 | valid_mse: 0.11067 |  0:02:03s\n",
      "epoch 48 | loss: 0.10688 | train_rmsle: 0.0068  | train_mae: 0.24236 | train_rmse: 0.31892 | train_mse: 0.10171 | valid_rmsle: 0.00671 | valid_mae: 0.24912 | valid_rmse: 0.32324 | valid_mse: 0.10448 |  0:02:05s\n",
      "epoch 49 | loss: 0.10101 | train_rmsle: 0.00649 | train_mae: 0.23764 | train_rmse: 0.31176 | train_mse: 0.0972  | valid_rmsle: 0.00631 | valid_mae: 0.24224 | valid_rmse: 0.31325 | valid_mse: 0.09813 |  0:02:08s\n",
      "epoch 50 | loss: 0.09457 | train_rmsle: 0.00612 | train_mae: 0.2304  | train_rmse: 0.30245 | train_mse: 0.09148 | valid_rmsle: 0.0059  | valid_mae: 0.23596 | valid_rmse: 0.30256 | valid_mse: 0.09154 |  0:02:11s\n",
      "epoch 51 | loss: 0.09014 | train_rmsle: 0.00632 | train_mae: 0.24788 | train_rmse: 0.31385 | train_mse: 0.0985  | valid_rmsle: 0.0063  | valid_mae: 0.25824 | valid_rmse: 0.3182  | valid_mse: 0.10125 |  0:02:13s\n",
      "epoch 52 | loss: 0.09301 | train_rmsle: 0.00699 | train_mae: 0.24861 | train_rmse: 0.32658 | train_mse: 0.10666 | valid_rmsle: 0.00692 | valid_mae: 0.255   | valid_rmse: 0.33138 | valid_mse: 0.10981 |  0:02:16s\n",
      "epoch 53 | loss: 0.08836 | train_rmsle: 0.00555 | train_mae: 0.21444 | train_rmse: 0.28624 | train_mse: 0.08193 | valid_rmsle: 0.00552 | valid_mae: 0.22204 | valid_rmse: 0.29161 | valid_mse: 0.08504 |  0:02:19s\n",
      "epoch 54 | loss: 0.0802  | train_rmsle: 0.00512 | train_mae: 0.20469 | train_rmse: 0.27443 | train_mse: 0.07531 | valid_rmsle: 0.00524 | valid_mae: 0.2161  | valid_rmse: 0.28332 | valid_mse: 0.08027 |  0:02:21s\n",
      "epoch 55 | loss: 0.07663 | train_rmsle: 0.00515 | train_mae: 0.20694 | train_rmse: 0.27553 | train_mse: 0.07592 | valid_rmsle: 0.00531 | valid_mae: 0.21631 | valid_rmse: 0.28588 | valid_mse: 0.08173 |  0:02:24s\n",
      "epoch 56 | loss: 0.06764 | train_rmsle: 0.00449 | train_mae: 0.19452 | train_rmse: 0.25784 | train_mse: 0.06648 | valid_rmsle: 0.00473 | valid_mae: 0.20917 | valid_rmse: 0.27098 | valid_mse: 0.07343 |  0:02:27s\n",
      "epoch 57 | loss: 0.06548 | train_rmsle: 0.00408 | train_mae: 0.18572 | train_rmse: 0.24674 | train_mse: 0.06088 | valid_rmsle: 0.00439 | valid_mae: 0.20084 | valid_rmse: 0.2612  | valid_mse: 0.06822 |  0:02:30s\n",
      "epoch 58 | loss: 0.06261 | train_rmsle: 0.00393 | train_mae: 0.18119 | train_rmse: 0.24081 | train_mse: 0.05799 | valid_rmsle: 0.00428 | valid_mae: 0.19724 | valid_rmse: 0.25791 | valid_mse: 0.06652 |  0:02:32s\n",
      "epoch 59 | loss: 0.05532 | train_rmsle: 0.00356 | train_mae: 0.17174 | train_rmse: 0.22865 | train_mse: 0.05228 | valid_rmsle: 0.00372 | valid_mae: 0.18292 | valid_rmse: 0.2401  | valid_mse: 0.05765 |  0:02:35s\n",
      "epoch 60 | loss: 0.05406 | train_rmsle: 0.00355 | train_mae: 0.17381 | train_rmse: 0.22992 | train_mse: 0.05286 | valid_rmsle: 0.00375 | valid_mae: 0.18618 | valid_rmse: 0.24138 | valid_mse: 0.05826 |  0:02:38s\n",
      "epoch 61 | loss: 0.05543 | train_rmsle: 0.00329 | train_mae: 0.16722 | train_rmse: 0.22143 | train_mse: 0.04903 | valid_rmsle: 0.00351 | valid_mae: 0.1807  | valid_rmse: 0.23404 | valid_mse: 0.05477 |  0:02:41s\n",
      "epoch 62 | loss: 0.04808 | train_rmsle: 0.00282 | train_mae: 0.15349 | train_rmse: 0.20468 | train_mse: 0.04189 | valid_rmsle: 0.00291 | valid_mae: 0.16525 | valid_rmse: 0.21383 | valid_mse: 0.04572 |  0:02:43s\n",
      "epoch 63 | loss: 0.04301 | train_rmsle: 0.00286 | train_mae: 0.15236 | train_rmse: 0.20395 | train_mse: 0.04159 | valid_rmsle: 0.00294 | valid_mae: 0.16218 | valid_rmse: 0.21323 | valid_mse: 0.04547 |  0:02:46s\n",
      "epoch 64 | loss: 0.03849 | train_rmsle: 0.00244 | train_mae: 0.14111 | train_rmse: 0.18898 | train_mse: 0.03571 | valid_rmsle: 0.00251 | valid_mae: 0.14962 | valid_rmse: 0.19693 | valid_mse: 0.03878 |  0:02:49s\n",
      "epoch 65 | loss: 0.03674 | train_rmsle: 0.00216 | train_mae: 0.13248 | train_rmse: 0.17779 | train_mse: 0.03161 | valid_rmsle: 0.00219 | valid_mae: 0.14014 | valid_rmse: 0.18315 | valid_mse: 0.03354 |  0:02:51s\n",
      "epoch 66 | loss: 0.03336 | train_rmsle: 0.00216 | train_mae: 0.12948 | train_rmse: 0.17584 | train_mse: 0.03092 | valid_rmsle: 0.00214 | valid_mae: 0.13529 | valid_rmse: 0.17902 | valid_mse: 0.03205 |  0:02:54s\n",
      "epoch 67 | loss: 0.02985 | train_rmsle: 0.00192 | train_mae: 0.12252 | train_rmse: 0.1662  | train_mse: 0.02762 | valid_rmsle: 0.00187 | valid_mae: 0.12943 | valid_rmse: 0.1683  | valid_mse: 0.02832 |  0:02:57s\n",
      "epoch 68 | loss: 0.03111 | train_rmsle: 0.00216 | train_mae: 0.13348 | train_rmse: 0.17723 | train_mse: 0.03141 | valid_rmsle: 0.00205 | valid_mae: 0.13614 | valid_rmse: 0.17701 | valid_mse: 0.03133 |  0:02:59s\n",
      "epoch 69 | loss: 0.03104 | train_rmsle: 0.00188 | train_mae: 0.12885 | train_rmse: 0.1698  | train_mse: 0.02883 | valid_rmsle: 0.0019  | valid_mae: 0.13567 | valid_rmse: 0.17447 | valid_mse: 0.03044 |  0:03:02s\n",
      "epoch 70 | loss: 0.02975 | train_rmsle: 0.00211 | train_mae: 0.13847 | train_rmse: 0.17907 | train_mse: 0.03206 | valid_rmsle: 0.00207 | valid_mae: 0.14328 | valid_rmse: 0.18128 | valid_mse: 0.03286 |  0:03:05s\n",
      "epoch 71 | loss: 0.03262 | train_rmsle: 0.00177 | train_mae: 0.1194  | train_rmse: 0.15954 | train_mse: 0.02545 | valid_rmsle: 0.00168 | valid_mae: 0.12279 | valid_rmse: 0.15968 | valid_mse: 0.0255  |  0:03:07s\n",
      "epoch 72 | loss: 0.02628 | train_rmsle: 0.00196 | train_mae: 0.13301 | train_rmse: 0.17139 | train_mse: 0.02937 | valid_rmsle: 0.00198 | valid_mae: 0.13709 | valid_rmse: 0.17553 | valid_mse: 0.03081 |  0:03:10s\n",
      "epoch 73 | loss: 0.02461 | train_rmsle: 0.00147 | train_mae: 0.11334 | train_rmse: 0.14825 | train_mse: 0.02198 | valid_rmsle: 0.0015  | valid_mae: 0.11926 | valid_rmse: 0.15314 | valid_mse: 0.02345 |  0:03:12s\n",
      "epoch 74 | loss: 0.02133 | train_rmsle: 0.0018  | train_mae: 0.11523 | train_rmse: 0.15988 | train_mse: 0.02556 | valid_rmsle: 0.00179 | valid_mae: 0.1192  | valid_rmse: 0.16299 | valid_mse: 0.02657 |  0:03:14s\n",
      "epoch 75 | loss: 0.02257 | train_rmsle: 0.00151 | train_mae: 0.11256 | train_rmse: 0.15004 | train_mse: 0.02251 | valid_rmsle: 0.0016  | valid_mae: 0.11776 | valid_rmse: 0.15687 | valid_mse: 0.02461 |  0:03:16s\n",
      "epoch 76 | loss: 0.02286 | train_rmsle: 0.00165 | train_mae: 0.13599 | train_rmse: 0.16725 | train_mse: 0.02797 | valid_rmsle: 0.00169 | valid_mae: 0.14182 | valid_rmse: 0.17178 | valid_mse: 0.02951 |  0:03:18s\n",
      "epoch 77 | loss: 0.02379 | train_rmsle: 0.00111 | train_mae: 0.09618 | train_rmse: 0.12796 | train_mse: 0.01637 | valid_rmsle: 0.00114 | valid_mae: 0.10319 | valid_rmse: 0.13359 | valid_mse: 0.01785 |  0:03:20s\n",
      "epoch 78 | loss: 0.01931 | train_rmsle: 0.00105 | train_mae: 0.09144 | train_rmse: 0.12261 | train_mse: 0.01503 | valid_rmsle: 0.00106 | valid_mae: 0.09571 | valid_rmse: 0.1277  | valid_mse: 0.01631 |  0:03:22s\n",
      "epoch 79 | loss: 0.0199  | train_rmsle: 0.00123 | train_mae: 0.09902 | train_rmse: 0.13283 | train_mse: 0.01764 | valid_rmsle: 0.00124 | valid_mae: 0.10435 | valid_rmse: 0.13782 | valid_mse: 0.019   |  0:03:25s\n",
      "epoch 80 | loss: 0.0166  | train_rmsle: 0.00088 | train_mae: 0.08713 | train_rmse: 0.11605 | train_mse: 0.01347 | valid_rmsle: 0.00101 | valid_mae: 0.0958  | valid_rmse: 0.12636 | valid_mse: 0.01597 |  0:03:28s\n",
      "epoch 81 | loss: 0.0181  | train_rmsle: 0.00129 | train_mae: 0.10571 | train_rmse: 0.13708 | train_mse: 0.01879 | valid_rmsle: 0.00126 | valid_mae: 0.10968 | valid_rmse: 0.13914 | valid_mse: 0.01936 |  0:03:30s\n",
      "epoch 82 | loss: 0.02088 | train_rmsle: 0.00142 | train_mae: 0.10962 | train_rmse: 0.14253 | train_mse: 0.02031 | valid_rmsle: 0.00142 | valid_mae: 0.11247 | valid_rmse: 0.14579 | valid_mse: 0.02126 |  0:03:33s\n",
      "epoch 83 | loss: 0.02001 | train_rmsle: 0.00085 | train_mae: 0.08822 | train_rmse: 0.11547 | train_mse: 0.01333 | valid_rmsle: 0.00093 | valid_mae: 0.0944  | valid_rmse: 0.12257 | valid_mse: 0.01502 |  0:03:36s\n",
      "epoch 84 | loss: 0.02087 | train_rmsle: 0.00131 | train_mae: 0.1185  | train_rmse: 0.15093 | train_mse: 0.02278 | valid_rmsle: 0.00145 | valid_mae: 0.12422 | valid_rmse: 0.15859 | valid_mse: 0.02515 |  0:03:38s\n",
      "epoch 85 | loss: 0.0201  | train_rmsle: 0.00182 | train_mae: 0.14885 | train_rmse: 0.17896 | train_mse: 0.03203 | valid_rmsle: 0.00198 | valid_mae: 0.15467 | valid_rmse: 0.18512 | valid_mse: 0.03427 |  0:03:41s\n",
      "epoch 86 | loss: 0.0226  | train_rmsle: 0.00146 | train_mae: 0.13072 | train_rmse: 0.16188 | train_mse: 0.02621 | valid_rmsle: 0.00158 | valid_mae: 0.13725 | valid_rmse: 0.16799 | valid_mse: 0.02822 |  0:03:44s\n",
      "epoch 87 | loss: 0.02137 | train_rmsle: 0.00097 | train_mae: 0.09689 | train_rmse: 0.12588 | train_mse: 0.01585 | valid_rmsle: 0.00111 | valid_mae: 0.10367 | valid_rmse: 0.13474 | valid_mse: 0.01815 |  0:03:46s\n",
      "epoch 88 | loss: 0.01896 | train_rmsle: 0.00086 | train_mae: 0.08733 | train_rmse: 0.11676 | train_mse: 0.01363 | valid_rmsle: 0.00095 | valid_mae: 0.09277 | valid_rmse: 0.12405 | valid_mse: 0.01539 |  0:03:49s\n",
      "epoch 89 | loss: 0.01749 | train_rmsle: 0.00088 | train_mae: 0.08744 | train_rmse: 0.11586 | train_mse: 0.01342 | valid_rmsle: 0.00093 | valid_mae: 0.09235 | valid_rmse: 0.12176 | valid_mse: 0.01483 |  0:03:52s\n",
      "epoch 90 | loss: 0.01584 | train_rmsle: 0.00074 | train_mae: 0.08637 | train_rmse: 0.11332 | train_mse: 0.01284 | valid_rmsle: 0.0009  | valid_mae: 0.09471 | valid_rmse: 0.12478 | valid_mse: 0.01557 |  0:03:54s\n",
      "epoch 91 | loss: 0.01657 | train_rmsle: 0.00068 | train_mae: 0.07749 | train_rmse: 0.10257 | train_mse: 0.01052 | valid_rmsle: 0.00075 | valid_mae: 0.08401 | valid_rmse: 0.10997 | valid_mse: 0.01209 |  0:03:57s\n",
      "epoch 92 | loss: 0.01725 | train_rmsle: 0.00071 | train_mae: 0.07545 | train_rmse: 0.10183 | train_mse: 0.01037 | valid_rmsle: 0.00074 | valid_mae: 0.08071 | valid_rmse: 0.108   | valid_mse: 0.01166 |  0:04:00s\n",
      "epoch 93 | loss: 0.01444 | train_rmsle: 0.00051 | train_mae: 0.0687  | train_rmse: 0.09075 | train_mse: 0.00824 | valid_rmsle: 0.00059 | valid_mae: 0.07612 | valid_rmse: 0.09893 | valid_mse: 0.00979 |  0:04:02s\n",
      "epoch 94 | loss: 0.01506 | train_rmsle: 0.00096 | train_mae: 0.10995 | train_rmse: 0.13142 | train_mse: 0.01727 | valid_rmsle: 0.00106 | valid_mae: 0.11533 | valid_rmse: 0.13821 | valid_mse: 0.0191  |  0:04:05s\n",
      "epoch 95 | loss: 0.01786 | train_rmsle: 0.00055 | train_mae: 0.07421 | train_rmse: 0.09633 | train_mse: 0.00928 | valid_rmsle: 0.00066 | valid_mae: 0.08042 | valid_rmse: 0.1058  | valid_mse: 0.01119 |  0:04:08s\n",
      "epoch 96 | loss: 0.01357 | train_rmsle: 0.00175 | train_mae: 0.0957  | train_rmse: 0.17275 | train_mse: 0.02984 | valid_rmsle: 0.00243 | valid_mae: 0.10613 | valid_rmse: 0.20133 | valid_mse: 0.04053 |  0:04:10s\n",
      "epoch 97 | loss: 0.01302 | train_rmsle: 0.00075 | train_mae: 0.08929 | train_rmse: 0.11033 | train_mse: 0.01217 | valid_rmsle: 0.00088 | valid_mae: 0.09609 | valid_rmse: 0.11976 | valid_mse: 0.01434 |  0:04:13s\n",
      "epoch 98 | loss: 0.0127  | train_rmsle: 0.00079 | train_mae: 0.07296 | train_rmse: 0.10218 | train_mse: 0.01044 | valid_rmsle: 0.00078 | valid_mae: 0.07759 | valid_rmse: 0.10609 | valid_mse: 0.01125 |  0:04:16s\n",
      "epoch 99 | loss: 0.0129  | train_rmsle: 0.00062 | train_mae: 0.0815  | train_rmse: 0.10205 | train_mse: 0.01041 | valid_rmsle: 0.00069 | valid_mae: 0.08679 | valid_rmse: 0.10892 | valid_mse: 0.01186 |  0:04:18s\n",
      "epoch 100| loss: 0.01197 | train_rmsle: 0.00043 | train_mae: 0.06619 | train_rmse: 0.08511 | train_mse: 0.00724 | valid_rmsle: 0.00053 | valid_mae: 0.07256 | valid_rmse: 0.0951  | valid_mse: 0.00904 |  0:04:21s\n",
      "epoch 101| loss: 0.01156 | train_rmsle: 0.00054 | train_mae: 0.07154 | train_rmse: 0.09226 | train_mse: 0.00851 | valid_rmsle: 0.00062 | valid_mae: 0.07755 | valid_rmse: 0.10064 | valid_mse: 0.01013 |  0:04:24s\n",
      "epoch 102| loss: 0.01348 | train_rmsle: 0.00059 | train_mae: 0.08123 | train_rmse: 0.1017  | train_mse: 0.01034 | valid_rmsle: 0.00068 | valid_mae: 0.08624 | valid_rmse: 0.10981 | valid_mse: 0.01206 |  0:04:26s\n",
      "epoch 103| loss: 0.01456 | train_rmsle: 0.00052 | train_mae: 0.07016 | train_rmse: 0.0915  | train_mse: 0.00837 | valid_rmsle: 0.00059 | valid_mae: 0.07592 | valid_rmse: 0.0997  | valid_mse: 0.00994 |  0:04:29s\n",
      "epoch 104| loss: 0.01619 | train_rmsle: 0.00054 | train_mae: 0.07406 | train_rmse: 0.095   | train_mse: 0.00903 | valid_rmsle: 0.00065 | valid_mae: 0.08142 | valid_rmse: 0.10537 | valid_mse: 0.0111  |  0:04:32s\n",
      "epoch 105| loss: 0.01377 | train_rmsle: 0.00067 | train_mae: 0.08006 | train_rmse: 0.10283 | train_mse: 0.01057 | valid_rmsle: 0.00085 | valid_mae: 0.08653 | valid_rmse: 0.11431 | valid_mse: 0.01307 |  0:04:34s\n",
      "epoch 106| loss: 0.01101 | train_rmsle: 0.00042 | train_mae: 0.06397 | train_rmse: 0.08253 | train_mse: 0.00681 | valid_rmsle: 0.00053 | valid_mae: 0.07174 | valid_rmse: 0.09304 | valid_mse: 0.00866 |  0:04:37s\n",
      "epoch 107| loss: 0.01174 | train_rmsle: 0.0004  | train_mae: 0.06317 | train_rmse: 0.08354 | train_mse: 0.00698 | valid_rmsle: 0.00048 | valid_mae: 0.06929 | valid_rmse: 0.0913  | valid_mse: 0.00834 |  0:04:39s\n",
      "epoch 108| loss: 0.01245 | train_rmsle: 0.00041 | train_mae: 0.06276 | train_rmse: 0.08214 | train_mse: 0.00675 | valid_rmsle: 0.00051 | valid_mae: 0.07085 | valid_rmse: 0.09188 | valid_mse: 0.00844 |  0:04:42s\n",
      "epoch 109| loss: 0.01353 | train_rmsle: 0.00043 | train_mae: 0.06436 | train_rmse: 0.08314 | train_mse: 0.00691 | valid_rmsle: 0.00054 | valid_mae: 0.07158 | valid_rmse: 0.09278 | valid_mse: 0.00861 |  0:04:44s\n",
      "epoch 110| loss: 0.01188 | train_rmsle: 0.00067 | train_mae: 0.08439 | train_rmse: 0.10415 | train_mse: 0.01085 | valid_rmsle: 0.00079 | valid_mae: 0.0898  | valid_rmse: 0.11242 | valid_mse: 0.01264 |  0:04:46s\n",
      "epoch 111| loss: 0.01276 | train_rmsle: 0.00141 | train_mae: 0.13216 | train_rmse: 0.15908 | train_mse: 0.02531 | valid_rmsle: 0.00166 | valid_mae: 0.14165 | valid_rmse: 0.17093 | valid_mse: 0.02922 |  0:04:49s\n",
      "epoch 112| loss: 0.01662 | train_rmsle: 0.00091 | train_mae: 0.10362 | train_rmse: 0.129   | train_mse: 0.01664 | valid_rmsle: 0.00108 | valid_mae: 0.11256 | valid_rmse: 0.14047 | valid_mse: 0.01973 |  0:04:51s\n",
      "epoch 113| loss: 0.01589 | train_rmsle: 0.00066 | train_mae: 0.08174 | train_rmse: 0.10375 | train_mse: 0.01076 | valid_rmsle: 0.0008  | valid_mae: 0.08943 | valid_rmse: 0.11427 | valid_mse: 0.01306 |  0:04:54s\n",
      "epoch 114| loss: 0.0163  | train_rmsle: 0.00054 | train_mae: 0.07447 | train_rmse: 0.09593 | train_mse: 0.0092  | valid_rmsle: 0.00068 | valid_mae: 0.08211 | valid_rmse: 0.10663 | valid_mse: 0.01137 |  0:04:57s\n",
      "epoch 115| loss: 0.01206 | train_rmsle: 0.00059 | train_mae: 0.07337 | train_rmse: 0.09441 | train_mse: 0.00891 | valid_rmsle: 0.00069 | valid_mae: 0.07917 | valid_rmse: 0.10262 | valid_mse: 0.01053 |  0:04:59s\n",
      "epoch 116| loss: 0.01415 | train_rmsle: 0.00087 | train_mae: 0.09352 | train_rmse: 0.11867 | train_mse: 0.01408 | valid_rmsle: 0.00098 | valid_mae: 0.10108 | valid_rmse: 0.12698 | valid_mse: 0.01612 |  0:05:02s\n",
      "epoch 117| loss: 0.01416 | train_rmsle: 0.00087 | train_mae: 0.09896 | train_rmse: 0.12323 | train_mse: 0.01518 | valid_rmsle: 0.00102 | valid_mae: 0.10554 | valid_rmse: 0.13257 | valid_mse: 0.01757 |  0:05:05s\n",
      "epoch 118| loss: 0.01468 | train_rmsle: 0.00057 | train_mae: 0.0714  | train_rmse: 0.09239 | train_mse: 0.00854 | valid_rmsle: 0.00064 | valid_mae: 0.07851 | valid_rmse: 0.10075 | valid_mse: 0.01015 |  0:05:07s\n",
      "epoch 119| loss: 0.01782 | train_rmsle: 0.00064 | train_mae: 0.08202 | train_rmse: 0.10239 | train_mse: 0.01048 | valid_rmsle: 0.00075 | valid_mae: 0.08855 | valid_rmse: 0.11141 | valid_mse: 0.01241 |  0:05:09s\n",
      "epoch 120| loss: 0.0148  | train_rmsle: 0.00159 | train_mae: 0.10239 | train_rmse: 0.13969 | train_mse: 0.01951 | valid_rmsle: 0.00175 | valid_mae: 0.11162 | valid_rmse: 0.1494  | valid_mse: 0.02232 |  0:05:11s\n",
      "epoch 121| loss: 0.01294 | train_rmsle: 0.00311 | train_mae: 0.19023 | train_rmse: 0.21458 | train_mse: 0.04604 | valid_rmsle: 0.00345 | valid_mae: 0.19471 | valid_rmse: 0.22386 | valid_mse: 0.05011 |  0:05:14s\n",
      "epoch 122| loss: 0.01865 | train_rmsle: 0.00114 | train_mae: 0.08781 | train_rmse: 0.12169 | train_mse: 0.01481 | valid_rmsle: 0.00123 | valid_mae: 0.09595 | valid_rmse: 0.13168 | valid_mse: 0.01734 |  0:05:16s\n",
      "epoch 123| loss: 0.01541 | train_rmsle: 0.00103 | train_mae: 0.10819 | train_rmse: 0.13383 | train_mse: 0.01791 | valid_rmsle: 0.00123 | valid_mae: 0.11933 | valid_rmse: 0.14861 | valid_mse: 0.02208 |  0:05:19s\n",
      "epoch 124| loss: 0.01529 | train_rmsle: 0.00096 | train_mae: 0.09954 | train_rmse: 0.12772 | train_mse: 0.01631 | valid_rmsle: 0.00135 | valid_mae: 0.1121  | valid_rmse: 0.15059 | valid_mse: 0.02268 |  0:05:22s\n",
      "epoch 125| loss: 0.01504 | train_rmsle: 0.00078 | train_mae: 0.0913  | train_rmse: 0.1142  | train_mse: 0.01304 | valid_rmsle: 0.00095 | valid_mae: 0.10259 | valid_rmse: 0.12868 | valid_mse: 0.01656 |  0:05:25s\n",
      "epoch 126| loss: 0.01367 | train_rmsle: 0.00067 | train_mae: 0.08019 | train_rmse: 0.10259 | train_mse: 0.01052 | valid_rmsle: 0.00084 | valid_mae: 0.08945 | valid_rmse: 0.11624 | valid_mse: 0.01351 |  0:05:27s\n",
      "epoch 127| loss: 0.01403 | train_rmsle: 0.00093 | train_mae: 0.08725 | train_rmse: 0.11541 | train_mse: 0.01332 | valid_rmsle: 0.00113 | valid_mae: 0.09665 | valid_rmse: 0.12723 | valid_mse: 0.01619 |  0:05:30s\n",
      "\n",
      "Early stopping occurred at epoch 127 with best_epoch = 107 and best_valid_mse = 0.00834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009675581572380524 RMSE: 0.09836453411865745 R2: 0.9571699285603725 MAE: 0.07256054381110555\n",
      "=====================================\n",
      "[29/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.05908 | train_rmsle: 0.47254 | train_mae: 2.11567 | train_rmse: 2.1693  | train_mse: 4.70588 | valid_rmsle: 0.47418 | valid_mae: 2.12187 | valid_rmse: 2.17427 | valid_mse: 4.72744 |  0:00:02s\n",
      "epoch 1  | loss: 1.73136 | train_rmsle: 0.12324 | train_mae: 1.22946 | train_rmse: 1.31296 | train_mse: 1.72386 | valid_rmsle: 0.12387 | valid_mae: 1.23267 | valid_rmse: 1.31742 | valid_mse: 1.7356  |  0:00:05s\n",
      "epoch 2  | loss: 0.66051 | train_rmsle: 0.04418 | train_mae: 0.75613 | train_rmse: 0.85082 | train_mse: 0.72389 | valid_rmsle: 0.04431 | valid_mae: 0.75629 | valid_rmse: 0.85431 | valid_mse: 0.72985 |  0:00:08s\n",
      "epoch 3  | loss: 0.35578 | train_rmsle: 0.02838 | train_mae: 0.60273 | train_rmse: 0.69509 | train_mse: 0.48315 | valid_rmsle: 0.02832 | valid_mae: 0.60343 | valid_rmse: 0.69767 | valid_mse: 0.48675 |  0:00:11s\n",
      "epoch 4  | loss: 0.29529 | train_rmsle: 0.01976 | train_mae: 0.49278 | train_rmse: 0.5817  | train_mse: 0.33837 | valid_rmsle: 0.0195  | valid_mae: 0.49447 | valid_rmse: 0.58226 | valid_mse: 0.33902 |  0:00:13s\n",
      "epoch 5  | loss: 0.26514 | train_rmsle: 0.02487 | train_mae: 0.56187 | train_rmse: 0.65226 | train_mse: 0.42545 | valid_rmsle: 0.02464 | valid_mae: 0.56264 | valid_rmse: 0.65296 | valid_mse: 0.42636 |  0:00:16s\n",
      "epoch 6  | loss: 0.26767 | train_rmsle: 0.0184  | train_mae: 0.47147 | train_rmse: 0.55986 | train_mse: 0.31344 | valid_rmsle: 0.018   | valid_mae: 0.47183 | valid_rmse: 0.55841 | valid_mse: 0.31182 |  0:00:18s\n",
      "epoch 7  | loss: 0.24778 | train_rmsle: 0.01839 | train_mae: 0.47148 | train_rmse: 0.55945 | train_mse: 0.31299 | valid_rmsle: 0.01797 | valid_mae: 0.47189 | valid_rmse: 0.55772 | valid_mse: 0.31106 |  0:00:21s\n",
      "epoch 8  | loss: 0.24935 | train_rmsle: 0.01736 | train_mae: 0.45375 | train_rmse: 0.54173 | train_mse: 0.29348 | valid_rmsle: 0.01692 | valid_mae: 0.45478 | valid_rmse: 0.53974 | valid_mse: 0.29132 |  0:00:23s\n",
      "epoch 9  | loss: 0.23796 | train_rmsle: 0.01469 | train_mae: 0.39167 | train_rmse: 0.48715 | train_mse: 0.23732 | valid_rmsle: 0.01424 | valid_mae: 0.39355 | valid_rmse: 0.485   | valid_mse: 0.23523 |  0:00:26s\n",
      "epoch 10 | loss: 0.23537 | train_rmsle: 0.01584 | train_mae: 0.42429 | train_rmse: 0.51604 | train_mse: 0.2663  | valid_rmsle: 0.01555 | valid_mae: 0.42633 | valid_rmse: 0.51654 | valid_mse: 0.26681 |  0:00:28s\n",
      "epoch 11 | loss: 0.23317 | train_rmsle: 0.01584 | train_mae: 0.42496 | train_rmse: 0.51637 | train_mse: 0.26664 | valid_rmsle: 0.01546 | valid_mae: 0.42625 | valid_rmse: 0.51497 | valid_mse: 0.26519 |  0:00:31s\n",
      "epoch 12 | loss: 0.23496 | train_rmsle: 0.01835 | train_mae: 0.4682  | train_rmse: 0.56025 | train_mse: 0.31388 | valid_rmsle: 0.01839 | valid_mae: 0.47186 | valid_rmse: 0.56515 | valid_mse: 0.3194  |  0:00:33s\n",
      "epoch 13 | loss: 0.25756 | train_rmsle: 0.0161  | train_mae: 0.43016 | train_rmse: 0.51925 | train_mse: 0.26962 | valid_rmsle: 0.01585 | valid_mae: 0.4337  | valid_rmse: 0.52047 | valid_mse: 0.27088 |  0:00:36s\n",
      "epoch 14 | loss: 0.22973 | train_rmsle: 0.01576 | train_mae: 0.42266 | train_rmse: 0.51252 | train_mse: 0.26268 | valid_rmsle: 0.01545 | valid_mae: 0.42569 | valid_rmse: 0.51271 | valid_mse: 0.26287 |  0:00:39s\n",
      "epoch 15 | loss: 0.2283  | train_rmsle: 0.01662 | train_mae: 0.43979 | train_rmse: 0.52924 | train_mse: 0.2801  | valid_rmsle: 0.01619 | valid_mae: 0.44086 | valid_rmse: 0.52738 | valid_mse: 0.27813 |  0:00:42s\n",
      "epoch 16 | loss: 0.22833 | train_rmsle: 0.0165  | train_mae: 0.43861 | train_rmse: 0.52848 | train_mse: 0.27929 | valid_rmsle: 0.0162  | valid_mae: 0.44058 | valid_rmse: 0.52858 | valid_mse: 0.2794  |  0:00:44s\n",
      "epoch 17 | loss: 0.23841 | train_rmsle: 0.01752 | train_mae: 0.45323 | train_rmse: 0.54674 | train_mse: 0.29893 | valid_rmsle: 0.01717 | valid_mae: 0.45383 | valid_rmse: 0.54614 | valid_mse: 0.29827 |  0:00:47s\n",
      "epoch 18 | loss: 0.22498 | train_rmsle: 0.01524 | train_mae: 0.41174 | train_rmse: 0.50336 | train_mse: 0.25337 | valid_rmsle: 0.01484 | valid_mae: 0.4143  | valid_rmse: 0.5018  | valid_mse: 0.2518  |  0:00:50s\n",
      "epoch 19 | loss: 0.23052 | train_rmsle: 0.01458 | train_mae: 0.39587 | train_rmse: 0.48906 | train_mse: 0.23918 | valid_rmsle: 0.01412 | valid_mae: 0.39867 | valid_rmse: 0.48661 | valid_mse: 0.23679 |  0:00:53s\n",
      "epoch 20 | loss: 0.22686 | train_rmsle: 0.01455 | train_mae: 0.3936  | train_rmse: 0.48789 | train_mse: 0.23804 | valid_rmsle: 0.01418 | valid_mae: 0.39723 | valid_rmse: 0.48744 | valid_mse: 0.2376  |  0:00:55s\n",
      "epoch 21 | loss: 0.22268 | train_rmsle: 0.01462 | train_mae: 0.3948  | train_rmse: 0.48849 | train_mse: 0.23863 | valid_rmsle: 0.01415 | valid_mae: 0.39705 | valid_rmse: 0.48584 | valid_mse: 0.23604 |  0:00:58s\n",
      "epoch 22 | loss: 0.22098 | train_rmsle: 0.01476 | train_mae: 0.40099 | train_rmse: 0.49349 | train_mse: 0.24353 | valid_rmsle: 0.01454 | valid_mae: 0.40547 | valid_rmse: 0.49505 | valid_mse: 0.24508 |  0:01:01s\n",
      "epoch 23 | loss: 0.22229 | train_rmsle: 0.01448 | train_mae: 0.37833 | train_rmse: 0.48001 | train_mse: 0.23041 | valid_rmsle: 0.01414 | valid_mae: 0.38227 | valid_rmse: 0.47961 | valid_mse: 0.23002 |  0:01:03s\n",
      "epoch 24 | loss: 0.22701 | train_rmsle: 0.0146  | train_mae: 0.39668 | train_rmse: 0.48941 | train_mse: 0.23952 | valid_rmsle: 0.0145  | valid_mae: 0.40422 | valid_rmse: 0.49314 | valid_mse: 0.24319 |  0:01:06s\n",
      "epoch 25 | loss: 0.21869 | train_rmsle: 0.01512 | train_mae: 0.41106 | train_rmse: 0.50137 | train_mse: 0.25137 | valid_rmsle: 0.01492 | valid_mae: 0.41508 | valid_rmse: 0.50293 | valid_mse: 0.25294 |  0:01:09s\n",
      "epoch 26 | loss: 0.22466 | train_rmsle: 0.01461 | train_mae: 0.39633 | train_rmse: 0.48937 | train_mse: 0.23948 | valid_rmsle: 0.01439 | valid_mae: 0.40107 | valid_rmse: 0.49118 | valid_mse: 0.24126 |  0:01:11s\n",
      "epoch 27 | loss: 0.22305 | train_rmsle: 0.01432 | train_mae: 0.38755 | train_rmse: 0.48251 | train_mse: 0.23281 | valid_rmsle: 0.01407 | valid_mae: 0.39293 | valid_rmse: 0.48384 | valid_mse: 0.2341  |  0:01:13s\n",
      "epoch 28 | loss: 0.21922 | train_rmsle: 0.01449 | train_mae: 0.37513 | train_rmse: 0.4789  | train_mse: 0.22935 | valid_rmsle: 0.01415 | valid_mae: 0.38132 | valid_rmse: 0.47882 | valid_mse: 0.22927 |  0:01:16s\n",
      "epoch 29 | loss: 0.2237  | train_rmsle: 0.01447 | train_mae: 0.3936  | train_rmse: 0.48722 | train_mse: 0.23738 | valid_rmsle: 0.01425 | valid_mae: 0.39722 | valid_rmse: 0.48889 | valid_mse: 0.23901 |  0:01:18s\n",
      "epoch 30 | loss: 0.21786 | train_rmsle: 0.01415 | train_mae: 0.38397 | train_rmse: 0.47911 | train_mse: 0.22955 | valid_rmsle: 0.01393 | valid_mae: 0.38951 | valid_rmse: 0.48125 | valid_mse: 0.2316  |  0:01:20s\n",
      "epoch 31 | loss: 0.21794 | train_rmsle: 0.01436 | train_mae: 0.39225 | train_rmse: 0.48502 | train_mse: 0.23525 | valid_rmsle: 0.01402 | valid_mae: 0.39699 | valid_rmse: 0.48454 | valid_mse: 0.23477 |  0:01:23s\n",
      "epoch 32 | loss: 0.22299 | train_rmsle: 0.01421 | train_mae: 0.38627 | train_rmse: 0.4811  | train_mse: 0.23146 | valid_rmsle: 0.01384 | valid_mae: 0.39113 | valid_rmse: 0.48022 | valid_mse: 0.23061 |  0:01:25s\n",
      "epoch 33 | loss: 0.22265 | train_rmsle: 0.01409 | train_mae: 0.38044 | train_rmse: 0.47674 | train_mse: 0.22728 | valid_rmsle: 0.01377 | valid_mae: 0.38615 | valid_rmse: 0.47677 | valid_mse: 0.22731 |  0:01:28s\n",
      "epoch 34 | loss: 0.21771 | train_rmsle: 0.01442 | train_mae: 0.37134 | train_rmse: 0.47669 | train_mse: 0.22723 | valid_rmsle: 0.01418 | valid_mae: 0.37993 | valid_rmse: 0.47837 | valid_mse: 0.22884 |  0:01:31s\n",
      "epoch 35 | loss: 0.2203  | train_rmsle: 0.01421 | train_mae: 0.37484 | train_rmse: 0.47574 | train_mse: 0.22633 | valid_rmsle: 0.01405 | valid_mae: 0.38366 | valid_rmse: 0.47893 | valid_mse: 0.22937 |  0:01:34s\n",
      "epoch 36 | loss: 0.21924 | train_rmsle: 0.01439 | train_mae: 0.37244 | train_rmse: 0.47661 | train_mse: 0.22716 | valid_rmsle: 0.01409 | valid_mae: 0.37849 | valid_rmse: 0.47765 | valid_mse: 0.22815 |  0:01:36s\n",
      "epoch 37 | loss: 0.2162  | train_rmsle: 0.01407 | train_mae: 0.37632 | train_rmse: 0.47428 | train_mse: 0.22494 | valid_rmsle: 0.01402 | valid_mae: 0.38895 | valid_rmse: 0.47975 | valid_mse: 0.23016 |  0:01:39s\n",
      "epoch 38 | loss: 0.21778 | train_rmsle: 0.01405 | train_mae: 0.37726 | train_rmse: 0.47469 | train_mse: 0.22533 | valid_rmsle: 0.01384 | valid_mae: 0.38476 | valid_rmse: 0.47668 | valid_mse: 0.22722 |  0:01:42s\n",
      "epoch 39 | loss: 0.21468 | train_rmsle: 0.01404 | train_mae: 0.37863 | train_rmse: 0.47507 | train_mse: 0.2257  | valid_rmsle: 0.01388 | valid_mae: 0.38781 | valid_rmse: 0.47848 | valid_mse: 0.22895 |  0:01:45s\n",
      "epoch 40 | loss: 0.21664 | train_rmsle: 0.0143  | train_mae: 0.3724  | train_rmse: 0.47584 | train_mse: 0.22643 | valid_rmsle: 0.01418 | valid_mae: 0.38279 | valid_rmse: 0.47983 | valid_mse: 0.23024 |  0:01:47s\n",
      "epoch 41 | loss: 0.21633 | train_rmsle: 0.01403 | train_mae: 0.37994 | train_rmse: 0.47501 | train_mse: 0.22563 | valid_rmsle: 0.01407 | valid_mae: 0.38885 | valid_rmse: 0.48192 | valid_mse: 0.23225 |  0:01:50s\n",
      "epoch 42 | loss: 0.21667 | train_rmsle: 0.01428 | train_mae: 0.37086 | train_rmse: 0.47516 | train_mse: 0.22577 | valid_rmsle: 0.01427 | valid_mae: 0.38082 | valid_rmse: 0.48109 | valid_mse: 0.23145 |  0:01:53s\n",
      "epoch 43 | loss: 0.21697 | train_rmsle: 0.01404 | train_mae: 0.37895 | train_rmse: 0.47517 | train_mse: 0.22579 | valid_rmsle: 0.01436 | valid_mae: 0.39104 | valid_rmse: 0.4866  | valid_mse: 0.23677 |  0:01:55s\n",
      "epoch 44 | loss: 0.2148  | train_rmsle: 0.01405 | train_mae: 0.36983 | train_rmse: 0.47179 | train_mse: 0.22259 | valid_rmsle: 0.014   | valid_mae: 0.38004 | valid_rmse: 0.47695 | valid_mse: 0.22749 |  0:01:58s\n",
      "epoch 45 | loss: 0.21433 | train_rmsle: 0.01399 | train_mae: 0.36983 | train_rmse: 0.47096 | train_mse: 0.2218  | valid_rmsle: 0.014   | valid_mae: 0.38257 | valid_rmse: 0.47739 | valid_mse: 0.2279  |  0:02:01s\n",
      "epoch 46 | loss: 0.21674 | train_rmsle: 0.01406 | train_mae: 0.37035 | train_rmse: 0.4721  | train_mse: 0.22287 | valid_rmsle: 0.01406 | valid_mae: 0.38263 | valid_rmse: 0.47856 | valid_mse: 0.22902 |  0:02:03s\n",
      "epoch 47 | loss: 0.21368 | train_rmsle: 0.01421 | train_mae: 0.36846 | train_rmse: 0.47312 | train_mse: 0.22384 | valid_rmsle: 0.01424 | valid_mae: 0.3828  | valid_rmse: 0.48047 | valid_mse: 0.23085 |  0:02:06s\n",
      "epoch 48 | loss: 0.21523 | train_rmsle: 0.014   | train_mae: 0.37242 | train_rmse: 0.47189 | train_mse: 0.22268 | valid_rmsle: 0.01396 | valid_mae: 0.38498 | valid_rmse: 0.47735 | valid_mse: 0.22786 |  0:02:08s\n",
      "epoch 49 | loss: 0.21604 | train_rmsle: 0.01397 | train_mae: 0.37711 | train_rmse: 0.47366 | train_mse: 0.22435 | valid_rmsle: 0.01398 | valid_mae: 0.38997 | valid_rmse: 0.48004 | valid_mse: 0.23043 |  0:02:10s\n",
      "epoch 50 | loss: 0.21555 | train_rmsle: 0.01407 | train_mae: 0.3708  | train_rmse: 0.47246 | train_mse: 0.22322 | valid_rmsle: 0.01391 | valid_mae: 0.38209 | valid_rmse: 0.47578 | valid_mse: 0.22637 |  0:02:13s\n",
      "epoch 51 | loss: 0.21546 | train_rmsle: 0.01394 | train_mae: 0.38103 | train_rmse: 0.475   | train_mse: 0.22563 | valid_rmsle: 0.01377 | valid_mae: 0.38841 | valid_rmse: 0.47755 | valid_mse: 0.22805 |  0:02:15s\n",
      "epoch 52 | loss: 0.21528 | train_rmsle: 0.01428 | train_mae: 0.3697  | train_rmse: 0.47467 | train_mse: 0.22531 | valid_rmsle: 0.01401 | valid_mae: 0.37947 | valid_rmse: 0.47603 | valid_mse: 0.2266  |  0:02:18s\n",
      "epoch 53 | loss: 0.21303 | train_rmsle: 0.0138  | train_mae: 0.36973 | train_rmse: 0.46891 | train_mse: 0.21988 | valid_rmsle: 0.01377 | valid_mae: 0.38226 | valid_rmse: 0.47423 | valid_mse: 0.22489 |  0:02:21s\n",
      "epoch 54 | loss: 0.21143 | train_rmsle: 0.01369 | train_mae: 0.36931 | train_rmse: 0.46728 | train_mse: 0.21835 | valid_rmsle: 0.01392 | valid_mae: 0.38473 | valid_rmse: 0.47753 | valid_mse: 0.22804 |  0:02:23s\n",
      "epoch 55 | loss: 0.21039 | train_rmsle: 0.01375 | train_mae: 0.36586 | train_rmse: 0.46658 | train_mse: 0.21769 | valid_rmsle: 0.01384 | valid_mae: 0.3808  | valid_rmse: 0.4745  | valid_mse: 0.22515 |  0:02:26s\n",
      "epoch 56 | loss: 0.20929 | train_rmsle: 0.01373 | train_mae: 0.36923 | train_rmse: 0.46825 | train_mse: 0.21926 | valid_rmsle: 0.01377 | valid_mae: 0.3839  | valid_rmse: 0.47453 | valid_mse: 0.22518 |  0:02:29s\n",
      "epoch 57 | loss: 0.21114 | train_rmsle: 0.01378 | train_mae: 0.37081 | train_rmse: 0.46892 | train_mse: 0.21988 | valid_rmsle: 0.01367 | valid_mae: 0.3821  | valid_rmse: 0.47286 | valid_mse: 0.2236  |  0:02:32s\n",
      "epoch 58 | loss: 0.21281 | train_rmsle: 0.01397 | train_mae: 0.36945 | train_rmse: 0.471   | train_mse: 0.22184 | valid_rmsle: 0.01394 | valid_mae: 0.3809  | valid_rmse: 0.47679 | valid_mse: 0.22733 |  0:02:34s\n",
      "epoch 59 | loss: 0.21078 | train_rmsle: 0.01383 | train_mae: 0.36752 | train_rmse: 0.46813 | train_mse: 0.21914 | valid_rmsle: 0.0139  | valid_mae: 0.3806  | valid_rmse: 0.47573 | valid_mse: 0.22632 |  0:02:37s\n",
      "epoch 60 | loss: 0.20882 | train_rmsle: 0.0137  | train_mae: 0.36671 | train_rmse: 0.46603 | train_mse: 0.21719 | valid_rmsle: 0.01378 | valid_mae: 0.37794 | valid_rmse: 0.47397 | valid_mse: 0.22465 |  0:02:40s\n",
      "epoch 61 | loss: 0.20771 | train_rmsle: 0.01347 | train_mae: 0.37016 | train_rmse: 0.46502 | train_mse: 0.21624 | valid_rmsle: 0.01362 | valid_mae: 0.38108 | valid_rmse: 0.4738  | valid_mse: 0.22449 |  0:02:42s\n",
      "epoch 62 | loss: 0.21065 | train_rmsle: 0.01349 | train_mae: 0.36935 | train_rmse: 0.46461 | train_mse: 0.21586 | valid_rmsle: 0.01363 | valid_mae: 0.38115 | valid_rmse: 0.47353 | valid_mse: 0.22423 |  0:02:45s\n",
      "epoch 63 | loss: 0.2082  | train_rmsle: 0.01349 | train_mae: 0.36554 | train_rmse: 0.46269 | train_mse: 0.21408 | valid_rmsle: 0.01362 | valid_mae: 0.37613 | valid_rmse: 0.47133 | valid_mse: 0.22215 |  0:02:48s\n",
      "epoch 64 | loss: 0.206   | train_rmsle: 0.01327 | train_mae: 0.36495 | train_rmse: 0.4603  | train_mse: 0.21187 | valid_rmsle: 0.01348 | valid_mae: 0.37708 | valid_rmse: 0.47081 | valid_mse: 0.22166 |  0:02:51s\n",
      "epoch 65 | loss: 0.20585 | train_rmsle: 0.01324 | train_mae: 0.36458 | train_rmse: 0.45978 | train_mse: 0.21139 | valid_rmsle: 0.01366 | valid_mae: 0.37962 | valid_rmse: 0.47396 | valid_mse: 0.22464 |  0:02:53s\n",
      "epoch 66 | loss: 0.20646 | train_rmsle: 0.01326 | train_mae: 0.36928 | train_rmse: 0.46226 | train_mse: 0.21369 | valid_rmsle: 0.01316 | valid_mae: 0.37723 | valid_rmse: 0.46699 | valid_mse: 0.21808 |  0:02:56s\n",
      "epoch 67 | loss: 0.20233 | train_rmsle: 0.01323 | train_mae: 0.36349 | train_rmse: 0.45956 | train_mse: 0.21119 | valid_rmsle: 0.01289 | valid_mae: 0.36972 | valid_rmse: 0.46004 | valid_mse: 0.21164 |  0:02:59s\n",
      "epoch 68 | loss: 0.20018 | train_rmsle: 0.01315 | train_mae: 0.35791 | train_rmse: 0.45658 | train_mse: 0.20846 | valid_rmsle: 0.01296 | valid_mae: 0.36661 | valid_rmse: 0.46008 | valid_mse: 0.21168 |  0:03:02s\n",
      "epoch 69 | loss: 0.19863 | train_rmsle: 0.01293 | train_mae: 0.3585  | train_rmse: 0.45433 | train_mse: 0.20642 | valid_rmsle: 0.01266 | valid_mae: 0.36457 | valid_rmse: 0.45601 | valid_mse: 0.20794 |  0:03:04s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.20794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.20691839603897613 RMSE: 0.45488283770546467 R2: 0.08405199023690002 MAE: 0.3573555169726746\n",
      "=====================================\n",
      "[30/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.05908 | train_rmsle: 0.47254 | train_mae: 2.11567 | train_rmse: 2.1693  | train_mse: 4.70588 | valid_rmsle: 0.47418 | valid_mae: 2.12187 | valid_rmse: 2.17427 | valid_mse: 4.72744 |  0:00:02s\n",
      "epoch 1  | loss: 1.73136 | train_rmsle: 0.12324 | train_mae: 1.22946 | train_rmse: 1.31296 | train_mse: 1.72386 | valid_rmsle: 0.12387 | valid_mae: 1.23267 | valid_rmse: 1.31742 | valid_mse: 1.7356  |  0:00:05s\n",
      "epoch 2  | loss: 0.66051 | train_rmsle: 0.04418 | train_mae: 0.75613 | train_rmse: 0.85082 | train_mse: 0.72389 | valid_rmsle: 0.04431 | valid_mae: 0.75629 | valid_rmse: 0.85431 | valid_mse: 0.72985 |  0:00:08s\n",
      "epoch 3  | loss: 0.35578 | train_rmsle: 0.02838 | train_mae: 0.60273 | train_rmse: 0.69509 | train_mse: 0.48315 | valid_rmsle: 0.02832 | valid_mae: 0.60343 | valid_rmse: 0.69767 | valid_mse: 0.48675 |  0:00:11s\n",
      "epoch 4  | loss: 0.29529 | train_rmsle: 0.01976 | train_mae: 0.49278 | train_rmse: 0.5817  | train_mse: 0.33837 | valid_rmsle: 0.0195  | valid_mae: 0.49447 | valid_rmse: 0.58226 | valid_mse: 0.33902 |  0:00:13s\n",
      "epoch 5  | loss: 0.26514 | train_rmsle: 0.02487 | train_mae: 0.56187 | train_rmse: 0.65226 | train_mse: 0.42545 | valid_rmsle: 0.02464 | valid_mae: 0.56264 | valid_rmse: 0.65296 | valid_mse: 0.42636 |  0:00:16s\n",
      "epoch 6  | loss: 0.26767 | train_rmsle: 0.0184  | train_mae: 0.47147 | train_rmse: 0.55986 | train_mse: 0.31344 | valid_rmsle: 0.018   | valid_mae: 0.47183 | valid_rmse: 0.55841 | valid_mse: 0.31182 |  0:00:19s\n",
      "epoch 7  | loss: 0.24778 | train_rmsle: 0.01839 | train_mae: 0.47148 | train_rmse: 0.55945 | train_mse: 0.31299 | valid_rmsle: 0.01797 | valid_mae: 0.47189 | valid_rmse: 0.55772 | valid_mse: 0.31106 |  0:00:22s\n",
      "epoch 8  | loss: 0.24935 | train_rmsle: 0.01736 | train_mae: 0.45375 | train_rmse: 0.54173 | train_mse: 0.29348 | valid_rmsle: 0.01692 | valid_mae: 0.45478 | valid_rmse: 0.53974 | valid_mse: 0.29132 |  0:00:24s\n",
      "epoch 9  | loss: 0.23796 | train_rmsle: 0.01469 | train_mae: 0.39167 | train_rmse: 0.48715 | train_mse: 0.23732 | valid_rmsle: 0.01424 | valid_mae: 0.39355 | valid_rmse: 0.485   | valid_mse: 0.23523 |  0:00:27s\n",
      "epoch 10 | loss: 0.23537 | train_rmsle: 0.01584 | train_mae: 0.42429 | train_rmse: 0.51604 | train_mse: 0.2663  | valid_rmsle: 0.01555 | valid_mae: 0.42633 | valid_rmse: 0.51654 | valid_mse: 0.26681 |  0:00:30s\n",
      "epoch 11 | loss: 0.23317 | train_rmsle: 0.01584 | train_mae: 0.42496 | train_rmse: 0.51637 | train_mse: 0.26664 | valid_rmsle: 0.01546 | valid_mae: 0.42625 | valid_rmse: 0.51497 | valid_mse: 0.26519 |  0:00:32s\n",
      "epoch 12 | loss: 0.23496 | train_rmsle: 0.01835 | train_mae: 0.4682  | train_rmse: 0.56025 | train_mse: 0.31388 | valid_rmsle: 0.01839 | valid_mae: 0.47186 | valid_rmse: 0.56515 | valid_mse: 0.3194  |  0:00:35s\n",
      "epoch 13 | loss: 0.25756 | train_rmsle: 0.0161  | train_mae: 0.43016 | train_rmse: 0.51925 | train_mse: 0.26962 | valid_rmsle: 0.01585 | valid_mae: 0.4337  | valid_rmse: 0.52047 | valid_mse: 0.27088 |  0:00:38s\n",
      "epoch 14 | loss: 0.22973 | train_rmsle: 0.01576 | train_mae: 0.42266 | train_rmse: 0.51252 | train_mse: 0.26268 | valid_rmsle: 0.01545 | valid_mae: 0.42569 | valid_rmse: 0.51271 | valid_mse: 0.26287 |  0:00:41s\n",
      "epoch 15 | loss: 0.2283  | train_rmsle: 0.01662 | train_mae: 0.43979 | train_rmse: 0.52924 | train_mse: 0.2801  | valid_rmsle: 0.01619 | valid_mae: 0.44086 | valid_rmse: 0.52738 | valid_mse: 0.27813 |  0:00:43s\n",
      "epoch 16 | loss: 0.22833 | train_rmsle: 0.0165  | train_mae: 0.43861 | train_rmse: 0.52848 | train_mse: 0.27929 | valid_rmsle: 0.0162  | valid_mae: 0.44058 | valid_rmse: 0.52858 | valid_mse: 0.2794  |  0:00:46s\n",
      "epoch 17 | loss: 0.23841 | train_rmsle: 0.01752 | train_mae: 0.45323 | train_rmse: 0.54674 | train_mse: 0.29893 | valid_rmsle: 0.01717 | valid_mae: 0.45383 | valid_rmse: 0.54614 | valid_mse: 0.29827 |  0:00:49s\n",
      "epoch 18 | loss: 0.22498 | train_rmsle: 0.01524 | train_mae: 0.41174 | train_rmse: 0.50336 | train_mse: 0.25337 | valid_rmsle: 0.01484 | valid_mae: 0.4143  | valid_rmse: 0.5018  | valid_mse: 0.2518  |  0:00:51s\n",
      "epoch 19 | loss: 0.23052 | train_rmsle: 0.01458 | train_mae: 0.39587 | train_rmse: 0.48906 | train_mse: 0.23918 | valid_rmsle: 0.01412 | valid_mae: 0.39867 | valid_rmse: 0.48661 | valid_mse: 0.23679 |  0:00:54s\n",
      "epoch 20 | loss: 0.22686 | train_rmsle: 0.01455 | train_mae: 0.3936  | train_rmse: 0.48789 | train_mse: 0.23804 | valid_rmsle: 0.01418 | valid_mae: 0.39723 | valid_rmse: 0.48744 | valid_mse: 0.2376  |  0:00:57s\n",
      "epoch 21 | loss: 0.22268 | train_rmsle: 0.01462 | train_mae: 0.3948  | train_rmse: 0.48849 | train_mse: 0.23863 | valid_rmsle: 0.01415 | valid_mae: 0.39705 | valid_rmse: 0.48584 | valid_mse: 0.23604 |  0:01:00s\n",
      "epoch 22 | loss: 0.22098 | train_rmsle: 0.01476 | train_mae: 0.40099 | train_rmse: 0.49349 | train_mse: 0.24353 | valid_rmsle: 0.01454 | valid_mae: 0.40547 | valid_rmse: 0.49505 | valid_mse: 0.24508 |  0:01:02s\n",
      "epoch 23 | loss: 0.22229 | train_rmsle: 0.01448 | train_mae: 0.37833 | train_rmse: 0.48001 | train_mse: 0.23041 | valid_rmsle: 0.01414 | valid_mae: 0.38227 | valid_rmse: 0.47961 | valid_mse: 0.23002 |  0:01:05s\n",
      "epoch 24 | loss: 0.22701 | train_rmsle: 0.0146  | train_mae: 0.39668 | train_rmse: 0.48941 | train_mse: 0.23952 | valid_rmsle: 0.0145  | valid_mae: 0.40422 | valid_rmse: 0.49314 | valid_mse: 0.24319 |  0:01:08s\n",
      "epoch 25 | loss: 0.21869 | train_rmsle: 0.01512 | train_mae: 0.41106 | train_rmse: 0.50137 | train_mse: 0.25137 | valid_rmsle: 0.01492 | valid_mae: 0.41508 | valid_rmse: 0.50293 | valid_mse: 0.25294 |  0:01:11s\n",
      "epoch 26 | loss: 0.22466 | train_rmsle: 0.01461 | train_mae: 0.39633 | train_rmse: 0.48937 | train_mse: 0.23948 | valid_rmsle: 0.01439 | valid_mae: 0.40107 | valid_rmse: 0.49118 | valid_mse: 0.24126 |  0:01:13s\n",
      "epoch 27 | loss: 0.22305 | train_rmsle: 0.01432 | train_mae: 0.38755 | train_rmse: 0.48251 | train_mse: 0.23281 | valid_rmsle: 0.01407 | valid_mae: 0.39293 | valid_rmse: 0.48384 | valid_mse: 0.2341  |  0:01:16s\n",
      "epoch 28 | loss: 0.21922 | train_rmsle: 0.01449 | train_mae: 0.37513 | train_rmse: 0.4789  | train_mse: 0.22935 | valid_rmsle: 0.01415 | valid_mae: 0.38132 | valid_rmse: 0.47882 | valid_mse: 0.22927 |  0:01:19s\n",
      "epoch 29 | loss: 0.2237  | train_rmsle: 0.01447 | train_mae: 0.3936  | train_rmse: 0.48722 | train_mse: 0.23738 | valid_rmsle: 0.01425 | valid_mae: 0.39722 | valid_rmse: 0.48889 | valid_mse: 0.23901 |  0:01:21s\n",
      "epoch 30 | loss: 0.21786 | train_rmsle: 0.01415 | train_mae: 0.38397 | train_rmse: 0.47911 | train_mse: 0.22955 | valid_rmsle: 0.01393 | valid_mae: 0.38951 | valid_rmse: 0.48125 | valid_mse: 0.2316  |  0:01:23s\n",
      "epoch 31 | loss: 0.21794 | train_rmsle: 0.01436 | train_mae: 0.39225 | train_rmse: 0.48502 | train_mse: 0.23525 | valid_rmsle: 0.01402 | valid_mae: 0.39699 | valid_rmse: 0.48454 | valid_mse: 0.23477 |  0:01:26s\n",
      "epoch 32 | loss: 0.22299 | train_rmsle: 0.01421 | train_mae: 0.38627 | train_rmse: 0.4811  | train_mse: 0.23146 | valid_rmsle: 0.01384 | valid_mae: 0.39113 | valid_rmse: 0.48022 | valid_mse: 0.23061 |  0:01:28s\n",
      "epoch 33 | loss: 0.22265 | train_rmsle: 0.01409 | train_mae: 0.38044 | train_rmse: 0.47674 | train_mse: 0.22728 | valid_rmsle: 0.01377 | valid_mae: 0.38615 | valid_rmse: 0.47677 | valid_mse: 0.22731 |  0:01:30s\n",
      "epoch 34 | loss: 0.21771 | train_rmsle: 0.01442 | train_mae: 0.37134 | train_rmse: 0.47669 | train_mse: 0.22723 | valid_rmsle: 0.01418 | valid_mae: 0.37993 | valid_rmse: 0.47837 | valid_mse: 0.22884 |  0:01:32s\n",
      "epoch 35 | loss: 0.2203  | train_rmsle: 0.01421 | train_mae: 0.37484 | train_rmse: 0.47574 | train_mse: 0.22633 | valid_rmsle: 0.01405 | valid_mae: 0.38366 | valid_rmse: 0.47893 | valid_mse: 0.22937 |  0:01:35s\n",
      "epoch 36 | loss: 0.21924 | train_rmsle: 0.01439 | train_mae: 0.37244 | train_rmse: 0.47661 | train_mse: 0.22716 | valid_rmsle: 0.01409 | valid_mae: 0.37849 | valid_rmse: 0.47765 | valid_mse: 0.22815 |  0:01:37s\n",
      "epoch 37 | loss: 0.2162  | train_rmsle: 0.01407 | train_mae: 0.37632 | train_rmse: 0.47428 | train_mse: 0.22494 | valid_rmsle: 0.01402 | valid_mae: 0.38895 | valid_rmse: 0.47975 | valid_mse: 0.23016 |  0:01:39s\n",
      "epoch 38 | loss: 0.21778 | train_rmsle: 0.01405 | train_mae: 0.37726 | train_rmse: 0.47469 | train_mse: 0.22533 | valid_rmsle: 0.01384 | valid_mae: 0.38476 | valid_rmse: 0.47668 | valid_mse: 0.22722 |  0:01:42s\n",
      "epoch 39 | loss: 0.21468 | train_rmsle: 0.01404 | train_mae: 0.37863 | train_rmse: 0.47507 | train_mse: 0.2257  | valid_rmsle: 0.01388 | valid_mae: 0.38781 | valid_rmse: 0.47848 | valid_mse: 0.22895 |  0:01:45s\n",
      "epoch 40 | loss: 0.21664 | train_rmsle: 0.0143  | train_mae: 0.3724  | train_rmse: 0.47584 | train_mse: 0.22643 | valid_rmsle: 0.01418 | valid_mae: 0.38279 | valid_rmse: 0.47983 | valid_mse: 0.23024 |  0:01:47s\n",
      "epoch 41 | loss: 0.21633 | train_rmsle: 0.01403 | train_mae: 0.37994 | train_rmse: 0.47501 | train_mse: 0.22563 | valid_rmsle: 0.01407 | valid_mae: 0.38885 | valid_rmse: 0.48192 | valid_mse: 0.23225 |  0:01:50s\n",
      "epoch 42 | loss: 0.21667 | train_rmsle: 0.01428 | train_mae: 0.37086 | train_rmse: 0.47516 | train_mse: 0.22577 | valid_rmsle: 0.01427 | valid_mae: 0.38082 | valid_rmse: 0.48109 | valid_mse: 0.23145 |  0:01:53s\n",
      "epoch 43 | loss: 0.21697 | train_rmsle: 0.01404 | train_mae: 0.37895 | train_rmse: 0.47517 | train_mse: 0.22579 | valid_rmsle: 0.01436 | valid_mae: 0.39104 | valid_rmse: 0.4866  | valid_mse: 0.23677 |  0:01:55s\n",
      "epoch 44 | loss: 0.2148  | train_rmsle: 0.01405 | train_mae: 0.36983 | train_rmse: 0.47179 | train_mse: 0.22259 | valid_rmsle: 0.014   | valid_mae: 0.38004 | valid_rmse: 0.47695 | valid_mse: 0.22749 |  0:01:58s\n",
      "epoch 45 | loss: 0.21433 | train_rmsle: 0.01399 | train_mae: 0.36983 | train_rmse: 0.47096 | train_mse: 0.2218  | valid_rmsle: 0.014   | valid_mae: 0.38257 | valid_rmse: 0.47739 | valid_mse: 0.2279  |  0:02:01s\n",
      "epoch 46 | loss: 0.21674 | train_rmsle: 0.01406 | train_mae: 0.37035 | train_rmse: 0.4721  | train_mse: 0.22287 | valid_rmsle: 0.01406 | valid_mae: 0.38263 | valid_rmse: 0.47856 | valid_mse: 0.22902 |  0:02:04s\n",
      "epoch 47 | loss: 0.21368 | train_rmsle: 0.01421 | train_mae: 0.36846 | train_rmse: 0.47312 | train_mse: 0.22384 | valid_rmsle: 0.01424 | valid_mae: 0.3828  | valid_rmse: 0.48047 | valid_mse: 0.23085 |  0:02:07s\n",
      "epoch 48 | loss: 0.21523 | train_rmsle: 0.014   | train_mae: 0.37242 | train_rmse: 0.47189 | train_mse: 0.22268 | valid_rmsle: 0.01396 | valid_mae: 0.38498 | valid_rmse: 0.47735 | valid_mse: 0.22786 |  0:02:09s\n",
      "epoch 49 | loss: 0.21604 | train_rmsle: 0.01397 | train_mae: 0.37711 | train_rmse: 0.47366 | train_mse: 0.22435 | valid_rmsle: 0.01398 | valid_mae: 0.38997 | valid_rmse: 0.48004 | valid_mse: 0.23043 |  0:02:12s\n",
      "epoch 50 | loss: 0.21555 | train_rmsle: 0.01407 | train_mae: 0.3708  | train_rmse: 0.47246 | train_mse: 0.22322 | valid_rmsle: 0.01391 | valid_mae: 0.38209 | valid_rmse: 0.47578 | valid_mse: 0.22637 |  0:02:15s\n",
      "epoch 51 | loss: 0.21546 | train_rmsle: 0.01394 | train_mae: 0.38103 | train_rmse: 0.475   | train_mse: 0.22563 | valid_rmsle: 0.01377 | valid_mae: 0.38841 | valid_rmse: 0.47755 | valid_mse: 0.22805 |  0:02:17s\n",
      "epoch 52 | loss: 0.21528 | train_rmsle: 0.01428 | train_mae: 0.3697  | train_rmse: 0.47467 | train_mse: 0.22531 | valid_rmsle: 0.01401 | valid_mae: 0.37947 | valid_rmse: 0.47603 | valid_mse: 0.2266  |  0:02:20s\n",
      "epoch 53 | loss: 0.21303 | train_rmsle: 0.0138  | train_mae: 0.36973 | train_rmse: 0.46891 | train_mse: 0.21988 | valid_rmsle: 0.01377 | valid_mae: 0.38226 | valid_rmse: 0.47423 | valid_mse: 0.22489 |  0:02:23s\n",
      "epoch 54 | loss: 0.21143 | train_rmsle: 0.01369 | train_mae: 0.36931 | train_rmse: 0.46728 | train_mse: 0.21835 | valid_rmsle: 0.01392 | valid_mae: 0.38473 | valid_rmse: 0.47753 | valid_mse: 0.22804 |  0:02:26s\n",
      "epoch 55 | loss: 0.21039 | train_rmsle: 0.01375 | train_mae: 0.36586 | train_rmse: 0.46658 | train_mse: 0.21769 | valid_rmsle: 0.01384 | valid_mae: 0.3808  | valid_rmse: 0.4745  | valid_mse: 0.22515 |  0:02:29s\n",
      "epoch 56 | loss: 0.20929 | train_rmsle: 0.01373 | train_mae: 0.36923 | train_rmse: 0.46825 | train_mse: 0.21926 | valid_rmsle: 0.01377 | valid_mae: 0.3839  | valid_rmse: 0.47453 | valid_mse: 0.22518 |  0:02:31s\n",
      "epoch 57 | loss: 0.21114 | train_rmsle: 0.01378 | train_mae: 0.37081 | train_rmse: 0.46892 | train_mse: 0.21988 | valid_rmsle: 0.01367 | valid_mae: 0.3821  | valid_rmse: 0.47286 | valid_mse: 0.2236  |  0:02:34s\n",
      "epoch 58 | loss: 0.21281 | train_rmsle: 0.01397 | train_mae: 0.36945 | train_rmse: 0.471   | train_mse: 0.22184 | valid_rmsle: 0.01394 | valid_mae: 0.3809  | valid_rmse: 0.47679 | valid_mse: 0.22733 |  0:02:37s\n",
      "epoch 59 | loss: 0.21078 | train_rmsle: 0.01383 | train_mae: 0.36752 | train_rmse: 0.46813 | train_mse: 0.21914 | valid_rmsle: 0.0139  | valid_mae: 0.3806  | valid_rmse: 0.47573 | valid_mse: 0.22632 |  0:02:39s\n",
      "epoch 60 | loss: 0.20882 | train_rmsle: 0.0137  | train_mae: 0.36671 | train_rmse: 0.46603 | train_mse: 0.21719 | valid_rmsle: 0.01378 | valid_mae: 0.37794 | valid_rmse: 0.47397 | valid_mse: 0.22465 |  0:02:42s\n",
      "epoch 61 | loss: 0.20771 | train_rmsle: 0.01347 | train_mae: 0.37016 | train_rmse: 0.46502 | train_mse: 0.21624 | valid_rmsle: 0.01362 | valid_mae: 0.38108 | valid_rmse: 0.4738  | valid_mse: 0.22449 |  0:02:45s\n",
      "epoch 62 | loss: 0.21065 | train_rmsle: 0.01349 | train_mae: 0.36935 | train_rmse: 0.46461 | train_mse: 0.21586 | valid_rmsle: 0.01363 | valid_mae: 0.38115 | valid_rmse: 0.47353 | valid_mse: 0.22423 |  0:02:48s\n",
      "epoch 63 | loss: 0.2082  | train_rmsle: 0.01349 | train_mae: 0.36554 | train_rmse: 0.46269 | train_mse: 0.21408 | valid_rmsle: 0.01362 | valid_mae: 0.37613 | valid_rmse: 0.47133 | valid_mse: 0.22215 |  0:02:50s\n",
      "epoch 64 | loss: 0.206   | train_rmsle: 0.01327 | train_mae: 0.36495 | train_rmse: 0.4603  | train_mse: 0.21187 | valid_rmsle: 0.01348 | valid_mae: 0.37708 | valid_rmse: 0.47081 | valid_mse: 0.22166 |  0:02:53s\n",
      "epoch 65 | loss: 0.20585 | train_rmsle: 0.01324 | train_mae: 0.36458 | train_rmse: 0.45978 | train_mse: 0.21139 | valid_rmsle: 0.01366 | valid_mae: 0.37962 | valid_rmse: 0.47396 | valid_mse: 0.22464 |  0:02:56s\n",
      "epoch 66 | loss: 0.20646 | train_rmsle: 0.01326 | train_mae: 0.36928 | train_rmse: 0.46226 | train_mse: 0.21369 | valid_rmsle: 0.01316 | valid_mae: 0.37723 | valid_rmse: 0.46699 | valid_mse: 0.21808 |  0:02:58s\n",
      "epoch 67 | loss: 0.20233 | train_rmsle: 0.01323 | train_mae: 0.36349 | train_rmse: 0.45956 | train_mse: 0.21119 | valid_rmsle: 0.01289 | valid_mae: 0.36972 | valid_rmse: 0.46004 | valid_mse: 0.21164 |  0:03:01s\n",
      "epoch 68 | loss: 0.20018 | train_rmsle: 0.01315 | train_mae: 0.35791 | train_rmse: 0.45658 | train_mse: 0.20846 | valid_rmsle: 0.01296 | valid_mae: 0.36661 | valid_rmse: 0.46008 | valid_mse: 0.21168 |  0:03:03s\n",
      "epoch 69 | loss: 0.19863 | train_rmsle: 0.01293 | train_mae: 0.3585  | train_rmse: 0.45433 | train_mse: 0.20642 | valid_rmsle: 0.01266 | valid_mae: 0.36457 | valid_rmse: 0.45601 | valid_mse: 0.20794 |  0:03:05s\n",
      "epoch 70 | loss: 0.20062 | train_rmsle: 0.01272 | train_mae: 0.35944 | train_rmse: 0.45216 | train_mse: 0.20445 | valid_rmsle: 0.01264 | valid_mae: 0.36766 | valid_rmse: 0.45746 | valid_mse: 0.20927 |  0:03:08s\n",
      "epoch 71 | loss: 0.19254 | train_rmsle: 0.0126  | train_mae: 0.34655 | train_rmse: 0.44594 | train_mse: 0.19887 | valid_rmsle: 0.01247 | valid_mae: 0.35643 | valid_rmse: 0.45018 | valid_mse: 0.20266 |  0:03:10s\n",
      "epoch 72 | loss: 0.18894 | train_rmsle: 0.01234 | train_mae: 0.34202 | train_rmse: 0.44117 | train_mse: 0.19463 | valid_rmsle: 0.01206 | valid_mae: 0.34866 | valid_rmse: 0.44197 | valid_mse: 0.19534 |  0:03:12s\n",
      "epoch 73 | loss: 0.1855  | train_rmsle: 0.01183 | train_mae: 0.33982 | train_rmse: 0.43368 | train_mse: 0.18808 | valid_rmsle: 0.0119  | valid_mae: 0.35037 | valid_rmse: 0.44142 | valid_mse: 0.19486 |  0:03:15s\n",
      "epoch 74 | loss: 0.1806  | train_rmsle: 0.01167 | train_mae: 0.33627 | train_rmse: 0.43003 | train_mse: 0.18493 | valid_rmsle: 0.01126 | valid_mae: 0.34106 | valid_rmse: 0.42794 | valid_mse: 0.18313 |  0:03:17s\n",
      "epoch 75 | loss: 0.17738 | train_rmsle: 0.01182 | train_mae: 0.32924 | train_rmse: 0.42946 | train_mse: 0.18443 | valid_rmsle: 0.0113  | valid_mae: 0.33    | valid_rmse: 0.42538 | valid_mse: 0.18095 |  0:03:20s\n",
      "epoch 76 | loss: 0.17334 | train_rmsle: 0.01138 | train_mae: 0.3436  | train_rmse: 0.42934 | train_mse: 0.18434 | valid_rmsle: 0.01111 | valid_mae: 0.34892 | valid_rmse: 0.42983 | valid_mse: 0.18476 |  0:03:23s\n",
      "epoch 77 | loss: 0.16708 | train_rmsle: 0.01081 | train_mae: 0.3156  | train_rmse: 0.41059 | train_mse: 0.16858 | valid_rmsle: 0.01071 | valid_mae: 0.32581 | valid_rmse: 0.41552 | valid_mse: 0.17266 |  0:03:26s\n",
      "epoch 78 | loss: 0.16111 | train_rmsle: 0.01017 | train_mae: 0.31432 | train_rmse: 0.40149 | train_mse: 0.1612  | valid_rmsle: 0.00993 | valid_mae: 0.32004 | valid_rmse: 0.40243 | valid_mse: 0.16195 |  0:03:28s\n",
      "epoch 79 | loss: 0.15289 | train_rmsle: 0.01    | train_mae: 0.30495 | train_rmse: 0.39537 | train_mse: 0.15632 | valid_rmsle: 0.0099  | valid_mae: 0.31432 | valid_rmse: 0.40015 | valid_mse: 0.16012 |  0:03:31s\n",
      "epoch 80 | loss: 0.14846 | train_rmsle: 0.00946 | train_mae: 0.30601 | train_rmse: 0.38813 | train_mse: 0.15064 | valid_rmsle: 0.00922 | valid_mae: 0.31103 | valid_rmse: 0.39022 | valid_mse: 0.15227 |  0:03:34s\n",
      "epoch 81 | loss: 0.14429 | train_rmsle: 0.0089  | train_mae: 0.28939 | train_rmse: 0.37305 | train_mse: 0.13916 | valid_rmsle: 0.00865 | valid_mae: 0.29562 | valid_rmse: 0.37496 | valid_mse: 0.14059 |  0:03:37s\n",
      "epoch 82 | loss: 0.13915 | train_rmsle: 0.00875 | train_mae: 0.28542 | train_rmse: 0.36961 | train_mse: 0.13661 | valid_rmsle: 0.00851 | valid_mae: 0.2912  | valid_rmse: 0.37101 | valid_mse: 0.13764 |  0:03:39s\n",
      "epoch 83 | loss: 0.13058 | train_rmsle: 0.0087  | train_mae: 0.28671 | train_rmse: 0.3698  | train_mse: 0.13676 | valid_rmsle: 0.00861 | valid_mae: 0.2964  | valid_rmse: 0.37477 | valid_mse: 0.14045 |  0:03:42s\n",
      "epoch 84 | loss: 0.12718 | train_rmsle: 0.00824 | train_mae: 0.27633 | train_rmse: 0.35813 | train_mse: 0.12826 | valid_rmsle: 0.00813 | valid_mae: 0.28789 | valid_rmse: 0.36283 | valid_mse: 0.13164 |  0:03:45s\n",
      "epoch 85 | loss: 0.12181 | train_rmsle: 0.00796 | train_mae: 0.27598 | train_rmse: 0.35324 | train_mse: 0.12478 | valid_rmsle: 0.00789 | valid_mae: 0.28853 | valid_rmse: 0.35865 | valid_mse: 0.12863 |  0:03:48s\n",
      "epoch 86 | loss: 0.11828 | train_rmsle: 0.00747 | train_mae: 0.25691 | train_rmse: 0.33774 | train_mse: 0.11407 | valid_rmsle: 0.00726 | valid_mae: 0.26656 | valid_rmse: 0.34045 | valid_mse: 0.11591 |  0:03:50s\n",
      "epoch 87 | loss: 0.11153 | train_rmsle: 0.0083  | train_mae: 0.29751 | train_rmse: 0.36729 | train_mse: 0.1349  | valid_rmsle: 0.00809 | valid_mae: 0.30231 | valid_rmse: 0.36968 | valid_mse: 0.13666 |  0:03:53s\n",
      "epoch 88 | loss: 0.11107 | train_rmsle: 0.00673 | train_mae: 0.24702 | train_rmse: 0.32199 | train_mse: 0.10368 | valid_rmsle: 0.00656 | valid_mae: 0.25686 | valid_rmse: 0.32534 | valid_mse: 0.10585 |  0:03:56s\n",
      "epoch 89 | loss: 0.10286 | train_rmsle: 0.00641 | train_mae: 0.24478 | train_rmse: 0.31587 | train_mse: 0.09977 | valid_rmsle: 0.00618 | valid_mae: 0.25256 | valid_rmse: 0.31729 | valid_mse: 0.10068 |  0:03:59s\n",
      "epoch 90 | loss: 0.09795 | train_rmsle: 0.00603 | train_mae: 0.23696 | train_rmse: 0.30647 | train_mse: 0.09392 | valid_rmsle: 0.00584 | valid_mae: 0.24369 | valid_rmse: 0.30863 | valid_mse: 0.09525 |  0:04:01s\n",
      "epoch 91 | loss: 0.09631 | train_rmsle: 0.00572 | train_mae: 0.22919 | train_rmse: 0.29812 | train_mse: 0.08887 | valid_rmsle: 0.00565 | valid_mae: 0.23754 | valid_rmse: 0.30236 | valid_mse: 0.09142 |  0:04:04s\n",
      "epoch 92 | loss: 0.09014 | train_rmsle: 0.00554 | train_mae: 0.22704 | train_rmse: 0.29408 | train_mse: 0.08649 | valid_rmsle: 0.00542 | valid_mae: 0.23387 | valid_rmse: 0.2966  | valid_mse: 0.08797 |  0:04:07s\n",
      "epoch 93 | loss: 0.08649 | train_rmsle: 0.00543 | train_mae: 0.22176 | train_rmse: 0.29071 | train_mse: 0.08451 | valid_rmsle: 0.00528 | valid_mae: 0.22914 | valid_rmse: 0.29333 | valid_mse: 0.08604 |  0:04:09s\n",
      "epoch 94 | loss: 0.0827  | train_rmsle: 0.00516 | train_mae: 0.22288 | train_rmse: 0.28588 | train_mse: 0.08173 | valid_rmsle: 0.0052  | valid_mae: 0.23318 | valid_rmse: 0.29352 | valid_mse: 0.08615 |  0:04:12s\n",
      "epoch 95 | loss: 0.07883 | train_rmsle: 0.00475 | train_mae: 0.20743 | train_rmse: 0.27099 | train_mse: 0.07343 | valid_rmsle: 0.00488 | valid_mae: 0.22278 | valid_rmse: 0.28224 | valid_mse: 0.07966 |  0:04:15s\n",
      "epoch 96 | loss: 0.07638 | train_rmsle: 0.00576 | train_mae: 0.24583 | train_rmse: 0.30618 | train_mse: 0.09375 | valid_rmsle: 0.00597 | valid_mae: 0.25456 | valid_rmse: 0.31644 | valid_mse: 0.10014 |  0:04:18s\n",
      "epoch 97 | loss: 0.07365 | train_rmsle: 0.00424 | train_mae: 0.19705 | train_rmse: 0.25674 | train_mse: 0.06591 | valid_rmsle: 0.00432 | valid_mae: 0.20761 | valid_rmse: 0.26487 | valid_mse: 0.07015 |  0:04:20s\n",
      "epoch 98 | loss: 0.06936 | train_rmsle: 0.00406 | train_mae: 0.19483 | train_rmse: 0.25295 | train_mse: 0.06398 | valid_rmsle: 0.00425 | valid_mae: 0.20827 | valid_rmse: 0.26422 | valid_mse: 0.06981 |  0:04:23s\n",
      "epoch 99 | loss: 0.06771 | train_rmsle: 0.00382 | train_mae: 0.18911 | train_rmse: 0.24572 | train_mse: 0.06038 | valid_rmsle: 0.00402 | valid_mae: 0.20208 | valid_rmse: 0.25744 | valid_mse: 0.06628 |  0:04:26s\n",
      "epoch 100| loss: 0.06453 | train_rmsle: 0.00363 | train_mae: 0.18285 | train_rmse: 0.2382  | train_mse: 0.05674 | valid_rmsle: 0.00393 | valid_mae: 0.19692 | valid_rmse: 0.25251 | valid_mse: 0.06376 |  0:04:29s\n",
      "epoch 101| loss: 0.05845 | train_rmsle: 0.00359 | train_mae: 0.18371 | train_rmse: 0.23767 | train_mse: 0.05649 | valid_rmsle: 0.0039  | valid_mae: 0.19631 | valid_rmse: 0.25132 | valid_mse: 0.06316 |  0:04:31s\n",
      "epoch 102| loss: 0.05853 | train_rmsle: 0.00339 | train_mae: 0.17828 | train_rmse: 0.23108 | train_mse: 0.0534  | valid_rmsle: 0.00377 | valid_mae: 0.19441 | valid_rmse: 0.24823 | valid_mse: 0.06162 |  0:04:34s\n",
      "epoch 103| loss: 0.05552 | train_rmsle: 0.00315 | train_mae: 0.17292 | train_rmse: 0.22389 | train_mse: 0.05013 | valid_rmsle: 0.00352 | valid_mae: 0.18983 | valid_rmse: 0.24098 | valid_mse: 0.05807 |  0:04:37s\n",
      "epoch 104| loss: 0.05372 | train_rmsle: 0.00315 | train_mae: 0.16929 | train_rmse: 0.22179 | train_mse: 0.04919 | valid_rmsle: 0.00357 | valid_mae: 0.18618 | valid_rmse: 0.24065 | valid_mse: 0.05791 |  0:04:40s\n",
      "epoch 105| loss: 0.05208 | train_rmsle: 0.00297 | train_mae: 0.1686  | train_rmse: 0.21807 | train_mse: 0.04755 | valid_rmsle: 0.00344 | valid_mae: 0.18773 | valid_rmse: 0.23835 | valid_mse: 0.05681 |  0:04:42s\n",
      "epoch 106| loss: 0.05223 | train_rmsle: 0.00298 | train_mae: 0.16762 | train_rmse: 0.21839 | train_mse: 0.04769 | valid_rmsle: 0.00336 | valid_mae: 0.1834  | valid_rmse: 0.23575 | valid_mse: 0.05558 |  0:04:45s\n",
      "epoch 107| loss: 0.04855 | train_rmsle: 0.00268 | train_mae: 0.15978 | train_rmse: 0.20789 | train_mse: 0.04322 | valid_rmsle: 0.00306 | valid_mae: 0.17684 | valid_rmse: 0.22576 | valid_mse: 0.05097 |  0:04:47s\n",
      "epoch 108| loss: 0.04574 | train_rmsle: 0.00258 | train_mae: 0.15554 | train_rmse: 0.20303 | train_mse: 0.04122 | valid_rmsle: 0.003   | valid_mae: 0.17243 | valid_rmse: 0.22203 | valid_mse: 0.0493  |  0:04:49s\n",
      "epoch 109| loss: 0.04544 | train_rmsle: 0.00253 | train_mae: 0.16027 | train_rmse: 0.20564 | train_mse: 0.04229 | valid_rmsle: 0.0029  | valid_mae: 0.17507 | valid_rmse: 0.22186 | valid_mse: 0.04922 |  0:04:52s\n",
      "epoch 110| loss: 0.04556 | train_rmsle: 0.00231 | train_mae: 0.14903 | train_rmse: 0.19404 | train_mse: 0.03765 | valid_rmsle: 0.00273 | valid_mae: 0.16736 | valid_rmse: 0.21352 | valid_mse: 0.04559 |  0:04:54s\n",
      "epoch 111| loss: 0.04312 | train_rmsle: 0.00244 | train_mae: 0.15126 | train_rmse: 0.19741 | train_mse: 0.03897 | valid_rmsle: 0.00286 | valid_mae: 0.16927 | valid_rmse: 0.21661 | valid_mse: 0.04692 |  0:04:56s\n",
      "epoch 112| loss: 0.04075 | train_rmsle: 0.00212 | train_mae: 0.14292 | train_rmse: 0.18613 | train_mse: 0.03465 | valid_rmsle: 0.00253 | valid_mae: 0.16224 | valid_rmse: 0.20634 | valid_mse: 0.04258 |  0:04:59s\n",
      "epoch 113| loss: 0.04088 | train_rmsle: 0.00246 | train_mae: 0.15896 | train_rmse: 0.20552 | train_mse: 0.04224 | valid_rmsle: 0.00282 | valid_mae: 0.17671 | valid_rmse: 0.22149 | valid_mse: 0.04906 |  0:05:02s\n",
      "epoch 114| loss: 0.04179 | train_rmsle: 0.00227 | train_mae: 0.14835 | train_rmse: 0.19282 | train_mse: 0.03718 | valid_rmsle: 0.00267 | valid_mae: 0.16569 | valid_rmse: 0.21188 | valid_mse: 0.04489 |  0:05:04s\n",
      "epoch 115| loss: 0.03837 | train_rmsle: 0.00223 | train_mae: 0.1494  | train_rmse: 0.19418 | train_mse: 0.03771 | valid_rmsle: 0.00257 | valid_mae: 0.16511 | valid_rmse: 0.2097  | valid_mse: 0.04397 |  0:05:07s\n",
      "epoch 116| loss: 0.03838 | train_rmsle: 0.00276 | train_mae: 0.16104 | train_rmse: 0.20626 | train_mse: 0.04254 | valid_rmsle: 0.00285 | valid_mae: 0.168   | valid_rmse: 0.21445 | valid_mse: 0.04599 |  0:05:09s\n",
      "epoch 117| loss: 0.0422  | train_rmsle: 0.00291 | train_mae: 0.16364 | train_rmse: 0.21082 | train_mse: 0.04444 | valid_rmsle: 0.0029  | valid_mae: 0.17123 | valid_rmse: 0.21674 | valid_mse: 0.04697 |  0:05:11s\n",
      "epoch 118| loss: 0.03797 | train_rmsle: 0.00194 | train_mae: 0.13964 | train_rmse: 0.1803  | train_mse: 0.03251 | valid_rmsle: 0.00221 | valid_mae: 0.15392 | valid_rmse: 0.19419 | valid_mse: 0.03771 |  0:05:14s\n",
      "epoch 119| loss: 0.03756 | train_rmsle: 0.00193 | train_mae: 0.14114 | train_rmse: 0.18143 | train_mse: 0.03292 | valid_rmsle: 0.00222 | valid_mae: 0.15582 | valid_rmse: 0.19642 | valid_mse: 0.03858 |  0:05:16s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 118 and best_valid_mse = 0.03771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.039037339211154036 RMSE: 0.1975786911869649 R2: 0.8271967411241272 MAE: 0.15303754941900286\n",
      "=====================================\n",
      "[31/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.05908 | train_rmsle: 0.47254 | train_mae: 2.11567 | train_rmse: 2.1693  | train_mse: 4.70588 | valid_rmsle: 0.47418 | valid_mae: 2.12187 | valid_rmse: 2.17427 | valid_mse: 4.72744 |  0:00:02s\n",
      "epoch 1  | loss: 1.73136 | train_rmsle: 0.12324 | train_mae: 1.22946 | train_rmse: 1.31296 | train_mse: 1.72386 | valid_rmsle: 0.12387 | valid_mae: 1.23267 | valid_rmse: 1.31742 | valid_mse: 1.7356  |  0:00:05s\n",
      "epoch 2  | loss: 0.66051 | train_rmsle: 0.04418 | train_mae: 0.75613 | train_rmse: 0.85082 | train_mse: 0.72389 | valid_rmsle: 0.04431 | valid_mae: 0.75629 | valid_rmse: 0.85431 | valid_mse: 0.72985 |  0:00:08s\n",
      "epoch 3  | loss: 0.35578 | train_rmsle: 0.02838 | train_mae: 0.60273 | train_rmse: 0.69509 | train_mse: 0.48315 | valid_rmsle: 0.02832 | valid_mae: 0.60343 | valid_rmse: 0.69767 | valid_mse: 0.48675 |  0:00:10s\n",
      "epoch 4  | loss: 0.29529 | train_rmsle: 0.01976 | train_mae: 0.49278 | train_rmse: 0.5817  | train_mse: 0.33837 | valid_rmsle: 0.0195  | valid_mae: 0.49447 | valid_rmse: 0.58226 | valid_mse: 0.33902 |  0:00:13s\n",
      "epoch 5  | loss: 0.26514 | train_rmsle: 0.02487 | train_mae: 0.56187 | train_rmse: 0.65226 | train_mse: 0.42545 | valid_rmsle: 0.02464 | valid_mae: 0.56264 | valid_rmse: 0.65296 | valid_mse: 0.42636 |  0:00:16s\n",
      "epoch 6  | loss: 0.26767 | train_rmsle: 0.0184  | train_mae: 0.47147 | train_rmse: 0.55986 | train_mse: 0.31344 | valid_rmsle: 0.018   | valid_mae: 0.47183 | valid_rmse: 0.55841 | valid_mse: 0.31182 |  0:00:19s\n",
      "epoch 7  | loss: 0.24778 | train_rmsle: 0.01839 | train_mae: 0.47148 | train_rmse: 0.55945 | train_mse: 0.31299 | valid_rmsle: 0.01797 | valid_mae: 0.47189 | valid_rmse: 0.55772 | valid_mse: 0.31106 |  0:00:21s\n",
      "epoch 8  | loss: 0.24935 | train_rmsle: 0.01736 | train_mae: 0.45375 | train_rmse: 0.54173 | train_mse: 0.29348 | valid_rmsle: 0.01692 | valid_mae: 0.45478 | valid_rmse: 0.53974 | valid_mse: 0.29132 |  0:00:24s\n",
      "epoch 9  | loss: 0.23796 | train_rmsle: 0.01469 | train_mae: 0.39167 | train_rmse: 0.48715 | train_mse: 0.23732 | valid_rmsle: 0.01424 | valid_mae: 0.39355 | valid_rmse: 0.485   | valid_mse: 0.23523 |  0:00:27s\n",
      "epoch 10 | loss: 0.23537 | train_rmsle: 0.01584 | train_mae: 0.42429 | train_rmse: 0.51604 | train_mse: 0.2663  | valid_rmsle: 0.01555 | valid_mae: 0.42633 | valid_rmse: 0.51654 | valid_mse: 0.26681 |  0:00:29s\n",
      "epoch 11 | loss: 0.23317 | train_rmsle: 0.01584 | train_mae: 0.42496 | train_rmse: 0.51637 | train_mse: 0.26664 | valid_rmsle: 0.01546 | valid_mae: 0.42625 | valid_rmse: 0.51497 | valid_mse: 0.26519 |  0:00:32s\n",
      "epoch 12 | loss: 0.23496 | train_rmsle: 0.01835 | train_mae: 0.4682  | train_rmse: 0.56025 | train_mse: 0.31388 | valid_rmsle: 0.01839 | valid_mae: 0.47186 | valid_rmse: 0.56515 | valid_mse: 0.3194  |  0:00:35s\n",
      "epoch 13 | loss: 0.25756 | train_rmsle: 0.0161  | train_mae: 0.43016 | train_rmse: 0.51925 | train_mse: 0.26962 | valid_rmsle: 0.01585 | valid_mae: 0.4337  | valid_rmse: 0.52047 | valid_mse: 0.27088 |  0:00:38s\n",
      "epoch 14 | loss: 0.22973 | train_rmsle: 0.01576 | train_mae: 0.42266 | train_rmse: 0.51252 | train_mse: 0.26268 | valid_rmsle: 0.01545 | valid_mae: 0.42569 | valid_rmse: 0.51271 | valid_mse: 0.26287 |  0:00:40s\n",
      "epoch 15 | loss: 0.2283  | train_rmsle: 0.01662 | train_mae: 0.43979 | train_rmse: 0.52924 | train_mse: 0.2801  | valid_rmsle: 0.01619 | valid_mae: 0.44086 | valid_rmse: 0.52738 | valid_mse: 0.27813 |  0:00:43s\n",
      "epoch 16 | loss: 0.22833 | train_rmsle: 0.0165  | train_mae: 0.43861 | train_rmse: 0.52848 | train_mse: 0.27929 | valid_rmsle: 0.0162  | valid_mae: 0.44058 | valid_rmse: 0.52858 | valid_mse: 0.2794  |  0:00:46s\n",
      "epoch 17 | loss: 0.23841 | train_rmsle: 0.01752 | train_mae: 0.45323 | train_rmse: 0.54674 | train_mse: 0.29893 | valid_rmsle: 0.01717 | valid_mae: 0.45383 | valid_rmse: 0.54614 | valid_mse: 0.29827 |  0:00:48s\n",
      "epoch 18 | loss: 0.22498 | train_rmsle: 0.01524 | train_mae: 0.41174 | train_rmse: 0.50336 | train_mse: 0.25337 | valid_rmsle: 0.01484 | valid_mae: 0.4143  | valid_rmse: 0.5018  | valid_mse: 0.2518  |  0:00:51s\n",
      "epoch 19 | loss: 0.23052 | train_rmsle: 0.01458 | train_mae: 0.39587 | train_rmse: 0.48906 | train_mse: 0.23918 | valid_rmsle: 0.01412 | valid_mae: 0.39867 | valid_rmse: 0.48661 | valid_mse: 0.23679 |  0:00:53s\n",
      "epoch 20 | loss: 0.22686 | train_rmsle: 0.01455 | train_mae: 0.3936  | train_rmse: 0.48789 | train_mse: 0.23804 | valid_rmsle: 0.01418 | valid_mae: 0.39723 | valid_rmse: 0.48744 | valid_mse: 0.2376  |  0:00:56s\n",
      "epoch 21 | loss: 0.22268 | train_rmsle: 0.01462 | train_mae: 0.3948  | train_rmse: 0.48849 | train_mse: 0.23863 | valid_rmsle: 0.01415 | valid_mae: 0.39705 | valid_rmse: 0.48584 | valid_mse: 0.23604 |  0:00:58s\n",
      "epoch 22 | loss: 0.22098 | train_rmsle: 0.01476 | train_mae: 0.40099 | train_rmse: 0.49349 | train_mse: 0.24353 | valid_rmsle: 0.01454 | valid_mae: 0.40547 | valid_rmse: 0.49505 | valid_mse: 0.24508 |  0:01:00s\n",
      "epoch 23 | loss: 0.22229 | train_rmsle: 0.01448 | train_mae: 0.37833 | train_rmse: 0.48001 | train_mse: 0.23041 | valid_rmsle: 0.01414 | valid_mae: 0.38227 | valid_rmse: 0.47961 | valid_mse: 0.23002 |  0:01:03s\n",
      "epoch 24 | loss: 0.22701 | train_rmsle: 0.0146  | train_mae: 0.39668 | train_rmse: 0.48941 | train_mse: 0.23952 | valid_rmsle: 0.0145  | valid_mae: 0.40422 | valid_rmse: 0.49314 | valid_mse: 0.24319 |  0:01:05s\n",
      "epoch 25 | loss: 0.21869 | train_rmsle: 0.01512 | train_mae: 0.41106 | train_rmse: 0.50137 | train_mse: 0.25137 | valid_rmsle: 0.01492 | valid_mae: 0.41508 | valid_rmse: 0.50293 | valid_mse: 0.25294 |  0:01:08s\n",
      "epoch 26 | loss: 0.22466 | train_rmsle: 0.01461 | train_mae: 0.39633 | train_rmse: 0.48937 | train_mse: 0.23948 | valid_rmsle: 0.01439 | valid_mae: 0.40107 | valid_rmse: 0.49118 | valid_mse: 0.24126 |  0:01:10s\n",
      "epoch 27 | loss: 0.22305 | train_rmsle: 0.01432 | train_mae: 0.38755 | train_rmse: 0.48251 | train_mse: 0.23281 | valid_rmsle: 0.01407 | valid_mae: 0.39293 | valid_rmse: 0.48384 | valid_mse: 0.2341  |  0:01:13s\n",
      "epoch 28 | loss: 0.21922 | train_rmsle: 0.01449 | train_mae: 0.37513 | train_rmse: 0.4789  | train_mse: 0.22935 | valid_rmsle: 0.01415 | valid_mae: 0.38132 | valid_rmse: 0.47882 | valid_mse: 0.22927 |  0:01:16s\n",
      "epoch 29 | loss: 0.2237  | train_rmsle: 0.01447 | train_mae: 0.3936  | train_rmse: 0.48722 | train_mse: 0.23738 | valid_rmsle: 0.01425 | valid_mae: 0.39722 | valid_rmse: 0.48889 | valid_mse: 0.23901 |  0:01:18s\n",
      "epoch 30 | loss: 0.21786 | train_rmsle: 0.01415 | train_mae: 0.38397 | train_rmse: 0.47911 | train_mse: 0.22955 | valid_rmsle: 0.01393 | valid_mae: 0.38951 | valid_rmse: 0.48125 | valid_mse: 0.2316  |  0:01:21s\n",
      "epoch 31 | loss: 0.21794 | train_rmsle: 0.01436 | train_mae: 0.39225 | train_rmse: 0.48502 | train_mse: 0.23525 | valid_rmsle: 0.01402 | valid_mae: 0.39699 | valid_rmse: 0.48454 | valid_mse: 0.23477 |  0:01:23s\n",
      "epoch 32 | loss: 0.22299 | train_rmsle: 0.01421 | train_mae: 0.38627 | train_rmse: 0.4811  | train_mse: 0.23146 | valid_rmsle: 0.01384 | valid_mae: 0.39113 | valid_rmse: 0.48022 | valid_mse: 0.23061 |  0:01:26s\n",
      "epoch 33 | loss: 0.22265 | train_rmsle: 0.01409 | train_mae: 0.38044 | train_rmse: 0.47674 | train_mse: 0.22728 | valid_rmsle: 0.01377 | valid_mae: 0.38615 | valid_rmse: 0.47677 | valid_mse: 0.22731 |  0:01:29s\n",
      "epoch 34 | loss: 0.21771 | train_rmsle: 0.01442 | train_mae: 0.37134 | train_rmse: 0.47669 | train_mse: 0.22723 | valid_rmsle: 0.01418 | valid_mae: 0.37993 | valid_rmse: 0.47837 | valid_mse: 0.22884 |  0:01:31s\n",
      "epoch 35 | loss: 0.2203  | train_rmsle: 0.01421 | train_mae: 0.37484 | train_rmse: 0.47574 | train_mse: 0.22633 | valid_rmsle: 0.01405 | valid_mae: 0.38366 | valid_rmse: 0.47893 | valid_mse: 0.22937 |  0:01:34s\n",
      "epoch 36 | loss: 0.21924 | train_rmsle: 0.01439 | train_mae: 0.37244 | train_rmse: 0.47661 | train_mse: 0.22716 | valid_rmsle: 0.01409 | valid_mae: 0.37849 | valid_rmse: 0.47765 | valid_mse: 0.22815 |  0:01:36s\n",
      "epoch 37 | loss: 0.2162  | train_rmsle: 0.01407 | train_mae: 0.37632 | train_rmse: 0.47428 | train_mse: 0.22494 | valid_rmsle: 0.01402 | valid_mae: 0.38895 | valid_rmse: 0.47975 | valid_mse: 0.23016 |  0:01:39s\n",
      "epoch 38 | loss: 0.21778 | train_rmsle: 0.01405 | train_mae: 0.37726 | train_rmse: 0.47469 | train_mse: 0.22533 | valid_rmsle: 0.01384 | valid_mae: 0.38476 | valid_rmse: 0.47668 | valid_mse: 0.22722 |  0:01:42s\n",
      "epoch 39 | loss: 0.21468 | train_rmsle: 0.01404 | train_mae: 0.37863 | train_rmse: 0.47507 | train_mse: 0.2257  | valid_rmsle: 0.01388 | valid_mae: 0.38781 | valid_rmse: 0.47848 | valid_mse: 0.22895 |  0:01:44s\n",
      "epoch 40 | loss: 0.21664 | train_rmsle: 0.0143  | train_mae: 0.3724  | train_rmse: 0.47584 | train_mse: 0.22643 | valid_rmsle: 0.01418 | valid_mae: 0.38279 | valid_rmse: 0.47983 | valid_mse: 0.23024 |  0:01:47s\n",
      "epoch 41 | loss: 0.21633 | train_rmsle: 0.01403 | train_mae: 0.37994 | train_rmse: 0.47501 | train_mse: 0.22563 | valid_rmsle: 0.01407 | valid_mae: 0.38885 | valid_rmse: 0.48192 | valid_mse: 0.23225 |  0:01:49s\n",
      "epoch 42 | loss: 0.21667 | train_rmsle: 0.01428 | train_mae: 0.37086 | train_rmse: 0.47516 | train_mse: 0.22577 | valid_rmsle: 0.01427 | valid_mae: 0.38082 | valid_rmse: 0.48109 | valid_mse: 0.23145 |  0:01:52s\n",
      "epoch 43 | loss: 0.21697 | train_rmsle: 0.01404 | train_mae: 0.37895 | train_rmse: 0.47517 | train_mse: 0.22579 | valid_rmsle: 0.01436 | valid_mae: 0.39104 | valid_rmse: 0.4866  | valid_mse: 0.23677 |  0:01:54s\n",
      "epoch 44 | loss: 0.2148  | train_rmsle: 0.01405 | train_mae: 0.36983 | train_rmse: 0.47179 | train_mse: 0.22259 | valid_rmsle: 0.014   | valid_mae: 0.38004 | valid_rmse: 0.47695 | valid_mse: 0.22749 |  0:01:57s\n",
      "epoch 45 | loss: 0.21433 | train_rmsle: 0.01399 | train_mae: 0.36983 | train_rmse: 0.47096 | train_mse: 0.2218  | valid_rmsle: 0.014   | valid_mae: 0.38257 | valid_rmse: 0.47739 | valid_mse: 0.2279  |  0:01:59s\n",
      "epoch 46 | loss: 0.21674 | train_rmsle: 0.01406 | train_mae: 0.37035 | train_rmse: 0.4721  | train_mse: 0.22287 | valid_rmsle: 0.01406 | valid_mae: 0.38263 | valid_rmse: 0.47856 | valid_mse: 0.22902 |  0:02:02s\n",
      "epoch 47 | loss: 0.21368 | train_rmsle: 0.01421 | train_mae: 0.36846 | train_rmse: 0.47312 | train_mse: 0.22384 | valid_rmsle: 0.01424 | valid_mae: 0.3828  | valid_rmse: 0.48047 | valid_mse: 0.23085 |  0:02:04s\n",
      "epoch 48 | loss: 0.21523 | train_rmsle: 0.014   | train_mae: 0.37242 | train_rmse: 0.47189 | train_mse: 0.22268 | valid_rmsle: 0.01396 | valid_mae: 0.38498 | valid_rmse: 0.47735 | valid_mse: 0.22786 |  0:02:06s\n",
      "epoch 49 | loss: 0.21604 | train_rmsle: 0.01397 | train_mae: 0.37711 | train_rmse: 0.47366 | train_mse: 0.22435 | valid_rmsle: 0.01398 | valid_mae: 0.38997 | valid_rmse: 0.48004 | valid_mse: 0.23043 |  0:02:08s\n",
      "epoch 50 | loss: 0.21555 | train_rmsle: 0.01407 | train_mae: 0.3708  | train_rmse: 0.47246 | train_mse: 0.22322 | valid_rmsle: 0.01391 | valid_mae: 0.38209 | valid_rmse: 0.47578 | valid_mse: 0.22637 |  0:02:11s\n",
      "epoch 51 | loss: 0.21546 | train_rmsle: 0.01394 | train_mae: 0.38103 | train_rmse: 0.475   | train_mse: 0.22563 | valid_rmsle: 0.01377 | valid_mae: 0.38841 | valid_rmse: 0.47755 | valid_mse: 0.22805 |  0:02:14s\n",
      "epoch 52 | loss: 0.21528 | train_rmsle: 0.01428 | train_mae: 0.3697  | train_rmse: 0.47467 | train_mse: 0.22531 | valid_rmsle: 0.01401 | valid_mae: 0.37947 | valid_rmse: 0.47603 | valid_mse: 0.2266  |  0:02:16s\n",
      "epoch 53 | loss: 0.21303 | train_rmsle: 0.0138  | train_mae: 0.36973 | train_rmse: 0.46891 | train_mse: 0.21988 | valid_rmsle: 0.01377 | valid_mae: 0.38226 | valid_rmse: 0.47423 | valid_mse: 0.22489 |  0:02:19s\n",
      "epoch 54 | loss: 0.21143 | train_rmsle: 0.01369 | train_mae: 0.36931 | train_rmse: 0.46728 | train_mse: 0.21835 | valid_rmsle: 0.01392 | valid_mae: 0.38473 | valid_rmse: 0.47753 | valid_mse: 0.22804 |  0:02:21s\n",
      "epoch 55 | loss: 0.21039 | train_rmsle: 0.01375 | train_mae: 0.36586 | train_rmse: 0.46658 | train_mse: 0.21769 | valid_rmsle: 0.01384 | valid_mae: 0.3808  | valid_rmse: 0.4745  | valid_mse: 0.22515 |  0:02:24s\n",
      "epoch 56 | loss: 0.20929 | train_rmsle: 0.01373 | train_mae: 0.36923 | train_rmse: 0.46825 | train_mse: 0.21926 | valid_rmsle: 0.01377 | valid_mae: 0.3839  | valid_rmse: 0.47453 | valid_mse: 0.22518 |  0:02:27s\n",
      "epoch 57 | loss: 0.21114 | train_rmsle: 0.01378 | train_mae: 0.37081 | train_rmse: 0.46892 | train_mse: 0.21988 | valid_rmsle: 0.01367 | valid_mae: 0.3821  | valid_rmse: 0.47286 | valid_mse: 0.2236  |  0:02:29s\n",
      "epoch 58 | loss: 0.21281 | train_rmsle: 0.01397 | train_mae: 0.36945 | train_rmse: 0.471   | train_mse: 0.22184 | valid_rmsle: 0.01394 | valid_mae: 0.3809  | valid_rmse: 0.47679 | valid_mse: 0.22733 |  0:02:32s\n",
      "epoch 59 | loss: 0.21078 | train_rmsle: 0.01383 | train_mae: 0.36752 | train_rmse: 0.46813 | train_mse: 0.21914 | valid_rmsle: 0.0139  | valid_mae: 0.3806  | valid_rmse: 0.47573 | valid_mse: 0.22632 |  0:02:34s\n",
      "epoch 60 | loss: 0.20882 | train_rmsle: 0.0137  | train_mae: 0.36671 | train_rmse: 0.46603 | train_mse: 0.21719 | valid_rmsle: 0.01378 | valid_mae: 0.37794 | valid_rmse: 0.47397 | valid_mse: 0.22465 |  0:02:37s\n",
      "epoch 61 | loss: 0.20771 | train_rmsle: 0.01347 | train_mae: 0.37016 | train_rmse: 0.46502 | train_mse: 0.21624 | valid_rmsle: 0.01362 | valid_mae: 0.38108 | valid_rmse: 0.4738  | valid_mse: 0.22449 |  0:02:39s\n",
      "epoch 62 | loss: 0.21065 | train_rmsle: 0.01349 | train_mae: 0.36935 | train_rmse: 0.46461 | train_mse: 0.21586 | valid_rmsle: 0.01363 | valid_mae: 0.38115 | valid_rmse: 0.47353 | valid_mse: 0.22423 |  0:02:42s\n",
      "epoch 63 | loss: 0.2082  | train_rmsle: 0.01349 | train_mae: 0.36554 | train_rmse: 0.46269 | train_mse: 0.21408 | valid_rmsle: 0.01362 | valid_mae: 0.37613 | valid_rmse: 0.47133 | valid_mse: 0.22215 |  0:02:44s\n",
      "epoch 64 | loss: 0.206   | train_rmsle: 0.01327 | train_mae: 0.36495 | train_rmse: 0.4603  | train_mse: 0.21187 | valid_rmsle: 0.01348 | valid_mae: 0.37708 | valid_rmse: 0.47081 | valid_mse: 0.22166 |  0:02:47s\n",
      "epoch 65 | loss: 0.20585 | train_rmsle: 0.01324 | train_mae: 0.36458 | train_rmse: 0.45978 | train_mse: 0.21139 | valid_rmsle: 0.01366 | valid_mae: 0.37962 | valid_rmse: 0.47396 | valid_mse: 0.22464 |  0:02:50s\n",
      "epoch 66 | loss: 0.20646 | train_rmsle: 0.01326 | train_mae: 0.36928 | train_rmse: 0.46226 | train_mse: 0.21369 | valid_rmsle: 0.01316 | valid_mae: 0.37723 | valid_rmse: 0.46699 | valid_mse: 0.21808 |  0:02:52s\n",
      "epoch 67 | loss: 0.20233 | train_rmsle: 0.01323 | train_mae: 0.36349 | train_rmse: 0.45956 | train_mse: 0.21119 | valid_rmsle: 0.01289 | valid_mae: 0.36972 | valid_rmse: 0.46004 | valid_mse: 0.21164 |  0:02:55s\n",
      "epoch 68 | loss: 0.20018 | train_rmsle: 0.01315 | train_mae: 0.35791 | train_rmse: 0.45658 | train_mse: 0.20846 | valid_rmsle: 0.01296 | valid_mae: 0.36661 | valid_rmse: 0.46008 | valid_mse: 0.21168 |  0:02:57s\n",
      "epoch 69 | loss: 0.19863 | train_rmsle: 0.01293 | train_mae: 0.3585  | train_rmse: 0.45433 | train_mse: 0.20642 | valid_rmsle: 0.01266 | valid_mae: 0.36457 | valid_rmse: 0.45601 | valid_mse: 0.20794 |  0:03:00s\n",
      "epoch 70 | loss: 0.20062 | train_rmsle: 0.01272 | train_mae: 0.35944 | train_rmse: 0.45216 | train_mse: 0.20445 | valid_rmsle: 0.01264 | valid_mae: 0.36766 | valid_rmse: 0.45746 | valid_mse: 0.20927 |  0:03:02s\n",
      "epoch 71 | loss: 0.19254 | train_rmsle: 0.0126  | train_mae: 0.34655 | train_rmse: 0.44594 | train_mse: 0.19887 | valid_rmsle: 0.01247 | valid_mae: 0.35643 | valid_rmse: 0.45018 | valid_mse: 0.20266 |  0:03:05s\n",
      "epoch 72 | loss: 0.18894 | train_rmsle: 0.01234 | train_mae: 0.34202 | train_rmse: 0.44117 | train_mse: 0.19463 | valid_rmsle: 0.01206 | valid_mae: 0.34866 | valid_rmse: 0.44197 | valid_mse: 0.19534 |  0:03:08s\n",
      "epoch 73 | loss: 0.1855  | train_rmsle: 0.01183 | train_mae: 0.33982 | train_rmse: 0.43368 | train_mse: 0.18808 | valid_rmsle: 0.0119  | valid_mae: 0.35037 | valid_rmse: 0.44142 | valid_mse: 0.19486 |  0:03:10s\n",
      "epoch 74 | loss: 0.1806  | train_rmsle: 0.01167 | train_mae: 0.33627 | train_rmse: 0.43003 | train_mse: 0.18493 | valid_rmsle: 0.01126 | valid_mae: 0.34106 | valid_rmse: 0.42794 | valid_mse: 0.18313 |  0:03:13s\n",
      "epoch 75 | loss: 0.17738 | train_rmsle: 0.01182 | train_mae: 0.32924 | train_rmse: 0.42946 | train_mse: 0.18443 | valid_rmsle: 0.0113  | valid_mae: 0.33    | valid_rmse: 0.42538 | valid_mse: 0.18095 |  0:03:15s\n",
      "epoch 76 | loss: 0.17334 | train_rmsle: 0.01138 | train_mae: 0.3436  | train_rmse: 0.42934 | train_mse: 0.18434 | valid_rmsle: 0.01111 | valid_mae: 0.34892 | valid_rmse: 0.42983 | valid_mse: 0.18476 |  0:03:18s\n",
      "epoch 77 | loss: 0.16708 | train_rmsle: 0.01081 | train_mae: 0.3156  | train_rmse: 0.41059 | train_mse: 0.16858 | valid_rmsle: 0.01071 | valid_mae: 0.32581 | valid_rmse: 0.41552 | valid_mse: 0.17266 |  0:03:20s\n",
      "epoch 78 | loss: 0.16111 | train_rmsle: 0.01017 | train_mae: 0.31432 | train_rmse: 0.40149 | train_mse: 0.1612  | valid_rmsle: 0.00993 | valid_mae: 0.32004 | valid_rmse: 0.40243 | valid_mse: 0.16195 |  0:03:23s\n",
      "epoch 79 | loss: 0.15289 | train_rmsle: 0.01    | train_mae: 0.30495 | train_rmse: 0.39537 | train_mse: 0.15632 | valid_rmsle: 0.0099  | valid_mae: 0.31432 | valid_rmse: 0.40015 | valid_mse: 0.16012 |  0:03:25s\n",
      "epoch 80 | loss: 0.14846 | train_rmsle: 0.00946 | train_mae: 0.30601 | train_rmse: 0.38813 | train_mse: 0.15064 | valid_rmsle: 0.00922 | valid_mae: 0.31103 | valid_rmse: 0.39022 | valid_mse: 0.15227 |  0:03:28s\n",
      "epoch 81 | loss: 0.14429 | train_rmsle: 0.0089  | train_mae: 0.28939 | train_rmse: 0.37305 | train_mse: 0.13916 | valid_rmsle: 0.00865 | valid_mae: 0.29562 | valid_rmse: 0.37496 | valid_mse: 0.14059 |  0:03:31s\n",
      "epoch 82 | loss: 0.13915 | train_rmsle: 0.00875 | train_mae: 0.28542 | train_rmse: 0.36961 | train_mse: 0.13661 | valid_rmsle: 0.00851 | valid_mae: 0.2912  | valid_rmse: 0.37101 | valid_mse: 0.13764 |  0:03:33s\n",
      "epoch 83 | loss: 0.13058 | train_rmsle: 0.0087  | train_mae: 0.28671 | train_rmse: 0.3698  | train_mse: 0.13676 | valid_rmsle: 0.00861 | valid_mae: 0.2964  | valid_rmse: 0.37477 | valid_mse: 0.14045 |  0:03:36s\n",
      "epoch 84 | loss: 0.12718 | train_rmsle: 0.00824 | train_mae: 0.27633 | train_rmse: 0.35813 | train_mse: 0.12826 | valid_rmsle: 0.00813 | valid_mae: 0.28789 | valid_rmse: 0.36283 | valid_mse: 0.13164 |  0:03:38s\n",
      "epoch 85 | loss: 0.12181 | train_rmsle: 0.00796 | train_mae: 0.27598 | train_rmse: 0.35324 | train_mse: 0.12478 | valid_rmsle: 0.00789 | valid_mae: 0.28853 | valid_rmse: 0.35865 | valid_mse: 0.12863 |  0:03:40s\n",
      "epoch 86 | loss: 0.11828 | train_rmsle: 0.00747 | train_mae: 0.25691 | train_rmse: 0.33774 | train_mse: 0.11407 | valid_rmsle: 0.00726 | valid_mae: 0.26656 | valid_rmse: 0.34045 | valid_mse: 0.11591 |  0:03:43s\n",
      "epoch 87 | loss: 0.11153 | train_rmsle: 0.0083  | train_mae: 0.29751 | train_rmse: 0.36729 | train_mse: 0.1349  | valid_rmsle: 0.00809 | valid_mae: 0.30231 | valid_rmse: 0.36968 | valid_mse: 0.13666 |  0:03:45s\n",
      "epoch 88 | loss: 0.11107 | train_rmsle: 0.00673 | train_mae: 0.24702 | train_rmse: 0.32199 | train_mse: 0.10368 | valid_rmsle: 0.00656 | valid_mae: 0.25686 | valid_rmse: 0.32534 | valid_mse: 0.10585 |  0:03:47s\n",
      "epoch 89 | loss: 0.10286 | train_rmsle: 0.00641 | train_mae: 0.24478 | train_rmse: 0.31587 | train_mse: 0.09977 | valid_rmsle: 0.00618 | valid_mae: 0.25256 | valid_rmse: 0.31729 | valid_mse: 0.10068 |  0:03:50s\n",
      "epoch 90 | loss: 0.09795 | train_rmsle: 0.00603 | train_mae: 0.23696 | train_rmse: 0.30647 | train_mse: 0.09392 | valid_rmsle: 0.00584 | valid_mae: 0.24369 | valid_rmse: 0.30863 | valid_mse: 0.09525 |  0:03:52s\n",
      "epoch 91 | loss: 0.09631 | train_rmsle: 0.00572 | train_mae: 0.22919 | train_rmse: 0.29812 | train_mse: 0.08887 | valid_rmsle: 0.00565 | valid_mae: 0.23754 | valid_rmse: 0.30236 | valid_mse: 0.09142 |  0:03:54s\n",
      "epoch 92 | loss: 0.09014 | train_rmsle: 0.00554 | train_mae: 0.22704 | train_rmse: 0.29408 | train_mse: 0.08649 | valid_rmsle: 0.00542 | valid_mae: 0.23387 | valid_rmse: 0.2966  | valid_mse: 0.08797 |  0:03:57s\n",
      "epoch 93 | loss: 0.08649 | train_rmsle: 0.00543 | train_mae: 0.22176 | train_rmse: 0.29071 | train_mse: 0.08451 | valid_rmsle: 0.00528 | valid_mae: 0.22914 | valid_rmse: 0.29333 | valid_mse: 0.08604 |  0:03:59s\n",
      "epoch 94 | loss: 0.0827  | train_rmsle: 0.00516 | train_mae: 0.22288 | train_rmse: 0.28588 | train_mse: 0.08173 | valid_rmsle: 0.0052  | valid_mae: 0.23318 | valid_rmse: 0.29352 | valid_mse: 0.08615 |  0:04:01s\n",
      "epoch 95 | loss: 0.07883 | train_rmsle: 0.00475 | train_mae: 0.20743 | train_rmse: 0.27099 | train_mse: 0.07343 | valid_rmsle: 0.00488 | valid_mae: 0.22278 | valid_rmse: 0.28224 | valid_mse: 0.07966 |  0:04:04s\n",
      "epoch 96 | loss: 0.07638 | train_rmsle: 0.00576 | train_mae: 0.24583 | train_rmse: 0.30618 | train_mse: 0.09375 | valid_rmsle: 0.00597 | valid_mae: 0.25456 | valid_rmse: 0.31644 | valid_mse: 0.10014 |  0:04:06s\n",
      "epoch 97 | loss: 0.07365 | train_rmsle: 0.00424 | train_mae: 0.19705 | train_rmse: 0.25674 | train_mse: 0.06591 | valid_rmsle: 0.00432 | valid_mae: 0.20761 | valid_rmse: 0.26487 | valid_mse: 0.07015 |  0:04:09s\n",
      "epoch 98 | loss: 0.06936 | train_rmsle: 0.00406 | train_mae: 0.19483 | train_rmse: 0.25295 | train_mse: 0.06398 | valid_rmsle: 0.00425 | valid_mae: 0.20827 | valid_rmse: 0.26422 | valid_mse: 0.06981 |  0:04:12s\n",
      "epoch 99 | loss: 0.06771 | train_rmsle: 0.00382 | train_mae: 0.18911 | train_rmse: 0.24572 | train_mse: 0.06038 | valid_rmsle: 0.00402 | valid_mae: 0.20208 | valid_rmse: 0.25744 | valid_mse: 0.06628 |  0:04:14s\n",
      "epoch 100| loss: 0.06453 | train_rmsle: 0.00363 | train_mae: 0.18285 | train_rmse: 0.2382  | train_mse: 0.05674 | valid_rmsle: 0.00393 | valid_mae: 0.19692 | valid_rmse: 0.25251 | valid_mse: 0.06376 |  0:04:17s\n",
      "epoch 101| loss: 0.05845 | train_rmsle: 0.00359 | train_mae: 0.18371 | train_rmse: 0.23767 | train_mse: 0.05649 | valid_rmsle: 0.0039  | valid_mae: 0.19631 | valid_rmse: 0.25132 | valid_mse: 0.06316 |  0:04:19s\n",
      "epoch 102| loss: 0.05853 | train_rmsle: 0.00339 | train_mae: 0.17828 | train_rmse: 0.23108 | train_mse: 0.0534  | valid_rmsle: 0.00377 | valid_mae: 0.19441 | valid_rmse: 0.24823 | valid_mse: 0.06162 |  0:04:22s\n",
      "epoch 103| loss: 0.05552 | train_rmsle: 0.00315 | train_mae: 0.17292 | train_rmse: 0.22389 | train_mse: 0.05013 | valid_rmsle: 0.00352 | valid_mae: 0.18983 | valid_rmse: 0.24098 | valid_mse: 0.05807 |  0:04:25s\n",
      "epoch 104| loss: 0.05372 | train_rmsle: 0.00315 | train_mae: 0.16929 | train_rmse: 0.22179 | train_mse: 0.04919 | valid_rmsle: 0.00357 | valid_mae: 0.18618 | valid_rmse: 0.24065 | valid_mse: 0.05791 |  0:04:27s\n",
      "epoch 105| loss: 0.05208 | train_rmsle: 0.00297 | train_mae: 0.1686  | train_rmse: 0.21807 | train_mse: 0.04755 | valid_rmsle: 0.00344 | valid_mae: 0.18773 | valid_rmse: 0.23835 | valid_mse: 0.05681 |  0:04:30s\n",
      "epoch 106| loss: 0.05223 | train_rmsle: 0.00298 | train_mae: 0.16762 | train_rmse: 0.21839 | train_mse: 0.04769 | valid_rmsle: 0.00336 | valid_mae: 0.1834  | valid_rmse: 0.23575 | valid_mse: 0.05558 |  0:04:32s\n",
      "epoch 107| loss: 0.04855 | train_rmsle: 0.00268 | train_mae: 0.15978 | train_rmse: 0.20789 | train_mse: 0.04322 | valid_rmsle: 0.00306 | valid_mae: 0.17684 | valid_rmse: 0.22576 | valid_mse: 0.05097 |  0:04:35s\n",
      "epoch 108| loss: 0.04574 | train_rmsle: 0.00258 | train_mae: 0.15554 | train_rmse: 0.20303 | train_mse: 0.04122 | valid_rmsle: 0.003   | valid_mae: 0.17243 | valid_rmse: 0.22203 | valid_mse: 0.0493  |  0:04:38s\n",
      "epoch 109| loss: 0.04544 | train_rmsle: 0.00253 | train_mae: 0.16027 | train_rmse: 0.20564 | train_mse: 0.04229 | valid_rmsle: 0.0029  | valid_mae: 0.17507 | valid_rmse: 0.22186 | valid_mse: 0.04922 |  0:04:40s\n",
      "epoch 110| loss: 0.04556 | train_rmsle: 0.00231 | train_mae: 0.14903 | train_rmse: 0.19404 | train_mse: 0.03765 | valid_rmsle: 0.00273 | valid_mae: 0.16736 | valid_rmse: 0.21352 | valid_mse: 0.04559 |  0:04:43s\n",
      "epoch 111| loss: 0.04312 | train_rmsle: 0.00244 | train_mae: 0.15126 | train_rmse: 0.19741 | train_mse: 0.03897 | valid_rmsle: 0.00286 | valid_mae: 0.16927 | valid_rmse: 0.21661 | valid_mse: 0.04692 |  0:04:45s\n",
      "epoch 112| loss: 0.04075 | train_rmsle: 0.00212 | train_mae: 0.14292 | train_rmse: 0.18613 | train_mse: 0.03465 | valid_rmsle: 0.00253 | valid_mae: 0.16224 | valid_rmse: 0.20634 | valid_mse: 0.04258 |  0:04:48s\n",
      "epoch 113| loss: 0.04088 | train_rmsle: 0.00246 | train_mae: 0.15896 | train_rmse: 0.20552 | train_mse: 0.04224 | valid_rmsle: 0.00282 | valid_mae: 0.17671 | valid_rmse: 0.22149 | valid_mse: 0.04906 |  0:04:50s\n",
      "epoch 114| loss: 0.04179 | train_rmsle: 0.00227 | train_mae: 0.14835 | train_rmse: 0.19282 | train_mse: 0.03718 | valid_rmsle: 0.00267 | valid_mae: 0.16569 | valid_rmse: 0.21188 | valid_mse: 0.04489 |  0:04:53s\n",
      "epoch 115| loss: 0.03837 | train_rmsle: 0.00223 | train_mae: 0.1494  | train_rmse: 0.19418 | train_mse: 0.03771 | valid_rmsle: 0.00257 | valid_mae: 0.16511 | valid_rmse: 0.2097  | valid_mse: 0.04397 |  0:04:56s\n",
      "epoch 116| loss: 0.03838 | train_rmsle: 0.00276 | train_mae: 0.16104 | train_rmse: 0.20626 | train_mse: 0.04254 | valid_rmsle: 0.00285 | valid_mae: 0.168   | valid_rmse: 0.21445 | valid_mse: 0.04599 |  0:04:58s\n",
      "epoch 117| loss: 0.0422  | train_rmsle: 0.00291 | train_mae: 0.16364 | train_rmse: 0.21082 | train_mse: 0.04444 | valid_rmsle: 0.0029  | valid_mae: 0.17123 | valid_rmse: 0.21674 | valid_mse: 0.04697 |  0:05:01s\n",
      "epoch 118| loss: 0.03797 | train_rmsle: 0.00194 | train_mae: 0.13964 | train_rmse: 0.1803  | train_mse: 0.03251 | valid_rmsle: 0.00221 | valid_mae: 0.15392 | valid_rmse: 0.19419 | valid_mse: 0.03771 |  0:05:03s\n",
      "epoch 119| loss: 0.03756 | train_rmsle: 0.00193 | train_mae: 0.14114 | train_rmse: 0.18143 | train_mse: 0.03292 | valid_rmsle: 0.00222 | valid_mae: 0.15582 | valid_rmse: 0.19642 | valid_mse: 0.03858 |  0:05:06s\n",
      "epoch 120| loss: 0.03537 | train_rmsle: 0.0019  | train_mae: 0.13728 | train_rmse: 0.17822 | train_mse: 0.03176 | valid_rmsle: 0.00225 | valid_mae: 0.15199 | valid_rmse: 0.19529 | valid_mse: 0.03814 |  0:05:08s\n",
      "epoch 121| loss: 0.03425 | train_rmsle: 0.00227 | train_mae: 0.15292 | train_rmse: 0.19511 | train_mse: 0.03807 | valid_rmsle: 0.00259 | valid_mae: 0.16456 | valid_rmse: 0.20988 | valid_mse: 0.04405 |  0:05:11s\n",
      "epoch 122| loss: 0.03587 | train_rmsle: 0.00201 | train_mae: 0.1373  | train_rmse: 0.1798  | train_mse: 0.03233 | valid_rmsle: 0.00226 | valid_mae: 0.14937 | valid_rmse: 0.1927  | valid_mse: 0.03713 |  0:05:13s\n",
      "epoch 123| loss: 0.03312 | train_rmsle: 0.00165 | train_mae: 0.12727 | train_rmse: 0.16606 | train_mse: 0.02758 | valid_rmsle: 0.00194 | valid_mae: 0.14067 | valid_rmse: 0.18206 | valid_mse: 0.03315 |  0:05:16s\n",
      "epoch 124| loss: 0.03117 | train_rmsle: 0.00163 | train_mae: 0.13042 | train_rmse: 0.16793 | train_mse: 0.0282  | valid_rmsle: 0.00191 | valid_mae: 0.14187 | valid_rmse: 0.1823  | valid_mse: 0.03323 |  0:05:18s\n",
      "epoch 125| loss: 0.0304  | train_rmsle: 0.00184 | train_mae: 0.13433 | train_rmse: 0.17302 | train_mse: 0.02993 | valid_rmsle: 0.00212 | valid_mae: 0.14662 | valid_rmse: 0.18734 | valid_mse: 0.0351  |  0:05:20s\n",
      "epoch 126| loss: 0.03127 | train_rmsle: 0.00182 | train_mae: 0.13707 | train_rmse: 0.17527 | train_mse: 0.03072 | valid_rmsle: 0.00206 | valid_mae: 0.14875 | valid_rmse: 0.18908 | valid_mse: 0.03575 |  0:05:22s\n",
      "epoch 127| loss: 0.02894 | train_rmsle: 0.0014  | train_mae: 0.11925 | train_rmse: 0.15486 | train_mse: 0.02398 | valid_rmsle: 0.00163 | valid_mae: 0.13048 | valid_rmse: 0.16835 | valid_mse: 0.02834 |  0:05:25s\n",
      "epoch 128| loss: 0.02875 | train_rmsle: 0.00148 | train_mae: 0.11976 | train_rmse: 0.15511 | train_mse: 0.02406 | valid_rmsle: 0.00176 | valid_mae: 0.1324  | valid_rmse: 0.17051 | valid_mse: 0.02908 |  0:05:28s\n",
      "epoch 129| loss: 0.02592 | train_rmsle: 0.00131 | train_mae: 0.1158  | train_rmse: 0.1501  | train_mse: 0.02253 | valid_rmsle: 0.00156 | valid_mae: 0.12828 | valid_rmse: 0.16515 | valid_mse: 0.02728 |  0:05:30s\n",
      "epoch 130| loss: 0.02706 | train_rmsle: 0.00126 | train_mae: 0.11207 | train_rmse: 0.14766 | train_mse: 0.0218  | valid_rmsle: 0.00154 | valid_mae: 0.12642 | valid_rmse: 0.16381 | valid_mse: 0.02683 |  0:05:33s\n",
      "epoch 131| loss: 0.02788 | train_rmsle: 0.0012  | train_mae: 0.1111  | train_rmse: 0.14449 | train_mse: 0.02088 | valid_rmsle: 0.00151 | valid_mae: 0.12462 | valid_rmse: 0.16219 | valid_mse: 0.02631 |  0:05:35s\n",
      "epoch 132| loss: 0.02705 | train_rmsle: 0.00117 | train_mae: 0.10865 | train_rmse: 0.14092 | train_mse: 0.01986 | valid_rmsle: 0.00147 | valid_mae: 0.12099 | valid_rmse: 0.15806 | valid_mse: 0.02498 |  0:05:37s\n",
      "epoch 133| loss: 0.02488 | train_rmsle: 0.00116 | train_mae: 0.11086 | train_rmse: 0.14288 | train_mse: 0.02041 | valid_rmsle: 0.00143 | valid_mae: 0.12395 | valid_rmse: 0.15853 | valid_mse: 0.02513 |  0:05:40s\n",
      "epoch 134| loss: 0.02539 | train_rmsle: 0.00123 | train_mae: 0.11514 | train_rmse: 0.14746 | train_mse: 0.02174 | valid_rmsle: 0.00151 | valid_mae: 0.12708 | valid_rmse: 0.16371 | valid_mse: 0.0268  |  0:05:42s\n",
      "epoch 135| loss: 0.0252  | train_rmsle: 0.00106 | train_mae: 0.10489 | train_rmse: 0.13575 | train_mse: 0.01843 | valid_rmsle: 0.00134 | valid_mae: 0.11838 | valid_rmse: 0.15278 | valid_mse: 0.02334 |  0:05:44s\n",
      "epoch 136| loss: 0.02397 | train_rmsle: 0.00103 | train_mae: 0.10267 | train_rmse: 0.13385 | train_mse: 0.01792 | valid_rmsle: 0.00126 | valid_mae: 0.11356 | valid_rmse: 0.14774 | valid_mse: 0.02183 |  0:05:46s\n",
      "epoch 137| loss: 0.02424 | train_rmsle: 0.0012  | train_mae: 0.11302 | train_rmse: 0.14593 | train_mse: 0.02129 | valid_rmsle: 0.00148 | valid_mae: 0.12628 | valid_rmse: 0.16154 | valid_mse: 0.0261  |  0:05:49s\n",
      "epoch 138| loss: 0.02327 | train_rmsle: 0.00131 | train_mae: 0.12013 | train_rmse: 0.15303 | train_mse: 0.02342 | valid_rmsle: 0.00153 | valid_mae: 0.1325  | valid_rmse: 0.16559 | valid_mse: 0.02742 |  0:05:52s\n",
      "epoch 139| loss: 0.02408 | train_rmsle: 0.00097 | train_mae: 0.09872 | train_rmse: 0.12848 | train_mse: 0.01651 | valid_rmsle: 0.00119 | valid_mae: 0.10976 | valid_rmse: 0.14326 | valid_mse: 0.02052 |  0:05:54s\n",
      "epoch 140| loss: 0.02078 | train_rmsle: 0.00113 | train_mae: 0.10953 | train_rmse: 0.13984 | train_mse: 0.01956 | valid_rmsle: 0.0013  | valid_mae: 0.11921 | valid_rmse: 0.1508  | valid_mse: 0.02274 |  0:05:57s\n",
      "epoch 141| loss: 0.02124 | train_rmsle: 0.0009  | train_mae: 0.09685 | train_rmse: 0.12502 | train_mse: 0.01563 | valid_rmsle: 0.00111 | valid_mae: 0.10864 | valid_rmse: 0.13893 | valid_mse: 0.0193  |  0:06:00s\n",
      "epoch 142| loss: 0.01918 | train_rmsle: 0.00089 | train_mae: 0.09621 | train_rmse: 0.12392 | train_mse: 0.01536 | valid_rmsle: 0.0011  | valid_mae: 0.10747 | valid_rmse: 0.13806 | valid_mse: 0.01906 |  0:06:02s\n",
      "epoch 143| loss: 0.01866 | train_rmsle: 0.00084 | train_mae: 0.0927  | train_rmse: 0.11994 | train_mse: 0.01438 | valid_rmsle: 0.00104 | valid_mae: 0.10347 | valid_rmse: 0.13407 | valid_mse: 0.01798 |  0:06:05s\n",
      "epoch 144| loss: 0.01959 | train_rmsle: 0.00094 | train_mae: 0.09695 | train_rmse: 0.12472 | train_mse: 0.01556 | valid_rmsle: 0.00114 | valid_mae: 0.10737 | valid_rmse: 0.14036 | valid_mse: 0.0197  |  0:06:07s\n",
      "epoch 145| loss: 0.01957 | train_rmsle: 0.0011  | train_mae: 0.10361 | train_rmse: 0.13217 | train_mse: 0.01747 | valid_rmsle: 0.00131 | valid_mae: 0.11473 | valid_rmse: 0.14938 | valid_mse: 0.02231 |  0:06:10s\n",
      "epoch 146| loss: 0.01741 | train_rmsle: 0.00092 | train_mae: 0.10073 | train_rmse: 0.12742 | train_mse: 0.01624 | valid_rmsle: 0.00115 | valid_mae: 0.11124 | valid_rmse: 0.14563 | valid_mse: 0.02121 |  0:06:13s\n",
      "epoch 147| loss: 0.01737 | train_rmsle: 0.00073 | train_mae: 0.08655 | train_rmse: 0.11263 | train_mse: 0.01269 | valid_rmsle: 0.00095 | valid_mae: 0.09769 | valid_rmse: 0.12976 | valid_mse: 0.01684 |  0:06:15s\n",
      "epoch 148| loss: 0.01815 | train_rmsle: 0.00076 | train_mae: 0.08753 | train_rmse: 0.11409 | train_mse: 0.01302 | valid_rmsle: 0.00095 | valid_mae: 0.09796 | valid_rmse: 0.1278  | valid_mse: 0.01633 |  0:06:18s\n",
      "epoch 149| loss: 0.01657 | train_rmsle: 0.00091 | train_mae: 0.09687 | train_rmse: 0.12308 | train_mse: 0.01515 | valid_rmsle: 0.00108 | valid_mae: 0.10594 | valid_rmse: 0.13522 | valid_mse: 0.01828 |  0:06:20s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 148 and best_valid_mse = 0.01633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.017808923451232778 RMSE: 0.1334500784984137 R2: 0.9211667579903943 MAE: 0.10183888326349934\n",
      "=====================================\n",
      "[32/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 6.05908 | train_rmsle: 0.47254 | train_mae: 2.11567 | train_rmse: 2.1693  | train_mse: 4.70588 | valid_rmsle: 0.47418 | valid_mae: 2.12187 | valid_rmse: 2.17427 | valid_mse: 4.72744 |  0:00:02s\n",
      "epoch 1  | loss: 1.73136 | train_rmsle: 0.12324 | train_mae: 1.22946 | train_rmse: 1.31296 | train_mse: 1.72386 | valid_rmsle: 0.12387 | valid_mae: 1.23267 | valid_rmse: 1.31742 | valid_mse: 1.7356  |  0:00:05s\n",
      "epoch 2  | loss: 0.66051 | train_rmsle: 0.04418 | train_mae: 0.75613 | train_rmse: 0.85082 | train_mse: 0.72389 | valid_rmsle: 0.04431 | valid_mae: 0.75629 | valid_rmse: 0.85431 | valid_mse: 0.72985 |  0:00:07s\n",
      "epoch 3  | loss: 0.35578 | train_rmsle: 0.02838 | train_mae: 0.60273 | train_rmse: 0.69509 | train_mse: 0.48315 | valid_rmsle: 0.02832 | valid_mae: 0.60343 | valid_rmse: 0.69767 | valid_mse: 0.48675 |  0:00:10s\n",
      "epoch 4  | loss: 0.29529 | train_rmsle: 0.01976 | train_mae: 0.49278 | train_rmse: 0.5817  | train_mse: 0.33837 | valid_rmsle: 0.0195  | valid_mae: 0.49447 | valid_rmse: 0.58226 | valid_mse: 0.33902 |  0:00:12s\n",
      "epoch 5  | loss: 0.26514 | train_rmsle: 0.02487 | train_mae: 0.56187 | train_rmse: 0.65226 | train_mse: 0.42545 | valid_rmsle: 0.02464 | valid_mae: 0.56264 | valid_rmse: 0.65296 | valid_mse: 0.42636 |  0:00:14s\n",
      "epoch 6  | loss: 0.26767 | train_rmsle: 0.0184  | train_mae: 0.47147 | train_rmse: 0.55986 | train_mse: 0.31344 | valid_rmsle: 0.018   | valid_mae: 0.47183 | valid_rmse: 0.55841 | valid_mse: 0.31182 |  0:00:16s\n",
      "epoch 7  | loss: 0.24778 | train_rmsle: 0.01839 | train_mae: 0.47148 | train_rmse: 0.55945 | train_mse: 0.31299 | valid_rmsle: 0.01797 | valid_mae: 0.47189 | valid_rmse: 0.55772 | valid_mse: 0.31106 |  0:00:19s\n",
      "epoch 8  | loss: 0.24935 | train_rmsle: 0.01736 | train_mae: 0.45375 | train_rmse: 0.54173 | train_mse: 0.29348 | valid_rmsle: 0.01692 | valid_mae: 0.45478 | valid_rmse: 0.53974 | valid_mse: 0.29132 |  0:00:21s\n",
      "epoch 9  | loss: 0.23796 | train_rmsle: 0.01469 | train_mae: 0.39167 | train_rmse: 0.48715 | train_mse: 0.23732 | valid_rmsle: 0.01424 | valid_mae: 0.39355 | valid_rmse: 0.485   | valid_mse: 0.23523 |  0:00:24s\n",
      "epoch 10 | loss: 0.23537 | train_rmsle: 0.01584 | train_mae: 0.42429 | train_rmse: 0.51604 | train_mse: 0.2663  | valid_rmsle: 0.01555 | valid_mae: 0.42633 | valid_rmse: 0.51654 | valid_mse: 0.26681 |  0:00:27s\n",
      "epoch 11 | loss: 0.23317 | train_rmsle: 0.01584 | train_mae: 0.42496 | train_rmse: 0.51637 | train_mse: 0.26664 | valid_rmsle: 0.01546 | valid_mae: 0.42625 | valid_rmse: 0.51497 | valid_mse: 0.26519 |  0:00:29s\n",
      "epoch 12 | loss: 0.23496 | train_rmsle: 0.01835 | train_mae: 0.4682  | train_rmse: 0.56025 | train_mse: 0.31388 | valid_rmsle: 0.01839 | valid_mae: 0.47186 | valid_rmse: 0.56515 | valid_mse: 0.3194  |  0:00:32s\n",
      "epoch 13 | loss: 0.25756 | train_rmsle: 0.0161  | train_mae: 0.43016 | train_rmse: 0.51925 | train_mse: 0.26962 | valid_rmsle: 0.01585 | valid_mae: 0.4337  | valid_rmse: 0.52047 | valid_mse: 0.27088 |  0:00:34s\n",
      "epoch 14 | loss: 0.22973 | train_rmsle: 0.01576 | train_mae: 0.42266 | train_rmse: 0.51252 | train_mse: 0.26268 | valid_rmsle: 0.01545 | valid_mae: 0.42569 | valid_rmse: 0.51271 | valid_mse: 0.26287 |  0:00:37s\n",
      "epoch 15 | loss: 0.2283  | train_rmsle: 0.01662 | train_mae: 0.43979 | train_rmse: 0.52924 | train_mse: 0.2801  | valid_rmsle: 0.01619 | valid_mae: 0.44086 | valid_rmse: 0.52738 | valid_mse: 0.27813 |  0:00:39s\n",
      "epoch 16 | loss: 0.22833 | train_rmsle: 0.0165  | train_mae: 0.43861 | train_rmse: 0.52848 | train_mse: 0.27929 | valid_rmsle: 0.0162  | valid_mae: 0.44058 | valid_rmse: 0.52858 | valid_mse: 0.2794  |  0:00:42s\n",
      "epoch 17 | loss: 0.23841 | train_rmsle: 0.01752 | train_mae: 0.45323 | train_rmse: 0.54674 | train_mse: 0.29893 | valid_rmsle: 0.01717 | valid_mae: 0.45383 | valid_rmse: 0.54614 | valid_mse: 0.29827 |  0:00:44s\n",
      "epoch 18 | loss: 0.22498 | train_rmsle: 0.01524 | train_mae: 0.41174 | train_rmse: 0.50336 | train_mse: 0.25337 | valid_rmsle: 0.01484 | valid_mae: 0.4143  | valid_rmse: 0.5018  | valid_mse: 0.2518  |  0:00:46s\n",
      "epoch 19 | loss: 0.23052 | train_rmsle: 0.01458 | train_mae: 0.39587 | train_rmse: 0.48906 | train_mse: 0.23918 | valid_rmsle: 0.01412 | valid_mae: 0.39867 | valid_rmse: 0.48661 | valid_mse: 0.23679 |  0:00:48s\n",
      "epoch 20 | loss: 0.22686 | train_rmsle: 0.01455 | train_mae: 0.3936  | train_rmse: 0.48789 | train_mse: 0.23804 | valid_rmsle: 0.01418 | valid_mae: 0.39723 | valid_rmse: 0.48744 | valid_mse: 0.2376  |  0:00:51s\n",
      "epoch 21 | loss: 0.22268 | train_rmsle: 0.01462 | train_mae: 0.3948  | train_rmse: 0.48849 | train_mse: 0.23863 | valid_rmsle: 0.01415 | valid_mae: 0.39705 | valid_rmse: 0.48584 | valid_mse: 0.23604 |  0:00:53s\n",
      "epoch 22 | loss: 0.22098 | train_rmsle: 0.01476 | train_mae: 0.40099 | train_rmse: 0.49349 | train_mse: 0.24353 | valid_rmsle: 0.01454 | valid_mae: 0.40547 | valid_rmse: 0.49505 | valid_mse: 0.24508 |  0:00:56s\n",
      "epoch 23 | loss: 0.22229 | train_rmsle: 0.01448 | train_mae: 0.37833 | train_rmse: 0.48001 | train_mse: 0.23041 | valid_rmsle: 0.01414 | valid_mae: 0.38227 | valid_rmse: 0.47961 | valid_mse: 0.23002 |  0:00:59s\n",
      "epoch 24 | loss: 0.22701 | train_rmsle: 0.0146  | train_mae: 0.39668 | train_rmse: 0.48941 | train_mse: 0.23952 | valid_rmsle: 0.0145  | valid_mae: 0.40422 | valid_rmse: 0.49314 | valid_mse: 0.24319 |  0:01:01s\n",
      "epoch 25 | loss: 0.21869 | train_rmsle: 0.01512 | train_mae: 0.41106 | train_rmse: 0.50137 | train_mse: 0.25137 | valid_rmsle: 0.01492 | valid_mae: 0.41508 | valid_rmse: 0.50293 | valid_mse: 0.25294 |  0:01:04s\n",
      "epoch 26 | loss: 0.22466 | train_rmsle: 0.01461 | train_mae: 0.39633 | train_rmse: 0.48937 | train_mse: 0.23948 | valid_rmsle: 0.01439 | valid_mae: 0.40107 | valid_rmse: 0.49118 | valid_mse: 0.24126 |  0:01:06s\n",
      "epoch 27 | loss: 0.22305 | train_rmsle: 0.01432 | train_mae: 0.38755 | train_rmse: 0.48251 | train_mse: 0.23281 | valid_rmsle: 0.01407 | valid_mae: 0.39293 | valid_rmse: 0.48384 | valid_mse: 0.2341  |  0:01:09s\n",
      "epoch 28 | loss: 0.21922 | train_rmsle: 0.01449 | train_mae: 0.37513 | train_rmse: 0.4789  | train_mse: 0.22935 | valid_rmsle: 0.01415 | valid_mae: 0.38132 | valid_rmse: 0.47882 | valid_mse: 0.22927 |  0:01:12s\n",
      "epoch 29 | loss: 0.2237  | train_rmsle: 0.01447 | train_mae: 0.3936  | train_rmse: 0.48722 | train_mse: 0.23738 | valid_rmsle: 0.01425 | valid_mae: 0.39722 | valid_rmse: 0.48889 | valid_mse: 0.23901 |  0:01:14s\n",
      "epoch 30 | loss: 0.21786 | train_rmsle: 0.01415 | train_mae: 0.38397 | train_rmse: 0.47911 | train_mse: 0.22955 | valid_rmsle: 0.01393 | valid_mae: 0.38951 | valid_rmse: 0.48125 | valid_mse: 0.2316  |  0:01:17s\n",
      "epoch 31 | loss: 0.21794 | train_rmsle: 0.01436 | train_mae: 0.39225 | train_rmse: 0.48502 | train_mse: 0.23525 | valid_rmsle: 0.01402 | valid_mae: 0.39699 | valid_rmse: 0.48454 | valid_mse: 0.23477 |  0:01:19s\n",
      "epoch 32 | loss: 0.22299 | train_rmsle: 0.01421 | train_mae: 0.38627 | train_rmse: 0.4811  | train_mse: 0.23146 | valid_rmsle: 0.01384 | valid_mae: 0.39113 | valid_rmse: 0.48022 | valid_mse: 0.23061 |  0:01:21s\n",
      "epoch 33 | loss: 0.22265 | train_rmsle: 0.01409 | train_mae: 0.38044 | train_rmse: 0.47674 | train_mse: 0.22728 | valid_rmsle: 0.01377 | valid_mae: 0.38615 | valid_rmse: 0.47677 | valid_mse: 0.22731 |  0:01:24s\n",
      "epoch 34 | loss: 0.21771 | train_rmsle: 0.01442 | train_mae: 0.37134 | train_rmse: 0.47669 | train_mse: 0.22723 | valid_rmsle: 0.01418 | valid_mae: 0.37993 | valid_rmse: 0.47837 | valid_mse: 0.22884 |  0:01:26s\n",
      "epoch 35 | loss: 0.2203  | train_rmsle: 0.01421 | train_mae: 0.37484 | train_rmse: 0.47574 | train_mse: 0.22633 | valid_rmsle: 0.01405 | valid_mae: 0.38366 | valid_rmse: 0.47893 | valid_mse: 0.22937 |  0:01:29s\n",
      "epoch 36 | loss: 0.21924 | train_rmsle: 0.01439 | train_mae: 0.37244 | train_rmse: 0.47661 | train_mse: 0.22716 | valid_rmsle: 0.01409 | valid_mae: 0.37849 | valid_rmse: 0.47765 | valid_mse: 0.22815 |  0:01:32s\n",
      "epoch 37 | loss: 0.2162  | train_rmsle: 0.01407 | train_mae: 0.37632 | train_rmse: 0.47428 | train_mse: 0.22494 | valid_rmsle: 0.01402 | valid_mae: 0.38895 | valid_rmse: 0.47975 | valid_mse: 0.23016 |  0:01:34s\n",
      "epoch 38 | loss: 0.21778 | train_rmsle: 0.01405 | train_mae: 0.37726 | train_rmse: 0.47469 | train_mse: 0.22533 | valid_rmsle: 0.01384 | valid_mae: 0.38476 | valid_rmse: 0.47668 | valid_mse: 0.22722 |  0:01:37s\n",
      "epoch 39 | loss: 0.21468 | train_rmsle: 0.01404 | train_mae: 0.37863 | train_rmse: 0.47507 | train_mse: 0.2257  | valid_rmsle: 0.01388 | valid_mae: 0.38781 | valid_rmse: 0.47848 | valid_mse: 0.22895 |  0:01:40s\n",
      "epoch 40 | loss: 0.21664 | train_rmsle: 0.0143  | train_mae: 0.3724  | train_rmse: 0.47584 | train_mse: 0.22643 | valid_rmsle: 0.01418 | valid_mae: 0.38279 | valid_rmse: 0.47983 | valid_mse: 0.23024 |  0:01:42s\n",
      "epoch 41 | loss: 0.21633 | train_rmsle: 0.01403 | train_mae: 0.37994 | train_rmse: 0.47501 | train_mse: 0.22563 | valid_rmsle: 0.01407 | valid_mae: 0.38885 | valid_rmse: 0.48192 | valid_mse: 0.23225 |  0:01:45s\n",
      "epoch 42 | loss: 0.21667 | train_rmsle: 0.01428 | train_mae: 0.37086 | train_rmse: 0.47516 | train_mse: 0.22577 | valid_rmsle: 0.01427 | valid_mae: 0.38082 | valid_rmse: 0.48109 | valid_mse: 0.23145 |  0:01:48s\n",
      "epoch 43 | loss: 0.21697 | train_rmsle: 0.01404 | train_mae: 0.37895 | train_rmse: 0.47517 | train_mse: 0.22579 | valid_rmsle: 0.01436 | valid_mae: 0.39104 | valid_rmse: 0.4866  | valid_mse: 0.23677 |  0:01:50s\n",
      "epoch 44 | loss: 0.2148  | train_rmsle: 0.01405 | train_mae: 0.36983 | train_rmse: 0.47179 | train_mse: 0.22259 | valid_rmsle: 0.014   | valid_mae: 0.38004 | valid_rmse: 0.47695 | valid_mse: 0.22749 |  0:01:53s\n",
      "epoch 45 | loss: 0.21433 | train_rmsle: 0.01399 | train_mae: 0.36983 | train_rmse: 0.47096 | train_mse: 0.2218  | valid_rmsle: 0.014   | valid_mae: 0.38257 | valid_rmse: 0.47739 | valid_mse: 0.2279  |  0:01:56s\n",
      "epoch 46 | loss: 0.21674 | train_rmsle: 0.01406 | train_mae: 0.37035 | train_rmse: 0.4721  | train_mse: 0.22287 | valid_rmsle: 0.01406 | valid_mae: 0.38263 | valid_rmse: 0.47856 | valid_mse: 0.22902 |  0:01:58s\n",
      "epoch 47 | loss: 0.21368 | train_rmsle: 0.01421 | train_mae: 0.36846 | train_rmse: 0.47312 | train_mse: 0.22384 | valid_rmsle: 0.01424 | valid_mae: 0.3828  | valid_rmse: 0.48047 | valid_mse: 0.23085 |  0:02:01s\n",
      "epoch 48 | loss: 0.21523 | train_rmsle: 0.014   | train_mae: 0.37242 | train_rmse: 0.47189 | train_mse: 0.22268 | valid_rmsle: 0.01396 | valid_mae: 0.38498 | valid_rmse: 0.47735 | valid_mse: 0.22786 |  0:02:04s\n",
      "epoch 49 | loss: 0.21604 | train_rmsle: 0.01397 | train_mae: 0.37711 | train_rmse: 0.47366 | train_mse: 0.22435 | valid_rmsle: 0.01398 | valid_mae: 0.38997 | valid_rmse: 0.48004 | valid_mse: 0.23043 |  0:02:06s\n",
      "epoch 50 | loss: 0.21555 | train_rmsle: 0.01407 | train_mae: 0.3708  | train_rmse: 0.47246 | train_mse: 0.22322 | valid_rmsle: 0.01391 | valid_mae: 0.38209 | valid_rmse: 0.47578 | valid_mse: 0.22637 |  0:02:09s\n",
      "epoch 51 | loss: 0.21546 | train_rmsle: 0.01394 | train_mae: 0.38103 | train_rmse: 0.475   | train_mse: 0.22563 | valid_rmsle: 0.01377 | valid_mae: 0.38841 | valid_rmse: 0.47755 | valid_mse: 0.22805 |  0:02:12s\n",
      "epoch 52 | loss: 0.21528 | train_rmsle: 0.01428 | train_mae: 0.3697  | train_rmse: 0.47467 | train_mse: 0.22531 | valid_rmsle: 0.01401 | valid_mae: 0.37947 | valid_rmse: 0.47603 | valid_mse: 0.2266  |  0:02:14s\n",
      "epoch 53 | loss: 0.21303 | train_rmsle: 0.0138  | train_mae: 0.36973 | train_rmse: 0.46891 | train_mse: 0.21988 | valid_rmsle: 0.01377 | valid_mae: 0.38226 | valid_rmse: 0.47423 | valid_mse: 0.22489 |  0:02:17s\n",
      "epoch 54 | loss: 0.21143 | train_rmsle: 0.01369 | train_mae: 0.36931 | train_rmse: 0.46728 | train_mse: 0.21835 | valid_rmsle: 0.01392 | valid_mae: 0.38473 | valid_rmse: 0.47753 | valid_mse: 0.22804 |  0:02:20s\n",
      "epoch 55 | loss: 0.21039 | train_rmsle: 0.01375 | train_mae: 0.36586 | train_rmse: 0.46658 | train_mse: 0.21769 | valid_rmsle: 0.01384 | valid_mae: 0.3808  | valid_rmse: 0.4745  | valid_mse: 0.22515 |  0:02:22s\n",
      "epoch 56 | loss: 0.20929 | train_rmsle: 0.01373 | train_mae: 0.36923 | train_rmse: 0.46825 | train_mse: 0.21926 | valid_rmsle: 0.01377 | valid_mae: 0.3839  | valid_rmse: 0.47453 | valid_mse: 0.22518 |  0:02:25s\n",
      "epoch 57 | loss: 0.21114 | train_rmsle: 0.01378 | train_mae: 0.37081 | train_rmse: 0.46892 | train_mse: 0.21988 | valid_rmsle: 0.01367 | valid_mae: 0.3821  | valid_rmse: 0.47286 | valid_mse: 0.2236  |  0:02:27s\n",
      "epoch 58 | loss: 0.21281 | train_rmsle: 0.01397 | train_mae: 0.36945 | train_rmse: 0.471   | train_mse: 0.22184 | valid_rmsle: 0.01394 | valid_mae: 0.3809  | valid_rmse: 0.47679 | valid_mse: 0.22733 |  0:02:29s\n",
      "epoch 59 | loss: 0.21078 | train_rmsle: 0.01383 | train_mae: 0.36752 | train_rmse: 0.46813 | train_mse: 0.21914 | valid_rmsle: 0.0139  | valid_mae: 0.3806  | valid_rmse: 0.47573 | valid_mse: 0.22632 |  0:02:31s\n",
      "epoch 60 | loss: 0.20882 | train_rmsle: 0.0137  | train_mae: 0.36671 | train_rmse: 0.46603 | train_mse: 0.21719 | valid_rmsle: 0.01378 | valid_mae: 0.37794 | valid_rmse: 0.47397 | valid_mse: 0.22465 |  0:02:33s\n",
      "epoch 61 | loss: 0.20771 | train_rmsle: 0.01347 | train_mae: 0.37016 | train_rmse: 0.46502 | train_mse: 0.21624 | valid_rmsle: 0.01362 | valid_mae: 0.38108 | valid_rmse: 0.4738  | valid_mse: 0.22449 |  0:02:36s\n",
      "epoch 62 | loss: 0.21065 | train_rmsle: 0.01349 | train_mae: 0.36935 | train_rmse: 0.46461 | train_mse: 0.21586 | valid_rmsle: 0.01363 | valid_mae: 0.38115 | valid_rmse: 0.47353 | valid_mse: 0.22423 |  0:02:38s\n",
      "epoch 63 | loss: 0.2082  | train_rmsle: 0.01349 | train_mae: 0.36554 | train_rmse: 0.46269 | train_mse: 0.21408 | valid_rmsle: 0.01362 | valid_mae: 0.37613 | valid_rmse: 0.47133 | valid_mse: 0.22215 |  0:02:40s\n",
      "epoch 64 | loss: 0.206   | train_rmsle: 0.01327 | train_mae: 0.36495 | train_rmse: 0.4603  | train_mse: 0.21187 | valid_rmsle: 0.01348 | valid_mae: 0.37708 | valid_rmse: 0.47081 | valid_mse: 0.22166 |  0:02:43s\n",
      "epoch 65 | loss: 0.20585 | train_rmsle: 0.01324 | train_mae: 0.36458 | train_rmse: 0.45978 | train_mse: 0.21139 | valid_rmsle: 0.01366 | valid_mae: 0.37962 | valid_rmse: 0.47396 | valid_mse: 0.22464 |  0:02:45s\n",
      "epoch 66 | loss: 0.20646 | train_rmsle: 0.01326 | train_mae: 0.36928 | train_rmse: 0.46226 | train_mse: 0.21369 | valid_rmsle: 0.01316 | valid_mae: 0.37723 | valid_rmse: 0.46699 | valid_mse: 0.21808 |  0:02:48s\n",
      "epoch 67 | loss: 0.20233 | train_rmsle: 0.01323 | train_mae: 0.36349 | train_rmse: 0.45956 | train_mse: 0.21119 | valid_rmsle: 0.01289 | valid_mae: 0.36972 | valid_rmse: 0.46004 | valid_mse: 0.21164 |  0:02:51s\n",
      "epoch 68 | loss: 0.20018 | train_rmsle: 0.01315 | train_mae: 0.35791 | train_rmse: 0.45658 | train_mse: 0.20846 | valid_rmsle: 0.01296 | valid_mae: 0.36661 | valid_rmse: 0.46008 | valid_mse: 0.21168 |  0:02:53s\n",
      "epoch 69 | loss: 0.19863 | train_rmsle: 0.01293 | train_mae: 0.3585  | train_rmse: 0.45433 | train_mse: 0.20642 | valid_rmsle: 0.01266 | valid_mae: 0.36457 | valid_rmse: 0.45601 | valid_mse: 0.20794 |  0:02:56s\n",
      "epoch 70 | loss: 0.20062 | train_rmsle: 0.01272 | train_mae: 0.35944 | train_rmse: 0.45216 | train_mse: 0.20445 | valid_rmsle: 0.01264 | valid_mae: 0.36766 | valid_rmse: 0.45746 | valid_mse: 0.20927 |  0:02:59s\n",
      "epoch 71 | loss: 0.19254 | train_rmsle: 0.0126  | train_mae: 0.34655 | train_rmse: 0.44594 | train_mse: 0.19887 | valid_rmsle: 0.01247 | valid_mae: 0.35643 | valid_rmse: 0.45018 | valid_mse: 0.20266 |  0:03:01s\n",
      "epoch 72 | loss: 0.18894 | train_rmsle: 0.01234 | train_mae: 0.34202 | train_rmse: 0.44117 | train_mse: 0.19463 | valid_rmsle: 0.01206 | valid_mae: 0.34866 | valid_rmse: 0.44197 | valid_mse: 0.19534 |  0:03:04s\n",
      "epoch 73 | loss: 0.1855  | train_rmsle: 0.01183 | train_mae: 0.33982 | train_rmse: 0.43368 | train_mse: 0.18808 | valid_rmsle: 0.0119  | valid_mae: 0.35037 | valid_rmse: 0.44142 | valid_mse: 0.19486 |  0:03:07s\n",
      "epoch 74 | loss: 0.1806  | train_rmsle: 0.01167 | train_mae: 0.33627 | train_rmse: 0.43003 | train_mse: 0.18493 | valid_rmsle: 0.01126 | valid_mae: 0.34106 | valid_rmse: 0.42794 | valid_mse: 0.18313 |  0:03:09s\n",
      "epoch 75 | loss: 0.17738 | train_rmsle: 0.01182 | train_mae: 0.32924 | train_rmse: 0.42946 | train_mse: 0.18443 | valid_rmsle: 0.0113  | valid_mae: 0.33    | valid_rmse: 0.42538 | valid_mse: 0.18095 |  0:03:12s\n",
      "epoch 76 | loss: 0.17334 | train_rmsle: 0.01138 | train_mae: 0.3436  | train_rmse: 0.42934 | train_mse: 0.18434 | valid_rmsle: 0.01111 | valid_mae: 0.34892 | valid_rmse: 0.42983 | valid_mse: 0.18476 |  0:03:15s\n",
      "epoch 77 | loss: 0.16708 | train_rmsle: 0.01081 | train_mae: 0.3156  | train_rmse: 0.41059 | train_mse: 0.16858 | valid_rmsle: 0.01071 | valid_mae: 0.32581 | valid_rmse: 0.41552 | valid_mse: 0.17266 |  0:03:17s\n",
      "epoch 78 | loss: 0.16111 | train_rmsle: 0.01017 | train_mae: 0.31432 | train_rmse: 0.40149 | train_mse: 0.1612  | valid_rmsle: 0.00993 | valid_mae: 0.32004 | valid_rmse: 0.40243 | valid_mse: 0.16195 |  0:03:20s\n",
      "epoch 79 | loss: 0.15289 | train_rmsle: 0.01    | train_mae: 0.30495 | train_rmse: 0.39537 | train_mse: 0.15632 | valid_rmsle: 0.0099  | valid_mae: 0.31432 | valid_rmse: 0.40015 | valid_mse: 0.16012 |  0:03:23s\n",
      "epoch 80 | loss: 0.14846 | train_rmsle: 0.00946 | train_mae: 0.30601 | train_rmse: 0.38813 | train_mse: 0.15064 | valid_rmsle: 0.00922 | valid_mae: 0.31103 | valid_rmse: 0.39022 | valid_mse: 0.15227 |  0:03:25s\n",
      "epoch 81 | loss: 0.14429 | train_rmsle: 0.0089  | train_mae: 0.28939 | train_rmse: 0.37305 | train_mse: 0.13916 | valid_rmsle: 0.00865 | valid_mae: 0.29562 | valid_rmse: 0.37496 | valid_mse: 0.14059 |  0:03:28s\n",
      "epoch 82 | loss: 0.13915 | train_rmsle: 0.00875 | train_mae: 0.28542 | train_rmse: 0.36961 | train_mse: 0.13661 | valid_rmsle: 0.00851 | valid_mae: 0.2912  | valid_rmse: 0.37101 | valid_mse: 0.13764 |  0:03:31s\n",
      "epoch 83 | loss: 0.13058 | train_rmsle: 0.0087  | train_mae: 0.28671 | train_rmse: 0.3698  | train_mse: 0.13676 | valid_rmsle: 0.00861 | valid_mae: 0.2964  | valid_rmse: 0.37477 | valid_mse: 0.14045 |  0:03:33s\n",
      "epoch 84 | loss: 0.12718 | train_rmsle: 0.00824 | train_mae: 0.27633 | train_rmse: 0.35813 | train_mse: 0.12826 | valid_rmsle: 0.00813 | valid_mae: 0.28789 | valid_rmse: 0.36283 | valid_mse: 0.13164 |  0:03:35s\n",
      "epoch 85 | loss: 0.12181 | train_rmsle: 0.00796 | train_mae: 0.27598 | train_rmse: 0.35324 | train_mse: 0.12478 | valid_rmsle: 0.00789 | valid_mae: 0.28853 | valid_rmse: 0.35865 | valid_mse: 0.12863 |  0:03:38s\n",
      "epoch 86 | loss: 0.11828 | train_rmsle: 0.00747 | train_mae: 0.25691 | train_rmse: 0.33774 | train_mse: 0.11407 | valid_rmsle: 0.00726 | valid_mae: 0.26656 | valid_rmse: 0.34045 | valid_mse: 0.11591 |  0:03:40s\n",
      "epoch 87 | loss: 0.11153 | train_rmsle: 0.0083  | train_mae: 0.29751 | train_rmse: 0.36729 | train_mse: 0.1349  | valid_rmsle: 0.00809 | valid_mae: 0.30231 | valid_rmse: 0.36968 | valid_mse: 0.13666 |  0:03:43s\n",
      "epoch 88 | loss: 0.11107 | train_rmsle: 0.00673 | train_mae: 0.24702 | train_rmse: 0.32199 | train_mse: 0.10368 | valid_rmsle: 0.00656 | valid_mae: 0.25686 | valid_rmse: 0.32534 | valid_mse: 0.10585 |  0:03:46s\n",
      "epoch 89 | loss: 0.10286 | train_rmsle: 0.00641 | train_mae: 0.24478 | train_rmse: 0.31587 | train_mse: 0.09977 | valid_rmsle: 0.00618 | valid_mae: 0.25256 | valid_rmse: 0.31729 | valid_mse: 0.10068 |  0:03:48s\n",
      "epoch 90 | loss: 0.09795 | train_rmsle: 0.00603 | train_mae: 0.23696 | train_rmse: 0.30647 | train_mse: 0.09392 | valid_rmsle: 0.00584 | valid_mae: 0.24369 | valid_rmse: 0.30863 | valid_mse: 0.09525 |  0:03:51s\n",
      "epoch 91 | loss: 0.09631 | train_rmsle: 0.00572 | train_mae: 0.22919 | train_rmse: 0.29812 | train_mse: 0.08887 | valid_rmsle: 0.00565 | valid_mae: 0.23754 | valid_rmse: 0.30236 | valid_mse: 0.09142 |  0:03:53s\n",
      "epoch 92 | loss: 0.09014 | train_rmsle: 0.00554 | train_mae: 0.22704 | train_rmse: 0.29408 | train_mse: 0.08649 | valid_rmsle: 0.00542 | valid_mae: 0.23387 | valid_rmse: 0.2966  | valid_mse: 0.08797 |  0:03:56s\n",
      "epoch 93 | loss: 0.08649 | train_rmsle: 0.00543 | train_mae: 0.22176 | train_rmse: 0.29071 | train_mse: 0.08451 | valid_rmsle: 0.00528 | valid_mae: 0.22914 | valid_rmse: 0.29333 | valid_mse: 0.08604 |  0:03:59s\n",
      "epoch 94 | loss: 0.0827  | train_rmsle: 0.00516 | train_mae: 0.22288 | train_rmse: 0.28588 | train_mse: 0.08173 | valid_rmsle: 0.0052  | valid_mae: 0.23318 | valid_rmse: 0.29352 | valid_mse: 0.08615 |  0:04:02s\n",
      "epoch 95 | loss: 0.07883 | train_rmsle: 0.00475 | train_mae: 0.20743 | train_rmse: 0.27099 | train_mse: 0.07343 | valid_rmsle: 0.00488 | valid_mae: 0.22278 | valid_rmse: 0.28224 | valid_mse: 0.07966 |  0:04:04s\n",
      "epoch 96 | loss: 0.07638 | train_rmsle: 0.00576 | train_mae: 0.24583 | train_rmse: 0.30618 | train_mse: 0.09375 | valid_rmsle: 0.00597 | valid_mae: 0.25456 | valid_rmse: 0.31644 | valid_mse: 0.10014 |  0:04:07s\n",
      "epoch 97 | loss: 0.07365 | train_rmsle: 0.00424 | train_mae: 0.19705 | train_rmse: 0.25674 | train_mse: 0.06591 | valid_rmsle: 0.00432 | valid_mae: 0.20761 | valid_rmse: 0.26487 | valid_mse: 0.07015 |  0:04:09s\n",
      "epoch 98 | loss: 0.06936 | train_rmsle: 0.00406 | train_mae: 0.19483 | train_rmse: 0.25295 | train_mse: 0.06398 | valid_rmsle: 0.00425 | valid_mae: 0.20827 | valid_rmse: 0.26422 | valid_mse: 0.06981 |  0:04:12s\n",
      "epoch 99 | loss: 0.06771 | train_rmsle: 0.00382 | train_mae: 0.18911 | train_rmse: 0.24572 | train_mse: 0.06038 | valid_rmsle: 0.00402 | valid_mae: 0.20208 | valid_rmse: 0.25744 | valid_mse: 0.06628 |  0:04:15s\n",
      "epoch 100| loss: 0.06453 | train_rmsle: 0.00363 | train_mae: 0.18285 | train_rmse: 0.2382  | train_mse: 0.05674 | valid_rmsle: 0.00393 | valid_mae: 0.19692 | valid_rmse: 0.25251 | valid_mse: 0.06376 |  0:04:17s\n",
      "epoch 101| loss: 0.05845 | train_rmsle: 0.00359 | train_mae: 0.18371 | train_rmse: 0.23767 | train_mse: 0.05649 | valid_rmsle: 0.0039  | valid_mae: 0.19631 | valid_rmse: 0.25132 | valid_mse: 0.06316 |  0:04:20s\n",
      "epoch 102| loss: 0.05853 | train_rmsle: 0.00339 | train_mae: 0.17828 | train_rmse: 0.23108 | train_mse: 0.0534  | valid_rmsle: 0.00377 | valid_mae: 0.19441 | valid_rmse: 0.24823 | valid_mse: 0.06162 |  0:04:23s\n",
      "epoch 103| loss: 0.05552 | train_rmsle: 0.00315 | train_mae: 0.17292 | train_rmse: 0.22389 | train_mse: 0.05013 | valid_rmsle: 0.00352 | valid_mae: 0.18983 | valid_rmse: 0.24098 | valid_mse: 0.05807 |  0:04:25s\n",
      "epoch 104| loss: 0.05372 | train_rmsle: 0.00315 | train_mae: 0.16929 | train_rmse: 0.22179 | train_mse: 0.04919 | valid_rmsle: 0.00357 | valid_mae: 0.18618 | valid_rmse: 0.24065 | valid_mse: 0.05791 |  0:04:27s\n",
      "epoch 105| loss: 0.05208 | train_rmsle: 0.00297 | train_mae: 0.1686  | train_rmse: 0.21807 | train_mse: 0.04755 | valid_rmsle: 0.00344 | valid_mae: 0.18773 | valid_rmse: 0.23835 | valid_mse: 0.05681 |  0:04:30s\n",
      "epoch 106| loss: 0.05223 | train_rmsle: 0.00298 | train_mae: 0.16762 | train_rmse: 0.21839 | train_mse: 0.04769 | valid_rmsle: 0.00336 | valid_mae: 0.1834  | valid_rmse: 0.23575 | valid_mse: 0.05558 |  0:04:32s\n",
      "epoch 107| loss: 0.04855 | train_rmsle: 0.00268 | train_mae: 0.15978 | train_rmse: 0.20789 | train_mse: 0.04322 | valid_rmsle: 0.00306 | valid_mae: 0.17684 | valid_rmse: 0.22576 | valid_mse: 0.05097 |  0:04:34s\n",
      "epoch 108| loss: 0.04574 | train_rmsle: 0.00258 | train_mae: 0.15554 | train_rmse: 0.20303 | train_mse: 0.04122 | valid_rmsle: 0.003   | valid_mae: 0.17243 | valid_rmse: 0.22203 | valid_mse: 0.0493  |  0:04:37s\n",
      "epoch 109| loss: 0.04544 | train_rmsle: 0.00253 | train_mae: 0.16027 | train_rmse: 0.20564 | train_mse: 0.04229 | valid_rmsle: 0.0029  | valid_mae: 0.17507 | valid_rmse: 0.22186 | valid_mse: 0.04922 |  0:04:39s\n",
      "epoch 110| loss: 0.04556 | train_rmsle: 0.00231 | train_mae: 0.14903 | train_rmse: 0.19404 | train_mse: 0.03765 | valid_rmsle: 0.00273 | valid_mae: 0.16736 | valid_rmse: 0.21352 | valid_mse: 0.04559 |  0:04:42s\n",
      "epoch 111| loss: 0.04312 | train_rmsle: 0.00244 | train_mae: 0.15126 | train_rmse: 0.19741 | train_mse: 0.03897 | valid_rmsle: 0.00286 | valid_mae: 0.16927 | valid_rmse: 0.21661 | valid_mse: 0.04692 |  0:04:44s\n",
      "epoch 112| loss: 0.04075 | train_rmsle: 0.00212 | train_mae: 0.14292 | train_rmse: 0.18613 | train_mse: 0.03465 | valid_rmsle: 0.00253 | valid_mae: 0.16224 | valid_rmse: 0.20634 | valid_mse: 0.04258 |  0:04:46s\n",
      "epoch 113| loss: 0.04088 | train_rmsle: 0.00246 | train_mae: 0.15896 | train_rmse: 0.20552 | train_mse: 0.04224 | valid_rmsle: 0.00282 | valid_mae: 0.17671 | valid_rmse: 0.22149 | valid_mse: 0.04906 |  0:04:49s\n",
      "epoch 114| loss: 0.04179 | train_rmsle: 0.00227 | train_mae: 0.14835 | train_rmse: 0.19282 | train_mse: 0.03718 | valid_rmsle: 0.00267 | valid_mae: 0.16569 | valid_rmse: 0.21188 | valid_mse: 0.04489 |  0:04:52s\n",
      "epoch 115| loss: 0.03837 | train_rmsle: 0.00223 | train_mae: 0.1494  | train_rmse: 0.19418 | train_mse: 0.03771 | valid_rmsle: 0.00257 | valid_mae: 0.16511 | valid_rmse: 0.2097  | valid_mse: 0.04397 |  0:04:54s\n",
      "epoch 116| loss: 0.03838 | train_rmsle: 0.00276 | train_mae: 0.16104 | train_rmse: 0.20626 | train_mse: 0.04254 | valid_rmsle: 0.00285 | valid_mae: 0.168   | valid_rmse: 0.21445 | valid_mse: 0.04599 |  0:04:57s\n",
      "epoch 117| loss: 0.0422  | train_rmsle: 0.00291 | train_mae: 0.16364 | train_rmse: 0.21082 | train_mse: 0.04444 | valid_rmsle: 0.0029  | valid_mae: 0.17123 | valid_rmse: 0.21674 | valid_mse: 0.04697 |  0:05:00s\n",
      "epoch 118| loss: 0.03797 | train_rmsle: 0.00194 | train_mae: 0.13964 | train_rmse: 0.1803  | train_mse: 0.03251 | valid_rmsle: 0.00221 | valid_mae: 0.15392 | valid_rmse: 0.19419 | valid_mse: 0.03771 |  0:05:02s\n",
      "epoch 119| loss: 0.03756 | train_rmsle: 0.00193 | train_mae: 0.14114 | train_rmse: 0.18143 | train_mse: 0.03292 | valid_rmsle: 0.00222 | valid_mae: 0.15582 | valid_rmse: 0.19642 | valid_mse: 0.03858 |  0:05:05s\n",
      "epoch 120| loss: 0.03537 | train_rmsle: 0.0019  | train_mae: 0.13728 | train_rmse: 0.17822 | train_mse: 0.03176 | valid_rmsle: 0.00225 | valid_mae: 0.15199 | valid_rmse: 0.19529 | valid_mse: 0.03814 |  0:05:08s\n",
      "epoch 121| loss: 0.03425 | train_rmsle: 0.00227 | train_mae: 0.15292 | train_rmse: 0.19511 | train_mse: 0.03807 | valid_rmsle: 0.00259 | valid_mae: 0.16456 | valid_rmse: 0.20988 | valid_mse: 0.04405 |  0:05:10s\n",
      "epoch 122| loss: 0.03587 | train_rmsle: 0.00201 | train_mae: 0.1373  | train_rmse: 0.1798  | train_mse: 0.03233 | valid_rmsle: 0.00226 | valid_mae: 0.14937 | valid_rmse: 0.1927  | valid_mse: 0.03713 |  0:05:13s\n",
      "epoch 123| loss: 0.03312 | train_rmsle: 0.00165 | train_mae: 0.12727 | train_rmse: 0.16606 | train_mse: 0.02758 | valid_rmsle: 0.00194 | valid_mae: 0.14067 | valid_rmse: 0.18206 | valid_mse: 0.03315 |  0:05:16s\n",
      "epoch 124| loss: 0.03117 | train_rmsle: 0.00163 | train_mae: 0.13042 | train_rmse: 0.16793 | train_mse: 0.0282  | valid_rmsle: 0.00191 | valid_mae: 0.14187 | valid_rmse: 0.1823  | valid_mse: 0.03323 |  0:05:18s\n",
      "epoch 125| loss: 0.0304  | train_rmsle: 0.00184 | train_mae: 0.13433 | train_rmse: 0.17302 | train_mse: 0.02993 | valid_rmsle: 0.00212 | valid_mae: 0.14662 | valid_rmse: 0.18734 | valid_mse: 0.0351  |  0:05:21s\n",
      "epoch 126| loss: 0.03127 | train_rmsle: 0.00182 | train_mae: 0.13707 | train_rmse: 0.17527 | train_mse: 0.03072 | valid_rmsle: 0.00206 | valid_mae: 0.14875 | valid_rmse: 0.18908 | valid_mse: 0.03575 |  0:05:24s\n",
      "epoch 127| loss: 0.02894 | train_rmsle: 0.0014  | train_mae: 0.11925 | train_rmse: 0.15486 | train_mse: 0.02398 | valid_rmsle: 0.00163 | valid_mae: 0.13048 | valid_rmse: 0.16835 | valid_mse: 0.02834 |  0:05:26s\n",
      "epoch 128| loss: 0.02875 | train_rmsle: 0.00148 | train_mae: 0.11976 | train_rmse: 0.15511 | train_mse: 0.02406 | valid_rmsle: 0.00176 | valid_mae: 0.1324  | valid_rmse: 0.17051 | valid_mse: 0.02908 |  0:05:29s\n",
      "epoch 129| loss: 0.02592 | train_rmsle: 0.00131 | train_mae: 0.1158  | train_rmse: 0.1501  | train_mse: 0.02253 | valid_rmsle: 0.00156 | valid_mae: 0.12828 | valid_rmse: 0.16515 | valid_mse: 0.02728 |  0:05:32s\n",
      "epoch 130| loss: 0.02706 | train_rmsle: 0.00126 | train_mae: 0.11207 | train_rmse: 0.14766 | train_mse: 0.0218  | valid_rmsle: 0.00154 | valid_mae: 0.12642 | valid_rmse: 0.16381 | valid_mse: 0.02683 |  0:05:34s\n",
      "epoch 131| loss: 0.02788 | train_rmsle: 0.0012  | train_mae: 0.1111  | train_rmse: 0.14449 | train_mse: 0.02088 | valid_rmsle: 0.00151 | valid_mae: 0.12462 | valid_rmse: 0.16219 | valid_mse: 0.02631 |  0:05:37s\n",
      "epoch 132| loss: 0.02705 | train_rmsle: 0.00117 | train_mae: 0.10865 | train_rmse: 0.14092 | train_mse: 0.01986 | valid_rmsle: 0.00147 | valid_mae: 0.12099 | valid_rmse: 0.15806 | valid_mse: 0.02498 |  0:05:40s\n",
      "epoch 133| loss: 0.02488 | train_rmsle: 0.00116 | train_mae: 0.11086 | train_rmse: 0.14288 | train_mse: 0.02041 | valid_rmsle: 0.00143 | valid_mae: 0.12395 | valid_rmse: 0.15853 | valid_mse: 0.02513 |  0:05:42s\n",
      "epoch 134| loss: 0.02539 | train_rmsle: 0.00123 | train_mae: 0.11514 | train_rmse: 0.14746 | train_mse: 0.02174 | valid_rmsle: 0.00151 | valid_mae: 0.12708 | valid_rmse: 0.16371 | valid_mse: 0.0268  |  0:05:45s\n",
      "epoch 135| loss: 0.0252  | train_rmsle: 0.00106 | train_mae: 0.10489 | train_rmse: 0.13575 | train_mse: 0.01843 | valid_rmsle: 0.00134 | valid_mae: 0.11838 | valid_rmse: 0.15278 | valid_mse: 0.02334 |  0:05:48s\n",
      "epoch 136| loss: 0.02397 | train_rmsle: 0.00103 | train_mae: 0.10267 | train_rmse: 0.13385 | train_mse: 0.01792 | valid_rmsle: 0.00126 | valid_mae: 0.11356 | valid_rmse: 0.14774 | valid_mse: 0.02183 |  0:05:50s\n",
      "epoch 137| loss: 0.02424 | train_rmsle: 0.0012  | train_mae: 0.11302 | train_rmse: 0.14593 | train_mse: 0.02129 | valid_rmsle: 0.00148 | valid_mae: 0.12628 | valid_rmse: 0.16154 | valid_mse: 0.0261  |  0:05:52s\n",
      "epoch 138| loss: 0.02327 | train_rmsle: 0.00131 | train_mae: 0.12013 | train_rmse: 0.15303 | train_mse: 0.02342 | valid_rmsle: 0.00153 | valid_mae: 0.1325  | valid_rmse: 0.16559 | valid_mse: 0.02742 |  0:05:55s\n",
      "epoch 139| loss: 0.02408 | train_rmsle: 0.00097 | train_mae: 0.09872 | train_rmse: 0.12848 | train_mse: 0.01651 | valid_rmsle: 0.00119 | valid_mae: 0.10976 | valid_rmse: 0.14326 | valid_mse: 0.02052 |  0:05:57s\n",
      "epoch 140| loss: 0.02078 | train_rmsle: 0.00113 | train_mae: 0.10953 | train_rmse: 0.13984 | train_mse: 0.01956 | valid_rmsle: 0.0013  | valid_mae: 0.11921 | valid_rmse: 0.1508  | valid_mse: 0.02274 |  0:05:59s\n",
      "epoch 141| loss: 0.02124 | train_rmsle: 0.0009  | train_mae: 0.09685 | train_rmse: 0.12502 | train_mse: 0.01563 | valid_rmsle: 0.00111 | valid_mae: 0.10864 | valid_rmse: 0.13893 | valid_mse: 0.0193  |  0:06:02s\n",
      "epoch 142| loss: 0.01918 | train_rmsle: 0.00089 | train_mae: 0.09621 | train_rmse: 0.12392 | train_mse: 0.01536 | valid_rmsle: 0.0011  | valid_mae: 0.10747 | valid_rmse: 0.13806 | valid_mse: 0.01906 |  0:06:05s\n",
      "epoch 143| loss: 0.01866 | train_rmsle: 0.00084 | train_mae: 0.0927  | train_rmse: 0.11994 | train_mse: 0.01438 | valid_rmsle: 0.00104 | valid_mae: 0.10347 | valid_rmse: 0.13407 | valid_mse: 0.01798 |  0:06:07s\n",
      "epoch 144| loss: 0.01959 | train_rmsle: 0.00094 | train_mae: 0.09695 | train_rmse: 0.12472 | train_mse: 0.01556 | valid_rmsle: 0.00114 | valid_mae: 0.10737 | valid_rmse: 0.14036 | valid_mse: 0.0197  |  0:06:10s\n",
      "epoch 145| loss: 0.01957 | train_rmsle: 0.0011  | train_mae: 0.10361 | train_rmse: 0.13217 | train_mse: 0.01747 | valid_rmsle: 0.00131 | valid_mae: 0.11473 | valid_rmse: 0.14938 | valid_mse: 0.02231 |  0:06:12s\n",
      "epoch 146| loss: 0.01741 | train_rmsle: 0.00092 | train_mae: 0.10073 | train_rmse: 0.12742 | train_mse: 0.01624 | valid_rmsle: 0.00115 | valid_mae: 0.11124 | valid_rmse: 0.14563 | valid_mse: 0.02121 |  0:06:15s\n",
      "epoch 147| loss: 0.01737 | train_rmsle: 0.00073 | train_mae: 0.08655 | train_rmse: 0.11263 | train_mse: 0.01269 | valid_rmsle: 0.00095 | valid_mae: 0.09769 | valid_rmse: 0.12976 | valid_mse: 0.01684 |  0:06:17s\n",
      "epoch 148| loss: 0.01815 | train_rmsle: 0.00076 | train_mae: 0.08753 | train_rmse: 0.11409 | train_mse: 0.01302 | valid_rmsle: 0.00095 | valid_mae: 0.09796 | valid_rmse: 0.1278  | valid_mse: 0.01633 |  0:06:19s\n",
      "epoch 149| loss: 0.01657 | train_rmsle: 0.00091 | train_mae: 0.09687 | train_rmse: 0.12308 | train_mse: 0.01515 | valid_rmsle: 0.00108 | valid_mae: 0.10594 | valid_rmse: 0.13522 | valid_mse: 0.01828 |  0:06:22s\n",
      "epoch 150| loss: 0.01732 | train_rmsle: 0.00074 | train_mae: 0.08568 | train_rmse: 0.11071 | train_mse: 0.01226 | valid_rmsle: 0.00091 | valid_mae: 0.09577 | valid_rmse: 0.12385 | valid_mse: 0.01534 |  0:06:24s\n",
      "epoch 151| loss: 0.01899 | train_rmsle: 0.00079 | train_mae: 0.09244 | train_rmse: 0.11824 | train_mse: 0.01398 | valid_rmsle: 0.00097 | valid_mae: 0.10233 | valid_rmse: 0.13191 | valid_mse: 0.0174  |  0:06:27s\n",
      "epoch 152| loss: 0.01913 | train_rmsle: 0.00088 | train_mae: 0.09529 | train_rmse: 0.12158 | train_mse: 0.01478 | valid_rmsle: 0.00106 | valid_mae: 0.10459 | valid_rmse: 0.13419 | valid_mse: 0.01801 |  0:06:29s\n",
      "epoch 153| loss: 0.02564 | train_rmsle: 0.00131 | train_mae: 0.12397 | train_rmse: 0.15707 | train_mse: 0.02467 | valid_rmsle: 0.00156 | valid_mae: 0.13307 | valid_rmse: 0.16955 | valid_mse: 0.02875 |  0:06:32s\n",
      "epoch 154| loss: 0.02113 | train_rmsle: 0.00076 | train_mae: 0.08919 | train_rmse: 0.11532 | train_mse: 0.0133  | valid_rmsle: 0.00092 | valid_mae: 0.09789 | valid_rmse: 0.12637 | valid_mse: 0.01597 |  0:06:34s\n",
      "epoch 155| loss: 0.01841 | train_rmsle: 0.00083 | train_mae: 0.09244 | train_rmse: 0.11856 | train_mse: 0.01406 | valid_rmsle: 0.00098 | valid_mae: 0.1016  | valid_rmse: 0.13002 | valid_mse: 0.01691 |  0:06:37s\n",
      "epoch 156| loss: 0.01723 | train_rmsle: 0.00069 | train_mae: 0.08485 | train_rmse: 0.10985 | train_mse: 0.01207 | valid_rmsle: 0.00085 | valid_mae: 0.09442 | valid_rmse: 0.12138 | valid_mse: 0.01473 |  0:06:40s\n",
      "epoch 157| loss: 0.01839 | train_rmsle: 0.00095 | train_mae: 0.09967 | train_rmse: 0.12698 | train_mse: 0.01613 | valid_rmsle: 0.00106 | valid_mae: 0.1072  | valid_rmse: 0.13594 | valid_mse: 0.01848 |  0:06:42s\n",
      "epoch 158| loss: 0.02003 | train_rmsle: 0.00099 | train_mae: 0.09797 | train_rmse: 0.12711 | train_mse: 0.01616 | valid_rmsle: 0.00114 | valid_mae: 0.1089  | valid_rmse: 0.13795 | valid_mse: 0.01903 |  0:06:45s\n",
      "epoch 159| loss: 0.02186 | train_rmsle: 0.00241 | train_mae: 0.1519  | train_rmse: 0.18774 | train_mse: 0.03525 | valid_rmsle: 0.00244 | valid_mae: 0.15637 | valid_rmse: 0.19212 | valid_mse: 0.03691 |  0:06:47s\n",
      "epoch 160| loss: 0.02147 | train_rmsle: 0.0009  | train_mae: 0.09511 | train_rmse: 0.12219 | train_mse: 0.01493 | valid_rmsle: 0.00102 | valid_mae: 0.10444 | valid_rmse: 0.13215 | valid_mse: 0.01746 |  0:06:50s\n",
      "epoch 161| loss: 0.0207  | train_rmsle: 0.00118 | train_mae: 0.11553 | train_rmse: 0.14502 | train_mse: 0.02103 | valid_rmsle: 0.00133 | valid_mae: 0.12516 | valid_rmse: 0.15528 | valid_mse: 0.02411 |  0:06:53s\n",
      "epoch 162| loss: 0.01773 | train_rmsle: 0.00084 | train_mae: 0.09611 | train_rmse: 0.1215  | train_mse: 0.01476 | valid_rmsle: 0.00099 | valid_mae: 0.10588 | valid_rmse: 0.13282 | valid_mse: 0.01764 |  0:06:55s\n",
      "epoch 163| loss: 0.01774 | train_rmsle: 0.00093 | train_mae: 0.09315 | train_rmse: 0.12019 | train_mse: 0.01445 | valid_rmsle: 0.00113 | valid_mae: 0.10511 | valid_rmse: 0.1353  | valid_mse: 0.01831 |  0:06:58s\n",
      "epoch 164| loss: 0.01781 | train_rmsle: 0.00075 | train_mae: 0.08912 | train_rmse: 0.113   | train_mse: 0.01277 | valid_rmsle: 0.0009  | valid_mae: 0.09899 | valid_rmse: 0.12543 | valid_mse: 0.01573 |  0:07:00s\n",
      "epoch 165| loss: 0.0172  | train_rmsle: 0.0007  | train_mae: 0.08239 | train_rmse: 0.10607 | train_mse: 0.01125 | valid_rmsle: 0.00085 | valid_mae: 0.09341 | valid_rmse: 0.11971 | valid_mse: 0.01433 |  0:07:03s\n",
      "epoch 166| loss: 0.01457 | train_rmsle: 0.00059 | train_mae: 0.07789 | train_rmse: 0.09975 | train_mse: 0.00995 | valid_rmsle: 0.00077 | valid_mae: 0.09026 | valid_rmse: 0.1157  | valid_mse: 0.01339 |  0:07:05s\n",
      "epoch 167| loss: 0.01697 | train_rmsle: 0.00056 | train_mae: 0.07525 | train_rmse: 0.09697 | train_mse: 0.0094  | valid_rmsle: 0.00074 | valid_mae: 0.08758 | valid_rmse: 0.11286 | valid_mse: 0.01274 |  0:07:08s\n",
      "epoch 168| loss: 0.01779 | train_rmsle: 0.00056 | train_mae: 0.0753  | train_rmse: 0.09703 | train_mse: 0.00942 | valid_rmsle: 0.00074 | valid_mae: 0.08751 | valid_rmse: 0.11265 | valid_mse: 0.01269 |  0:07:10s\n",
      "epoch 169| loss: 0.01417 | train_rmsle: 0.00054 | train_mae: 0.07387 | train_rmse: 0.09525 | train_mse: 0.00907 | valid_rmsle: 0.00071 | valid_mae: 0.08513 | valid_rmse: 0.11005 | valid_mse: 0.01211 |  0:07:13s\n",
      "epoch 170| loss: 0.01376 | train_rmsle: 0.00059 | train_mae: 0.08004 | train_rmse: 0.10174 | train_mse: 0.01035 | valid_rmsle: 0.00075 | valid_mae: 0.09049 | valid_rmse: 0.11505 | valid_mse: 0.01324 |  0:07:15s\n",
      "epoch 171| loss: 0.01409 | train_rmsle: 0.00051 | train_mae: 0.07272 | train_rmse: 0.09361 | train_mse: 0.00876 | valid_rmsle: 0.00067 | valid_mae: 0.08367 | valid_rmse: 0.10784 | valid_mse: 0.01163 |  0:07:17s\n",
      "epoch 172| loss: 0.01387 | train_rmsle: 0.00058 | train_mae: 0.07672 | train_rmse: 0.09833 | train_mse: 0.00967 | valid_rmsle: 0.00074 | valid_mae: 0.08749 | valid_rmse: 0.11249 | valid_mse: 0.01265 |  0:07:19s\n",
      "epoch 173| loss: 0.01434 | train_rmsle: 0.00094 | train_mae: 0.10039 | train_rmse: 0.1227  | train_mse: 0.01505 | valid_rmsle: 0.00107 | valid_mae: 0.10772 | valid_rmse: 0.13249 | valid_mse: 0.01755 |  0:07:22s\n",
      "epoch 174| loss: 0.01278 | train_rmsle: 0.00047 | train_mae: 0.06877 | train_rmse: 0.08866 | train_mse: 0.00786 | valid_rmsle: 0.00062 | valid_mae: 0.0799  | valid_rmse: 0.10286 | valid_mse: 0.01058 |  0:07:24s\n",
      "epoch 175| loss: 0.01288 | train_rmsle: 0.00048 | train_mae: 0.07059 | train_rmse: 0.09034 | train_mse: 0.00816 | valid_rmsle: 0.00062 | valid_mae: 0.08125 | valid_rmse: 0.10385 | valid_mse: 0.01078 |  0:07:27s\n",
      "epoch 176| loss: 0.01385 | train_rmsle: 0.00054 | train_mae: 0.07476 | train_rmse: 0.0954  | train_mse: 0.0091  | valid_rmsle: 0.00068 | valid_mae: 0.08464 | valid_rmse: 0.10701 | valid_mse: 0.01145 |  0:07:30s\n",
      "epoch 177| loss: 0.01358 | train_rmsle: 0.00054 | train_mae: 0.07273 | train_rmse: 0.09411 | train_mse: 0.00886 | valid_rmsle: 0.00069 | valid_mae: 0.08298 | valid_rmse: 0.10756 | valid_mse: 0.01157 |  0:07:32s\n",
      "epoch 178| loss: 0.01297 | train_rmsle: 0.00045 | train_mae: 0.06827 | train_rmse: 0.08792 | train_mse: 0.00773 | valid_rmsle: 0.00059 | valid_mae: 0.07789 | valid_rmse: 0.10028 | valid_mse: 0.01006 |  0:07:35s\n",
      "epoch 179| loss: 0.013   | train_rmsle: 0.00071 | train_mae: 0.0782  | train_rmse: 0.10207 | train_mse: 0.01042 | valid_rmsle: 0.00082 | valid_mae: 0.0863  | valid_rmse: 0.11292 | valid_mse: 0.01275 |  0:07:37s\n",
      "epoch 180| loss: 0.01441 | train_rmsle: 0.00048 | train_mae: 0.0713  | train_rmse: 0.09083 | train_mse: 0.00825 | valid_rmsle: 0.00061 | valid_mae: 0.08199 | valid_rmse: 0.10374 | valid_mse: 0.01076 |  0:07:40s\n",
      "epoch 181| loss: 0.01247 | train_rmsle: 0.00046 | train_mae: 0.06933 | train_rmse: 0.08829 | train_mse: 0.0078  | valid_rmsle: 0.0006  | valid_mae: 0.07939 | valid_rmse: 0.10159 | valid_mse: 0.01032 |  0:07:43s\n",
      "epoch 182| loss: 0.01189 | train_rmsle: 0.00071 | train_mae: 0.08445 | train_rmse: 0.10521 | train_mse: 0.01107 | valid_rmsle: 0.00083 | valid_mae: 0.09253 | valid_rmse: 0.11595 | valid_mse: 0.01345 |  0:07:45s\n",
      "epoch 183| loss: 0.01216 | train_rmsle: 0.00049 | train_mae: 0.07208 | train_rmse: 0.09393 | train_mse: 0.00882 | valid_rmsle: 0.00065 | valid_mae: 0.08394 | valid_rmse: 0.10859 | valid_mse: 0.01179 |  0:07:48s\n",
      "epoch 184| loss: 0.01256 | train_rmsle: 0.00051 | train_mae: 0.07519 | train_rmse: 0.09557 | train_mse: 0.00913 | valid_rmsle: 0.00065 | valid_mae: 0.08573 | valid_rmse: 0.10818 | valid_mse: 0.0117  |  0:07:50s\n",
      "epoch 185| loss: 0.01413 | train_rmsle: 0.00049 | train_mae: 0.07212 | train_rmse: 0.09159 | train_mse: 0.00839 | valid_rmsle: 0.00063 | valid_mae: 0.08259 | valid_rmse: 0.10467 | valid_mse: 0.01096 |  0:07:53s\n",
      "epoch 186| loss: 0.01246 | train_rmsle: 0.00044 | train_mae: 0.06806 | train_rmse: 0.08736 | train_mse: 0.00763 | valid_rmsle: 0.00058 | valid_mae: 0.07951 | valid_rmse: 0.10133 | valid_mse: 0.01027 |  0:07:55s\n",
      "epoch 187| loss: 0.01633 | train_rmsle: 0.00101 | train_mae: 0.11436 | train_rmse: 0.13533 | train_mse: 0.01831 | valid_rmsle: 0.00114 | valid_mae: 0.11899 | valid_rmse: 0.14416 | valid_mse: 0.02078 |  0:07:58s\n",
      "epoch 188| loss: 0.01537 | train_rmsle: 0.00042 | train_mae: 0.0649  | train_rmse: 0.08381 | train_mse: 0.00702 | valid_rmsle: 0.00056 | valid_mae: 0.07461 | valid_rmse: 0.09684 | valid_mse: 0.00938 |  0:08:00s\n",
      "epoch 189| loss: 0.0117  | train_rmsle: 0.0004  | train_mae: 0.06393 | train_rmse: 0.08237 | train_mse: 0.00678 | valid_rmsle: 0.00054 | valid_mae: 0.07517 | valid_rmse: 0.09631 | valid_mse: 0.00928 |  0:08:03s\n",
      "epoch 190| loss: 0.01077 | train_rmsle: 0.00122 | train_mae: 0.10867 | train_rmse: 0.13239 | train_mse: 0.01753 | valid_rmsle: 0.0013  | valid_mae: 0.11385 | valid_rmse: 0.1384  | valid_mse: 0.01915 |  0:08:05s\n",
      "epoch 191| loss: 0.01207 | train_rmsle: 0.00047 | train_mae: 0.06589 | train_rmse: 0.0859  | train_mse: 0.00738 | valid_rmsle: 0.00059 | valid_mae: 0.07575 | valid_rmse: 0.09844 | valid_mse: 0.00969 |  0:08:07s\n",
      "epoch 192| loss: 0.01386 | train_rmsle: 0.00138 | train_mae: 0.10053 | train_rmse: 0.1427  | train_mse: 0.02036 | valid_rmsle: 0.00148 | valid_mae: 0.10867 | valid_rmse: 0.15258 | valid_mse: 0.02328 |  0:08:10s\n",
      "epoch 193| loss: 0.01495 | train_rmsle: 0.0007  | train_mae: 0.08562 | train_rmse: 0.11067 | train_mse: 0.01225 | valid_rmsle: 0.00084 | valid_mae: 0.09514 | valid_rmse: 0.12276 | valid_mse: 0.01507 |  0:08:12s\n",
      "epoch 194| loss: 0.01405 | train_rmsle: 0.00084 | train_mae: 0.09858 | train_rmse: 0.1237  | train_mse: 0.0153  | valid_rmsle: 0.00094 | valid_mae: 0.10521 | valid_rmse: 0.13213 | valid_mse: 0.01746 |  0:08:14s\n",
      "epoch 195| loss: 0.013   | train_rmsle: 0.00069 | train_mae: 0.08989 | train_rmse: 0.11487 | train_mse: 0.01319 | valid_rmsle: 0.00081 | valid_mae: 0.09813 | valid_rmse: 0.12494 | valid_mse: 0.01561 |  0:08:17s\n",
      "epoch 196| loss: 0.01355 | train_rmsle: 0.00071 | train_mae: 0.08601 | train_rmse: 0.10848 | train_mse: 0.01177 | valid_rmsle: 0.00082 | valid_mae: 0.09367 | valid_rmse: 0.11911 | valid_mse: 0.01419 |  0:08:19s\n",
      "epoch 197| loss: 0.01175 | train_rmsle: 0.00043 | train_mae: 0.06524 | train_rmse: 0.08464 | train_mse: 0.00716 | valid_rmsle: 0.00056 | valid_mae: 0.0764  | valid_rmse: 0.0979  | valid_mse: 0.00959 |  0:08:22s\n",
      "epoch 198| loss: 0.0117  | train_rmsle: 0.00045 | train_mae: 0.06882 | train_rmse: 0.08792 | train_mse: 0.00773 | valid_rmsle: 0.00057 | valid_mae: 0.07936 | valid_rmse: 0.09993 | valid_mse: 0.00999 |  0:08:24s\n",
      "epoch 199| loss: 0.01177 | train_rmsle: 0.0004  | train_mae: 0.06392 | train_rmse: 0.08207 | train_mse: 0.00674 | valid_rmsle: 0.00052 | valid_mae: 0.07468 | valid_rmse: 0.09495 | valid_mse: 0.00902 |  0:08:27s\n",
      "epoch 200| loss: 0.01261 | train_rmsle: 0.00044 | train_mae: 0.06914 | train_rmse: 0.08719 | train_mse: 0.0076  | valid_rmsle: 0.00055 | valid_mae: 0.07735 | valid_rmse: 0.09787 | valid_mse: 0.00958 |  0:08:30s\n",
      "epoch 201| loss: 0.01169 | train_rmsle: 0.00045 | train_mae: 0.07143 | train_rmse: 0.0898  | train_mse: 0.00806 | valid_rmsle: 0.00057 | valid_mae: 0.07995 | valid_rmse: 0.10098 | valid_mse: 0.0102  |  0:08:32s\n",
      "epoch 202| loss: 0.0123  | train_rmsle: 0.00095 | train_mae: 0.10739 | train_rmse: 0.12768 | train_mse: 0.0163  | valid_rmsle: 0.00106 | valid_mae: 0.11269 | valid_rmse: 0.13523 | valid_mse: 0.01829 |  0:08:34s\n",
      "epoch 203| loss: 0.01315 | train_rmsle: 0.00045 | train_mae: 0.06937 | train_rmse: 0.08812 | train_mse: 0.00777 | valid_rmsle: 0.00057 | valid_mae: 0.07716 | valid_rmse: 0.10004 | valid_mse: 0.01001 |  0:08:37s\n",
      "epoch 204| loss: 0.01308 | train_rmsle: 0.00038 | train_mae: 0.06136 | train_rmse: 0.07883 | train_mse: 0.00621 | valid_rmsle: 0.00049 | valid_mae: 0.07024 | valid_rmse: 0.09128 | valid_mse: 0.00833 |  0:08:39s\n",
      "epoch 205| loss: 0.01226 | train_rmsle: 0.00045 | train_mae: 0.06327 | train_rmse: 0.08415 | train_mse: 0.00708 | valid_rmsle: 0.00053 | valid_mae: 0.07214 | valid_rmse: 0.09383 | valid_mse: 0.0088  |  0:08:41s\n",
      "epoch 206| loss: 0.01242 | train_rmsle: 0.0005  | train_mae: 0.06961 | train_rmse: 0.08911 | train_mse: 0.00794 | valid_rmsle: 0.00061 | valid_mae: 0.07715 | valid_rmse: 0.1002  | valid_mse: 0.01004 |  0:08:44s\n",
      "epoch 207| loss: 0.01304 | train_rmsle: 0.00064 | train_mae: 0.08153 | train_rmse: 0.10042 | train_mse: 0.01009 | valid_rmsle: 0.00075 | valid_mae: 0.0889  | valid_rmse: 0.10997 | valid_mse: 0.01209 |  0:08:46s\n",
      "epoch 208| loss: 0.0144  | train_rmsle: 0.00033 | train_mae: 0.05802 | train_rmse: 0.07444 | train_mse: 0.00554 | valid_rmsle: 0.00045 | valid_mae: 0.06789 | valid_rmse: 0.08744 | valid_mse: 0.00765 |  0:08:49s\n",
      "epoch 209| loss: 0.01155 | train_rmsle: 0.00032 | train_mae: 0.05783 | train_rmse: 0.07384 | train_mse: 0.00545 | valid_rmsle: 0.00044 | valid_mae: 0.06705 | valid_rmse: 0.08667 | valid_mse: 0.00751 |  0:08:52s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 209 and best_valid_mse = 0.00751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008448922782351981 RMSE: 0.0919180220759345 R2: 0.9625998743694123 MAE: 0.06885722591817509\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_7_0.01_210.pt.zip\n",
      "New best model: 512_8_7_0.01_210 with r2: 0.9625998743694123\n",
      "[33/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.39831 | train_rmsle: 0.86702 | train_mae: 2.58602 | train_rmse: 2.63107 | train_mse: 6.92252 | valid_rmsle: 0.87081 | valid_mae: 2.59352 | valid_rmse: 2.63752 | valid_mse: 6.95654 |  0:00:02s\n",
      "epoch 1  | loss: 2.79417 | train_rmsle: 0.33039 | train_mae: 1.85282 | train_rmse: 1.9151  | train_mse: 3.66759 | valid_rmsle: 0.33152 | valid_mae: 1.85823 | valid_rmse: 1.9196  | valid_mse: 3.68487 |  0:00:05s\n",
      "epoch 2  | loss: 1.68546 | train_rmsle: 0.14234 | train_mae: 1.31002 | train_rmse: 1.39095 | train_mse: 1.93474 | valid_rmsle: 0.14284 | valid_mae: 1.31261 | valid_rmse: 1.3946  | valid_mse: 1.94492 |  0:00:07s\n",
      "epoch 3  | loss: 0.97534 | train_rmsle: 0.03686 | train_mae: 0.69025 | train_rmse: 0.784   | train_mse: 0.61465 | valid_rmsle: 0.03678 | valid_mae: 0.69008 | valid_rmse: 0.78578 | valid_mse: 0.61746 |  0:00:10s\n",
      "epoch 4  | loss: 0.55782 | train_rmsle: 0.02265 | train_mae: 0.53273 | train_rmse: 0.62284 | train_mse: 0.38793 | valid_rmsle: 0.0224  | valid_mae: 0.53451 | valid_rmse: 0.62319 | valid_mse: 0.38837 |  0:00:13s\n",
      "epoch 5  | loss: 0.4022  | train_rmsle: 0.01809 | train_mae: 0.46611 | train_rmse: 0.55427 | train_mse: 0.30721 | valid_rmsle: 0.01774 | valid_mae: 0.4678  | valid_rmse: 0.55338 | valid_mse: 0.30623 |  0:00:15s\n",
      "epoch 6  | loss: 0.34074 | train_rmsle: 0.02227 | train_mae: 0.52819 | train_rmse: 0.61768 | train_mse: 0.38152 | valid_rmsle: 0.022   | valid_mae: 0.52954 | valid_rmse: 0.61804 | valid_mse: 0.38197 |  0:00:18s\n",
      "epoch 7  | loss: 0.31281 | train_rmsle: 0.01748 | train_mae: 0.45588 | train_rmse: 0.5439  | train_mse: 0.29583 | valid_rmsle: 0.01709 | valid_mae: 0.45696 | valid_rmse: 0.54259 | valid_mse: 0.2944  |  0:00:20s\n",
      "epoch 8  | loss: 0.28    | train_rmsle: 0.01647 | train_mae: 0.43727 | train_rmse: 0.52567 | train_mse: 0.27633 | valid_rmsle: 0.01604 | valid_mae: 0.43818 | valid_rmse: 0.52384 | valid_mse: 0.27441 |  0:00:23s\n",
      "epoch 9  | loss: 0.26637 | train_rmsle: 0.01562 | train_mae: 0.41889 | train_rmse: 0.50884 | train_mse: 0.25892 | valid_rmsle: 0.01512 | valid_mae: 0.41959 | valid_rmse: 0.50576 | valid_mse: 0.2558  |  0:00:26s\n",
      "epoch 10 | loss: 0.26164 | train_rmsle: 0.01617 | train_mae: 0.43123 | train_rmse: 0.52008 | train_mse: 0.27048 | valid_rmsle: 0.01565 | valid_mae: 0.43161 | valid_rmse: 0.51686 | valid_mse: 0.26714 |  0:00:28s\n",
      "epoch 11 | loss: 0.25288 | train_rmsle: 0.01583 | train_mae: 0.42392 | train_rmse: 0.51337 | train_mse: 0.26355 | valid_rmsle: 0.0153  | valid_mae: 0.42438 | valid_rmse: 0.50991 | valid_mse: 0.26001 |  0:00:31s\n",
      "epoch 12 | loss: 0.2418  | train_rmsle: 0.01547 | train_mae: 0.41577 | train_rmse: 0.50594 | train_mse: 0.25598 | valid_rmsle: 0.01497 | valid_mae: 0.4157  | valid_rmse: 0.50288 | valid_mse: 0.25289 |  0:00:33s\n",
      "epoch 13 | loss: 0.24466 | train_rmsle: 0.01703 | train_mae: 0.44814 | train_rmse: 0.53644 | train_mse: 0.28777 | valid_rmsle: 0.01669 | valid_mae: 0.44999 | valid_rmse: 0.53606 | valid_mse: 0.28736 |  0:00:36s\n",
      "epoch 14 | loss: 0.24656 | train_rmsle: 0.01798 | train_mae: 0.46475 | train_rmse: 0.55293 | train_mse: 0.30573 | valid_rmsle: 0.01765 | valid_mae: 0.46675 | valid_rmse: 0.55254 | valid_mse: 0.3053  |  0:00:38s\n",
      "epoch 15 | loss: 0.24272 | train_rmsle: 0.01563 | train_mae: 0.42052 | train_rmse: 0.51012 | train_mse: 0.26022 | valid_rmsle: 0.01523 | valid_mae: 0.4229  | valid_rmse: 0.50892 | valid_mse: 0.259   |  0:00:41s\n",
      "epoch 16 | loss: 0.23783 | train_rmsle: 0.01755 | train_mae: 0.45747 | train_rmse: 0.54547 | train_mse: 0.29754 | valid_rmsle: 0.01728 | valid_mae: 0.46008 | valid_rmse: 0.54619 | valid_mse: 0.29833 |  0:00:43s\n",
      "epoch 17 | loss: 0.23596 | train_rmsle: 0.01632 | train_mae: 0.43423 | train_rmse: 0.52321 | train_mse: 0.27375 | valid_rmsle: 0.01595 | valid_mae: 0.43637 | valid_rmse: 0.52252 | valid_mse: 0.27303 |  0:00:45s\n",
      "epoch 18 | loss: 0.23105 | train_rmsle: 0.01594 | train_mae: 0.42727 | train_rmse: 0.51623 | train_mse: 0.2665  | valid_rmsle: 0.01556 | valid_mae: 0.42869 | valid_rmse: 0.51551 | valid_mse: 0.26575 |  0:00:47s\n",
      "epoch 19 | loss: 0.23873 | train_rmsle: 0.01499 | train_mae: 0.40395 | train_rmse: 0.49606 | train_mse: 0.24608 | valid_rmsle: 0.01447 | valid_mae: 0.40388 | valid_rmse: 0.49253 | valid_mse: 0.24259 |  0:00:49s\n",
      "epoch 20 | loss: 0.23323 | train_rmsle: 0.01492 | train_mae: 0.40327 | train_rmse: 0.49485 | train_mse: 0.24488 | valid_rmsle: 0.01458 | valid_mae: 0.40677 | valid_rmse: 0.49463 | valid_mse: 0.24466 |  0:00:51s\n",
      "epoch 21 | loss: 0.23143 | train_rmsle: 0.01588 | train_mae: 0.42537 | train_rmse: 0.51479 | train_mse: 0.26501 | valid_rmsle: 0.01548 | valid_mae: 0.42782 | valid_rmse: 0.51366 | valid_mse: 0.26385 |  0:00:53s\n",
      "epoch 22 | loss: 0.2311  | train_rmsle: 0.01586 | train_mae: 0.42628 | train_rmse: 0.51465 | train_mse: 0.26487 | valid_rmsle: 0.0155  | valid_mae: 0.42791 | valid_rmse: 0.51402 | valid_mse: 0.26422 |  0:00:56s\n",
      "epoch 23 | loss: 0.23317 | train_rmsle: 0.01502 | train_mae: 0.40676 | train_rmse: 0.49705 | train_mse: 0.24706 | valid_rmsle: 0.01459 | valid_mae: 0.40787 | valid_rmse: 0.49549 | valid_mse: 0.24551 |  0:00:59s\n",
      "epoch 24 | loss: 0.23322 | train_rmsle: 0.01455 | train_mae: 0.39318 | train_rmse: 0.48616 | train_mse: 0.23635 | valid_rmsle: 0.01422 | valid_mae: 0.3983  | valid_rmse: 0.48667 | valid_mse: 0.23685 |  0:01:01s\n",
      "epoch 25 | loss: 0.22772 | train_rmsle: 0.01533 | train_mae: 0.41334 | train_rmse: 0.504   | train_mse: 0.25402 | valid_rmsle: 0.01501 | valid_mae: 0.41792 | valid_rmse: 0.50458 | valid_mse: 0.2546  |  0:01:04s\n",
      "epoch 26 | loss: 0.22791 | train_rmsle: 0.01541 | train_mae: 0.41515 | train_rmse: 0.50574 | train_mse: 0.25577 | valid_rmsle: 0.01508 | valid_mae: 0.41803 | valid_rmse: 0.50592 | valid_mse: 0.25595 |  0:01:07s\n",
      "epoch 27 | loss: 0.23602 | train_rmsle: 0.01714 | train_mae: 0.45014 | train_rmse: 0.53869 | train_mse: 0.29019 | valid_rmsle: 0.01719 | valid_mae: 0.45685 | valid_rmse: 0.54432 | valid_mse: 0.29629 |  0:01:09s\n",
      "epoch 28 | loss: 0.22977 | train_rmsle: 0.01455 | train_mae: 0.39109 | train_rmse: 0.48565 | train_mse: 0.23586 | valid_rmsle: 0.01417 | valid_mae: 0.39274 | valid_rmse: 0.48497 | valid_mse: 0.23519 |  0:01:12s\n",
      "epoch 29 | loss: 0.22818 | train_rmsle: 0.01494 | train_mae: 0.40433 | train_rmse: 0.49556 | train_mse: 0.24558 | valid_rmsle: 0.01459 | valid_mae: 0.40678 | valid_rmse: 0.49551 | valid_mse: 0.24553 |  0:01:15s\n",
      "epoch 30 | loss: 0.225   | train_rmsle: 0.01535 | train_mae: 0.41246 | train_rmse: 0.50353 | train_mse: 0.25354 | valid_rmsle: 0.01512 | valid_mae: 0.41686 | valid_rmse: 0.50512 | valid_mse: 0.25514 |  0:01:17s\n",
      "epoch 31 | loss: 0.22473 | train_rmsle: 0.01446 | train_mae: 0.38662 | train_rmse: 0.48307 | train_mse: 0.23336 | valid_rmsle: 0.01393 | valid_mae: 0.38758 | valid_rmse: 0.47941 | valid_mse: 0.22983 |  0:01:20s\n",
      "epoch 32 | loss: 0.22381 | train_rmsle: 0.01446 | train_mae: 0.38815 | train_rmse: 0.48368 | train_mse: 0.23395 | valid_rmsle: 0.01396 | valid_mae: 0.38917 | valid_rmse: 0.48057 | valid_mse: 0.23095 |  0:01:23s\n",
      "epoch 33 | loss: 0.22346 | train_rmsle: 0.01448 | train_mae: 0.39028 | train_rmse: 0.48431 | train_mse: 0.23455 | valid_rmsle: 0.01399 | valid_mae: 0.39028 | valid_rmse: 0.48123 | valid_mse: 0.23158 |  0:01:25s\n",
      "epoch 34 | loss: 0.22986 | train_rmsle: 0.01544 | train_mae: 0.41641 | train_rmse: 0.50669 | train_mse: 0.25674 | valid_rmsle: 0.01506 | valid_mae: 0.4185  | valid_rmse: 0.50601 | valid_mse: 0.25605 |  0:01:28s\n",
      "epoch 35 | loss: 0.22958 | train_rmsle: 0.01465 | train_mae: 0.39147 | train_rmse: 0.487   | train_mse: 0.23717 | valid_rmsle: 0.01421 | valid_mae: 0.39399 | valid_rmse: 0.48531 | valid_mse: 0.23553 |  0:01:31s\n",
      "epoch 36 | loss: 0.22319 | train_rmsle: 0.01438 | train_mae: 0.38123 | train_rmse: 0.47978 | train_mse: 0.23019 | valid_rmsle: 0.01409 | valid_mae: 0.38705 | valid_rmse: 0.4807  | valid_mse: 0.23108 |  0:01:33s\n",
      "epoch 37 | loss: 0.22563 | train_rmsle: 0.01448 | train_mae: 0.3886  | train_rmse: 0.48414 | train_mse: 0.23439 | valid_rmsle: 0.01418 | valid_mae: 0.39427 | valid_rmse: 0.48473 | valid_mse: 0.23496 |  0:01:36s\n",
      "epoch 38 | loss: 0.22237 | train_rmsle: 0.01475 | train_mae: 0.3981  | train_rmse: 0.49116 | train_mse: 0.24124 | valid_rmsle: 0.0144  | valid_mae: 0.39996 | valid_rmse: 0.49089 | valid_mse: 0.24098 |  0:01:39s\n",
      "epoch 39 | loss: 0.2197  | train_rmsle: 0.01447 | train_mae: 0.3873  | train_rmse: 0.48341 | train_mse: 0.23369 | valid_rmsle: 0.01396 | valid_mae: 0.38683 | valid_rmse: 0.48024 | valid_mse: 0.23063 |  0:01:41s\n",
      "epoch 40 | loss: 0.22092 | train_rmsle: 0.01461 | train_mae: 0.3947  | train_rmse: 0.48832 | train_mse: 0.23846 | valid_rmsle: 0.01437 | valid_mae: 0.39939 | valid_rmse: 0.49007 | valid_mse: 0.24017 |  0:01:44s\n",
      "epoch 41 | loss: 0.22154 | train_rmsle: 0.01448 | train_mae: 0.38163 | train_rmse: 0.48096 | train_mse: 0.23132 | valid_rmsle: 0.01391 | valid_mae: 0.38223 | valid_rmse: 0.47714 | valid_mse: 0.22767 |  0:01:47s\n",
      "epoch 42 | loss: 0.22257 | train_rmsle: 0.01446 | train_mae: 0.38553 | train_rmse: 0.4824  | train_mse: 0.23271 | valid_rmsle: 0.01423 | valid_mae: 0.39002 | valid_rmse: 0.48409 | valid_mse: 0.23435 |  0:01:49s\n",
      "epoch 43 | loss: 0.22406 | train_rmsle: 0.01442 | train_mae: 0.38144 | train_rmse: 0.48066 | train_mse: 0.23103 | valid_rmsle: 0.01402 | valid_mae: 0.38273 | valid_rmse: 0.47926 | valid_mse: 0.22969 |  0:01:52s\n",
      "epoch 44 | loss: 0.22203 | train_rmsle: 0.01449 | train_mae: 0.388   | train_rmse: 0.48401 | train_mse: 0.23426 | valid_rmsle: 0.01434 | valid_mae: 0.39409 | valid_rmse: 0.48755 | valid_mse: 0.23771 |  0:01:55s\n",
      "epoch 45 | loss: 0.22265 | train_rmsle: 0.01437 | train_mae: 0.3841  | train_rmse: 0.48091 | train_mse: 0.23128 | valid_rmsle: 0.01405 | valid_mae: 0.38811 | valid_rmse: 0.48109 | valid_mse: 0.23145 |  0:01:57s\n",
      "epoch 46 | loss: 0.22359 | train_rmsle: 0.01464 | train_mae: 0.37764 | train_rmse: 0.482   | train_mse: 0.23232 | valid_rmsle: 0.01438 | valid_mae: 0.38227 | valid_rmse: 0.48374 | valid_mse: 0.234   |  0:02:00s\n",
      "epoch 47 | loss: 0.22226 | train_rmsle: 0.01476 | train_mae: 0.37648 | train_rmse: 0.4827  | train_mse: 0.233   | valid_rmsle: 0.01433 | valid_mae: 0.38093 | valid_rmse: 0.48159 | valid_mse: 0.23193 |  0:02:03s\n",
      "epoch 48 | loss: 0.23538 | train_rmsle: 0.01425 | train_mae: 0.3819  | train_rmse: 0.47884 | train_mse: 0.22929 | valid_rmsle: 0.0138  | valid_mae: 0.38359 | valid_rmse: 0.47718 | valid_mse: 0.2277  |  0:02:05s\n",
      "epoch 49 | loss: 0.2247  | train_rmsle: 0.01414 | train_mae: 0.37987 | train_rmse: 0.47636 | train_mse: 0.22692 | valid_rmsle: 0.01363 | valid_mae: 0.38208 | valid_rmse: 0.47405 | valid_mse: 0.22473 |  0:02:08s\n",
      "epoch 50 | loss: 0.21642 | train_rmsle: 0.01403 | train_mae: 0.38222 | train_rmse: 0.47629 | train_mse: 0.22685 | valid_rmsle: 0.01382 | valid_mae: 0.39113 | valid_rmse: 0.47905 | valid_mse: 0.22949 |  0:02:10s\n",
      "epoch 51 | loss: 0.2176  | train_rmsle: 0.01419 | train_mae: 0.38079 | train_rmse: 0.47763 | train_mse: 0.22813 | valid_rmsle: 0.01385 | valid_mae: 0.38573 | valid_rmse: 0.4778  | valid_mse: 0.2283  |  0:02:12s\n",
      "epoch 52 | loss: 0.2209  | train_rmsle: 0.01405 | train_mae: 0.37912 | train_rmse: 0.47504 | train_mse: 0.22566 | valid_rmsle: 0.01376 | valid_mae: 0.38631 | valid_rmse: 0.47658 | valid_mse: 0.22713 |  0:02:14s\n",
      "epoch 53 | loss: 0.21516 | train_rmsle: 0.01403 | train_mae: 0.37604 | train_rmse: 0.47319 | train_mse: 0.22391 | valid_rmsle: 0.01371 | valid_mae: 0.38101 | valid_rmse: 0.47391 | valid_mse: 0.22459 |  0:02:17s\n",
      "epoch 54 | loss: 0.2174  | train_rmsle: 0.01405 | train_mae: 0.37611 | train_rmse: 0.47396 | train_mse: 0.22464 | valid_rmsle: 0.01392 | valid_mae: 0.38472 | valid_rmse: 0.47819 | valid_mse: 0.22866 |  0:02:20s\n",
      "epoch 55 | loss: 0.21691 | train_rmsle: 0.01443 | train_mae: 0.37878 | train_rmse: 0.47911 | train_mse: 0.22955 | valid_rmsle: 0.01424 | valid_mae: 0.38787 | valid_rmse: 0.48308 | valid_mse: 0.23336 |  0:02:22s\n",
      "epoch 56 | loss: 0.2165  | train_rmsle: 0.0141  | train_mae: 0.3784  | train_rmse: 0.47553 | train_mse: 0.22613 | valid_rmsle: 0.0141  | valid_mae: 0.38738 | valid_rmse: 0.4818  | valid_mse: 0.23213 |  0:02:25s\n",
      "epoch 57 | loss: 0.21585 | train_rmsle: 0.01552 | train_mae: 0.37856 | train_rmse: 0.49376 | train_mse: 0.2438  | valid_rmsle: 0.01499 | valid_mae: 0.38628 | valid_rmse: 0.49166 | valid_mse: 0.24173 |  0:02:28s\n",
      "epoch 58 | loss: 0.22204 | train_rmsle: 0.01405 | train_mae: 0.37304 | train_rmse: 0.47267 | train_mse: 0.22342 | valid_rmsle: 0.0139  | valid_mae: 0.38014 | valid_rmse: 0.47557 | valid_mse: 0.22616 |  0:02:30s\n",
      "epoch 59 | loss: 0.2144  | train_rmsle: 0.01405 | train_mae: 0.38099 | train_rmse: 0.47591 | train_mse: 0.22649 | valid_rmsle: 0.01402 | valid_mae: 0.38707 | valid_rmse: 0.47939 | valid_mse: 0.22981 |  0:02:33s\n",
      "epoch 60 | loss: 0.21427 | train_rmsle: 0.01411 | train_mae: 0.37329 | train_rmse: 0.47367 | train_mse: 0.22437 | valid_rmsle: 0.01374 | valid_mae: 0.38132 | valid_rmse: 0.47329 | valid_mse: 0.224   |  0:02:35s\n",
      "epoch 61 | loss: 0.21575 | train_rmsle: 0.01412 | train_mae: 0.38295 | train_rmse: 0.478   | train_mse: 0.22849 | valid_rmsle: 0.01372 | valid_mae: 0.38564 | valid_rmse: 0.47661 | valid_mse: 0.22716 |  0:02:38s\n",
      "epoch 62 | loss: 0.21536 | train_rmsle: 0.01402 | train_mae: 0.37365 | train_rmse: 0.47282 | train_mse: 0.22356 | valid_rmsle: 0.01373 | valid_mae: 0.38061 | valid_rmse: 0.47394 | valid_mse: 0.22462 |  0:02:40s\n",
      "epoch 63 | loss: 0.21726 | train_rmsle: 0.01411 | train_mae: 0.38575 | train_rmse: 0.47889 | train_mse: 0.22934 | valid_rmsle: 0.01385 | valid_mae: 0.39093 | valid_rmse: 0.48164 | valid_mse: 0.23198 |  0:02:42s\n",
      "epoch 64 | loss: 0.21318 | train_rmsle: 0.01398 | train_mae: 0.37296 | train_rmse: 0.4723  | train_mse: 0.22307 | valid_rmsle: 0.01361 | valid_mae: 0.37695 | valid_rmse: 0.47184 | valid_mse: 0.22263 |  0:02:45s\n",
      "epoch 65 | loss: 0.21317 | train_rmsle: 0.01385 | train_mae: 0.37986 | train_rmse: 0.47339 | train_mse: 0.2241  | valid_rmsle: 0.01351 | valid_mae: 0.38287 | valid_rmse: 0.47314 | valid_mse: 0.22387 |  0:02:47s\n",
      "epoch 66 | loss: 0.21312 | train_rmsle: 0.01402 | train_mae: 0.38682 | train_rmse: 0.47812 | train_mse: 0.2286  | valid_rmsle: 0.0138  | valid_mae: 0.39097 | valid_rmse: 0.47999 | valid_mse: 0.23039 |  0:02:50s\n",
      "epoch 67 | loss: 0.21007 | train_rmsle: 0.0139  | train_mae: 0.3699  | train_rmse: 0.46952 | train_mse: 0.22045 | valid_rmsle: 0.01364 | valid_mae: 0.37571 | valid_rmse: 0.47083 | valid_mse: 0.22168 |  0:02:53s\n",
      "epoch 68 | loss: 0.21085 | train_rmsle: 0.01376 | train_mae: 0.37693 | train_rmse: 0.47074 | train_mse: 0.2216  | valid_rmsle: 0.01362 | valid_mae: 0.38504 | valid_rmse: 0.47403 | valid_mse: 0.2247  |  0:02:55s\n",
      "epoch 69 | loss: 0.2116  | train_rmsle: 0.01375 | train_mae: 0.37125 | train_rmse: 0.46828 | train_mse: 0.21928 | valid_rmsle: 0.01352 | valid_mae: 0.37693 | valid_rmse: 0.46991 | valid_mse: 0.22082 |  0:02:58s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.22082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2197345513237125 RMSE: 0.46875852133450596 R2: 0.027319809094059955 MAE: 0.36835769197633633\n",
      "=====================================\n",
      "[34/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.39831 | train_rmsle: 0.86702 | train_mae: 2.58602 | train_rmse: 2.63107 | train_mse: 6.92252 | valid_rmsle: 0.87081 | valid_mae: 2.59352 | valid_rmse: 2.63752 | valid_mse: 6.95654 |  0:00:02s\n",
      "epoch 1  | loss: 2.79417 | train_rmsle: 0.33039 | train_mae: 1.85282 | train_rmse: 1.9151  | train_mse: 3.66759 | valid_rmsle: 0.33152 | valid_mae: 1.85823 | valid_rmse: 1.9196  | valid_mse: 3.68487 |  0:00:05s\n",
      "epoch 2  | loss: 1.68546 | train_rmsle: 0.14234 | train_mae: 1.31002 | train_rmse: 1.39095 | train_mse: 1.93474 | valid_rmsle: 0.14284 | valid_mae: 1.31261 | valid_rmse: 1.3946  | valid_mse: 1.94492 |  0:00:08s\n",
      "epoch 3  | loss: 0.97534 | train_rmsle: 0.03686 | train_mae: 0.69025 | train_rmse: 0.784   | train_mse: 0.61465 | valid_rmsle: 0.03678 | valid_mae: 0.69008 | valid_rmse: 0.78578 | valid_mse: 0.61746 |  0:00:10s\n",
      "epoch 4  | loss: 0.55782 | train_rmsle: 0.02265 | train_mae: 0.53273 | train_rmse: 0.62284 | train_mse: 0.38793 | valid_rmsle: 0.0224  | valid_mae: 0.53451 | valid_rmse: 0.62319 | valid_mse: 0.38837 |  0:00:13s\n",
      "epoch 5  | loss: 0.4022  | train_rmsle: 0.01809 | train_mae: 0.46611 | train_rmse: 0.55427 | train_mse: 0.30721 | valid_rmsle: 0.01774 | valid_mae: 0.4678  | valid_rmse: 0.55338 | valid_mse: 0.30623 |  0:00:16s\n",
      "epoch 6  | loss: 0.34074 | train_rmsle: 0.02227 | train_mae: 0.52819 | train_rmse: 0.61768 | train_mse: 0.38152 | valid_rmsle: 0.022   | valid_mae: 0.52954 | valid_rmse: 0.61804 | valid_mse: 0.38197 |  0:00:19s\n",
      "epoch 7  | loss: 0.31281 | train_rmsle: 0.01748 | train_mae: 0.45588 | train_rmse: 0.5439  | train_mse: 0.29583 | valid_rmsle: 0.01709 | valid_mae: 0.45696 | valid_rmse: 0.54259 | valid_mse: 0.2944  |  0:00:21s\n",
      "epoch 8  | loss: 0.28    | train_rmsle: 0.01647 | train_mae: 0.43727 | train_rmse: 0.52567 | train_mse: 0.27633 | valid_rmsle: 0.01604 | valid_mae: 0.43818 | valid_rmse: 0.52384 | valid_mse: 0.27441 |  0:00:24s\n",
      "epoch 9  | loss: 0.26637 | train_rmsle: 0.01562 | train_mae: 0.41889 | train_rmse: 0.50884 | train_mse: 0.25892 | valid_rmsle: 0.01512 | valid_mae: 0.41959 | valid_rmse: 0.50576 | valid_mse: 0.2558  |  0:00:27s\n",
      "epoch 10 | loss: 0.26164 | train_rmsle: 0.01617 | train_mae: 0.43123 | train_rmse: 0.52008 | train_mse: 0.27048 | valid_rmsle: 0.01565 | valid_mae: 0.43161 | valid_rmse: 0.51686 | valid_mse: 0.26714 |  0:00:29s\n",
      "epoch 11 | loss: 0.25288 | train_rmsle: 0.01583 | train_mae: 0.42392 | train_rmse: 0.51337 | train_mse: 0.26355 | valid_rmsle: 0.0153  | valid_mae: 0.42438 | valid_rmse: 0.50991 | valid_mse: 0.26001 |  0:00:32s\n",
      "epoch 12 | loss: 0.2418  | train_rmsle: 0.01547 | train_mae: 0.41577 | train_rmse: 0.50594 | train_mse: 0.25598 | valid_rmsle: 0.01497 | valid_mae: 0.4157  | valid_rmse: 0.50288 | valid_mse: 0.25289 |  0:00:35s\n",
      "epoch 13 | loss: 0.24466 | train_rmsle: 0.01703 | train_mae: 0.44814 | train_rmse: 0.53644 | train_mse: 0.28777 | valid_rmsle: 0.01669 | valid_mae: 0.44999 | valid_rmse: 0.53606 | valid_mse: 0.28736 |  0:00:38s\n",
      "epoch 14 | loss: 0.24656 | train_rmsle: 0.01798 | train_mae: 0.46475 | train_rmse: 0.55293 | train_mse: 0.30573 | valid_rmsle: 0.01765 | valid_mae: 0.46675 | valid_rmse: 0.55254 | valid_mse: 0.3053  |  0:00:40s\n",
      "epoch 15 | loss: 0.24272 | train_rmsle: 0.01563 | train_mae: 0.42052 | train_rmse: 0.51012 | train_mse: 0.26022 | valid_rmsle: 0.01523 | valid_mae: 0.4229  | valid_rmse: 0.50892 | valid_mse: 0.259   |  0:00:43s\n",
      "epoch 16 | loss: 0.23783 | train_rmsle: 0.01755 | train_mae: 0.45747 | train_rmse: 0.54547 | train_mse: 0.29754 | valid_rmsle: 0.01728 | valid_mae: 0.46008 | valid_rmse: 0.54619 | valid_mse: 0.29833 |  0:00:46s\n",
      "epoch 17 | loss: 0.23596 | train_rmsle: 0.01632 | train_mae: 0.43423 | train_rmse: 0.52321 | train_mse: 0.27375 | valid_rmsle: 0.01595 | valid_mae: 0.43637 | valid_rmse: 0.52252 | valid_mse: 0.27303 |  0:00:48s\n",
      "epoch 18 | loss: 0.23105 | train_rmsle: 0.01594 | train_mae: 0.42727 | train_rmse: 0.51623 | train_mse: 0.2665  | valid_rmsle: 0.01556 | valid_mae: 0.42869 | valid_rmse: 0.51551 | valid_mse: 0.26575 |  0:00:51s\n",
      "epoch 19 | loss: 0.23873 | train_rmsle: 0.01499 | train_mae: 0.40395 | train_rmse: 0.49606 | train_mse: 0.24608 | valid_rmsle: 0.01447 | valid_mae: 0.40388 | valid_rmse: 0.49253 | valid_mse: 0.24259 |  0:00:54s\n",
      "epoch 20 | loss: 0.23323 | train_rmsle: 0.01492 | train_mae: 0.40327 | train_rmse: 0.49485 | train_mse: 0.24488 | valid_rmsle: 0.01458 | valid_mae: 0.40677 | valid_rmse: 0.49463 | valid_mse: 0.24466 |  0:00:56s\n",
      "epoch 21 | loss: 0.23143 | train_rmsle: 0.01588 | train_mae: 0.42537 | train_rmse: 0.51479 | train_mse: 0.26501 | valid_rmsle: 0.01548 | valid_mae: 0.42782 | valid_rmse: 0.51366 | valid_mse: 0.26385 |  0:00:59s\n",
      "epoch 22 | loss: 0.2311  | train_rmsle: 0.01586 | train_mae: 0.42628 | train_rmse: 0.51465 | train_mse: 0.26487 | valid_rmsle: 0.0155  | valid_mae: 0.42791 | valid_rmse: 0.51402 | valid_mse: 0.26422 |  0:01:01s\n",
      "epoch 23 | loss: 0.23317 | train_rmsle: 0.01502 | train_mae: 0.40676 | train_rmse: 0.49705 | train_mse: 0.24706 | valid_rmsle: 0.01459 | valid_mae: 0.40787 | valid_rmse: 0.49549 | valid_mse: 0.24551 |  0:01:03s\n",
      "epoch 24 | loss: 0.23322 | train_rmsle: 0.01455 | train_mae: 0.39318 | train_rmse: 0.48616 | train_mse: 0.23635 | valid_rmsle: 0.01422 | valid_mae: 0.3983  | valid_rmse: 0.48667 | valid_mse: 0.23685 |  0:01:05s\n",
      "epoch 25 | loss: 0.22772 | train_rmsle: 0.01533 | train_mae: 0.41334 | train_rmse: 0.504   | train_mse: 0.25402 | valid_rmsle: 0.01501 | valid_mae: 0.41792 | valid_rmse: 0.50458 | valid_mse: 0.2546  |  0:01:07s\n",
      "epoch 26 | loss: 0.22791 | train_rmsle: 0.01541 | train_mae: 0.41515 | train_rmse: 0.50574 | train_mse: 0.25577 | valid_rmsle: 0.01508 | valid_mae: 0.41803 | valid_rmse: 0.50592 | valid_mse: 0.25595 |  0:01:09s\n",
      "epoch 27 | loss: 0.23602 | train_rmsle: 0.01714 | train_mae: 0.45014 | train_rmse: 0.53869 | train_mse: 0.29019 | valid_rmsle: 0.01719 | valid_mae: 0.45685 | valid_rmse: 0.54432 | valid_mse: 0.29629 |  0:01:11s\n",
      "epoch 28 | loss: 0.22977 | train_rmsle: 0.01455 | train_mae: 0.39109 | train_rmse: 0.48565 | train_mse: 0.23586 | valid_rmsle: 0.01417 | valid_mae: 0.39274 | valid_rmse: 0.48497 | valid_mse: 0.23519 |  0:01:14s\n",
      "epoch 29 | loss: 0.22818 | train_rmsle: 0.01494 | train_mae: 0.40433 | train_rmse: 0.49556 | train_mse: 0.24558 | valid_rmsle: 0.01459 | valid_mae: 0.40678 | valid_rmse: 0.49551 | valid_mse: 0.24553 |  0:01:16s\n",
      "epoch 30 | loss: 0.225   | train_rmsle: 0.01535 | train_mae: 0.41246 | train_rmse: 0.50353 | train_mse: 0.25354 | valid_rmsle: 0.01512 | valid_mae: 0.41686 | valid_rmse: 0.50512 | valid_mse: 0.25514 |  0:01:19s\n",
      "epoch 31 | loss: 0.22473 | train_rmsle: 0.01446 | train_mae: 0.38662 | train_rmse: 0.48307 | train_mse: 0.23336 | valid_rmsle: 0.01393 | valid_mae: 0.38758 | valid_rmse: 0.47941 | valid_mse: 0.22983 |  0:01:22s\n",
      "epoch 32 | loss: 0.22381 | train_rmsle: 0.01446 | train_mae: 0.38815 | train_rmse: 0.48368 | train_mse: 0.23395 | valid_rmsle: 0.01396 | valid_mae: 0.38917 | valid_rmse: 0.48057 | valid_mse: 0.23095 |  0:01:25s\n",
      "epoch 33 | loss: 0.22346 | train_rmsle: 0.01448 | train_mae: 0.39028 | train_rmse: 0.48431 | train_mse: 0.23455 | valid_rmsle: 0.01399 | valid_mae: 0.39028 | valid_rmse: 0.48123 | valid_mse: 0.23158 |  0:01:27s\n",
      "epoch 34 | loss: 0.22986 | train_rmsle: 0.01544 | train_mae: 0.41641 | train_rmse: 0.50669 | train_mse: 0.25674 | valid_rmsle: 0.01506 | valid_mae: 0.4185  | valid_rmse: 0.50601 | valid_mse: 0.25605 |  0:01:30s\n",
      "epoch 35 | loss: 0.22958 | train_rmsle: 0.01465 | train_mae: 0.39147 | train_rmse: 0.487   | train_mse: 0.23717 | valid_rmsle: 0.01421 | valid_mae: 0.39399 | valid_rmse: 0.48531 | valid_mse: 0.23553 |  0:01:33s\n",
      "epoch 36 | loss: 0.22319 | train_rmsle: 0.01438 | train_mae: 0.38123 | train_rmse: 0.47978 | train_mse: 0.23019 | valid_rmsle: 0.01409 | valid_mae: 0.38705 | valid_rmse: 0.4807  | valid_mse: 0.23108 |  0:01:36s\n",
      "epoch 37 | loss: 0.22563 | train_rmsle: 0.01448 | train_mae: 0.3886  | train_rmse: 0.48414 | train_mse: 0.23439 | valid_rmsle: 0.01418 | valid_mae: 0.39427 | valid_rmse: 0.48473 | valid_mse: 0.23496 |  0:01:38s\n",
      "epoch 38 | loss: 0.22237 | train_rmsle: 0.01475 | train_mae: 0.3981  | train_rmse: 0.49116 | train_mse: 0.24124 | valid_rmsle: 0.0144  | valid_mae: 0.39996 | valid_rmse: 0.49089 | valid_mse: 0.24098 |  0:01:41s\n",
      "epoch 39 | loss: 0.2197  | train_rmsle: 0.01447 | train_mae: 0.3873  | train_rmse: 0.48341 | train_mse: 0.23369 | valid_rmsle: 0.01396 | valid_mae: 0.38683 | valid_rmse: 0.48024 | valid_mse: 0.23063 |  0:01:44s\n",
      "epoch 40 | loss: 0.22092 | train_rmsle: 0.01461 | train_mae: 0.3947  | train_rmse: 0.48832 | train_mse: 0.23846 | valid_rmsle: 0.01437 | valid_mae: 0.39939 | valid_rmse: 0.49007 | valid_mse: 0.24017 |  0:01:46s\n",
      "epoch 41 | loss: 0.22154 | train_rmsle: 0.01448 | train_mae: 0.38163 | train_rmse: 0.48096 | train_mse: 0.23132 | valid_rmsle: 0.01391 | valid_mae: 0.38223 | valid_rmse: 0.47714 | valid_mse: 0.22767 |  0:01:49s\n",
      "epoch 42 | loss: 0.22257 | train_rmsle: 0.01446 | train_mae: 0.38553 | train_rmse: 0.4824  | train_mse: 0.23271 | valid_rmsle: 0.01423 | valid_mae: 0.39002 | valid_rmse: 0.48409 | valid_mse: 0.23435 |  0:01:52s\n",
      "epoch 43 | loss: 0.22406 | train_rmsle: 0.01442 | train_mae: 0.38144 | train_rmse: 0.48066 | train_mse: 0.23103 | valid_rmsle: 0.01402 | valid_mae: 0.38273 | valid_rmse: 0.47926 | valid_mse: 0.22969 |  0:01:55s\n",
      "epoch 44 | loss: 0.22203 | train_rmsle: 0.01449 | train_mae: 0.388   | train_rmse: 0.48401 | train_mse: 0.23426 | valid_rmsle: 0.01434 | valid_mae: 0.39409 | valid_rmse: 0.48755 | valid_mse: 0.23771 |  0:01:57s\n",
      "epoch 45 | loss: 0.22265 | train_rmsle: 0.01437 | train_mae: 0.3841  | train_rmse: 0.48091 | train_mse: 0.23128 | valid_rmsle: 0.01405 | valid_mae: 0.38811 | valid_rmse: 0.48109 | valid_mse: 0.23145 |  0:02:00s\n",
      "epoch 46 | loss: 0.22359 | train_rmsle: 0.01464 | train_mae: 0.37764 | train_rmse: 0.482   | train_mse: 0.23232 | valid_rmsle: 0.01438 | valid_mae: 0.38227 | valid_rmse: 0.48374 | valid_mse: 0.234   |  0:02:03s\n",
      "epoch 47 | loss: 0.22226 | train_rmsle: 0.01476 | train_mae: 0.37648 | train_rmse: 0.4827  | train_mse: 0.233   | valid_rmsle: 0.01433 | valid_mae: 0.38093 | valid_rmse: 0.48159 | valid_mse: 0.23193 |  0:02:05s\n",
      "epoch 48 | loss: 0.23538 | train_rmsle: 0.01425 | train_mae: 0.3819  | train_rmse: 0.47884 | train_mse: 0.22929 | valid_rmsle: 0.0138  | valid_mae: 0.38359 | valid_rmse: 0.47718 | valid_mse: 0.2277  |  0:02:08s\n",
      "epoch 49 | loss: 0.2247  | train_rmsle: 0.01414 | train_mae: 0.37987 | train_rmse: 0.47636 | train_mse: 0.22692 | valid_rmsle: 0.01363 | valid_mae: 0.38208 | valid_rmse: 0.47405 | valid_mse: 0.22473 |  0:02:11s\n",
      "epoch 50 | loss: 0.21642 | train_rmsle: 0.01403 | train_mae: 0.38222 | train_rmse: 0.47629 | train_mse: 0.22685 | valid_rmsle: 0.01382 | valid_mae: 0.39113 | valid_rmse: 0.47905 | valid_mse: 0.22949 |  0:02:14s\n",
      "epoch 51 | loss: 0.2176  | train_rmsle: 0.01419 | train_mae: 0.38079 | train_rmse: 0.47763 | train_mse: 0.22813 | valid_rmsle: 0.01385 | valid_mae: 0.38573 | valid_rmse: 0.4778  | valid_mse: 0.2283  |  0:02:16s\n",
      "epoch 52 | loss: 0.2209  | train_rmsle: 0.01405 | train_mae: 0.37912 | train_rmse: 0.47504 | train_mse: 0.22566 | valid_rmsle: 0.01376 | valid_mae: 0.38631 | valid_rmse: 0.47658 | valid_mse: 0.22713 |  0:02:19s\n",
      "epoch 53 | loss: 0.21516 | train_rmsle: 0.01403 | train_mae: 0.37604 | train_rmse: 0.47319 | train_mse: 0.22391 | valid_rmsle: 0.01371 | valid_mae: 0.38101 | valid_rmse: 0.47391 | valid_mse: 0.22459 |  0:02:22s\n",
      "epoch 54 | loss: 0.2174  | train_rmsle: 0.01405 | train_mae: 0.37611 | train_rmse: 0.47396 | train_mse: 0.22464 | valid_rmsle: 0.01392 | valid_mae: 0.38472 | valid_rmse: 0.47819 | valid_mse: 0.22866 |  0:02:24s\n",
      "epoch 55 | loss: 0.21691 | train_rmsle: 0.01443 | train_mae: 0.37878 | train_rmse: 0.47911 | train_mse: 0.22955 | valid_rmsle: 0.01424 | valid_mae: 0.38787 | valid_rmse: 0.48308 | valid_mse: 0.23336 |  0:02:27s\n",
      "epoch 56 | loss: 0.2165  | train_rmsle: 0.0141  | train_mae: 0.3784  | train_rmse: 0.47553 | train_mse: 0.22613 | valid_rmsle: 0.0141  | valid_mae: 0.38738 | valid_rmse: 0.4818  | valid_mse: 0.23213 |  0:02:30s\n",
      "epoch 57 | loss: 0.21585 | train_rmsle: 0.01552 | train_mae: 0.37856 | train_rmse: 0.49376 | train_mse: 0.2438  | valid_rmsle: 0.01499 | valid_mae: 0.38628 | valid_rmse: 0.49166 | valid_mse: 0.24173 |  0:02:32s\n",
      "epoch 58 | loss: 0.22204 | train_rmsle: 0.01405 | train_mae: 0.37304 | train_rmse: 0.47267 | train_mse: 0.22342 | valid_rmsle: 0.0139  | valid_mae: 0.38014 | valid_rmse: 0.47557 | valid_mse: 0.22616 |  0:02:35s\n",
      "epoch 59 | loss: 0.2144  | train_rmsle: 0.01405 | train_mae: 0.38099 | train_rmse: 0.47591 | train_mse: 0.22649 | valid_rmsle: 0.01402 | valid_mae: 0.38707 | valid_rmse: 0.47939 | valid_mse: 0.22981 |  0:02:38s\n",
      "epoch 60 | loss: 0.21427 | train_rmsle: 0.01411 | train_mae: 0.37329 | train_rmse: 0.47367 | train_mse: 0.22437 | valid_rmsle: 0.01374 | valid_mae: 0.38132 | valid_rmse: 0.47329 | valid_mse: 0.224   |  0:02:41s\n",
      "epoch 61 | loss: 0.21575 | train_rmsle: 0.01412 | train_mae: 0.38295 | train_rmse: 0.478   | train_mse: 0.22849 | valid_rmsle: 0.01372 | valid_mae: 0.38564 | valid_rmse: 0.47661 | valid_mse: 0.22716 |  0:02:43s\n",
      "epoch 62 | loss: 0.21536 | train_rmsle: 0.01402 | train_mae: 0.37365 | train_rmse: 0.47282 | train_mse: 0.22356 | valid_rmsle: 0.01373 | valid_mae: 0.38061 | valid_rmse: 0.47394 | valid_mse: 0.22462 |  0:02:46s\n",
      "epoch 63 | loss: 0.21726 | train_rmsle: 0.01411 | train_mae: 0.38575 | train_rmse: 0.47889 | train_mse: 0.22934 | valid_rmsle: 0.01385 | valid_mae: 0.39093 | valid_rmse: 0.48164 | valid_mse: 0.23198 |  0:02:49s\n",
      "epoch 64 | loss: 0.21318 | train_rmsle: 0.01398 | train_mae: 0.37296 | train_rmse: 0.4723  | train_mse: 0.22307 | valid_rmsle: 0.01361 | valid_mae: 0.37695 | valid_rmse: 0.47184 | valid_mse: 0.22263 |  0:02:51s\n",
      "epoch 65 | loss: 0.21317 | train_rmsle: 0.01385 | train_mae: 0.37986 | train_rmse: 0.47339 | train_mse: 0.2241  | valid_rmsle: 0.01351 | valid_mae: 0.38287 | valid_rmse: 0.47314 | valid_mse: 0.22387 |  0:02:53s\n",
      "epoch 66 | loss: 0.21312 | train_rmsle: 0.01402 | train_mae: 0.38682 | train_rmse: 0.47812 | train_mse: 0.2286  | valid_rmsle: 0.0138  | valid_mae: 0.39097 | valid_rmse: 0.47999 | valid_mse: 0.23039 |  0:02:56s\n",
      "epoch 67 | loss: 0.21007 | train_rmsle: 0.0139  | train_mae: 0.3699  | train_rmse: 0.46952 | train_mse: 0.22045 | valid_rmsle: 0.01364 | valid_mae: 0.37571 | valid_rmse: 0.47083 | valid_mse: 0.22168 |  0:02:58s\n",
      "epoch 68 | loss: 0.21085 | train_rmsle: 0.01376 | train_mae: 0.37693 | train_rmse: 0.47074 | train_mse: 0.2216  | valid_rmsle: 0.01362 | valid_mae: 0.38504 | valid_rmse: 0.47403 | valid_mse: 0.2247  |  0:03:00s\n",
      "epoch 69 | loss: 0.2116  | train_rmsle: 0.01375 | train_mae: 0.37125 | train_rmse: 0.46828 | train_mse: 0.21928 | valid_rmsle: 0.01352 | valid_mae: 0.37693 | valid_rmse: 0.46991 | valid_mse: 0.22082 |  0:03:03s\n",
      "epoch 70 | loss: 0.21237 | train_rmsle: 0.01369 | train_mae: 0.37356 | train_rmse: 0.46861 | train_mse: 0.2196  | valid_rmsle: 0.01356 | valid_mae: 0.38147 | valid_rmse: 0.47242 | valid_mse: 0.22318 |  0:03:05s\n",
      "epoch 71 | loss: 0.20871 | train_rmsle: 0.01386 | train_mae: 0.3839  | train_rmse: 0.47554 | train_mse: 0.22613 | valid_rmsle: 0.01373 | valid_mae: 0.393   | valid_rmse: 0.4794  | valid_mse: 0.22983 |  0:03:08s\n",
      "epoch 72 | loss: 0.21099 | train_rmsle: 0.01364 | train_mae: 0.37393 | train_rmse: 0.46877 | train_mse: 0.21974 | valid_rmsle: 0.01342 | valid_mae: 0.38563 | valid_rmse: 0.4715  | valid_mse: 0.22231 |  0:03:11s\n",
      "epoch 73 | loss: 0.20898 | train_rmsle: 0.01355 | train_mae: 0.36687 | train_rmse: 0.46451 | train_mse: 0.21577 | valid_rmsle: 0.01322 | valid_mae: 0.37699 | valid_rmse: 0.46529 | valid_mse: 0.21649 |  0:03:13s\n",
      "epoch 74 | loss: 0.20843 | train_rmsle: 0.0135  | train_mae: 0.36871 | train_rmse: 0.46477 | train_mse: 0.21601 | valid_rmsle: 0.01305 | valid_mae: 0.37647 | valid_rmse: 0.46307 | valid_mse: 0.21443 |  0:03:16s\n",
      "epoch 75 | loss: 0.20992 | train_rmsle: 0.01362 | train_mae: 0.36646 | train_rmse: 0.46486 | train_mse: 0.21609 | valid_rmsle: 0.01313 | valid_mae: 0.37161 | valid_rmse: 0.46238 | valid_mse: 0.2138  |  0:03:19s\n",
      "epoch 76 | loss: 0.20838 | train_rmsle: 0.01352 | train_mae: 0.36865 | train_rmse: 0.46477 | train_mse: 0.21602 | valid_rmsle: 0.01318 | valid_mae: 0.37527 | valid_rmse: 0.46459 | valid_mse: 0.21584 |  0:03:22s\n",
      "epoch 77 | loss: 0.2061  | train_rmsle: 0.01361 | train_mae: 0.36732 | train_rmse: 0.46515 | train_mse: 0.21637 | valid_rmsle: 0.01322 | valid_mae: 0.37423 | valid_rmse: 0.46426 | valid_mse: 0.21553 |  0:03:24s\n",
      "epoch 78 | loss: 0.20878 | train_rmsle: 0.01361 | train_mae: 0.36722 | train_rmse: 0.46528 | train_mse: 0.21648 | valid_rmsle: 0.01322 | valid_mae: 0.37442 | valid_rmse: 0.46522 | valid_mse: 0.21643 |  0:03:27s\n",
      "epoch 79 | loss: 0.20929 | train_rmsle: 0.01372 | train_mae: 0.37765 | train_rmse: 0.47106 | train_mse: 0.2219  | valid_rmsle: 0.01331 | valid_mae: 0.38155 | valid_rmse: 0.46981 | valid_mse: 0.22072 |  0:03:30s\n",
      "epoch 80 | loss: 0.20854 | train_rmsle: 0.01361 | train_mae: 0.36889 | train_rmse: 0.46592 | train_mse: 0.21708 | valid_rmsle: 0.01323 | valid_mae: 0.37602 | valid_rmse: 0.46581 | valid_mse: 0.21698 |  0:03:33s\n",
      "epoch 81 | loss: 0.21257 | train_rmsle: 0.01383 | train_mae: 0.36634 | train_rmse: 0.46767 | train_mse: 0.21872 | valid_rmsle: 0.01349 | valid_mae: 0.37294 | valid_rmse: 0.46803 | valid_mse: 0.21905 |  0:03:35s\n",
      "epoch 82 | loss: 0.2142  | train_rmsle: 0.01375 | train_mae: 0.37926 | train_rmse: 0.47231 | train_mse: 0.22308 | valid_rmsle: 0.01364 | valid_mae: 0.38735 | valid_rmse: 0.47664 | valid_mse: 0.22718 |  0:03:38s\n",
      "epoch 83 | loss: 0.21297 | train_rmsle: 0.01378 | train_mae: 0.38006 | train_rmse: 0.4728  | train_mse: 0.22354 | valid_rmsle: 0.01391 | valid_mae: 0.39111 | valid_rmse: 0.48148 | valid_mse: 0.23182 |  0:03:40s\n",
      "epoch 84 | loss: 0.21456 | train_rmsle: 0.01363 | train_mae: 0.37244 | train_rmse: 0.46747 | train_mse: 0.21853 | valid_rmsle: 0.01343 | valid_mae: 0.37916 | valid_rmse: 0.47021 | valid_mse: 0.22109 |  0:03:42s\n",
      "epoch 85 | loss: 0.21083 | train_rmsle: 0.0137  | train_mae: 0.37576 | train_rmse: 0.46951 | train_mse: 0.22044 | valid_rmsle: 0.0135  | valid_mae: 0.38023 | valid_rmse: 0.47177 | valid_mse: 0.22256 |  0:03:44s\n",
      "epoch 86 | loss: 0.21206 | train_rmsle: 0.01388 | train_mae: 0.36724 | train_rmse: 0.46842 | train_mse: 0.21942 | valid_rmsle: 0.01349 | valid_mae: 0.37006 | valid_rmse: 0.46719 | valid_mse: 0.21827 |  0:03:47s\n",
      "epoch 87 | loss: 0.21042 | train_rmsle: 0.01363 | train_mae: 0.37096 | train_rmse: 0.46658 | train_mse: 0.2177  | valid_rmsle: 0.01341 | valid_mae: 0.37658 | valid_rmse: 0.46853 | valid_mse: 0.21952 |  0:03:50s\n",
      "epoch 88 | loss: 0.20877 | train_rmsle: 0.01361 | train_mae: 0.37084 | train_rmse: 0.46645 | train_mse: 0.21757 | valid_rmsle: 0.01361 | valid_mae: 0.38144 | valid_rmse: 0.47329 | valid_mse: 0.22401 |  0:03:52s\n",
      "epoch 89 | loss: 0.20885 | train_rmsle: 0.01363 | train_mae: 0.36964 | train_rmse: 0.46597 | train_mse: 0.21713 | valid_rmsle: 0.01358 | valid_mae: 0.37958 | valid_rmse: 0.47195 | valid_mse: 0.22274 |  0:03:55s\n",
      "epoch 90 | loss: 0.20928 | train_rmsle: 0.01365 | train_mae: 0.36971 | train_rmse: 0.4663  | train_mse: 0.21744 | valid_rmsle: 0.01352 | valid_mae: 0.37816 | valid_rmse: 0.47062 | valid_mse: 0.22148 |  0:03:58s\n",
      "epoch 91 | loss: 0.21038 | train_rmsle: 0.0136  | train_mae: 0.37501 | train_rmse: 0.4681  | train_mse: 0.21912 | valid_rmsle: 0.01346 | valid_mae: 0.38317 | valid_rmse: 0.47232 | valid_mse: 0.22308 |  0:04:01s\n",
      "epoch 92 | loss: 0.20732 | train_rmsle: 0.01353 | train_mae: 0.36964 | train_rmse: 0.46503 | train_mse: 0.21625 | valid_rmsle: 0.01357 | valid_mae: 0.38148 | valid_rmse: 0.47235 | valid_mse: 0.22311 |  0:04:03s\n",
      "epoch 93 | loss: 0.20728 | train_rmsle: 0.01364 | train_mae: 0.36505 | train_rmse: 0.46442 | train_mse: 0.21568 | valid_rmsle: 0.01376 | valid_mae: 0.37735 | valid_rmse: 0.47312 | valid_mse: 0.22384 |  0:04:06s\n",
      "epoch 94 | loss: 0.20774 | train_rmsle: 0.01345 | train_mae: 0.36773 | train_rmse: 0.46358 | train_mse: 0.21491 | valid_rmsle: 0.01365 | valid_mae: 0.38218 | valid_rmse: 0.47397 | valid_mse: 0.22464 |  0:04:09s\n",
      "epoch 95 | loss: 0.20711 | train_rmsle: 0.01362 | train_mae: 0.36328 | train_rmse: 0.46367 | train_mse: 0.21499 | valid_rmsle: 0.01369 | valid_mae: 0.37644 | valid_rmse: 0.47183 | valid_mse: 0.22263 |  0:04:11s\n",
      "\n",
      "Early stopping occurred at epoch 95 with best_epoch = 75 and best_valid_mse = 0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21387850549948076 RMSE: 0.46247000497273416 R2: 0.05324226751470329 MAE: 0.3638193553172873\n",
      "=====================================\n",
      "[35/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.39831 | train_rmsle: 0.86702 | train_mae: 2.58602 | train_rmse: 2.63107 | train_mse: 6.92252 | valid_rmsle: 0.87081 | valid_mae: 2.59352 | valid_rmse: 2.63752 | valid_mse: 6.95654 |  0:00:02s\n",
      "epoch 1  | loss: 2.79417 | train_rmsle: 0.33039 | train_mae: 1.85282 | train_rmse: 1.9151  | train_mse: 3.66759 | valid_rmsle: 0.33152 | valid_mae: 1.85823 | valid_rmse: 1.9196  | valid_mse: 3.68487 |  0:00:05s\n",
      "epoch 2  | loss: 1.68546 | train_rmsle: 0.14234 | train_mae: 1.31002 | train_rmse: 1.39095 | train_mse: 1.93474 | valid_rmsle: 0.14284 | valid_mae: 1.31261 | valid_rmse: 1.3946  | valid_mse: 1.94492 |  0:00:07s\n",
      "epoch 3  | loss: 0.97534 | train_rmsle: 0.03686 | train_mae: 0.69025 | train_rmse: 0.784   | train_mse: 0.61465 | valid_rmsle: 0.03678 | valid_mae: 0.69008 | valid_rmse: 0.78578 | valid_mse: 0.61746 |  0:00:10s\n",
      "epoch 4  | loss: 0.55782 | train_rmsle: 0.02265 | train_mae: 0.53273 | train_rmse: 0.62284 | train_mse: 0.38793 | valid_rmsle: 0.0224  | valid_mae: 0.53451 | valid_rmse: 0.62319 | valid_mse: 0.38837 |  0:00:12s\n",
      "epoch 5  | loss: 0.4022  | train_rmsle: 0.01809 | train_mae: 0.46611 | train_rmse: 0.55427 | train_mse: 0.30721 | valid_rmsle: 0.01774 | valid_mae: 0.4678  | valid_rmse: 0.55338 | valid_mse: 0.30623 |  0:00:14s\n",
      "epoch 6  | loss: 0.34074 | train_rmsle: 0.02227 | train_mae: 0.52819 | train_rmse: 0.61768 | train_mse: 0.38152 | valid_rmsle: 0.022   | valid_mae: 0.52954 | valid_rmse: 0.61804 | valid_mse: 0.38197 |  0:00:17s\n",
      "epoch 7  | loss: 0.31281 | train_rmsle: 0.01748 | train_mae: 0.45588 | train_rmse: 0.5439  | train_mse: 0.29583 | valid_rmsle: 0.01709 | valid_mae: 0.45696 | valid_rmse: 0.54259 | valid_mse: 0.2944  |  0:00:19s\n",
      "epoch 8  | loss: 0.28    | train_rmsle: 0.01647 | train_mae: 0.43727 | train_rmse: 0.52567 | train_mse: 0.27633 | valid_rmsle: 0.01604 | valid_mae: 0.43818 | valid_rmse: 0.52384 | valid_mse: 0.27441 |  0:00:22s\n",
      "epoch 9  | loss: 0.26637 | train_rmsle: 0.01562 | train_mae: 0.41889 | train_rmse: 0.50884 | train_mse: 0.25892 | valid_rmsle: 0.01512 | valid_mae: 0.41959 | valid_rmse: 0.50576 | valid_mse: 0.2558  |  0:00:25s\n",
      "epoch 10 | loss: 0.26164 | train_rmsle: 0.01617 | train_mae: 0.43123 | train_rmse: 0.52008 | train_mse: 0.27048 | valid_rmsle: 0.01565 | valid_mae: 0.43161 | valid_rmse: 0.51686 | valid_mse: 0.26714 |  0:00:27s\n",
      "epoch 11 | loss: 0.25288 | train_rmsle: 0.01583 | train_mae: 0.42392 | train_rmse: 0.51337 | train_mse: 0.26355 | valid_rmsle: 0.0153  | valid_mae: 0.42438 | valid_rmse: 0.50991 | valid_mse: 0.26001 |  0:00:30s\n",
      "epoch 12 | loss: 0.2418  | train_rmsle: 0.01547 | train_mae: 0.41577 | train_rmse: 0.50594 | train_mse: 0.25598 | valid_rmsle: 0.01497 | valid_mae: 0.4157  | valid_rmse: 0.50288 | valid_mse: 0.25289 |  0:00:33s\n",
      "epoch 13 | loss: 0.24466 | train_rmsle: 0.01703 | train_mae: 0.44814 | train_rmse: 0.53644 | train_mse: 0.28777 | valid_rmsle: 0.01669 | valid_mae: 0.44999 | valid_rmse: 0.53606 | valid_mse: 0.28736 |  0:00:35s\n",
      "epoch 14 | loss: 0.24656 | train_rmsle: 0.01798 | train_mae: 0.46475 | train_rmse: 0.55293 | train_mse: 0.30573 | valid_rmsle: 0.01765 | valid_mae: 0.46675 | valid_rmse: 0.55254 | valid_mse: 0.3053  |  0:00:38s\n",
      "epoch 15 | loss: 0.24272 | train_rmsle: 0.01563 | train_mae: 0.42052 | train_rmse: 0.51012 | train_mse: 0.26022 | valid_rmsle: 0.01523 | valid_mae: 0.4229  | valid_rmse: 0.50892 | valid_mse: 0.259   |  0:00:41s\n",
      "epoch 16 | loss: 0.23783 | train_rmsle: 0.01755 | train_mae: 0.45747 | train_rmse: 0.54547 | train_mse: 0.29754 | valid_rmsle: 0.01728 | valid_mae: 0.46008 | valid_rmse: 0.54619 | valid_mse: 0.29833 |  0:00:44s\n",
      "epoch 17 | loss: 0.23596 | train_rmsle: 0.01632 | train_mae: 0.43423 | train_rmse: 0.52321 | train_mse: 0.27375 | valid_rmsle: 0.01595 | valid_mae: 0.43637 | valid_rmse: 0.52252 | valid_mse: 0.27303 |  0:00:46s\n",
      "epoch 18 | loss: 0.23105 | train_rmsle: 0.01594 | train_mae: 0.42727 | train_rmse: 0.51623 | train_mse: 0.2665  | valid_rmsle: 0.01556 | valid_mae: 0.42869 | valid_rmse: 0.51551 | valid_mse: 0.26575 |  0:00:49s\n",
      "epoch 19 | loss: 0.23873 | train_rmsle: 0.01499 | train_mae: 0.40395 | train_rmse: 0.49606 | train_mse: 0.24608 | valid_rmsle: 0.01447 | valid_mae: 0.40388 | valid_rmse: 0.49253 | valid_mse: 0.24259 |  0:00:52s\n",
      "epoch 20 | loss: 0.23323 | train_rmsle: 0.01492 | train_mae: 0.40327 | train_rmse: 0.49485 | train_mse: 0.24488 | valid_rmsle: 0.01458 | valid_mae: 0.40677 | valid_rmse: 0.49463 | valid_mse: 0.24466 |  0:00:55s\n",
      "epoch 21 | loss: 0.23143 | train_rmsle: 0.01588 | train_mae: 0.42537 | train_rmse: 0.51479 | train_mse: 0.26501 | valid_rmsle: 0.01548 | valid_mae: 0.42782 | valid_rmse: 0.51366 | valid_mse: 0.26385 |  0:00:57s\n",
      "epoch 22 | loss: 0.2311  | train_rmsle: 0.01586 | train_mae: 0.42628 | train_rmse: 0.51465 | train_mse: 0.26487 | valid_rmsle: 0.0155  | valid_mae: 0.42791 | valid_rmse: 0.51402 | valid_mse: 0.26422 |  0:01:00s\n",
      "epoch 23 | loss: 0.23317 | train_rmsle: 0.01502 | train_mae: 0.40676 | train_rmse: 0.49705 | train_mse: 0.24706 | valid_rmsle: 0.01459 | valid_mae: 0.40787 | valid_rmse: 0.49549 | valid_mse: 0.24551 |  0:01:03s\n",
      "epoch 24 | loss: 0.23322 | train_rmsle: 0.01455 | train_mae: 0.39318 | train_rmse: 0.48616 | train_mse: 0.23635 | valid_rmsle: 0.01422 | valid_mae: 0.3983  | valid_rmse: 0.48667 | valid_mse: 0.23685 |  0:01:05s\n",
      "epoch 25 | loss: 0.22772 | train_rmsle: 0.01533 | train_mae: 0.41334 | train_rmse: 0.504   | train_mse: 0.25402 | valid_rmsle: 0.01501 | valid_mae: 0.41792 | valid_rmse: 0.50458 | valid_mse: 0.2546  |  0:01:08s\n",
      "epoch 26 | loss: 0.22791 | train_rmsle: 0.01541 | train_mae: 0.41515 | train_rmse: 0.50574 | train_mse: 0.25577 | valid_rmsle: 0.01508 | valid_mae: 0.41803 | valid_rmse: 0.50592 | valid_mse: 0.25595 |  0:01:11s\n",
      "epoch 27 | loss: 0.23602 | train_rmsle: 0.01714 | train_mae: 0.45014 | train_rmse: 0.53869 | train_mse: 0.29019 | valid_rmsle: 0.01719 | valid_mae: 0.45685 | valid_rmse: 0.54432 | valid_mse: 0.29629 |  0:01:14s\n",
      "epoch 28 | loss: 0.22977 | train_rmsle: 0.01455 | train_mae: 0.39109 | train_rmse: 0.48565 | train_mse: 0.23586 | valid_rmsle: 0.01417 | valid_mae: 0.39274 | valid_rmse: 0.48497 | valid_mse: 0.23519 |  0:01:16s\n",
      "epoch 29 | loss: 0.22818 | train_rmsle: 0.01494 | train_mae: 0.40433 | train_rmse: 0.49556 | train_mse: 0.24558 | valid_rmsle: 0.01459 | valid_mae: 0.40678 | valid_rmse: 0.49551 | valid_mse: 0.24553 |  0:01:19s\n",
      "epoch 30 | loss: 0.225   | train_rmsle: 0.01535 | train_mae: 0.41246 | train_rmse: 0.50353 | train_mse: 0.25354 | valid_rmsle: 0.01512 | valid_mae: 0.41686 | valid_rmse: 0.50512 | valid_mse: 0.25514 |  0:01:22s\n",
      "epoch 31 | loss: 0.22473 | train_rmsle: 0.01446 | train_mae: 0.38662 | train_rmse: 0.48307 | train_mse: 0.23336 | valid_rmsle: 0.01393 | valid_mae: 0.38758 | valid_rmse: 0.47941 | valid_mse: 0.22983 |  0:01:24s\n",
      "epoch 32 | loss: 0.22381 | train_rmsle: 0.01446 | train_mae: 0.38815 | train_rmse: 0.48368 | train_mse: 0.23395 | valid_rmsle: 0.01396 | valid_mae: 0.38917 | valid_rmse: 0.48057 | valid_mse: 0.23095 |  0:01:27s\n",
      "epoch 33 | loss: 0.22346 | train_rmsle: 0.01448 | train_mae: 0.39028 | train_rmse: 0.48431 | train_mse: 0.23455 | valid_rmsle: 0.01399 | valid_mae: 0.39028 | valid_rmse: 0.48123 | valid_mse: 0.23158 |  0:01:30s\n",
      "epoch 34 | loss: 0.22986 | train_rmsle: 0.01544 | train_mae: 0.41641 | train_rmse: 0.50669 | train_mse: 0.25674 | valid_rmsle: 0.01506 | valid_mae: 0.4185  | valid_rmse: 0.50601 | valid_mse: 0.25605 |  0:01:33s\n",
      "epoch 35 | loss: 0.22958 | train_rmsle: 0.01465 | train_mae: 0.39147 | train_rmse: 0.487   | train_mse: 0.23717 | valid_rmsle: 0.01421 | valid_mae: 0.39399 | valid_rmse: 0.48531 | valid_mse: 0.23553 |  0:01:35s\n",
      "epoch 36 | loss: 0.22319 | train_rmsle: 0.01438 | train_mae: 0.38123 | train_rmse: 0.47978 | train_mse: 0.23019 | valid_rmsle: 0.01409 | valid_mae: 0.38705 | valid_rmse: 0.4807  | valid_mse: 0.23108 |  0:01:38s\n",
      "epoch 37 | loss: 0.22563 | train_rmsle: 0.01448 | train_mae: 0.3886  | train_rmse: 0.48414 | train_mse: 0.23439 | valid_rmsle: 0.01418 | valid_mae: 0.39427 | valid_rmse: 0.48473 | valid_mse: 0.23496 |  0:01:41s\n",
      "epoch 38 | loss: 0.22237 | train_rmsle: 0.01475 | train_mae: 0.3981  | train_rmse: 0.49116 | train_mse: 0.24124 | valid_rmsle: 0.0144  | valid_mae: 0.39996 | valid_rmse: 0.49089 | valid_mse: 0.24098 |  0:01:44s\n",
      "epoch 39 | loss: 0.2197  | train_rmsle: 0.01447 | train_mae: 0.3873  | train_rmse: 0.48341 | train_mse: 0.23369 | valid_rmsle: 0.01396 | valid_mae: 0.38683 | valid_rmse: 0.48024 | valid_mse: 0.23063 |  0:01:46s\n",
      "epoch 40 | loss: 0.22092 | train_rmsle: 0.01461 | train_mae: 0.3947  | train_rmse: 0.48832 | train_mse: 0.23846 | valid_rmsle: 0.01437 | valid_mae: 0.39939 | valid_rmse: 0.49007 | valid_mse: 0.24017 |  0:01:49s\n",
      "epoch 41 | loss: 0.22154 | train_rmsle: 0.01448 | train_mae: 0.38163 | train_rmse: 0.48096 | train_mse: 0.23132 | valid_rmsle: 0.01391 | valid_mae: 0.38223 | valid_rmse: 0.47714 | valid_mse: 0.22767 |  0:01:51s\n",
      "epoch 42 | loss: 0.22257 | train_rmsle: 0.01446 | train_mae: 0.38553 | train_rmse: 0.4824  | train_mse: 0.23271 | valid_rmsle: 0.01423 | valid_mae: 0.39002 | valid_rmse: 0.48409 | valid_mse: 0.23435 |  0:01:54s\n",
      "epoch 43 | loss: 0.22406 | train_rmsle: 0.01442 | train_mae: 0.38144 | train_rmse: 0.48066 | train_mse: 0.23103 | valid_rmsle: 0.01402 | valid_mae: 0.38273 | valid_rmse: 0.47926 | valid_mse: 0.22969 |  0:01:56s\n",
      "epoch 44 | loss: 0.22203 | train_rmsle: 0.01449 | train_mae: 0.388   | train_rmse: 0.48401 | train_mse: 0.23426 | valid_rmsle: 0.01434 | valid_mae: 0.39409 | valid_rmse: 0.48755 | valid_mse: 0.23771 |  0:01:59s\n",
      "epoch 45 | loss: 0.22265 | train_rmsle: 0.01437 | train_mae: 0.3841  | train_rmse: 0.48091 | train_mse: 0.23128 | valid_rmsle: 0.01405 | valid_mae: 0.38811 | valid_rmse: 0.48109 | valid_mse: 0.23145 |  0:02:01s\n",
      "epoch 46 | loss: 0.22359 | train_rmsle: 0.01464 | train_mae: 0.37764 | train_rmse: 0.482   | train_mse: 0.23232 | valid_rmsle: 0.01438 | valid_mae: 0.38227 | valid_rmse: 0.48374 | valid_mse: 0.234   |  0:02:03s\n",
      "epoch 47 | loss: 0.22226 | train_rmsle: 0.01476 | train_mae: 0.37648 | train_rmse: 0.4827  | train_mse: 0.233   | valid_rmsle: 0.01433 | valid_mae: 0.38093 | valid_rmse: 0.48159 | valid_mse: 0.23193 |  0:02:06s\n",
      "epoch 48 | loss: 0.23538 | train_rmsle: 0.01425 | train_mae: 0.3819  | train_rmse: 0.47884 | train_mse: 0.22929 | valid_rmsle: 0.0138  | valid_mae: 0.38359 | valid_rmse: 0.47718 | valid_mse: 0.2277  |  0:02:09s\n",
      "epoch 49 | loss: 0.2247  | train_rmsle: 0.01414 | train_mae: 0.37987 | train_rmse: 0.47636 | train_mse: 0.22692 | valid_rmsle: 0.01363 | valid_mae: 0.38208 | valid_rmse: 0.47405 | valid_mse: 0.22473 |  0:02:11s\n",
      "epoch 50 | loss: 0.21642 | train_rmsle: 0.01403 | train_mae: 0.38222 | train_rmse: 0.47629 | train_mse: 0.22685 | valid_rmsle: 0.01382 | valid_mae: 0.39113 | valid_rmse: 0.47905 | valid_mse: 0.22949 |  0:02:14s\n",
      "epoch 51 | loss: 0.2176  | train_rmsle: 0.01419 | train_mae: 0.38079 | train_rmse: 0.47763 | train_mse: 0.22813 | valid_rmsle: 0.01385 | valid_mae: 0.38573 | valid_rmse: 0.4778  | valid_mse: 0.2283  |  0:02:17s\n",
      "epoch 52 | loss: 0.2209  | train_rmsle: 0.01405 | train_mae: 0.37912 | train_rmse: 0.47504 | train_mse: 0.22566 | valid_rmsle: 0.01376 | valid_mae: 0.38631 | valid_rmse: 0.47658 | valid_mse: 0.22713 |  0:02:19s\n",
      "epoch 53 | loss: 0.21516 | train_rmsle: 0.01403 | train_mae: 0.37604 | train_rmse: 0.47319 | train_mse: 0.22391 | valid_rmsle: 0.01371 | valid_mae: 0.38101 | valid_rmse: 0.47391 | valid_mse: 0.22459 |  0:02:22s\n",
      "epoch 54 | loss: 0.2174  | train_rmsle: 0.01405 | train_mae: 0.37611 | train_rmse: 0.47396 | train_mse: 0.22464 | valid_rmsle: 0.01392 | valid_mae: 0.38472 | valid_rmse: 0.47819 | valid_mse: 0.22866 |  0:02:25s\n",
      "epoch 55 | loss: 0.21691 | train_rmsle: 0.01443 | train_mae: 0.37878 | train_rmse: 0.47911 | train_mse: 0.22955 | valid_rmsle: 0.01424 | valid_mae: 0.38787 | valid_rmse: 0.48308 | valid_mse: 0.23336 |  0:02:27s\n",
      "epoch 56 | loss: 0.2165  | train_rmsle: 0.0141  | train_mae: 0.3784  | train_rmse: 0.47553 | train_mse: 0.22613 | valid_rmsle: 0.0141  | valid_mae: 0.38738 | valid_rmse: 0.4818  | valid_mse: 0.23213 |  0:02:30s\n",
      "epoch 57 | loss: 0.21585 | train_rmsle: 0.01552 | train_mae: 0.37856 | train_rmse: 0.49376 | train_mse: 0.2438  | valid_rmsle: 0.01499 | valid_mae: 0.38628 | valid_rmse: 0.49166 | valid_mse: 0.24173 |  0:02:33s\n",
      "epoch 58 | loss: 0.22204 | train_rmsle: 0.01405 | train_mae: 0.37304 | train_rmse: 0.47267 | train_mse: 0.22342 | valid_rmsle: 0.0139  | valid_mae: 0.38014 | valid_rmse: 0.47557 | valid_mse: 0.22616 |  0:02:36s\n",
      "epoch 59 | loss: 0.2144  | train_rmsle: 0.01405 | train_mae: 0.38099 | train_rmse: 0.47591 | train_mse: 0.22649 | valid_rmsle: 0.01402 | valid_mae: 0.38707 | valid_rmse: 0.47939 | valid_mse: 0.22981 |  0:02:38s\n",
      "epoch 60 | loss: 0.21427 | train_rmsle: 0.01411 | train_mae: 0.37329 | train_rmse: 0.47367 | train_mse: 0.22437 | valid_rmsle: 0.01374 | valid_mae: 0.38132 | valid_rmse: 0.47329 | valid_mse: 0.224   |  0:02:41s\n",
      "epoch 61 | loss: 0.21575 | train_rmsle: 0.01412 | train_mae: 0.38295 | train_rmse: 0.478   | train_mse: 0.22849 | valid_rmsle: 0.01372 | valid_mae: 0.38564 | valid_rmse: 0.47661 | valid_mse: 0.22716 |  0:02:43s\n",
      "epoch 62 | loss: 0.21536 | train_rmsle: 0.01402 | train_mae: 0.37365 | train_rmse: 0.47282 | train_mse: 0.22356 | valid_rmsle: 0.01373 | valid_mae: 0.38061 | valid_rmse: 0.47394 | valid_mse: 0.22462 |  0:02:46s\n",
      "epoch 63 | loss: 0.21726 | train_rmsle: 0.01411 | train_mae: 0.38575 | train_rmse: 0.47889 | train_mse: 0.22934 | valid_rmsle: 0.01385 | valid_mae: 0.39093 | valid_rmse: 0.48164 | valid_mse: 0.23198 |  0:02:48s\n",
      "epoch 64 | loss: 0.21318 | train_rmsle: 0.01398 | train_mae: 0.37296 | train_rmse: 0.4723  | train_mse: 0.22307 | valid_rmsle: 0.01361 | valid_mae: 0.37695 | valid_rmse: 0.47184 | valid_mse: 0.22263 |  0:02:50s\n",
      "epoch 65 | loss: 0.21317 | train_rmsle: 0.01385 | train_mae: 0.37986 | train_rmse: 0.47339 | train_mse: 0.2241  | valid_rmsle: 0.01351 | valid_mae: 0.38287 | valid_rmse: 0.47314 | valid_mse: 0.22387 |  0:02:53s\n",
      "epoch 66 | loss: 0.21312 | train_rmsle: 0.01402 | train_mae: 0.38682 | train_rmse: 0.47812 | train_mse: 0.2286  | valid_rmsle: 0.0138  | valid_mae: 0.39097 | valid_rmse: 0.47999 | valid_mse: 0.23039 |  0:02:55s\n",
      "epoch 67 | loss: 0.21007 | train_rmsle: 0.0139  | train_mae: 0.3699  | train_rmse: 0.46952 | train_mse: 0.22045 | valid_rmsle: 0.01364 | valid_mae: 0.37571 | valid_rmse: 0.47083 | valid_mse: 0.22168 |  0:02:58s\n",
      "epoch 68 | loss: 0.21085 | train_rmsle: 0.01376 | train_mae: 0.37693 | train_rmse: 0.47074 | train_mse: 0.2216  | valid_rmsle: 0.01362 | valid_mae: 0.38504 | valid_rmse: 0.47403 | valid_mse: 0.2247  |  0:03:01s\n",
      "epoch 69 | loss: 0.2116  | train_rmsle: 0.01375 | train_mae: 0.37125 | train_rmse: 0.46828 | train_mse: 0.21928 | valid_rmsle: 0.01352 | valid_mae: 0.37693 | valid_rmse: 0.46991 | valid_mse: 0.22082 |  0:03:03s\n",
      "epoch 70 | loss: 0.21237 | train_rmsle: 0.01369 | train_mae: 0.37356 | train_rmse: 0.46861 | train_mse: 0.2196  | valid_rmsle: 0.01356 | valid_mae: 0.38147 | valid_rmse: 0.47242 | valid_mse: 0.22318 |  0:03:06s\n",
      "epoch 71 | loss: 0.20871 | train_rmsle: 0.01386 | train_mae: 0.3839  | train_rmse: 0.47554 | train_mse: 0.22613 | valid_rmsle: 0.01373 | valid_mae: 0.393   | valid_rmse: 0.4794  | valid_mse: 0.22983 |  0:03:09s\n",
      "epoch 72 | loss: 0.21099 | train_rmsle: 0.01364 | train_mae: 0.37393 | train_rmse: 0.46877 | train_mse: 0.21974 | valid_rmsle: 0.01342 | valid_mae: 0.38563 | valid_rmse: 0.4715  | valid_mse: 0.22231 |  0:03:11s\n",
      "epoch 73 | loss: 0.20898 | train_rmsle: 0.01355 | train_mae: 0.36687 | train_rmse: 0.46451 | train_mse: 0.21577 | valid_rmsle: 0.01322 | valid_mae: 0.37699 | valid_rmse: 0.46529 | valid_mse: 0.21649 |  0:03:14s\n",
      "epoch 74 | loss: 0.20843 | train_rmsle: 0.0135  | train_mae: 0.36871 | train_rmse: 0.46477 | train_mse: 0.21601 | valid_rmsle: 0.01305 | valid_mae: 0.37647 | valid_rmse: 0.46307 | valid_mse: 0.21443 |  0:03:17s\n",
      "epoch 75 | loss: 0.20992 | train_rmsle: 0.01362 | train_mae: 0.36646 | train_rmse: 0.46486 | train_mse: 0.21609 | valid_rmsle: 0.01313 | valid_mae: 0.37161 | valid_rmse: 0.46238 | valid_mse: 0.2138  |  0:03:20s\n",
      "epoch 76 | loss: 0.20838 | train_rmsle: 0.01352 | train_mae: 0.36865 | train_rmse: 0.46477 | train_mse: 0.21602 | valid_rmsle: 0.01318 | valid_mae: 0.37527 | valid_rmse: 0.46459 | valid_mse: 0.21584 |  0:03:22s\n",
      "epoch 77 | loss: 0.2061  | train_rmsle: 0.01361 | train_mae: 0.36732 | train_rmse: 0.46515 | train_mse: 0.21637 | valid_rmsle: 0.01322 | valid_mae: 0.37423 | valid_rmse: 0.46426 | valid_mse: 0.21553 |  0:03:25s\n",
      "epoch 78 | loss: 0.20878 | train_rmsle: 0.01361 | train_mae: 0.36722 | train_rmse: 0.46528 | train_mse: 0.21648 | valid_rmsle: 0.01322 | valid_mae: 0.37442 | valid_rmse: 0.46522 | valid_mse: 0.21643 |  0:03:28s\n",
      "epoch 79 | loss: 0.20929 | train_rmsle: 0.01372 | train_mae: 0.37765 | train_rmse: 0.47106 | train_mse: 0.2219  | valid_rmsle: 0.01331 | valid_mae: 0.38155 | valid_rmse: 0.46981 | valid_mse: 0.22072 |  0:03:31s\n",
      "epoch 80 | loss: 0.20854 | train_rmsle: 0.01361 | train_mae: 0.36889 | train_rmse: 0.46592 | train_mse: 0.21708 | valid_rmsle: 0.01323 | valid_mae: 0.37602 | valid_rmse: 0.46581 | valid_mse: 0.21698 |  0:03:33s\n",
      "epoch 81 | loss: 0.21257 | train_rmsle: 0.01383 | train_mae: 0.36634 | train_rmse: 0.46767 | train_mse: 0.21872 | valid_rmsle: 0.01349 | valid_mae: 0.37294 | valid_rmse: 0.46803 | valid_mse: 0.21905 |  0:03:36s\n",
      "epoch 82 | loss: 0.2142  | train_rmsle: 0.01375 | train_mae: 0.37926 | train_rmse: 0.47231 | train_mse: 0.22308 | valid_rmsle: 0.01364 | valid_mae: 0.38735 | valid_rmse: 0.47664 | valid_mse: 0.22718 |  0:03:39s\n",
      "epoch 83 | loss: 0.21297 | train_rmsle: 0.01378 | train_mae: 0.38006 | train_rmse: 0.4728  | train_mse: 0.22354 | valid_rmsle: 0.01391 | valid_mae: 0.39111 | valid_rmse: 0.48148 | valid_mse: 0.23182 |  0:03:41s\n",
      "epoch 84 | loss: 0.21456 | train_rmsle: 0.01363 | train_mae: 0.37244 | train_rmse: 0.46747 | train_mse: 0.21853 | valid_rmsle: 0.01343 | valid_mae: 0.37916 | valid_rmse: 0.47021 | valid_mse: 0.22109 |  0:03:43s\n",
      "epoch 85 | loss: 0.21083 | train_rmsle: 0.0137  | train_mae: 0.37576 | train_rmse: 0.46951 | train_mse: 0.22044 | valid_rmsle: 0.0135  | valid_mae: 0.38023 | valid_rmse: 0.47177 | valid_mse: 0.22256 |  0:03:46s\n",
      "epoch 86 | loss: 0.21206 | train_rmsle: 0.01388 | train_mae: 0.36724 | train_rmse: 0.46842 | train_mse: 0.21942 | valid_rmsle: 0.01349 | valid_mae: 0.37006 | valid_rmse: 0.46719 | valid_mse: 0.21827 |  0:03:48s\n",
      "epoch 87 | loss: 0.21042 | train_rmsle: 0.01363 | train_mae: 0.37096 | train_rmse: 0.46658 | train_mse: 0.2177  | valid_rmsle: 0.01341 | valid_mae: 0.37658 | valid_rmse: 0.46853 | valid_mse: 0.21952 |  0:03:50s\n",
      "epoch 88 | loss: 0.20877 | train_rmsle: 0.01361 | train_mae: 0.37084 | train_rmse: 0.46645 | train_mse: 0.21757 | valid_rmsle: 0.01361 | valid_mae: 0.38144 | valid_rmse: 0.47329 | valid_mse: 0.22401 |  0:03:53s\n",
      "epoch 89 | loss: 0.20885 | train_rmsle: 0.01363 | train_mae: 0.36964 | train_rmse: 0.46597 | train_mse: 0.21713 | valid_rmsle: 0.01358 | valid_mae: 0.37958 | valid_rmse: 0.47195 | valid_mse: 0.22274 |  0:03:55s\n",
      "epoch 90 | loss: 0.20928 | train_rmsle: 0.01365 | train_mae: 0.36971 | train_rmse: 0.4663  | train_mse: 0.21744 | valid_rmsle: 0.01352 | valid_mae: 0.37816 | valid_rmse: 0.47062 | valid_mse: 0.22148 |  0:03:58s\n",
      "epoch 91 | loss: 0.21038 | train_rmsle: 0.0136  | train_mae: 0.37501 | train_rmse: 0.4681  | train_mse: 0.21912 | valid_rmsle: 0.01346 | valid_mae: 0.38317 | valid_rmse: 0.47232 | valid_mse: 0.22308 |  0:04:01s\n",
      "epoch 92 | loss: 0.20732 | train_rmsle: 0.01353 | train_mae: 0.36964 | train_rmse: 0.46503 | train_mse: 0.21625 | valid_rmsle: 0.01357 | valid_mae: 0.38148 | valid_rmse: 0.47235 | valid_mse: 0.22311 |  0:04:03s\n",
      "epoch 93 | loss: 0.20728 | train_rmsle: 0.01364 | train_mae: 0.36505 | train_rmse: 0.46442 | train_mse: 0.21568 | valid_rmsle: 0.01376 | valid_mae: 0.37735 | valid_rmse: 0.47312 | valid_mse: 0.22384 |  0:04:06s\n",
      "epoch 94 | loss: 0.20774 | train_rmsle: 0.01345 | train_mae: 0.36773 | train_rmse: 0.46358 | train_mse: 0.21491 | valid_rmsle: 0.01365 | valid_mae: 0.38218 | valid_rmse: 0.47397 | valid_mse: 0.22464 |  0:04:08s\n",
      "epoch 95 | loss: 0.20711 | train_rmsle: 0.01362 | train_mae: 0.36328 | train_rmse: 0.46367 | train_mse: 0.21499 | valid_rmsle: 0.01369 | valid_mae: 0.37644 | valid_rmse: 0.47183 | valid_mse: 0.22263 |  0:04:10s\n",
      "\n",
      "Early stopping occurred at epoch 95 with best_epoch = 75 and best_valid_mse = 0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21387850549948076 RMSE: 0.46247000497273416 R2: 0.05324226751470329 MAE: 0.3638193553172873\n",
      "=====================================\n",
      "[36/108] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.39831 | train_rmsle: 0.86702 | train_mae: 2.58602 | train_rmse: 2.63107 | train_mse: 6.92252 | valid_rmsle: 0.87081 | valid_mae: 2.59352 | valid_rmse: 2.63752 | valid_mse: 6.95654 |  0:00:02s\n",
      "epoch 1  | loss: 2.79417 | train_rmsle: 0.33039 | train_mae: 1.85282 | train_rmse: 1.9151  | train_mse: 3.66759 | valid_rmsle: 0.33152 | valid_mae: 1.85823 | valid_rmse: 1.9196  | valid_mse: 3.68487 |  0:00:05s\n",
      "epoch 2  | loss: 1.68546 | train_rmsle: 0.14234 | train_mae: 1.31002 | train_rmse: 1.39095 | train_mse: 1.93474 | valid_rmsle: 0.14284 | valid_mae: 1.31261 | valid_rmse: 1.3946  | valid_mse: 1.94492 |  0:00:08s\n",
      "epoch 3  | loss: 0.97534 | train_rmsle: 0.03686 | train_mae: 0.69025 | train_rmse: 0.784   | train_mse: 0.61465 | valid_rmsle: 0.03678 | valid_mae: 0.69008 | valid_rmse: 0.78578 | valid_mse: 0.61746 |  0:00:10s\n",
      "epoch 4  | loss: 0.55782 | train_rmsle: 0.02265 | train_mae: 0.53273 | train_rmse: 0.62284 | train_mse: 0.38793 | valid_rmsle: 0.0224  | valid_mae: 0.53451 | valid_rmse: 0.62319 | valid_mse: 0.38837 |  0:00:13s\n",
      "epoch 5  | loss: 0.4022  | train_rmsle: 0.01809 | train_mae: 0.46611 | train_rmse: 0.55427 | train_mse: 0.30721 | valid_rmsle: 0.01774 | valid_mae: 0.4678  | valid_rmse: 0.55338 | valid_mse: 0.30623 |  0:00:16s\n",
      "epoch 6  | loss: 0.34074 | train_rmsle: 0.02227 | train_mae: 0.52819 | train_rmse: 0.61768 | train_mse: 0.38152 | valid_rmsle: 0.022   | valid_mae: 0.52954 | valid_rmse: 0.61804 | valid_mse: 0.38197 |  0:00:19s\n",
      "epoch 7  | loss: 0.31281 | train_rmsle: 0.01748 | train_mae: 0.45588 | train_rmse: 0.5439  | train_mse: 0.29583 | valid_rmsle: 0.01709 | valid_mae: 0.45696 | valid_rmse: 0.54259 | valid_mse: 0.2944  |  0:00:21s\n",
      "epoch 8  | loss: 0.28    | train_rmsle: 0.01647 | train_mae: 0.43727 | train_rmse: 0.52567 | train_mse: 0.27633 | valid_rmsle: 0.01604 | valid_mae: 0.43818 | valid_rmse: 0.52384 | valid_mse: 0.27441 |  0:00:24s\n",
      "epoch 9  | loss: 0.26637 | train_rmsle: 0.01562 | train_mae: 0.41889 | train_rmse: 0.50884 | train_mse: 0.25892 | valid_rmsle: 0.01512 | valid_mae: 0.41959 | valid_rmse: 0.50576 | valid_mse: 0.2558  |  0:00:27s\n",
      "epoch 10 | loss: 0.26164 | train_rmsle: 0.01617 | train_mae: 0.43123 | train_rmse: 0.52008 | train_mse: 0.27048 | valid_rmsle: 0.01565 | valid_mae: 0.43161 | valid_rmse: 0.51686 | valid_mse: 0.26714 |  0:00:30s\n",
      "epoch 11 | loss: 0.25288 | train_rmsle: 0.01583 | train_mae: 0.42392 | train_rmse: 0.51337 | train_mse: 0.26355 | valid_rmsle: 0.0153  | valid_mae: 0.42438 | valid_rmse: 0.50991 | valid_mse: 0.26001 |  0:00:32s\n",
      "epoch 12 | loss: 0.2418  | train_rmsle: 0.01547 | train_mae: 0.41577 | train_rmse: 0.50594 | train_mse: 0.25598 | valid_rmsle: 0.01497 | valid_mae: 0.4157  | valid_rmse: 0.50288 | valid_mse: 0.25289 |  0:00:35s\n",
      "epoch 13 | loss: 0.24466 | train_rmsle: 0.01703 | train_mae: 0.44814 | train_rmse: 0.53644 | train_mse: 0.28777 | valid_rmsle: 0.01669 | valid_mae: 0.44999 | valid_rmse: 0.53606 | valid_mse: 0.28736 |  0:00:38s\n",
      "epoch 14 | loss: 0.24656 | train_rmsle: 0.01798 | train_mae: 0.46475 | train_rmse: 0.55293 | train_mse: 0.30573 | valid_rmsle: 0.01765 | valid_mae: 0.46675 | valid_rmse: 0.55254 | valid_mse: 0.3053  |  0:00:41s\n",
      "epoch 15 | loss: 0.24272 | train_rmsle: 0.01563 | train_mae: 0.42052 | train_rmse: 0.51012 | train_mse: 0.26022 | valid_rmsle: 0.01523 | valid_mae: 0.4229  | valid_rmse: 0.50892 | valid_mse: 0.259   |  0:00:43s\n",
      "epoch 16 | loss: 0.23783 | train_rmsle: 0.01755 | train_mae: 0.45747 | train_rmse: 0.54547 | train_mse: 0.29754 | valid_rmsle: 0.01728 | valid_mae: 0.46008 | valid_rmse: 0.54619 | valid_mse: 0.29833 |  0:00:46s\n",
      "epoch 17 | loss: 0.23596 | train_rmsle: 0.01632 | train_mae: 0.43423 | train_rmse: 0.52321 | train_mse: 0.27375 | valid_rmsle: 0.01595 | valid_mae: 0.43637 | valid_rmse: 0.52252 | valid_mse: 0.27303 |  0:00:49s\n",
      "epoch 18 | loss: 0.23105 | train_rmsle: 0.01594 | train_mae: 0.42727 | train_rmse: 0.51623 | train_mse: 0.2665  | valid_rmsle: 0.01556 | valid_mae: 0.42869 | valid_rmse: 0.51551 | valid_mse: 0.26575 |  0:00:51s\n",
      "epoch 19 | loss: 0.23873 | train_rmsle: 0.01499 | train_mae: 0.40395 | train_rmse: 0.49606 | train_mse: 0.24608 | valid_rmsle: 0.01447 | valid_mae: 0.40388 | valid_rmse: 0.49253 | valid_mse: 0.24259 |  0:00:54s\n",
      "epoch 20 | loss: 0.23323 | train_rmsle: 0.01492 | train_mae: 0.40327 | train_rmse: 0.49485 | train_mse: 0.24488 | valid_rmsle: 0.01458 | valid_mae: 0.40677 | valid_rmse: 0.49463 | valid_mse: 0.24466 |  0:00:57s\n",
      "epoch 21 | loss: 0.23143 | train_rmsle: 0.01588 | train_mae: 0.42537 | train_rmse: 0.51479 | train_mse: 0.26501 | valid_rmsle: 0.01548 | valid_mae: 0.42782 | valid_rmse: 0.51366 | valid_mse: 0.26385 |  0:00:59s\n",
      "epoch 22 | loss: 0.2311  | train_rmsle: 0.01586 | train_mae: 0.42628 | train_rmse: 0.51465 | train_mse: 0.26487 | valid_rmsle: 0.0155  | valid_mae: 0.42791 | valid_rmse: 0.51402 | valid_mse: 0.26422 |  0:01:02s\n",
      "epoch 23 | loss: 0.23317 | train_rmsle: 0.01502 | train_mae: 0.40676 | train_rmse: 0.49705 | train_mse: 0.24706 | valid_rmsle: 0.01459 | valid_mae: 0.40787 | valid_rmse: 0.49549 | valid_mse: 0.24551 |  0:01:04s\n",
      "epoch 24 | loss: 0.23322 | train_rmsle: 0.01455 | train_mae: 0.39318 | train_rmse: 0.48616 | train_mse: 0.23635 | valid_rmsle: 0.01422 | valid_mae: 0.3983  | valid_rmse: 0.48667 | valid_mse: 0.23685 |  0:01:07s\n",
      "epoch 25 | loss: 0.22772 | train_rmsle: 0.01533 | train_mae: 0.41334 | train_rmse: 0.504   | train_mse: 0.25402 | valid_rmsle: 0.01501 | valid_mae: 0.41792 | valid_rmse: 0.50458 | valid_mse: 0.2546  |  0:01:09s\n",
      "epoch 26 | loss: 0.22791 | train_rmsle: 0.01541 | train_mae: 0.41515 | train_rmse: 0.50574 | train_mse: 0.25577 | valid_rmsle: 0.01508 | valid_mae: 0.41803 | valid_rmse: 0.50592 | valid_mse: 0.25595 |  0:01:11s\n",
      "epoch 27 | loss: 0.23602 | train_rmsle: 0.01714 | train_mae: 0.45014 | train_rmse: 0.53869 | train_mse: 0.29019 | valid_rmsle: 0.01719 | valid_mae: 0.45685 | valid_rmse: 0.54432 | valid_mse: 0.29629 |  0:01:14s\n",
      "epoch 28 | loss: 0.22977 | train_rmsle: 0.01455 | train_mae: 0.39109 | train_rmse: 0.48565 | train_mse: 0.23586 | valid_rmsle: 0.01417 | valid_mae: 0.39274 | valid_rmse: 0.48497 | valid_mse: 0.23519 |  0:01:17s\n",
      "epoch 29 | loss: 0.22818 | train_rmsle: 0.01494 | train_mae: 0.40433 | train_rmse: 0.49556 | train_mse: 0.24558 | valid_rmsle: 0.01459 | valid_mae: 0.40678 | valid_rmse: 0.49551 | valid_mse: 0.24553 |  0:01:19s\n",
      "epoch 30 | loss: 0.225   | train_rmsle: 0.01535 | train_mae: 0.41246 | train_rmse: 0.50353 | train_mse: 0.25354 | valid_rmsle: 0.01512 | valid_mae: 0.41686 | valid_rmse: 0.50512 | valid_mse: 0.25514 |  0:01:21s\n",
      "epoch 31 | loss: 0.22473 | train_rmsle: 0.01446 | train_mae: 0.38662 | train_rmse: 0.48307 | train_mse: 0.23336 | valid_rmsle: 0.01393 | valid_mae: 0.38758 | valid_rmse: 0.47941 | valid_mse: 0.22983 |  0:01:24s\n",
      "epoch 32 | loss: 0.22381 | train_rmsle: 0.01446 | train_mae: 0.38815 | train_rmse: 0.48368 | train_mse: 0.23395 | valid_rmsle: 0.01396 | valid_mae: 0.38917 | valid_rmse: 0.48057 | valid_mse: 0.23095 |  0:01:26s\n",
      "epoch 33 | loss: 0.22346 | train_rmsle: 0.01448 | train_mae: 0.39028 | train_rmse: 0.48431 | train_mse: 0.23455 | valid_rmsle: 0.01399 | valid_mae: 0.39028 | valid_rmse: 0.48123 | valid_mse: 0.23158 |  0:01:28s\n",
      "epoch 34 | loss: 0.22986 | train_rmsle: 0.01544 | train_mae: 0.41641 | train_rmse: 0.50669 | train_mse: 0.25674 | valid_rmsle: 0.01506 | valid_mae: 0.4185  | valid_rmse: 0.50601 | valid_mse: 0.25605 |  0:01:30s\n",
      "epoch 35 | loss: 0.22958 | train_rmsle: 0.01465 | train_mae: 0.39147 | train_rmse: 0.487   | train_mse: 0.23717 | valid_rmsle: 0.01421 | valid_mae: 0.39399 | valid_rmse: 0.48531 | valid_mse: 0.23553 |  0:01:33s\n",
      "epoch 36 | loss: 0.22319 | train_rmsle: 0.01438 | train_mae: 0.38123 | train_rmse: 0.47978 | train_mse: 0.23019 | valid_rmsle: 0.01409 | valid_mae: 0.38705 | valid_rmse: 0.4807  | valid_mse: 0.23108 |  0:01:36s\n",
      "epoch 37 | loss: 0.22563 | train_rmsle: 0.01448 | train_mae: 0.3886  | train_rmse: 0.48414 | train_mse: 0.23439 | valid_rmsle: 0.01418 | valid_mae: 0.39427 | valid_rmse: 0.48473 | valid_mse: 0.23496 |  0:01:38s\n",
      "epoch 38 | loss: 0.22237 | train_rmsle: 0.01475 | train_mae: 0.3981  | train_rmse: 0.49116 | train_mse: 0.24124 | valid_rmsle: 0.0144  | valid_mae: 0.39996 | valid_rmse: 0.49089 | valid_mse: 0.24098 |  0:01:41s\n",
      "epoch 39 | loss: 0.2197  | train_rmsle: 0.01447 | train_mae: 0.3873  | train_rmse: 0.48341 | train_mse: 0.23369 | valid_rmsle: 0.01396 | valid_mae: 0.38683 | valid_rmse: 0.48024 | valid_mse: 0.23063 |  0:01:44s\n",
      "epoch 40 | loss: 0.22092 | train_rmsle: 0.01461 | train_mae: 0.3947  | train_rmse: 0.48832 | train_mse: 0.23846 | valid_rmsle: 0.01437 | valid_mae: 0.39939 | valid_rmse: 0.49007 | valid_mse: 0.24017 |  0:01:47s\n",
      "epoch 41 | loss: 0.22154 | train_rmsle: 0.01448 | train_mae: 0.38163 | train_rmse: 0.48096 | train_mse: 0.23132 | valid_rmsle: 0.01391 | valid_mae: 0.38223 | valid_rmse: 0.47714 | valid_mse: 0.22767 |  0:01:50s\n",
      "epoch 42 | loss: 0.22257 | train_rmsle: 0.01446 | train_mae: 0.38553 | train_rmse: 0.4824  | train_mse: 0.23271 | valid_rmsle: 0.01423 | valid_mae: 0.39002 | valid_rmse: 0.48409 | valid_mse: 0.23435 |  0:01:52s\n",
      "epoch 43 | loss: 0.22406 | train_rmsle: 0.01442 | train_mae: 0.38144 | train_rmse: 0.48066 | train_mse: 0.23103 | valid_rmsle: 0.01402 | valid_mae: 0.38273 | valid_rmse: 0.47926 | valid_mse: 0.22969 |  0:01:55s\n",
      "epoch 44 | loss: 0.22203 | train_rmsle: 0.01449 | train_mae: 0.388   | train_rmse: 0.48401 | train_mse: 0.23426 | valid_rmsle: 0.01434 | valid_mae: 0.39409 | valid_rmse: 0.48755 | valid_mse: 0.23771 |  0:01:58s\n",
      "epoch 45 | loss: 0.22265 | train_rmsle: 0.01437 | train_mae: 0.3841  | train_rmse: 0.48091 | train_mse: 0.23128 | valid_rmsle: 0.01405 | valid_mae: 0.38811 | valid_rmse: 0.48109 | valid_mse: 0.23145 |  0:02:00s\n",
      "epoch 46 | loss: 0.22359 | train_rmsle: 0.01464 | train_mae: 0.37764 | train_rmse: 0.482   | train_mse: 0.23232 | valid_rmsle: 0.01438 | valid_mae: 0.38227 | valid_rmse: 0.48374 | valid_mse: 0.234   |  0:02:03s\n",
      "epoch 47 | loss: 0.22226 | train_rmsle: 0.01476 | train_mae: 0.37648 | train_rmse: 0.4827  | train_mse: 0.233   | valid_rmsle: 0.01433 | valid_mae: 0.38093 | valid_rmse: 0.48159 | valid_mse: 0.23193 |  0:02:06s\n",
      "epoch 48 | loss: 0.23538 | train_rmsle: 0.01425 | train_mae: 0.3819  | train_rmse: 0.47884 | train_mse: 0.22929 | valid_rmsle: 0.0138  | valid_mae: 0.38359 | valid_rmse: 0.47718 | valid_mse: 0.2277  |  0:02:08s\n",
      "epoch 49 | loss: 0.2247  | train_rmsle: 0.01414 | train_mae: 0.37987 | train_rmse: 0.47636 | train_mse: 0.22692 | valid_rmsle: 0.01363 | valid_mae: 0.38208 | valid_rmse: 0.47405 | valid_mse: 0.22473 |  0:02:11s\n",
      "epoch 50 | loss: 0.21642 | train_rmsle: 0.01403 | train_mae: 0.38222 | train_rmse: 0.47629 | train_mse: 0.22685 | valid_rmsle: 0.01382 | valid_mae: 0.39113 | valid_rmse: 0.47905 | valid_mse: 0.22949 |  0:02:14s\n",
      "epoch 51 | loss: 0.2176  | train_rmsle: 0.01419 | train_mae: 0.38079 | train_rmse: 0.47763 | train_mse: 0.22813 | valid_rmsle: 0.01385 | valid_mae: 0.38573 | valid_rmse: 0.4778  | valid_mse: 0.2283  |  0:02:17s\n",
      "epoch 52 | loss: 0.2209  | train_rmsle: 0.01405 | train_mae: 0.37912 | train_rmse: 0.47504 | train_mse: 0.22566 | valid_rmsle: 0.01376 | valid_mae: 0.38631 | valid_rmse: 0.47658 | valid_mse: 0.22713 |  0:02:19s\n",
      "epoch 53 | loss: 0.21516 | train_rmsle: 0.01403 | train_mae: 0.37604 | train_rmse: 0.47319 | train_mse: 0.22391 | valid_rmsle: 0.01371 | valid_mae: 0.38101 | valid_rmse: 0.47391 | valid_mse: 0.22459 |  0:02:22s\n",
      "epoch 54 | loss: 0.2174  | train_rmsle: 0.01405 | train_mae: 0.37611 | train_rmse: 0.47396 | train_mse: 0.22464 | valid_rmsle: 0.01392 | valid_mae: 0.38472 | valid_rmse: 0.47819 | valid_mse: 0.22866 |  0:02:25s\n",
      "epoch 55 | loss: 0.21691 | train_rmsle: 0.01443 | train_mae: 0.37878 | train_rmse: 0.47911 | train_mse: 0.22955 | valid_rmsle: 0.01424 | valid_mae: 0.38787 | valid_rmse: 0.48308 | valid_mse: 0.23336 |  0:02:27s\n",
      "epoch 56 | loss: 0.2165  | train_rmsle: 0.0141  | train_mae: 0.3784  | train_rmse: 0.47553 | train_mse: 0.22613 | valid_rmsle: 0.0141  | valid_mae: 0.38738 | valid_rmse: 0.4818  | valid_mse: 0.23213 |  0:02:30s\n",
      "epoch 57 | loss: 0.21585 | train_rmsle: 0.01552 | train_mae: 0.37856 | train_rmse: 0.49376 | train_mse: 0.2438  | valid_rmsle: 0.01499 | valid_mae: 0.38628 | valid_rmse: 0.49166 | valid_mse: 0.24173 |  0:02:33s\n",
      "epoch 58 | loss: 0.22204 | train_rmsle: 0.01405 | train_mae: 0.37304 | train_rmse: 0.47267 | train_mse: 0.22342 | valid_rmsle: 0.0139  | valid_mae: 0.38014 | valid_rmse: 0.47557 | valid_mse: 0.22616 |  0:02:35s\n",
      "epoch 59 | loss: 0.2144  | train_rmsle: 0.01405 | train_mae: 0.38099 | train_rmse: 0.47591 | train_mse: 0.22649 | valid_rmsle: 0.01402 | valid_mae: 0.38707 | valid_rmse: 0.47939 | valid_mse: 0.22981 |  0:02:38s\n",
      "epoch 60 | loss: 0.21427 | train_rmsle: 0.01411 | train_mae: 0.37329 | train_rmse: 0.47367 | train_mse: 0.22437 | valid_rmsle: 0.01374 | valid_mae: 0.38132 | valid_rmse: 0.47329 | valid_mse: 0.224   |  0:02:41s\n",
      "epoch 61 | loss: 0.21575 | train_rmsle: 0.01412 | train_mae: 0.38295 | train_rmse: 0.478   | train_mse: 0.22849 | valid_rmsle: 0.01372 | valid_mae: 0.38564 | valid_rmse: 0.47661 | valid_mse: 0.22716 |  0:02:44s\n",
      "epoch 62 | loss: 0.21536 | train_rmsle: 0.01402 | train_mae: 0.37365 | train_rmse: 0.47282 | train_mse: 0.22356 | valid_rmsle: 0.01373 | valid_mae: 0.38061 | valid_rmse: 0.47394 | valid_mse: 0.22462 |  0:02:47s\n",
      "epoch 63 | loss: 0.21726 | train_rmsle: 0.01411 | train_mae: 0.38575 | train_rmse: 0.47889 | train_mse: 0.22934 | valid_rmsle: 0.01385 | valid_mae: 0.39093 | valid_rmse: 0.48164 | valid_mse: 0.23198 |  0:02:49s\n",
      "epoch 64 | loss: 0.21318 | train_rmsle: 0.01398 | train_mae: 0.37296 | train_rmse: 0.4723  | train_mse: 0.22307 | valid_rmsle: 0.01361 | valid_mae: 0.37695 | valid_rmse: 0.47184 | valid_mse: 0.22263 |  0:02:51s\n",
      "epoch 65 | loss: 0.21317 | train_rmsle: 0.01385 | train_mae: 0.37986 | train_rmse: 0.47339 | train_mse: 0.2241  | valid_rmsle: 0.01351 | valid_mae: 0.38287 | valid_rmse: 0.47314 | valid_mse: 0.22387 |  0:02:54s\n",
      "epoch 66 | loss: 0.21312 | train_rmsle: 0.01402 | train_mae: 0.38682 | train_rmse: 0.47812 | train_mse: 0.2286  | valid_rmsle: 0.0138  | valid_mae: 0.39097 | valid_rmse: 0.47999 | valid_mse: 0.23039 |  0:02:56s\n",
      "epoch 67 | loss: 0.21007 | train_rmsle: 0.0139  | train_mae: 0.3699  | train_rmse: 0.46952 | train_mse: 0.22045 | valid_rmsle: 0.01364 | valid_mae: 0.37571 | valid_rmse: 0.47083 | valid_mse: 0.22168 |  0:02:59s\n",
      "epoch 68 | loss: 0.21085 | train_rmsle: 0.01376 | train_mae: 0.37693 | train_rmse: 0.47074 | train_mse: 0.2216  | valid_rmsle: 0.01362 | valid_mae: 0.38504 | valid_rmse: 0.47403 | valid_mse: 0.2247  |  0:03:01s\n",
      "epoch 69 | loss: 0.2116  | train_rmsle: 0.01375 | train_mae: 0.37125 | train_rmse: 0.46828 | train_mse: 0.21928 | valid_rmsle: 0.01352 | valid_mae: 0.37693 | valid_rmse: 0.46991 | valid_mse: 0.22082 |  0:03:03s\n",
      "epoch 70 | loss: 0.21237 | train_rmsle: 0.01369 | train_mae: 0.37356 | train_rmse: 0.46861 | train_mse: 0.2196  | valid_rmsle: 0.01356 | valid_mae: 0.38147 | valid_rmse: 0.47242 | valid_mse: 0.22318 |  0:03:05s\n",
      "epoch 71 | loss: 0.20871 | train_rmsle: 0.01386 | train_mae: 0.3839  | train_rmse: 0.47554 | train_mse: 0.22613 | valid_rmsle: 0.01373 | valid_mae: 0.393   | valid_rmse: 0.4794  | valid_mse: 0.22983 |  0:03:08s\n",
      "epoch 72 | loss: 0.21099 | train_rmsle: 0.01364 | train_mae: 0.37393 | train_rmse: 0.46877 | train_mse: 0.21974 | valid_rmsle: 0.01342 | valid_mae: 0.38563 | valid_rmse: 0.4715  | valid_mse: 0.22231 |  0:03:10s\n",
      "epoch 73 | loss: 0.20898 | train_rmsle: 0.01355 | train_mae: 0.36687 | train_rmse: 0.46451 | train_mse: 0.21577 | valid_rmsle: 0.01322 | valid_mae: 0.37699 | valid_rmse: 0.46529 | valid_mse: 0.21649 |  0:03:12s\n",
      "epoch 74 | loss: 0.20843 | train_rmsle: 0.0135  | train_mae: 0.36871 | train_rmse: 0.46477 | train_mse: 0.21601 | valid_rmsle: 0.01305 | valid_mae: 0.37647 | valid_rmse: 0.46307 | valid_mse: 0.21443 |  0:03:15s\n",
      "epoch 75 | loss: 0.20992 | train_rmsle: 0.01362 | train_mae: 0.36646 | train_rmse: 0.46486 | train_mse: 0.21609 | valid_rmsle: 0.01313 | valid_mae: 0.37161 | valid_rmse: 0.46238 | valid_mse: 0.2138  |  0:03:18s\n",
      "epoch 76 | loss: 0.20838 | train_rmsle: 0.01352 | train_mae: 0.36865 | train_rmse: 0.46477 | train_mse: 0.21602 | valid_rmsle: 0.01318 | valid_mae: 0.37527 | valid_rmse: 0.46459 | valid_mse: 0.21584 |  0:03:21s\n",
      "epoch 77 | loss: 0.2061  | train_rmsle: 0.01361 | train_mae: 0.36732 | train_rmse: 0.46515 | train_mse: 0.21637 | valid_rmsle: 0.01322 | valid_mae: 0.37423 | valid_rmse: 0.46426 | valid_mse: 0.21553 |  0:03:23s\n",
      "epoch 78 | loss: 0.20878 | train_rmsle: 0.01361 | train_mae: 0.36722 | train_rmse: 0.46528 | train_mse: 0.21648 | valid_rmsle: 0.01322 | valid_mae: 0.37442 | valid_rmse: 0.46522 | valid_mse: 0.21643 |  0:03:26s\n",
      "epoch 79 | loss: 0.20929 | train_rmsle: 0.01372 | train_mae: 0.37765 | train_rmse: 0.47106 | train_mse: 0.2219  | valid_rmsle: 0.01331 | valid_mae: 0.38155 | valid_rmse: 0.46981 | valid_mse: 0.22072 |  0:03:29s\n",
      "epoch 80 | loss: 0.20854 | train_rmsle: 0.01361 | train_mae: 0.36889 | train_rmse: 0.46592 | train_mse: 0.21708 | valid_rmsle: 0.01323 | valid_mae: 0.37602 | valid_rmse: 0.46581 | valid_mse: 0.21698 |  0:03:31s\n",
      "epoch 81 | loss: 0.21257 | train_rmsle: 0.01383 | train_mae: 0.36634 | train_rmse: 0.46767 | train_mse: 0.21872 | valid_rmsle: 0.01349 | valid_mae: 0.37294 | valid_rmse: 0.46803 | valid_mse: 0.21905 |  0:03:34s\n",
      "epoch 82 | loss: 0.2142  | train_rmsle: 0.01375 | train_mae: 0.37926 | train_rmse: 0.47231 | train_mse: 0.22308 | valid_rmsle: 0.01364 | valid_mae: 0.38735 | valid_rmse: 0.47664 | valid_mse: 0.22718 |  0:03:37s\n",
      "epoch 83 | loss: 0.21297 | train_rmsle: 0.01378 | train_mae: 0.38006 | train_rmse: 0.4728  | train_mse: 0.22354 | valid_rmsle: 0.01391 | valid_mae: 0.39111 | valid_rmse: 0.48148 | valid_mse: 0.23182 |  0:03:39s\n",
      "epoch 84 | loss: 0.21456 | train_rmsle: 0.01363 | train_mae: 0.37244 | train_rmse: 0.46747 | train_mse: 0.21853 | valid_rmsle: 0.01343 | valid_mae: 0.37916 | valid_rmse: 0.47021 | valid_mse: 0.22109 |  0:03:42s\n",
      "epoch 85 | loss: 0.21083 | train_rmsle: 0.0137  | train_mae: 0.37576 | train_rmse: 0.46951 | train_mse: 0.22044 | valid_rmsle: 0.0135  | valid_mae: 0.38023 | valid_rmse: 0.47177 | valid_mse: 0.22256 |  0:03:45s\n",
      "epoch 86 | loss: 0.21206 | train_rmsle: 0.01388 | train_mae: 0.36724 | train_rmse: 0.46842 | train_mse: 0.21942 | valid_rmsle: 0.01349 | valid_mae: 0.37006 | valid_rmse: 0.46719 | valid_mse: 0.21827 |  0:03:48s\n",
      "epoch 87 | loss: 0.21042 | train_rmsle: 0.01363 | train_mae: 0.37096 | train_rmse: 0.46658 | train_mse: 0.2177  | valid_rmsle: 0.01341 | valid_mae: 0.37658 | valid_rmse: 0.46853 | valid_mse: 0.21952 |  0:03:50s\n",
      "epoch 88 | loss: 0.20877 | train_rmsle: 0.01361 | train_mae: 0.37084 | train_rmse: 0.46645 | train_mse: 0.21757 | valid_rmsle: 0.01361 | valid_mae: 0.38144 | valid_rmse: 0.47329 | valid_mse: 0.22401 |  0:03:53s\n",
      "epoch 89 | loss: 0.20885 | train_rmsle: 0.01363 | train_mae: 0.36964 | train_rmse: 0.46597 | train_mse: 0.21713 | valid_rmsle: 0.01358 | valid_mae: 0.37958 | valid_rmse: 0.47195 | valid_mse: 0.22274 |  0:03:56s\n",
      "epoch 90 | loss: 0.20928 | train_rmsle: 0.01365 | train_mae: 0.36971 | train_rmse: 0.4663  | train_mse: 0.21744 | valid_rmsle: 0.01352 | valid_mae: 0.37816 | valid_rmse: 0.47062 | valid_mse: 0.22148 |  0:03:58s\n",
      "epoch 91 | loss: 0.21038 | train_rmsle: 0.0136  | train_mae: 0.37501 | train_rmse: 0.4681  | train_mse: 0.21912 | valid_rmsle: 0.01346 | valid_mae: 0.38317 | valid_rmse: 0.47232 | valid_mse: 0.22308 |  0:04:01s\n",
      "epoch 92 | loss: 0.20732 | train_rmsle: 0.01353 | train_mae: 0.36964 | train_rmse: 0.46503 | train_mse: 0.21625 | valid_rmsle: 0.01357 | valid_mae: 0.38148 | valid_rmse: 0.47235 | valid_mse: 0.22311 |  0:04:04s\n",
      "epoch 93 | loss: 0.20728 | train_rmsle: 0.01364 | train_mae: 0.36505 | train_rmse: 0.46442 | train_mse: 0.21568 | valid_rmsle: 0.01376 | valid_mae: 0.37735 | valid_rmse: 0.47312 | valid_mse: 0.22384 |  0:04:07s\n",
      "epoch 94 | loss: 0.20774 | train_rmsle: 0.01345 | train_mae: 0.36773 | train_rmse: 0.46358 | train_mse: 0.21491 | valid_rmsle: 0.01365 | valid_mae: 0.38218 | valid_rmse: 0.47397 | valid_mse: 0.22464 |  0:04:09s\n",
      "epoch 95 | loss: 0.20711 | train_rmsle: 0.01362 | train_mae: 0.36328 | train_rmse: 0.46367 | train_mse: 0.21499 | valid_rmsle: 0.01369 | valid_mae: 0.37644 | valid_rmse: 0.47183 | valid_mse: 0.22263 |  0:04:12s\n",
      "\n",
      "Early stopping occurred at epoch 95 with best_epoch = 75 and best_valid_mse = 0.2138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21387850549948076 RMSE: 0.46247000497273416 R2: 0.05324226751470329 MAE: 0.3638193553172873\n",
      "=====================================\n",
      "[37/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25806 | train_rmsle: 0.16137 | train_mae: 1.38403 | train_rmse: 1.4619  | train_mse: 2.13715 | valid_rmsle: 0.16213 | valid_mae: 1.38796 | valid_rmse: 1.46633 | valid_mse: 2.15013 |  0:00:01s\n",
      "epoch 1  | loss: 0.35967 | train_rmsle: 0.1098  | train_mae: 1.16754 | train_rmse: 1.25285 | train_mse: 1.56962 | valid_rmsle: 0.11029 | valid_mae: 1.17063 | valid_rmse: 1.25685 | valid_mse: 1.57967 |  0:00:03s\n",
      "epoch 2  | loss: 0.26771 | train_rmsle: 0.05449 | train_mae: 0.83962 | train_rmse: 0.9326  | train_mse: 0.86975 | valid_rmsle: 0.05448 | valid_mae: 0.83979 | valid_rmse: 0.93468 | valid_mse: 0.87362 |  0:00:05s\n",
      "epoch 3  | loss: 0.24587 | train_rmsle: 0.04306 | train_mae: 0.74839 | train_rmse: 0.84082 | train_mse: 0.70698 | valid_rmsle: 0.04307 | valid_mae: 0.74848 | valid_rmse: 0.84329 | valid_mse: 0.71113 |  0:00:06s\n",
      "epoch 4  | loss: 0.23121 | train_rmsle: 0.03004 | train_mae: 0.62193 | train_rmse: 0.71342 | train_mse: 0.50897 | valid_rmsle: 0.0298  | valid_mae: 0.62106 | valid_rmse: 0.71382 | valid_mse: 0.50954 |  0:00:08s\n",
      "epoch 5  | loss: 0.22596 | train_rmsle: 0.02275 | train_mae: 0.53581 | train_rmse: 0.62461 | train_mse: 0.39013 | valid_rmsle: 0.02247 | valid_mae: 0.53654 | valid_rmse: 0.62461 | valid_mse: 0.39014 |  0:00:09s\n",
      "epoch 6  | loss: 0.22236 | train_rmsle: 0.01826 | train_mae: 0.47077 | train_rmse: 0.55789 | train_mse: 0.31124 | valid_rmsle: 0.01788 | valid_mae: 0.47163 | valid_rmse: 0.55679 | valid_mse: 0.31002 |  0:00:11s\n",
      "epoch 7  | loss: 0.22582 | train_rmsle: 0.02021 | train_mae: 0.50115 | train_rmse: 0.5888  | train_mse: 0.34668 | valid_rmsle: 0.01978 | valid_mae: 0.50044 | valid_rmse: 0.5869  | valid_mse: 0.34445 |  0:00:12s\n",
      "epoch 8  | loss: 0.21553 | train_rmsle: 0.01476 | train_mae: 0.40632 | train_rmse: 0.49404 | train_mse: 0.24408 | valid_rmsle: 0.01437 | valid_mae: 0.40816 | valid_rmse: 0.49319 | valid_mse: 0.24324 |  0:00:13s\n",
      "epoch 9  | loss: 0.21478 | train_rmsle: 0.01394 | train_mae: 0.38402 | train_rmse: 0.47518 | train_mse: 0.2258  | valid_rmsle: 0.01347 | valid_mae: 0.38605 | valid_rmse: 0.47299 | valid_mse: 0.22372 |  0:00:14s\n",
      "epoch 10 | loss: 0.20802 | train_rmsle: 0.01418 | train_mae: 0.39695 | train_rmse: 0.48372 | train_mse: 0.23398 | valid_rmsle: 0.01378 | valid_mae: 0.39878 | valid_rmse: 0.48243 | valid_mse: 0.23274 |  0:00:16s\n",
      "epoch 11 | loss: 0.19951 | train_rmsle: 0.01288 | train_mae: 0.36244 | train_rmse: 0.45301 | train_mse: 0.20521 | valid_rmsle: 0.01236 | valid_mae: 0.36298 | valid_rmse: 0.4491  | valid_mse: 0.20169 |  0:00:17s\n",
      "epoch 12 | loss: 0.19172 | train_rmsle: 0.01226 | train_mae: 0.35579 | train_rmse: 0.44341 | train_mse: 0.19661 | valid_rmsle: 0.01177 | valid_mae: 0.35707 | valid_rmse: 0.44025 | valid_mse: 0.19382 |  0:00:18s\n",
      "epoch 13 | loss: 0.18183 | train_rmsle: 0.01018 | train_mae: 0.32981 | train_rmse: 0.40615 | train_mse: 0.16495 | valid_rmsle: 0.0098  | valid_mae: 0.33154 | valid_rmse: 0.40489 | valid_mse: 0.16394 |  0:00:19s\n",
      "epoch 14 | loss: 0.16379 | train_rmsle: 0.01151 | train_mae: 0.37106 | train_rmse: 0.43952 | train_mse: 0.19318 | valid_rmsle: 0.01144 | valid_mae: 0.37338 | valid_rmse: 0.44292 | valid_mse: 0.19618 |  0:00:21s\n",
      "epoch 15 | loss: 0.13555 | train_rmsle: 0.01054 | train_mae: 0.34695 | train_rmse: 0.41495 | train_mse: 0.17218 | valid_rmsle: 0.01028 | valid_mae: 0.3468  | valid_rmse: 0.41435 | valid_mse: 0.17169 |  0:00:22s\n",
      "epoch 16 | loss: 0.11419 | train_rmsle: 0.01237 | train_mae: 0.37178 | train_rmse: 0.44283 | train_mse: 0.1961  | valid_rmsle: 0.0122  | valid_mae: 0.37391 | valid_rmse: 0.44374 | valid_mse: 0.1969  |  0:00:24s\n",
      "epoch 17 | loss: 0.09763 | train_rmsle: 0.00908 | train_mae: 0.31585 | train_rmse: 0.3803  | train_mse: 0.14463 | valid_rmsle: 0.00877 | valid_mae: 0.31503 | valid_rmse: 0.37813 | valid_mse: 0.14298 |  0:00:25s\n",
      "epoch 18 | loss: 0.08568 | train_rmsle: 0.00774 | train_mae: 0.28534 | train_rmse: 0.34781 | train_mse: 0.12097 | valid_rmsle: 0.00742 | valid_mae: 0.28446 | valid_rmse: 0.34379 | valid_mse: 0.11819 |  0:00:27s\n",
      "epoch 19 | loss: 0.07544 | train_rmsle: 0.00495 | train_mae: 0.22748 | train_rmse: 0.28089 | train_mse: 0.0789  | valid_rmsle: 0.00477 | valid_mae: 0.22821 | valid_rmse: 0.27867 | valid_mse: 0.07766 |  0:00:28s\n",
      "epoch 20 | loss: 0.06821 | train_rmsle: 0.00429 | train_mae: 0.22137 | train_rmse: 0.27036 | train_mse: 0.07309 | valid_rmsle: 0.00427 | valid_mae: 0.22409 | valid_rmse: 0.2728  | valid_mse: 0.07442 |  0:00:30s\n",
      "epoch 21 | loss: 0.05828 | train_rmsle: 0.00293 | train_mae: 0.17773 | train_rmse: 0.22461 | train_mse: 0.05045 | valid_rmsle: 0.00288 | valid_mae: 0.18163 | valid_rmse: 0.22722 | valid_mse: 0.05163 |  0:00:32s\n",
      "epoch 22 | loss: 0.04963 | train_rmsle: 0.00286 | train_mae: 0.1773  | train_rmse: 0.22003 | train_mse: 0.04841 | valid_rmsle: 0.0029  | valid_mae: 0.18139 | valid_rmse: 0.22579 | valid_mse: 0.05098 |  0:00:33s\n",
      "epoch 23 | loss: 0.04728 | train_rmsle: 0.00312 | train_mae: 0.19152 | train_rmse: 0.23528 | train_mse: 0.05536 | valid_rmsle: 0.0032  | valid_mae: 0.19742 | valid_rmse: 0.2424  | valid_mse: 0.05876 |  0:00:35s\n",
      "epoch 24 | loss: 0.04214 | train_rmsle: 0.00256 | train_mae: 0.17056 | train_rmse: 0.21457 | train_mse: 0.04604 | valid_rmsle: 0.00265 | valid_mae: 0.17749 | valid_rmse: 0.22261 | valid_mse: 0.04956 |  0:00:37s\n",
      "epoch 25 | loss: 0.03916 | train_rmsle: 0.00195 | train_mae: 0.1421  | train_rmse: 0.18136 | train_mse: 0.03289 | valid_rmsle: 0.00202 | valid_mae: 0.14845 | valid_rmse: 0.1895  | valid_mse: 0.03591 |  0:00:38s\n",
      "epoch 26 | loss: 0.03935 | train_rmsle: 0.002   | train_mae: 0.14331 | train_rmse: 0.18168 | train_mse: 0.03301 | valid_rmsle: 0.00209 | valid_mae: 0.14969 | valid_rmse: 0.1903  | valid_mse: 0.03621 |  0:00:40s\n",
      "epoch 27 | loss: 0.03464 | train_rmsle: 0.00321 | train_mae: 0.17919 | train_rmse: 0.21991 | train_mse: 0.04836 | valid_rmsle: 0.0034  | valid_mae: 0.18746 | valid_rmse: 0.23086 | valid_mse: 0.0533  |  0:00:42s\n",
      "epoch 28 | loss: 0.0331  | train_rmsle: 0.00139 | train_mae: 0.11792 | train_rmse: 0.15574 | train_mse: 0.02425 | valid_rmsle: 0.0015  | valid_mae: 0.12666 | valid_rmse: 0.16598 | valid_mse: 0.02755 |  0:00:43s\n",
      "epoch 29 | loss: 0.03059 | train_rmsle: 0.00156 | train_mae: 0.12786 | train_rmse: 0.16151 | train_mse: 0.02608 | valid_rmsle: 0.00168 | valid_mae: 0.13481 | valid_rmse: 0.1727  | valid_mse: 0.02982 |  0:00:45s\n",
      "epoch 30 | loss: 0.02827 | train_rmsle: 0.0012  | train_mae: 0.11094 | train_rmse: 0.14573 | train_mse: 0.02124 | valid_rmsle: 0.00137 | valid_mae: 0.12224 | valid_rmse: 0.15956 | valid_mse: 0.02546 |  0:00:47s\n",
      "epoch 31 | loss: 0.02849 | train_rmsle: 0.00144 | train_mae: 0.12199 | train_rmse: 0.16469 | train_mse: 0.02712 | valid_rmsle: 0.00179 | valid_mae: 0.13776 | valid_rmse: 0.1858  | valid_mse: 0.03452 |  0:00:48s\n",
      "epoch 32 | loss: 0.02827 | train_rmsle: 0.00181 | train_mae: 0.14429 | train_rmse: 0.17564 | train_mse: 0.03085 | valid_rmsle: 0.00203 | valid_mae: 0.15329 | valid_rmse: 0.18974 | valid_mse: 0.036   |  0:00:50s\n",
      "epoch 33 | loss: 0.02595 | train_rmsle: 0.00099 | train_mae: 0.10119 | train_rmse: 0.13342 | train_mse: 0.0178  | valid_rmsle: 0.00125 | valid_mae: 0.11603 | valid_rmse: 0.15299 | valid_mse: 0.02341 |  0:00:52s\n",
      "epoch 34 | loss: 0.02374 | train_rmsle: 0.00109 | train_mae: 0.10609 | train_rmse: 0.13682 | train_mse: 0.01872 | valid_rmsle: 0.00138 | valid_mae: 0.12225 | valid_rmse: 0.15628 | valid_mse: 0.02442 |  0:00:53s\n",
      "epoch 35 | loss: 0.02157 | train_rmsle: 0.001   | train_mae: 0.10183 | train_rmse: 0.13038 | train_mse: 0.017   | valid_rmsle: 0.00122 | valid_mae: 0.11471 | valid_rmse: 0.14787 | valid_mse: 0.02186 |  0:00:55s\n",
      "epoch 36 | loss: 0.0208  | train_rmsle: 0.0027  | train_mae: 0.16298 | train_rmse: 0.19608 | train_mse: 0.03845 | valid_rmsle: 0.00291 | valid_mae: 0.1746  | valid_rmse: 0.20908 | valid_mse: 0.04372 |  0:00:56s\n",
      "epoch 37 | loss: 0.02073 | train_rmsle: 0.00096 | train_mae: 0.10468 | train_rmse: 0.13214 | train_mse: 0.01746 | valid_rmsle: 0.00124 | valid_mae: 0.12017 | valid_rmse: 0.15242 | valid_mse: 0.02323 |  0:00:58s\n",
      "epoch 38 | loss: 0.02074 | train_rmsle: 0.00228 | train_mae: 0.13767 | train_rmse: 0.17583 | train_mse: 0.03092 | valid_rmsle: 0.00244 | valid_mae: 0.15112 | valid_rmse: 0.18863 | valid_mse: 0.03558 |  0:01:00s\n",
      "epoch 39 | loss: 0.01828 | train_rmsle: 0.00078 | train_mae: 0.09063 | train_rmse: 0.11735 | train_mse: 0.01377 | valid_rmsle: 0.00107 | valid_mae: 0.10872 | valid_rmse: 0.14002 | valid_mse: 0.01961 |  0:01:01s\n",
      "epoch 40 | loss: 0.01874 | train_rmsle: 0.00067 | train_mae: 0.08331 | train_rmse: 0.10899 | train_mse: 0.01188 | valid_rmsle: 0.00097 | valid_mae: 0.1023  | valid_rmse: 0.1338  | valid_mse: 0.0179  |  0:01:03s\n",
      "epoch 41 | loss: 0.0174  | train_rmsle: 0.00131 | train_mae: 0.12335 | train_rmse: 0.14986 | train_mse: 0.02246 | valid_rmsle: 0.00163 | valid_mae: 0.13707 | valid_rmse: 0.17059 | valid_mse: 0.0291  |  0:01:05s\n",
      "epoch 42 | loss: 0.01884 | train_rmsle: 0.00101 | train_mae: 0.10379 | train_rmse: 0.12783 | train_mse: 0.01634 | valid_rmsle: 0.00129 | valid_mae: 0.11995 | valid_rmse: 0.14876 | valid_mse: 0.02213 |  0:01:06s\n",
      "epoch 43 | loss: 0.01978 | train_rmsle: 0.0009  | train_mae: 0.10378 | train_rmse: 0.13039 | train_mse: 0.017   | valid_rmsle: 0.0012  | valid_mae: 0.11884 | valid_rmse: 0.1516  | valid_mse: 0.02298 |  0:01:08s\n",
      "epoch 44 | loss: 0.0193  | train_rmsle: 0.00078 | train_mae: 0.08819 | train_rmse: 0.11192 | train_mse: 0.01253 | valid_rmsle: 0.00102 | valid_mae: 0.10503 | valid_rmse: 0.13269 | valid_mse: 0.01761 |  0:01:10s\n",
      "epoch 45 | loss: 0.01568 | train_rmsle: 0.00057 | train_mae: 0.07771 | train_rmse: 0.10041 | train_mse: 0.01008 | valid_rmsle: 0.00086 | valid_mae: 0.09771 | valid_rmse: 0.1254  | valid_mse: 0.01572 |  0:01:11s\n",
      "epoch 46 | loss: 0.01494 | train_rmsle: 0.00054 | train_mae: 0.07438 | train_rmse: 0.09763 | train_mse: 0.00953 | valid_rmsle: 0.00087 | valid_mae: 0.0943  | valid_rmse: 0.1256  | valid_mse: 0.01578 |  0:01:13s\n",
      "epoch 47 | loss: 0.01788 | train_rmsle: 0.00055 | train_mae: 0.07644 | train_rmse: 0.09807 | train_mse: 0.00962 | valid_rmsle: 0.00085 | valid_mae: 0.09419 | valid_rmse: 0.12385 | valid_mse: 0.01534 |  0:01:15s\n",
      "epoch 48 | loss: 0.01621 | train_rmsle: 0.00049 | train_mae: 0.07092 | train_rmse: 0.09482 | train_mse: 0.00899 | valid_rmsle: 0.00076 | valid_mae: 0.08907 | valid_rmse: 0.11889 | valid_mse: 0.01414 |  0:01:16s\n",
      "epoch 49 | loss: 0.01363 | train_rmsle: 0.00088 | train_mae: 0.08942 | train_rmse: 0.11395 | train_mse: 0.01298 | valid_rmsle: 0.00108 | valid_mae: 0.10429 | valid_rmse: 0.13148 | valid_mse: 0.01729 |  0:01:18s\n",
      "epoch 50 | loss: 0.0148  | train_rmsle: 0.00056 | train_mae: 0.07535 | train_rmse: 0.09781 | train_mse: 0.00957 | valid_rmsle: 0.00081 | valid_mae: 0.09213 | valid_rmse: 0.12    | valid_mse: 0.0144  |  0:01:20s\n",
      "epoch 51 | loss: 0.01566 | train_rmsle: 0.00114 | train_mae: 0.10459 | train_rmse: 0.1304  | train_mse: 0.017   | valid_rmsle: 0.00141 | valid_mae: 0.11844 | valid_rmse: 0.14994 | valid_mse: 0.02248 |  0:01:21s\n",
      "epoch 52 | loss: 0.01701 | train_rmsle: 0.00059 | train_mae: 0.08072 | train_rmse: 0.10255 | train_mse: 0.01052 | valid_rmsle: 0.00092 | valid_mae: 0.09934 | valid_rmse: 0.12991 | valid_mse: 0.01688 |  0:01:23s\n",
      "epoch 53 | loss: 0.01534 | train_rmsle: 0.0005  | train_mae: 0.07336 | train_rmse: 0.09444 | train_mse: 0.00892 | valid_rmsle: 0.00083 | valid_mae: 0.09245 | valid_rmse: 0.12274 | valid_mse: 0.01506 |  0:01:24s\n",
      "epoch 54 | loss: 0.01299 | train_rmsle: 0.00047 | train_mae: 0.06946 | train_rmse: 0.08926 | train_mse: 0.00797 | valid_rmsle: 0.00077 | valid_mae: 0.08901 | valid_rmse: 0.11737 | valid_mse: 0.01378 |  0:01:26s\n",
      "epoch 55 | loss: 0.01288 | train_rmsle: 0.00047 | train_mae: 0.07037 | train_rmse: 0.08922 | train_mse: 0.00796 | valid_rmsle: 0.00078 | valid_mae: 0.0901  | valid_rmse: 0.11804 | valid_mse: 0.01393 |  0:01:28s\n",
      "epoch 56 | loss: 0.01464 | train_rmsle: 0.00045 | train_mae: 0.07159 | train_rmse: 0.0911  | train_mse: 0.0083  | valid_rmsle: 0.00081 | valid_mae: 0.09151 | valid_rmse: 0.12169 | valid_mse: 0.01481 |  0:01:29s\n",
      "epoch 57 | loss: 0.01191 | train_rmsle: 0.00039 | train_mae: 0.06382 | train_rmse: 0.08254 | train_mse: 0.00681 | valid_rmsle: 0.00075 | valid_mae: 0.08456 | valid_rmse: 0.11472 | valid_mse: 0.01316 |  0:01:31s\n",
      "epoch 58 | loss: 0.01343 | train_rmsle: 0.00044 | train_mae: 0.0677  | train_rmse: 0.09027 | train_mse: 0.00815 | valid_rmsle: 0.00076 | valid_mae: 0.08743 | valid_rmse: 0.11808 | valid_mse: 0.01394 |  0:01:33s\n",
      "epoch 59 | loss: 0.01074 | train_rmsle: 0.00039 | train_mae: 0.06508 | train_rmse: 0.08343 | train_mse: 0.00696 | valid_rmsle: 0.00068 | valid_mae: 0.08624 | valid_rmse: 0.11125 | valid_mse: 0.01238 |  0:01:34s\n",
      "epoch 60 | loss: 0.01229 | train_rmsle: 0.00085 | train_mae: 0.08377 | train_rmse: 0.10937 | train_mse: 0.01196 | valid_rmsle: 0.00111 | valid_mae: 0.10159 | valid_rmse: 0.13068 | valid_mse: 0.01708 |  0:01:36s\n",
      "epoch 61 | loss: 0.01218 | train_rmsle: 0.00038 | train_mae: 0.06142 | train_rmse: 0.07882 | train_mse: 0.00621 | valid_rmsle: 0.00063 | valid_mae: 0.08206 | valid_rmse: 0.10512 | valid_mse: 0.01105 |  0:01:37s\n",
      "epoch 62 | loss: 0.01082 | train_rmsle: 0.00033 | train_mae: 0.0578  | train_rmse: 0.07587 | train_mse: 0.00576 | valid_rmsle: 0.00059 | valid_mae: 0.07892 | valid_rmse: 0.10311 | valid_mse: 0.01063 |  0:01:39s\n",
      "epoch 63 | loss: 0.01135 | train_rmsle: 0.00035 | train_mae: 0.05846 | train_rmse: 0.07555 | train_mse: 0.00571 | valid_rmsle: 0.0006  | valid_mae: 0.07958 | valid_rmse: 0.10325 | valid_mse: 0.01066 |  0:01:40s\n",
      "epoch 64 | loss: 0.01142 | train_rmsle: 0.00033 | train_mae: 0.05923 | train_rmse: 0.07744 | train_mse: 0.006   | valid_rmsle: 0.00062 | valid_mae: 0.0817  | valid_rmse: 0.10681 | valid_mse: 0.01141 |  0:01:41s\n",
      "epoch 65 | loss: 0.01314 | train_rmsle: 0.00059 | train_mae: 0.08134 | train_rmse: 0.09909 | train_mse: 0.00982 | valid_rmsle: 0.00085 | valid_mae: 0.09777 | valid_rmse: 0.12198 | valid_mse: 0.01488 |  0:01:43s\n",
      "epoch 66 | loss: 0.0103  | train_rmsle: 0.00028 | train_mae: 0.05362 | train_rmse: 0.06963 | train_mse: 0.00485 | valid_rmsle: 0.00054 | valid_mae: 0.0749  | valid_rmse: 0.09855 | valid_mse: 0.00971 |  0:01:44s\n",
      "epoch 67 | loss: 0.01202 | train_rmsle: 0.0003  | train_mae: 0.05601 | train_rmse: 0.07218 | train_mse: 0.00521 | valid_rmsle: 0.00057 | valid_mae: 0.07708 | valid_rmse: 0.10167 | valid_mse: 0.01034 |  0:01:45s\n",
      "epoch 68 | loss: 0.0134  | train_rmsle: 0.00073 | train_mae: 0.09648 | train_rmse: 0.11318 | train_mse: 0.01281 | valid_rmsle: 0.001   | valid_mae: 0.10707 | valid_rmse: 0.13275 | valid_mse: 0.01762 |  0:01:47s\n",
      "epoch 69 | loss: 0.01376 | train_rmsle: 0.00026 | train_mae: 0.05201 | train_rmse: 0.06712 | train_mse: 0.0045  | valid_rmsle: 0.00054 | valid_mae: 0.07457 | valid_rmse: 0.09867 | valid_mse: 0.00974 |  0:01:48s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 66 and best_valid_mse = 0.00971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010701015286653378 RMSE: 0.1034457117847491 R2: 0.9526307286259439 MAE: 0.07624393800015498\n",
      "=====================================\n",
      "[38/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25806 | train_rmsle: 0.16137 | train_mae: 1.38403 | train_rmse: 1.4619  | train_mse: 2.13715 | valid_rmsle: 0.16213 | valid_mae: 1.38796 | valid_rmse: 1.46633 | valid_mse: 2.15013 |  0:00:01s\n",
      "epoch 1  | loss: 0.35967 | train_rmsle: 0.1098  | train_mae: 1.16754 | train_rmse: 1.25285 | train_mse: 1.56962 | valid_rmsle: 0.11029 | valid_mae: 1.17063 | valid_rmse: 1.25685 | valid_mse: 1.57967 |  0:00:03s\n",
      "epoch 2  | loss: 0.26771 | train_rmsle: 0.05449 | train_mae: 0.83962 | train_rmse: 0.9326  | train_mse: 0.86975 | valid_rmsle: 0.05448 | valid_mae: 0.83979 | valid_rmse: 0.93468 | valid_mse: 0.87362 |  0:00:04s\n",
      "epoch 3  | loss: 0.24587 | train_rmsle: 0.04306 | train_mae: 0.74839 | train_rmse: 0.84082 | train_mse: 0.70698 | valid_rmsle: 0.04307 | valid_mae: 0.74848 | valid_rmse: 0.84329 | valid_mse: 0.71113 |  0:00:06s\n",
      "epoch 4  | loss: 0.23121 | train_rmsle: 0.03004 | train_mae: 0.62193 | train_rmse: 0.71342 | train_mse: 0.50897 | valid_rmsle: 0.0298  | valid_mae: 0.62106 | valid_rmse: 0.71382 | valid_mse: 0.50954 |  0:00:08s\n",
      "epoch 5  | loss: 0.22596 | train_rmsle: 0.02275 | train_mae: 0.53581 | train_rmse: 0.62461 | train_mse: 0.39013 | valid_rmsle: 0.02247 | valid_mae: 0.53654 | valid_rmse: 0.62461 | valid_mse: 0.39014 |  0:00:09s\n",
      "epoch 6  | loss: 0.22236 | train_rmsle: 0.01826 | train_mae: 0.47077 | train_rmse: 0.55789 | train_mse: 0.31124 | valid_rmsle: 0.01788 | valid_mae: 0.47163 | valid_rmse: 0.55679 | valid_mse: 0.31002 |  0:00:11s\n",
      "epoch 7  | loss: 0.22582 | train_rmsle: 0.02021 | train_mae: 0.50115 | train_rmse: 0.5888  | train_mse: 0.34668 | valid_rmsle: 0.01978 | valid_mae: 0.50044 | valid_rmse: 0.5869  | valid_mse: 0.34445 |  0:00:12s\n",
      "epoch 8  | loss: 0.21553 | train_rmsle: 0.01476 | train_mae: 0.40632 | train_rmse: 0.49404 | train_mse: 0.24408 | valid_rmsle: 0.01437 | valid_mae: 0.40816 | valid_rmse: 0.49319 | valid_mse: 0.24324 |  0:00:14s\n",
      "epoch 9  | loss: 0.21478 | train_rmsle: 0.01394 | train_mae: 0.38402 | train_rmse: 0.47518 | train_mse: 0.2258  | valid_rmsle: 0.01347 | valid_mae: 0.38605 | valid_rmse: 0.47299 | valid_mse: 0.22372 |  0:00:16s\n",
      "epoch 10 | loss: 0.20802 | train_rmsle: 0.01418 | train_mae: 0.39695 | train_rmse: 0.48372 | train_mse: 0.23398 | valid_rmsle: 0.01378 | valid_mae: 0.39878 | valid_rmse: 0.48243 | valid_mse: 0.23274 |  0:00:17s\n",
      "epoch 11 | loss: 0.19951 | train_rmsle: 0.01288 | train_mae: 0.36244 | train_rmse: 0.45301 | train_mse: 0.20521 | valid_rmsle: 0.01236 | valid_mae: 0.36298 | valid_rmse: 0.4491  | valid_mse: 0.20169 |  0:00:19s\n",
      "epoch 12 | loss: 0.19172 | train_rmsle: 0.01226 | train_mae: 0.35579 | train_rmse: 0.44341 | train_mse: 0.19661 | valid_rmsle: 0.01177 | valid_mae: 0.35707 | valid_rmse: 0.44025 | valid_mse: 0.19382 |  0:00:21s\n",
      "epoch 13 | loss: 0.18183 | train_rmsle: 0.01018 | train_mae: 0.32981 | train_rmse: 0.40615 | train_mse: 0.16495 | valid_rmsle: 0.0098  | valid_mae: 0.33154 | valid_rmse: 0.40489 | valid_mse: 0.16394 |  0:00:22s\n",
      "epoch 14 | loss: 0.16379 | train_rmsle: 0.01151 | train_mae: 0.37106 | train_rmse: 0.43952 | train_mse: 0.19318 | valid_rmsle: 0.01144 | valid_mae: 0.37338 | valid_rmse: 0.44292 | valid_mse: 0.19618 |  0:00:24s\n",
      "epoch 15 | loss: 0.13555 | train_rmsle: 0.01054 | train_mae: 0.34695 | train_rmse: 0.41495 | train_mse: 0.17218 | valid_rmsle: 0.01028 | valid_mae: 0.3468  | valid_rmse: 0.41435 | valid_mse: 0.17169 |  0:00:26s\n",
      "epoch 16 | loss: 0.11419 | train_rmsle: 0.01237 | train_mae: 0.37178 | train_rmse: 0.44283 | train_mse: 0.1961  | valid_rmsle: 0.0122  | valid_mae: 0.37391 | valid_rmse: 0.44374 | valid_mse: 0.1969  |  0:00:27s\n",
      "epoch 17 | loss: 0.09763 | train_rmsle: 0.00908 | train_mae: 0.31585 | train_rmse: 0.3803  | train_mse: 0.14463 | valid_rmsle: 0.00877 | valid_mae: 0.31503 | valid_rmse: 0.37813 | valid_mse: 0.14298 |  0:00:29s\n",
      "epoch 18 | loss: 0.08568 | train_rmsle: 0.00774 | train_mae: 0.28534 | train_rmse: 0.34781 | train_mse: 0.12097 | valid_rmsle: 0.00742 | valid_mae: 0.28446 | valid_rmse: 0.34379 | valid_mse: 0.11819 |  0:00:30s\n",
      "epoch 19 | loss: 0.07544 | train_rmsle: 0.00495 | train_mae: 0.22748 | train_rmse: 0.28089 | train_mse: 0.0789  | valid_rmsle: 0.00477 | valid_mae: 0.22821 | valid_rmse: 0.27867 | valid_mse: 0.07766 |  0:00:32s\n",
      "epoch 20 | loss: 0.06821 | train_rmsle: 0.00429 | train_mae: 0.22137 | train_rmse: 0.27036 | train_mse: 0.07309 | valid_rmsle: 0.00427 | valid_mae: 0.22409 | valid_rmse: 0.2728  | valid_mse: 0.07442 |  0:00:34s\n",
      "epoch 21 | loss: 0.05828 | train_rmsle: 0.00293 | train_mae: 0.17773 | train_rmse: 0.22461 | train_mse: 0.05045 | valid_rmsle: 0.00288 | valid_mae: 0.18163 | valid_rmse: 0.22722 | valid_mse: 0.05163 |  0:00:35s\n",
      "epoch 22 | loss: 0.04963 | train_rmsle: 0.00286 | train_mae: 0.1773  | train_rmse: 0.22003 | train_mse: 0.04841 | valid_rmsle: 0.0029  | valid_mae: 0.18139 | valid_rmse: 0.22579 | valid_mse: 0.05098 |  0:00:37s\n",
      "epoch 23 | loss: 0.04728 | train_rmsle: 0.00312 | train_mae: 0.19152 | train_rmse: 0.23528 | train_mse: 0.05536 | valid_rmsle: 0.0032  | valid_mae: 0.19742 | valid_rmse: 0.2424  | valid_mse: 0.05876 |  0:00:39s\n",
      "epoch 24 | loss: 0.04214 | train_rmsle: 0.00256 | train_mae: 0.17056 | train_rmse: 0.21457 | train_mse: 0.04604 | valid_rmsle: 0.00265 | valid_mae: 0.17749 | valid_rmse: 0.22261 | valid_mse: 0.04956 |  0:00:40s\n",
      "epoch 25 | loss: 0.03916 | train_rmsle: 0.00195 | train_mae: 0.1421  | train_rmse: 0.18136 | train_mse: 0.03289 | valid_rmsle: 0.00202 | valid_mae: 0.14845 | valid_rmse: 0.1895  | valid_mse: 0.03591 |  0:00:42s\n",
      "epoch 26 | loss: 0.03935 | train_rmsle: 0.002   | train_mae: 0.14331 | train_rmse: 0.18168 | train_mse: 0.03301 | valid_rmsle: 0.00209 | valid_mae: 0.14969 | valid_rmse: 0.1903  | valid_mse: 0.03621 |  0:00:44s\n",
      "epoch 27 | loss: 0.03464 | train_rmsle: 0.00321 | train_mae: 0.17919 | train_rmse: 0.21991 | train_mse: 0.04836 | valid_rmsle: 0.0034  | valid_mae: 0.18746 | valid_rmse: 0.23086 | valid_mse: 0.0533  |  0:00:45s\n",
      "epoch 28 | loss: 0.0331  | train_rmsle: 0.00139 | train_mae: 0.11792 | train_rmse: 0.15574 | train_mse: 0.02425 | valid_rmsle: 0.0015  | valid_mae: 0.12666 | valid_rmse: 0.16598 | valid_mse: 0.02755 |  0:00:47s\n",
      "epoch 29 | loss: 0.03059 | train_rmsle: 0.00156 | train_mae: 0.12786 | train_rmse: 0.16151 | train_mse: 0.02608 | valid_rmsle: 0.00168 | valid_mae: 0.13481 | valid_rmse: 0.1727  | valid_mse: 0.02982 |  0:00:49s\n",
      "epoch 30 | loss: 0.02827 | train_rmsle: 0.0012  | train_mae: 0.11094 | train_rmse: 0.14573 | train_mse: 0.02124 | valid_rmsle: 0.00137 | valid_mae: 0.12224 | valid_rmse: 0.15956 | valid_mse: 0.02546 |  0:00:50s\n",
      "epoch 31 | loss: 0.02849 | train_rmsle: 0.00144 | train_mae: 0.12199 | train_rmse: 0.16469 | train_mse: 0.02712 | valid_rmsle: 0.00179 | valid_mae: 0.13776 | valid_rmse: 0.1858  | valid_mse: 0.03452 |  0:00:52s\n",
      "epoch 32 | loss: 0.02827 | train_rmsle: 0.00181 | train_mae: 0.14429 | train_rmse: 0.17564 | train_mse: 0.03085 | valid_rmsle: 0.00203 | valid_mae: 0.15329 | valid_rmse: 0.18974 | valid_mse: 0.036   |  0:00:54s\n",
      "epoch 33 | loss: 0.02595 | train_rmsle: 0.00099 | train_mae: 0.10119 | train_rmse: 0.13342 | train_mse: 0.0178  | valid_rmsle: 0.00125 | valid_mae: 0.11603 | valid_rmse: 0.15299 | valid_mse: 0.02341 |  0:00:55s\n",
      "epoch 34 | loss: 0.02374 | train_rmsle: 0.00109 | train_mae: 0.10609 | train_rmse: 0.13682 | train_mse: 0.01872 | valid_rmsle: 0.00138 | valid_mae: 0.12225 | valid_rmse: 0.15628 | valid_mse: 0.02442 |  0:00:57s\n",
      "epoch 35 | loss: 0.02157 | train_rmsle: 0.001   | train_mae: 0.10183 | train_rmse: 0.13038 | train_mse: 0.017   | valid_rmsle: 0.00122 | valid_mae: 0.11471 | valid_rmse: 0.14787 | valid_mse: 0.02186 |  0:00:59s\n",
      "epoch 36 | loss: 0.0208  | train_rmsle: 0.0027  | train_mae: 0.16298 | train_rmse: 0.19608 | train_mse: 0.03845 | valid_rmsle: 0.00291 | valid_mae: 0.1746  | valid_rmse: 0.20908 | valid_mse: 0.04372 |  0:01:00s\n",
      "epoch 37 | loss: 0.02073 | train_rmsle: 0.00096 | train_mae: 0.10468 | train_rmse: 0.13214 | train_mse: 0.01746 | valid_rmsle: 0.00124 | valid_mae: 0.12017 | valid_rmse: 0.15242 | valid_mse: 0.02323 |  0:01:02s\n",
      "epoch 38 | loss: 0.02074 | train_rmsle: 0.00228 | train_mae: 0.13767 | train_rmse: 0.17583 | train_mse: 0.03092 | valid_rmsle: 0.00244 | valid_mae: 0.15112 | valid_rmse: 0.18863 | valid_mse: 0.03558 |  0:01:04s\n",
      "epoch 39 | loss: 0.01828 | train_rmsle: 0.00078 | train_mae: 0.09063 | train_rmse: 0.11735 | train_mse: 0.01377 | valid_rmsle: 0.00107 | valid_mae: 0.10872 | valid_rmse: 0.14002 | valid_mse: 0.01961 |  0:01:05s\n",
      "epoch 40 | loss: 0.01874 | train_rmsle: 0.00067 | train_mae: 0.08331 | train_rmse: 0.10899 | train_mse: 0.01188 | valid_rmsle: 0.00097 | valid_mae: 0.1023  | valid_rmse: 0.1338  | valid_mse: 0.0179  |  0:01:07s\n",
      "epoch 41 | loss: 0.0174  | train_rmsle: 0.00131 | train_mae: 0.12335 | train_rmse: 0.14986 | train_mse: 0.02246 | valid_rmsle: 0.00163 | valid_mae: 0.13707 | valid_rmse: 0.17059 | valid_mse: 0.0291  |  0:01:08s\n",
      "epoch 42 | loss: 0.01884 | train_rmsle: 0.00101 | train_mae: 0.10379 | train_rmse: 0.12783 | train_mse: 0.01634 | valid_rmsle: 0.00129 | valid_mae: 0.11995 | valid_rmse: 0.14876 | valid_mse: 0.02213 |  0:01:10s\n",
      "epoch 43 | loss: 0.01978 | train_rmsle: 0.0009  | train_mae: 0.10378 | train_rmse: 0.13039 | train_mse: 0.017   | valid_rmsle: 0.0012  | valid_mae: 0.11884 | valid_rmse: 0.1516  | valid_mse: 0.02298 |  0:01:12s\n",
      "epoch 44 | loss: 0.0193  | train_rmsle: 0.00078 | train_mae: 0.08819 | train_rmse: 0.11192 | train_mse: 0.01253 | valid_rmsle: 0.00102 | valid_mae: 0.10503 | valid_rmse: 0.13269 | valid_mse: 0.01761 |  0:01:13s\n",
      "epoch 45 | loss: 0.01568 | train_rmsle: 0.00057 | train_mae: 0.07771 | train_rmse: 0.10041 | train_mse: 0.01008 | valid_rmsle: 0.00086 | valid_mae: 0.09771 | valid_rmse: 0.1254  | valid_mse: 0.01572 |  0:01:15s\n",
      "epoch 46 | loss: 0.01494 | train_rmsle: 0.00054 | train_mae: 0.07438 | train_rmse: 0.09763 | train_mse: 0.00953 | valid_rmsle: 0.00087 | valid_mae: 0.0943  | valid_rmse: 0.1256  | valid_mse: 0.01578 |  0:01:17s\n",
      "epoch 47 | loss: 0.01788 | train_rmsle: 0.00055 | train_mae: 0.07644 | train_rmse: 0.09807 | train_mse: 0.00962 | valid_rmsle: 0.00085 | valid_mae: 0.09419 | valid_rmse: 0.12385 | valid_mse: 0.01534 |  0:01:18s\n",
      "epoch 48 | loss: 0.01621 | train_rmsle: 0.00049 | train_mae: 0.07092 | train_rmse: 0.09482 | train_mse: 0.00899 | valid_rmsle: 0.00076 | valid_mae: 0.08907 | valid_rmse: 0.11889 | valid_mse: 0.01414 |  0:01:20s\n",
      "epoch 49 | loss: 0.01363 | train_rmsle: 0.00088 | train_mae: 0.08942 | train_rmse: 0.11395 | train_mse: 0.01298 | valid_rmsle: 0.00108 | valid_mae: 0.10429 | valid_rmse: 0.13148 | valid_mse: 0.01729 |  0:01:22s\n",
      "epoch 50 | loss: 0.0148  | train_rmsle: 0.00056 | train_mae: 0.07535 | train_rmse: 0.09781 | train_mse: 0.00957 | valid_rmsle: 0.00081 | valid_mae: 0.09213 | valid_rmse: 0.12    | valid_mse: 0.0144  |  0:01:23s\n",
      "epoch 51 | loss: 0.01566 | train_rmsle: 0.00114 | train_mae: 0.10459 | train_rmse: 0.1304  | train_mse: 0.017   | valid_rmsle: 0.00141 | valid_mae: 0.11844 | valid_rmse: 0.14994 | valid_mse: 0.02248 |  0:01:25s\n",
      "epoch 52 | loss: 0.01701 | train_rmsle: 0.00059 | train_mae: 0.08072 | train_rmse: 0.10255 | train_mse: 0.01052 | valid_rmsle: 0.00092 | valid_mae: 0.09934 | valid_rmse: 0.12991 | valid_mse: 0.01688 |  0:01:26s\n",
      "epoch 53 | loss: 0.01534 | train_rmsle: 0.0005  | train_mae: 0.07336 | train_rmse: 0.09444 | train_mse: 0.00892 | valid_rmsle: 0.00083 | valid_mae: 0.09245 | valid_rmse: 0.12274 | valid_mse: 0.01506 |  0:01:28s\n",
      "epoch 54 | loss: 0.01299 | train_rmsle: 0.00047 | train_mae: 0.06946 | train_rmse: 0.08926 | train_mse: 0.00797 | valid_rmsle: 0.00077 | valid_mae: 0.08901 | valid_rmse: 0.11737 | valid_mse: 0.01378 |  0:01:30s\n",
      "epoch 55 | loss: 0.01288 | train_rmsle: 0.00047 | train_mae: 0.07037 | train_rmse: 0.08922 | train_mse: 0.00796 | valid_rmsle: 0.00078 | valid_mae: 0.0901  | valid_rmse: 0.11804 | valid_mse: 0.01393 |  0:01:31s\n",
      "epoch 56 | loss: 0.01464 | train_rmsle: 0.00045 | train_mae: 0.07159 | train_rmse: 0.0911  | train_mse: 0.0083  | valid_rmsle: 0.00081 | valid_mae: 0.09151 | valid_rmse: 0.12169 | valid_mse: 0.01481 |  0:01:33s\n",
      "epoch 57 | loss: 0.01191 | train_rmsle: 0.00039 | train_mae: 0.06382 | train_rmse: 0.08254 | train_mse: 0.00681 | valid_rmsle: 0.00075 | valid_mae: 0.08456 | valid_rmse: 0.11472 | valid_mse: 0.01316 |  0:01:34s\n",
      "epoch 58 | loss: 0.01343 | train_rmsle: 0.00044 | train_mae: 0.0677  | train_rmse: 0.09027 | train_mse: 0.00815 | valid_rmsle: 0.00076 | valid_mae: 0.08743 | valid_rmse: 0.11808 | valid_mse: 0.01394 |  0:01:36s\n",
      "epoch 59 | loss: 0.01074 | train_rmsle: 0.00039 | train_mae: 0.06508 | train_rmse: 0.08343 | train_mse: 0.00696 | valid_rmsle: 0.00068 | valid_mae: 0.08624 | valid_rmse: 0.11125 | valid_mse: 0.01238 |  0:01:37s\n",
      "epoch 60 | loss: 0.01229 | train_rmsle: 0.00085 | train_mae: 0.08377 | train_rmse: 0.10937 | train_mse: 0.01196 | valid_rmsle: 0.00111 | valid_mae: 0.10159 | valid_rmse: 0.13068 | valid_mse: 0.01708 |  0:01:39s\n",
      "epoch 61 | loss: 0.01218 | train_rmsle: 0.00038 | train_mae: 0.06142 | train_rmse: 0.07882 | train_mse: 0.00621 | valid_rmsle: 0.00063 | valid_mae: 0.08206 | valid_rmse: 0.10512 | valid_mse: 0.01105 |  0:01:40s\n",
      "epoch 62 | loss: 0.01082 | train_rmsle: 0.00033 | train_mae: 0.0578  | train_rmse: 0.07587 | train_mse: 0.00576 | valid_rmsle: 0.00059 | valid_mae: 0.07892 | valid_rmse: 0.10311 | valid_mse: 0.01063 |  0:01:41s\n",
      "epoch 63 | loss: 0.01135 | train_rmsle: 0.00035 | train_mae: 0.05846 | train_rmse: 0.07555 | train_mse: 0.00571 | valid_rmsle: 0.0006  | valid_mae: 0.07958 | valid_rmse: 0.10325 | valid_mse: 0.01066 |  0:01:42s\n",
      "epoch 64 | loss: 0.01142 | train_rmsle: 0.00033 | train_mae: 0.05923 | train_rmse: 0.07744 | train_mse: 0.006   | valid_rmsle: 0.00062 | valid_mae: 0.0817  | valid_rmse: 0.10681 | valid_mse: 0.01141 |  0:01:43s\n",
      "epoch 65 | loss: 0.01314 | train_rmsle: 0.00059 | train_mae: 0.08134 | train_rmse: 0.09909 | train_mse: 0.00982 | valid_rmsle: 0.00085 | valid_mae: 0.09777 | valid_rmse: 0.12198 | valid_mse: 0.01488 |  0:01:45s\n",
      "epoch 66 | loss: 0.0103  | train_rmsle: 0.00028 | train_mae: 0.05362 | train_rmse: 0.06963 | train_mse: 0.00485 | valid_rmsle: 0.00054 | valid_mae: 0.0749  | valid_rmse: 0.09855 | valid_mse: 0.00971 |  0:01:46s\n",
      "epoch 67 | loss: 0.01202 | train_rmsle: 0.0003  | train_mae: 0.05601 | train_rmse: 0.07218 | train_mse: 0.00521 | valid_rmsle: 0.00057 | valid_mae: 0.07708 | valid_rmse: 0.10167 | valid_mse: 0.01034 |  0:01:47s\n",
      "epoch 68 | loss: 0.0134  | train_rmsle: 0.00073 | train_mae: 0.09648 | train_rmse: 0.11318 | train_mse: 0.01281 | valid_rmsle: 0.001   | valid_mae: 0.10707 | valid_rmse: 0.13275 | valid_mse: 0.01762 |  0:01:49s\n",
      "epoch 69 | loss: 0.01376 | train_rmsle: 0.00026 | train_mae: 0.05201 | train_rmse: 0.06712 | train_mse: 0.0045  | valid_rmsle: 0.00054 | valid_mae: 0.07457 | valid_rmse: 0.09867 | valid_mse: 0.00974 |  0:01:50s\n",
      "epoch 70 | loss: 0.01598 | train_rmsle: 0.00119 | train_mae: 0.11623 | train_rmse: 0.13491 | train_mse: 0.0182  | valid_rmsle: 0.00145 | valid_mae: 0.12817 | valid_rmse: 0.15276 | valid_mse: 0.02333 |  0:01:52s\n",
      "epoch 71 | loss: 0.01669 | train_rmsle: 0.0007  | train_mae: 0.09357 | train_rmse: 0.10957 | train_mse: 0.012   | valid_rmsle: 0.00098 | valid_mae: 0.10818 | valid_rmse: 0.13158 | valid_mse: 0.01731 |  0:01:53s\n",
      "epoch 72 | loss: 0.01373 | train_rmsle: 0.00062 | train_mae: 0.08047 | train_rmse: 0.09865 | train_mse: 0.00973 | valid_rmsle: 0.00084 | valid_mae: 0.09621 | valid_rmse: 0.11964 | valid_mse: 0.01431 |  0:01:55s\n",
      "epoch 73 | loss: 0.01268 | train_rmsle: 0.00057 | train_mae: 0.08634 | train_rmse: 0.10526 | train_mse: 0.01108 | valid_rmsle: 0.00085 | valid_mae: 0.10235 | valid_rmse: 0.12768 | valid_mse: 0.0163  |  0:01:57s\n",
      "epoch 74 | loss: 0.01143 | train_rmsle: 0.00055 | train_mae: 0.08341 | train_rmse: 0.09921 | train_mse: 0.00984 | valid_rmsle: 0.00081 | valid_mae: 0.09904 | valid_rmse: 0.12208 | valid_mse: 0.0149  |  0:01:58s\n",
      "epoch 75 | loss: 0.01183 | train_rmsle: 0.00036 | train_mae: 0.06409 | train_rmse: 0.08082 | train_mse: 0.00653 | valid_rmsle: 0.00061 | valid_mae: 0.07999 | valid_rmse: 0.10504 | valid_mse: 0.01103 |  0:02:00s\n",
      "epoch 76 | loss: 0.01005 | train_rmsle: 0.00026 | train_mae: 0.0525  | train_rmse: 0.0674  | train_mse: 0.00454 | valid_rmsle: 0.00051 | valid_mae: 0.07326 | valid_rmse: 0.09598 | valid_mse: 0.00921 |  0:02:01s\n",
      "epoch 77 | loss: 0.01011 | train_rmsle: 0.00043 | train_mae: 0.06208 | train_rmse: 0.08011 | train_mse: 0.00642 | valid_rmsle: 0.00071 | valid_mae: 0.084   | valid_rmse: 0.10766 | valid_mse: 0.01159 |  0:02:03s\n",
      "epoch 78 | loss: 0.00994 | train_rmsle: 0.00034 | train_mae: 0.06108 | train_rmse: 0.07559 | train_mse: 0.00571 | valid_rmsle: 0.00061 | valid_mae: 0.0829  | valid_rmse: 0.10458 | valid_mse: 0.01094 |  0:02:05s\n",
      "epoch 79 | loss: 0.01057 | train_rmsle: 0.00035 | train_mae: 0.06366 | train_rmse: 0.07981 | train_mse: 0.00637 | valid_rmsle: 0.00062 | valid_mae: 0.08152 | valid_rmse: 0.10679 | valid_mse: 0.0114  |  0:02:06s\n",
      "epoch 80 | loss: 0.01055 | train_rmsle: 0.00028 | train_mae: 0.05386 | train_rmse: 0.06888 | train_mse: 0.00475 | valid_rmsle: 0.00055 | valid_mae: 0.07544 | valid_rmse: 0.09949 | valid_mse: 0.0099  |  0:02:08s\n",
      "epoch 81 | loss: 0.01115 | train_rmsle: 0.00045 | train_mae: 0.06685 | train_rmse: 0.08303 | train_mse: 0.00689 | valid_rmsle: 0.00073 | valid_mae: 0.08791 | valid_rmse: 0.11062 | valid_mse: 0.01224 |  0:02:10s\n",
      "epoch 82 | loss: 0.01046 | train_rmsle: 0.00033 | train_mae: 0.05761 | train_rmse: 0.07296 | train_mse: 0.00532 | valid_rmsle: 0.00061 | valid_mae: 0.07949 | valid_rmse: 0.10208 | valid_mse: 0.01042 |  0:02:11s\n",
      "epoch 83 | loss: 0.0109  | train_rmsle: 0.00066 | train_mae: 0.09172 | train_rmse: 0.10577 | train_mse: 0.01119 | valid_rmsle: 0.00094 | valid_mae: 0.10653 | valid_rmse: 0.1288  | valid_mse: 0.01659 |  0:02:13s\n",
      "epoch 84 | loss: 0.01047 | train_rmsle: 0.00029 | train_mae: 0.05598 | train_rmse: 0.07034 | train_mse: 0.00495 | valid_rmsle: 0.00058 | valid_mae: 0.0793  | valid_rmse: 0.10182 | valid_mse: 0.01037 |  0:02:15s\n",
      "epoch 85 | loss: 0.00974 | train_rmsle: 0.00022 | train_mae: 0.04792 | train_rmse: 0.06148 | train_mse: 0.00378 | valid_rmsle: 0.00052 | valid_mae: 0.0739  | valid_rmse: 0.09659 | valid_mse: 0.00933 |  0:02:16s\n",
      "epoch 86 | loss: 0.00942 | train_rmsle: 0.00039 | train_mae: 0.05964 | train_rmse: 0.07642 | train_mse: 0.00584 | valid_rmsle: 0.00067 | valid_mae: 0.08012 | valid_rmse: 0.10499 | valid_mse: 0.01102 |  0:02:18s\n",
      "epoch 87 | loss: 0.01205 | train_rmsle: 0.00055 | train_mae: 0.08179 | train_rmse: 0.09906 | train_mse: 0.00981 | valid_rmsle: 0.00083 | valid_mae: 0.09621 | valid_rmse: 0.12209 | valid_mse: 0.01491 |  0:02:19s\n",
      "epoch 88 | loss: 0.0129  | train_rmsle: 0.0004  | train_mae: 0.05682 | train_rmse: 0.07454 | train_mse: 0.00556 | valid_rmsle: 0.00067 | valid_mae: 0.07905 | valid_rmse: 0.10365 | valid_mse: 0.01074 |  0:02:21s\n",
      "epoch 89 | loss: 0.01294 | train_rmsle: 0.00066 | train_mae: 0.07107 | train_rmse: 0.09453 | train_mse: 0.00894 | valid_rmsle: 0.00091 | valid_mae: 0.09202 | valid_rmse: 0.11759 | valid_mse: 0.01383 |  0:02:23s\n",
      "epoch 90 | loss: 0.01047 | train_rmsle: 0.00022 | train_mae: 0.0473  | train_rmse: 0.06118 | train_mse: 0.00374 | valid_rmsle: 0.00051 | valid_mae: 0.07154 | valid_rmse: 0.094   | valid_mse: 0.00884 |  0:02:24s\n",
      "epoch 91 | loss: 0.0084  | train_rmsle: 0.00022 | train_mae: 0.04657 | train_rmse: 0.06021 | train_mse: 0.00362 | valid_rmsle: 0.0005  | valid_mae: 0.07079 | valid_rmse: 0.09328 | valid_mse: 0.0087  |  0:02:26s\n",
      "epoch 92 | loss: 0.00832 | train_rmsle: 0.00027 | train_mae: 0.0507  | train_rmse: 0.06538 | train_mse: 0.00428 | valid_rmsle: 0.00055 | valid_mae: 0.07376 | valid_rmse: 0.09673 | valid_mse: 0.00936 |  0:02:28s\n",
      "epoch 93 | loss: 0.00933 | train_rmsle: 0.00028 | train_mae: 0.05426 | train_rmse: 0.06824 | train_mse: 0.00466 | valid_rmsle: 0.00057 | valid_mae: 0.07819 | valid_rmse: 0.10028 | valid_mse: 0.01006 |  0:02:29s\n",
      "epoch 94 | loss: 0.01418 | train_rmsle: 0.0003  | train_mae: 0.05097 | train_rmse: 0.06609 | train_mse: 0.00437 | valid_rmsle: 0.00058 | valid_mae: 0.07514 | valid_rmse: 0.09813 | valid_mse: 0.00963 |  0:02:31s\n",
      "epoch 95 | loss: 0.0115  | train_rmsle: 0.00028 | train_mae: 0.05422 | train_rmse: 0.06832 | train_mse: 0.00467 | valid_rmsle: 0.00057 | valid_mae: 0.07796 | valid_rmse: 0.0992  | valid_mse: 0.00984 |  0:02:33s\n",
      "epoch 96 | loss: 0.00951 | train_rmsle: 0.00021 | train_mae: 0.04631 | train_rmse: 0.05932 | train_mse: 0.00352 | valid_rmsle: 0.0005  | valid_mae: 0.07227 | valid_rmse: 0.09313 | valid_mse: 0.00867 |  0:02:34s\n",
      "epoch 97 | loss: 0.00921 | train_rmsle: 0.00022 | train_mae: 0.04644 | train_rmse: 0.05978 | train_mse: 0.00357 | valid_rmsle: 0.0005  | valid_mae: 0.07239 | valid_rmse: 0.09412 | valid_mse: 0.00886 |  0:02:36s\n",
      "epoch 98 | loss: 0.0085  | train_rmsle: 0.00025 | train_mae: 0.05207 | train_rmse: 0.06512 | train_mse: 0.00424 | valid_rmsle: 0.00055 | valid_mae: 0.077   | valid_rmse: 0.09872 | valid_mse: 0.00975 |  0:02:37s\n",
      "epoch 99 | loss: 0.00932 | train_rmsle: 0.00059 | train_mae: 0.08828 | train_rmse: 0.10064 | train_mse: 0.01013 | valid_rmsle: 0.00087 | valid_mae: 0.1022  | valid_rmse: 0.12384 | valid_mse: 0.01534 |  0:02:39s\n",
      "epoch 100| loss: 0.00901 | train_rmsle: 0.00019 | train_mae: 0.04407 | train_rmse: 0.05636 | train_mse: 0.00318 | valid_rmsle: 0.0005  | valid_mae: 0.07127 | valid_rmse: 0.09356 | valid_mse: 0.00875 |  0:02:41s\n",
      "epoch 101| loss: 0.00775 | train_rmsle: 0.00033 | train_mae: 0.06164 | train_rmse: 0.0753  | train_mse: 0.00567 | valid_rmsle: 0.00064 | valid_mae: 0.08148 | valid_rmse: 0.10638 | valid_mse: 0.01132 |  0:02:42s\n",
      "epoch 102| loss: 0.00977 | train_rmsle: 0.00023 | train_mae: 0.05063 | train_rmse: 0.06464 | train_mse: 0.00418 | valid_rmsle: 0.00053 | valid_mae: 0.07457 | valid_rmse: 0.09809 | valid_mse: 0.00962 |  0:02:44s\n",
      "epoch 103| loss: 0.00967 | train_rmsle: 0.00026 | train_mae: 0.05071 | train_rmse: 0.06357 | train_mse: 0.00404 | valid_rmsle: 0.00056 | valid_mae: 0.07653 | valid_rmse: 0.09771 | valid_mse: 0.00955 |  0:02:46s\n",
      "epoch 104| loss: 0.00852 | train_rmsle: 0.00029 | train_mae: 0.05984 | train_rmse: 0.07261 | train_mse: 0.00527 | valid_rmsle: 0.00059 | valid_mae: 0.08244 | valid_rmse: 0.10315 | valid_mse: 0.01064 |  0:02:47s\n",
      "epoch 105| loss: 0.00957 | train_rmsle: 0.00045 | train_mae: 0.0755  | train_rmse: 0.08806 | train_mse: 0.00775 | valid_rmsle: 0.00074 | valid_mae: 0.09243 | valid_rmse: 0.11365 | valid_mse: 0.01292 |  0:02:49s\n",
      "epoch 106| loss: 0.00875 | train_rmsle: 0.0003  | train_mae: 0.05969 | train_rmse: 0.07196 | train_mse: 0.00518 | valid_rmsle: 0.00059 | valid_mae: 0.08066 | valid_rmse: 0.10109 | valid_mse: 0.01022 |  0:02:51s\n",
      "epoch 107| loss: 0.00962 | train_rmsle: 0.00029 | train_mae: 0.05878 | train_rmse: 0.07186 | train_mse: 0.00516 | valid_rmsle: 0.00058 | valid_mae: 0.07819 | valid_rmse: 0.10212 | valid_mse: 0.01043 |  0:02:52s\n",
      "epoch 108| loss: 0.01036 | train_rmsle: 0.0002  | train_mae: 0.04681 | train_rmse: 0.05917 | train_mse: 0.0035  | valid_rmsle: 0.00049 | valid_mae: 0.07107 | valid_rmse: 0.09349 | valid_mse: 0.00874 |  0:02:54s\n",
      "epoch 109| loss: 0.0087  | train_rmsle: 0.00016 | train_mae: 0.04093 | train_rmse: 0.05224 | train_mse: 0.00273 | valid_rmsle: 0.00047 | valid_mae: 0.07042 | valid_rmse: 0.09072 | valid_mse: 0.00823 |  0:02:55s\n",
      "epoch 110| loss: 0.00879 | train_rmsle: 0.00094 | train_mae: 0.09229 | train_rmse: 0.1142  | train_mse: 0.01304 | valid_rmsle: 0.00123 | valid_mae: 0.10681 | valid_rmse: 0.13633 | valid_mse: 0.01859 |  0:02:57s\n",
      "epoch 111| loss: 0.00964 | train_rmsle: 0.0003  | train_mae: 0.0576  | train_rmse: 0.07103 | train_mse: 0.00505 | valid_rmsle: 0.0006  | valid_mae: 0.07862 | valid_rmse: 0.10249 | valid_mse: 0.0105  |  0:02:59s\n",
      "epoch 112| loss: 0.01051 | train_rmsle: 0.00022 | train_mae: 0.04936 | train_rmse: 0.06221 | train_mse: 0.00387 | valid_rmsle: 0.00054 | valid_mae: 0.07784 | valid_rmse: 0.09809 | valid_mse: 0.00962 |  0:03:00s\n",
      "epoch 113| loss: 0.00917 | train_rmsle: 0.00045 | train_mae: 0.07555 | train_rmse: 0.08813 | train_mse: 0.00777 | valid_rmsle: 0.00076 | valid_mae: 0.09415 | valid_rmse: 0.11534 | valid_mse: 0.0133  |  0:03:02s\n",
      "epoch 114| loss: 0.00854 | train_rmsle: 0.00031 | train_mae: 0.05304 | train_rmse: 0.06822 | train_mse: 0.00465 | valid_rmsle: 0.00063 | valid_mae: 0.07905 | valid_rmse: 0.10199 | valid_mse: 0.0104  |  0:03:04s\n",
      "epoch 115| loss: 0.00817 | train_rmsle: 0.00022 | train_mae: 0.05108 | train_rmse: 0.06392 | train_mse: 0.00409 | valid_rmsle: 0.00054 | valid_mae: 0.07823 | valid_rmse: 0.09798 | valid_mse: 0.0096  |  0:03:05s\n",
      "epoch 116| loss: 0.00935 | train_rmsle: 0.00028 | train_mae: 0.05625 | train_rmse: 0.06831 | train_mse: 0.00467 | valid_rmsle: 0.0006  | valid_mae: 0.08119 | valid_rmse: 0.10211 | valid_mse: 0.01043 |  0:03:07s\n",
      "epoch 117| loss: 0.00884 | train_rmsle: 0.00042 | train_mae: 0.06977 | train_rmse: 0.08182 | train_mse: 0.0067  | valid_rmsle: 0.00073 | valid_mae: 0.08996 | valid_rmse: 0.11127 | valid_mse: 0.01238 |  0:03:09s\n",
      "epoch 118| loss: 0.0083  | train_rmsle: 0.00019 | train_mae: 0.0423  | train_rmse: 0.05412 | train_mse: 0.00293 | valid_rmsle: 0.00053 | valid_mae: 0.07251 | valid_rmse: 0.0942  | valid_mse: 0.00887 |  0:03:10s\n",
      "epoch 119| loss: 0.00761 | train_rmsle: 0.00028 | train_mae: 0.05354 | train_rmse: 0.06806 | train_mse: 0.00463 | valid_rmsle: 0.00061 | valid_mae: 0.07749 | valid_rmse: 0.10195 | valid_mse: 0.01039 |  0:03:12s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 109 and best_valid_mse = 0.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008290198305983244 RMSE: 0.0910505261159058 R2: 0.9633024864668077 MAE: 0.06962713662719916\n",
      "=====================================\n",
      "Successfully saved model at model/512_16_3_0.02_120.pt.zip\n",
      "New best model: 512_16_3_0.02_120 with r2: 0.9633024864668077\n",
      "[39/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25806 | train_rmsle: 0.16137 | train_mae: 1.38403 | train_rmse: 1.4619  | train_mse: 2.13715 | valid_rmsle: 0.16213 | valid_mae: 1.38796 | valid_rmse: 1.46633 | valid_mse: 2.15013 |  0:00:01s\n",
      "epoch 1  | loss: 0.35967 | train_rmsle: 0.1098  | train_mae: 1.16754 | train_rmse: 1.25285 | train_mse: 1.56962 | valid_rmsle: 0.11029 | valid_mae: 1.17063 | valid_rmse: 1.25685 | valid_mse: 1.57967 |  0:00:02s\n",
      "epoch 2  | loss: 0.26771 | train_rmsle: 0.05449 | train_mae: 0.83962 | train_rmse: 0.9326  | train_mse: 0.86975 | valid_rmsle: 0.05448 | valid_mae: 0.83979 | valid_rmse: 0.93468 | valid_mse: 0.87362 |  0:00:04s\n",
      "epoch 3  | loss: 0.24587 | train_rmsle: 0.04306 | train_mae: 0.74839 | train_rmse: 0.84082 | train_mse: 0.70698 | valid_rmsle: 0.04307 | valid_mae: 0.74848 | valid_rmse: 0.84329 | valid_mse: 0.71113 |  0:00:05s\n",
      "epoch 4  | loss: 0.23121 | train_rmsle: 0.03004 | train_mae: 0.62193 | train_rmse: 0.71342 | train_mse: 0.50897 | valid_rmsle: 0.0298  | valid_mae: 0.62106 | valid_rmse: 0.71382 | valid_mse: 0.50954 |  0:00:07s\n",
      "epoch 5  | loss: 0.22596 | train_rmsle: 0.02275 | train_mae: 0.53581 | train_rmse: 0.62461 | train_mse: 0.39013 | valid_rmsle: 0.02247 | valid_mae: 0.53654 | valid_rmse: 0.62461 | valid_mse: 0.39014 |  0:00:09s\n",
      "epoch 6  | loss: 0.22236 | train_rmsle: 0.01826 | train_mae: 0.47077 | train_rmse: 0.55789 | train_mse: 0.31124 | valid_rmsle: 0.01788 | valid_mae: 0.47163 | valid_rmse: 0.55679 | valid_mse: 0.31002 |  0:00:10s\n",
      "epoch 7  | loss: 0.22582 | train_rmsle: 0.02021 | train_mae: 0.50115 | train_rmse: 0.5888  | train_mse: 0.34668 | valid_rmsle: 0.01978 | valid_mae: 0.50044 | valid_rmse: 0.5869  | valid_mse: 0.34445 |  0:00:12s\n",
      "epoch 8  | loss: 0.21553 | train_rmsle: 0.01476 | train_mae: 0.40632 | train_rmse: 0.49404 | train_mse: 0.24408 | valid_rmsle: 0.01437 | valid_mae: 0.40816 | valid_rmse: 0.49319 | valid_mse: 0.24324 |  0:00:14s\n",
      "epoch 9  | loss: 0.21478 | train_rmsle: 0.01394 | train_mae: 0.38402 | train_rmse: 0.47518 | train_mse: 0.2258  | valid_rmsle: 0.01347 | valid_mae: 0.38605 | valid_rmse: 0.47299 | valid_mse: 0.22372 |  0:00:15s\n",
      "epoch 10 | loss: 0.20802 | train_rmsle: 0.01418 | train_mae: 0.39695 | train_rmse: 0.48372 | train_mse: 0.23398 | valid_rmsle: 0.01378 | valid_mae: 0.39878 | valid_rmse: 0.48243 | valid_mse: 0.23274 |  0:00:17s\n",
      "epoch 11 | loss: 0.19951 | train_rmsle: 0.01288 | train_mae: 0.36244 | train_rmse: 0.45301 | train_mse: 0.20521 | valid_rmsle: 0.01236 | valid_mae: 0.36298 | valid_rmse: 0.4491  | valid_mse: 0.20169 |  0:00:19s\n",
      "epoch 12 | loss: 0.19172 | train_rmsle: 0.01226 | train_mae: 0.35579 | train_rmse: 0.44341 | train_mse: 0.19661 | valid_rmsle: 0.01177 | valid_mae: 0.35707 | valid_rmse: 0.44025 | valid_mse: 0.19382 |  0:00:20s\n",
      "epoch 13 | loss: 0.18183 | train_rmsle: 0.01018 | train_mae: 0.32981 | train_rmse: 0.40615 | train_mse: 0.16495 | valid_rmsle: 0.0098  | valid_mae: 0.33154 | valid_rmse: 0.40489 | valid_mse: 0.16394 |  0:00:22s\n",
      "epoch 14 | loss: 0.16379 | train_rmsle: 0.01151 | train_mae: 0.37106 | train_rmse: 0.43952 | train_mse: 0.19318 | valid_rmsle: 0.01144 | valid_mae: 0.37338 | valid_rmse: 0.44292 | valid_mse: 0.19618 |  0:00:23s\n",
      "epoch 15 | loss: 0.13555 | train_rmsle: 0.01054 | train_mae: 0.34695 | train_rmse: 0.41495 | train_mse: 0.17218 | valid_rmsle: 0.01028 | valid_mae: 0.3468  | valid_rmse: 0.41435 | valid_mse: 0.17169 |  0:00:25s\n",
      "epoch 16 | loss: 0.11419 | train_rmsle: 0.01237 | train_mae: 0.37178 | train_rmse: 0.44283 | train_mse: 0.1961  | valid_rmsle: 0.0122  | valid_mae: 0.37391 | valid_rmse: 0.44374 | valid_mse: 0.1969  |  0:00:27s\n",
      "epoch 17 | loss: 0.09763 | train_rmsle: 0.00908 | train_mae: 0.31585 | train_rmse: 0.3803  | train_mse: 0.14463 | valid_rmsle: 0.00877 | valid_mae: 0.31503 | valid_rmse: 0.37813 | valid_mse: 0.14298 |  0:00:28s\n",
      "epoch 18 | loss: 0.08568 | train_rmsle: 0.00774 | train_mae: 0.28534 | train_rmse: 0.34781 | train_mse: 0.12097 | valid_rmsle: 0.00742 | valid_mae: 0.28446 | valid_rmse: 0.34379 | valid_mse: 0.11819 |  0:00:30s\n",
      "epoch 19 | loss: 0.07544 | train_rmsle: 0.00495 | train_mae: 0.22748 | train_rmse: 0.28089 | train_mse: 0.0789  | valid_rmsle: 0.00477 | valid_mae: 0.22821 | valid_rmse: 0.27867 | valid_mse: 0.07766 |  0:00:31s\n",
      "epoch 20 | loss: 0.06821 | train_rmsle: 0.00429 | train_mae: 0.22137 | train_rmse: 0.27036 | train_mse: 0.07309 | valid_rmsle: 0.00427 | valid_mae: 0.22409 | valid_rmse: 0.2728  | valid_mse: 0.07442 |  0:00:33s\n",
      "epoch 21 | loss: 0.05828 | train_rmsle: 0.00293 | train_mae: 0.17773 | train_rmse: 0.22461 | train_mse: 0.05045 | valid_rmsle: 0.00288 | valid_mae: 0.18163 | valid_rmse: 0.22722 | valid_mse: 0.05163 |  0:00:34s\n",
      "epoch 22 | loss: 0.04963 | train_rmsle: 0.00286 | train_mae: 0.1773  | train_rmse: 0.22003 | train_mse: 0.04841 | valid_rmsle: 0.0029  | valid_mae: 0.18139 | valid_rmse: 0.22579 | valid_mse: 0.05098 |  0:00:35s\n",
      "epoch 23 | loss: 0.04728 | train_rmsle: 0.00312 | train_mae: 0.19152 | train_rmse: 0.23528 | train_mse: 0.05536 | valid_rmsle: 0.0032  | valid_mae: 0.19742 | valid_rmse: 0.2424  | valid_mse: 0.05876 |  0:00:37s\n",
      "epoch 24 | loss: 0.04214 | train_rmsle: 0.00256 | train_mae: 0.17056 | train_rmse: 0.21457 | train_mse: 0.04604 | valid_rmsle: 0.00265 | valid_mae: 0.17749 | valid_rmse: 0.22261 | valid_mse: 0.04956 |  0:00:38s\n",
      "epoch 25 | loss: 0.03916 | train_rmsle: 0.00195 | train_mae: 0.1421  | train_rmse: 0.18136 | train_mse: 0.03289 | valid_rmsle: 0.00202 | valid_mae: 0.14845 | valid_rmse: 0.1895  | valid_mse: 0.03591 |  0:00:40s\n",
      "epoch 26 | loss: 0.03935 | train_rmsle: 0.002   | train_mae: 0.14331 | train_rmse: 0.18168 | train_mse: 0.03301 | valid_rmsle: 0.00209 | valid_mae: 0.14969 | valid_rmse: 0.1903  | valid_mse: 0.03621 |  0:00:41s\n",
      "epoch 27 | loss: 0.03464 | train_rmsle: 0.00321 | train_mae: 0.17919 | train_rmse: 0.21991 | train_mse: 0.04836 | valid_rmsle: 0.0034  | valid_mae: 0.18746 | valid_rmse: 0.23086 | valid_mse: 0.0533  |  0:00:43s\n",
      "epoch 28 | loss: 0.0331  | train_rmsle: 0.00139 | train_mae: 0.11792 | train_rmse: 0.15574 | train_mse: 0.02425 | valid_rmsle: 0.0015  | valid_mae: 0.12666 | valid_rmse: 0.16598 | valid_mse: 0.02755 |  0:00:44s\n",
      "epoch 29 | loss: 0.03059 | train_rmsle: 0.00156 | train_mae: 0.12786 | train_rmse: 0.16151 | train_mse: 0.02608 | valid_rmsle: 0.00168 | valid_mae: 0.13481 | valid_rmse: 0.1727  | valid_mse: 0.02982 |  0:00:46s\n",
      "epoch 30 | loss: 0.02827 | train_rmsle: 0.0012  | train_mae: 0.11094 | train_rmse: 0.14573 | train_mse: 0.02124 | valid_rmsle: 0.00137 | valid_mae: 0.12224 | valid_rmse: 0.15956 | valid_mse: 0.02546 |  0:00:48s\n",
      "epoch 31 | loss: 0.02849 | train_rmsle: 0.00144 | train_mae: 0.12199 | train_rmse: 0.16469 | train_mse: 0.02712 | valid_rmsle: 0.00179 | valid_mae: 0.13776 | valid_rmse: 0.1858  | valid_mse: 0.03452 |  0:00:49s\n",
      "epoch 32 | loss: 0.02827 | train_rmsle: 0.00181 | train_mae: 0.14429 | train_rmse: 0.17564 | train_mse: 0.03085 | valid_rmsle: 0.00203 | valid_mae: 0.15329 | valid_rmse: 0.18974 | valid_mse: 0.036   |  0:00:51s\n",
      "epoch 33 | loss: 0.02595 | train_rmsle: 0.00099 | train_mae: 0.10119 | train_rmse: 0.13342 | train_mse: 0.0178  | valid_rmsle: 0.00125 | valid_mae: 0.11603 | valid_rmse: 0.15299 | valid_mse: 0.02341 |  0:00:53s\n",
      "epoch 34 | loss: 0.02374 | train_rmsle: 0.00109 | train_mae: 0.10609 | train_rmse: 0.13682 | train_mse: 0.01872 | valid_rmsle: 0.00138 | valid_mae: 0.12225 | valid_rmse: 0.15628 | valid_mse: 0.02442 |  0:00:54s\n",
      "epoch 35 | loss: 0.02157 | train_rmsle: 0.001   | train_mae: 0.10183 | train_rmse: 0.13038 | train_mse: 0.017   | valid_rmsle: 0.00122 | valid_mae: 0.11471 | valid_rmse: 0.14787 | valid_mse: 0.02186 |  0:00:56s\n",
      "epoch 36 | loss: 0.0208  | train_rmsle: 0.0027  | train_mae: 0.16298 | train_rmse: 0.19608 | train_mse: 0.03845 | valid_rmsle: 0.00291 | valid_mae: 0.1746  | valid_rmse: 0.20908 | valid_mse: 0.04372 |  0:00:58s\n",
      "epoch 37 | loss: 0.02073 | train_rmsle: 0.00096 | train_mae: 0.10468 | train_rmse: 0.13214 | train_mse: 0.01746 | valid_rmsle: 0.00124 | valid_mae: 0.12017 | valid_rmse: 0.15242 | valid_mse: 0.02323 |  0:00:59s\n",
      "epoch 38 | loss: 0.02074 | train_rmsle: 0.00228 | train_mae: 0.13767 | train_rmse: 0.17583 | train_mse: 0.03092 | valid_rmsle: 0.00244 | valid_mae: 0.15112 | valid_rmse: 0.18863 | valid_mse: 0.03558 |  0:01:01s\n",
      "epoch 39 | loss: 0.01828 | train_rmsle: 0.00078 | train_mae: 0.09063 | train_rmse: 0.11735 | train_mse: 0.01377 | valid_rmsle: 0.00107 | valid_mae: 0.10872 | valid_rmse: 0.14002 | valid_mse: 0.01961 |  0:01:02s\n",
      "epoch 40 | loss: 0.01874 | train_rmsle: 0.00067 | train_mae: 0.08331 | train_rmse: 0.10899 | train_mse: 0.01188 | valid_rmsle: 0.00097 | valid_mae: 0.1023  | valid_rmse: 0.1338  | valid_mse: 0.0179  |  0:01:04s\n",
      "epoch 41 | loss: 0.0174  | train_rmsle: 0.00131 | train_mae: 0.12335 | train_rmse: 0.14986 | train_mse: 0.02246 | valid_rmsle: 0.00163 | valid_mae: 0.13707 | valid_rmse: 0.17059 | valid_mse: 0.0291  |  0:01:06s\n",
      "epoch 42 | loss: 0.01884 | train_rmsle: 0.00101 | train_mae: 0.10379 | train_rmse: 0.12783 | train_mse: 0.01634 | valid_rmsle: 0.00129 | valid_mae: 0.11995 | valid_rmse: 0.14876 | valid_mse: 0.02213 |  0:01:07s\n",
      "epoch 43 | loss: 0.01978 | train_rmsle: 0.0009  | train_mae: 0.10378 | train_rmse: 0.13039 | train_mse: 0.017   | valid_rmsle: 0.0012  | valid_mae: 0.11884 | valid_rmse: 0.1516  | valid_mse: 0.02298 |  0:01:09s\n",
      "epoch 44 | loss: 0.0193  | train_rmsle: 0.00078 | train_mae: 0.08819 | train_rmse: 0.11192 | train_mse: 0.01253 | valid_rmsle: 0.00102 | valid_mae: 0.10503 | valid_rmse: 0.13269 | valid_mse: 0.01761 |  0:01:10s\n",
      "epoch 45 | loss: 0.01568 | train_rmsle: 0.00057 | train_mae: 0.07771 | train_rmse: 0.10041 | train_mse: 0.01008 | valid_rmsle: 0.00086 | valid_mae: 0.09771 | valid_rmse: 0.1254  | valid_mse: 0.01572 |  0:01:12s\n",
      "epoch 46 | loss: 0.01494 | train_rmsle: 0.00054 | train_mae: 0.07438 | train_rmse: 0.09763 | train_mse: 0.00953 | valid_rmsle: 0.00087 | valid_mae: 0.0943  | valid_rmse: 0.1256  | valid_mse: 0.01578 |  0:01:14s\n",
      "epoch 47 | loss: 0.01788 | train_rmsle: 0.00055 | train_mae: 0.07644 | train_rmse: 0.09807 | train_mse: 0.00962 | valid_rmsle: 0.00085 | valid_mae: 0.09419 | valid_rmse: 0.12385 | valid_mse: 0.01534 |  0:01:16s\n",
      "epoch 48 | loss: 0.01621 | train_rmsle: 0.00049 | train_mae: 0.07092 | train_rmse: 0.09482 | train_mse: 0.00899 | valid_rmsle: 0.00076 | valid_mae: 0.08907 | valid_rmse: 0.11889 | valid_mse: 0.01414 |  0:01:17s\n",
      "epoch 49 | loss: 0.01363 | train_rmsle: 0.00088 | train_mae: 0.08942 | train_rmse: 0.11395 | train_mse: 0.01298 | valid_rmsle: 0.00108 | valid_mae: 0.10429 | valid_rmse: 0.13148 | valid_mse: 0.01729 |  0:01:19s\n",
      "epoch 50 | loss: 0.0148  | train_rmsle: 0.00056 | train_mae: 0.07535 | train_rmse: 0.09781 | train_mse: 0.00957 | valid_rmsle: 0.00081 | valid_mae: 0.09213 | valid_rmse: 0.12    | valid_mse: 0.0144  |  0:01:21s\n",
      "epoch 51 | loss: 0.01566 | train_rmsle: 0.00114 | train_mae: 0.10459 | train_rmse: 0.1304  | train_mse: 0.017   | valid_rmsle: 0.00141 | valid_mae: 0.11844 | valid_rmse: 0.14994 | valid_mse: 0.02248 |  0:01:22s\n",
      "epoch 52 | loss: 0.01701 | train_rmsle: 0.00059 | train_mae: 0.08072 | train_rmse: 0.10255 | train_mse: 0.01052 | valid_rmsle: 0.00092 | valid_mae: 0.09934 | valid_rmse: 0.12991 | valid_mse: 0.01688 |  0:01:24s\n",
      "epoch 53 | loss: 0.01534 | train_rmsle: 0.0005  | train_mae: 0.07336 | train_rmse: 0.09444 | train_mse: 0.00892 | valid_rmsle: 0.00083 | valid_mae: 0.09245 | valid_rmse: 0.12274 | valid_mse: 0.01506 |  0:01:26s\n",
      "epoch 54 | loss: 0.01299 | train_rmsle: 0.00047 | train_mae: 0.06946 | train_rmse: 0.08926 | train_mse: 0.00797 | valid_rmsle: 0.00077 | valid_mae: 0.08901 | valid_rmse: 0.11737 | valid_mse: 0.01378 |  0:01:27s\n",
      "epoch 55 | loss: 0.01288 | train_rmsle: 0.00047 | train_mae: 0.07037 | train_rmse: 0.08922 | train_mse: 0.00796 | valid_rmsle: 0.00078 | valid_mae: 0.0901  | valid_rmse: 0.11804 | valid_mse: 0.01393 |  0:01:29s\n",
      "epoch 56 | loss: 0.01464 | train_rmsle: 0.00045 | train_mae: 0.07159 | train_rmse: 0.0911  | train_mse: 0.0083  | valid_rmsle: 0.00081 | valid_mae: 0.09151 | valid_rmse: 0.12169 | valid_mse: 0.01481 |  0:01:31s\n",
      "epoch 57 | loss: 0.01191 | train_rmsle: 0.00039 | train_mae: 0.06382 | train_rmse: 0.08254 | train_mse: 0.00681 | valid_rmsle: 0.00075 | valid_mae: 0.08456 | valid_rmse: 0.11472 | valid_mse: 0.01316 |  0:01:32s\n",
      "epoch 58 | loss: 0.01343 | train_rmsle: 0.00044 | train_mae: 0.0677  | train_rmse: 0.09027 | train_mse: 0.00815 | valid_rmsle: 0.00076 | valid_mae: 0.08743 | valid_rmse: 0.11808 | valid_mse: 0.01394 |  0:01:34s\n",
      "epoch 59 | loss: 0.01074 | train_rmsle: 0.00039 | train_mae: 0.06508 | train_rmse: 0.08343 | train_mse: 0.00696 | valid_rmsle: 0.00068 | valid_mae: 0.08624 | valid_rmse: 0.11125 | valid_mse: 0.01238 |  0:01:35s\n",
      "epoch 60 | loss: 0.01229 | train_rmsle: 0.00085 | train_mae: 0.08377 | train_rmse: 0.10937 | train_mse: 0.01196 | valid_rmsle: 0.00111 | valid_mae: 0.10159 | valid_rmse: 0.13068 | valid_mse: 0.01708 |  0:01:37s\n",
      "epoch 61 | loss: 0.01218 | train_rmsle: 0.00038 | train_mae: 0.06142 | train_rmse: 0.07882 | train_mse: 0.00621 | valid_rmsle: 0.00063 | valid_mae: 0.08206 | valid_rmse: 0.10512 | valid_mse: 0.01105 |  0:01:38s\n",
      "epoch 62 | loss: 0.01082 | train_rmsle: 0.00033 | train_mae: 0.0578  | train_rmse: 0.07587 | train_mse: 0.00576 | valid_rmsle: 0.00059 | valid_mae: 0.07892 | valid_rmse: 0.10311 | valid_mse: 0.01063 |  0:01:40s\n",
      "epoch 63 | loss: 0.01135 | train_rmsle: 0.00035 | train_mae: 0.05846 | train_rmse: 0.07555 | train_mse: 0.00571 | valid_rmsle: 0.0006  | valid_mae: 0.07958 | valid_rmse: 0.10325 | valid_mse: 0.01066 |  0:01:41s\n",
      "epoch 64 | loss: 0.01142 | train_rmsle: 0.00033 | train_mae: 0.05923 | train_rmse: 0.07744 | train_mse: 0.006   | valid_rmsle: 0.00062 | valid_mae: 0.0817  | valid_rmse: 0.10681 | valid_mse: 0.01141 |  0:01:42s\n",
      "epoch 65 | loss: 0.01314 | train_rmsle: 0.00059 | train_mae: 0.08134 | train_rmse: 0.09909 | train_mse: 0.00982 | valid_rmsle: 0.00085 | valid_mae: 0.09777 | valid_rmse: 0.12198 | valid_mse: 0.01488 |  0:01:44s\n",
      "epoch 66 | loss: 0.0103  | train_rmsle: 0.00028 | train_mae: 0.05362 | train_rmse: 0.06963 | train_mse: 0.00485 | valid_rmsle: 0.00054 | valid_mae: 0.0749  | valid_rmse: 0.09855 | valid_mse: 0.00971 |  0:01:45s\n",
      "epoch 67 | loss: 0.01202 | train_rmsle: 0.0003  | train_mae: 0.05601 | train_rmse: 0.07218 | train_mse: 0.00521 | valid_rmsle: 0.00057 | valid_mae: 0.07708 | valid_rmse: 0.10167 | valid_mse: 0.01034 |  0:01:47s\n",
      "epoch 68 | loss: 0.0134  | train_rmsle: 0.00073 | train_mae: 0.09648 | train_rmse: 0.11318 | train_mse: 0.01281 | valid_rmsle: 0.001   | valid_mae: 0.10707 | valid_rmse: 0.13275 | valid_mse: 0.01762 |  0:01:48s\n",
      "epoch 69 | loss: 0.01376 | train_rmsle: 0.00026 | train_mae: 0.05201 | train_rmse: 0.06712 | train_mse: 0.0045  | valid_rmsle: 0.00054 | valid_mae: 0.07457 | valid_rmse: 0.09867 | valid_mse: 0.00974 |  0:01:50s\n",
      "epoch 70 | loss: 0.01598 | train_rmsle: 0.00119 | train_mae: 0.11623 | train_rmse: 0.13491 | train_mse: 0.0182  | valid_rmsle: 0.00145 | valid_mae: 0.12817 | valid_rmse: 0.15276 | valid_mse: 0.02333 |  0:01:51s\n",
      "epoch 71 | loss: 0.01669 | train_rmsle: 0.0007  | train_mae: 0.09357 | train_rmse: 0.10957 | train_mse: 0.012   | valid_rmsle: 0.00098 | valid_mae: 0.10818 | valid_rmse: 0.13158 | valid_mse: 0.01731 |  0:01:53s\n",
      "epoch 72 | loss: 0.01373 | train_rmsle: 0.00062 | train_mae: 0.08047 | train_rmse: 0.09865 | train_mse: 0.00973 | valid_rmsle: 0.00084 | valid_mae: 0.09621 | valid_rmse: 0.11964 | valid_mse: 0.01431 |  0:01:54s\n",
      "epoch 73 | loss: 0.01268 | train_rmsle: 0.00057 | train_mae: 0.08634 | train_rmse: 0.10526 | train_mse: 0.01108 | valid_rmsle: 0.00085 | valid_mae: 0.10235 | valid_rmse: 0.12768 | valid_mse: 0.0163  |  0:01:56s\n",
      "epoch 74 | loss: 0.01143 | train_rmsle: 0.00055 | train_mae: 0.08341 | train_rmse: 0.09921 | train_mse: 0.00984 | valid_rmsle: 0.00081 | valid_mae: 0.09904 | valid_rmse: 0.12208 | valid_mse: 0.0149  |  0:01:58s\n",
      "epoch 75 | loss: 0.01183 | train_rmsle: 0.00036 | train_mae: 0.06409 | train_rmse: 0.08082 | train_mse: 0.00653 | valid_rmsle: 0.00061 | valid_mae: 0.07999 | valid_rmse: 0.10504 | valid_mse: 0.01103 |  0:01:59s\n",
      "epoch 76 | loss: 0.01005 | train_rmsle: 0.00026 | train_mae: 0.0525  | train_rmse: 0.0674  | train_mse: 0.00454 | valid_rmsle: 0.00051 | valid_mae: 0.07326 | valid_rmse: 0.09598 | valid_mse: 0.00921 |  0:02:01s\n",
      "epoch 77 | loss: 0.01011 | train_rmsle: 0.00043 | train_mae: 0.06208 | train_rmse: 0.08011 | train_mse: 0.00642 | valid_rmsle: 0.00071 | valid_mae: 0.084   | valid_rmse: 0.10766 | valid_mse: 0.01159 |  0:02:03s\n",
      "epoch 78 | loss: 0.00994 | train_rmsle: 0.00034 | train_mae: 0.06108 | train_rmse: 0.07559 | train_mse: 0.00571 | valid_rmsle: 0.00061 | valid_mae: 0.0829  | valid_rmse: 0.10458 | valid_mse: 0.01094 |  0:02:04s\n",
      "epoch 79 | loss: 0.01057 | train_rmsle: 0.00035 | train_mae: 0.06366 | train_rmse: 0.07981 | train_mse: 0.00637 | valid_rmsle: 0.00062 | valid_mae: 0.08152 | valid_rmse: 0.10679 | valid_mse: 0.0114  |  0:02:06s\n",
      "epoch 80 | loss: 0.01055 | train_rmsle: 0.00028 | train_mae: 0.05386 | train_rmse: 0.06888 | train_mse: 0.00475 | valid_rmsle: 0.00055 | valid_mae: 0.07544 | valid_rmse: 0.09949 | valid_mse: 0.0099  |  0:02:07s\n",
      "epoch 81 | loss: 0.01115 | train_rmsle: 0.00045 | train_mae: 0.06685 | train_rmse: 0.08303 | train_mse: 0.00689 | valid_rmsle: 0.00073 | valid_mae: 0.08791 | valid_rmse: 0.11062 | valid_mse: 0.01224 |  0:02:09s\n",
      "epoch 82 | loss: 0.01046 | train_rmsle: 0.00033 | train_mae: 0.05761 | train_rmse: 0.07296 | train_mse: 0.00532 | valid_rmsle: 0.00061 | valid_mae: 0.07949 | valid_rmse: 0.10208 | valid_mse: 0.01042 |  0:02:11s\n",
      "epoch 83 | loss: 0.0109  | train_rmsle: 0.00066 | train_mae: 0.09172 | train_rmse: 0.10577 | train_mse: 0.01119 | valid_rmsle: 0.00094 | valid_mae: 0.10653 | valid_rmse: 0.1288  | valid_mse: 0.01659 |  0:02:12s\n",
      "epoch 84 | loss: 0.01047 | train_rmsle: 0.00029 | train_mae: 0.05598 | train_rmse: 0.07034 | train_mse: 0.00495 | valid_rmsle: 0.00058 | valid_mae: 0.0793  | valid_rmse: 0.10182 | valid_mse: 0.01037 |  0:02:14s\n",
      "epoch 85 | loss: 0.00974 | train_rmsle: 0.00022 | train_mae: 0.04792 | train_rmse: 0.06148 | train_mse: 0.00378 | valid_rmsle: 0.00052 | valid_mae: 0.0739  | valid_rmse: 0.09659 | valid_mse: 0.00933 |  0:02:16s\n",
      "epoch 86 | loss: 0.00942 | train_rmsle: 0.00039 | train_mae: 0.05964 | train_rmse: 0.07642 | train_mse: 0.00584 | valid_rmsle: 0.00067 | valid_mae: 0.08012 | valid_rmse: 0.10499 | valid_mse: 0.01102 |  0:02:17s\n",
      "epoch 87 | loss: 0.01205 | train_rmsle: 0.00055 | train_mae: 0.08179 | train_rmse: 0.09906 | train_mse: 0.00981 | valid_rmsle: 0.00083 | valid_mae: 0.09621 | valid_rmse: 0.12209 | valid_mse: 0.01491 |  0:02:19s\n",
      "epoch 88 | loss: 0.0129  | train_rmsle: 0.0004  | train_mae: 0.05682 | train_rmse: 0.07454 | train_mse: 0.00556 | valid_rmsle: 0.00067 | valid_mae: 0.07905 | valid_rmse: 0.10365 | valid_mse: 0.01074 |  0:02:20s\n",
      "epoch 89 | loss: 0.01294 | train_rmsle: 0.00066 | train_mae: 0.07107 | train_rmse: 0.09453 | train_mse: 0.00894 | valid_rmsle: 0.00091 | valid_mae: 0.09202 | valid_rmse: 0.11759 | valid_mse: 0.01383 |  0:02:22s\n",
      "epoch 90 | loss: 0.01047 | train_rmsle: 0.00022 | train_mae: 0.0473  | train_rmse: 0.06118 | train_mse: 0.00374 | valid_rmsle: 0.00051 | valid_mae: 0.07154 | valid_rmse: 0.094   | valid_mse: 0.00884 |  0:02:23s\n",
      "epoch 91 | loss: 0.0084  | train_rmsle: 0.00022 | train_mae: 0.04657 | train_rmse: 0.06021 | train_mse: 0.00362 | valid_rmsle: 0.0005  | valid_mae: 0.07079 | valid_rmse: 0.09328 | valid_mse: 0.0087  |  0:02:25s\n",
      "epoch 92 | loss: 0.00832 | train_rmsle: 0.00027 | train_mae: 0.0507  | train_rmse: 0.06538 | train_mse: 0.00428 | valid_rmsle: 0.00055 | valid_mae: 0.07376 | valid_rmse: 0.09673 | valid_mse: 0.00936 |  0:02:27s\n",
      "epoch 93 | loss: 0.00933 | train_rmsle: 0.00028 | train_mae: 0.05426 | train_rmse: 0.06824 | train_mse: 0.00466 | valid_rmsle: 0.00057 | valid_mae: 0.07819 | valid_rmse: 0.10028 | valid_mse: 0.01006 |  0:02:28s\n",
      "epoch 94 | loss: 0.01418 | train_rmsle: 0.0003  | train_mae: 0.05097 | train_rmse: 0.06609 | train_mse: 0.00437 | valid_rmsle: 0.00058 | valid_mae: 0.07514 | valid_rmse: 0.09813 | valid_mse: 0.00963 |  0:02:30s\n",
      "epoch 95 | loss: 0.0115  | train_rmsle: 0.00028 | train_mae: 0.05422 | train_rmse: 0.06832 | train_mse: 0.00467 | valid_rmsle: 0.00057 | valid_mae: 0.07796 | valid_rmse: 0.0992  | valid_mse: 0.00984 |  0:02:32s\n",
      "epoch 96 | loss: 0.00951 | train_rmsle: 0.00021 | train_mae: 0.04631 | train_rmse: 0.05932 | train_mse: 0.00352 | valid_rmsle: 0.0005  | valid_mae: 0.07227 | valid_rmse: 0.09313 | valid_mse: 0.00867 |  0:02:33s\n",
      "epoch 97 | loss: 0.00921 | train_rmsle: 0.00022 | train_mae: 0.04644 | train_rmse: 0.05978 | train_mse: 0.00357 | valid_rmsle: 0.0005  | valid_mae: 0.07239 | valid_rmse: 0.09412 | valid_mse: 0.00886 |  0:02:35s\n",
      "epoch 98 | loss: 0.0085  | train_rmsle: 0.00025 | train_mae: 0.05207 | train_rmse: 0.06512 | train_mse: 0.00424 | valid_rmsle: 0.00055 | valid_mae: 0.077   | valid_rmse: 0.09872 | valid_mse: 0.00975 |  0:02:36s\n",
      "epoch 99 | loss: 0.00932 | train_rmsle: 0.00059 | train_mae: 0.08828 | train_rmse: 0.10064 | train_mse: 0.01013 | valid_rmsle: 0.00087 | valid_mae: 0.1022  | valid_rmse: 0.12384 | valid_mse: 0.01534 |  0:02:38s\n",
      "epoch 100| loss: 0.00901 | train_rmsle: 0.00019 | train_mae: 0.04407 | train_rmse: 0.05636 | train_mse: 0.00318 | valid_rmsle: 0.0005  | valid_mae: 0.07127 | valid_rmse: 0.09356 | valid_mse: 0.00875 |  0:02:40s\n",
      "epoch 101| loss: 0.00775 | train_rmsle: 0.00033 | train_mae: 0.06164 | train_rmse: 0.0753  | train_mse: 0.00567 | valid_rmsle: 0.00064 | valid_mae: 0.08148 | valid_rmse: 0.10638 | valid_mse: 0.01132 |  0:02:41s\n",
      "epoch 102| loss: 0.00977 | train_rmsle: 0.00023 | train_mae: 0.05063 | train_rmse: 0.06464 | train_mse: 0.00418 | valid_rmsle: 0.00053 | valid_mae: 0.07457 | valid_rmse: 0.09809 | valid_mse: 0.00962 |  0:02:43s\n",
      "epoch 103| loss: 0.00967 | train_rmsle: 0.00026 | train_mae: 0.05071 | train_rmse: 0.06357 | train_mse: 0.00404 | valid_rmsle: 0.00056 | valid_mae: 0.07653 | valid_rmse: 0.09771 | valid_mse: 0.00955 |  0:02:44s\n",
      "epoch 104| loss: 0.00852 | train_rmsle: 0.00029 | train_mae: 0.05984 | train_rmse: 0.07261 | train_mse: 0.00527 | valid_rmsle: 0.00059 | valid_mae: 0.08244 | valid_rmse: 0.10315 | valid_mse: 0.01064 |  0:02:46s\n",
      "epoch 105| loss: 0.00957 | train_rmsle: 0.00045 | train_mae: 0.0755  | train_rmse: 0.08806 | train_mse: 0.00775 | valid_rmsle: 0.00074 | valid_mae: 0.09243 | valid_rmse: 0.11365 | valid_mse: 0.01292 |  0:02:47s\n",
      "epoch 106| loss: 0.00875 | train_rmsle: 0.0003  | train_mae: 0.05969 | train_rmse: 0.07196 | train_mse: 0.00518 | valid_rmsle: 0.00059 | valid_mae: 0.08066 | valid_rmse: 0.10109 | valid_mse: 0.01022 |  0:02:49s\n",
      "epoch 107| loss: 0.00962 | train_rmsle: 0.00029 | train_mae: 0.05878 | train_rmse: 0.07186 | train_mse: 0.00516 | valid_rmsle: 0.00058 | valid_mae: 0.07819 | valid_rmse: 0.10212 | valid_mse: 0.01043 |  0:02:50s\n",
      "epoch 108| loss: 0.01036 | train_rmsle: 0.0002  | train_mae: 0.04681 | train_rmse: 0.05917 | train_mse: 0.0035  | valid_rmsle: 0.00049 | valid_mae: 0.07107 | valid_rmse: 0.09349 | valid_mse: 0.00874 |  0:02:51s\n",
      "epoch 109| loss: 0.0087  | train_rmsle: 0.00016 | train_mae: 0.04093 | train_rmse: 0.05224 | train_mse: 0.00273 | valid_rmsle: 0.00047 | valid_mae: 0.07042 | valid_rmse: 0.09072 | valid_mse: 0.00823 |  0:02:53s\n",
      "epoch 110| loss: 0.00879 | train_rmsle: 0.00094 | train_mae: 0.09229 | train_rmse: 0.1142  | train_mse: 0.01304 | valid_rmsle: 0.00123 | valid_mae: 0.10681 | valid_rmse: 0.13633 | valid_mse: 0.01859 |  0:02:54s\n",
      "epoch 111| loss: 0.00964 | train_rmsle: 0.0003  | train_mae: 0.0576  | train_rmse: 0.07103 | train_mse: 0.00505 | valid_rmsle: 0.0006  | valid_mae: 0.07862 | valid_rmse: 0.10249 | valid_mse: 0.0105  |  0:02:55s\n",
      "epoch 112| loss: 0.01051 | train_rmsle: 0.00022 | train_mae: 0.04936 | train_rmse: 0.06221 | train_mse: 0.00387 | valid_rmsle: 0.00054 | valid_mae: 0.07784 | valid_rmse: 0.09809 | valid_mse: 0.00962 |  0:02:57s\n",
      "epoch 113| loss: 0.00917 | train_rmsle: 0.00045 | train_mae: 0.07555 | train_rmse: 0.08813 | train_mse: 0.00777 | valid_rmsle: 0.00076 | valid_mae: 0.09415 | valid_rmse: 0.11534 | valid_mse: 0.0133  |  0:02:58s\n",
      "epoch 114| loss: 0.00854 | train_rmsle: 0.00031 | train_mae: 0.05304 | train_rmse: 0.06822 | train_mse: 0.00465 | valid_rmsle: 0.00063 | valid_mae: 0.07905 | valid_rmse: 0.10199 | valid_mse: 0.0104  |  0:03:00s\n",
      "epoch 115| loss: 0.00817 | train_rmsle: 0.00022 | train_mae: 0.05108 | train_rmse: 0.06392 | train_mse: 0.00409 | valid_rmsle: 0.00054 | valid_mae: 0.07823 | valid_rmse: 0.09798 | valid_mse: 0.0096  |  0:03:01s\n",
      "epoch 116| loss: 0.00935 | train_rmsle: 0.00028 | train_mae: 0.05625 | train_rmse: 0.06831 | train_mse: 0.00467 | valid_rmsle: 0.0006  | valid_mae: 0.08119 | valid_rmse: 0.10211 | valid_mse: 0.01043 |  0:03:03s\n",
      "epoch 117| loss: 0.00884 | train_rmsle: 0.00042 | train_mae: 0.06977 | train_rmse: 0.08182 | train_mse: 0.0067  | valid_rmsle: 0.00073 | valid_mae: 0.08996 | valid_rmse: 0.11127 | valid_mse: 0.01238 |  0:03:04s\n",
      "epoch 118| loss: 0.0083  | train_rmsle: 0.00019 | train_mae: 0.0423  | train_rmse: 0.05412 | train_mse: 0.00293 | valid_rmsle: 0.00053 | valid_mae: 0.07251 | valid_rmse: 0.0942  | valid_mse: 0.00887 |  0:03:05s\n",
      "epoch 119| loss: 0.00761 | train_rmsle: 0.00028 | train_mae: 0.05354 | train_rmse: 0.06806 | train_mse: 0.00463 | valid_rmsle: 0.00061 | valid_mae: 0.07749 | valid_rmse: 0.10195 | valid_mse: 0.01039 |  0:03:07s\n",
      "epoch 120| loss: 0.00886 | train_rmsle: 0.00016 | train_mae: 0.04218 | train_rmse: 0.05413 | train_mse: 0.00293 | valid_rmsle: 0.0005  | valid_mae: 0.07233 | valid_rmse: 0.09435 | valid_mse: 0.0089  |  0:03:08s\n",
      "epoch 121| loss: 0.00835 | train_rmsle: 0.00014 | train_mae: 0.03851 | train_rmse: 0.04905 | train_mse: 0.00241 | valid_rmsle: 0.00049 | valid_mae: 0.07033 | valid_rmse: 0.09152 | valid_mse: 0.00838 |  0:03:10s\n",
      "epoch 122| loss: 0.00844 | train_rmsle: 0.00018 | train_mae: 0.04515 | train_rmse: 0.05654 | train_mse: 0.0032  | valid_rmsle: 0.00051 | valid_mae: 0.07234 | valid_rmse: 0.09501 | valid_mse: 0.00903 |  0:03:11s\n",
      "epoch 123| loss: 0.009   | train_rmsle: 0.00017 | train_mae: 0.04425 | train_rmse: 0.05626 | train_mse: 0.00317 | valid_rmsle: 0.00051 | valid_mae: 0.07507 | valid_rmse: 0.096   | valid_mse: 0.00922 |  0:03:13s\n",
      "epoch 124| loss: 0.0091  | train_rmsle: 0.00045 | train_mae: 0.07271 | train_rmse: 0.0852  | train_mse: 0.00726 | valid_rmsle: 0.0008  | valid_mae: 0.09077 | valid_rmse: 0.11556 | valid_mse: 0.01335 |  0:03:14s\n",
      "epoch 125| loss: 0.00951 | train_rmsle: 0.00021 | train_mae: 0.04721 | train_rmse: 0.05901 | train_mse: 0.00348 | valid_rmsle: 0.00056 | valid_mae: 0.07498 | valid_rmse: 0.09867 | valid_mse: 0.00974 |  0:03:16s\n",
      "epoch 126| loss: 0.00874 | train_rmsle: 0.00025 | train_mae: 0.04973 | train_rmse: 0.06208 | train_mse: 0.00385 | valid_rmsle: 0.00061 | valid_mae: 0.0764  | valid_rmse: 0.10026 | valid_mse: 0.01005 |  0:03:17s\n",
      "epoch 127| loss: 0.00794 | train_rmsle: 0.00023 | train_mae: 0.05404 | train_rmse: 0.06501 | train_mse: 0.00423 | valid_rmsle: 0.00058 | valid_mae: 0.0817  | valid_rmse: 0.10128 | valid_mse: 0.01026 |  0:03:19s\n",
      "epoch 128| loss: 0.00803 | train_rmsle: 0.00022 | train_mae: 0.05111 | train_rmse: 0.06327 | train_mse: 0.004   | valid_rmsle: 0.00058 | valid_mae: 0.07796 | valid_rmse: 0.10153 | valid_mse: 0.01031 |  0:03:21s\n",
      "epoch 129| loss: 0.00819 | train_rmsle: 0.0002  | train_mae: 0.04651 | train_rmse: 0.05784 | train_mse: 0.00334 | valid_rmsle: 0.00053 | valid_mae: 0.07619 | valid_rmse: 0.09622 | valid_mse: 0.00926 |  0:03:22s\n",
      "\n",
      "Early stopping occurred at epoch 129 with best_epoch = 109 and best_valid_mse = 0.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008290198305983244 RMSE: 0.0910505261159058 R2: 0.9633024864668077 MAE: 0.06962713662719916\n",
      "=====================================\n",
      "[40/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25806 | train_rmsle: 0.16137 | train_mae: 1.38403 | train_rmse: 1.4619  | train_mse: 2.13715 | valid_rmsle: 0.16213 | valid_mae: 1.38796 | valid_rmse: 1.46633 | valid_mse: 2.15013 |  0:00:01s\n",
      "epoch 1  | loss: 0.35967 | train_rmsle: 0.1098  | train_mae: 1.16754 | train_rmse: 1.25285 | train_mse: 1.56962 | valid_rmsle: 0.11029 | valid_mae: 1.17063 | valid_rmse: 1.25685 | valid_mse: 1.57967 |  0:00:03s\n",
      "epoch 2  | loss: 0.26771 | train_rmsle: 0.05449 | train_mae: 0.83962 | train_rmse: 0.9326  | train_mse: 0.86975 | valid_rmsle: 0.05448 | valid_mae: 0.83979 | valid_rmse: 0.93468 | valid_mse: 0.87362 |  0:00:05s\n",
      "epoch 3  | loss: 0.24587 | train_rmsle: 0.04306 | train_mae: 0.74839 | train_rmse: 0.84082 | train_mse: 0.70698 | valid_rmsle: 0.04307 | valid_mae: 0.74848 | valid_rmse: 0.84329 | valid_mse: 0.71113 |  0:00:06s\n",
      "epoch 4  | loss: 0.23121 | train_rmsle: 0.03004 | train_mae: 0.62193 | train_rmse: 0.71342 | train_mse: 0.50897 | valid_rmsle: 0.0298  | valid_mae: 0.62106 | valid_rmse: 0.71382 | valid_mse: 0.50954 |  0:00:08s\n",
      "epoch 5  | loss: 0.22596 | train_rmsle: 0.02275 | train_mae: 0.53581 | train_rmse: 0.62461 | train_mse: 0.39013 | valid_rmsle: 0.02247 | valid_mae: 0.53654 | valid_rmse: 0.62461 | valid_mse: 0.39014 |  0:00:10s\n",
      "epoch 6  | loss: 0.22236 | train_rmsle: 0.01826 | train_mae: 0.47077 | train_rmse: 0.55789 | train_mse: 0.31124 | valid_rmsle: 0.01788 | valid_mae: 0.47163 | valid_rmse: 0.55679 | valid_mse: 0.31002 |  0:00:11s\n",
      "epoch 7  | loss: 0.22582 | train_rmsle: 0.02021 | train_mae: 0.50115 | train_rmse: 0.5888  | train_mse: 0.34668 | valid_rmsle: 0.01978 | valid_mae: 0.50044 | valid_rmse: 0.5869  | valid_mse: 0.34445 |  0:00:13s\n",
      "epoch 8  | loss: 0.21553 | train_rmsle: 0.01476 | train_mae: 0.40632 | train_rmse: 0.49404 | train_mse: 0.24408 | valid_rmsle: 0.01437 | valid_mae: 0.40816 | valid_rmse: 0.49319 | valid_mse: 0.24324 |  0:00:15s\n",
      "epoch 9  | loss: 0.21478 | train_rmsle: 0.01394 | train_mae: 0.38402 | train_rmse: 0.47518 | train_mse: 0.2258  | valid_rmsle: 0.01347 | valid_mae: 0.38605 | valid_rmse: 0.47299 | valid_mse: 0.22372 |  0:00:16s\n",
      "epoch 10 | loss: 0.20802 | train_rmsle: 0.01418 | train_mae: 0.39695 | train_rmse: 0.48372 | train_mse: 0.23398 | valid_rmsle: 0.01378 | valid_mae: 0.39878 | valid_rmse: 0.48243 | valid_mse: 0.23274 |  0:00:18s\n",
      "epoch 11 | loss: 0.19951 | train_rmsle: 0.01288 | train_mae: 0.36244 | train_rmse: 0.45301 | train_mse: 0.20521 | valid_rmsle: 0.01236 | valid_mae: 0.36298 | valid_rmse: 0.4491  | valid_mse: 0.20169 |  0:00:20s\n",
      "epoch 12 | loss: 0.19172 | train_rmsle: 0.01226 | train_mae: 0.35579 | train_rmse: 0.44341 | train_mse: 0.19661 | valid_rmsle: 0.01177 | valid_mae: 0.35707 | valid_rmse: 0.44025 | valid_mse: 0.19382 |  0:00:21s\n",
      "epoch 13 | loss: 0.18183 | train_rmsle: 0.01018 | train_mae: 0.32981 | train_rmse: 0.40615 | train_mse: 0.16495 | valid_rmsle: 0.0098  | valid_mae: 0.33154 | valid_rmse: 0.40489 | valid_mse: 0.16394 |  0:00:23s\n",
      "epoch 14 | loss: 0.16379 | train_rmsle: 0.01151 | train_mae: 0.37106 | train_rmse: 0.43952 | train_mse: 0.19318 | valid_rmsle: 0.01144 | valid_mae: 0.37338 | valid_rmse: 0.44292 | valid_mse: 0.19618 |  0:00:25s\n",
      "epoch 15 | loss: 0.13555 | train_rmsle: 0.01054 | train_mae: 0.34695 | train_rmse: 0.41495 | train_mse: 0.17218 | valid_rmsle: 0.01028 | valid_mae: 0.3468  | valid_rmse: 0.41435 | valid_mse: 0.17169 |  0:00:26s\n",
      "epoch 16 | loss: 0.11419 | train_rmsle: 0.01237 | train_mae: 0.37178 | train_rmse: 0.44283 | train_mse: 0.1961  | valid_rmsle: 0.0122  | valid_mae: 0.37391 | valid_rmse: 0.44374 | valid_mse: 0.1969  |  0:00:28s\n",
      "epoch 17 | loss: 0.09763 | train_rmsle: 0.00908 | train_mae: 0.31585 | train_rmse: 0.3803  | train_mse: 0.14463 | valid_rmsle: 0.00877 | valid_mae: 0.31503 | valid_rmse: 0.37813 | valid_mse: 0.14298 |  0:00:30s\n",
      "epoch 18 | loss: 0.08568 | train_rmsle: 0.00774 | train_mae: 0.28534 | train_rmse: 0.34781 | train_mse: 0.12097 | valid_rmsle: 0.00742 | valid_mae: 0.28446 | valid_rmse: 0.34379 | valid_mse: 0.11819 |  0:00:31s\n",
      "epoch 19 | loss: 0.07544 | train_rmsle: 0.00495 | train_mae: 0.22748 | train_rmse: 0.28089 | train_mse: 0.0789  | valid_rmsle: 0.00477 | valid_mae: 0.22821 | valid_rmse: 0.27867 | valid_mse: 0.07766 |  0:00:33s\n",
      "epoch 20 | loss: 0.06821 | train_rmsle: 0.00429 | train_mae: 0.22137 | train_rmse: 0.27036 | train_mse: 0.07309 | valid_rmsle: 0.00427 | valid_mae: 0.22409 | valid_rmse: 0.2728  | valid_mse: 0.07442 |  0:00:35s\n",
      "epoch 21 | loss: 0.05828 | train_rmsle: 0.00293 | train_mae: 0.17773 | train_rmse: 0.22461 | train_mse: 0.05045 | valid_rmsle: 0.00288 | valid_mae: 0.18163 | valid_rmse: 0.22722 | valid_mse: 0.05163 |  0:00:36s\n",
      "epoch 22 | loss: 0.04963 | train_rmsle: 0.00286 | train_mae: 0.1773  | train_rmse: 0.22003 | train_mse: 0.04841 | valid_rmsle: 0.0029  | valid_mae: 0.18139 | valid_rmse: 0.22579 | valid_mse: 0.05098 |  0:00:38s\n",
      "epoch 23 | loss: 0.04728 | train_rmsle: 0.00312 | train_mae: 0.19152 | train_rmse: 0.23528 | train_mse: 0.05536 | valid_rmsle: 0.0032  | valid_mae: 0.19742 | valid_rmse: 0.2424  | valid_mse: 0.05876 |  0:00:40s\n",
      "epoch 24 | loss: 0.04214 | train_rmsle: 0.00256 | train_mae: 0.17056 | train_rmse: 0.21457 | train_mse: 0.04604 | valid_rmsle: 0.00265 | valid_mae: 0.17749 | valid_rmse: 0.22261 | valid_mse: 0.04956 |  0:00:41s\n",
      "epoch 25 | loss: 0.03916 | train_rmsle: 0.00195 | train_mae: 0.1421  | train_rmse: 0.18136 | train_mse: 0.03289 | valid_rmsle: 0.00202 | valid_mae: 0.14845 | valid_rmse: 0.1895  | valid_mse: 0.03591 |  0:00:43s\n",
      "epoch 26 | loss: 0.03935 | train_rmsle: 0.002   | train_mae: 0.14331 | train_rmse: 0.18168 | train_mse: 0.03301 | valid_rmsle: 0.00209 | valid_mae: 0.14969 | valid_rmse: 0.1903  | valid_mse: 0.03621 |  0:00:44s\n",
      "epoch 27 | loss: 0.03464 | train_rmsle: 0.00321 | train_mae: 0.17919 | train_rmse: 0.21991 | train_mse: 0.04836 | valid_rmsle: 0.0034  | valid_mae: 0.18746 | valid_rmse: 0.23086 | valid_mse: 0.0533  |  0:00:45s\n",
      "epoch 28 | loss: 0.0331  | train_rmsle: 0.00139 | train_mae: 0.11792 | train_rmse: 0.15574 | train_mse: 0.02425 | valid_rmsle: 0.0015  | valid_mae: 0.12666 | valid_rmse: 0.16598 | valid_mse: 0.02755 |  0:00:47s\n",
      "epoch 29 | loss: 0.03059 | train_rmsle: 0.00156 | train_mae: 0.12786 | train_rmse: 0.16151 | train_mse: 0.02608 | valid_rmsle: 0.00168 | valid_mae: 0.13481 | valid_rmse: 0.1727  | valid_mse: 0.02982 |  0:00:48s\n",
      "epoch 30 | loss: 0.02827 | train_rmsle: 0.0012  | train_mae: 0.11094 | train_rmse: 0.14573 | train_mse: 0.02124 | valid_rmsle: 0.00137 | valid_mae: 0.12224 | valid_rmse: 0.15956 | valid_mse: 0.02546 |  0:00:49s\n",
      "epoch 31 | loss: 0.02849 | train_rmsle: 0.00144 | train_mae: 0.12199 | train_rmse: 0.16469 | train_mse: 0.02712 | valid_rmsle: 0.00179 | valid_mae: 0.13776 | valid_rmse: 0.1858  | valid_mse: 0.03452 |  0:00:51s\n",
      "epoch 32 | loss: 0.02827 | train_rmsle: 0.00181 | train_mae: 0.14429 | train_rmse: 0.17564 | train_mse: 0.03085 | valid_rmsle: 0.00203 | valid_mae: 0.15329 | valid_rmse: 0.18974 | valid_mse: 0.036   |  0:00:52s\n",
      "epoch 33 | loss: 0.02595 | train_rmsle: 0.00099 | train_mae: 0.10119 | train_rmse: 0.13342 | train_mse: 0.0178  | valid_rmsle: 0.00125 | valid_mae: 0.11603 | valid_rmse: 0.15299 | valid_mse: 0.02341 |  0:00:53s\n",
      "epoch 34 | loss: 0.02374 | train_rmsle: 0.00109 | train_mae: 0.10609 | train_rmse: 0.13682 | train_mse: 0.01872 | valid_rmsle: 0.00138 | valid_mae: 0.12225 | valid_rmse: 0.15628 | valid_mse: 0.02442 |  0:00:55s\n",
      "epoch 35 | loss: 0.02157 | train_rmsle: 0.001   | train_mae: 0.10183 | train_rmse: 0.13038 | train_mse: 0.017   | valid_rmsle: 0.00122 | valid_mae: 0.11471 | valid_rmse: 0.14787 | valid_mse: 0.02186 |  0:00:57s\n",
      "epoch 36 | loss: 0.0208  | train_rmsle: 0.0027  | train_mae: 0.16298 | train_rmse: 0.19608 | train_mse: 0.03845 | valid_rmsle: 0.00291 | valid_mae: 0.1746  | valid_rmse: 0.20908 | valid_mse: 0.04372 |  0:00:59s\n",
      "epoch 37 | loss: 0.02073 | train_rmsle: 0.00096 | train_mae: 0.10468 | train_rmse: 0.13214 | train_mse: 0.01746 | valid_rmsle: 0.00124 | valid_mae: 0.12017 | valid_rmse: 0.15242 | valid_mse: 0.02323 |  0:01:00s\n",
      "epoch 38 | loss: 0.02074 | train_rmsle: 0.00228 | train_mae: 0.13767 | train_rmse: 0.17583 | train_mse: 0.03092 | valid_rmsle: 0.00244 | valid_mae: 0.15112 | valid_rmse: 0.18863 | valid_mse: 0.03558 |  0:01:02s\n",
      "epoch 39 | loss: 0.01828 | train_rmsle: 0.00078 | train_mae: 0.09063 | train_rmse: 0.11735 | train_mse: 0.01377 | valid_rmsle: 0.00107 | valid_mae: 0.10872 | valid_rmse: 0.14002 | valid_mse: 0.01961 |  0:01:04s\n",
      "epoch 40 | loss: 0.01874 | train_rmsle: 0.00067 | train_mae: 0.08331 | train_rmse: 0.10899 | train_mse: 0.01188 | valid_rmsle: 0.00097 | valid_mae: 0.1023  | valid_rmse: 0.1338  | valid_mse: 0.0179  |  0:01:05s\n",
      "epoch 41 | loss: 0.0174  | train_rmsle: 0.00131 | train_mae: 0.12335 | train_rmse: 0.14986 | train_mse: 0.02246 | valid_rmsle: 0.00163 | valid_mae: 0.13707 | valid_rmse: 0.17059 | valid_mse: 0.0291  |  0:01:07s\n",
      "epoch 42 | loss: 0.01884 | train_rmsle: 0.00101 | train_mae: 0.10379 | train_rmse: 0.12783 | train_mse: 0.01634 | valid_rmsle: 0.00129 | valid_mae: 0.11995 | valid_rmse: 0.14876 | valid_mse: 0.02213 |  0:01:09s\n",
      "epoch 43 | loss: 0.01978 | train_rmsle: 0.0009  | train_mae: 0.10378 | train_rmse: 0.13039 | train_mse: 0.017   | valid_rmsle: 0.0012  | valid_mae: 0.11884 | valid_rmse: 0.1516  | valid_mse: 0.02298 |  0:01:10s\n",
      "epoch 44 | loss: 0.0193  | train_rmsle: 0.00078 | train_mae: 0.08819 | train_rmse: 0.11192 | train_mse: 0.01253 | valid_rmsle: 0.00102 | valid_mae: 0.10503 | valid_rmse: 0.13269 | valid_mse: 0.01761 |  0:01:12s\n",
      "epoch 45 | loss: 0.01568 | train_rmsle: 0.00057 | train_mae: 0.07771 | train_rmse: 0.10041 | train_mse: 0.01008 | valid_rmsle: 0.00086 | valid_mae: 0.09771 | valid_rmse: 0.1254  | valid_mse: 0.01572 |  0:01:14s\n",
      "epoch 46 | loss: 0.01494 | train_rmsle: 0.00054 | train_mae: 0.07438 | train_rmse: 0.09763 | train_mse: 0.00953 | valid_rmsle: 0.00087 | valid_mae: 0.0943  | valid_rmse: 0.1256  | valid_mse: 0.01578 |  0:01:16s\n",
      "epoch 47 | loss: 0.01788 | train_rmsle: 0.00055 | train_mae: 0.07644 | train_rmse: 0.09807 | train_mse: 0.00962 | valid_rmsle: 0.00085 | valid_mae: 0.09419 | valid_rmse: 0.12385 | valid_mse: 0.01534 |  0:01:17s\n",
      "epoch 48 | loss: 0.01621 | train_rmsle: 0.00049 | train_mae: 0.07092 | train_rmse: 0.09482 | train_mse: 0.00899 | valid_rmsle: 0.00076 | valid_mae: 0.08907 | valid_rmse: 0.11889 | valid_mse: 0.01414 |  0:01:19s\n",
      "epoch 49 | loss: 0.01363 | train_rmsle: 0.00088 | train_mae: 0.08942 | train_rmse: 0.11395 | train_mse: 0.01298 | valid_rmsle: 0.00108 | valid_mae: 0.10429 | valid_rmse: 0.13148 | valid_mse: 0.01729 |  0:01:21s\n",
      "epoch 50 | loss: 0.0148  | train_rmsle: 0.00056 | train_mae: 0.07535 | train_rmse: 0.09781 | train_mse: 0.00957 | valid_rmsle: 0.00081 | valid_mae: 0.09213 | valid_rmse: 0.12    | valid_mse: 0.0144  |  0:01:22s\n",
      "epoch 51 | loss: 0.01566 | train_rmsle: 0.00114 | train_mae: 0.10459 | train_rmse: 0.1304  | train_mse: 0.017   | valid_rmsle: 0.00141 | valid_mae: 0.11844 | valid_rmse: 0.14994 | valid_mse: 0.02248 |  0:01:24s\n",
      "epoch 52 | loss: 0.01701 | train_rmsle: 0.00059 | train_mae: 0.08072 | train_rmse: 0.10255 | train_mse: 0.01052 | valid_rmsle: 0.00092 | valid_mae: 0.09934 | valid_rmse: 0.12991 | valid_mse: 0.01688 |  0:01:26s\n",
      "epoch 53 | loss: 0.01534 | train_rmsle: 0.0005  | train_mae: 0.07336 | train_rmse: 0.09444 | train_mse: 0.00892 | valid_rmsle: 0.00083 | valid_mae: 0.09245 | valid_rmse: 0.12274 | valid_mse: 0.01506 |  0:01:27s\n",
      "epoch 54 | loss: 0.01299 | train_rmsle: 0.00047 | train_mae: 0.06946 | train_rmse: 0.08926 | train_mse: 0.00797 | valid_rmsle: 0.00077 | valid_mae: 0.08901 | valid_rmse: 0.11737 | valid_mse: 0.01378 |  0:01:29s\n",
      "epoch 55 | loss: 0.01288 | train_rmsle: 0.00047 | train_mae: 0.07037 | train_rmse: 0.08922 | train_mse: 0.00796 | valid_rmsle: 0.00078 | valid_mae: 0.0901  | valid_rmse: 0.11804 | valid_mse: 0.01393 |  0:01:31s\n",
      "epoch 56 | loss: 0.01464 | train_rmsle: 0.00045 | train_mae: 0.07159 | train_rmse: 0.0911  | train_mse: 0.0083  | valid_rmsle: 0.00081 | valid_mae: 0.09151 | valid_rmse: 0.12169 | valid_mse: 0.01481 |  0:01:33s\n",
      "epoch 57 | loss: 0.01191 | train_rmsle: 0.00039 | train_mae: 0.06382 | train_rmse: 0.08254 | train_mse: 0.00681 | valid_rmsle: 0.00075 | valid_mae: 0.08456 | valid_rmse: 0.11472 | valid_mse: 0.01316 |  0:01:34s\n",
      "epoch 58 | loss: 0.01343 | train_rmsle: 0.00044 | train_mae: 0.0677  | train_rmse: 0.09027 | train_mse: 0.00815 | valid_rmsle: 0.00076 | valid_mae: 0.08743 | valid_rmse: 0.11808 | valid_mse: 0.01394 |  0:01:36s\n",
      "epoch 59 | loss: 0.01074 | train_rmsle: 0.00039 | train_mae: 0.06508 | train_rmse: 0.08343 | train_mse: 0.00696 | valid_rmsle: 0.00068 | valid_mae: 0.08624 | valid_rmse: 0.11125 | valid_mse: 0.01238 |  0:01:38s\n",
      "epoch 60 | loss: 0.01229 | train_rmsle: 0.00085 | train_mae: 0.08377 | train_rmse: 0.10937 | train_mse: 0.01196 | valid_rmsle: 0.00111 | valid_mae: 0.10159 | valid_rmse: 0.13068 | valid_mse: 0.01708 |  0:01:39s\n",
      "epoch 61 | loss: 0.01218 | train_rmsle: 0.00038 | train_mae: 0.06142 | train_rmse: 0.07882 | train_mse: 0.00621 | valid_rmsle: 0.00063 | valid_mae: 0.08206 | valid_rmse: 0.10512 | valid_mse: 0.01105 |  0:01:41s\n",
      "epoch 62 | loss: 0.01082 | train_rmsle: 0.00033 | train_mae: 0.0578  | train_rmse: 0.07587 | train_mse: 0.00576 | valid_rmsle: 0.00059 | valid_mae: 0.07892 | valid_rmse: 0.10311 | valid_mse: 0.01063 |  0:01:42s\n",
      "epoch 63 | loss: 0.01135 | train_rmsle: 0.00035 | train_mae: 0.05846 | train_rmse: 0.07555 | train_mse: 0.00571 | valid_rmsle: 0.0006  | valid_mae: 0.07958 | valid_rmse: 0.10325 | valid_mse: 0.01066 |  0:01:43s\n",
      "epoch 64 | loss: 0.01142 | train_rmsle: 0.00033 | train_mae: 0.05923 | train_rmse: 0.07744 | train_mse: 0.006   | valid_rmsle: 0.00062 | valid_mae: 0.0817  | valid_rmse: 0.10681 | valid_mse: 0.01141 |  0:01:45s\n",
      "epoch 65 | loss: 0.01314 | train_rmsle: 0.00059 | train_mae: 0.08134 | train_rmse: 0.09909 | train_mse: 0.00982 | valid_rmsle: 0.00085 | valid_mae: 0.09777 | valid_rmse: 0.12198 | valid_mse: 0.01488 |  0:01:46s\n",
      "epoch 66 | loss: 0.0103  | train_rmsle: 0.00028 | train_mae: 0.05362 | train_rmse: 0.06963 | train_mse: 0.00485 | valid_rmsle: 0.00054 | valid_mae: 0.0749  | valid_rmse: 0.09855 | valid_mse: 0.00971 |  0:01:48s\n",
      "epoch 67 | loss: 0.01202 | train_rmsle: 0.0003  | train_mae: 0.05601 | train_rmse: 0.07218 | train_mse: 0.00521 | valid_rmsle: 0.00057 | valid_mae: 0.07708 | valid_rmse: 0.10167 | valid_mse: 0.01034 |  0:01:49s\n",
      "epoch 68 | loss: 0.0134  | train_rmsle: 0.00073 | train_mae: 0.09648 | train_rmse: 0.11318 | train_mse: 0.01281 | valid_rmsle: 0.001   | valid_mae: 0.10707 | valid_rmse: 0.13275 | valid_mse: 0.01762 |  0:01:51s\n",
      "epoch 69 | loss: 0.01376 | train_rmsle: 0.00026 | train_mae: 0.05201 | train_rmse: 0.06712 | train_mse: 0.0045  | valid_rmsle: 0.00054 | valid_mae: 0.07457 | valid_rmse: 0.09867 | valid_mse: 0.00974 |  0:01:52s\n",
      "epoch 70 | loss: 0.01598 | train_rmsle: 0.00119 | train_mae: 0.11623 | train_rmse: 0.13491 | train_mse: 0.0182  | valid_rmsle: 0.00145 | valid_mae: 0.12817 | valid_rmse: 0.15276 | valid_mse: 0.02333 |  0:01:54s\n",
      "epoch 71 | loss: 0.01669 | train_rmsle: 0.0007  | train_mae: 0.09357 | train_rmse: 0.10957 | train_mse: 0.012   | valid_rmsle: 0.00098 | valid_mae: 0.10818 | valid_rmse: 0.13158 | valid_mse: 0.01731 |  0:01:56s\n",
      "epoch 72 | loss: 0.01373 | train_rmsle: 0.00062 | train_mae: 0.08047 | train_rmse: 0.09865 | train_mse: 0.00973 | valid_rmsle: 0.00084 | valid_mae: 0.09621 | valid_rmse: 0.11964 | valid_mse: 0.01431 |  0:01:57s\n",
      "epoch 73 | loss: 0.01268 | train_rmsle: 0.00057 | train_mae: 0.08634 | train_rmse: 0.10526 | train_mse: 0.01108 | valid_rmsle: 0.00085 | valid_mae: 0.10235 | valid_rmse: 0.12768 | valid_mse: 0.0163  |  0:01:59s\n",
      "epoch 74 | loss: 0.01143 | train_rmsle: 0.00055 | train_mae: 0.08341 | train_rmse: 0.09921 | train_mse: 0.00984 | valid_rmsle: 0.00081 | valid_mae: 0.09904 | valid_rmse: 0.12208 | valid_mse: 0.0149  |  0:02:01s\n",
      "epoch 75 | loss: 0.01183 | train_rmsle: 0.00036 | train_mae: 0.06409 | train_rmse: 0.08082 | train_mse: 0.00653 | valid_rmsle: 0.00061 | valid_mae: 0.07999 | valid_rmse: 0.10504 | valid_mse: 0.01103 |  0:02:03s\n",
      "epoch 76 | loss: 0.01005 | train_rmsle: 0.00026 | train_mae: 0.0525  | train_rmse: 0.0674  | train_mse: 0.00454 | valid_rmsle: 0.00051 | valid_mae: 0.07326 | valid_rmse: 0.09598 | valid_mse: 0.00921 |  0:02:04s\n",
      "epoch 77 | loss: 0.01011 | train_rmsle: 0.00043 | train_mae: 0.06208 | train_rmse: 0.08011 | train_mse: 0.00642 | valid_rmsle: 0.00071 | valid_mae: 0.084   | valid_rmse: 0.10766 | valid_mse: 0.01159 |  0:02:06s\n",
      "epoch 78 | loss: 0.00994 | train_rmsle: 0.00034 | train_mae: 0.06108 | train_rmse: 0.07559 | train_mse: 0.00571 | valid_rmsle: 0.00061 | valid_mae: 0.0829  | valid_rmse: 0.10458 | valid_mse: 0.01094 |  0:02:07s\n",
      "epoch 79 | loss: 0.01057 | train_rmsle: 0.00035 | train_mae: 0.06366 | train_rmse: 0.07981 | train_mse: 0.00637 | valid_rmsle: 0.00062 | valid_mae: 0.08152 | valid_rmse: 0.10679 | valid_mse: 0.0114  |  0:02:09s\n",
      "epoch 80 | loss: 0.01055 | train_rmsle: 0.00028 | train_mae: 0.05386 | train_rmse: 0.06888 | train_mse: 0.00475 | valid_rmsle: 0.00055 | valid_mae: 0.07544 | valid_rmse: 0.09949 | valid_mse: 0.0099  |  0:02:11s\n",
      "epoch 81 | loss: 0.01115 | train_rmsle: 0.00045 | train_mae: 0.06685 | train_rmse: 0.08303 | train_mse: 0.00689 | valid_rmsle: 0.00073 | valid_mae: 0.08791 | valid_rmse: 0.11062 | valid_mse: 0.01224 |  0:02:12s\n",
      "epoch 82 | loss: 0.01046 | train_rmsle: 0.00033 | train_mae: 0.05761 | train_rmse: 0.07296 | train_mse: 0.00532 | valid_rmsle: 0.00061 | valid_mae: 0.07949 | valid_rmse: 0.10208 | valid_mse: 0.01042 |  0:02:14s\n",
      "epoch 83 | loss: 0.0109  | train_rmsle: 0.00066 | train_mae: 0.09172 | train_rmse: 0.10577 | train_mse: 0.01119 | valid_rmsle: 0.00094 | valid_mae: 0.10653 | valid_rmse: 0.1288  | valid_mse: 0.01659 |  0:02:16s\n",
      "epoch 84 | loss: 0.01047 | train_rmsle: 0.00029 | train_mae: 0.05598 | train_rmse: 0.07034 | train_mse: 0.00495 | valid_rmsle: 0.00058 | valid_mae: 0.0793  | valid_rmse: 0.10182 | valid_mse: 0.01037 |  0:02:18s\n",
      "epoch 85 | loss: 0.00974 | train_rmsle: 0.00022 | train_mae: 0.04792 | train_rmse: 0.06148 | train_mse: 0.00378 | valid_rmsle: 0.00052 | valid_mae: 0.0739  | valid_rmse: 0.09659 | valid_mse: 0.00933 |  0:02:19s\n",
      "epoch 86 | loss: 0.00942 | train_rmsle: 0.00039 | train_mae: 0.05964 | train_rmse: 0.07642 | train_mse: 0.00584 | valid_rmsle: 0.00067 | valid_mae: 0.08012 | valid_rmse: 0.10499 | valid_mse: 0.01102 |  0:02:21s\n",
      "epoch 87 | loss: 0.01205 | train_rmsle: 0.00055 | train_mae: 0.08179 | train_rmse: 0.09906 | train_mse: 0.00981 | valid_rmsle: 0.00083 | valid_mae: 0.09621 | valid_rmse: 0.12209 | valid_mse: 0.01491 |  0:02:22s\n",
      "epoch 88 | loss: 0.0129  | train_rmsle: 0.0004  | train_mae: 0.05682 | train_rmse: 0.07454 | train_mse: 0.00556 | valid_rmsle: 0.00067 | valid_mae: 0.07905 | valid_rmse: 0.10365 | valid_mse: 0.01074 |  0:02:24s\n",
      "epoch 89 | loss: 0.01294 | train_rmsle: 0.00066 | train_mae: 0.07107 | train_rmse: 0.09453 | train_mse: 0.00894 | valid_rmsle: 0.00091 | valid_mae: 0.09202 | valid_rmse: 0.11759 | valid_mse: 0.01383 |  0:02:26s\n",
      "epoch 90 | loss: 0.01047 | train_rmsle: 0.00022 | train_mae: 0.0473  | train_rmse: 0.06118 | train_mse: 0.00374 | valid_rmsle: 0.00051 | valid_mae: 0.07154 | valid_rmse: 0.094   | valid_mse: 0.00884 |  0:02:27s\n",
      "epoch 91 | loss: 0.0084  | train_rmsle: 0.00022 | train_mae: 0.04657 | train_rmse: 0.06021 | train_mse: 0.00362 | valid_rmsle: 0.0005  | valid_mae: 0.07079 | valid_rmse: 0.09328 | valid_mse: 0.0087  |  0:02:29s\n",
      "epoch 92 | loss: 0.00832 | train_rmsle: 0.00027 | train_mae: 0.0507  | train_rmse: 0.06538 | train_mse: 0.00428 | valid_rmsle: 0.00055 | valid_mae: 0.07376 | valid_rmse: 0.09673 | valid_mse: 0.00936 |  0:02:31s\n",
      "epoch 93 | loss: 0.00933 | train_rmsle: 0.00028 | train_mae: 0.05426 | train_rmse: 0.06824 | train_mse: 0.00466 | valid_rmsle: 0.00057 | valid_mae: 0.07819 | valid_rmse: 0.10028 | valid_mse: 0.01006 |  0:02:32s\n",
      "epoch 94 | loss: 0.01418 | train_rmsle: 0.0003  | train_mae: 0.05097 | train_rmse: 0.06609 | train_mse: 0.00437 | valid_rmsle: 0.00058 | valid_mae: 0.07514 | valid_rmse: 0.09813 | valid_mse: 0.00963 |  0:02:34s\n",
      "epoch 95 | loss: 0.0115  | train_rmsle: 0.00028 | train_mae: 0.05422 | train_rmse: 0.06832 | train_mse: 0.00467 | valid_rmsle: 0.00057 | valid_mae: 0.07796 | valid_rmse: 0.0992  | valid_mse: 0.00984 |  0:02:35s\n",
      "epoch 96 | loss: 0.00951 | train_rmsle: 0.00021 | train_mae: 0.04631 | train_rmse: 0.05932 | train_mse: 0.00352 | valid_rmsle: 0.0005  | valid_mae: 0.07227 | valid_rmse: 0.09313 | valid_mse: 0.00867 |  0:02:37s\n",
      "epoch 97 | loss: 0.00921 | train_rmsle: 0.00022 | train_mae: 0.04644 | train_rmse: 0.05978 | train_mse: 0.00357 | valid_rmsle: 0.0005  | valid_mae: 0.07239 | valid_rmse: 0.09412 | valid_mse: 0.00886 |  0:02:38s\n",
      "epoch 98 | loss: 0.0085  | train_rmsle: 0.00025 | train_mae: 0.05207 | train_rmse: 0.06512 | train_mse: 0.00424 | valid_rmsle: 0.00055 | valid_mae: 0.077   | valid_rmse: 0.09872 | valid_mse: 0.00975 |  0:02:40s\n",
      "epoch 99 | loss: 0.00932 | train_rmsle: 0.00059 | train_mae: 0.08828 | train_rmse: 0.10064 | train_mse: 0.01013 | valid_rmsle: 0.00087 | valid_mae: 0.1022  | valid_rmse: 0.12384 | valid_mse: 0.01534 |  0:02:41s\n",
      "epoch 100| loss: 0.00901 | train_rmsle: 0.00019 | train_mae: 0.04407 | train_rmse: 0.05636 | train_mse: 0.00318 | valid_rmsle: 0.0005  | valid_mae: 0.07127 | valid_rmse: 0.09356 | valid_mse: 0.00875 |  0:02:42s\n",
      "epoch 101| loss: 0.00775 | train_rmsle: 0.00033 | train_mae: 0.06164 | train_rmse: 0.0753  | train_mse: 0.00567 | valid_rmsle: 0.00064 | valid_mae: 0.08148 | valid_rmse: 0.10638 | valid_mse: 0.01132 |  0:02:44s\n",
      "epoch 102| loss: 0.00977 | train_rmsle: 0.00023 | train_mae: 0.05063 | train_rmse: 0.06464 | train_mse: 0.00418 | valid_rmsle: 0.00053 | valid_mae: 0.07457 | valid_rmse: 0.09809 | valid_mse: 0.00962 |  0:02:45s\n",
      "epoch 103| loss: 0.00967 | train_rmsle: 0.00026 | train_mae: 0.05071 | train_rmse: 0.06357 | train_mse: 0.00404 | valid_rmsle: 0.00056 | valid_mae: 0.07653 | valid_rmse: 0.09771 | valid_mse: 0.00955 |  0:02:46s\n",
      "epoch 104| loss: 0.00852 | train_rmsle: 0.00029 | train_mae: 0.05984 | train_rmse: 0.07261 | train_mse: 0.00527 | valid_rmsle: 0.00059 | valid_mae: 0.08244 | valid_rmse: 0.10315 | valid_mse: 0.01064 |  0:02:48s\n",
      "epoch 105| loss: 0.00957 | train_rmsle: 0.00045 | train_mae: 0.0755  | train_rmse: 0.08806 | train_mse: 0.00775 | valid_rmsle: 0.00074 | valid_mae: 0.09243 | valid_rmse: 0.11365 | valid_mse: 0.01292 |  0:02:49s\n",
      "epoch 106| loss: 0.00875 | train_rmsle: 0.0003  | train_mae: 0.05969 | train_rmse: 0.07196 | train_mse: 0.00518 | valid_rmsle: 0.00059 | valid_mae: 0.08066 | valid_rmse: 0.10109 | valid_mse: 0.01022 |  0:02:51s\n",
      "epoch 107| loss: 0.00962 | train_rmsle: 0.00029 | train_mae: 0.05878 | train_rmse: 0.07186 | train_mse: 0.00516 | valid_rmsle: 0.00058 | valid_mae: 0.07819 | valid_rmse: 0.10212 | valid_mse: 0.01043 |  0:02:53s\n",
      "epoch 108| loss: 0.01036 | train_rmsle: 0.0002  | train_mae: 0.04681 | train_rmse: 0.05917 | train_mse: 0.0035  | valid_rmsle: 0.00049 | valid_mae: 0.07107 | valid_rmse: 0.09349 | valid_mse: 0.00874 |  0:02:54s\n",
      "epoch 109| loss: 0.0087  | train_rmsle: 0.00016 | train_mae: 0.04093 | train_rmse: 0.05224 | train_mse: 0.00273 | valid_rmsle: 0.00047 | valid_mae: 0.07042 | valid_rmse: 0.09072 | valid_mse: 0.00823 |  0:02:56s\n",
      "epoch 110| loss: 0.00879 | train_rmsle: 0.00094 | train_mae: 0.09229 | train_rmse: 0.1142  | train_mse: 0.01304 | valid_rmsle: 0.00123 | valid_mae: 0.10681 | valid_rmse: 0.13633 | valid_mse: 0.01859 |  0:02:58s\n",
      "epoch 111| loss: 0.00964 | train_rmsle: 0.0003  | train_mae: 0.0576  | train_rmse: 0.07103 | train_mse: 0.00505 | valid_rmsle: 0.0006  | valid_mae: 0.07862 | valid_rmse: 0.10249 | valid_mse: 0.0105  |  0:02:59s\n",
      "epoch 112| loss: 0.01051 | train_rmsle: 0.00022 | train_mae: 0.04936 | train_rmse: 0.06221 | train_mse: 0.00387 | valid_rmsle: 0.00054 | valid_mae: 0.07784 | valid_rmse: 0.09809 | valid_mse: 0.00962 |  0:03:01s\n",
      "epoch 113| loss: 0.00917 | train_rmsle: 0.00045 | train_mae: 0.07555 | train_rmse: 0.08813 | train_mse: 0.00777 | valid_rmsle: 0.00076 | valid_mae: 0.09415 | valid_rmse: 0.11534 | valid_mse: 0.0133  |  0:03:03s\n",
      "epoch 114| loss: 0.00854 | train_rmsle: 0.00031 | train_mae: 0.05304 | train_rmse: 0.06822 | train_mse: 0.00465 | valid_rmsle: 0.00063 | valid_mae: 0.07905 | valid_rmse: 0.10199 | valid_mse: 0.0104  |  0:03:04s\n",
      "epoch 115| loss: 0.00817 | train_rmsle: 0.00022 | train_mae: 0.05108 | train_rmse: 0.06392 | train_mse: 0.00409 | valid_rmsle: 0.00054 | valid_mae: 0.07823 | valid_rmse: 0.09798 | valid_mse: 0.0096  |  0:03:06s\n",
      "epoch 116| loss: 0.00935 | train_rmsle: 0.00028 | train_mae: 0.05625 | train_rmse: 0.06831 | train_mse: 0.00467 | valid_rmsle: 0.0006  | valid_mae: 0.08119 | valid_rmse: 0.10211 | valid_mse: 0.01043 |  0:03:07s\n",
      "epoch 117| loss: 0.00884 | train_rmsle: 0.00042 | train_mae: 0.06977 | train_rmse: 0.08182 | train_mse: 0.0067  | valid_rmsle: 0.00073 | valid_mae: 0.08996 | valid_rmse: 0.11127 | valid_mse: 0.01238 |  0:03:09s\n",
      "epoch 118| loss: 0.0083  | train_rmsle: 0.00019 | train_mae: 0.0423  | train_rmse: 0.05412 | train_mse: 0.00293 | valid_rmsle: 0.00053 | valid_mae: 0.07251 | valid_rmse: 0.0942  | valid_mse: 0.00887 |  0:03:11s\n",
      "epoch 119| loss: 0.00761 | train_rmsle: 0.00028 | train_mae: 0.05354 | train_rmse: 0.06806 | train_mse: 0.00463 | valid_rmsle: 0.00061 | valid_mae: 0.07749 | valid_rmse: 0.10195 | valid_mse: 0.01039 |  0:03:12s\n",
      "epoch 120| loss: 0.00886 | train_rmsle: 0.00016 | train_mae: 0.04218 | train_rmse: 0.05413 | train_mse: 0.00293 | valid_rmsle: 0.0005  | valid_mae: 0.07233 | valid_rmse: 0.09435 | valid_mse: 0.0089  |  0:03:14s\n",
      "epoch 121| loss: 0.00835 | train_rmsle: 0.00014 | train_mae: 0.03851 | train_rmse: 0.04905 | train_mse: 0.00241 | valid_rmsle: 0.00049 | valid_mae: 0.07033 | valid_rmse: 0.09152 | valid_mse: 0.00838 |  0:03:16s\n",
      "epoch 122| loss: 0.00844 | train_rmsle: 0.00018 | train_mae: 0.04515 | train_rmse: 0.05654 | train_mse: 0.0032  | valid_rmsle: 0.00051 | valid_mae: 0.07234 | valid_rmse: 0.09501 | valid_mse: 0.00903 |  0:03:17s\n",
      "epoch 123| loss: 0.009   | train_rmsle: 0.00017 | train_mae: 0.04425 | train_rmse: 0.05626 | train_mse: 0.00317 | valid_rmsle: 0.00051 | valid_mae: 0.07507 | valid_rmse: 0.096   | valid_mse: 0.00922 |  0:03:19s\n",
      "epoch 124| loss: 0.0091  | train_rmsle: 0.00045 | train_mae: 0.07271 | train_rmse: 0.0852  | train_mse: 0.00726 | valid_rmsle: 0.0008  | valid_mae: 0.09077 | valid_rmse: 0.11556 | valid_mse: 0.01335 |  0:03:21s\n",
      "epoch 125| loss: 0.00951 | train_rmsle: 0.00021 | train_mae: 0.04721 | train_rmse: 0.05901 | train_mse: 0.00348 | valid_rmsle: 0.00056 | valid_mae: 0.07498 | valid_rmse: 0.09867 | valid_mse: 0.00974 |  0:03:22s\n",
      "epoch 126| loss: 0.00874 | train_rmsle: 0.00025 | train_mae: 0.04973 | train_rmse: 0.06208 | train_mse: 0.00385 | valid_rmsle: 0.00061 | valid_mae: 0.0764  | valid_rmse: 0.10026 | valid_mse: 0.01005 |  0:03:24s\n",
      "epoch 127| loss: 0.00794 | train_rmsle: 0.00023 | train_mae: 0.05404 | train_rmse: 0.06501 | train_mse: 0.00423 | valid_rmsle: 0.00058 | valid_mae: 0.0817  | valid_rmse: 0.10128 | valid_mse: 0.01026 |  0:03:26s\n",
      "epoch 128| loss: 0.00803 | train_rmsle: 0.00022 | train_mae: 0.05111 | train_rmse: 0.06327 | train_mse: 0.004   | valid_rmsle: 0.00058 | valid_mae: 0.07796 | valid_rmse: 0.10153 | valid_mse: 0.01031 |  0:03:27s\n",
      "epoch 129| loss: 0.00819 | train_rmsle: 0.0002  | train_mae: 0.04651 | train_rmse: 0.05784 | train_mse: 0.00334 | valid_rmsle: 0.00053 | valid_mae: 0.07619 | valid_rmse: 0.09622 | valid_mse: 0.00926 |  0:03:29s\n",
      "\n",
      "Early stopping occurred at epoch 129 with best_epoch = 109 and best_valid_mse = 0.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008290198305983244 RMSE: 0.0910505261159058 R2: 0.9633024864668077 MAE: 0.06962713662719916\n",
      "=====================================\n",
      "[41/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.50662 | train_rmsle: 0.29481 | train_mae: 1.77415 | train_rmse: 1.83727 | train_mse: 3.37555 | valid_rmsle: 0.29613 | valid_mae: 1.78039 | valid_rmse: 1.8423  | valid_mse: 3.39407 |  0:00:01s\n",
      "epoch 1  | loss: 0.74127 | train_rmsle: 0.0539  | train_mae: 0.83517 | train_rmse: 0.92824 | train_mse: 0.86164 | valid_rmsle: 0.05399 | valid_mae: 0.83595 | valid_rmse: 0.93105 | valid_mse: 0.86685 |  0:00:03s\n",
      "epoch 2  | loss: 0.35745 | train_rmsle: 0.05258 | train_mae: 0.82503 | train_rmse: 0.91819 | train_mse: 0.84308 | valid_rmsle: 0.05261 | valid_mae: 0.8252  | valid_rmse: 0.92064 | valid_mse: 0.84758 |  0:00:05s\n",
      "epoch 3  | loss: 0.27672 | train_rmsle: 0.04404 | train_mae: 0.75595 | train_rmse: 0.84928 | train_mse: 0.72128 | valid_rmsle: 0.04402 | valid_mae: 0.75548 | valid_rmse: 0.85146 | valid_mse: 0.72498 |  0:00:06s\n",
      "epoch 4  | loss: 0.2563  | train_rmsle: 0.02714 | train_mae: 0.58933 | train_rmse: 0.68017 | train_mse: 0.46264 | valid_rmsle: 0.02697 | valid_mae: 0.58992 | valid_rmse: 0.68151 | valid_mse: 0.46445 |  0:00:08s\n",
      "epoch 5  | loss: 0.24116 | train_rmsle: 0.02197 | train_mae: 0.52474 | train_rmse: 0.61347 | train_mse: 0.37634 | valid_rmsle: 0.02167 | valid_mae: 0.5258  | valid_rmse: 0.61354 | valid_mse: 0.37643 |  0:00:10s\n",
      "epoch 6  | loss: 0.23515 | train_rmsle: 0.02128 | train_mae: 0.51506 | train_rmse: 0.60362 | train_mse: 0.36436 | valid_rmsle: 0.02094 | valid_mae: 0.51535 | valid_rmse: 0.60315 | valid_mse: 0.36379 |  0:00:11s\n",
      "epoch 7  | loss: 0.23052 | train_rmsle: 0.0212  | train_mae: 0.5139  | train_rmse: 0.60252 | train_mse: 0.36303 | valid_rmsle: 0.0209  | valid_mae: 0.51478 | valid_rmse: 0.60243 | valid_mse: 0.36292 |  0:00:13s\n",
      "epoch 8  | loss: 0.22824 | train_rmsle: 0.01714 | train_mae: 0.45    | train_rmse: 0.53789 | train_mse: 0.28933 | valid_rmsle: 0.01673 | valid_mae: 0.4511  | valid_rmse: 0.53632 | valid_mse: 0.28764 |  0:00:15s\n",
      "epoch 9  | loss: 0.23502 | train_rmsle: 0.01783 | train_mae: 0.46238 | train_rmse: 0.54995 | train_mse: 0.30245 | valid_rmsle: 0.01745 | valid_mae: 0.46355 | valid_rmse: 0.54898 | valid_mse: 0.30137 |  0:00:17s\n",
      "epoch 10 | loss: 0.22551 | train_rmsle: 0.01558 | train_mae: 0.41842 | train_rmse: 0.50822 | train_mse: 0.25829 | valid_rmsle: 0.01501 | valid_mae: 0.41896 | valid_rmse: 0.50421 | valid_mse: 0.25423 |  0:00:18s\n",
      "epoch 11 | loss: 0.22105 | train_rmsle: 0.01494 | train_mae: 0.40263 | train_rmse: 0.49451 | train_mse: 0.24454 | valid_rmsle: 0.01434 | valid_mae: 0.40346 | valid_rmse: 0.48991 | valid_mse: 0.24001 |  0:00:20s\n",
      "epoch 12 | loss: 0.21645 | train_rmsle: 0.01476 | train_mae: 0.39785 | train_rmse: 0.49035 | train_mse: 0.24045 | valid_rmsle: 0.01419 | valid_mae: 0.3983  | valid_rmse: 0.48638 | valid_mse: 0.23657 |  0:00:22s\n",
      "epoch 13 | loss: 0.21549 | train_rmsle: 0.01466 | train_mae: 0.40007 | train_rmse: 0.49073 | train_mse: 0.24081 | valid_rmsle: 0.014   | valid_mae: 0.39963 | valid_rmse: 0.48487 | valid_mse: 0.2351  |  0:00:23s\n",
      "epoch 14 | loss: 0.20472 | train_rmsle: 0.01208 | train_mae: 0.33888 | train_rmse: 0.43587 | train_mse: 0.18999 | valid_rmsle: 0.01133 | valid_mae: 0.33663 | valid_rmse: 0.42705 | valid_mse: 0.18237 |  0:00:25s\n",
      "epoch 15 | loss: 0.14507 | train_rmsle: 0.00864 | train_mae: 0.2825  | train_rmse: 0.36676 | train_mse: 0.13451 | valid_rmsle: 0.00781 | valid_mae: 0.26837 | valid_rmse: 0.35135 | valid_mse: 0.12345 |  0:00:27s\n",
      "epoch 16 | loss: 0.11577 | train_rmsle: 0.00814 | train_mae: 0.27811 | train_rmse: 0.35729 | train_mse: 0.12766 | valid_rmsle: 0.00718 | valid_mae: 0.26567 | valid_rmse: 0.34045 | valid_mse: 0.1159  |  0:00:28s\n",
      "epoch 17 | loss: 0.10805 | train_rmsle: 0.0082  | train_mae: 0.27546 | train_rmse: 0.35632 | train_mse: 0.12697 | valid_rmsle: 0.00732 | valid_mae: 0.26376 | valid_rmse: 0.34022 | valid_mse: 0.11575 |  0:00:30s\n",
      "epoch 18 | loss: 0.10404 | train_rmsle: 0.00727 | train_mae: 0.26162 | train_rmse: 0.33579 | train_mse: 0.11276 | valid_rmsle: 0.00657 | valid_mae: 0.25145 | valid_rmse: 0.32322 | valid_mse: 0.10447 |  0:00:32s\n",
      "epoch 19 | loss: 0.10303 | train_rmsle: 0.00699 | train_mae: 0.25356 | train_rmse: 0.32873 | train_mse: 0.10806 | valid_rmsle: 0.0064  | valid_mae: 0.2455  | valid_rmse: 0.31915 | valid_mse: 0.10186 |  0:00:34s\n",
      "epoch 20 | loss: 0.10132 | train_rmsle: 0.00708 | train_mae: 0.25765 | train_rmse: 0.33127 | train_mse: 0.10974 | valid_rmsle: 0.00643 | valid_mae: 0.2477  | valid_rmse: 0.31942 | valid_mse: 0.10203 |  0:00:35s\n",
      "epoch 21 | loss: 0.09961 | train_rmsle: 0.0068  | train_mae: 0.2477  | train_rmse: 0.32173 | train_mse: 0.10351 | valid_rmsle: 0.00609 | valid_mae: 0.23682 | valid_rmse: 0.30865 | valid_mse: 0.09527 |  0:00:37s\n",
      "epoch 22 | loss: 0.09836 | train_rmsle: 0.00683 | train_mae: 0.25244 | train_rmse: 0.32395 | train_mse: 0.10494 | valid_rmsle: 0.00613 | valid_mae: 0.23948 | valid_rmse: 0.31067 | valid_mse: 0.09652 |  0:00:39s\n",
      "epoch 23 | loss: 0.0967  | train_rmsle: 0.00684 | train_mae: 0.25441 | train_rmse: 0.32485 | train_mse: 0.10553 | valid_rmsle: 0.00625 | valid_mae: 0.24444 | valid_rmse: 0.31394 | valid_mse: 0.09856 |  0:00:40s\n",
      "epoch 24 | loss: 0.09739 | train_rmsle: 0.0065  | train_mae: 0.23875 | train_rmse: 0.31252 | train_mse: 0.09767 | valid_rmsle: 0.00604 | valid_mae: 0.2333  | valid_rmse: 0.30511 | valid_mse: 0.09309 |  0:00:42s\n",
      "epoch 25 | loss: 0.097   | train_rmsle: 0.00649 | train_mae: 0.2401  | train_rmse: 0.31341 | train_mse: 0.09823 | valid_rmsle: 0.006   | valid_mae: 0.23332 | valid_rmse: 0.3055  | valid_mse: 0.09333 |  0:00:43s\n",
      "epoch 26 | loss: 0.09711 | train_rmsle: 0.00654 | train_mae: 0.23851 | train_rmse: 0.31419 | train_mse: 0.09872 | valid_rmsle: 0.00614 | valid_mae: 0.23477 | valid_rmse: 0.30864 | valid_mse: 0.09526 |  0:00:45s\n",
      "epoch 27 | loss: 0.09769 | train_rmsle: 0.00649 | train_mae: 0.24036 | train_rmse: 0.31364 | train_mse: 0.09837 | valid_rmsle: 0.0061  | valid_mae: 0.23498 | valid_rmse: 0.30801 | valid_mse: 0.09487 |  0:00:46s\n",
      "epoch 28 | loss: 0.09658 | train_rmsle: 0.00632 | train_mae: 0.23715 | train_rmse: 0.30862 | train_mse: 0.09525 | valid_rmsle: 0.00588 | valid_mae: 0.23172 | valid_rmse: 0.30155 | valid_mse: 0.09093 |  0:00:47s\n",
      "epoch 29 | loss: 0.09554 | train_rmsle: 0.00629 | train_mae: 0.23645 | train_rmse: 0.3086  | train_mse: 0.09523 | valid_rmsle: 0.00603 | valid_mae: 0.23364 | valid_rmse: 0.30571 | valid_mse: 0.09346 |  0:00:48s\n",
      "epoch 30 | loss: 0.09451 | train_rmsle: 0.00624 | train_mae: 0.23352 | train_rmse: 0.30581 | train_mse: 0.09352 | valid_rmsle: 0.00608 | valid_mae: 0.23156 | valid_rmse: 0.30505 | valid_mse: 0.09305 |  0:00:50s\n",
      "epoch 31 | loss: 0.09449 | train_rmsle: 0.00631 | train_mae: 0.23199 | train_rmse: 0.30698 | train_mse: 0.09424 | valid_rmsle: 0.00631 | valid_mae: 0.23463 | valid_rmse: 0.3116  | valid_mse: 0.0971  |  0:00:51s\n",
      "epoch 32 | loss: 0.09528 | train_rmsle: 0.00616 | train_mae: 0.23296 | train_rmse: 0.30489 | train_mse: 0.09296 | valid_rmsle: 0.00613 | valid_mae: 0.23383 | valid_rmse: 0.30823 | valid_mse: 0.09501 |  0:00:52s\n",
      "epoch 33 | loss: 0.09378 | train_rmsle: 0.00611 | train_mae: 0.2334  | train_rmse: 0.30417 | train_mse: 0.09252 | valid_rmsle: 0.00617 | valid_mae: 0.23678 | valid_rmse: 0.3095  | valid_mse: 0.09579 |  0:00:53s\n",
      "epoch 34 | loss: 0.09223 | train_rmsle: 0.00612 | train_mae: 0.22991 | train_rmse: 0.30191 | train_mse: 0.09115 | valid_rmsle: 0.0061  | valid_mae: 0.23335 | valid_rmse: 0.30628 | valid_mse: 0.09381 |  0:00:55s\n",
      "epoch 35 | loss: 0.0918  | train_rmsle: 0.00595 | train_mae: 0.23068 | train_rmse: 0.3002  | train_mse: 0.09012 | valid_rmsle: 0.00607 | valid_mae: 0.23553 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:00:56s\n",
      "epoch 36 | loss: 0.09108 | train_rmsle: 0.00588 | train_mae: 0.22792 | train_rmse: 0.29797 | train_mse: 0.08879 | valid_rmsle: 0.00605 | valid_mae: 0.23437 | valid_rmse: 0.30704 | valid_mse: 0.09428 |  0:00:58s\n",
      "epoch 37 | loss: 0.0901  | train_rmsle: 0.00587 | train_mae: 0.23061 | train_rmse: 0.29881 | train_mse: 0.08929 | valid_rmsle: 0.00622 | valid_mae: 0.23892 | valid_rmse: 0.31142 | valid_mse: 0.09698 |  0:00:59s\n",
      "epoch 38 | loss: 0.09084 | train_rmsle: 0.00579 | train_mae: 0.22849 | train_rmse: 0.29668 | train_mse: 0.08802 | valid_rmsle: 0.00631 | valid_mae: 0.23993 | valid_rmse: 0.31377 | valid_mse: 0.09845 |  0:01:01s\n",
      "epoch 39 | loss: 0.08889 | train_rmsle: 0.00575 | train_mae: 0.22583 | train_rmse: 0.29466 | train_mse: 0.08682 | valid_rmsle: 0.00617 | valid_mae: 0.23538 | valid_rmse: 0.30936 | valid_mse: 0.0957  |  0:01:03s\n",
      "epoch 40 | loss: 0.09098 | train_rmsle: 0.00567 | train_mae: 0.2252  | train_rmse: 0.29277 | train_mse: 0.08572 | valid_rmsle: 0.00638 | valid_mae: 0.24243 | valid_rmse: 0.31586 | valid_mse: 0.09977 |  0:01:04s\n",
      "epoch 41 | loss: 0.08761 | train_rmsle: 0.00569 | train_mae: 0.22853 | train_rmse: 0.29448 | train_mse: 0.08672 | valid_rmsle: 0.0065  | valid_mae: 0.24919 | valid_rmse: 0.31996 | valid_mse: 0.10238 |  0:01:06s\n",
      "epoch 42 | loss: 0.08842 | train_rmsle: 0.00559 | train_mae: 0.22193 | train_rmse: 0.2902  | train_mse: 0.08421 | valid_rmsle: 0.00646 | valid_mae: 0.24559 | valid_rmse: 0.31771 | valid_mse: 0.10094 |  0:01:08s\n",
      "epoch 43 | loss: 0.08717 | train_rmsle: 0.00567 | train_mae: 0.22283 | train_rmse: 0.29137 | train_mse: 0.0849  | valid_rmsle: 0.0065  | valid_mae: 0.24491 | valid_rmse: 0.31856 | valid_mse: 0.10148 |  0:01:09s\n",
      "epoch 44 | loss: 0.08697 | train_rmsle: 0.00539 | train_mae: 0.21754 | train_rmse: 0.28524 | train_mse: 0.08136 | valid_rmsle: 0.00651 | valid_mae: 0.24314 | valid_rmse: 0.31975 | valid_mse: 0.10224 |  0:01:11s\n",
      "epoch 45 | loss: 0.08592 | train_rmsle: 0.00545 | train_mae: 0.21656 | train_rmse: 0.28538 | train_mse: 0.08144 | valid_rmsle: 0.00657 | valid_mae: 0.2471  | valid_rmse: 0.32094 | valid_mse: 0.103   |  0:01:13s\n",
      "epoch 46 | loss: 0.08374 | train_rmsle: 0.00551 | train_mae: 0.21385 | train_rmse: 0.28555 | train_mse: 0.08154 | valid_rmsle: 0.00668 | valid_mae: 0.24377 | valid_rmse: 0.32246 | valid_mse: 0.10398 |  0:01:14s\n",
      "epoch 47 | loss: 0.08609 | train_rmsle: 0.00532 | train_mae: 0.2116  | train_rmse: 0.28113 | train_mse: 0.07903 | valid_rmsle: 0.00665 | valid_mae: 0.24337 | valid_rmse: 0.32118 | valid_mse: 0.10316 |  0:01:16s\n",
      "epoch 48 | loss: 0.08469 | train_rmsle: 0.00527 | train_mae: 0.21053 | train_rmse: 0.27972 | train_mse: 0.07824 | valid_rmsle: 0.00666 | valid_mae: 0.24246 | valid_rmse: 0.32169 | valid_mse: 0.10348 |  0:01:17s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_valid_mse = 0.09093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10023314423349099 RMSE: 0.3165961848056464 R2: 0.5563064921706122 MAE: 0.242297519581371\n",
      "=====================================\n",
      "[42/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.50662 | train_rmsle: 0.29481 | train_mae: 1.77415 | train_rmse: 1.83727 | train_mse: 3.37555 | valid_rmsle: 0.29613 | valid_mae: 1.78039 | valid_rmse: 1.8423  | valid_mse: 3.39407 |  0:00:01s\n",
      "epoch 1  | loss: 0.74127 | train_rmsle: 0.0539  | train_mae: 0.83517 | train_rmse: 0.92824 | train_mse: 0.86164 | valid_rmsle: 0.05399 | valid_mae: 0.83595 | valid_rmse: 0.93105 | valid_mse: 0.86685 |  0:00:03s\n",
      "epoch 2  | loss: 0.35745 | train_rmsle: 0.05258 | train_mae: 0.82503 | train_rmse: 0.91819 | train_mse: 0.84308 | valid_rmsle: 0.05261 | valid_mae: 0.8252  | valid_rmse: 0.92064 | valid_mse: 0.84758 |  0:00:04s\n",
      "epoch 3  | loss: 0.27672 | train_rmsle: 0.04404 | train_mae: 0.75595 | train_rmse: 0.84928 | train_mse: 0.72128 | valid_rmsle: 0.04402 | valid_mae: 0.75548 | valid_rmse: 0.85146 | valid_mse: 0.72498 |  0:00:06s\n",
      "epoch 4  | loss: 0.2563  | train_rmsle: 0.02714 | train_mae: 0.58933 | train_rmse: 0.68017 | train_mse: 0.46264 | valid_rmsle: 0.02697 | valid_mae: 0.58992 | valid_rmse: 0.68151 | valid_mse: 0.46445 |  0:00:08s\n",
      "epoch 5  | loss: 0.24116 | train_rmsle: 0.02197 | train_mae: 0.52474 | train_rmse: 0.61347 | train_mse: 0.37634 | valid_rmsle: 0.02167 | valid_mae: 0.5258  | valid_rmse: 0.61354 | valid_mse: 0.37643 |  0:00:09s\n",
      "epoch 6  | loss: 0.23515 | train_rmsle: 0.02128 | train_mae: 0.51506 | train_rmse: 0.60362 | train_mse: 0.36436 | valid_rmsle: 0.02094 | valid_mae: 0.51535 | valid_rmse: 0.60315 | valid_mse: 0.36379 |  0:00:11s\n",
      "epoch 7  | loss: 0.23052 | train_rmsle: 0.0212  | train_mae: 0.5139  | train_rmse: 0.60252 | train_mse: 0.36303 | valid_rmsle: 0.0209  | valid_mae: 0.51478 | valid_rmse: 0.60243 | valid_mse: 0.36292 |  0:00:13s\n",
      "epoch 8  | loss: 0.22824 | train_rmsle: 0.01714 | train_mae: 0.45    | train_rmse: 0.53789 | train_mse: 0.28933 | valid_rmsle: 0.01673 | valid_mae: 0.4511  | valid_rmse: 0.53632 | valid_mse: 0.28764 |  0:00:14s\n",
      "epoch 9  | loss: 0.23502 | train_rmsle: 0.01783 | train_mae: 0.46238 | train_rmse: 0.54995 | train_mse: 0.30245 | valid_rmsle: 0.01745 | valid_mae: 0.46355 | valid_rmse: 0.54898 | valid_mse: 0.30137 |  0:00:16s\n",
      "epoch 10 | loss: 0.22551 | train_rmsle: 0.01558 | train_mae: 0.41842 | train_rmse: 0.50822 | train_mse: 0.25829 | valid_rmsle: 0.01501 | valid_mae: 0.41896 | valid_rmse: 0.50421 | valid_mse: 0.25423 |  0:00:18s\n",
      "epoch 11 | loss: 0.22105 | train_rmsle: 0.01494 | train_mae: 0.40263 | train_rmse: 0.49451 | train_mse: 0.24454 | valid_rmsle: 0.01434 | valid_mae: 0.40346 | valid_rmse: 0.48991 | valid_mse: 0.24001 |  0:00:20s\n",
      "epoch 12 | loss: 0.21645 | train_rmsle: 0.01476 | train_mae: 0.39785 | train_rmse: 0.49035 | train_mse: 0.24045 | valid_rmsle: 0.01419 | valid_mae: 0.3983  | valid_rmse: 0.48638 | valid_mse: 0.23657 |  0:00:21s\n",
      "epoch 13 | loss: 0.21549 | train_rmsle: 0.01466 | train_mae: 0.40007 | train_rmse: 0.49073 | train_mse: 0.24081 | valid_rmsle: 0.014   | valid_mae: 0.39963 | valid_rmse: 0.48487 | valid_mse: 0.2351  |  0:00:23s\n",
      "epoch 14 | loss: 0.20472 | train_rmsle: 0.01208 | train_mae: 0.33888 | train_rmse: 0.43587 | train_mse: 0.18999 | valid_rmsle: 0.01133 | valid_mae: 0.33663 | valid_rmse: 0.42705 | valid_mse: 0.18237 |  0:00:24s\n",
      "epoch 15 | loss: 0.14507 | train_rmsle: 0.00864 | train_mae: 0.2825  | train_rmse: 0.36676 | train_mse: 0.13451 | valid_rmsle: 0.00781 | valid_mae: 0.26837 | valid_rmse: 0.35135 | valid_mse: 0.12345 |  0:00:26s\n",
      "epoch 16 | loss: 0.11577 | train_rmsle: 0.00814 | train_mae: 0.27811 | train_rmse: 0.35729 | train_mse: 0.12766 | valid_rmsle: 0.00718 | valid_mae: 0.26567 | valid_rmse: 0.34045 | valid_mse: 0.1159  |  0:00:28s\n",
      "epoch 17 | loss: 0.10805 | train_rmsle: 0.0082  | train_mae: 0.27546 | train_rmse: 0.35632 | train_mse: 0.12697 | valid_rmsle: 0.00732 | valid_mae: 0.26376 | valid_rmse: 0.34022 | valid_mse: 0.11575 |  0:00:30s\n",
      "epoch 18 | loss: 0.10404 | train_rmsle: 0.00727 | train_mae: 0.26162 | train_rmse: 0.33579 | train_mse: 0.11276 | valid_rmsle: 0.00657 | valid_mae: 0.25145 | valid_rmse: 0.32322 | valid_mse: 0.10447 |  0:00:31s\n",
      "epoch 19 | loss: 0.10303 | train_rmsle: 0.00699 | train_mae: 0.25356 | train_rmse: 0.32873 | train_mse: 0.10806 | valid_rmsle: 0.0064  | valid_mae: 0.2455  | valid_rmse: 0.31915 | valid_mse: 0.10186 |  0:00:33s\n",
      "epoch 20 | loss: 0.10132 | train_rmsle: 0.00708 | train_mae: 0.25765 | train_rmse: 0.33127 | train_mse: 0.10974 | valid_rmsle: 0.00643 | valid_mae: 0.2477  | valid_rmse: 0.31942 | valid_mse: 0.10203 |  0:00:35s\n",
      "epoch 21 | loss: 0.09961 | train_rmsle: 0.0068  | train_mae: 0.2477  | train_rmse: 0.32173 | train_mse: 0.10351 | valid_rmsle: 0.00609 | valid_mae: 0.23682 | valid_rmse: 0.30865 | valid_mse: 0.09527 |  0:00:36s\n",
      "epoch 22 | loss: 0.09836 | train_rmsle: 0.00683 | train_mae: 0.25244 | train_rmse: 0.32395 | train_mse: 0.10494 | valid_rmsle: 0.00613 | valid_mae: 0.23948 | valid_rmse: 0.31067 | valid_mse: 0.09652 |  0:00:38s\n",
      "epoch 23 | loss: 0.0967  | train_rmsle: 0.00684 | train_mae: 0.25441 | train_rmse: 0.32485 | train_mse: 0.10553 | valid_rmsle: 0.00625 | valid_mae: 0.24444 | valid_rmse: 0.31394 | valid_mse: 0.09856 |  0:00:40s\n",
      "epoch 24 | loss: 0.09739 | train_rmsle: 0.0065  | train_mae: 0.23875 | train_rmse: 0.31252 | train_mse: 0.09767 | valid_rmsle: 0.00604 | valid_mae: 0.2333  | valid_rmse: 0.30511 | valid_mse: 0.09309 |  0:00:41s\n",
      "epoch 25 | loss: 0.097   | train_rmsle: 0.00649 | train_mae: 0.2401  | train_rmse: 0.31341 | train_mse: 0.09823 | valid_rmsle: 0.006   | valid_mae: 0.23332 | valid_rmse: 0.3055  | valid_mse: 0.09333 |  0:00:43s\n",
      "epoch 26 | loss: 0.09711 | train_rmsle: 0.00654 | train_mae: 0.23851 | train_rmse: 0.31419 | train_mse: 0.09872 | valid_rmsle: 0.00614 | valid_mae: 0.23477 | valid_rmse: 0.30864 | valid_mse: 0.09526 |  0:00:44s\n",
      "epoch 27 | loss: 0.09769 | train_rmsle: 0.00649 | train_mae: 0.24036 | train_rmse: 0.31364 | train_mse: 0.09837 | valid_rmsle: 0.0061  | valid_mae: 0.23498 | valid_rmse: 0.30801 | valid_mse: 0.09487 |  0:00:46s\n",
      "epoch 28 | loss: 0.09658 | train_rmsle: 0.00632 | train_mae: 0.23715 | train_rmse: 0.30862 | train_mse: 0.09525 | valid_rmsle: 0.00588 | valid_mae: 0.23172 | valid_rmse: 0.30155 | valid_mse: 0.09093 |  0:00:48s\n",
      "epoch 29 | loss: 0.09554 | train_rmsle: 0.00629 | train_mae: 0.23645 | train_rmse: 0.3086  | train_mse: 0.09523 | valid_rmsle: 0.00603 | valid_mae: 0.23364 | valid_rmse: 0.30571 | valid_mse: 0.09346 |  0:00:49s\n",
      "epoch 30 | loss: 0.09451 | train_rmsle: 0.00624 | train_mae: 0.23352 | train_rmse: 0.30581 | train_mse: 0.09352 | valid_rmsle: 0.00608 | valid_mae: 0.23156 | valid_rmse: 0.30505 | valid_mse: 0.09305 |  0:00:51s\n",
      "epoch 31 | loss: 0.09449 | train_rmsle: 0.00631 | train_mae: 0.23199 | train_rmse: 0.30698 | train_mse: 0.09424 | valid_rmsle: 0.00631 | valid_mae: 0.23463 | valid_rmse: 0.3116  | valid_mse: 0.0971  |  0:00:53s\n",
      "epoch 32 | loss: 0.09528 | train_rmsle: 0.00616 | train_mae: 0.23296 | train_rmse: 0.30489 | train_mse: 0.09296 | valid_rmsle: 0.00613 | valid_mae: 0.23383 | valid_rmse: 0.30823 | valid_mse: 0.09501 |  0:00:54s\n",
      "epoch 33 | loss: 0.09378 | train_rmsle: 0.00611 | train_mae: 0.2334  | train_rmse: 0.30417 | train_mse: 0.09252 | valid_rmsle: 0.00617 | valid_mae: 0.23678 | valid_rmse: 0.3095  | valid_mse: 0.09579 |  0:00:56s\n",
      "epoch 34 | loss: 0.09223 | train_rmsle: 0.00612 | train_mae: 0.22991 | train_rmse: 0.30191 | train_mse: 0.09115 | valid_rmsle: 0.0061  | valid_mae: 0.23335 | valid_rmse: 0.30628 | valid_mse: 0.09381 |  0:00:58s\n",
      "epoch 35 | loss: 0.0918  | train_rmsle: 0.00595 | train_mae: 0.23068 | train_rmse: 0.3002  | train_mse: 0.09012 | valid_rmsle: 0.00607 | valid_mae: 0.23553 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:00:59s\n",
      "epoch 36 | loss: 0.09108 | train_rmsle: 0.00588 | train_mae: 0.22792 | train_rmse: 0.29797 | train_mse: 0.08879 | valid_rmsle: 0.00605 | valid_mae: 0.23437 | valid_rmse: 0.30704 | valid_mse: 0.09428 |  0:01:01s\n",
      "epoch 37 | loss: 0.0901  | train_rmsle: 0.00587 | train_mae: 0.23061 | train_rmse: 0.29881 | train_mse: 0.08929 | valid_rmsle: 0.00622 | valid_mae: 0.23892 | valid_rmse: 0.31142 | valid_mse: 0.09698 |  0:01:03s\n",
      "epoch 38 | loss: 0.09084 | train_rmsle: 0.00579 | train_mae: 0.22849 | train_rmse: 0.29668 | train_mse: 0.08802 | valid_rmsle: 0.00631 | valid_mae: 0.23993 | valid_rmse: 0.31377 | valid_mse: 0.09845 |  0:01:04s\n",
      "epoch 39 | loss: 0.08889 | train_rmsle: 0.00575 | train_mae: 0.22583 | train_rmse: 0.29466 | train_mse: 0.08682 | valid_rmsle: 0.00617 | valid_mae: 0.23538 | valid_rmse: 0.30936 | valid_mse: 0.0957  |  0:01:06s\n",
      "epoch 40 | loss: 0.09098 | train_rmsle: 0.00567 | train_mae: 0.2252  | train_rmse: 0.29277 | train_mse: 0.08572 | valid_rmsle: 0.00638 | valid_mae: 0.24243 | valid_rmse: 0.31586 | valid_mse: 0.09977 |  0:01:08s\n",
      "epoch 41 | loss: 0.08761 | train_rmsle: 0.00569 | train_mae: 0.22853 | train_rmse: 0.29448 | train_mse: 0.08672 | valid_rmsle: 0.0065  | valid_mae: 0.24919 | valid_rmse: 0.31996 | valid_mse: 0.10238 |  0:01:09s\n",
      "epoch 42 | loss: 0.08842 | train_rmsle: 0.00559 | train_mae: 0.22193 | train_rmse: 0.2902  | train_mse: 0.08421 | valid_rmsle: 0.00646 | valid_mae: 0.24559 | valid_rmse: 0.31771 | valid_mse: 0.10094 |  0:01:10s\n",
      "epoch 43 | loss: 0.08717 | train_rmsle: 0.00567 | train_mae: 0.22283 | train_rmse: 0.29137 | train_mse: 0.0849  | valid_rmsle: 0.0065  | valid_mae: 0.24491 | valid_rmse: 0.31856 | valid_mse: 0.10148 |  0:01:12s\n",
      "epoch 44 | loss: 0.08697 | train_rmsle: 0.00539 | train_mae: 0.21754 | train_rmse: 0.28524 | train_mse: 0.08136 | valid_rmsle: 0.00651 | valid_mae: 0.24314 | valid_rmse: 0.31975 | valid_mse: 0.10224 |  0:01:13s\n",
      "epoch 45 | loss: 0.08592 | train_rmsle: 0.00545 | train_mae: 0.21656 | train_rmse: 0.28538 | train_mse: 0.08144 | valid_rmsle: 0.00657 | valid_mae: 0.2471  | valid_rmse: 0.32094 | valid_mse: 0.103   |  0:01:14s\n",
      "epoch 46 | loss: 0.08374 | train_rmsle: 0.00551 | train_mae: 0.21385 | train_rmse: 0.28555 | train_mse: 0.08154 | valid_rmsle: 0.00668 | valid_mae: 0.24377 | valid_rmse: 0.32246 | valid_mse: 0.10398 |  0:01:16s\n",
      "epoch 47 | loss: 0.08609 | train_rmsle: 0.00532 | train_mae: 0.2116  | train_rmse: 0.28113 | train_mse: 0.07903 | valid_rmsle: 0.00665 | valid_mae: 0.24337 | valid_rmse: 0.32118 | valid_mse: 0.10316 |  0:01:17s\n",
      "epoch 48 | loss: 0.08469 | train_rmsle: 0.00527 | train_mae: 0.21053 | train_rmse: 0.27972 | train_mse: 0.07824 | valid_rmsle: 0.00666 | valid_mae: 0.24246 | valid_rmse: 0.32169 | valid_mse: 0.10348 |  0:01:18s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_valid_mse = 0.09093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10023314423349099 RMSE: 0.3165961848056464 R2: 0.5563064921706122 MAE: 0.242297519581371\n",
      "=====================================\n",
      "[43/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.50662 | train_rmsle: 0.29481 | train_mae: 1.77415 | train_rmse: 1.83727 | train_mse: 3.37555 | valid_rmsle: 0.29613 | valid_mae: 1.78039 | valid_rmse: 1.8423  | valid_mse: 3.39407 |  0:00:01s\n",
      "epoch 1  | loss: 0.74127 | train_rmsle: 0.0539  | train_mae: 0.83517 | train_rmse: 0.92824 | train_mse: 0.86164 | valid_rmsle: 0.05399 | valid_mae: 0.83595 | valid_rmse: 0.93105 | valid_mse: 0.86685 |  0:00:03s\n",
      "epoch 2  | loss: 0.35745 | train_rmsle: 0.05258 | train_mae: 0.82503 | train_rmse: 0.91819 | train_mse: 0.84308 | valid_rmsle: 0.05261 | valid_mae: 0.8252  | valid_rmse: 0.92064 | valid_mse: 0.84758 |  0:00:05s\n",
      "epoch 3  | loss: 0.27672 | train_rmsle: 0.04404 | train_mae: 0.75595 | train_rmse: 0.84928 | train_mse: 0.72128 | valid_rmsle: 0.04402 | valid_mae: 0.75548 | valid_rmse: 0.85146 | valid_mse: 0.72498 |  0:00:06s\n",
      "epoch 4  | loss: 0.2563  | train_rmsle: 0.02714 | train_mae: 0.58933 | train_rmse: 0.68017 | train_mse: 0.46264 | valid_rmsle: 0.02697 | valid_mae: 0.58992 | valid_rmse: 0.68151 | valid_mse: 0.46445 |  0:00:08s\n",
      "epoch 5  | loss: 0.24116 | train_rmsle: 0.02197 | train_mae: 0.52474 | train_rmse: 0.61347 | train_mse: 0.37634 | valid_rmsle: 0.02167 | valid_mae: 0.5258  | valid_rmse: 0.61354 | valid_mse: 0.37643 |  0:00:10s\n",
      "epoch 6  | loss: 0.23515 | train_rmsle: 0.02128 | train_mae: 0.51506 | train_rmse: 0.60362 | train_mse: 0.36436 | valid_rmsle: 0.02094 | valid_mae: 0.51535 | valid_rmse: 0.60315 | valid_mse: 0.36379 |  0:00:11s\n",
      "epoch 7  | loss: 0.23052 | train_rmsle: 0.0212  | train_mae: 0.5139  | train_rmse: 0.60252 | train_mse: 0.36303 | valid_rmsle: 0.0209  | valid_mae: 0.51478 | valid_rmse: 0.60243 | valid_mse: 0.36292 |  0:00:13s\n",
      "epoch 8  | loss: 0.22824 | train_rmsle: 0.01714 | train_mae: 0.45    | train_rmse: 0.53789 | train_mse: 0.28933 | valid_rmsle: 0.01673 | valid_mae: 0.4511  | valid_rmse: 0.53632 | valid_mse: 0.28764 |  0:00:15s\n",
      "epoch 9  | loss: 0.23502 | train_rmsle: 0.01783 | train_mae: 0.46238 | train_rmse: 0.54995 | train_mse: 0.30245 | valid_rmsle: 0.01745 | valid_mae: 0.46355 | valid_rmse: 0.54898 | valid_mse: 0.30137 |  0:00:16s\n",
      "epoch 10 | loss: 0.22551 | train_rmsle: 0.01558 | train_mae: 0.41842 | train_rmse: 0.50822 | train_mse: 0.25829 | valid_rmsle: 0.01501 | valid_mae: 0.41896 | valid_rmse: 0.50421 | valid_mse: 0.25423 |  0:00:18s\n",
      "epoch 11 | loss: 0.22105 | train_rmsle: 0.01494 | train_mae: 0.40263 | train_rmse: 0.49451 | train_mse: 0.24454 | valid_rmsle: 0.01434 | valid_mae: 0.40346 | valid_rmse: 0.48991 | valid_mse: 0.24001 |  0:00:19s\n",
      "epoch 12 | loss: 0.21645 | train_rmsle: 0.01476 | train_mae: 0.39785 | train_rmse: 0.49035 | train_mse: 0.24045 | valid_rmsle: 0.01419 | valid_mae: 0.3983  | valid_rmse: 0.48638 | valid_mse: 0.23657 |  0:00:21s\n",
      "epoch 13 | loss: 0.21549 | train_rmsle: 0.01466 | train_mae: 0.40007 | train_rmse: 0.49073 | train_mse: 0.24081 | valid_rmsle: 0.014   | valid_mae: 0.39963 | valid_rmse: 0.48487 | valid_mse: 0.2351  |  0:00:23s\n",
      "epoch 14 | loss: 0.20472 | train_rmsle: 0.01208 | train_mae: 0.33888 | train_rmse: 0.43587 | train_mse: 0.18999 | valid_rmsle: 0.01133 | valid_mae: 0.33663 | valid_rmse: 0.42705 | valid_mse: 0.18237 |  0:00:25s\n",
      "epoch 15 | loss: 0.14507 | train_rmsle: 0.00864 | train_mae: 0.2825  | train_rmse: 0.36676 | train_mse: 0.13451 | valid_rmsle: 0.00781 | valid_mae: 0.26837 | valid_rmse: 0.35135 | valid_mse: 0.12345 |  0:00:26s\n",
      "epoch 16 | loss: 0.11577 | train_rmsle: 0.00814 | train_mae: 0.27811 | train_rmse: 0.35729 | train_mse: 0.12766 | valid_rmsle: 0.00718 | valid_mae: 0.26567 | valid_rmse: 0.34045 | valid_mse: 0.1159  |  0:00:28s\n",
      "epoch 17 | loss: 0.10805 | train_rmsle: 0.0082  | train_mae: 0.27546 | train_rmse: 0.35632 | train_mse: 0.12697 | valid_rmsle: 0.00732 | valid_mae: 0.26376 | valid_rmse: 0.34022 | valid_mse: 0.11575 |  0:00:29s\n",
      "epoch 18 | loss: 0.10404 | train_rmsle: 0.00727 | train_mae: 0.26162 | train_rmse: 0.33579 | train_mse: 0.11276 | valid_rmsle: 0.00657 | valid_mae: 0.25145 | valid_rmse: 0.32322 | valid_mse: 0.10447 |  0:00:31s\n",
      "epoch 19 | loss: 0.10303 | train_rmsle: 0.00699 | train_mae: 0.25356 | train_rmse: 0.32873 | train_mse: 0.10806 | valid_rmsle: 0.0064  | valid_mae: 0.2455  | valid_rmse: 0.31915 | valid_mse: 0.10186 |  0:00:33s\n",
      "epoch 20 | loss: 0.10132 | train_rmsle: 0.00708 | train_mae: 0.25765 | train_rmse: 0.33127 | train_mse: 0.10974 | valid_rmsle: 0.00643 | valid_mae: 0.2477  | valid_rmse: 0.31942 | valid_mse: 0.10203 |  0:00:34s\n",
      "epoch 21 | loss: 0.09961 | train_rmsle: 0.0068  | train_mae: 0.2477  | train_rmse: 0.32173 | train_mse: 0.10351 | valid_rmsle: 0.00609 | valid_mae: 0.23682 | valid_rmse: 0.30865 | valid_mse: 0.09527 |  0:00:36s\n",
      "epoch 22 | loss: 0.09836 | train_rmsle: 0.00683 | train_mae: 0.25244 | train_rmse: 0.32395 | train_mse: 0.10494 | valid_rmsle: 0.00613 | valid_mae: 0.23948 | valid_rmse: 0.31067 | valid_mse: 0.09652 |  0:00:38s\n",
      "epoch 23 | loss: 0.0967  | train_rmsle: 0.00684 | train_mae: 0.25441 | train_rmse: 0.32485 | train_mse: 0.10553 | valid_rmsle: 0.00625 | valid_mae: 0.24444 | valid_rmse: 0.31394 | valid_mse: 0.09856 |  0:00:39s\n",
      "epoch 24 | loss: 0.09739 | train_rmsle: 0.0065  | train_mae: 0.23875 | train_rmse: 0.31252 | train_mse: 0.09767 | valid_rmsle: 0.00604 | valid_mae: 0.2333  | valid_rmse: 0.30511 | valid_mse: 0.09309 |  0:00:41s\n",
      "epoch 25 | loss: 0.097   | train_rmsle: 0.00649 | train_mae: 0.2401  | train_rmse: 0.31341 | train_mse: 0.09823 | valid_rmsle: 0.006   | valid_mae: 0.23332 | valid_rmse: 0.3055  | valid_mse: 0.09333 |  0:00:43s\n",
      "epoch 26 | loss: 0.09711 | train_rmsle: 0.00654 | train_mae: 0.23851 | train_rmse: 0.31419 | train_mse: 0.09872 | valid_rmsle: 0.00614 | valid_mae: 0.23477 | valid_rmse: 0.30864 | valid_mse: 0.09526 |  0:00:44s\n",
      "epoch 27 | loss: 0.09769 | train_rmsle: 0.00649 | train_mae: 0.24036 | train_rmse: 0.31364 | train_mse: 0.09837 | valid_rmsle: 0.0061  | valid_mae: 0.23498 | valid_rmse: 0.30801 | valid_mse: 0.09487 |  0:00:46s\n",
      "epoch 28 | loss: 0.09658 | train_rmsle: 0.00632 | train_mae: 0.23715 | train_rmse: 0.30862 | train_mse: 0.09525 | valid_rmsle: 0.00588 | valid_mae: 0.23172 | valid_rmse: 0.30155 | valid_mse: 0.09093 |  0:00:48s\n",
      "epoch 29 | loss: 0.09554 | train_rmsle: 0.00629 | train_mae: 0.23645 | train_rmse: 0.3086  | train_mse: 0.09523 | valid_rmsle: 0.00603 | valid_mae: 0.23364 | valid_rmse: 0.30571 | valid_mse: 0.09346 |  0:00:49s\n",
      "epoch 30 | loss: 0.09451 | train_rmsle: 0.00624 | train_mae: 0.23352 | train_rmse: 0.30581 | train_mse: 0.09352 | valid_rmsle: 0.00608 | valid_mae: 0.23156 | valid_rmse: 0.30505 | valid_mse: 0.09305 |  0:00:51s\n",
      "epoch 31 | loss: 0.09449 | train_rmsle: 0.00631 | train_mae: 0.23199 | train_rmse: 0.30698 | train_mse: 0.09424 | valid_rmsle: 0.00631 | valid_mae: 0.23463 | valid_rmse: 0.3116  | valid_mse: 0.0971  |  0:00:52s\n",
      "epoch 32 | loss: 0.09528 | train_rmsle: 0.00616 | train_mae: 0.23296 | train_rmse: 0.30489 | train_mse: 0.09296 | valid_rmsle: 0.00613 | valid_mae: 0.23383 | valid_rmse: 0.30823 | valid_mse: 0.09501 |  0:00:53s\n",
      "epoch 33 | loss: 0.09378 | train_rmsle: 0.00611 | train_mae: 0.2334  | train_rmse: 0.30417 | train_mse: 0.09252 | valid_rmsle: 0.00617 | valid_mae: 0.23678 | valid_rmse: 0.3095  | valid_mse: 0.09579 |  0:00:55s\n",
      "epoch 34 | loss: 0.09223 | train_rmsle: 0.00612 | train_mae: 0.22991 | train_rmse: 0.30191 | train_mse: 0.09115 | valid_rmsle: 0.0061  | valid_mae: 0.23335 | valid_rmse: 0.30628 | valid_mse: 0.09381 |  0:00:56s\n",
      "epoch 35 | loss: 0.0918  | train_rmsle: 0.00595 | train_mae: 0.23068 | train_rmse: 0.3002  | train_mse: 0.09012 | valid_rmsle: 0.00607 | valid_mae: 0.23553 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:00:58s\n",
      "epoch 36 | loss: 0.09108 | train_rmsle: 0.00588 | train_mae: 0.22792 | train_rmse: 0.29797 | train_mse: 0.08879 | valid_rmsle: 0.00605 | valid_mae: 0.23437 | valid_rmse: 0.30704 | valid_mse: 0.09428 |  0:00:59s\n",
      "epoch 37 | loss: 0.0901  | train_rmsle: 0.00587 | train_mae: 0.23061 | train_rmse: 0.29881 | train_mse: 0.08929 | valid_rmsle: 0.00622 | valid_mae: 0.23892 | valid_rmse: 0.31142 | valid_mse: 0.09698 |  0:01:00s\n",
      "epoch 38 | loss: 0.09084 | train_rmsle: 0.00579 | train_mae: 0.22849 | train_rmse: 0.29668 | train_mse: 0.08802 | valid_rmsle: 0.00631 | valid_mae: 0.23993 | valid_rmse: 0.31377 | valid_mse: 0.09845 |  0:01:02s\n",
      "epoch 39 | loss: 0.08889 | train_rmsle: 0.00575 | train_mae: 0.22583 | train_rmse: 0.29466 | train_mse: 0.08682 | valid_rmsle: 0.00617 | valid_mae: 0.23538 | valid_rmse: 0.30936 | valid_mse: 0.0957  |  0:01:03s\n",
      "epoch 40 | loss: 0.09098 | train_rmsle: 0.00567 | train_mae: 0.2252  | train_rmse: 0.29277 | train_mse: 0.08572 | valid_rmsle: 0.00638 | valid_mae: 0.24243 | valid_rmse: 0.31586 | valid_mse: 0.09977 |  0:01:04s\n",
      "epoch 41 | loss: 0.08761 | train_rmsle: 0.00569 | train_mae: 0.22853 | train_rmse: 0.29448 | train_mse: 0.08672 | valid_rmsle: 0.0065  | valid_mae: 0.24919 | valid_rmse: 0.31996 | valid_mse: 0.10238 |  0:01:06s\n",
      "epoch 42 | loss: 0.08842 | train_rmsle: 0.00559 | train_mae: 0.22193 | train_rmse: 0.2902  | train_mse: 0.08421 | valid_rmsle: 0.00646 | valid_mae: 0.24559 | valid_rmse: 0.31771 | valid_mse: 0.10094 |  0:01:08s\n",
      "epoch 43 | loss: 0.08717 | train_rmsle: 0.00567 | train_mae: 0.22283 | train_rmse: 0.29137 | train_mse: 0.0849  | valid_rmsle: 0.0065  | valid_mae: 0.24491 | valid_rmse: 0.31856 | valid_mse: 0.10148 |  0:01:10s\n",
      "epoch 44 | loss: 0.08697 | train_rmsle: 0.00539 | train_mae: 0.21754 | train_rmse: 0.28524 | train_mse: 0.08136 | valid_rmsle: 0.00651 | valid_mae: 0.24314 | valid_rmse: 0.31975 | valid_mse: 0.10224 |  0:01:11s\n",
      "epoch 45 | loss: 0.08592 | train_rmsle: 0.00545 | train_mae: 0.21656 | train_rmse: 0.28538 | train_mse: 0.08144 | valid_rmsle: 0.00657 | valid_mae: 0.2471  | valid_rmse: 0.32094 | valid_mse: 0.103   |  0:01:13s\n",
      "epoch 46 | loss: 0.08374 | train_rmsle: 0.00551 | train_mae: 0.21385 | train_rmse: 0.28555 | train_mse: 0.08154 | valid_rmsle: 0.00668 | valid_mae: 0.24377 | valid_rmse: 0.32246 | valid_mse: 0.10398 |  0:01:14s\n",
      "epoch 47 | loss: 0.08609 | train_rmsle: 0.00532 | train_mae: 0.2116  | train_rmse: 0.28113 | train_mse: 0.07903 | valid_rmsle: 0.00665 | valid_mae: 0.24337 | valid_rmse: 0.32118 | valid_mse: 0.10316 |  0:01:16s\n",
      "epoch 48 | loss: 0.08469 | train_rmsle: 0.00527 | train_mae: 0.21053 | train_rmse: 0.27972 | train_mse: 0.07824 | valid_rmsle: 0.00666 | valid_mae: 0.24246 | valid_rmse: 0.32169 | valid_mse: 0.10348 |  0:01:18s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_valid_mse = 0.09093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10023314423349099 RMSE: 0.3165961848056464 R2: 0.5563064921706122 MAE: 0.242297519581371\n",
      "=====================================\n",
      "[44/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.50662 | train_rmsle: 0.29481 | train_mae: 1.77415 | train_rmse: 1.83727 | train_mse: 3.37555 | valid_rmsle: 0.29613 | valid_mae: 1.78039 | valid_rmse: 1.8423  | valid_mse: 3.39407 |  0:00:01s\n",
      "epoch 1  | loss: 0.74127 | train_rmsle: 0.0539  | train_mae: 0.83517 | train_rmse: 0.92824 | train_mse: 0.86164 | valid_rmsle: 0.05399 | valid_mae: 0.83595 | valid_rmse: 0.93105 | valid_mse: 0.86685 |  0:00:03s\n",
      "epoch 2  | loss: 0.35745 | train_rmsle: 0.05258 | train_mae: 0.82503 | train_rmse: 0.91819 | train_mse: 0.84308 | valid_rmsle: 0.05261 | valid_mae: 0.8252  | valid_rmse: 0.92064 | valid_mse: 0.84758 |  0:00:04s\n",
      "epoch 3  | loss: 0.27672 | train_rmsle: 0.04404 | train_mae: 0.75595 | train_rmse: 0.84928 | train_mse: 0.72128 | valid_rmsle: 0.04402 | valid_mae: 0.75548 | valid_rmse: 0.85146 | valid_mse: 0.72498 |  0:00:06s\n",
      "epoch 4  | loss: 0.2563  | train_rmsle: 0.02714 | train_mae: 0.58933 | train_rmse: 0.68017 | train_mse: 0.46264 | valid_rmsle: 0.02697 | valid_mae: 0.58992 | valid_rmse: 0.68151 | valid_mse: 0.46445 |  0:00:08s\n",
      "epoch 5  | loss: 0.24116 | train_rmsle: 0.02197 | train_mae: 0.52474 | train_rmse: 0.61347 | train_mse: 0.37634 | valid_rmsle: 0.02167 | valid_mae: 0.5258  | valid_rmse: 0.61354 | valid_mse: 0.37643 |  0:00:09s\n",
      "epoch 6  | loss: 0.23515 | train_rmsle: 0.02128 | train_mae: 0.51506 | train_rmse: 0.60362 | train_mse: 0.36436 | valid_rmsle: 0.02094 | valid_mae: 0.51535 | valid_rmse: 0.60315 | valid_mse: 0.36379 |  0:00:11s\n",
      "epoch 7  | loss: 0.23052 | train_rmsle: 0.0212  | train_mae: 0.5139  | train_rmse: 0.60252 | train_mse: 0.36303 | valid_rmsle: 0.0209  | valid_mae: 0.51478 | valid_rmse: 0.60243 | valid_mse: 0.36292 |  0:00:13s\n",
      "epoch 8  | loss: 0.22824 | train_rmsle: 0.01714 | train_mae: 0.45    | train_rmse: 0.53789 | train_mse: 0.28933 | valid_rmsle: 0.01673 | valid_mae: 0.4511  | valid_rmse: 0.53632 | valid_mse: 0.28764 |  0:00:14s\n",
      "epoch 9  | loss: 0.23502 | train_rmsle: 0.01783 | train_mae: 0.46238 | train_rmse: 0.54995 | train_mse: 0.30245 | valid_rmsle: 0.01745 | valid_mae: 0.46355 | valid_rmse: 0.54898 | valid_mse: 0.30137 |  0:00:16s\n",
      "epoch 10 | loss: 0.22551 | train_rmsle: 0.01558 | train_mae: 0.41842 | train_rmse: 0.50822 | train_mse: 0.25829 | valid_rmsle: 0.01501 | valid_mae: 0.41896 | valid_rmse: 0.50421 | valid_mse: 0.25423 |  0:00:18s\n",
      "epoch 11 | loss: 0.22105 | train_rmsle: 0.01494 | train_mae: 0.40263 | train_rmse: 0.49451 | train_mse: 0.24454 | valid_rmsle: 0.01434 | valid_mae: 0.40346 | valid_rmse: 0.48991 | valid_mse: 0.24001 |  0:00:19s\n",
      "epoch 12 | loss: 0.21645 | train_rmsle: 0.01476 | train_mae: 0.39785 | train_rmse: 0.49035 | train_mse: 0.24045 | valid_rmsle: 0.01419 | valid_mae: 0.3983  | valid_rmse: 0.48638 | valid_mse: 0.23657 |  0:00:21s\n",
      "epoch 13 | loss: 0.21549 | train_rmsle: 0.01466 | train_mae: 0.40007 | train_rmse: 0.49073 | train_mse: 0.24081 | valid_rmsle: 0.014   | valid_mae: 0.39963 | valid_rmse: 0.48487 | valid_mse: 0.2351  |  0:00:23s\n",
      "epoch 14 | loss: 0.20472 | train_rmsle: 0.01208 | train_mae: 0.33888 | train_rmse: 0.43587 | train_mse: 0.18999 | valid_rmsle: 0.01133 | valid_mae: 0.33663 | valid_rmse: 0.42705 | valid_mse: 0.18237 |  0:00:24s\n",
      "epoch 15 | loss: 0.14507 | train_rmsle: 0.00864 | train_mae: 0.2825  | train_rmse: 0.36676 | train_mse: 0.13451 | valid_rmsle: 0.00781 | valid_mae: 0.26837 | valid_rmse: 0.35135 | valid_mse: 0.12345 |  0:00:26s\n",
      "epoch 16 | loss: 0.11577 | train_rmsle: 0.00814 | train_mae: 0.27811 | train_rmse: 0.35729 | train_mse: 0.12766 | valid_rmsle: 0.00718 | valid_mae: 0.26567 | valid_rmse: 0.34045 | valid_mse: 0.1159  |  0:00:28s\n",
      "epoch 17 | loss: 0.10805 | train_rmsle: 0.0082  | train_mae: 0.27546 | train_rmse: 0.35632 | train_mse: 0.12697 | valid_rmsle: 0.00732 | valid_mae: 0.26376 | valid_rmse: 0.34022 | valid_mse: 0.11575 |  0:00:29s\n",
      "epoch 18 | loss: 0.10404 | train_rmsle: 0.00727 | train_mae: 0.26162 | train_rmse: 0.33579 | train_mse: 0.11276 | valid_rmsle: 0.00657 | valid_mae: 0.25145 | valid_rmse: 0.32322 | valid_mse: 0.10447 |  0:00:31s\n",
      "epoch 19 | loss: 0.10303 | train_rmsle: 0.00699 | train_mae: 0.25356 | train_rmse: 0.32873 | train_mse: 0.10806 | valid_rmsle: 0.0064  | valid_mae: 0.2455  | valid_rmse: 0.31915 | valid_mse: 0.10186 |  0:00:33s\n",
      "epoch 20 | loss: 0.10132 | train_rmsle: 0.00708 | train_mae: 0.25765 | train_rmse: 0.33127 | train_mse: 0.10974 | valid_rmsle: 0.00643 | valid_mae: 0.2477  | valid_rmse: 0.31942 | valid_mse: 0.10203 |  0:00:35s\n",
      "epoch 21 | loss: 0.09961 | train_rmsle: 0.0068  | train_mae: 0.2477  | train_rmse: 0.32173 | train_mse: 0.10351 | valid_rmsle: 0.00609 | valid_mae: 0.23682 | valid_rmse: 0.30865 | valid_mse: 0.09527 |  0:00:36s\n",
      "epoch 22 | loss: 0.09836 | train_rmsle: 0.00683 | train_mae: 0.25244 | train_rmse: 0.32395 | train_mse: 0.10494 | valid_rmsle: 0.00613 | valid_mae: 0.23948 | valid_rmse: 0.31067 | valid_mse: 0.09652 |  0:00:37s\n",
      "epoch 23 | loss: 0.0967  | train_rmsle: 0.00684 | train_mae: 0.25441 | train_rmse: 0.32485 | train_mse: 0.10553 | valid_rmsle: 0.00625 | valid_mae: 0.24444 | valid_rmse: 0.31394 | valid_mse: 0.09856 |  0:00:39s\n",
      "epoch 24 | loss: 0.09739 | train_rmsle: 0.0065  | train_mae: 0.23875 | train_rmse: 0.31252 | train_mse: 0.09767 | valid_rmsle: 0.00604 | valid_mae: 0.2333  | valid_rmse: 0.30511 | valid_mse: 0.09309 |  0:00:40s\n",
      "epoch 25 | loss: 0.097   | train_rmsle: 0.00649 | train_mae: 0.2401  | train_rmse: 0.31341 | train_mse: 0.09823 | valid_rmsle: 0.006   | valid_mae: 0.23332 | valid_rmse: 0.3055  | valid_mse: 0.09333 |  0:00:41s\n",
      "epoch 26 | loss: 0.09711 | train_rmsle: 0.00654 | train_mae: 0.23851 | train_rmse: 0.31419 | train_mse: 0.09872 | valid_rmsle: 0.00614 | valid_mae: 0.23477 | valid_rmse: 0.30864 | valid_mse: 0.09526 |  0:00:43s\n",
      "epoch 27 | loss: 0.09769 | train_rmsle: 0.00649 | train_mae: 0.24036 | train_rmse: 0.31364 | train_mse: 0.09837 | valid_rmsle: 0.0061  | valid_mae: 0.23498 | valid_rmse: 0.30801 | valid_mse: 0.09487 |  0:00:44s\n",
      "epoch 28 | loss: 0.09658 | train_rmsle: 0.00632 | train_mae: 0.23715 | train_rmse: 0.30862 | train_mse: 0.09525 | valid_rmsle: 0.00588 | valid_mae: 0.23172 | valid_rmse: 0.30155 | valid_mse: 0.09093 |  0:00:45s\n",
      "epoch 29 | loss: 0.09554 | train_rmsle: 0.00629 | train_mae: 0.23645 | train_rmse: 0.3086  | train_mse: 0.09523 | valid_rmsle: 0.00603 | valid_mae: 0.23364 | valid_rmse: 0.30571 | valid_mse: 0.09346 |  0:00:47s\n",
      "epoch 30 | loss: 0.09451 | train_rmsle: 0.00624 | train_mae: 0.23352 | train_rmse: 0.30581 | train_mse: 0.09352 | valid_rmsle: 0.00608 | valid_mae: 0.23156 | valid_rmse: 0.30505 | valid_mse: 0.09305 |  0:00:48s\n",
      "epoch 31 | loss: 0.09449 | train_rmsle: 0.00631 | train_mae: 0.23199 | train_rmse: 0.30698 | train_mse: 0.09424 | valid_rmsle: 0.00631 | valid_mae: 0.23463 | valid_rmse: 0.3116  | valid_mse: 0.0971  |  0:00:50s\n",
      "epoch 32 | loss: 0.09528 | train_rmsle: 0.00616 | train_mae: 0.23296 | train_rmse: 0.30489 | train_mse: 0.09296 | valid_rmsle: 0.00613 | valid_mae: 0.23383 | valid_rmse: 0.30823 | valid_mse: 0.09501 |  0:00:52s\n",
      "epoch 33 | loss: 0.09378 | train_rmsle: 0.00611 | train_mae: 0.2334  | train_rmse: 0.30417 | train_mse: 0.09252 | valid_rmsle: 0.00617 | valid_mae: 0.23678 | valid_rmse: 0.3095  | valid_mse: 0.09579 |  0:00:53s\n",
      "epoch 34 | loss: 0.09223 | train_rmsle: 0.00612 | train_mae: 0.22991 | train_rmse: 0.30191 | train_mse: 0.09115 | valid_rmsle: 0.0061  | valid_mae: 0.23335 | valid_rmse: 0.30628 | valid_mse: 0.09381 |  0:00:55s\n",
      "epoch 35 | loss: 0.0918  | train_rmsle: 0.00595 | train_mae: 0.23068 | train_rmse: 0.3002  | train_mse: 0.09012 | valid_rmsle: 0.00607 | valid_mae: 0.23553 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:00:57s\n",
      "epoch 36 | loss: 0.09108 | train_rmsle: 0.00588 | train_mae: 0.22792 | train_rmse: 0.29797 | train_mse: 0.08879 | valid_rmsle: 0.00605 | valid_mae: 0.23437 | valid_rmse: 0.30704 | valid_mse: 0.09428 |  0:00:58s\n",
      "epoch 37 | loss: 0.0901  | train_rmsle: 0.00587 | train_mae: 0.23061 | train_rmse: 0.29881 | train_mse: 0.08929 | valid_rmsle: 0.00622 | valid_mae: 0.23892 | valid_rmse: 0.31142 | valid_mse: 0.09698 |  0:01:00s\n",
      "epoch 38 | loss: 0.09084 | train_rmsle: 0.00579 | train_mae: 0.22849 | train_rmse: 0.29668 | train_mse: 0.08802 | valid_rmsle: 0.00631 | valid_mae: 0.23993 | valid_rmse: 0.31377 | valid_mse: 0.09845 |  0:01:01s\n",
      "epoch 39 | loss: 0.08889 | train_rmsle: 0.00575 | train_mae: 0.22583 | train_rmse: 0.29466 | train_mse: 0.08682 | valid_rmsle: 0.00617 | valid_mae: 0.23538 | valid_rmse: 0.30936 | valid_mse: 0.0957  |  0:01:03s\n",
      "epoch 40 | loss: 0.09098 | train_rmsle: 0.00567 | train_mae: 0.2252  | train_rmse: 0.29277 | train_mse: 0.08572 | valid_rmsle: 0.00638 | valid_mae: 0.24243 | valid_rmse: 0.31586 | valid_mse: 0.09977 |  0:01:04s\n",
      "epoch 41 | loss: 0.08761 | train_rmsle: 0.00569 | train_mae: 0.22853 | train_rmse: 0.29448 | train_mse: 0.08672 | valid_rmsle: 0.0065  | valid_mae: 0.24919 | valid_rmse: 0.31996 | valid_mse: 0.10238 |  0:01:06s\n",
      "epoch 42 | loss: 0.08842 | train_rmsle: 0.00559 | train_mae: 0.22193 | train_rmse: 0.2902  | train_mse: 0.08421 | valid_rmsle: 0.00646 | valid_mae: 0.24559 | valid_rmse: 0.31771 | valid_mse: 0.10094 |  0:01:07s\n",
      "epoch 43 | loss: 0.08717 | train_rmsle: 0.00567 | train_mae: 0.22283 | train_rmse: 0.29137 | train_mse: 0.0849  | valid_rmsle: 0.0065  | valid_mae: 0.24491 | valid_rmse: 0.31856 | valid_mse: 0.10148 |  0:01:08s\n",
      "epoch 44 | loss: 0.08697 | train_rmsle: 0.00539 | train_mae: 0.21754 | train_rmse: 0.28524 | train_mse: 0.08136 | valid_rmsle: 0.00651 | valid_mae: 0.24314 | valid_rmse: 0.31975 | valid_mse: 0.10224 |  0:01:10s\n",
      "epoch 45 | loss: 0.08592 | train_rmsle: 0.00545 | train_mae: 0.21656 | train_rmse: 0.28538 | train_mse: 0.08144 | valid_rmsle: 0.00657 | valid_mae: 0.2471  | valid_rmse: 0.32094 | valid_mse: 0.103   |  0:01:12s\n",
      "epoch 46 | loss: 0.08374 | train_rmsle: 0.00551 | train_mae: 0.21385 | train_rmse: 0.28555 | train_mse: 0.08154 | valid_rmsle: 0.00668 | valid_mae: 0.24377 | valid_rmse: 0.32246 | valid_mse: 0.10398 |  0:01:13s\n",
      "epoch 47 | loss: 0.08609 | train_rmsle: 0.00532 | train_mae: 0.2116  | train_rmse: 0.28113 | train_mse: 0.07903 | valid_rmsle: 0.00665 | valid_mae: 0.24337 | valid_rmse: 0.32118 | valid_mse: 0.10316 |  0:01:15s\n",
      "epoch 48 | loss: 0.08469 | train_rmsle: 0.00527 | train_mae: 0.21053 | train_rmse: 0.27972 | train_mse: 0.07824 | valid_rmsle: 0.00666 | valid_mae: 0.24246 | valid_rmse: 0.32169 | valid_mse: 0.10348 |  0:01:17s\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_valid_mse = 0.09093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10023314423349099 RMSE: 0.3165961848056464 R2: 0.5563064921706122 MAE: 0.242297519581371\n",
      "=====================================\n",
      "[45/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.6166  | train_rmsle: 0.46568 | train_mae: 2.10375 | train_rmse: 2.15906 | train_mse: 4.66153 | valid_rmsle: 0.46767 | valid_mae: 2.11069 | valid_rmse: 2.16455 | valid_mse: 4.68526 |  0:00:01s\n",
      "epoch 1  | loss: 1.93206 | train_rmsle: 0.14751 | train_mae: 1.33116 | train_rmse: 1.411   | train_mse: 1.99091 | valid_rmsle: 0.14824 | valid_mae: 1.33505 | valid_rmse: 1.41545 | valid_mse: 2.00351 |  0:00:03s\n",
      "epoch 2  | loss: 0.78889 | train_rmsle: 0.04252 | train_mae: 0.74314 | train_rmse: 0.83614 | train_mse: 0.69913 | valid_rmsle: 0.04254 | valid_mae: 0.74324 | valid_rmse: 0.83872 | valid_mse: 0.70344 |  0:00:05s\n",
      "epoch 3  | loss: 0.47918 | train_rmsle: 0.02946 | train_mae: 0.61561 | train_rmse: 0.70711 | train_mse: 0.5     | valid_rmsle: 0.02931 | valid_mae: 0.61563 | valid_rmse: 0.70863 | valid_mse: 0.50216 |  0:00:06s\n",
      "epoch 4  | loss: 0.35437 | train_rmsle: 0.02388 | train_mae: 0.54955 | train_rmse: 0.63939 | train_mse: 0.40882 | valid_rmsle: 0.02366 | valid_mae: 0.55062 | valid_rmse: 0.64025 | valid_mse: 0.40992 |  0:00:08s\n",
      "epoch 5  | loss: 0.30807 | train_rmsle: 0.0205  | train_mae: 0.50396 | train_rmse: 0.5922  | train_mse: 0.3507  | valid_rmsle: 0.0202  | valid_mae: 0.5051  | valid_rmse: 0.59219 | valid_mse: 0.35069 |  0:00:10s\n",
      "epoch 6  | loss: 0.27652 | train_rmsle: 0.02214 | train_mae: 0.52683 | train_rmse: 0.61576 | train_mse: 0.37916 | valid_rmsle: 0.02187 | valid_mae: 0.52799 | valid_rmse: 0.61613 | valid_mse: 0.37962 |  0:00:11s\n",
      "epoch 7  | loss: 0.25906 | train_rmsle: 0.02013 | train_mae: 0.4984  | train_rmse: 0.58659 | train_mse: 0.34409 | valid_rmsle: 0.01982 | valid_mae: 0.49958 | valid_rmse: 0.58652 | valid_mse: 0.344   |  0:00:13s\n",
      "epoch 8  | loss: 0.24257 | train_rmsle: 0.01783 | train_mae: 0.46198 | train_rmse: 0.54974 | train_mse: 0.30222 | valid_rmsle: 0.01746 | valid_mae: 0.46344 | valid_rmse: 0.54875 | valid_mse: 0.30112 |  0:00:15s\n",
      "epoch 9  | loss: 0.24001 | train_rmsle: 0.01756 | train_mae: 0.45777 | train_rmse: 0.5453  | train_mse: 0.29735 | valid_rmsle: 0.0172  | valid_mae: 0.45943 | valid_rmse: 0.54454 | valid_mse: 0.29652 |  0:00:16s\n",
      "epoch 10 | loss: 0.2292  | train_rmsle: 0.0162  | train_mae: 0.43828 | train_rmse: 0.52247 | train_mse: 0.27298 | valid_rmsle: 0.01565 | valid_mae: 0.43579 | valid_rmse: 0.51879 | valid_mse: 0.26914 |  0:00:18s\n",
      "epoch 11 | loss: 0.20653 | train_rmsle: 0.01374 | train_mae: 0.39461 | train_rmse: 0.47765 | train_mse: 0.22815 | valid_rmsle: 0.01319 | valid_mae: 0.39056 | valid_rmse: 0.47346 | valid_mse: 0.22417 |  0:00:20s\n",
      "epoch 12 | loss: 0.16895 | train_rmsle: 0.01064 | train_mae: 0.33186 | train_rmse: 0.41398 | train_mse: 0.17138 | valid_rmsle: 0.01001 | valid_mae: 0.32508 | valid_rmse: 0.40626 | valid_mse: 0.16504 |  0:00:21s\n",
      "epoch 13 | loss: 0.15161 | train_rmsle: 0.00939 | train_mae: 0.30654 | train_rmse: 0.38637 | train_mse: 0.14928 | valid_rmsle: 0.00886 | valid_mae: 0.30253 | valid_rmse: 0.38027 | valid_mse: 0.14461 |  0:00:22s\n",
      "epoch 14 | loss: 0.13899 | train_rmsle: 0.00861 | train_mae: 0.29152 | train_rmse: 0.36834 | train_mse: 0.13568 | valid_rmsle: 0.00777 | valid_mae: 0.27801 | valid_rmse: 0.35392 | valid_mse: 0.12526 |  0:00:24s\n",
      "epoch 15 | loss: 0.13145 | train_rmsle: 0.00753 | train_mae: 0.26743 | train_rmse: 0.34259 | train_mse: 0.11737 | valid_rmsle: 0.00679 | valid_mae: 0.25536 | valid_rmse: 0.33028 | valid_mse: 0.10909 |  0:00:25s\n",
      "epoch 16 | loss: 0.12929 | train_rmsle: 0.00816 | train_mae: 0.27955 | train_rmse: 0.35666 | train_mse: 0.1272  | valid_rmsle: 0.0073  | valid_mae: 0.26536 | valid_rmse: 0.34132 | valid_mse: 0.1165  |  0:00:26s\n",
      "epoch 17 | loss: 0.12206 | train_rmsle: 0.00723 | train_mae: 0.26175 | train_rmse: 0.33608 | train_mse: 0.11295 | valid_rmsle: 0.00663 | valid_mae: 0.25252 | valid_rmse: 0.32697 | valid_mse: 0.10691 |  0:00:28s\n",
      "epoch 18 | loss: 0.12076 | train_rmsle: 0.0067  | train_mae: 0.24937 | train_rmse: 0.32159 | train_mse: 0.10342 | valid_rmsle: 0.00615 | valid_mae: 0.23925 | valid_rmse: 0.31236 | valid_mse: 0.09757 |  0:00:29s\n",
      "epoch 19 | loss: 0.11354 | train_rmsle: 0.00659 | train_mae: 0.2502  | train_rmse: 0.32064 | train_mse: 0.10281 | valid_rmsle: 0.00618 | valid_mae: 0.24184 | valid_rmse: 0.3143  | valid_mse: 0.09878 |  0:00:31s\n",
      "epoch 20 | loss: 0.11027 | train_rmsle: 0.00626 | train_mae: 0.2403  | train_rmse: 0.31087 | train_mse: 0.09664 | valid_rmsle: 0.00584 | valid_mae: 0.23371 | valid_rmse: 0.3037  | valid_mse: 0.09223 |  0:00:32s\n",
      "epoch 21 | loss: 0.10861 | train_rmsle: 0.00618 | train_mae: 0.24156 | train_rmse: 0.30988 | train_mse: 0.09602 | valid_rmsle: 0.0057  | valid_mae: 0.23328 | valid_rmse: 0.30081 | valid_mse: 0.09049 |  0:00:33s\n",
      "epoch 22 | loss: 0.10656 | train_rmsle: 0.00602 | train_mae: 0.23524 | train_rmse: 0.30408 | train_mse: 0.09247 | valid_rmsle: 0.00554 | valid_mae: 0.22786 | valid_rmse: 0.29456 | valid_mse: 0.08677 |  0:00:35s\n",
      "epoch 23 | loss: 0.10628 | train_rmsle: 0.0063  | train_mae: 0.25099 | train_rmse: 0.31641 | train_mse: 0.10011 | valid_rmsle: 0.00579 | valid_mae: 0.24322 | valid_rmse: 0.30627 | valid_mse: 0.0938  |  0:00:36s\n",
      "epoch 24 | loss: 0.10802 | train_rmsle: 0.00595 | train_mae: 0.23531 | train_rmse: 0.30388 | train_mse: 0.09234 | valid_rmsle: 0.00549 | valid_mae: 0.22888 | valid_rmse: 0.29494 | valid_mse: 0.08699 |  0:00:38s\n",
      "epoch 25 | loss: 0.09887 | train_rmsle: 0.00595 | train_mae: 0.2378  | train_rmse: 0.30534 | train_mse: 0.09323 | valid_rmsle: 0.00555 | valid_mae: 0.23264 | valid_rmse: 0.29768 | valid_mse: 0.08861 |  0:00:39s\n",
      "epoch 26 | loss: 0.09713 | train_rmsle: 0.00604 | train_mae: 0.23956 | train_rmse: 0.30751 | train_mse: 0.09456 | valid_rmsle: 0.00568 | valid_mae: 0.23363 | valid_rmse: 0.30107 | valid_mse: 0.09064 |  0:00:41s\n",
      "epoch 27 | loss: 0.0947  | train_rmsle: 0.00589 | train_mae: 0.23533 | train_rmse: 0.30328 | train_mse: 0.09198 | valid_rmsle: 0.00558 | valid_mae: 0.23023 | valid_rmse: 0.29842 | valid_mse: 0.08905 |  0:00:42s\n",
      "epoch 28 | loss: 0.09302 | train_rmsle: 0.00584 | train_mae: 0.23277 | train_rmse: 0.30164 | train_mse: 0.09099 | valid_rmsle: 0.0057  | valid_mae: 0.23154 | valid_rmse: 0.30127 | valid_mse: 0.09076 |  0:00:44s\n",
      "epoch 29 | loss: 0.09435 | train_rmsle: 0.00583 | train_mae: 0.23056 | train_rmse: 0.30044 | train_mse: 0.09026 | valid_rmsle: 0.00576 | valid_mae: 0.23347 | valid_rmse: 0.3025  | valid_mse: 0.09151 |  0:00:45s\n",
      "epoch 30 | loss: 0.09223 | train_rmsle: 0.00561 | train_mae: 0.22741 | train_rmse: 0.29465 | train_mse: 0.08682 | valid_rmsle: 0.00563 | valid_mae: 0.22901 | valid_rmse: 0.29877 | valid_mse: 0.08926 |  0:00:47s\n",
      "epoch 31 | loss: 0.08931 | train_rmsle: 0.00566 | train_mae: 0.22755 | train_rmse: 0.29526 | train_mse: 0.08718 | valid_rmsle: 0.00565 | valid_mae: 0.22696 | valid_rmse: 0.29825 | valid_mse: 0.08895 |  0:00:49s\n",
      "epoch 32 | loss: 0.09195 | train_rmsle: 0.00549 | train_mae: 0.22762 | train_rmse: 0.29285 | train_mse: 0.08576 | valid_rmsle: 0.00571 | valid_mae: 0.23085 | valid_rmse: 0.3014  | valid_mse: 0.09084 |  0:00:50s\n",
      "epoch 33 | loss: 0.08835 | train_rmsle: 0.00549 | train_mae: 0.22602 | train_rmse: 0.29222 | train_mse: 0.08539 | valid_rmsle: 0.00577 | valid_mae: 0.23078 | valid_rmse: 0.303   | valid_mse: 0.09181 |  0:00:52s\n",
      "epoch 34 | loss: 0.08626 | train_rmsle: 0.00544 | train_mae: 0.22942 | train_rmse: 0.293   | train_mse: 0.08585 | valid_rmsle: 0.00602 | valid_mae: 0.24126 | valid_rmse: 0.31146 | valid_mse: 0.09701 |  0:00:54s\n",
      "epoch 35 | loss: 0.08508 | train_rmsle: 0.00517 | train_mae: 0.21652 | train_rmse: 0.28184 | train_mse: 0.07943 | valid_rmsle: 0.00576 | valid_mae: 0.23073 | valid_rmse: 0.30152 | valid_mse: 0.09092 |  0:00:55s\n",
      "epoch 36 | loss: 0.08394 | train_rmsle: 0.00489 | train_mae: 0.21145 | train_rmse: 0.27577 | train_mse: 0.07605 | valid_rmsle: 0.00568 | valid_mae: 0.22945 | valid_rmse: 0.30074 | valid_mse: 0.09044 |  0:00:57s\n",
      "epoch 37 | loss: 0.08291 | train_rmsle: 0.00482 | train_mae: 0.20831 | train_rmse: 0.27226 | train_mse: 0.07413 | valid_rmsle: 0.00561 | valid_mae: 0.2269  | valid_rmse: 0.29839 | valid_mse: 0.08903 |  0:00:59s\n",
      "epoch 38 | loss: 0.07962 | train_rmsle: 0.00499 | train_mae: 0.21038 | train_rmse: 0.27531 | train_mse: 0.0758  | valid_rmsle: 0.00587 | valid_mae: 0.2306  | valid_rmse: 0.30412 | valid_mse: 0.09249 |  0:01:00s\n",
      "epoch 39 | loss: 0.07795 | train_rmsle: 0.00465 | train_mae: 0.20517 | train_rmse: 0.26797 | train_mse: 0.07181 | valid_rmsle: 0.00585 | valid_mae: 0.22948 | valid_rmse: 0.30441 | valid_mse: 0.09267 |  0:01:02s\n",
      "epoch 40 | loss: 0.0802  | train_rmsle: 0.00464 | train_mae: 0.2019  | train_rmse: 0.26606 | train_mse: 0.07079 | valid_rmsle: 0.00566 | valid_mae: 0.22684 | valid_rmse: 0.29916 | valid_mse: 0.0895  |  0:01:04s\n",
      "epoch 41 | loss: 0.0769  | train_rmsle: 0.00477 | train_mae: 0.20987 | train_rmse: 0.27264 | train_mse: 0.07433 | valid_rmsle: 0.00571 | valid_mae: 0.23192 | valid_rmse: 0.30209 | valid_mse: 0.09126 |  0:01:05s\n",
      "epoch 42 | loss: 0.07549 | train_rmsle: 0.00474 | train_mae: 0.21485 | train_rmse: 0.27527 | train_mse: 0.07577 | valid_rmsle: 0.00602 | valid_mae: 0.24256 | valid_rmse: 0.31177 | valid_mse: 0.0972  |  0:01:07s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.08677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09542888893565864 RMSE: 0.30891566638106693 R2: 0.5775730792053121 MAE: 0.23847859812361852\n",
      "=====================================\n",
      "[46/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.6166  | train_rmsle: 0.46568 | train_mae: 2.10375 | train_rmse: 2.15906 | train_mse: 4.66153 | valid_rmsle: 0.46767 | valid_mae: 2.11069 | valid_rmse: 2.16455 | valid_mse: 4.68526 |  0:00:01s\n",
      "epoch 1  | loss: 1.93206 | train_rmsle: 0.14751 | train_mae: 1.33116 | train_rmse: 1.411   | train_mse: 1.99091 | valid_rmsle: 0.14824 | valid_mae: 1.33505 | valid_rmse: 1.41545 | valid_mse: 2.00351 |  0:00:03s\n",
      "epoch 2  | loss: 0.78889 | train_rmsle: 0.04252 | train_mae: 0.74314 | train_rmse: 0.83614 | train_mse: 0.69913 | valid_rmsle: 0.04254 | valid_mae: 0.74324 | valid_rmse: 0.83872 | valid_mse: 0.70344 |  0:00:05s\n",
      "epoch 3  | loss: 0.47918 | train_rmsle: 0.02946 | train_mae: 0.61561 | train_rmse: 0.70711 | train_mse: 0.5     | valid_rmsle: 0.02931 | valid_mae: 0.61563 | valid_rmse: 0.70863 | valid_mse: 0.50216 |  0:00:06s\n",
      "epoch 4  | loss: 0.35437 | train_rmsle: 0.02388 | train_mae: 0.54955 | train_rmse: 0.63939 | train_mse: 0.40882 | valid_rmsle: 0.02366 | valid_mae: 0.55062 | valid_rmse: 0.64025 | valid_mse: 0.40992 |  0:00:08s\n",
      "epoch 5  | loss: 0.30807 | train_rmsle: 0.0205  | train_mae: 0.50396 | train_rmse: 0.5922  | train_mse: 0.3507  | valid_rmsle: 0.0202  | valid_mae: 0.5051  | valid_rmse: 0.59219 | valid_mse: 0.35069 |  0:00:10s\n",
      "epoch 6  | loss: 0.27652 | train_rmsle: 0.02214 | train_mae: 0.52683 | train_rmse: 0.61576 | train_mse: 0.37916 | valid_rmsle: 0.02187 | valid_mae: 0.52799 | valid_rmse: 0.61613 | valid_mse: 0.37962 |  0:00:11s\n",
      "epoch 7  | loss: 0.25906 | train_rmsle: 0.02013 | train_mae: 0.4984  | train_rmse: 0.58659 | train_mse: 0.34409 | valid_rmsle: 0.01982 | valid_mae: 0.49958 | valid_rmse: 0.58652 | valid_mse: 0.344   |  0:00:13s\n",
      "epoch 8  | loss: 0.24257 | train_rmsle: 0.01783 | train_mae: 0.46198 | train_rmse: 0.54974 | train_mse: 0.30222 | valid_rmsle: 0.01746 | valid_mae: 0.46344 | valid_rmse: 0.54875 | valid_mse: 0.30112 |  0:00:14s\n",
      "epoch 9  | loss: 0.24001 | train_rmsle: 0.01756 | train_mae: 0.45777 | train_rmse: 0.5453  | train_mse: 0.29735 | valid_rmsle: 0.0172  | valid_mae: 0.45943 | valid_rmse: 0.54454 | valid_mse: 0.29652 |  0:00:16s\n",
      "epoch 10 | loss: 0.2292  | train_rmsle: 0.0162  | train_mae: 0.43828 | train_rmse: 0.52247 | train_mse: 0.27298 | valid_rmsle: 0.01565 | valid_mae: 0.43579 | valid_rmse: 0.51879 | valid_mse: 0.26914 |  0:00:17s\n",
      "epoch 11 | loss: 0.20653 | train_rmsle: 0.01374 | train_mae: 0.39461 | train_rmse: 0.47765 | train_mse: 0.22815 | valid_rmsle: 0.01319 | valid_mae: 0.39056 | valid_rmse: 0.47346 | valid_mse: 0.22417 |  0:00:18s\n",
      "epoch 12 | loss: 0.16895 | train_rmsle: 0.01064 | train_mae: 0.33186 | train_rmse: 0.41398 | train_mse: 0.17138 | valid_rmsle: 0.01001 | valid_mae: 0.32508 | valid_rmse: 0.40626 | valid_mse: 0.16504 |  0:00:20s\n",
      "epoch 13 | loss: 0.15161 | train_rmsle: 0.00939 | train_mae: 0.30654 | train_rmse: 0.38637 | train_mse: 0.14928 | valid_rmsle: 0.00886 | valid_mae: 0.30253 | valid_rmse: 0.38027 | valid_mse: 0.14461 |  0:00:21s\n",
      "epoch 14 | loss: 0.13899 | train_rmsle: 0.00861 | train_mae: 0.29152 | train_rmse: 0.36834 | train_mse: 0.13568 | valid_rmsle: 0.00777 | valid_mae: 0.27801 | valid_rmse: 0.35392 | valid_mse: 0.12526 |  0:00:22s\n",
      "epoch 15 | loss: 0.13145 | train_rmsle: 0.00753 | train_mae: 0.26743 | train_rmse: 0.34259 | train_mse: 0.11737 | valid_rmsle: 0.00679 | valid_mae: 0.25536 | valid_rmse: 0.33028 | valid_mse: 0.10909 |  0:00:23s\n",
      "epoch 16 | loss: 0.12929 | train_rmsle: 0.00816 | train_mae: 0.27955 | train_rmse: 0.35666 | train_mse: 0.1272  | valid_rmsle: 0.0073  | valid_mae: 0.26536 | valid_rmse: 0.34132 | valid_mse: 0.1165  |  0:00:25s\n",
      "epoch 17 | loss: 0.12206 | train_rmsle: 0.00723 | train_mae: 0.26175 | train_rmse: 0.33608 | train_mse: 0.11295 | valid_rmsle: 0.00663 | valid_mae: 0.25252 | valid_rmse: 0.32697 | valid_mse: 0.10691 |  0:00:26s\n",
      "epoch 18 | loss: 0.12076 | train_rmsle: 0.0067  | train_mae: 0.24937 | train_rmse: 0.32159 | train_mse: 0.10342 | valid_rmsle: 0.00615 | valid_mae: 0.23925 | valid_rmse: 0.31236 | valid_mse: 0.09757 |  0:00:27s\n",
      "epoch 19 | loss: 0.11354 | train_rmsle: 0.00659 | train_mae: 0.2502  | train_rmse: 0.32064 | train_mse: 0.10281 | valid_rmsle: 0.00618 | valid_mae: 0.24184 | valid_rmse: 0.3143  | valid_mse: 0.09878 |  0:00:29s\n",
      "epoch 20 | loss: 0.11027 | train_rmsle: 0.00626 | train_mae: 0.2403  | train_rmse: 0.31087 | train_mse: 0.09664 | valid_rmsle: 0.00584 | valid_mae: 0.23371 | valid_rmse: 0.3037  | valid_mse: 0.09223 |  0:00:31s\n",
      "epoch 21 | loss: 0.10861 | train_rmsle: 0.00618 | train_mae: 0.24156 | train_rmse: 0.30988 | train_mse: 0.09602 | valid_rmsle: 0.0057  | valid_mae: 0.23328 | valid_rmse: 0.30081 | valid_mse: 0.09049 |  0:00:32s\n",
      "epoch 22 | loss: 0.10656 | train_rmsle: 0.00602 | train_mae: 0.23524 | train_rmse: 0.30408 | train_mse: 0.09247 | valid_rmsle: 0.00554 | valid_mae: 0.22786 | valid_rmse: 0.29456 | valid_mse: 0.08677 |  0:00:34s\n",
      "epoch 23 | loss: 0.10628 | train_rmsle: 0.0063  | train_mae: 0.25099 | train_rmse: 0.31641 | train_mse: 0.10011 | valid_rmsle: 0.00579 | valid_mae: 0.24322 | valid_rmse: 0.30627 | valid_mse: 0.0938  |  0:00:36s\n",
      "epoch 24 | loss: 0.10802 | train_rmsle: 0.00595 | train_mae: 0.23531 | train_rmse: 0.30388 | train_mse: 0.09234 | valid_rmsle: 0.00549 | valid_mae: 0.22888 | valid_rmse: 0.29494 | valid_mse: 0.08699 |  0:00:37s\n",
      "epoch 25 | loss: 0.09887 | train_rmsle: 0.00595 | train_mae: 0.2378  | train_rmse: 0.30534 | train_mse: 0.09323 | valid_rmsle: 0.00555 | valid_mae: 0.23264 | valid_rmse: 0.29768 | valid_mse: 0.08861 |  0:00:39s\n",
      "epoch 26 | loss: 0.09713 | train_rmsle: 0.00604 | train_mae: 0.23956 | train_rmse: 0.30751 | train_mse: 0.09456 | valid_rmsle: 0.00568 | valid_mae: 0.23363 | valid_rmse: 0.30107 | valid_mse: 0.09064 |  0:00:40s\n",
      "epoch 27 | loss: 0.0947  | train_rmsle: 0.00589 | train_mae: 0.23533 | train_rmse: 0.30328 | train_mse: 0.09198 | valid_rmsle: 0.00558 | valid_mae: 0.23023 | valid_rmse: 0.29842 | valid_mse: 0.08905 |  0:00:42s\n",
      "epoch 28 | loss: 0.09302 | train_rmsle: 0.00584 | train_mae: 0.23277 | train_rmse: 0.30164 | train_mse: 0.09099 | valid_rmsle: 0.0057  | valid_mae: 0.23154 | valid_rmse: 0.30127 | valid_mse: 0.09076 |  0:00:44s\n",
      "epoch 29 | loss: 0.09435 | train_rmsle: 0.00583 | train_mae: 0.23056 | train_rmse: 0.30044 | train_mse: 0.09026 | valid_rmsle: 0.00576 | valid_mae: 0.23347 | valid_rmse: 0.3025  | valid_mse: 0.09151 |  0:00:45s\n",
      "epoch 30 | loss: 0.09223 | train_rmsle: 0.00561 | train_mae: 0.22741 | train_rmse: 0.29465 | train_mse: 0.08682 | valid_rmsle: 0.00563 | valid_mae: 0.22901 | valid_rmse: 0.29877 | valid_mse: 0.08926 |  0:00:47s\n",
      "epoch 31 | loss: 0.08931 | train_rmsle: 0.00566 | train_mae: 0.22755 | train_rmse: 0.29526 | train_mse: 0.08718 | valid_rmsle: 0.00565 | valid_mae: 0.22696 | valid_rmse: 0.29825 | valid_mse: 0.08895 |  0:00:49s\n",
      "epoch 32 | loss: 0.09195 | train_rmsle: 0.00549 | train_mae: 0.22762 | train_rmse: 0.29285 | train_mse: 0.08576 | valid_rmsle: 0.00571 | valid_mae: 0.23085 | valid_rmse: 0.3014  | valid_mse: 0.09084 |  0:00:51s\n",
      "epoch 33 | loss: 0.08835 | train_rmsle: 0.00549 | train_mae: 0.22602 | train_rmse: 0.29222 | train_mse: 0.08539 | valid_rmsle: 0.00577 | valid_mae: 0.23078 | valid_rmse: 0.303   | valid_mse: 0.09181 |  0:00:52s\n",
      "epoch 34 | loss: 0.08626 | train_rmsle: 0.00544 | train_mae: 0.22942 | train_rmse: 0.293   | train_mse: 0.08585 | valid_rmsle: 0.00602 | valid_mae: 0.24126 | valid_rmse: 0.31146 | valid_mse: 0.09701 |  0:00:54s\n",
      "epoch 35 | loss: 0.08508 | train_rmsle: 0.00517 | train_mae: 0.21652 | train_rmse: 0.28184 | train_mse: 0.07943 | valid_rmsle: 0.00576 | valid_mae: 0.23073 | valid_rmse: 0.30152 | valid_mse: 0.09092 |  0:00:55s\n",
      "epoch 36 | loss: 0.08394 | train_rmsle: 0.00489 | train_mae: 0.21145 | train_rmse: 0.27577 | train_mse: 0.07605 | valid_rmsle: 0.00568 | valid_mae: 0.22945 | valid_rmse: 0.30074 | valid_mse: 0.09044 |  0:00:57s\n",
      "epoch 37 | loss: 0.08291 | train_rmsle: 0.00482 | train_mae: 0.20831 | train_rmse: 0.27226 | train_mse: 0.07413 | valid_rmsle: 0.00561 | valid_mae: 0.2269  | valid_rmse: 0.29839 | valid_mse: 0.08903 |  0:00:59s\n",
      "epoch 38 | loss: 0.07962 | train_rmsle: 0.00499 | train_mae: 0.21038 | train_rmse: 0.27531 | train_mse: 0.0758  | valid_rmsle: 0.00587 | valid_mae: 0.2306  | valid_rmse: 0.30412 | valid_mse: 0.09249 |  0:01:00s\n",
      "epoch 39 | loss: 0.07795 | train_rmsle: 0.00465 | train_mae: 0.20517 | train_rmse: 0.26797 | train_mse: 0.07181 | valid_rmsle: 0.00585 | valid_mae: 0.22948 | valid_rmse: 0.30441 | valid_mse: 0.09267 |  0:01:02s\n",
      "epoch 40 | loss: 0.0802  | train_rmsle: 0.00464 | train_mae: 0.2019  | train_rmse: 0.26606 | train_mse: 0.07079 | valid_rmsle: 0.00566 | valid_mae: 0.22684 | valid_rmse: 0.29916 | valid_mse: 0.0895  |  0:01:04s\n",
      "epoch 41 | loss: 0.0769  | train_rmsle: 0.00477 | train_mae: 0.20987 | train_rmse: 0.27264 | train_mse: 0.07433 | valid_rmsle: 0.00571 | valid_mae: 0.23192 | valid_rmse: 0.30209 | valid_mse: 0.09126 |  0:01:05s\n",
      "epoch 42 | loss: 0.07549 | train_rmsle: 0.00474 | train_mae: 0.21485 | train_rmse: 0.27527 | train_mse: 0.07577 | valid_rmsle: 0.00602 | valid_mae: 0.24256 | valid_rmse: 0.31177 | valid_mse: 0.0972  |  0:01:07s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.08677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09542888893565864 RMSE: 0.30891566638106693 R2: 0.5775730792053121 MAE: 0.23847859812361852\n",
      "=====================================\n",
      "[47/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.6166  | train_rmsle: 0.46568 | train_mae: 2.10375 | train_rmse: 2.15906 | train_mse: 4.66153 | valid_rmsle: 0.46767 | valid_mae: 2.11069 | valid_rmse: 2.16455 | valid_mse: 4.68526 |  0:00:01s\n",
      "epoch 1  | loss: 1.93206 | train_rmsle: 0.14751 | train_mae: 1.33116 | train_rmse: 1.411   | train_mse: 1.99091 | valid_rmsle: 0.14824 | valid_mae: 1.33505 | valid_rmse: 1.41545 | valid_mse: 2.00351 |  0:00:03s\n",
      "epoch 2  | loss: 0.78889 | train_rmsle: 0.04252 | train_mae: 0.74314 | train_rmse: 0.83614 | train_mse: 0.69913 | valid_rmsle: 0.04254 | valid_mae: 0.74324 | valid_rmse: 0.83872 | valid_mse: 0.70344 |  0:00:04s\n",
      "epoch 3  | loss: 0.47918 | train_rmsle: 0.02946 | train_mae: 0.61561 | train_rmse: 0.70711 | train_mse: 0.5     | valid_rmsle: 0.02931 | valid_mae: 0.61563 | valid_rmse: 0.70863 | valid_mse: 0.50216 |  0:00:06s\n",
      "epoch 4  | loss: 0.35437 | train_rmsle: 0.02388 | train_mae: 0.54955 | train_rmse: 0.63939 | train_mse: 0.40882 | valid_rmsle: 0.02366 | valid_mae: 0.55062 | valid_rmse: 0.64025 | valid_mse: 0.40992 |  0:00:07s\n",
      "epoch 5  | loss: 0.30807 | train_rmsle: 0.0205  | train_mae: 0.50396 | train_rmse: 0.5922  | train_mse: 0.3507  | valid_rmsle: 0.0202  | valid_mae: 0.5051  | valid_rmse: 0.59219 | valid_mse: 0.35069 |  0:00:09s\n",
      "epoch 6  | loss: 0.27652 | train_rmsle: 0.02214 | train_mae: 0.52683 | train_rmse: 0.61576 | train_mse: 0.37916 | valid_rmsle: 0.02187 | valid_mae: 0.52799 | valid_rmse: 0.61613 | valid_mse: 0.37962 |  0:00:10s\n",
      "epoch 7  | loss: 0.25906 | train_rmsle: 0.02013 | train_mae: 0.4984  | train_rmse: 0.58659 | train_mse: 0.34409 | valid_rmsle: 0.01982 | valid_mae: 0.49958 | valid_rmse: 0.58652 | valid_mse: 0.344   |  0:00:12s\n",
      "epoch 8  | loss: 0.24257 | train_rmsle: 0.01783 | train_mae: 0.46198 | train_rmse: 0.54974 | train_mse: 0.30222 | valid_rmsle: 0.01746 | valid_mae: 0.46344 | valid_rmse: 0.54875 | valid_mse: 0.30112 |  0:00:13s\n",
      "epoch 9  | loss: 0.24001 | train_rmsle: 0.01756 | train_mae: 0.45777 | train_rmse: 0.5453  | train_mse: 0.29735 | valid_rmsle: 0.0172  | valid_mae: 0.45943 | valid_rmse: 0.54454 | valid_mse: 0.29652 |  0:00:15s\n",
      "epoch 10 | loss: 0.2292  | train_rmsle: 0.0162  | train_mae: 0.43828 | train_rmse: 0.52247 | train_mse: 0.27298 | valid_rmsle: 0.01565 | valid_mae: 0.43579 | valid_rmse: 0.51879 | valid_mse: 0.26914 |  0:00:16s\n",
      "epoch 11 | loss: 0.20653 | train_rmsle: 0.01374 | train_mae: 0.39461 | train_rmse: 0.47765 | train_mse: 0.22815 | valid_rmsle: 0.01319 | valid_mae: 0.39056 | valid_rmse: 0.47346 | valid_mse: 0.22417 |  0:00:17s\n",
      "epoch 12 | loss: 0.16895 | train_rmsle: 0.01064 | train_mae: 0.33186 | train_rmse: 0.41398 | train_mse: 0.17138 | valid_rmsle: 0.01001 | valid_mae: 0.32508 | valid_rmse: 0.40626 | valid_mse: 0.16504 |  0:00:19s\n",
      "epoch 13 | loss: 0.15161 | train_rmsle: 0.00939 | train_mae: 0.30654 | train_rmse: 0.38637 | train_mse: 0.14928 | valid_rmsle: 0.00886 | valid_mae: 0.30253 | valid_rmse: 0.38027 | valid_mse: 0.14461 |  0:00:20s\n",
      "epoch 14 | loss: 0.13899 | train_rmsle: 0.00861 | train_mae: 0.29152 | train_rmse: 0.36834 | train_mse: 0.13568 | valid_rmsle: 0.00777 | valid_mae: 0.27801 | valid_rmse: 0.35392 | valid_mse: 0.12526 |  0:00:22s\n",
      "epoch 15 | loss: 0.13145 | train_rmsle: 0.00753 | train_mae: 0.26743 | train_rmse: 0.34259 | train_mse: 0.11737 | valid_rmsle: 0.00679 | valid_mae: 0.25536 | valid_rmse: 0.33028 | valid_mse: 0.10909 |  0:00:23s\n",
      "epoch 16 | loss: 0.12929 | train_rmsle: 0.00816 | train_mae: 0.27955 | train_rmse: 0.35666 | train_mse: 0.1272  | valid_rmsle: 0.0073  | valid_mae: 0.26536 | valid_rmse: 0.34132 | valid_mse: 0.1165  |  0:00:24s\n",
      "epoch 17 | loss: 0.12206 | train_rmsle: 0.00723 | train_mae: 0.26175 | train_rmse: 0.33608 | train_mse: 0.11295 | valid_rmsle: 0.00663 | valid_mae: 0.25252 | valid_rmse: 0.32697 | valid_mse: 0.10691 |  0:00:26s\n",
      "epoch 18 | loss: 0.12076 | train_rmsle: 0.0067  | train_mae: 0.24937 | train_rmse: 0.32159 | train_mse: 0.10342 | valid_rmsle: 0.00615 | valid_mae: 0.23925 | valid_rmse: 0.31236 | valid_mse: 0.09757 |  0:00:27s\n",
      "epoch 19 | loss: 0.11354 | train_rmsle: 0.00659 | train_mae: 0.2502  | train_rmse: 0.32064 | train_mse: 0.10281 | valid_rmsle: 0.00618 | valid_mae: 0.24184 | valid_rmse: 0.3143  | valid_mse: 0.09878 |  0:00:28s\n",
      "epoch 20 | loss: 0.11027 | train_rmsle: 0.00626 | train_mae: 0.2403  | train_rmse: 0.31087 | train_mse: 0.09664 | valid_rmsle: 0.00584 | valid_mae: 0.23371 | valid_rmse: 0.3037  | valid_mse: 0.09223 |  0:00:30s\n",
      "epoch 21 | loss: 0.10861 | train_rmsle: 0.00618 | train_mae: 0.24156 | train_rmse: 0.30988 | train_mse: 0.09602 | valid_rmsle: 0.0057  | valid_mae: 0.23328 | valid_rmse: 0.30081 | valid_mse: 0.09049 |  0:00:32s\n",
      "epoch 22 | loss: 0.10656 | train_rmsle: 0.00602 | train_mae: 0.23524 | train_rmse: 0.30408 | train_mse: 0.09247 | valid_rmsle: 0.00554 | valid_mae: 0.22786 | valid_rmse: 0.29456 | valid_mse: 0.08677 |  0:00:33s\n",
      "epoch 23 | loss: 0.10628 | train_rmsle: 0.0063  | train_mae: 0.25099 | train_rmse: 0.31641 | train_mse: 0.10011 | valid_rmsle: 0.00579 | valid_mae: 0.24322 | valid_rmse: 0.30627 | valid_mse: 0.0938  |  0:00:35s\n",
      "epoch 24 | loss: 0.10802 | train_rmsle: 0.00595 | train_mae: 0.23531 | train_rmse: 0.30388 | train_mse: 0.09234 | valid_rmsle: 0.00549 | valid_mae: 0.22888 | valid_rmse: 0.29494 | valid_mse: 0.08699 |  0:00:37s\n",
      "epoch 25 | loss: 0.09887 | train_rmsle: 0.00595 | train_mae: 0.2378  | train_rmse: 0.30534 | train_mse: 0.09323 | valid_rmsle: 0.00555 | valid_mae: 0.23264 | valid_rmse: 0.29768 | valid_mse: 0.08861 |  0:00:38s\n",
      "epoch 26 | loss: 0.09713 | train_rmsle: 0.00604 | train_mae: 0.23956 | train_rmse: 0.30751 | train_mse: 0.09456 | valid_rmsle: 0.00568 | valid_mae: 0.23363 | valid_rmse: 0.30107 | valid_mse: 0.09064 |  0:00:40s\n",
      "epoch 27 | loss: 0.0947  | train_rmsle: 0.00589 | train_mae: 0.23533 | train_rmse: 0.30328 | train_mse: 0.09198 | valid_rmsle: 0.00558 | valid_mae: 0.23023 | valid_rmse: 0.29842 | valid_mse: 0.08905 |  0:00:42s\n",
      "epoch 28 | loss: 0.09302 | train_rmsle: 0.00584 | train_mae: 0.23277 | train_rmse: 0.30164 | train_mse: 0.09099 | valid_rmsle: 0.0057  | valid_mae: 0.23154 | valid_rmse: 0.30127 | valid_mse: 0.09076 |  0:00:43s\n",
      "epoch 29 | loss: 0.09435 | train_rmsle: 0.00583 | train_mae: 0.23056 | train_rmse: 0.30044 | train_mse: 0.09026 | valid_rmsle: 0.00576 | valid_mae: 0.23347 | valid_rmse: 0.3025  | valid_mse: 0.09151 |  0:00:45s\n",
      "epoch 30 | loss: 0.09223 | train_rmsle: 0.00561 | train_mae: 0.22741 | train_rmse: 0.29465 | train_mse: 0.08682 | valid_rmsle: 0.00563 | valid_mae: 0.22901 | valid_rmse: 0.29877 | valid_mse: 0.08926 |  0:00:47s\n",
      "epoch 31 | loss: 0.08931 | train_rmsle: 0.00566 | train_mae: 0.22755 | train_rmse: 0.29526 | train_mse: 0.08718 | valid_rmsle: 0.00565 | valid_mae: 0.22696 | valid_rmse: 0.29825 | valid_mse: 0.08895 |  0:00:49s\n",
      "epoch 32 | loss: 0.09195 | train_rmsle: 0.00549 | train_mae: 0.22762 | train_rmse: 0.29285 | train_mse: 0.08576 | valid_rmsle: 0.00571 | valid_mae: 0.23085 | valid_rmse: 0.3014  | valid_mse: 0.09084 |  0:00:50s\n",
      "epoch 33 | loss: 0.08835 | train_rmsle: 0.00549 | train_mae: 0.22602 | train_rmse: 0.29222 | train_mse: 0.08539 | valid_rmsle: 0.00577 | valid_mae: 0.23078 | valid_rmse: 0.303   | valid_mse: 0.09181 |  0:00:52s\n",
      "epoch 34 | loss: 0.08626 | train_rmsle: 0.00544 | train_mae: 0.22942 | train_rmse: 0.293   | train_mse: 0.08585 | valid_rmsle: 0.00602 | valid_mae: 0.24126 | valid_rmse: 0.31146 | valid_mse: 0.09701 |  0:00:54s\n",
      "epoch 35 | loss: 0.08508 | train_rmsle: 0.00517 | train_mae: 0.21652 | train_rmse: 0.28184 | train_mse: 0.07943 | valid_rmsle: 0.00576 | valid_mae: 0.23073 | valid_rmse: 0.30152 | valid_mse: 0.09092 |  0:00:55s\n",
      "epoch 36 | loss: 0.08394 | train_rmsle: 0.00489 | train_mae: 0.21145 | train_rmse: 0.27577 | train_mse: 0.07605 | valid_rmsle: 0.00568 | valid_mae: 0.22945 | valid_rmse: 0.30074 | valid_mse: 0.09044 |  0:00:57s\n",
      "epoch 37 | loss: 0.08291 | train_rmsle: 0.00482 | train_mae: 0.20831 | train_rmse: 0.27226 | train_mse: 0.07413 | valid_rmsle: 0.00561 | valid_mae: 0.2269  | valid_rmse: 0.29839 | valid_mse: 0.08903 |  0:00:59s\n",
      "epoch 38 | loss: 0.07962 | train_rmsle: 0.00499 | train_mae: 0.21038 | train_rmse: 0.27531 | train_mse: 0.0758  | valid_rmsle: 0.00587 | valid_mae: 0.2306  | valid_rmse: 0.30412 | valid_mse: 0.09249 |  0:01:00s\n",
      "epoch 39 | loss: 0.07795 | train_rmsle: 0.00465 | train_mae: 0.20517 | train_rmse: 0.26797 | train_mse: 0.07181 | valid_rmsle: 0.00585 | valid_mae: 0.22948 | valid_rmse: 0.30441 | valid_mse: 0.09267 |  0:01:02s\n",
      "epoch 40 | loss: 0.0802  | train_rmsle: 0.00464 | train_mae: 0.2019  | train_rmse: 0.26606 | train_mse: 0.07079 | valid_rmsle: 0.00566 | valid_mae: 0.22684 | valid_rmse: 0.29916 | valid_mse: 0.0895  |  0:01:04s\n",
      "epoch 41 | loss: 0.0769  | train_rmsle: 0.00477 | train_mae: 0.20987 | train_rmse: 0.27264 | train_mse: 0.07433 | valid_rmsle: 0.00571 | valid_mae: 0.23192 | valid_rmse: 0.30209 | valid_mse: 0.09126 |  0:01:05s\n",
      "epoch 42 | loss: 0.07549 | train_rmsle: 0.00474 | train_mae: 0.21485 | train_rmse: 0.27527 | train_mse: 0.07577 | valid_rmsle: 0.00602 | valid_mae: 0.24256 | valid_rmse: 0.31177 | valid_mse: 0.0972  |  0:01:07s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.08677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09542888893565864 RMSE: 0.30891566638106693 R2: 0.5775730792053121 MAE: 0.23847859812361852\n",
      "=====================================\n",
      "[48/108] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.6166  | train_rmsle: 0.46568 | train_mae: 2.10375 | train_rmse: 2.15906 | train_mse: 4.66153 | valid_rmsle: 0.46767 | valid_mae: 2.11069 | valid_rmse: 2.16455 | valid_mse: 4.68526 |  0:00:01s\n",
      "epoch 1  | loss: 1.93206 | train_rmsle: 0.14751 | train_mae: 1.33116 | train_rmse: 1.411   | train_mse: 1.99091 | valid_rmsle: 0.14824 | valid_mae: 1.33505 | valid_rmse: 1.41545 | valid_mse: 2.00351 |  0:00:02s\n",
      "epoch 2  | loss: 0.78889 | train_rmsle: 0.04252 | train_mae: 0.74314 | train_rmse: 0.83614 | train_mse: 0.69913 | valid_rmsle: 0.04254 | valid_mae: 0.74324 | valid_rmse: 0.83872 | valid_mse: 0.70344 |  0:00:04s\n",
      "epoch 3  | loss: 0.47918 | train_rmsle: 0.02946 | train_mae: 0.61561 | train_rmse: 0.70711 | train_mse: 0.5     | valid_rmsle: 0.02931 | valid_mae: 0.61563 | valid_rmse: 0.70863 | valid_mse: 0.50216 |  0:00:05s\n",
      "epoch 4  | loss: 0.35437 | train_rmsle: 0.02388 | train_mae: 0.54955 | train_rmse: 0.63939 | train_mse: 0.40882 | valid_rmsle: 0.02366 | valid_mae: 0.55062 | valid_rmse: 0.64025 | valid_mse: 0.40992 |  0:00:07s\n",
      "epoch 5  | loss: 0.30807 | train_rmsle: 0.0205  | train_mae: 0.50396 | train_rmse: 0.5922  | train_mse: 0.3507  | valid_rmsle: 0.0202  | valid_mae: 0.5051  | valid_rmse: 0.59219 | valid_mse: 0.35069 |  0:00:08s\n",
      "epoch 6  | loss: 0.27652 | train_rmsle: 0.02214 | train_mae: 0.52683 | train_rmse: 0.61576 | train_mse: 0.37916 | valid_rmsle: 0.02187 | valid_mae: 0.52799 | valid_rmse: 0.61613 | valid_mse: 0.37962 |  0:00:10s\n",
      "epoch 7  | loss: 0.25906 | train_rmsle: 0.02013 | train_mae: 0.4984  | train_rmse: 0.58659 | train_mse: 0.34409 | valid_rmsle: 0.01982 | valid_mae: 0.49958 | valid_rmse: 0.58652 | valid_mse: 0.344   |  0:00:12s\n",
      "epoch 8  | loss: 0.24257 | train_rmsle: 0.01783 | train_mae: 0.46198 | train_rmse: 0.54974 | train_mse: 0.30222 | valid_rmsle: 0.01746 | valid_mae: 0.46344 | valid_rmse: 0.54875 | valid_mse: 0.30112 |  0:00:13s\n",
      "epoch 9  | loss: 0.24001 | train_rmsle: 0.01756 | train_mae: 0.45777 | train_rmse: 0.5453  | train_mse: 0.29735 | valid_rmsle: 0.0172  | valid_mae: 0.45943 | valid_rmse: 0.54454 | valid_mse: 0.29652 |  0:00:15s\n",
      "epoch 10 | loss: 0.2292  | train_rmsle: 0.0162  | train_mae: 0.43828 | train_rmse: 0.52247 | train_mse: 0.27298 | valid_rmsle: 0.01565 | valid_mae: 0.43579 | valid_rmse: 0.51879 | valid_mse: 0.26914 |  0:00:17s\n",
      "epoch 11 | loss: 0.20653 | train_rmsle: 0.01374 | train_mae: 0.39461 | train_rmse: 0.47765 | train_mse: 0.22815 | valid_rmsle: 0.01319 | valid_mae: 0.39056 | valid_rmse: 0.47346 | valid_mse: 0.22417 |  0:00:18s\n",
      "epoch 12 | loss: 0.16895 | train_rmsle: 0.01064 | train_mae: 0.33186 | train_rmse: 0.41398 | train_mse: 0.17138 | valid_rmsle: 0.01001 | valid_mae: 0.32508 | valid_rmse: 0.40626 | valid_mse: 0.16504 |  0:00:20s\n",
      "epoch 13 | loss: 0.15161 | train_rmsle: 0.00939 | train_mae: 0.30654 | train_rmse: 0.38637 | train_mse: 0.14928 | valid_rmsle: 0.00886 | valid_mae: 0.30253 | valid_rmse: 0.38027 | valid_mse: 0.14461 |  0:00:22s\n",
      "epoch 14 | loss: 0.13899 | train_rmsle: 0.00861 | train_mae: 0.29152 | train_rmse: 0.36834 | train_mse: 0.13568 | valid_rmsle: 0.00777 | valid_mae: 0.27801 | valid_rmse: 0.35392 | valid_mse: 0.12526 |  0:00:23s\n",
      "epoch 15 | loss: 0.13145 | train_rmsle: 0.00753 | train_mae: 0.26743 | train_rmse: 0.34259 | train_mse: 0.11737 | valid_rmsle: 0.00679 | valid_mae: 0.25536 | valid_rmse: 0.33028 | valid_mse: 0.10909 |  0:00:24s\n",
      "epoch 16 | loss: 0.12929 | train_rmsle: 0.00816 | train_mae: 0.27955 | train_rmse: 0.35666 | train_mse: 0.1272  | valid_rmsle: 0.0073  | valid_mae: 0.26536 | valid_rmse: 0.34132 | valid_mse: 0.1165  |  0:00:26s\n",
      "epoch 17 | loss: 0.12206 | train_rmsle: 0.00723 | train_mae: 0.26175 | train_rmse: 0.33608 | train_mse: 0.11295 | valid_rmsle: 0.00663 | valid_mae: 0.25252 | valid_rmse: 0.32697 | valid_mse: 0.10691 |  0:00:27s\n",
      "epoch 18 | loss: 0.12076 | train_rmsle: 0.0067  | train_mae: 0.24937 | train_rmse: 0.32159 | train_mse: 0.10342 | valid_rmsle: 0.00615 | valid_mae: 0.23925 | valid_rmse: 0.31236 | valid_mse: 0.09757 |  0:00:28s\n",
      "epoch 19 | loss: 0.11354 | train_rmsle: 0.00659 | train_mae: 0.2502  | train_rmse: 0.32064 | train_mse: 0.10281 | valid_rmsle: 0.00618 | valid_mae: 0.24184 | valid_rmse: 0.3143  | valid_mse: 0.09878 |  0:00:30s\n",
      "epoch 20 | loss: 0.11027 | train_rmsle: 0.00626 | train_mae: 0.2403  | train_rmse: 0.31087 | train_mse: 0.09664 | valid_rmsle: 0.00584 | valid_mae: 0.23371 | valid_rmse: 0.3037  | valid_mse: 0.09223 |  0:00:31s\n",
      "epoch 21 | loss: 0.10861 | train_rmsle: 0.00618 | train_mae: 0.24156 | train_rmse: 0.30988 | train_mse: 0.09602 | valid_rmsle: 0.0057  | valid_mae: 0.23328 | valid_rmse: 0.30081 | valid_mse: 0.09049 |  0:00:32s\n",
      "epoch 22 | loss: 0.10656 | train_rmsle: 0.00602 | train_mae: 0.23524 | train_rmse: 0.30408 | train_mse: 0.09247 | valid_rmsle: 0.00554 | valid_mae: 0.22786 | valid_rmse: 0.29456 | valid_mse: 0.08677 |  0:00:34s\n",
      "epoch 23 | loss: 0.10628 | train_rmsle: 0.0063  | train_mae: 0.25099 | train_rmse: 0.31641 | train_mse: 0.10011 | valid_rmsle: 0.00579 | valid_mae: 0.24322 | valid_rmse: 0.30627 | valid_mse: 0.0938  |  0:00:36s\n",
      "epoch 24 | loss: 0.10802 | train_rmsle: 0.00595 | train_mae: 0.23531 | train_rmse: 0.30388 | train_mse: 0.09234 | valid_rmsle: 0.00549 | valid_mae: 0.22888 | valid_rmse: 0.29494 | valid_mse: 0.08699 |  0:00:37s\n",
      "epoch 25 | loss: 0.09887 | train_rmsle: 0.00595 | train_mae: 0.2378  | train_rmse: 0.30534 | train_mse: 0.09323 | valid_rmsle: 0.00555 | valid_mae: 0.23264 | valid_rmse: 0.29768 | valid_mse: 0.08861 |  0:00:39s\n",
      "epoch 26 | loss: 0.09713 | train_rmsle: 0.00604 | train_mae: 0.23956 | train_rmse: 0.30751 | train_mse: 0.09456 | valid_rmsle: 0.00568 | valid_mae: 0.23363 | valid_rmse: 0.30107 | valid_mse: 0.09064 |  0:00:41s\n",
      "epoch 27 | loss: 0.0947  | train_rmsle: 0.00589 | train_mae: 0.23533 | train_rmse: 0.30328 | train_mse: 0.09198 | valid_rmsle: 0.00558 | valid_mae: 0.23023 | valid_rmse: 0.29842 | valid_mse: 0.08905 |  0:00:43s\n",
      "epoch 28 | loss: 0.09302 | train_rmsle: 0.00584 | train_mae: 0.23277 | train_rmse: 0.30164 | train_mse: 0.09099 | valid_rmsle: 0.0057  | valid_mae: 0.23154 | valid_rmse: 0.30127 | valid_mse: 0.09076 |  0:00:44s\n",
      "epoch 29 | loss: 0.09435 | train_rmsle: 0.00583 | train_mae: 0.23056 | train_rmse: 0.30044 | train_mse: 0.09026 | valid_rmsle: 0.00576 | valid_mae: 0.23347 | valid_rmse: 0.3025  | valid_mse: 0.09151 |  0:00:46s\n",
      "epoch 30 | loss: 0.09223 | train_rmsle: 0.00561 | train_mae: 0.22741 | train_rmse: 0.29465 | train_mse: 0.08682 | valid_rmsle: 0.00563 | valid_mae: 0.22901 | valid_rmse: 0.29877 | valid_mse: 0.08926 |  0:00:47s\n",
      "epoch 31 | loss: 0.08931 | train_rmsle: 0.00566 | train_mae: 0.22755 | train_rmse: 0.29526 | train_mse: 0.08718 | valid_rmsle: 0.00565 | valid_mae: 0.22696 | valid_rmse: 0.29825 | valid_mse: 0.08895 |  0:00:49s\n",
      "epoch 32 | loss: 0.09195 | train_rmsle: 0.00549 | train_mae: 0.22762 | train_rmse: 0.29285 | train_mse: 0.08576 | valid_rmsle: 0.00571 | valid_mae: 0.23085 | valid_rmse: 0.3014  | valid_mse: 0.09084 |  0:00:51s\n",
      "epoch 33 | loss: 0.08835 | train_rmsle: 0.00549 | train_mae: 0.22602 | train_rmse: 0.29222 | train_mse: 0.08539 | valid_rmsle: 0.00577 | valid_mae: 0.23078 | valid_rmse: 0.303   | valid_mse: 0.09181 |  0:00:52s\n",
      "epoch 34 | loss: 0.08626 | train_rmsle: 0.00544 | train_mae: 0.22942 | train_rmse: 0.293   | train_mse: 0.08585 | valid_rmsle: 0.00602 | valid_mae: 0.24126 | valid_rmse: 0.31146 | valid_mse: 0.09701 |  0:00:54s\n",
      "epoch 35 | loss: 0.08508 | train_rmsle: 0.00517 | train_mae: 0.21652 | train_rmse: 0.28184 | train_mse: 0.07943 | valid_rmsle: 0.00576 | valid_mae: 0.23073 | valid_rmse: 0.30152 | valid_mse: 0.09092 |  0:00:56s\n",
      "epoch 36 | loss: 0.08394 | train_rmsle: 0.00489 | train_mae: 0.21145 | train_rmse: 0.27577 | train_mse: 0.07605 | valid_rmsle: 0.00568 | valid_mae: 0.22945 | valid_rmse: 0.30074 | valid_mse: 0.09044 |  0:00:58s\n",
      "epoch 37 | loss: 0.08291 | train_rmsle: 0.00482 | train_mae: 0.20831 | train_rmse: 0.27226 | train_mse: 0.07413 | valid_rmsle: 0.00561 | valid_mae: 0.2269  | valid_rmse: 0.29839 | valid_mse: 0.08903 |  0:00:59s\n",
      "epoch 38 | loss: 0.07962 | train_rmsle: 0.00499 | train_mae: 0.21038 | train_rmse: 0.27531 | train_mse: 0.0758  | valid_rmsle: 0.00587 | valid_mae: 0.2306  | valid_rmse: 0.30412 | valid_mse: 0.09249 |  0:01:01s\n",
      "epoch 39 | loss: 0.07795 | train_rmsle: 0.00465 | train_mae: 0.20517 | train_rmse: 0.26797 | train_mse: 0.07181 | valid_rmsle: 0.00585 | valid_mae: 0.22948 | valid_rmse: 0.30441 | valid_mse: 0.09267 |  0:01:03s\n",
      "epoch 40 | loss: 0.0802  | train_rmsle: 0.00464 | train_mae: 0.2019  | train_rmse: 0.26606 | train_mse: 0.07079 | valid_rmsle: 0.00566 | valid_mae: 0.22684 | valid_rmse: 0.29916 | valid_mse: 0.0895  |  0:01:04s\n",
      "epoch 41 | loss: 0.0769  | train_rmsle: 0.00477 | train_mae: 0.20987 | train_rmse: 0.27264 | train_mse: 0.07433 | valid_rmsle: 0.00571 | valid_mae: 0.23192 | valid_rmse: 0.30209 | valid_mse: 0.09126 |  0:01:06s\n",
      "epoch 42 | loss: 0.07549 | train_rmsle: 0.00474 | train_mae: 0.21485 | train_rmse: 0.27527 | train_mse: 0.07577 | valid_rmsle: 0.00602 | valid_mae: 0.24256 | valid_rmse: 0.31177 | valid_mse: 0.0972  |  0:01:07s\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.08677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09542888893565864 RMSE: 0.30891566638106693 R2: 0.5775730792053121 MAE: 0.23847859812361852\n",
      "=====================================\n",
      "[49/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.43363 | train_rmsle: 0.19232 | train_mae: 1.49096 | train_rmse: 1.56531 | train_mse: 2.4502  | valid_rmsle: 0.19321 | valid_mae: 1.49571 | valid_rmse: 1.5699  | valid_mse: 2.46458 |  0:00:02s\n",
      "epoch 1  | loss: 0.37577 | train_rmsle: 0.096   | train_mae: 1.09805 | train_rmse: 1.18557 | train_mse: 1.40557 | valid_rmsle: 0.09636 | valid_mae: 1.10059 | valid_rmse: 1.18916 | valid_mse: 1.4141  |  0:00:04s\n",
      "epoch 2  | loss: 0.30256 | train_rmsle: 0.04756 | train_mae: 0.7855  | train_rmse: 0.87867 | train_mse: 0.77206 | valid_rmsle: 0.04759 | valid_mae: 0.78567 | valid_rmse: 0.88121 | valid_mse: 0.77654 |  0:00:06s\n",
      "epoch 3  | loss: 0.2617  | train_rmsle: 0.03138 | train_mae: 0.63623 | train_rmse: 0.7282  | train_mse: 0.53027 | valid_rmsle: 0.03125 | valid_mae: 0.63566 | valid_rmse: 0.72978 | valid_mse: 0.53258 |  0:00:08s\n",
      "epoch 4  | loss: 0.31695 | train_rmsle: 0.04698 | train_mae: 0.77998 | train_rmse: 0.87372 | train_mse: 0.76339 | valid_rmsle: 0.04691 | valid_mae: 0.77921 | valid_rmse: 0.87549 | valid_mse: 0.76648 |  0:00:11s\n",
      "epoch 5  | loss: 0.25331 | train_rmsle: 0.01984 | train_mae: 0.48821 | train_rmse: 0.58092 | train_mse: 0.33747 | valid_rmsle: 0.0194  | valid_mae: 0.48576 | valid_rmse: 0.57832 | valid_mse: 0.33445 |  0:00:13s\n",
      "epoch 6  | loss: 0.23396 | train_rmsle: 0.01858 | train_mae: 0.46564 | train_rmse: 0.56141 | train_mse: 0.31518 | valid_rmsle: 0.01798 | valid_mae: 0.45918 | valid_rmse: 0.55651 | valid_mse: 0.3097  |  0:00:15s\n",
      "epoch 7  | loss: 0.22161 | train_rmsle: 0.01827 | train_mae: 0.46411 | train_rmse: 0.55668 | train_mse: 0.30989 | valid_rmsle: 0.01749 | valid_mae: 0.46067 | valid_rmse: 0.54919 | valid_mse: 0.30161 |  0:00:17s\n",
      "epoch 8  | loss: 0.22191 | train_rmsle: 0.01489 | train_mae: 0.40304 | train_rmse: 0.49719 | train_mse: 0.2472  | valid_rmsle: 0.01426 | valid_mae: 0.40162 | valid_rmse: 0.49166 | valid_mse: 0.24173 |  0:00:19s\n",
      "epoch 9  | loss: 0.22382 | train_rmsle: 0.01656 | train_mae: 0.43663 | train_rmse: 0.52935 | train_mse: 0.28021 | valid_rmsle: 0.01606 | valid_mae: 0.43382 | valid_rmse: 0.5259  | valid_mse: 0.27658 |  0:00:22s\n",
      "epoch 10 | loss: 0.21723 | train_rmsle: 0.01587 | train_mae: 0.42864 | train_rmse: 0.51773 | train_mse: 0.26804 | valid_rmsle: 0.01548 | valid_mae: 0.4278  | valid_rmse: 0.51623 | valid_mse: 0.26649 |  0:00:24s\n",
      "epoch 11 | loss: 0.21238 | train_rmsle: 0.01446 | train_mae: 0.3971  | train_rmse: 0.48853 | train_mse: 0.23866 | valid_rmsle: 0.01375 | valid_mae: 0.39312 | valid_rmse: 0.48101 | valid_mse: 0.23137 |  0:00:26s\n",
      "epoch 12 | loss: 0.21639 | train_rmsle: 0.0137  | train_mae: 0.37578 | train_rmse: 0.47058 | train_mse: 0.22145 | valid_rmsle: 0.01308 | valid_mae: 0.37644 | valid_rmse: 0.46495 | valid_mse: 0.21618 |  0:00:28s\n",
      "epoch 13 | loss: 0.21724 | train_rmsle: 0.01405 | train_mae: 0.38788 | train_rmse: 0.48057 | train_mse: 0.23095 | valid_rmsle: 0.01354 | valid_mae: 0.38858 | valid_rmse: 0.47701 | valid_mse: 0.22754 |  0:00:30s\n",
      "epoch 14 | loss: 0.21532 | train_rmsle: 0.01384 | train_mae: 0.38154 | train_rmse: 0.47523 | train_mse: 0.22584 | valid_rmsle: 0.01323 | valid_mae: 0.38077 | valid_rmse: 0.46996 | valid_mse: 0.22086 |  0:00:31s\n",
      "epoch 15 | loss: 0.21439 | train_rmsle: 0.01484 | train_mae: 0.40684 | train_rmse: 0.49772 | train_mse: 0.24773 | valid_rmsle: 0.01431 | valid_mae: 0.4048  | valid_rmse: 0.49382 | valid_mse: 0.24386 |  0:00:33s\n",
      "epoch 16 | loss: 0.2127  | train_rmsle: 0.0149  | train_mae: 0.40905 | train_rmse: 0.49902 | train_mse: 0.24902 | valid_rmsle: 0.01434 | valid_mae: 0.40524 | valid_rmse: 0.49448 | valid_mse: 0.24451 |  0:00:35s\n",
      "epoch 17 | loss: 0.21377 | train_rmsle: 0.01438 | train_mae: 0.39916 | train_rmse: 0.48961 | train_mse: 0.23972 | valid_rmsle: 0.01387 | valid_mae: 0.39903 | valid_rmse: 0.48603 | valid_mse: 0.23623 |  0:00:37s\n",
      "epoch 18 | loss: 0.20643 | train_rmsle: 0.01348 | train_mae: 0.37476 | train_rmse: 0.46813 | train_mse: 0.21914 | valid_rmsle: 0.01279 | valid_mae: 0.37531 | valid_rmse: 0.46136 | valid_mse: 0.21285 |  0:00:39s\n",
      "epoch 19 | loss: 0.2119  | train_rmsle: 0.0137  | train_mae: 0.38325 | train_rmse: 0.47482 | train_mse: 0.22546 | valid_rmsle: 0.01306 | valid_mae: 0.38199 | valid_rmse: 0.4688  | valid_mse: 0.21977 |  0:00:41s\n",
      "epoch 20 | loss: 0.20772 | train_rmsle: 0.01328 | train_mae: 0.366   | train_rmse: 0.46147 | train_mse: 0.21296 | valid_rmsle: 0.01264 | valid_mae: 0.36555 | valid_rmse: 0.45514 | valid_mse: 0.20715 |  0:00:43s\n",
      "epoch 21 | loss: 0.20618 | train_rmsle: 0.01316 | train_mae: 0.36525 | train_rmse: 0.45994 | train_mse: 0.21154 | valid_rmsle: 0.01253 | valid_mae: 0.36362 | valid_rmse: 0.45384 | valid_mse: 0.20597 |  0:00:45s\n",
      "epoch 22 | loss: 0.20195 | train_rmsle: 0.01379 | train_mae: 0.3861  | train_rmse: 0.47725 | train_mse: 0.22777 | valid_rmsle: 0.01325 | valid_mae: 0.38589 | valid_rmse: 0.47291 | valid_mse: 0.22364 |  0:00:48s\n",
      "epoch 23 | loss: 0.2068  | train_rmsle: 0.01321 | train_mae: 0.37218 | train_rmse: 0.46413 | train_mse: 0.21542 | valid_rmsle: 0.01269 | valid_mae: 0.3703  | valid_rmse: 0.4598  | valid_mse: 0.21141 |  0:00:50s\n",
      "epoch 24 | loss: 0.2058  | train_rmsle: 0.01304 | train_mae: 0.36384 | train_rmse: 0.45813 | train_mse: 0.20988 | valid_rmsle: 0.01255 | valid_mae: 0.36367 | valid_rmse: 0.45477 | valid_mse: 0.20681 |  0:00:52s\n",
      "epoch 25 | loss: 0.20631 | train_rmsle: 0.01348 | train_mae: 0.35618 | train_rmse: 0.4601  | train_mse: 0.2117  | valid_rmsle: 0.01292 | valid_mae: 0.35911 | valid_rmse: 0.45518 | valid_mse: 0.20719 |  0:00:54s\n",
      "epoch 26 | loss: 0.21141 | train_rmsle: 0.01321 | train_mae: 0.35551 | train_rmse: 0.45638 | train_mse: 0.20828 | valid_rmsle: 0.0127  | valid_mae: 0.35681 | valid_rmse: 0.45272 | valid_mse: 0.20496 |  0:00:56s\n",
      "epoch 27 | loss: 0.20227 | train_rmsle: 0.01289 | train_mae: 0.36507 | train_rmse: 0.45701 | train_mse: 0.20886 | valid_rmsle: 0.01255 | valid_mae: 0.36932 | valid_rmse: 0.45659 | valid_mse: 0.20848 |  0:00:58s\n",
      "epoch 28 | loss: 0.20005 | train_rmsle: 0.01288 | train_mae: 0.36249 | train_rmse: 0.45547 | train_mse: 0.20746 | valid_rmsle: 0.01255 | valid_mae: 0.36779 | valid_rmse: 0.45522 | valid_mse: 0.20723 |  0:01:01s\n",
      "epoch 29 | loss: 0.19977 | train_rmsle: 0.01287 | train_mae: 0.35195 | train_rmse: 0.45078 | train_mse: 0.2032  | valid_rmsle: 0.01254 | valid_mae: 0.3596  | valid_rmse: 0.45074 | valid_mse: 0.20317 |  0:01:03s\n",
      "epoch 30 | loss: 0.1971  | train_rmsle: 0.01262 | train_mae: 0.3599  | train_rmse: 0.45192 | train_mse: 0.20423 | valid_rmsle: 0.01231 | valid_mae: 0.36447 | valid_rmse: 0.45198 | valid_mse: 0.20428 |  0:01:05s\n",
      "epoch 31 | loss: 0.1977  | train_rmsle: 0.0132  | train_mae: 0.37555 | train_rmse: 0.46588 | train_mse: 0.21705 | valid_rmsle: 0.01289 | valid_mae: 0.38062 | valid_rmse: 0.46576 | valid_mse: 0.21693 |  0:01:07s\n",
      "epoch 32 | loss: 0.19348 | train_rmsle: 0.01269 | train_mae: 0.35949 | train_rmse: 0.45209 | train_mse: 0.20439 | valid_rmsle: 0.01242 | valid_mae: 0.36483 | valid_rmse: 0.45259 | valid_mse: 0.20484 |  0:01:09s\n",
      "epoch 33 | loss: 0.19298 | train_rmsle: 0.01278 | train_mae: 0.35561 | train_rmse: 0.45162 | train_mse: 0.20396 | valid_rmsle: 0.0125  | valid_mae: 0.36213 | valid_rmse: 0.45236 | valid_mse: 0.20463 |  0:01:11s\n",
      "epoch 34 | loss: 0.19811 | train_rmsle: 0.01249 | train_mae: 0.35122 | train_rmse: 0.44605 | train_mse: 0.19896 | valid_rmsle: 0.01222 | valid_mae: 0.35719 | valid_rmse: 0.44649 | valid_mse: 0.19935 |  0:01:13s\n",
      "epoch 35 | loss: 0.19466 | train_rmsle: 0.01316 | train_mae: 0.35303 | train_rmse: 0.45505 | train_mse: 0.20707 | valid_rmsle: 0.01283 | valid_mae: 0.35789 | valid_rmse: 0.45456 | valid_mse: 0.20663 |  0:01:15s\n",
      "epoch 36 | loss: 0.1997  | train_rmsle: 0.01273 | train_mae: 0.3488  | train_rmse: 0.44876 | train_mse: 0.20139 | valid_rmsle: 0.0124  | valid_mae: 0.35592 | valid_rmse: 0.44824 | valid_mse: 0.20092 |  0:01:17s\n",
      "epoch 37 | loss: 0.18962 | train_rmsle: 0.01289 | train_mae: 0.35114 | train_rmse: 0.45105 | train_mse: 0.20345 | valid_rmsle: 0.01243 | valid_mae: 0.35101 | valid_rmse: 0.44686 | valid_mse: 0.19969 |  0:01:19s\n",
      "epoch 38 | loss: 0.18832 | train_rmsle: 0.01181 | train_mae: 0.34685 | train_rmse: 0.43673 | train_mse: 0.19073 | valid_rmsle: 0.01161 | valid_mae: 0.34949 | valid_rmse: 0.43768 | valid_mse: 0.19157 |  0:01:21s\n",
      "epoch 39 | loss: 0.18671 | train_rmsle: 0.01239 | train_mae: 0.34439 | train_rmse: 0.44231 | train_mse: 0.19564 | valid_rmsle: 0.01238 | valid_mae: 0.35285 | valid_rmse: 0.44797 | valid_mse: 0.20068 |  0:01:24s\n",
      "epoch 40 | loss: 0.1896  | train_rmsle: 0.01161 | train_mae: 0.34551 | train_rmse: 0.43381 | train_mse: 0.18819 | valid_rmsle: 0.01136 | valid_mae: 0.35032 | valid_rmse: 0.43425 | valid_mse: 0.18857 |  0:01:26s\n",
      "epoch 41 | loss: 0.1815  | train_rmsle: 0.01111 | train_mae: 0.33274 | train_rmse: 0.42152 | train_mse: 0.17768 | valid_rmsle: 0.01103 | valid_mae: 0.34087 | valid_rmse: 0.42505 | valid_mse: 0.18067 |  0:01:28s\n",
      "epoch 42 | loss: 0.17057 | train_rmsle: 0.01164 | train_mae: 0.33295 | train_rmse: 0.42801 | train_mse: 0.18319 | valid_rmsle: 0.01145 | valid_mae: 0.33992 | valid_rmse: 0.42938 | valid_mse: 0.18436 |  0:01:30s\n",
      "epoch 43 | loss: 0.17472 | train_rmsle: 0.01053 | train_mae: 0.32244 | train_rmse: 0.40996 | train_mse: 0.16806 | valid_rmsle: 0.01046 | valid_mae: 0.33091 | valid_rmse: 0.4143  | valid_mse: 0.17165 |  0:01:33s\n",
      "epoch 44 | loss: 0.16293 | train_rmsle: 0.01001 | train_mae: 0.31333 | train_rmse: 0.39914 | train_mse: 0.15932 | valid_rmsle: 0.0099  | valid_mae: 0.32191 | valid_rmse: 0.40209 | valid_mse: 0.16168 |  0:01:35s\n",
      "epoch 45 | loss: 0.14862 | train_rmsle: 0.00946 | train_mae: 0.29673 | train_rmse: 0.38406 | train_mse: 0.1475  | valid_rmsle: 0.00925 | valid_mae: 0.30244 | valid_rmse: 0.38511 | valid_mse: 0.14831 |  0:01:37s\n",
      "epoch 46 | loss: 0.13648 | train_rmsle: 0.00828 | train_mae: 0.28353 | train_rmse: 0.36152 | train_mse: 0.1307  | valid_rmsle: 0.00798 | valid_mae: 0.28635 | valid_rmse: 0.36001 | valid_mse: 0.12961 |  0:01:39s\n",
      "epoch 47 | loss: 0.12312 | train_rmsle: 0.00808 | train_mae: 0.2756  | train_rmse: 0.35627 | train_mse: 0.12693 | valid_rmsle: 0.00803 | valid_mae: 0.28272 | valid_rmse: 0.36138 | valid_mse: 0.1306  |  0:01:41s\n",
      "epoch 48 | loss: 0.11854 | train_rmsle: 0.0073  | train_mae: 0.26026 | train_rmse: 0.33673 | train_mse: 0.11338 | valid_rmsle: 0.00729 | valid_mae: 0.26826 | valid_rmse: 0.34462 | valid_mse: 0.11876 |  0:01:43s\n",
      "epoch 49 | loss: 0.10824 | train_rmsle: 0.00669 | train_mae: 0.25307 | train_rmse: 0.32412 | train_mse: 0.10506 | valid_rmsle: 0.00664 | valid_mae: 0.26173 | valid_rmse: 0.32951 | valid_mse: 0.10857 |  0:01:46s\n",
      "epoch 50 | loss: 0.0993  | train_rmsle: 0.00646 | train_mae: 0.24338 | train_rmse: 0.3166  | train_mse: 0.10024 | valid_rmsle: 0.00649 | valid_mae: 0.25311 | valid_rmse: 0.32327 | valid_mse: 0.1045  |  0:01:48s\n",
      "epoch 51 | loss: 0.09637 | train_rmsle: 0.00579 | train_mae: 0.23607 | train_rmse: 0.30348 | train_mse: 0.0921  | valid_rmsle: 0.00576 | valid_mae: 0.24355 | valid_rmse: 0.30785 | valid_mse: 0.09477 |  0:01:50s\n",
      "epoch 52 | loss: 0.08304 | train_rmsle: 0.00622 | train_mae: 0.23551 | train_rmse: 0.30817 | train_mse: 0.09497 | valid_rmsle: 0.00609 | valid_mae: 0.24035 | valid_rmse: 0.31046 | valid_mse: 0.09639 |  0:01:52s\n",
      "epoch 53 | loss: 0.07278 | train_rmsle: 0.00655 | train_mae: 0.24636 | train_rmse: 0.31803 | train_mse: 0.10114 | valid_rmsle: 0.00675 | valid_mae: 0.25663 | valid_rmse: 0.32855 | valid_mse: 0.10794 |  0:01:55s\n",
      "epoch 54 | loss: 0.07144 | train_rmsle: 0.00379 | train_mae: 0.19243 | train_rmse: 0.24673 | train_mse: 0.06088 | valid_rmsle: 0.00424 | valid_mae: 0.20602 | valid_rmse: 0.26508 | valid_mse: 0.07027 |  0:01:56s\n",
      "epoch 55 | loss: 0.06034 | train_rmsle: 0.00337 | train_mae: 0.18384 | train_rmse: 0.23492 | train_mse: 0.05519 | valid_rmsle: 0.00391 | valid_mae: 0.19844 | valid_rmse: 0.25685 | valid_mse: 0.06597 |  0:01:58s\n",
      "epoch 56 | loss: 0.05514 | train_rmsle: 0.00301 | train_mae: 0.17678 | train_rmse: 0.22527 | train_mse: 0.05075 | valid_rmsle: 0.00345 | valid_mae: 0.19065 | valid_rmse: 0.24409 | valid_mse: 0.05958 |  0:02:00s\n",
      "epoch 57 | loss: 0.05429 | train_rmsle: 0.00283 | train_mae: 0.17085 | train_rmse: 0.21866 | train_mse: 0.04781 | valid_rmsle: 0.00314 | valid_mae: 0.18402 | valid_rmse: 0.23348 | valid_mse: 0.05452 |  0:02:02s\n",
      "epoch 58 | loss: 0.04918 | train_rmsle: 0.00275 | train_mae: 0.16714 | train_rmse: 0.2149  | train_mse: 0.04618 | valid_rmsle: 0.00316 | valid_mae: 0.18037 | valid_rmse: 0.23302 | valid_mse: 0.0543  |  0:02:03s\n",
      "epoch 59 | loss: 0.04542 | train_rmsle: 0.00229 | train_mae: 0.15549 | train_rmse: 0.19899 | train_mse: 0.0396  | valid_rmsle: 0.0026  | valid_mae: 0.16877 | valid_rmse: 0.21399 | valid_mse: 0.04579 |  0:02:05s\n",
      "epoch 60 | loss: 0.04135 | train_rmsle: 0.00207 | train_mae: 0.14676 | train_rmse: 0.18946 | train_mse: 0.0359  | valid_rmsle: 0.00241 | valid_mae: 0.1599  | valid_rmse: 0.20589 | valid_mse: 0.04239 |  0:02:07s\n",
      "epoch 61 | loss: 0.04073 | train_rmsle: 0.00203 | train_mae: 0.14524 | train_rmse: 0.18694 | train_mse: 0.03495 | valid_rmsle: 0.00235 | valid_mae: 0.15877 | valid_rmse: 0.20309 | valid_mse: 0.04125 |  0:02:09s\n",
      "epoch 62 | loss: 0.03673 | train_rmsle: 0.00201 | train_mae: 0.14473 | train_rmse: 0.18733 | train_mse: 0.03509 | valid_rmsle: 0.00239 | valid_mae: 0.1589  | valid_rmse: 0.20635 | valid_mse: 0.04258 |  0:02:11s\n",
      "epoch 63 | loss: 0.03551 | train_rmsle: 0.00168 | train_mae: 0.13153 | train_rmse: 0.1699  | train_mse: 0.02886 | valid_rmsle: 0.00201 | valid_mae: 0.14637 | valid_rmse: 0.18738 | valid_mse: 0.03511 |  0:02:13s\n",
      "epoch 64 | loss: 0.03214 | train_rmsle: 0.00222 | train_mae: 0.15613 | train_rmse: 0.19873 | train_mse: 0.03949 | valid_rmsle: 0.00266 | valid_mae: 0.17042 | valid_rmse: 0.21912 | valid_mse: 0.04801 |  0:02:15s\n",
      "epoch 65 | loss: 0.03776 | train_rmsle: 0.00168 | train_mae: 0.13058 | train_rmse: 0.16791 | train_mse: 0.02819 | valid_rmsle: 0.00202 | valid_mae: 0.14394 | valid_rmse: 0.18608 | valid_mse: 0.03462 |  0:02:16s\n",
      "epoch 66 | loss: 0.02977 | train_rmsle: 0.00132 | train_mae: 0.11695 | train_rmse: 0.15194 | train_mse: 0.02308 | valid_rmsle: 0.00161 | valid_mae: 0.13084 | valid_rmse: 0.16895 | valid_mse: 0.02854 |  0:02:18s\n",
      "epoch 67 | loss: 0.0304  | train_rmsle: 0.00151 | train_mae: 0.12684 | train_rmse: 0.16369 | train_mse: 0.0268  | valid_rmsle: 0.00183 | valid_mae: 0.13889 | valid_rmse: 0.18115 | valid_mse: 0.03282 |  0:02:19s\n",
      "epoch 68 | loss: 0.02913 | train_rmsle: 0.00143 | train_mae: 0.12157 | train_rmse: 0.15624 | train_mse: 0.02441 | valid_rmsle: 0.00173 | valid_mae: 0.13397 | valid_rmse: 0.17322 | valid_mse: 0.03001 |  0:02:21s\n",
      "epoch 69 | loss: 0.0305  | train_rmsle: 0.00176 | train_mae: 0.14389 | train_rmse: 0.18223 | train_mse: 0.03321 | valid_rmsle: 0.00195 | valid_mae: 0.15181 | valid_rmse: 0.19142 | valid_mse: 0.03664 |  0:02:22s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 66 and best_valid_mse = 0.02854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.028448336167221415 RMSE: 0.16866634568645109 R2: 0.8740701774600562 MAE: 0.1313403816019833\n",
      "=====================================\n",
      "[50/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.43363 | train_rmsle: 0.19232 | train_mae: 1.49096 | train_rmse: 1.56531 | train_mse: 2.4502  | valid_rmsle: 0.19321 | valid_mae: 1.49571 | valid_rmse: 1.5699  | valid_mse: 2.46458 |  0:00:01s\n",
      "epoch 1  | loss: 0.37577 | train_rmsle: 0.096   | train_mae: 1.09805 | train_rmse: 1.18557 | train_mse: 1.40557 | valid_rmsle: 0.09636 | valid_mae: 1.10059 | valid_rmse: 1.18916 | valid_mse: 1.4141  |  0:00:03s\n",
      "epoch 2  | loss: 0.30256 | train_rmsle: 0.04756 | train_mae: 0.7855  | train_rmse: 0.87867 | train_mse: 0.77206 | valid_rmsle: 0.04759 | valid_mae: 0.78567 | valid_rmse: 0.88121 | valid_mse: 0.77654 |  0:00:05s\n",
      "epoch 3  | loss: 0.2617  | train_rmsle: 0.03138 | train_mae: 0.63623 | train_rmse: 0.7282  | train_mse: 0.53027 | valid_rmsle: 0.03125 | valid_mae: 0.63566 | valid_rmse: 0.72978 | valid_mse: 0.53258 |  0:00:07s\n",
      "epoch 4  | loss: 0.31695 | train_rmsle: 0.04698 | train_mae: 0.77998 | train_rmse: 0.87372 | train_mse: 0.76339 | valid_rmsle: 0.04691 | valid_mae: 0.77921 | valid_rmse: 0.87549 | valid_mse: 0.76648 |  0:00:08s\n",
      "epoch 5  | loss: 0.25331 | train_rmsle: 0.01984 | train_mae: 0.48821 | train_rmse: 0.58092 | train_mse: 0.33747 | valid_rmsle: 0.0194  | valid_mae: 0.48576 | valid_rmse: 0.57832 | valid_mse: 0.33445 |  0:00:10s\n",
      "epoch 6  | loss: 0.23396 | train_rmsle: 0.01858 | train_mae: 0.46564 | train_rmse: 0.56141 | train_mse: 0.31518 | valid_rmsle: 0.01798 | valid_mae: 0.45918 | valid_rmse: 0.55651 | valid_mse: 0.3097  |  0:00:12s\n",
      "epoch 7  | loss: 0.22161 | train_rmsle: 0.01827 | train_mae: 0.46411 | train_rmse: 0.55668 | train_mse: 0.30989 | valid_rmsle: 0.01749 | valid_mae: 0.46067 | valid_rmse: 0.54919 | valid_mse: 0.30161 |  0:00:14s\n",
      "epoch 8  | loss: 0.22191 | train_rmsle: 0.01489 | train_mae: 0.40304 | train_rmse: 0.49719 | train_mse: 0.2472  | valid_rmsle: 0.01426 | valid_mae: 0.40162 | valid_rmse: 0.49166 | valid_mse: 0.24173 |  0:00:15s\n",
      "epoch 9  | loss: 0.22382 | train_rmsle: 0.01656 | train_mae: 0.43663 | train_rmse: 0.52935 | train_mse: 0.28021 | valid_rmsle: 0.01606 | valid_mae: 0.43382 | valid_rmse: 0.5259  | valid_mse: 0.27658 |  0:00:17s\n",
      "epoch 10 | loss: 0.21723 | train_rmsle: 0.01587 | train_mae: 0.42864 | train_rmse: 0.51773 | train_mse: 0.26804 | valid_rmsle: 0.01548 | valid_mae: 0.4278  | valid_rmse: 0.51623 | valid_mse: 0.26649 |  0:00:19s\n",
      "epoch 11 | loss: 0.21238 | train_rmsle: 0.01446 | train_mae: 0.3971  | train_rmse: 0.48853 | train_mse: 0.23866 | valid_rmsle: 0.01375 | valid_mae: 0.39312 | valid_rmse: 0.48101 | valid_mse: 0.23137 |  0:00:21s\n",
      "epoch 12 | loss: 0.21639 | train_rmsle: 0.0137  | train_mae: 0.37578 | train_rmse: 0.47058 | train_mse: 0.22145 | valid_rmsle: 0.01308 | valid_mae: 0.37644 | valid_rmse: 0.46495 | valid_mse: 0.21618 |  0:00:23s\n",
      "epoch 13 | loss: 0.21724 | train_rmsle: 0.01405 | train_mae: 0.38788 | train_rmse: 0.48057 | train_mse: 0.23095 | valid_rmsle: 0.01354 | valid_mae: 0.38858 | valid_rmse: 0.47701 | valid_mse: 0.22754 |  0:00:24s\n",
      "epoch 14 | loss: 0.21532 | train_rmsle: 0.01384 | train_mae: 0.38154 | train_rmse: 0.47523 | train_mse: 0.22584 | valid_rmsle: 0.01323 | valid_mae: 0.38077 | valid_rmse: 0.46996 | valid_mse: 0.22086 |  0:00:26s\n",
      "epoch 15 | loss: 0.21439 | train_rmsle: 0.01484 | train_mae: 0.40684 | train_rmse: 0.49772 | train_mse: 0.24773 | valid_rmsle: 0.01431 | valid_mae: 0.4048  | valid_rmse: 0.49382 | valid_mse: 0.24386 |  0:00:28s\n",
      "epoch 16 | loss: 0.2127  | train_rmsle: 0.0149  | train_mae: 0.40905 | train_rmse: 0.49902 | train_mse: 0.24902 | valid_rmsle: 0.01434 | valid_mae: 0.40524 | valid_rmse: 0.49448 | valid_mse: 0.24451 |  0:00:30s\n",
      "epoch 17 | loss: 0.21377 | train_rmsle: 0.01438 | train_mae: 0.39916 | train_rmse: 0.48961 | train_mse: 0.23972 | valid_rmsle: 0.01387 | valid_mae: 0.39903 | valid_rmse: 0.48603 | valid_mse: 0.23623 |  0:00:31s\n",
      "epoch 18 | loss: 0.20643 | train_rmsle: 0.01348 | train_mae: 0.37476 | train_rmse: 0.46813 | train_mse: 0.21914 | valid_rmsle: 0.01279 | valid_mae: 0.37531 | valid_rmse: 0.46136 | valid_mse: 0.21285 |  0:00:33s\n",
      "epoch 19 | loss: 0.2119  | train_rmsle: 0.0137  | train_mae: 0.38325 | train_rmse: 0.47482 | train_mse: 0.22546 | valid_rmsle: 0.01306 | valid_mae: 0.38199 | valid_rmse: 0.4688  | valid_mse: 0.21977 |  0:00:35s\n",
      "epoch 20 | loss: 0.20772 | train_rmsle: 0.01328 | train_mae: 0.366   | train_rmse: 0.46147 | train_mse: 0.21296 | valid_rmsle: 0.01264 | valid_mae: 0.36555 | valid_rmse: 0.45514 | valid_mse: 0.20715 |  0:00:37s\n",
      "epoch 21 | loss: 0.20618 | train_rmsle: 0.01316 | train_mae: 0.36525 | train_rmse: 0.45994 | train_mse: 0.21154 | valid_rmsle: 0.01253 | valid_mae: 0.36362 | valid_rmse: 0.45384 | valid_mse: 0.20597 |  0:00:38s\n",
      "epoch 22 | loss: 0.20195 | train_rmsle: 0.01379 | train_mae: 0.3861  | train_rmse: 0.47725 | train_mse: 0.22777 | valid_rmsle: 0.01325 | valid_mae: 0.38589 | valid_rmse: 0.47291 | valid_mse: 0.22364 |  0:00:40s\n",
      "epoch 23 | loss: 0.2068  | train_rmsle: 0.01321 | train_mae: 0.37218 | train_rmse: 0.46413 | train_mse: 0.21542 | valid_rmsle: 0.01269 | valid_mae: 0.3703  | valid_rmse: 0.4598  | valid_mse: 0.21141 |  0:00:42s\n",
      "epoch 24 | loss: 0.2058  | train_rmsle: 0.01304 | train_mae: 0.36384 | train_rmse: 0.45813 | train_mse: 0.20988 | valid_rmsle: 0.01255 | valid_mae: 0.36367 | valid_rmse: 0.45477 | valid_mse: 0.20681 |  0:00:44s\n",
      "epoch 25 | loss: 0.20631 | train_rmsle: 0.01348 | train_mae: 0.35618 | train_rmse: 0.4601  | train_mse: 0.2117  | valid_rmsle: 0.01292 | valid_mae: 0.35911 | valid_rmse: 0.45518 | valid_mse: 0.20719 |  0:00:46s\n",
      "epoch 26 | loss: 0.21141 | train_rmsle: 0.01321 | train_mae: 0.35551 | train_rmse: 0.45638 | train_mse: 0.20828 | valid_rmsle: 0.0127  | valid_mae: 0.35681 | valid_rmse: 0.45272 | valid_mse: 0.20496 |  0:00:47s\n",
      "epoch 27 | loss: 0.20227 | train_rmsle: 0.01289 | train_mae: 0.36507 | train_rmse: 0.45701 | train_mse: 0.20886 | valid_rmsle: 0.01255 | valid_mae: 0.36932 | valid_rmse: 0.45659 | valid_mse: 0.20848 |  0:00:49s\n",
      "epoch 28 | loss: 0.20005 | train_rmsle: 0.01288 | train_mae: 0.36249 | train_rmse: 0.45547 | train_mse: 0.20746 | valid_rmsle: 0.01255 | valid_mae: 0.36779 | valid_rmse: 0.45522 | valid_mse: 0.20723 |  0:00:51s\n",
      "epoch 29 | loss: 0.19977 | train_rmsle: 0.01287 | train_mae: 0.35195 | train_rmse: 0.45078 | train_mse: 0.2032  | valid_rmsle: 0.01254 | valid_mae: 0.3596  | valid_rmse: 0.45074 | valid_mse: 0.20317 |  0:00:53s\n",
      "epoch 30 | loss: 0.1971  | train_rmsle: 0.01262 | train_mae: 0.3599  | train_rmse: 0.45192 | train_mse: 0.20423 | valid_rmsle: 0.01231 | valid_mae: 0.36447 | valid_rmse: 0.45198 | valid_mse: 0.20428 |  0:00:54s\n",
      "epoch 31 | loss: 0.1977  | train_rmsle: 0.0132  | train_mae: 0.37555 | train_rmse: 0.46588 | train_mse: 0.21705 | valid_rmsle: 0.01289 | valid_mae: 0.38062 | valid_rmse: 0.46576 | valid_mse: 0.21693 |  0:00:56s\n",
      "epoch 32 | loss: 0.19348 | train_rmsle: 0.01269 | train_mae: 0.35949 | train_rmse: 0.45209 | train_mse: 0.20439 | valid_rmsle: 0.01242 | valid_mae: 0.36483 | valid_rmse: 0.45259 | valid_mse: 0.20484 |  0:00:58s\n",
      "epoch 33 | loss: 0.19298 | train_rmsle: 0.01278 | train_mae: 0.35561 | train_rmse: 0.45162 | train_mse: 0.20396 | valid_rmsle: 0.0125  | valid_mae: 0.36213 | valid_rmse: 0.45236 | valid_mse: 0.20463 |  0:01:00s\n",
      "epoch 34 | loss: 0.19811 | train_rmsle: 0.01249 | train_mae: 0.35122 | train_rmse: 0.44605 | train_mse: 0.19896 | valid_rmsle: 0.01222 | valid_mae: 0.35719 | valid_rmse: 0.44649 | valid_mse: 0.19935 |  0:01:01s\n",
      "epoch 35 | loss: 0.19466 | train_rmsle: 0.01316 | train_mae: 0.35303 | train_rmse: 0.45505 | train_mse: 0.20707 | valid_rmsle: 0.01283 | valid_mae: 0.35789 | valid_rmse: 0.45456 | valid_mse: 0.20663 |  0:01:03s\n",
      "epoch 36 | loss: 0.1997  | train_rmsle: 0.01273 | train_mae: 0.3488  | train_rmse: 0.44876 | train_mse: 0.20139 | valid_rmsle: 0.0124  | valid_mae: 0.35592 | valid_rmse: 0.44824 | valid_mse: 0.20092 |  0:01:05s\n",
      "epoch 37 | loss: 0.18962 | train_rmsle: 0.01289 | train_mae: 0.35114 | train_rmse: 0.45105 | train_mse: 0.20345 | valid_rmsle: 0.01243 | valid_mae: 0.35101 | valid_rmse: 0.44686 | valid_mse: 0.19969 |  0:01:07s\n",
      "epoch 38 | loss: 0.18832 | train_rmsle: 0.01181 | train_mae: 0.34685 | train_rmse: 0.43673 | train_mse: 0.19073 | valid_rmsle: 0.01161 | valid_mae: 0.34949 | valid_rmse: 0.43768 | valid_mse: 0.19157 |  0:01:08s\n",
      "epoch 39 | loss: 0.18671 | train_rmsle: 0.01239 | train_mae: 0.34439 | train_rmse: 0.44231 | train_mse: 0.19564 | valid_rmsle: 0.01238 | valid_mae: 0.35285 | valid_rmse: 0.44797 | valid_mse: 0.20068 |  0:01:10s\n",
      "epoch 40 | loss: 0.1896  | train_rmsle: 0.01161 | train_mae: 0.34551 | train_rmse: 0.43381 | train_mse: 0.18819 | valid_rmsle: 0.01136 | valid_mae: 0.35032 | valid_rmse: 0.43425 | valid_mse: 0.18857 |  0:01:11s\n",
      "epoch 41 | loss: 0.1815  | train_rmsle: 0.01111 | train_mae: 0.33274 | train_rmse: 0.42152 | train_mse: 0.17768 | valid_rmsle: 0.01103 | valid_mae: 0.34087 | valid_rmse: 0.42505 | valid_mse: 0.18067 |  0:01:13s\n",
      "epoch 42 | loss: 0.17057 | train_rmsle: 0.01164 | train_mae: 0.33295 | train_rmse: 0.42801 | train_mse: 0.18319 | valid_rmsle: 0.01145 | valid_mae: 0.33992 | valid_rmse: 0.42938 | valid_mse: 0.18436 |  0:01:14s\n",
      "epoch 43 | loss: 0.17472 | train_rmsle: 0.01053 | train_mae: 0.32244 | train_rmse: 0.40996 | train_mse: 0.16806 | valid_rmsle: 0.01046 | valid_mae: 0.33091 | valid_rmse: 0.4143  | valid_mse: 0.17165 |  0:01:16s\n",
      "epoch 44 | loss: 0.16293 | train_rmsle: 0.01001 | train_mae: 0.31333 | train_rmse: 0.39914 | train_mse: 0.15932 | valid_rmsle: 0.0099  | valid_mae: 0.32191 | valid_rmse: 0.40209 | valid_mse: 0.16168 |  0:01:17s\n",
      "epoch 45 | loss: 0.14862 | train_rmsle: 0.00946 | train_mae: 0.29673 | train_rmse: 0.38406 | train_mse: 0.1475  | valid_rmsle: 0.00925 | valid_mae: 0.30244 | valid_rmse: 0.38511 | valid_mse: 0.14831 |  0:01:19s\n",
      "epoch 46 | loss: 0.13648 | train_rmsle: 0.00828 | train_mae: 0.28353 | train_rmse: 0.36152 | train_mse: 0.1307  | valid_rmsle: 0.00798 | valid_mae: 0.28635 | valid_rmse: 0.36001 | valid_mse: 0.12961 |  0:01:21s\n",
      "epoch 47 | loss: 0.12312 | train_rmsle: 0.00808 | train_mae: 0.2756  | train_rmse: 0.35627 | train_mse: 0.12693 | valid_rmsle: 0.00803 | valid_mae: 0.28272 | valid_rmse: 0.36138 | valid_mse: 0.1306  |  0:01:22s\n",
      "epoch 48 | loss: 0.11854 | train_rmsle: 0.0073  | train_mae: 0.26026 | train_rmse: 0.33673 | train_mse: 0.11338 | valid_rmsle: 0.00729 | valid_mae: 0.26826 | valid_rmse: 0.34462 | valid_mse: 0.11876 |  0:01:24s\n",
      "epoch 49 | loss: 0.10824 | train_rmsle: 0.00669 | train_mae: 0.25307 | train_rmse: 0.32412 | train_mse: 0.10506 | valid_rmsle: 0.00664 | valid_mae: 0.26173 | valid_rmse: 0.32951 | valid_mse: 0.10857 |  0:01:26s\n",
      "epoch 50 | loss: 0.0993  | train_rmsle: 0.00646 | train_mae: 0.24338 | train_rmse: 0.3166  | train_mse: 0.10024 | valid_rmsle: 0.00649 | valid_mae: 0.25311 | valid_rmse: 0.32327 | valid_mse: 0.1045  |  0:01:28s\n",
      "epoch 51 | loss: 0.09637 | train_rmsle: 0.00579 | train_mae: 0.23607 | train_rmse: 0.30348 | train_mse: 0.0921  | valid_rmsle: 0.00576 | valid_mae: 0.24355 | valid_rmse: 0.30785 | valid_mse: 0.09477 |  0:01:29s\n",
      "epoch 52 | loss: 0.08304 | train_rmsle: 0.00622 | train_mae: 0.23551 | train_rmse: 0.30817 | train_mse: 0.09497 | valid_rmsle: 0.00609 | valid_mae: 0.24035 | valid_rmse: 0.31046 | valid_mse: 0.09639 |  0:01:31s\n",
      "epoch 53 | loss: 0.07278 | train_rmsle: 0.00655 | train_mae: 0.24636 | train_rmse: 0.31803 | train_mse: 0.10114 | valid_rmsle: 0.00675 | valid_mae: 0.25663 | valid_rmse: 0.32855 | valid_mse: 0.10794 |  0:01:33s\n",
      "epoch 54 | loss: 0.07144 | train_rmsle: 0.00379 | train_mae: 0.19243 | train_rmse: 0.24673 | train_mse: 0.06088 | valid_rmsle: 0.00424 | valid_mae: 0.20602 | valid_rmse: 0.26508 | valid_mse: 0.07027 |  0:01:35s\n",
      "epoch 55 | loss: 0.06034 | train_rmsle: 0.00337 | train_mae: 0.18384 | train_rmse: 0.23492 | train_mse: 0.05519 | valid_rmsle: 0.00391 | valid_mae: 0.19844 | valid_rmse: 0.25685 | valid_mse: 0.06597 |  0:01:36s\n",
      "epoch 56 | loss: 0.05514 | train_rmsle: 0.00301 | train_mae: 0.17678 | train_rmse: 0.22527 | train_mse: 0.05075 | valid_rmsle: 0.00345 | valid_mae: 0.19065 | valid_rmse: 0.24409 | valid_mse: 0.05958 |  0:01:38s\n",
      "epoch 57 | loss: 0.05429 | train_rmsle: 0.00283 | train_mae: 0.17085 | train_rmse: 0.21866 | train_mse: 0.04781 | valid_rmsle: 0.00314 | valid_mae: 0.18402 | valid_rmse: 0.23348 | valid_mse: 0.05452 |  0:01:40s\n",
      "epoch 58 | loss: 0.04918 | train_rmsle: 0.00275 | train_mae: 0.16714 | train_rmse: 0.2149  | train_mse: 0.04618 | valid_rmsle: 0.00316 | valid_mae: 0.18037 | valid_rmse: 0.23302 | valid_mse: 0.0543  |  0:01:42s\n",
      "epoch 59 | loss: 0.04542 | train_rmsle: 0.00229 | train_mae: 0.15549 | train_rmse: 0.19899 | train_mse: 0.0396  | valid_rmsle: 0.0026  | valid_mae: 0.16877 | valid_rmse: 0.21399 | valid_mse: 0.04579 |  0:01:43s\n",
      "epoch 60 | loss: 0.04135 | train_rmsle: 0.00207 | train_mae: 0.14676 | train_rmse: 0.18946 | train_mse: 0.0359  | valid_rmsle: 0.00241 | valid_mae: 0.1599  | valid_rmse: 0.20589 | valid_mse: 0.04239 |  0:01:45s\n",
      "epoch 61 | loss: 0.04073 | train_rmsle: 0.00203 | train_mae: 0.14524 | train_rmse: 0.18694 | train_mse: 0.03495 | valid_rmsle: 0.00235 | valid_mae: 0.15877 | valid_rmse: 0.20309 | valid_mse: 0.04125 |  0:01:47s\n",
      "epoch 62 | loss: 0.03673 | train_rmsle: 0.00201 | train_mae: 0.14473 | train_rmse: 0.18733 | train_mse: 0.03509 | valid_rmsle: 0.00239 | valid_mae: 0.1589  | valid_rmse: 0.20635 | valid_mse: 0.04258 |  0:01:49s\n",
      "epoch 63 | loss: 0.03551 | train_rmsle: 0.00168 | train_mae: 0.13153 | train_rmse: 0.1699  | train_mse: 0.02886 | valid_rmsle: 0.00201 | valid_mae: 0.14637 | valid_rmse: 0.18738 | valid_mse: 0.03511 |  0:01:51s\n",
      "epoch 64 | loss: 0.03214 | train_rmsle: 0.00222 | train_mae: 0.15613 | train_rmse: 0.19873 | train_mse: 0.03949 | valid_rmsle: 0.00266 | valid_mae: 0.17042 | valid_rmse: 0.21912 | valid_mse: 0.04801 |  0:01:52s\n",
      "epoch 65 | loss: 0.03776 | train_rmsle: 0.00168 | train_mae: 0.13058 | train_rmse: 0.16791 | train_mse: 0.02819 | valid_rmsle: 0.00202 | valid_mae: 0.14394 | valid_rmse: 0.18608 | valid_mse: 0.03462 |  0:01:54s\n",
      "epoch 66 | loss: 0.02977 | train_rmsle: 0.00132 | train_mae: 0.11695 | train_rmse: 0.15194 | train_mse: 0.02308 | valid_rmsle: 0.00161 | valid_mae: 0.13084 | valid_rmse: 0.16895 | valid_mse: 0.02854 |  0:01:56s\n",
      "epoch 67 | loss: 0.0304  | train_rmsle: 0.00151 | train_mae: 0.12684 | train_rmse: 0.16369 | train_mse: 0.0268  | valid_rmsle: 0.00183 | valid_mae: 0.13889 | valid_rmse: 0.18115 | valid_mse: 0.03282 |  0:01:58s\n",
      "epoch 68 | loss: 0.02913 | train_rmsle: 0.00143 | train_mae: 0.12157 | train_rmse: 0.15624 | train_mse: 0.02441 | valid_rmsle: 0.00173 | valid_mae: 0.13397 | valid_rmse: 0.17322 | valid_mse: 0.03001 |  0:01:59s\n",
      "epoch 69 | loss: 0.0305  | train_rmsle: 0.00176 | train_mae: 0.14389 | train_rmse: 0.18223 | train_mse: 0.03321 | valid_rmsle: 0.00195 | valid_mae: 0.15181 | valid_rmse: 0.19142 | valid_mse: 0.03664 |  0:02:01s\n",
      "epoch 70 | loss: 0.02788 | train_rmsle: 0.00133 | train_mae: 0.11714 | train_rmse: 0.15104 | train_mse: 0.02281 | valid_rmsle: 0.00154 | valid_mae: 0.12814 | valid_rmse: 0.16429 | valid_mse: 0.02699 |  0:02:03s\n",
      "epoch 71 | loss: 0.02871 | train_rmsle: 0.00125 | train_mae: 0.11802 | train_rmse: 0.15055 | train_mse: 0.02266 | valid_rmsle: 0.00145 | valid_mae: 0.12802 | valid_rmse: 0.16298 | valid_mse: 0.02656 |  0:02:05s\n",
      "epoch 72 | loss: 0.02655 | train_rmsle: 0.00129 | train_mae: 0.11986 | train_rmse: 0.15056 | train_mse: 0.02267 | valid_rmsle: 0.00152 | valid_mae: 0.1293  | valid_rmse: 0.16428 | valid_mse: 0.02699 |  0:02:06s\n",
      "epoch 73 | loss: 0.02753 | train_rmsle: 0.00109 | train_mae: 0.10749 | train_rmse: 0.13864 | train_mse: 0.01922 | valid_rmsle: 0.00135 | valid_mae: 0.12006 | valid_rmse: 0.15494 | valid_mse: 0.02401 |  0:02:08s\n",
      "epoch 74 | loss: 0.02905 | train_rmsle: 0.00103 | train_mae: 0.10611 | train_rmse: 0.13679 | train_mse: 0.01871 | valid_rmsle: 0.00125 | valid_mae: 0.1165  | valid_rmse: 0.15045 | valid_mse: 0.02264 |  0:02:10s\n",
      "epoch 75 | loss: 0.0216  | train_rmsle: 0.00097 | train_mae: 0.10265 | train_rmse: 0.13323 | train_mse: 0.01775 | valid_rmsle: 0.00124 | valid_mae: 0.11556 | valid_rmse: 0.14996 | valid_mse: 0.02249 |  0:02:12s\n",
      "epoch 76 | loss: 0.02424 | train_rmsle: 0.00091 | train_mae: 0.09958 | train_rmse: 0.12899 | train_mse: 0.01664 | valid_rmsle: 0.00116 | valid_mae: 0.11195 | valid_rmse: 0.14547 | valid_mse: 0.02116 |  0:02:14s\n",
      "epoch 77 | loss: 0.02245 | train_rmsle: 0.00107 | train_mae: 0.10722 | train_rmse: 0.13861 | train_mse: 0.01921 | valid_rmsle: 0.0013  | valid_mae: 0.11718 | valid_rmse: 0.15341 | valid_mse: 0.02354 |  0:02:15s\n",
      "epoch 78 | loss: 0.02532 | train_rmsle: 0.00211 | train_mae: 0.16123 | train_rmse: 0.19128 | train_mse: 0.03659 | valid_rmsle: 0.0022  | valid_mae: 0.16195 | valid_rmse: 0.1951  | valid_mse: 0.03807 |  0:02:17s\n",
      "epoch 79 | loss: 0.02429 | train_rmsle: 0.00105 | train_mae: 0.10591 | train_rmse: 0.13608 | train_mse: 0.01852 | valid_rmsle: 0.00124 | valid_mae: 0.11485 | valid_rmse: 0.14851 | valid_mse: 0.02206 |  0:02:19s\n",
      "epoch 80 | loss: 0.02146 | train_rmsle: 0.00162 | train_mae: 0.13948 | train_rmse: 0.1679  | train_mse: 0.02819 | valid_rmsle: 0.00178 | valid_mae: 0.14454 | valid_rmse: 0.17581 | valid_mse: 0.03091 |  0:02:21s\n",
      "epoch 81 | loss: 0.02227 | train_rmsle: 0.00103 | train_mae: 0.09819 | train_rmse: 0.13577 | train_mse: 0.01843 | valid_rmsle: 0.00138 | valid_mae: 0.1096  | valid_rmse: 0.15937 | valid_mse: 0.0254  |  0:02:22s\n",
      "epoch 82 | loss: 0.02081 | train_rmsle: 0.00143 | train_mae: 0.09957 | train_rmse: 0.17642 | train_mse: 0.03112 | valid_rmsle: 0.00184 | valid_mae: 0.11126 | valid_rmse: 0.21746 | valid_mse: 0.04729 |  0:02:24s\n",
      "epoch 83 | loss: 0.01943 | train_rmsle: 0.00176 | train_mae: 0.10377 | train_rmse: 0.18122 | train_mse: 0.03284 | valid_rmsle: 0.00251 | valid_mae: 0.12266 | valid_rmse: 0.21981 | valid_mse: 0.04832 |  0:02:26s\n",
      "epoch 84 | loss: 0.02053 | train_rmsle: 0.00171 | train_mae: 0.13747 | train_rmse: 0.16934 | train_mse: 0.02868 | valid_rmsle: 0.00186 | valid_mae: 0.14166 | valid_rmse: 0.17726 | valid_mse: 0.03142 |  0:02:27s\n",
      "epoch 85 | loss: 0.02493 | train_rmsle: 0.00092 | train_mae: 0.09927 | train_rmse: 0.12796 | train_mse: 0.01637 | valid_rmsle: 0.00113 | valid_mae: 0.10884 | valid_rmse: 0.14278 | valid_mse: 0.02039 |  0:02:29s\n",
      "epoch 86 | loss: 0.01791 | train_rmsle: 0.00068 | train_mae: 0.08557 | train_rmse: 0.11107 | train_mse: 0.01234 | valid_rmsle: 0.00086 | valid_mae: 0.09519 | valid_rmse: 0.12508 | valid_mse: 0.01565 |  0:02:31s\n",
      "epoch 87 | loss: 0.02189 | train_rmsle: 0.00125 | train_mae: 0.12505 | train_rmse: 0.15359 | train_mse: 0.02359 | valid_rmsle: 0.00139 | valid_mae: 0.13097 | valid_rmse: 0.16127 | valid_mse: 0.02601 |  0:02:33s\n",
      "epoch 88 | loss: 0.02087 | train_rmsle: 0.00063 | train_mae: 0.0828  | train_rmse: 0.10706 | train_mse: 0.01146 | valid_rmsle: 0.0008  | valid_mae: 0.09264 | valid_rmse: 0.12069 | valid_mse: 0.01457 |  0:02:34s\n",
      "epoch 89 | loss: 0.02943 | train_rmsle: 0.01011 | train_mae: 0.28057 | train_rmse: 0.36021 | train_mse: 0.12975 | valid_rmsle: 0.01037 | valid_mae: 0.28635 | valid_rmse: 0.36613 | valid_mse: 0.13405 |  0:02:36s\n",
      "epoch 90 | loss: 0.02764 | train_rmsle: 0.00306 | train_mae: 0.17812 | train_rmse: 0.21373 | train_mse: 0.04568 | valid_rmsle: 0.00312 | valid_mae: 0.18057 | valid_rmse: 0.21765 | valid_mse: 0.04737 |  0:02:38s\n",
      "epoch 91 | loss: 0.0257  | train_rmsle: 0.00096 | train_mae: 0.10208 | train_rmse: 0.12994 | train_mse: 0.01689 | valid_rmsle: 0.0011  | valid_mae: 0.1096  | valid_rmse: 0.14106 | valid_mse: 0.0199  |  0:02:40s\n",
      "epoch 92 | loss: 0.01937 | train_rmsle: 0.00122 | train_mae: 0.11736 | train_rmse: 0.14435 | train_mse: 0.02084 | valid_rmsle: 0.00131 | valid_mae: 0.12165 | valid_rmse: 0.15094 | valid_mse: 0.02278 |  0:02:42s\n",
      "epoch 93 | loss: 0.01951 | train_rmsle: 0.00083 | train_mae: 0.09508 | train_rmse: 0.123   | train_mse: 0.01513 | valid_rmsle: 0.00099 | valid_mae: 0.10447 | valid_rmse: 0.13504 | valid_mse: 0.01823 |  0:02:43s\n",
      "epoch 94 | loss: 0.0199  | train_rmsle: 0.00071 | train_mae: 0.08663 | train_rmse: 0.11174 | train_mse: 0.01249 | valid_rmsle: 0.00087 | valid_mae: 0.09558 | valid_rmse: 0.12383 | valid_mse: 0.01534 |  0:02:45s\n",
      "epoch 95 | loss: 0.01661 | train_rmsle: 0.00078 | train_mae: 0.09348 | train_rmse: 0.11819 | train_mse: 0.01397 | valid_rmsle: 0.00093 | valid_mae: 0.10201 | valid_rmse: 0.12939 | valid_mse: 0.01674 |  0:02:47s\n",
      "epoch 96 | loss: 0.01751 | train_rmsle: 0.00108 | train_mae: 0.10866 | train_rmse: 0.13334 | train_mse: 0.01778 | valid_rmsle: 0.00119 | valid_mae: 0.1152  | valid_rmse: 0.14124 | valid_mse: 0.01995 |  0:02:48s\n",
      "epoch 97 | loss: 0.01903 | train_rmsle: 0.00072 | train_mae: 0.09079 | train_rmse: 0.11546 | train_mse: 0.01333 | valid_rmsle: 0.00082 | valid_mae: 0.0976  | valid_rmse: 0.12311 | valid_mse: 0.01516 |  0:02:50s\n",
      "epoch 98 | loss: 0.0172  | train_rmsle: 0.00079 | train_mae: 0.09464 | train_rmse: 0.11827 | train_mse: 0.01399 | valid_rmsle: 0.00089 | valid_mae: 0.1015  | valid_rmse: 0.12577 | valid_mse: 0.01582 |  0:02:52s\n",
      "epoch 99 | loss: 0.01654 | train_rmsle: 0.00065 | train_mae: 0.08387 | train_rmse: 0.10848 | train_mse: 0.01177 | valid_rmsle: 0.00078 | valid_mae: 0.09193 | valid_rmse: 0.11924 | valid_mse: 0.01422 |  0:02:54s\n",
      "epoch 100| loss: 0.01863 | train_rmsle: 0.00074 | train_mae: 0.09285 | train_rmse: 0.11696 | train_mse: 0.01368 | valid_rmsle: 0.00086 | valid_mae: 0.10076 | valid_rmse: 0.12617 | valid_mse: 0.01592 |  0:02:56s\n",
      "epoch 101| loss: 0.01504 | train_rmsle: 0.00059 | train_mae: 0.08169 | train_rmse: 0.10406 | train_mse: 0.01083 | valid_rmsle: 0.00072 | valid_mae: 0.09068 | valid_rmse: 0.11474 | valid_mse: 0.01317 |  0:02:57s\n",
      "epoch 102| loss: 0.01509 | train_rmsle: 0.00054 | train_mae: 0.07583 | train_rmse: 0.09784 | train_mse: 0.00957 | valid_rmsle: 0.00067 | valid_mae: 0.08455 | valid_rmse: 0.10976 | valid_mse: 0.01205 |  0:02:59s\n",
      "epoch 103| loss: 0.015   | train_rmsle: 0.0005  | train_mae: 0.07339 | train_rmse: 0.09456 | train_mse: 0.00894 | valid_rmsle: 0.00064 | valid_mae: 0.08275 | valid_rmse: 0.10791 | valid_mse: 0.01164 |  0:03:01s\n",
      "epoch 104| loss: 0.01457 | train_rmsle: 0.0005  | train_mae: 0.07321 | train_rmse: 0.09451 | train_mse: 0.00893 | valid_rmsle: 0.00064 | valid_mae: 0.08291 | valid_rmse: 0.10719 | valid_mse: 0.01149 |  0:03:03s\n",
      "epoch 105| loss: 0.01775 | train_rmsle: 0.0008  | train_mae: 0.09519 | train_rmse: 0.11713 | train_mse: 0.01372 | valid_rmsle: 0.00094 | valid_mae: 0.10298 | valid_rmse: 0.127   | valid_mse: 0.01613 |  0:03:04s\n",
      "epoch 106| loss: 0.01728 | train_rmsle: 0.00115 | train_mae: 0.11726 | train_rmse: 0.1407  | train_mse: 0.0198  | valid_rmsle: 0.00128 | valid_mae: 0.12397 | valid_rmse: 0.14895 | valid_mse: 0.02219 |  0:03:06s\n",
      "epoch 107| loss: 0.01905 | train_rmsle: 0.00067 | train_mae: 0.08389 | train_rmse: 0.11118 | train_mse: 0.01236 | valid_rmsle: 0.00083 | valid_mae: 0.09414 | valid_rmse: 0.12325 | valid_mse: 0.01519 |  0:03:08s\n",
      "epoch 108| loss: 0.01843 | train_rmsle: 0.00061 | train_mae: 0.08189 | train_rmse: 0.10648 | train_mse: 0.01134 | valid_rmsle: 0.00076 | valid_mae: 0.0916  | valid_rmse: 0.11893 | valid_mse: 0.01415 |  0:03:09s\n",
      "epoch 109| loss: 0.01487 | train_rmsle: 0.00053 | train_mae: 0.07527 | train_rmse: 0.0979  | train_mse: 0.00958 | valid_rmsle: 0.00066 | valid_mae: 0.084   | valid_rmse: 0.1092  | valid_mse: 0.01192 |  0:03:11s\n",
      "epoch 110| loss: 0.01556 | train_rmsle: 0.00074 | train_mae: 0.09366 | train_rmse: 0.11686 | train_mse: 0.01366 | valid_rmsle: 0.00085 | valid_mae: 0.10038 | valid_rmse: 0.12537 | valid_mse: 0.01572 |  0:03:13s\n",
      "epoch 111| loss: 0.01407 | train_rmsle: 0.00056 | train_mae: 0.07802 | train_rmse: 0.10007 | train_mse: 0.01001 | valid_rmsle: 0.00067 | valid_mae: 0.08528 | valid_rmse: 0.10932 | valid_mse: 0.01195 |  0:03:15s\n",
      "epoch 112| loss: 0.01497 | train_rmsle: 0.00066 | train_mae: 0.08722 | train_rmse: 0.11106 | train_mse: 0.01234 | valid_rmsle: 0.00078 | valid_mae: 0.09469 | valid_rmse: 0.11991 | valid_mse: 0.01438 |  0:03:16s\n",
      "epoch 113| loss: 0.0148  | train_rmsle: 0.00046 | train_mae: 0.06993 | train_rmse: 0.09079 | train_mse: 0.00824 | valid_rmsle: 0.00058 | valid_mae: 0.07883 | valid_rmse: 0.10134 | valid_mse: 0.01027 |  0:03:18s\n",
      "epoch 114| loss: 0.01387 | train_rmsle: 0.00059 | train_mae: 0.08169 | train_rmse: 0.10309 | train_mse: 0.01063 | valid_rmsle: 0.00074 | valid_mae: 0.09098 | valid_rmse: 0.11458 | valid_mse: 0.01313 |  0:03:20s\n",
      "epoch 115| loss: 0.0159  | train_rmsle: 0.00054 | train_mae: 0.07481 | train_rmse: 0.09699 | train_mse: 0.00941 | valid_rmsle: 0.00068 | valid_mae: 0.08418 | valid_rmse: 0.10901 | valid_mse: 0.01188 |  0:03:22s\n",
      "epoch 116| loss: 0.01471 | train_rmsle: 0.00069 | train_mae: 0.08192 | train_rmse: 0.10442 | train_mse: 0.0109  | valid_rmsle: 0.00081 | valid_mae: 0.09021 | valid_rmse: 0.11459 | valid_mse: 0.01313 |  0:03:23s\n",
      "epoch 117| loss: 0.01701 | train_rmsle: 0.00164 | train_mae: 0.13058 | train_rmse: 0.15727 | train_mse: 0.02473 | valid_rmsle: 0.00179 | valid_mae: 0.13363 | valid_rmse: 0.16403 | valid_mse: 0.0269  |  0:03:25s\n",
      "epoch 118| loss: 0.01934 | train_rmsle: 0.00065 | train_mae: 0.08546 | train_rmse: 0.10779 | train_mse: 0.01162 | valid_rmsle: 0.0008  | valid_mae: 0.0935  | valid_rmse: 0.11783 | valid_mse: 0.01388 |  0:03:27s\n",
      "epoch 119| loss: 0.01878 | train_rmsle: 0.00078 | train_mae: 0.0931  | train_rmse: 0.11538 | train_mse: 0.01331 | valid_rmsle: 0.00094 | valid_mae: 0.10093 | valid_rmse: 0.12651 | valid_mse: 0.01601 |  0:03:29s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 113 and best_valid_mse = 0.01027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011874775249514729 RMSE: 0.10897144235768713 R2: 0.9474349455418727 MAE: 0.08537998864179489\n",
      "=====================================\n",
      "[51/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.43363 | train_rmsle: 0.19232 | train_mae: 1.49096 | train_rmse: 1.56531 | train_mse: 2.4502  | valid_rmsle: 0.19321 | valid_mae: 1.49571 | valid_rmse: 1.5699  | valid_mse: 2.46458 |  0:00:01s\n",
      "epoch 1  | loss: 0.37577 | train_rmsle: 0.096   | train_mae: 1.09805 | train_rmse: 1.18557 | train_mse: 1.40557 | valid_rmsle: 0.09636 | valid_mae: 1.10059 | valid_rmse: 1.18916 | valid_mse: 1.4141  |  0:00:03s\n",
      "epoch 2  | loss: 0.30256 | train_rmsle: 0.04756 | train_mae: 0.7855  | train_rmse: 0.87867 | train_mse: 0.77206 | valid_rmsle: 0.04759 | valid_mae: 0.78567 | valid_rmse: 0.88121 | valid_mse: 0.77654 |  0:00:05s\n",
      "epoch 3  | loss: 0.2617  | train_rmsle: 0.03138 | train_mae: 0.63623 | train_rmse: 0.7282  | train_mse: 0.53027 | valid_rmsle: 0.03125 | valid_mae: 0.63566 | valid_rmse: 0.72978 | valid_mse: 0.53258 |  0:00:07s\n",
      "epoch 4  | loss: 0.31695 | train_rmsle: 0.04698 | train_mae: 0.77998 | train_rmse: 0.87372 | train_mse: 0.76339 | valid_rmsle: 0.04691 | valid_mae: 0.77921 | valid_rmse: 0.87549 | valid_mse: 0.76648 |  0:00:08s\n",
      "epoch 5  | loss: 0.25331 | train_rmsle: 0.01984 | train_mae: 0.48821 | train_rmse: 0.58092 | train_mse: 0.33747 | valid_rmsle: 0.0194  | valid_mae: 0.48576 | valid_rmse: 0.57832 | valid_mse: 0.33445 |  0:00:10s\n",
      "epoch 6  | loss: 0.23396 | train_rmsle: 0.01858 | train_mae: 0.46564 | train_rmse: 0.56141 | train_mse: 0.31518 | valid_rmsle: 0.01798 | valid_mae: 0.45918 | valid_rmse: 0.55651 | valid_mse: 0.3097  |  0:00:12s\n",
      "epoch 7  | loss: 0.22161 | train_rmsle: 0.01827 | train_mae: 0.46411 | train_rmse: 0.55668 | train_mse: 0.30989 | valid_rmsle: 0.01749 | valid_mae: 0.46067 | valid_rmse: 0.54919 | valid_mse: 0.30161 |  0:00:14s\n",
      "epoch 8  | loss: 0.22191 | train_rmsle: 0.01489 | train_mae: 0.40304 | train_rmse: 0.49719 | train_mse: 0.2472  | valid_rmsle: 0.01426 | valid_mae: 0.40162 | valid_rmse: 0.49166 | valid_mse: 0.24173 |  0:00:16s\n",
      "epoch 9  | loss: 0.22382 | train_rmsle: 0.01656 | train_mae: 0.43663 | train_rmse: 0.52935 | train_mse: 0.28021 | valid_rmsle: 0.01606 | valid_mae: 0.43382 | valid_rmse: 0.5259  | valid_mse: 0.27658 |  0:00:17s\n",
      "epoch 10 | loss: 0.21723 | train_rmsle: 0.01587 | train_mae: 0.42864 | train_rmse: 0.51773 | train_mse: 0.26804 | valid_rmsle: 0.01548 | valid_mae: 0.4278  | valid_rmse: 0.51623 | valid_mse: 0.26649 |  0:00:19s\n",
      "epoch 11 | loss: 0.21238 | train_rmsle: 0.01446 | train_mae: 0.3971  | train_rmse: 0.48853 | train_mse: 0.23866 | valid_rmsle: 0.01375 | valid_mae: 0.39312 | valid_rmse: 0.48101 | valid_mse: 0.23137 |  0:00:21s\n",
      "epoch 12 | loss: 0.21639 | train_rmsle: 0.0137  | train_mae: 0.37578 | train_rmse: 0.47058 | train_mse: 0.22145 | valid_rmsle: 0.01308 | valid_mae: 0.37644 | valid_rmse: 0.46495 | valid_mse: 0.21618 |  0:00:23s\n",
      "epoch 13 | loss: 0.21724 | train_rmsle: 0.01405 | train_mae: 0.38788 | train_rmse: 0.48057 | train_mse: 0.23095 | valid_rmsle: 0.01354 | valid_mae: 0.38858 | valid_rmse: 0.47701 | valid_mse: 0.22754 |  0:00:24s\n",
      "epoch 14 | loss: 0.21532 | train_rmsle: 0.01384 | train_mae: 0.38154 | train_rmse: 0.47523 | train_mse: 0.22584 | valid_rmsle: 0.01323 | valid_mae: 0.38077 | valid_rmse: 0.46996 | valid_mse: 0.22086 |  0:00:26s\n",
      "epoch 15 | loss: 0.21439 | train_rmsle: 0.01484 | train_mae: 0.40684 | train_rmse: 0.49772 | train_mse: 0.24773 | valid_rmsle: 0.01431 | valid_mae: 0.4048  | valid_rmse: 0.49382 | valid_mse: 0.24386 |  0:00:28s\n",
      "epoch 16 | loss: 0.2127  | train_rmsle: 0.0149  | train_mae: 0.40905 | train_rmse: 0.49902 | train_mse: 0.24902 | valid_rmsle: 0.01434 | valid_mae: 0.40524 | valid_rmse: 0.49448 | valid_mse: 0.24451 |  0:00:30s\n",
      "epoch 17 | loss: 0.21377 | train_rmsle: 0.01438 | train_mae: 0.39916 | train_rmse: 0.48961 | train_mse: 0.23972 | valid_rmsle: 0.01387 | valid_mae: 0.39903 | valid_rmse: 0.48603 | valid_mse: 0.23623 |  0:00:31s\n",
      "epoch 18 | loss: 0.20643 | train_rmsle: 0.01348 | train_mae: 0.37476 | train_rmse: 0.46813 | train_mse: 0.21914 | valid_rmsle: 0.01279 | valid_mae: 0.37531 | valid_rmse: 0.46136 | valid_mse: 0.21285 |  0:00:33s\n",
      "epoch 19 | loss: 0.2119  | train_rmsle: 0.0137  | train_mae: 0.38325 | train_rmse: 0.47482 | train_mse: 0.22546 | valid_rmsle: 0.01306 | valid_mae: 0.38199 | valid_rmse: 0.4688  | valid_mse: 0.21977 |  0:00:35s\n",
      "epoch 20 | loss: 0.20772 | train_rmsle: 0.01328 | train_mae: 0.366   | train_rmse: 0.46147 | train_mse: 0.21296 | valid_rmsle: 0.01264 | valid_mae: 0.36555 | valid_rmse: 0.45514 | valid_mse: 0.20715 |  0:00:37s\n",
      "epoch 21 | loss: 0.20618 | train_rmsle: 0.01316 | train_mae: 0.36525 | train_rmse: 0.45994 | train_mse: 0.21154 | valid_rmsle: 0.01253 | valid_mae: 0.36362 | valid_rmse: 0.45384 | valid_mse: 0.20597 |  0:00:38s\n",
      "epoch 22 | loss: 0.20195 | train_rmsle: 0.01379 | train_mae: 0.3861  | train_rmse: 0.47725 | train_mse: 0.22777 | valid_rmsle: 0.01325 | valid_mae: 0.38589 | valid_rmse: 0.47291 | valid_mse: 0.22364 |  0:00:40s\n",
      "epoch 23 | loss: 0.2068  | train_rmsle: 0.01321 | train_mae: 0.37218 | train_rmse: 0.46413 | train_mse: 0.21542 | valid_rmsle: 0.01269 | valid_mae: 0.3703  | valid_rmse: 0.4598  | valid_mse: 0.21141 |  0:00:42s\n",
      "epoch 24 | loss: 0.2058  | train_rmsle: 0.01304 | train_mae: 0.36384 | train_rmse: 0.45813 | train_mse: 0.20988 | valid_rmsle: 0.01255 | valid_mae: 0.36367 | valid_rmse: 0.45477 | valid_mse: 0.20681 |  0:00:44s\n",
      "epoch 25 | loss: 0.20631 | train_rmsle: 0.01348 | train_mae: 0.35618 | train_rmse: 0.4601  | train_mse: 0.2117  | valid_rmsle: 0.01292 | valid_mae: 0.35911 | valid_rmse: 0.45518 | valid_mse: 0.20719 |  0:00:45s\n",
      "epoch 26 | loss: 0.21141 | train_rmsle: 0.01321 | train_mae: 0.35551 | train_rmse: 0.45638 | train_mse: 0.20828 | valid_rmsle: 0.0127  | valid_mae: 0.35681 | valid_rmse: 0.45272 | valid_mse: 0.20496 |  0:00:47s\n",
      "epoch 27 | loss: 0.20227 | train_rmsle: 0.01289 | train_mae: 0.36507 | train_rmse: 0.45701 | train_mse: 0.20886 | valid_rmsle: 0.01255 | valid_mae: 0.36932 | valid_rmse: 0.45659 | valid_mse: 0.20848 |  0:00:49s\n",
      "epoch 28 | loss: 0.20005 | train_rmsle: 0.01288 | train_mae: 0.36249 | train_rmse: 0.45547 | train_mse: 0.20746 | valid_rmsle: 0.01255 | valid_mae: 0.36779 | valid_rmse: 0.45522 | valid_mse: 0.20723 |  0:00:51s\n",
      "epoch 29 | loss: 0.19977 | train_rmsle: 0.01287 | train_mae: 0.35195 | train_rmse: 0.45078 | train_mse: 0.2032  | valid_rmsle: 0.01254 | valid_mae: 0.3596  | valid_rmse: 0.45074 | valid_mse: 0.20317 |  0:00:53s\n",
      "epoch 30 | loss: 0.1971  | train_rmsle: 0.01262 | train_mae: 0.3599  | train_rmse: 0.45192 | train_mse: 0.20423 | valid_rmsle: 0.01231 | valid_mae: 0.36447 | valid_rmse: 0.45198 | valid_mse: 0.20428 |  0:00:54s\n",
      "epoch 31 | loss: 0.1977  | train_rmsle: 0.0132  | train_mae: 0.37555 | train_rmse: 0.46588 | train_mse: 0.21705 | valid_rmsle: 0.01289 | valid_mae: 0.38062 | valid_rmse: 0.46576 | valid_mse: 0.21693 |  0:00:56s\n",
      "epoch 32 | loss: 0.19348 | train_rmsle: 0.01269 | train_mae: 0.35949 | train_rmse: 0.45209 | train_mse: 0.20439 | valid_rmsle: 0.01242 | valid_mae: 0.36483 | valid_rmse: 0.45259 | valid_mse: 0.20484 |  0:00:58s\n",
      "epoch 33 | loss: 0.19298 | train_rmsle: 0.01278 | train_mae: 0.35561 | train_rmse: 0.45162 | train_mse: 0.20396 | valid_rmsle: 0.0125  | valid_mae: 0.36213 | valid_rmse: 0.45236 | valid_mse: 0.20463 |  0:00:59s\n",
      "epoch 34 | loss: 0.19811 | train_rmsle: 0.01249 | train_mae: 0.35122 | train_rmse: 0.44605 | train_mse: 0.19896 | valid_rmsle: 0.01222 | valid_mae: 0.35719 | valid_rmse: 0.44649 | valid_mse: 0.19935 |  0:01:01s\n",
      "epoch 35 | loss: 0.19466 | train_rmsle: 0.01316 | train_mae: 0.35303 | train_rmse: 0.45505 | train_mse: 0.20707 | valid_rmsle: 0.01283 | valid_mae: 0.35789 | valid_rmse: 0.45456 | valid_mse: 0.20663 |  0:01:03s\n",
      "epoch 36 | loss: 0.1997  | train_rmsle: 0.01273 | train_mae: 0.3488  | train_rmse: 0.44876 | train_mse: 0.20139 | valid_rmsle: 0.0124  | valid_mae: 0.35592 | valid_rmse: 0.44824 | valid_mse: 0.20092 |  0:01:05s\n",
      "epoch 37 | loss: 0.18962 | train_rmsle: 0.01289 | train_mae: 0.35114 | train_rmse: 0.45105 | train_mse: 0.20345 | valid_rmsle: 0.01243 | valid_mae: 0.35101 | valid_rmse: 0.44686 | valid_mse: 0.19969 |  0:01:07s\n",
      "epoch 38 | loss: 0.18832 | train_rmsle: 0.01181 | train_mae: 0.34685 | train_rmse: 0.43673 | train_mse: 0.19073 | valid_rmsle: 0.01161 | valid_mae: 0.34949 | valid_rmse: 0.43768 | valid_mse: 0.19157 |  0:01:08s\n",
      "epoch 39 | loss: 0.18671 | train_rmsle: 0.01239 | train_mae: 0.34439 | train_rmse: 0.44231 | train_mse: 0.19564 | valid_rmsle: 0.01238 | valid_mae: 0.35285 | valid_rmse: 0.44797 | valid_mse: 0.20068 |  0:01:10s\n",
      "epoch 40 | loss: 0.1896  | train_rmsle: 0.01161 | train_mae: 0.34551 | train_rmse: 0.43381 | train_mse: 0.18819 | valid_rmsle: 0.01136 | valid_mae: 0.35032 | valid_rmse: 0.43425 | valid_mse: 0.18857 |  0:01:12s\n",
      "epoch 41 | loss: 0.1815  | train_rmsle: 0.01111 | train_mae: 0.33274 | train_rmse: 0.42152 | train_mse: 0.17768 | valid_rmsle: 0.01103 | valid_mae: 0.34087 | valid_rmse: 0.42505 | valid_mse: 0.18067 |  0:01:14s\n",
      "epoch 42 | loss: 0.17057 | train_rmsle: 0.01164 | train_mae: 0.33295 | train_rmse: 0.42801 | train_mse: 0.18319 | valid_rmsle: 0.01145 | valid_mae: 0.33992 | valid_rmse: 0.42938 | valid_mse: 0.18436 |  0:01:15s\n",
      "epoch 43 | loss: 0.17472 | train_rmsle: 0.01053 | train_mae: 0.32244 | train_rmse: 0.40996 | train_mse: 0.16806 | valid_rmsle: 0.01046 | valid_mae: 0.33091 | valid_rmse: 0.4143  | valid_mse: 0.17165 |  0:01:17s\n",
      "epoch 44 | loss: 0.16293 | train_rmsle: 0.01001 | train_mae: 0.31333 | train_rmse: 0.39914 | train_mse: 0.15932 | valid_rmsle: 0.0099  | valid_mae: 0.32191 | valid_rmse: 0.40209 | valid_mse: 0.16168 |  0:01:19s\n",
      "epoch 45 | loss: 0.14862 | train_rmsle: 0.00946 | train_mae: 0.29673 | train_rmse: 0.38406 | train_mse: 0.1475  | valid_rmsle: 0.00925 | valid_mae: 0.30244 | valid_rmse: 0.38511 | valid_mse: 0.14831 |  0:01:21s\n",
      "epoch 46 | loss: 0.13648 | train_rmsle: 0.00828 | train_mae: 0.28353 | train_rmse: 0.36152 | train_mse: 0.1307  | valid_rmsle: 0.00798 | valid_mae: 0.28635 | valid_rmse: 0.36001 | valid_mse: 0.12961 |  0:01:23s\n",
      "epoch 47 | loss: 0.12312 | train_rmsle: 0.00808 | train_mae: 0.2756  | train_rmse: 0.35627 | train_mse: 0.12693 | valid_rmsle: 0.00803 | valid_mae: 0.28272 | valid_rmse: 0.36138 | valid_mse: 0.1306  |  0:01:24s\n",
      "epoch 48 | loss: 0.11854 | train_rmsle: 0.0073  | train_mae: 0.26026 | train_rmse: 0.33673 | train_mse: 0.11338 | valid_rmsle: 0.00729 | valid_mae: 0.26826 | valid_rmse: 0.34462 | valid_mse: 0.11876 |  0:01:26s\n",
      "epoch 49 | loss: 0.10824 | train_rmsle: 0.00669 | train_mae: 0.25307 | train_rmse: 0.32412 | train_mse: 0.10506 | valid_rmsle: 0.00664 | valid_mae: 0.26173 | valid_rmse: 0.32951 | valid_mse: 0.10857 |  0:01:28s\n",
      "epoch 50 | loss: 0.0993  | train_rmsle: 0.00646 | train_mae: 0.24338 | train_rmse: 0.3166  | train_mse: 0.10024 | valid_rmsle: 0.00649 | valid_mae: 0.25311 | valid_rmse: 0.32327 | valid_mse: 0.1045  |  0:01:30s\n",
      "epoch 51 | loss: 0.09637 | train_rmsle: 0.00579 | train_mae: 0.23607 | train_rmse: 0.30348 | train_mse: 0.0921  | valid_rmsle: 0.00576 | valid_mae: 0.24355 | valid_rmse: 0.30785 | valid_mse: 0.09477 |  0:01:31s\n",
      "epoch 52 | loss: 0.08304 | train_rmsle: 0.00622 | train_mae: 0.23551 | train_rmse: 0.30817 | train_mse: 0.09497 | valid_rmsle: 0.00609 | valid_mae: 0.24035 | valid_rmse: 0.31046 | valid_mse: 0.09639 |  0:01:33s\n",
      "epoch 53 | loss: 0.07278 | train_rmsle: 0.00655 | train_mae: 0.24636 | train_rmse: 0.31803 | train_mse: 0.10114 | valid_rmsle: 0.00675 | valid_mae: 0.25663 | valid_rmse: 0.32855 | valid_mse: 0.10794 |  0:01:35s\n",
      "epoch 54 | loss: 0.07144 | train_rmsle: 0.00379 | train_mae: 0.19243 | train_rmse: 0.24673 | train_mse: 0.06088 | valid_rmsle: 0.00424 | valid_mae: 0.20602 | valid_rmse: 0.26508 | valid_mse: 0.07027 |  0:01:37s\n",
      "epoch 55 | loss: 0.06034 | train_rmsle: 0.00337 | train_mae: 0.18384 | train_rmse: 0.23492 | train_mse: 0.05519 | valid_rmsle: 0.00391 | valid_mae: 0.19844 | valid_rmse: 0.25685 | valid_mse: 0.06597 |  0:01:38s\n",
      "epoch 56 | loss: 0.05514 | train_rmsle: 0.00301 | train_mae: 0.17678 | train_rmse: 0.22527 | train_mse: 0.05075 | valid_rmsle: 0.00345 | valid_mae: 0.19065 | valid_rmse: 0.24409 | valid_mse: 0.05958 |  0:01:40s\n",
      "epoch 57 | loss: 0.05429 | train_rmsle: 0.00283 | train_mae: 0.17085 | train_rmse: 0.21866 | train_mse: 0.04781 | valid_rmsle: 0.00314 | valid_mae: 0.18402 | valid_rmse: 0.23348 | valid_mse: 0.05452 |  0:01:42s\n",
      "epoch 58 | loss: 0.04918 | train_rmsle: 0.00275 | train_mae: 0.16714 | train_rmse: 0.2149  | train_mse: 0.04618 | valid_rmsle: 0.00316 | valid_mae: 0.18037 | valid_rmse: 0.23302 | valid_mse: 0.0543  |  0:01:44s\n",
      "epoch 59 | loss: 0.04542 | train_rmsle: 0.00229 | train_mae: 0.15549 | train_rmse: 0.19899 | train_mse: 0.0396  | valid_rmsle: 0.0026  | valid_mae: 0.16877 | valid_rmse: 0.21399 | valid_mse: 0.04579 |  0:01:45s\n",
      "epoch 60 | loss: 0.04135 | train_rmsle: 0.00207 | train_mae: 0.14676 | train_rmse: 0.18946 | train_mse: 0.0359  | valid_rmsle: 0.00241 | valid_mae: 0.1599  | valid_rmse: 0.20589 | valid_mse: 0.04239 |  0:01:47s\n",
      "epoch 61 | loss: 0.04073 | train_rmsle: 0.00203 | train_mae: 0.14524 | train_rmse: 0.18694 | train_mse: 0.03495 | valid_rmsle: 0.00235 | valid_mae: 0.15877 | valid_rmse: 0.20309 | valid_mse: 0.04125 |  0:01:49s\n",
      "epoch 62 | loss: 0.03673 | train_rmsle: 0.00201 | train_mae: 0.14473 | train_rmse: 0.18733 | train_mse: 0.03509 | valid_rmsle: 0.00239 | valid_mae: 0.1589  | valid_rmse: 0.20635 | valid_mse: 0.04258 |  0:01:51s\n",
      "epoch 63 | loss: 0.03551 | train_rmsle: 0.00168 | train_mae: 0.13153 | train_rmse: 0.1699  | train_mse: 0.02886 | valid_rmsle: 0.00201 | valid_mae: 0.14637 | valid_rmse: 0.18738 | valid_mse: 0.03511 |  0:01:52s\n",
      "epoch 64 | loss: 0.03214 | train_rmsle: 0.00222 | train_mae: 0.15613 | train_rmse: 0.19873 | train_mse: 0.03949 | valid_rmsle: 0.00266 | valid_mae: 0.17042 | valid_rmse: 0.21912 | valid_mse: 0.04801 |  0:01:54s\n",
      "epoch 65 | loss: 0.03776 | train_rmsle: 0.00168 | train_mae: 0.13058 | train_rmse: 0.16791 | train_mse: 0.02819 | valid_rmsle: 0.00202 | valid_mae: 0.14394 | valid_rmse: 0.18608 | valid_mse: 0.03462 |  0:01:56s\n",
      "epoch 66 | loss: 0.02977 | train_rmsle: 0.00132 | train_mae: 0.11695 | train_rmse: 0.15194 | train_mse: 0.02308 | valid_rmsle: 0.00161 | valid_mae: 0.13084 | valid_rmse: 0.16895 | valid_mse: 0.02854 |  0:01:58s\n",
      "epoch 67 | loss: 0.0304  | train_rmsle: 0.00151 | train_mae: 0.12684 | train_rmse: 0.16369 | train_mse: 0.0268  | valid_rmsle: 0.00183 | valid_mae: 0.13889 | valid_rmse: 0.18115 | valid_mse: 0.03282 |  0:01:59s\n",
      "epoch 68 | loss: 0.02913 | train_rmsle: 0.00143 | train_mae: 0.12157 | train_rmse: 0.15624 | train_mse: 0.02441 | valid_rmsle: 0.00173 | valid_mae: 0.13397 | valid_rmse: 0.17322 | valid_mse: 0.03001 |  0:02:01s\n",
      "epoch 69 | loss: 0.0305  | train_rmsle: 0.00176 | train_mae: 0.14389 | train_rmse: 0.18223 | train_mse: 0.03321 | valid_rmsle: 0.00195 | valid_mae: 0.15181 | valid_rmse: 0.19142 | valid_mse: 0.03664 |  0:02:03s\n",
      "epoch 70 | loss: 0.02788 | train_rmsle: 0.00133 | train_mae: 0.11714 | train_rmse: 0.15104 | train_mse: 0.02281 | valid_rmsle: 0.00154 | valid_mae: 0.12814 | valid_rmse: 0.16429 | valid_mse: 0.02699 |  0:02:05s\n",
      "epoch 71 | loss: 0.02871 | train_rmsle: 0.00125 | train_mae: 0.11802 | train_rmse: 0.15055 | train_mse: 0.02266 | valid_rmsle: 0.00145 | valid_mae: 0.12802 | valid_rmse: 0.16298 | valid_mse: 0.02656 |  0:02:06s\n",
      "epoch 72 | loss: 0.02655 | train_rmsle: 0.00129 | train_mae: 0.11986 | train_rmse: 0.15056 | train_mse: 0.02267 | valid_rmsle: 0.00152 | valid_mae: 0.1293  | valid_rmse: 0.16428 | valid_mse: 0.02699 |  0:02:08s\n",
      "epoch 73 | loss: 0.02753 | train_rmsle: 0.00109 | train_mae: 0.10749 | train_rmse: 0.13864 | train_mse: 0.01922 | valid_rmsle: 0.00135 | valid_mae: 0.12006 | valid_rmse: 0.15494 | valid_mse: 0.02401 |  0:02:10s\n",
      "epoch 74 | loss: 0.02905 | train_rmsle: 0.00103 | train_mae: 0.10611 | train_rmse: 0.13679 | train_mse: 0.01871 | valid_rmsle: 0.00125 | valid_mae: 0.1165  | valid_rmse: 0.15045 | valid_mse: 0.02264 |  0:02:12s\n",
      "epoch 75 | loss: 0.0216  | train_rmsle: 0.00097 | train_mae: 0.10265 | train_rmse: 0.13323 | train_mse: 0.01775 | valid_rmsle: 0.00124 | valid_mae: 0.11556 | valid_rmse: 0.14996 | valid_mse: 0.02249 |  0:02:13s\n",
      "epoch 76 | loss: 0.02424 | train_rmsle: 0.00091 | train_mae: 0.09958 | train_rmse: 0.12899 | train_mse: 0.01664 | valid_rmsle: 0.00116 | valid_mae: 0.11195 | valid_rmse: 0.14547 | valid_mse: 0.02116 |  0:02:15s\n",
      "epoch 77 | loss: 0.02245 | train_rmsle: 0.00107 | train_mae: 0.10722 | train_rmse: 0.13861 | train_mse: 0.01921 | valid_rmsle: 0.0013  | valid_mae: 0.11718 | valid_rmse: 0.15341 | valid_mse: 0.02354 |  0:02:17s\n",
      "epoch 78 | loss: 0.02532 | train_rmsle: 0.00211 | train_mae: 0.16123 | train_rmse: 0.19128 | train_mse: 0.03659 | valid_rmsle: 0.0022  | valid_mae: 0.16195 | valid_rmse: 0.1951  | valid_mse: 0.03807 |  0:02:19s\n",
      "epoch 79 | loss: 0.02429 | train_rmsle: 0.00105 | train_mae: 0.10591 | train_rmse: 0.13608 | train_mse: 0.01852 | valid_rmsle: 0.00124 | valid_mae: 0.11485 | valid_rmse: 0.14851 | valid_mse: 0.02206 |  0:02:20s\n",
      "epoch 80 | loss: 0.02146 | train_rmsle: 0.00162 | train_mae: 0.13948 | train_rmse: 0.1679  | train_mse: 0.02819 | valid_rmsle: 0.00178 | valid_mae: 0.14454 | valid_rmse: 0.17581 | valid_mse: 0.03091 |  0:02:22s\n",
      "epoch 81 | loss: 0.02227 | train_rmsle: 0.00103 | train_mae: 0.09819 | train_rmse: 0.13577 | train_mse: 0.01843 | valid_rmsle: 0.00138 | valid_mae: 0.1096  | valid_rmse: 0.15937 | valid_mse: 0.0254  |  0:02:24s\n",
      "epoch 82 | loss: 0.02081 | train_rmsle: 0.00143 | train_mae: 0.09957 | train_rmse: 0.17642 | train_mse: 0.03112 | valid_rmsle: 0.00184 | valid_mae: 0.11126 | valid_rmse: 0.21746 | valid_mse: 0.04729 |  0:02:26s\n",
      "epoch 83 | loss: 0.01943 | train_rmsle: 0.00176 | train_mae: 0.10377 | train_rmse: 0.18122 | train_mse: 0.03284 | valid_rmsle: 0.00251 | valid_mae: 0.12266 | valid_rmse: 0.21981 | valid_mse: 0.04832 |  0:02:27s\n",
      "epoch 84 | loss: 0.02053 | train_rmsle: 0.00171 | train_mae: 0.13747 | train_rmse: 0.16934 | train_mse: 0.02868 | valid_rmsle: 0.00186 | valid_mae: 0.14166 | valid_rmse: 0.17726 | valid_mse: 0.03142 |  0:02:29s\n",
      "epoch 85 | loss: 0.02493 | train_rmsle: 0.00092 | train_mae: 0.09927 | train_rmse: 0.12796 | train_mse: 0.01637 | valid_rmsle: 0.00113 | valid_mae: 0.10884 | valid_rmse: 0.14278 | valid_mse: 0.02039 |  0:02:31s\n",
      "epoch 86 | loss: 0.01791 | train_rmsle: 0.00068 | train_mae: 0.08557 | train_rmse: 0.11107 | train_mse: 0.01234 | valid_rmsle: 0.00086 | valid_mae: 0.09519 | valid_rmse: 0.12508 | valid_mse: 0.01565 |  0:02:33s\n",
      "epoch 87 | loss: 0.02189 | train_rmsle: 0.00125 | train_mae: 0.12505 | train_rmse: 0.15359 | train_mse: 0.02359 | valid_rmsle: 0.00139 | valid_mae: 0.13097 | valid_rmse: 0.16127 | valid_mse: 0.02601 |  0:02:34s\n",
      "epoch 88 | loss: 0.02087 | train_rmsle: 0.00063 | train_mae: 0.0828  | train_rmse: 0.10706 | train_mse: 0.01146 | valid_rmsle: 0.0008  | valid_mae: 0.09264 | valid_rmse: 0.12069 | valid_mse: 0.01457 |  0:02:36s\n",
      "epoch 89 | loss: 0.02943 | train_rmsle: 0.01011 | train_mae: 0.28057 | train_rmse: 0.36021 | train_mse: 0.12975 | valid_rmsle: 0.01037 | valid_mae: 0.28635 | valid_rmse: 0.36613 | valid_mse: 0.13405 |  0:02:38s\n",
      "epoch 90 | loss: 0.02764 | train_rmsle: 0.00306 | train_mae: 0.17812 | train_rmse: 0.21373 | train_mse: 0.04568 | valid_rmsle: 0.00312 | valid_mae: 0.18057 | valid_rmse: 0.21765 | valid_mse: 0.04737 |  0:02:40s\n",
      "epoch 91 | loss: 0.0257  | train_rmsle: 0.00096 | train_mae: 0.10208 | train_rmse: 0.12994 | train_mse: 0.01689 | valid_rmsle: 0.0011  | valid_mae: 0.1096  | valid_rmse: 0.14106 | valid_mse: 0.0199  |  0:02:42s\n",
      "epoch 92 | loss: 0.01937 | train_rmsle: 0.00122 | train_mae: 0.11736 | train_rmse: 0.14435 | train_mse: 0.02084 | valid_rmsle: 0.00131 | valid_mae: 0.12165 | valid_rmse: 0.15094 | valid_mse: 0.02278 |  0:02:43s\n",
      "epoch 93 | loss: 0.01951 | train_rmsle: 0.00083 | train_mae: 0.09508 | train_rmse: 0.123   | train_mse: 0.01513 | valid_rmsle: 0.00099 | valid_mae: 0.10447 | valid_rmse: 0.13504 | valid_mse: 0.01823 |  0:02:45s\n",
      "epoch 94 | loss: 0.0199  | train_rmsle: 0.00071 | train_mae: 0.08663 | train_rmse: 0.11174 | train_mse: 0.01249 | valid_rmsle: 0.00087 | valid_mae: 0.09558 | valid_rmse: 0.12383 | valid_mse: 0.01534 |  0:02:47s\n",
      "epoch 95 | loss: 0.01661 | train_rmsle: 0.00078 | train_mae: 0.09348 | train_rmse: 0.11819 | train_mse: 0.01397 | valid_rmsle: 0.00093 | valid_mae: 0.10201 | valid_rmse: 0.12939 | valid_mse: 0.01674 |  0:02:48s\n",
      "epoch 96 | loss: 0.01751 | train_rmsle: 0.00108 | train_mae: 0.10866 | train_rmse: 0.13334 | train_mse: 0.01778 | valid_rmsle: 0.00119 | valid_mae: 0.1152  | valid_rmse: 0.14124 | valid_mse: 0.01995 |  0:02:50s\n",
      "epoch 97 | loss: 0.01903 | train_rmsle: 0.00072 | train_mae: 0.09079 | train_rmse: 0.11546 | train_mse: 0.01333 | valid_rmsle: 0.00082 | valid_mae: 0.0976  | valid_rmse: 0.12311 | valid_mse: 0.01516 |  0:02:52s\n",
      "epoch 98 | loss: 0.0172  | train_rmsle: 0.00079 | train_mae: 0.09464 | train_rmse: 0.11827 | train_mse: 0.01399 | valid_rmsle: 0.00089 | valid_mae: 0.1015  | valid_rmse: 0.12577 | valid_mse: 0.01582 |  0:02:53s\n",
      "epoch 99 | loss: 0.01654 | train_rmsle: 0.00065 | train_mae: 0.08387 | train_rmse: 0.10848 | train_mse: 0.01177 | valid_rmsle: 0.00078 | valid_mae: 0.09193 | valid_rmse: 0.11924 | valid_mse: 0.01422 |  0:02:54s\n",
      "epoch 100| loss: 0.01863 | train_rmsle: 0.00074 | train_mae: 0.09285 | train_rmse: 0.11696 | train_mse: 0.01368 | valid_rmsle: 0.00086 | valid_mae: 0.10076 | valid_rmse: 0.12617 | valid_mse: 0.01592 |  0:02:56s\n",
      "epoch 101| loss: 0.01504 | train_rmsle: 0.00059 | train_mae: 0.08169 | train_rmse: 0.10406 | train_mse: 0.01083 | valid_rmsle: 0.00072 | valid_mae: 0.09068 | valid_rmse: 0.11474 | valid_mse: 0.01317 |  0:02:57s\n",
      "epoch 102| loss: 0.01509 | train_rmsle: 0.00054 | train_mae: 0.07583 | train_rmse: 0.09784 | train_mse: 0.00957 | valid_rmsle: 0.00067 | valid_mae: 0.08455 | valid_rmse: 0.10976 | valid_mse: 0.01205 |  0:02:59s\n",
      "epoch 103| loss: 0.015   | train_rmsle: 0.0005  | train_mae: 0.07339 | train_rmse: 0.09456 | train_mse: 0.00894 | valid_rmsle: 0.00064 | valid_mae: 0.08275 | valid_rmse: 0.10791 | valid_mse: 0.01164 |  0:03:01s\n",
      "epoch 104| loss: 0.01457 | train_rmsle: 0.0005  | train_mae: 0.07321 | train_rmse: 0.09451 | train_mse: 0.00893 | valid_rmsle: 0.00064 | valid_mae: 0.08291 | valid_rmse: 0.10719 | valid_mse: 0.01149 |  0:03:02s\n",
      "epoch 105| loss: 0.01775 | train_rmsle: 0.0008  | train_mae: 0.09519 | train_rmse: 0.11713 | train_mse: 0.01372 | valid_rmsle: 0.00094 | valid_mae: 0.10298 | valid_rmse: 0.127   | valid_mse: 0.01613 |  0:03:04s\n",
      "epoch 106| loss: 0.01728 | train_rmsle: 0.00115 | train_mae: 0.11726 | train_rmse: 0.1407  | train_mse: 0.0198  | valid_rmsle: 0.00128 | valid_mae: 0.12397 | valid_rmse: 0.14895 | valid_mse: 0.02219 |  0:03:06s\n",
      "epoch 107| loss: 0.01905 | train_rmsle: 0.00067 | train_mae: 0.08389 | train_rmse: 0.11118 | train_mse: 0.01236 | valid_rmsle: 0.00083 | valid_mae: 0.09414 | valid_rmse: 0.12325 | valid_mse: 0.01519 |  0:03:08s\n",
      "epoch 108| loss: 0.01843 | train_rmsle: 0.00061 | train_mae: 0.08189 | train_rmse: 0.10648 | train_mse: 0.01134 | valid_rmsle: 0.00076 | valid_mae: 0.0916  | valid_rmse: 0.11893 | valid_mse: 0.01415 |  0:03:10s\n",
      "epoch 109| loss: 0.01487 | train_rmsle: 0.00053 | train_mae: 0.07527 | train_rmse: 0.0979  | train_mse: 0.00958 | valid_rmsle: 0.00066 | valid_mae: 0.084   | valid_rmse: 0.1092  | valid_mse: 0.01192 |  0:03:11s\n",
      "epoch 110| loss: 0.01556 | train_rmsle: 0.00074 | train_mae: 0.09366 | train_rmse: 0.11686 | train_mse: 0.01366 | valid_rmsle: 0.00085 | valid_mae: 0.10038 | valid_rmse: 0.12537 | valid_mse: 0.01572 |  0:03:13s\n",
      "epoch 111| loss: 0.01407 | train_rmsle: 0.00056 | train_mae: 0.07802 | train_rmse: 0.10007 | train_mse: 0.01001 | valid_rmsle: 0.00067 | valid_mae: 0.08528 | valid_rmse: 0.10932 | valid_mse: 0.01195 |  0:03:15s\n",
      "epoch 112| loss: 0.01497 | train_rmsle: 0.00066 | train_mae: 0.08722 | train_rmse: 0.11106 | train_mse: 0.01234 | valid_rmsle: 0.00078 | valid_mae: 0.09469 | valid_rmse: 0.11991 | valid_mse: 0.01438 |  0:03:17s\n",
      "epoch 113| loss: 0.0148  | train_rmsle: 0.00046 | train_mae: 0.06993 | train_rmse: 0.09079 | train_mse: 0.00824 | valid_rmsle: 0.00058 | valid_mae: 0.07883 | valid_rmse: 0.10134 | valid_mse: 0.01027 |  0:03:18s\n",
      "epoch 114| loss: 0.01387 | train_rmsle: 0.00059 | train_mae: 0.08169 | train_rmse: 0.10309 | train_mse: 0.01063 | valid_rmsle: 0.00074 | valid_mae: 0.09098 | valid_rmse: 0.11458 | valid_mse: 0.01313 |  0:03:20s\n",
      "epoch 115| loss: 0.0159  | train_rmsle: 0.00054 | train_mae: 0.07481 | train_rmse: 0.09699 | train_mse: 0.00941 | valid_rmsle: 0.00068 | valid_mae: 0.08418 | valid_rmse: 0.10901 | valid_mse: 0.01188 |  0:03:22s\n",
      "epoch 116| loss: 0.01471 | train_rmsle: 0.00069 | train_mae: 0.08192 | train_rmse: 0.10442 | train_mse: 0.0109  | valid_rmsle: 0.00081 | valid_mae: 0.09021 | valid_rmse: 0.11459 | valid_mse: 0.01313 |  0:03:24s\n",
      "epoch 117| loss: 0.01701 | train_rmsle: 0.00164 | train_mae: 0.13058 | train_rmse: 0.15727 | train_mse: 0.02473 | valid_rmsle: 0.00179 | valid_mae: 0.13363 | valid_rmse: 0.16403 | valid_mse: 0.0269  |  0:03:26s\n",
      "epoch 118| loss: 0.01934 | train_rmsle: 0.00065 | train_mae: 0.08546 | train_rmse: 0.10779 | train_mse: 0.01162 | valid_rmsle: 0.0008  | valid_mae: 0.0935  | valid_rmse: 0.11783 | valid_mse: 0.01388 |  0:03:27s\n",
      "epoch 119| loss: 0.01878 | train_rmsle: 0.00078 | train_mae: 0.0931  | train_rmse: 0.11538 | train_mse: 0.01331 | valid_rmsle: 0.00094 | valid_mae: 0.10093 | valid_rmse: 0.12651 | valid_mse: 0.01601 |  0:03:29s\n",
      "epoch 120| loss: 0.01857 | train_rmsle: 0.00103 | train_mae: 0.11051 | train_rmse: 0.13278 | train_mse: 0.01763 | valid_rmsle: 0.0012  | valid_mae: 0.11757 | valid_rmse: 0.14363 | valid_mse: 0.02063 |  0:03:31s\n",
      "epoch 121| loss: 0.01481 | train_rmsle: 0.00058 | train_mae: 0.07602 | train_rmse: 0.09679 | train_mse: 0.00937 | valid_rmsle: 0.00073 | valid_mae: 0.0862  | valid_rmse: 0.11028 | valid_mse: 0.01216 |  0:03:33s\n",
      "epoch 122| loss: 0.01284 | train_rmsle: 0.00064 | train_mae: 0.08175 | train_rmse: 0.10283 | train_mse: 0.01057 | valid_rmsle: 0.0008  | valid_mae: 0.09186 | valid_rmse: 0.11649 | valid_mse: 0.01357 |  0:03:34s\n",
      "epoch 123| loss: 0.0142  | train_rmsle: 0.00065 | train_mae: 0.08507 | train_rmse: 0.10536 | train_mse: 0.0111  | valid_rmsle: 0.00082 | valid_mae: 0.09377 | valid_rmse: 0.11725 | valid_mse: 0.01375 |  0:03:36s\n",
      "epoch 124| loss: 0.01261 | train_rmsle: 0.00063 | train_mae: 0.08503 | train_rmse: 0.10661 | train_mse: 0.01137 | valid_rmsle: 0.00076 | valid_mae: 0.09362 | valid_rmse: 0.11721 | valid_mse: 0.01374 |  0:03:38s\n",
      "epoch 125| loss: 0.01183 | train_rmsle: 0.00049 | train_mae: 0.07541 | train_rmse: 0.09536 | train_mse: 0.00909 | valid_rmsle: 0.00064 | valid_mae: 0.08534 | valid_rmse: 0.10752 | valid_mse: 0.01156 |  0:03:40s\n",
      "epoch 126| loss: 0.01488 | train_rmsle: 0.00065 | train_mae: 0.08644 | train_rmse: 0.1074  | train_mse: 0.01153 | valid_rmsle: 0.00082 | valid_mae: 0.09598 | valid_rmse: 0.12035 | valid_mse: 0.01448 |  0:03:41s\n",
      "epoch 127| loss: 0.01977 | train_rmsle: 0.00167 | train_mae: 0.13119 | train_rmse: 0.16691 | train_mse: 0.02786 | valid_rmsle: 0.00183 | valid_mae: 0.13988 | valid_rmse: 0.17702 | valid_mse: 0.03134 |  0:03:43s\n",
      "epoch 128| loss: 0.02891 | train_rmsle: 0.00141 | train_mae: 0.11445 | train_rmse: 0.14737 | train_mse: 0.02172 | valid_rmsle: 0.00166 | valid_mae: 0.12552 | valid_rmse: 0.16179 | valid_mse: 0.02618 |  0:03:45s\n",
      "epoch 129| loss: 0.02291 | train_rmsle: 0.00091 | train_mae: 0.09534 | train_rmse: 0.12241 | train_mse: 0.01498 | valid_rmsle: 0.00113 | valid_mae: 0.10647 | valid_rmse: 0.13746 | valid_mse: 0.0189  |  0:03:47s\n",
      "epoch 130| loss: 0.01855 | train_rmsle: 0.00093 | train_mae: 0.09549 | train_rmse: 0.12278 | train_mse: 0.01507 | valid_rmsle: 0.00113 | valid_mae: 0.10542 | valid_rmse: 0.13613 | valid_mse: 0.01853 |  0:03:48s\n",
      "epoch 131| loss: 0.02099 | train_rmsle: 0.00074 | train_mae: 0.08914 | train_rmse: 0.11354 | train_mse: 0.01289 | valid_rmsle: 0.00096 | valid_mae: 0.10019 | valid_rmse: 0.12856 | valid_mse: 0.01653 |  0:03:50s\n",
      "epoch 132| loss: 0.01796 | train_rmsle: 0.00064 | train_mae: 0.08059 | train_rmse: 0.10342 | train_mse: 0.0107  | valid_rmsle: 0.00082 | valid_mae: 0.09089 | valid_rmse: 0.11745 | valid_mse: 0.01379 |  0:03:52s\n",
      "epoch 133| loss: 0.01448 | train_rmsle: 0.00069 | train_mae: 0.0861  | train_rmse: 0.11082 | train_mse: 0.01228 | valid_rmsle: 0.00091 | valid_mae: 0.09738 | valid_rmse: 0.12744 | valid_mse: 0.01624 |  0:03:54s\n",
      "\n",
      "Early stopping occurred at epoch 133 with best_epoch = 113 and best_valid_mse = 0.01027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011874775249514729 RMSE: 0.10897144235768713 R2: 0.9474349455418727 MAE: 0.08537998864179489\n",
      "=====================================\n",
      "[52/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 1.43363 | train_rmsle: 0.19232 | train_mae: 1.49096 | train_rmse: 1.56531 | train_mse: 2.4502  | valid_rmsle: 0.19321 | valid_mae: 1.49571 | valid_rmse: 1.5699  | valid_mse: 2.46458 |  0:00:01s\n",
      "epoch 1  | loss: 0.37577 | train_rmsle: 0.096   | train_mae: 1.09805 | train_rmse: 1.18557 | train_mse: 1.40557 | valid_rmsle: 0.09636 | valid_mae: 1.10059 | valid_rmse: 1.18916 | valid_mse: 1.4141  |  0:00:03s\n",
      "epoch 2  | loss: 0.30256 | train_rmsle: 0.04756 | train_mae: 0.7855  | train_rmse: 0.87867 | train_mse: 0.77206 | valid_rmsle: 0.04759 | valid_mae: 0.78567 | valid_rmse: 0.88121 | valid_mse: 0.77654 |  0:00:05s\n",
      "epoch 3  | loss: 0.2617  | train_rmsle: 0.03138 | train_mae: 0.63623 | train_rmse: 0.7282  | train_mse: 0.53027 | valid_rmsle: 0.03125 | valid_mae: 0.63566 | valid_rmse: 0.72978 | valid_mse: 0.53258 |  0:00:06s\n",
      "epoch 4  | loss: 0.31695 | train_rmsle: 0.04698 | train_mae: 0.77998 | train_rmse: 0.87372 | train_mse: 0.76339 | valid_rmsle: 0.04691 | valid_mae: 0.77921 | valid_rmse: 0.87549 | valid_mse: 0.76648 |  0:00:08s\n",
      "epoch 5  | loss: 0.25331 | train_rmsle: 0.01984 | train_mae: 0.48821 | train_rmse: 0.58092 | train_mse: 0.33747 | valid_rmsle: 0.0194  | valid_mae: 0.48576 | valid_rmse: 0.57832 | valid_mse: 0.33445 |  0:00:10s\n",
      "epoch 6  | loss: 0.23396 | train_rmsle: 0.01858 | train_mae: 0.46564 | train_rmse: 0.56141 | train_mse: 0.31518 | valid_rmsle: 0.01798 | valid_mae: 0.45918 | valid_rmse: 0.55651 | valid_mse: 0.3097  |  0:00:12s\n",
      "epoch 7  | loss: 0.22161 | train_rmsle: 0.01827 | train_mae: 0.46411 | train_rmse: 0.55668 | train_mse: 0.30989 | valid_rmsle: 0.01749 | valid_mae: 0.46067 | valid_rmse: 0.54919 | valid_mse: 0.30161 |  0:00:14s\n",
      "epoch 8  | loss: 0.22191 | train_rmsle: 0.01489 | train_mae: 0.40304 | train_rmse: 0.49719 | train_mse: 0.2472  | valid_rmsle: 0.01426 | valid_mae: 0.40162 | valid_rmse: 0.49166 | valid_mse: 0.24173 |  0:00:15s\n",
      "epoch 9  | loss: 0.22382 | train_rmsle: 0.01656 | train_mae: 0.43663 | train_rmse: 0.52935 | train_mse: 0.28021 | valid_rmsle: 0.01606 | valid_mae: 0.43382 | valid_rmse: 0.5259  | valid_mse: 0.27658 |  0:00:17s\n",
      "epoch 10 | loss: 0.21723 | train_rmsle: 0.01587 | train_mae: 0.42864 | train_rmse: 0.51773 | train_mse: 0.26804 | valid_rmsle: 0.01548 | valid_mae: 0.4278  | valid_rmse: 0.51623 | valid_mse: 0.26649 |  0:00:19s\n",
      "epoch 11 | loss: 0.21238 | train_rmsle: 0.01446 | train_mae: 0.3971  | train_rmse: 0.48853 | train_mse: 0.23866 | valid_rmsle: 0.01375 | valid_mae: 0.39312 | valid_rmse: 0.48101 | valid_mse: 0.23137 |  0:00:21s\n",
      "epoch 12 | loss: 0.21639 | train_rmsle: 0.0137  | train_mae: 0.37578 | train_rmse: 0.47058 | train_mse: 0.22145 | valid_rmsle: 0.01308 | valid_mae: 0.37644 | valid_rmse: 0.46495 | valid_mse: 0.21618 |  0:00:22s\n",
      "epoch 13 | loss: 0.21724 | train_rmsle: 0.01405 | train_mae: 0.38788 | train_rmse: 0.48057 | train_mse: 0.23095 | valid_rmsle: 0.01354 | valid_mae: 0.38858 | valid_rmse: 0.47701 | valid_mse: 0.22754 |  0:00:24s\n",
      "epoch 14 | loss: 0.21532 | train_rmsle: 0.01384 | train_mae: 0.38154 | train_rmse: 0.47523 | train_mse: 0.22584 | valid_rmsle: 0.01323 | valid_mae: 0.38077 | valid_rmse: 0.46996 | valid_mse: 0.22086 |  0:00:26s\n",
      "epoch 15 | loss: 0.21439 | train_rmsle: 0.01484 | train_mae: 0.40684 | train_rmse: 0.49772 | train_mse: 0.24773 | valid_rmsle: 0.01431 | valid_mae: 0.4048  | valid_rmse: 0.49382 | valid_mse: 0.24386 |  0:00:28s\n",
      "epoch 16 | loss: 0.2127  | train_rmsle: 0.0149  | train_mae: 0.40905 | train_rmse: 0.49902 | train_mse: 0.24902 | valid_rmsle: 0.01434 | valid_mae: 0.40524 | valid_rmse: 0.49448 | valid_mse: 0.24451 |  0:00:29s\n",
      "epoch 17 | loss: 0.21377 | train_rmsle: 0.01438 | train_mae: 0.39916 | train_rmse: 0.48961 | train_mse: 0.23972 | valid_rmsle: 0.01387 | valid_mae: 0.39903 | valid_rmse: 0.48603 | valid_mse: 0.23623 |  0:00:31s\n",
      "epoch 18 | loss: 0.20643 | train_rmsle: 0.01348 | train_mae: 0.37476 | train_rmse: 0.46813 | train_mse: 0.21914 | valid_rmsle: 0.01279 | valid_mae: 0.37531 | valid_rmse: 0.46136 | valid_mse: 0.21285 |  0:00:33s\n",
      "epoch 19 | loss: 0.2119  | train_rmsle: 0.0137  | train_mae: 0.38325 | train_rmse: 0.47482 | train_mse: 0.22546 | valid_rmsle: 0.01306 | valid_mae: 0.38199 | valid_rmse: 0.4688  | valid_mse: 0.21977 |  0:00:35s\n",
      "epoch 20 | loss: 0.20772 | train_rmsle: 0.01328 | train_mae: 0.366   | train_rmse: 0.46147 | train_mse: 0.21296 | valid_rmsle: 0.01264 | valid_mae: 0.36555 | valid_rmse: 0.45514 | valid_mse: 0.20715 |  0:00:36s\n",
      "epoch 21 | loss: 0.20618 | train_rmsle: 0.01316 | train_mae: 0.36525 | train_rmse: 0.45994 | train_mse: 0.21154 | valid_rmsle: 0.01253 | valid_mae: 0.36362 | valid_rmse: 0.45384 | valid_mse: 0.20597 |  0:00:38s\n",
      "epoch 22 | loss: 0.20195 | train_rmsle: 0.01379 | train_mae: 0.3861  | train_rmse: 0.47725 | train_mse: 0.22777 | valid_rmsle: 0.01325 | valid_mae: 0.38589 | valid_rmse: 0.47291 | valid_mse: 0.22364 |  0:00:40s\n",
      "epoch 23 | loss: 0.2068  | train_rmsle: 0.01321 | train_mae: 0.37218 | train_rmse: 0.46413 | train_mse: 0.21542 | valid_rmsle: 0.01269 | valid_mae: 0.3703  | valid_rmse: 0.4598  | valid_mse: 0.21141 |  0:00:42s\n",
      "epoch 24 | loss: 0.2058  | train_rmsle: 0.01304 | train_mae: 0.36384 | train_rmse: 0.45813 | train_mse: 0.20988 | valid_rmsle: 0.01255 | valid_mae: 0.36367 | valid_rmse: 0.45477 | valid_mse: 0.20681 |  0:00:44s\n",
      "epoch 25 | loss: 0.20631 | train_rmsle: 0.01348 | train_mae: 0.35618 | train_rmse: 0.4601  | train_mse: 0.2117  | valid_rmsle: 0.01292 | valid_mae: 0.35911 | valid_rmse: 0.45518 | valid_mse: 0.20719 |  0:00:45s\n",
      "epoch 26 | loss: 0.21141 | train_rmsle: 0.01321 | train_mae: 0.35551 | train_rmse: 0.45638 | train_mse: 0.20828 | valid_rmsle: 0.0127  | valid_mae: 0.35681 | valid_rmse: 0.45272 | valid_mse: 0.20496 |  0:00:47s\n",
      "epoch 27 | loss: 0.20227 | train_rmsle: 0.01289 | train_mae: 0.36507 | train_rmse: 0.45701 | train_mse: 0.20886 | valid_rmsle: 0.01255 | valid_mae: 0.36932 | valid_rmse: 0.45659 | valid_mse: 0.20848 |  0:00:49s\n",
      "epoch 28 | loss: 0.20005 | train_rmsle: 0.01288 | train_mae: 0.36249 | train_rmse: 0.45547 | train_mse: 0.20746 | valid_rmsle: 0.01255 | valid_mae: 0.36779 | valid_rmse: 0.45522 | valid_mse: 0.20723 |  0:00:51s\n",
      "epoch 29 | loss: 0.19977 | train_rmsle: 0.01287 | train_mae: 0.35195 | train_rmse: 0.45078 | train_mse: 0.2032  | valid_rmsle: 0.01254 | valid_mae: 0.3596  | valid_rmse: 0.45074 | valid_mse: 0.20317 |  0:00:52s\n",
      "epoch 30 | loss: 0.1971  | train_rmsle: 0.01262 | train_mae: 0.3599  | train_rmse: 0.45192 | train_mse: 0.20423 | valid_rmsle: 0.01231 | valid_mae: 0.36447 | valid_rmse: 0.45198 | valid_mse: 0.20428 |  0:00:54s\n",
      "epoch 31 | loss: 0.1977  | train_rmsle: 0.0132  | train_mae: 0.37555 | train_rmse: 0.46588 | train_mse: 0.21705 | valid_rmsle: 0.01289 | valid_mae: 0.38062 | valid_rmse: 0.46576 | valid_mse: 0.21693 |  0:00:56s\n",
      "epoch 32 | loss: 0.19348 | train_rmsle: 0.01269 | train_mae: 0.35949 | train_rmse: 0.45209 | train_mse: 0.20439 | valid_rmsle: 0.01242 | valid_mae: 0.36483 | valid_rmse: 0.45259 | valid_mse: 0.20484 |  0:00:58s\n",
      "epoch 33 | loss: 0.19298 | train_rmsle: 0.01278 | train_mae: 0.35561 | train_rmse: 0.45162 | train_mse: 0.20396 | valid_rmsle: 0.0125  | valid_mae: 0.36213 | valid_rmse: 0.45236 | valid_mse: 0.20463 |  0:00:59s\n",
      "epoch 34 | loss: 0.19811 | train_rmsle: 0.01249 | train_mae: 0.35122 | train_rmse: 0.44605 | train_mse: 0.19896 | valid_rmsle: 0.01222 | valid_mae: 0.35719 | valid_rmse: 0.44649 | valid_mse: 0.19935 |  0:01:01s\n",
      "epoch 35 | loss: 0.19466 | train_rmsle: 0.01316 | train_mae: 0.35303 | train_rmse: 0.45505 | train_mse: 0.20707 | valid_rmsle: 0.01283 | valid_mae: 0.35789 | valid_rmse: 0.45456 | valid_mse: 0.20663 |  0:01:03s\n",
      "epoch 36 | loss: 0.1997  | train_rmsle: 0.01273 | train_mae: 0.3488  | train_rmse: 0.44876 | train_mse: 0.20139 | valid_rmsle: 0.0124  | valid_mae: 0.35592 | valid_rmse: 0.44824 | valid_mse: 0.20092 |  0:01:05s\n",
      "epoch 37 | loss: 0.18962 | train_rmsle: 0.01289 | train_mae: 0.35114 | train_rmse: 0.45105 | train_mse: 0.20345 | valid_rmsle: 0.01243 | valid_mae: 0.35101 | valid_rmse: 0.44686 | valid_mse: 0.19969 |  0:01:06s\n",
      "epoch 38 | loss: 0.18832 | train_rmsle: 0.01181 | train_mae: 0.34685 | train_rmse: 0.43673 | train_mse: 0.19073 | valid_rmsle: 0.01161 | valid_mae: 0.34949 | valid_rmse: 0.43768 | valid_mse: 0.19157 |  0:01:08s\n",
      "epoch 39 | loss: 0.18671 | train_rmsle: 0.01239 | train_mae: 0.34439 | train_rmse: 0.44231 | train_mse: 0.19564 | valid_rmsle: 0.01238 | valid_mae: 0.35285 | valid_rmse: 0.44797 | valid_mse: 0.20068 |  0:01:10s\n",
      "epoch 40 | loss: 0.1896  | train_rmsle: 0.01161 | train_mae: 0.34551 | train_rmse: 0.43381 | train_mse: 0.18819 | valid_rmsle: 0.01136 | valid_mae: 0.35032 | valid_rmse: 0.43425 | valid_mse: 0.18857 |  0:01:12s\n",
      "epoch 41 | loss: 0.1815  | train_rmsle: 0.01111 | train_mae: 0.33274 | train_rmse: 0.42152 | train_mse: 0.17768 | valid_rmsle: 0.01103 | valid_mae: 0.34087 | valid_rmse: 0.42505 | valid_mse: 0.18067 |  0:01:13s\n",
      "epoch 42 | loss: 0.17057 | train_rmsle: 0.01164 | train_mae: 0.33295 | train_rmse: 0.42801 | train_mse: 0.18319 | valid_rmsle: 0.01145 | valid_mae: 0.33992 | valid_rmse: 0.42938 | valid_mse: 0.18436 |  0:01:15s\n",
      "epoch 43 | loss: 0.17472 | train_rmsle: 0.01053 | train_mae: 0.32244 | train_rmse: 0.40996 | train_mse: 0.16806 | valid_rmsle: 0.01046 | valid_mae: 0.33091 | valid_rmse: 0.4143  | valid_mse: 0.17165 |  0:01:17s\n",
      "epoch 44 | loss: 0.16293 | train_rmsle: 0.01001 | train_mae: 0.31333 | train_rmse: 0.39914 | train_mse: 0.15932 | valid_rmsle: 0.0099  | valid_mae: 0.32191 | valid_rmse: 0.40209 | valid_mse: 0.16168 |  0:01:19s\n",
      "epoch 45 | loss: 0.14862 | train_rmsle: 0.00946 | train_mae: 0.29673 | train_rmse: 0.38406 | train_mse: 0.1475  | valid_rmsle: 0.00925 | valid_mae: 0.30244 | valid_rmse: 0.38511 | valid_mse: 0.14831 |  0:01:20s\n",
      "epoch 46 | loss: 0.13648 | train_rmsle: 0.00828 | train_mae: 0.28353 | train_rmse: 0.36152 | train_mse: 0.1307  | valid_rmsle: 0.00798 | valid_mae: 0.28635 | valid_rmse: 0.36001 | valid_mse: 0.12961 |  0:01:22s\n",
      "epoch 47 | loss: 0.12312 | train_rmsle: 0.00808 | train_mae: 0.2756  | train_rmse: 0.35627 | train_mse: 0.12693 | valid_rmsle: 0.00803 | valid_mae: 0.28272 | valid_rmse: 0.36138 | valid_mse: 0.1306  |  0:01:24s\n",
      "epoch 48 | loss: 0.11854 | train_rmsle: 0.0073  | train_mae: 0.26026 | train_rmse: 0.33673 | train_mse: 0.11338 | valid_rmsle: 0.00729 | valid_mae: 0.26826 | valid_rmse: 0.34462 | valid_mse: 0.11876 |  0:01:26s\n",
      "epoch 49 | loss: 0.10824 | train_rmsle: 0.00669 | train_mae: 0.25307 | train_rmse: 0.32412 | train_mse: 0.10506 | valid_rmsle: 0.00664 | valid_mae: 0.26173 | valid_rmse: 0.32951 | valid_mse: 0.10857 |  0:01:28s\n",
      "epoch 50 | loss: 0.0993  | train_rmsle: 0.00646 | train_mae: 0.24338 | train_rmse: 0.3166  | train_mse: 0.10024 | valid_rmsle: 0.00649 | valid_mae: 0.25311 | valid_rmse: 0.32327 | valid_mse: 0.1045  |  0:01:29s\n",
      "epoch 51 | loss: 0.09637 | train_rmsle: 0.00579 | train_mae: 0.23607 | train_rmse: 0.30348 | train_mse: 0.0921  | valid_rmsle: 0.00576 | valid_mae: 0.24355 | valid_rmse: 0.30785 | valid_mse: 0.09477 |  0:01:31s\n",
      "epoch 52 | loss: 0.08304 | train_rmsle: 0.00622 | train_mae: 0.23551 | train_rmse: 0.30817 | train_mse: 0.09497 | valid_rmsle: 0.00609 | valid_mae: 0.24035 | valid_rmse: 0.31046 | valid_mse: 0.09639 |  0:01:33s\n",
      "epoch 53 | loss: 0.07278 | train_rmsle: 0.00655 | train_mae: 0.24636 | train_rmse: 0.31803 | train_mse: 0.10114 | valid_rmsle: 0.00675 | valid_mae: 0.25663 | valid_rmse: 0.32855 | valid_mse: 0.10794 |  0:01:35s\n",
      "epoch 54 | loss: 0.07144 | train_rmsle: 0.00379 | train_mae: 0.19243 | train_rmse: 0.24673 | train_mse: 0.06088 | valid_rmsle: 0.00424 | valid_mae: 0.20602 | valid_rmse: 0.26508 | valid_mse: 0.07027 |  0:01:37s\n",
      "epoch 55 | loss: 0.06034 | train_rmsle: 0.00337 | train_mae: 0.18384 | train_rmse: 0.23492 | train_mse: 0.05519 | valid_rmsle: 0.00391 | valid_mae: 0.19844 | valid_rmse: 0.25685 | valid_mse: 0.06597 |  0:01:38s\n",
      "epoch 56 | loss: 0.05514 | train_rmsle: 0.00301 | train_mae: 0.17678 | train_rmse: 0.22527 | train_mse: 0.05075 | valid_rmsle: 0.00345 | valid_mae: 0.19065 | valid_rmse: 0.24409 | valid_mse: 0.05958 |  0:01:40s\n",
      "epoch 57 | loss: 0.05429 | train_rmsle: 0.00283 | train_mae: 0.17085 | train_rmse: 0.21866 | train_mse: 0.04781 | valid_rmsle: 0.00314 | valid_mae: 0.18402 | valid_rmse: 0.23348 | valid_mse: 0.05452 |  0:01:42s\n",
      "epoch 58 | loss: 0.04918 | train_rmsle: 0.00275 | train_mae: 0.16714 | train_rmse: 0.2149  | train_mse: 0.04618 | valid_rmsle: 0.00316 | valid_mae: 0.18037 | valid_rmse: 0.23302 | valid_mse: 0.0543  |  0:01:44s\n",
      "epoch 59 | loss: 0.04542 | train_rmsle: 0.00229 | train_mae: 0.15549 | train_rmse: 0.19899 | train_mse: 0.0396  | valid_rmsle: 0.0026  | valid_mae: 0.16877 | valid_rmse: 0.21399 | valid_mse: 0.04579 |  0:01:45s\n",
      "epoch 60 | loss: 0.04135 | train_rmsle: 0.00207 | train_mae: 0.14676 | train_rmse: 0.18946 | train_mse: 0.0359  | valid_rmsle: 0.00241 | valid_mae: 0.1599  | valid_rmse: 0.20589 | valid_mse: 0.04239 |  0:01:47s\n",
      "epoch 61 | loss: 0.04073 | train_rmsle: 0.00203 | train_mae: 0.14524 | train_rmse: 0.18694 | train_mse: 0.03495 | valid_rmsle: 0.00235 | valid_mae: 0.15877 | valid_rmse: 0.20309 | valid_mse: 0.04125 |  0:01:49s\n",
      "epoch 62 | loss: 0.03673 | train_rmsle: 0.00201 | train_mae: 0.14473 | train_rmse: 0.18733 | train_mse: 0.03509 | valid_rmsle: 0.00239 | valid_mae: 0.1589  | valid_rmse: 0.20635 | valid_mse: 0.04258 |  0:01:51s\n",
      "epoch 63 | loss: 0.03551 | train_rmsle: 0.00168 | train_mae: 0.13153 | train_rmse: 0.1699  | train_mse: 0.02886 | valid_rmsle: 0.00201 | valid_mae: 0.14637 | valid_rmse: 0.18738 | valid_mse: 0.03511 |  0:01:52s\n",
      "epoch 64 | loss: 0.03214 | train_rmsle: 0.00222 | train_mae: 0.15613 | train_rmse: 0.19873 | train_mse: 0.03949 | valid_rmsle: 0.00266 | valid_mae: 0.17042 | valid_rmse: 0.21912 | valid_mse: 0.04801 |  0:01:54s\n",
      "epoch 65 | loss: 0.03776 | train_rmsle: 0.00168 | train_mae: 0.13058 | train_rmse: 0.16791 | train_mse: 0.02819 | valid_rmsle: 0.00202 | valid_mae: 0.14394 | valid_rmse: 0.18608 | valid_mse: 0.03462 |  0:01:56s\n",
      "epoch 66 | loss: 0.02977 | train_rmsle: 0.00132 | train_mae: 0.11695 | train_rmse: 0.15194 | train_mse: 0.02308 | valid_rmsle: 0.00161 | valid_mae: 0.13084 | valid_rmse: 0.16895 | valid_mse: 0.02854 |  0:01:58s\n",
      "epoch 67 | loss: 0.0304  | train_rmsle: 0.00151 | train_mae: 0.12684 | train_rmse: 0.16369 | train_mse: 0.0268  | valid_rmsle: 0.00183 | valid_mae: 0.13889 | valid_rmse: 0.18115 | valid_mse: 0.03282 |  0:02:00s\n",
      "epoch 68 | loss: 0.02913 | train_rmsle: 0.00143 | train_mae: 0.12157 | train_rmse: 0.15624 | train_mse: 0.02441 | valid_rmsle: 0.00173 | valid_mae: 0.13397 | valid_rmse: 0.17322 | valid_mse: 0.03001 |  0:02:01s\n",
      "epoch 69 | loss: 0.0305  | train_rmsle: 0.00176 | train_mae: 0.14389 | train_rmse: 0.18223 | train_mse: 0.03321 | valid_rmsle: 0.00195 | valid_mae: 0.15181 | valid_rmse: 0.19142 | valid_mse: 0.03664 |  0:02:03s\n",
      "epoch 70 | loss: 0.02788 | train_rmsle: 0.00133 | train_mae: 0.11714 | train_rmse: 0.15104 | train_mse: 0.02281 | valid_rmsle: 0.00154 | valid_mae: 0.12814 | valid_rmse: 0.16429 | valid_mse: 0.02699 |  0:02:05s\n",
      "epoch 71 | loss: 0.02871 | train_rmsle: 0.00125 | train_mae: 0.11802 | train_rmse: 0.15055 | train_mse: 0.02266 | valid_rmsle: 0.00145 | valid_mae: 0.12802 | valid_rmse: 0.16298 | valid_mse: 0.02656 |  0:02:07s\n",
      "epoch 72 | loss: 0.02655 | train_rmsle: 0.00129 | train_mae: 0.11986 | train_rmse: 0.15056 | train_mse: 0.02267 | valid_rmsle: 0.00152 | valid_mae: 0.1293  | valid_rmse: 0.16428 | valid_mse: 0.02699 |  0:02:08s\n",
      "epoch 73 | loss: 0.02753 | train_rmsle: 0.00109 | train_mae: 0.10749 | train_rmse: 0.13864 | train_mse: 0.01922 | valid_rmsle: 0.00135 | valid_mae: 0.12006 | valid_rmse: 0.15494 | valid_mse: 0.02401 |  0:02:10s\n",
      "epoch 74 | loss: 0.02905 | train_rmsle: 0.00103 | train_mae: 0.10611 | train_rmse: 0.13679 | train_mse: 0.01871 | valid_rmsle: 0.00125 | valid_mae: 0.1165  | valid_rmse: 0.15045 | valid_mse: 0.02264 |  0:02:12s\n",
      "epoch 75 | loss: 0.0216  | train_rmsle: 0.00097 | train_mae: 0.10265 | train_rmse: 0.13323 | train_mse: 0.01775 | valid_rmsle: 0.00124 | valid_mae: 0.11556 | valid_rmse: 0.14996 | valid_mse: 0.02249 |  0:02:14s\n",
      "epoch 76 | loss: 0.02424 | train_rmsle: 0.00091 | train_mae: 0.09958 | train_rmse: 0.12899 | train_mse: 0.01664 | valid_rmsle: 0.00116 | valid_mae: 0.11195 | valid_rmse: 0.14547 | valid_mse: 0.02116 |  0:02:15s\n",
      "epoch 77 | loss: 0.02245 | train_rmsle: 0.00107 | train_mae: 0.10722 | train_rmse: 0.13861 | train_mse: 0.01921 | valid_rmsle: 0.0013  | valid_mae: 0.11718 | valid_rmse: 0.15341 | valid_mse: 0.02354 |  0:02:17s\n",
      "epoch 78 | loss: 0.02532 | train_rmsle: 0.00211 | train_mae: 0.16123 | train_rmse: 0.19128 | train_mse: 0.03659 | valid_rmsle: 0.0022  | valid_mae: 0.16195 | valid_rmse: 0.1951  | valid_mse: 0.03807 |  0:02:19s\n",
      "epoch 79 | loss: 0.02429 | train_rmsle: 0.00105 | train_mae: 0.10591 | train_rmse: 0.13608 | train_mse: 0.01852 | valid_rmsle: 0.00124 | valid_mae: 0.11485 | valid_rmse: 0.14851 | valid_mse: 0.02206 |  0:02:21s\n",
      "epoch 80 | loss: 0.02146 | train_rmsle: 0.00162 | train_mae: 0.13948 | train_rmse: 0.1679  | train_mse: 0.02819 | valid_rmsle: 0.00178 | valid_mae: 0.14454 | valid_rmse: 0.17581 | valid_mse: 0.03091 |  0:02:22s\n",
      "epoch 81 | loss: 0.02227 | train_rmsle: 0.00103 | train_mae: 0.09819 | train_rmse: 0.13577 | train_mse: 0.01843 | valid_rmsle: 0.00138 | valid_mae: 0.1096  | valid_rmse: 0.15937 | valid_mse: 0.0254  |  0:02:24s\n",
      "epoch 82 | loss: 0.02081 | train_rmsle: 0.00143 | train_mae: 0.09957 | train_rmse: 0.17642 | train_mse: 0.03112 | valid_rmsle: 0.00184 | valid_mae: 0.11126 | valid_rmse: 0.21746 | valid_mse: 0.04729 |  0:02:26s\n",
      "epoch 83 | loss: 0.01943 | train_rmsle: 0.00176 | train_mae: 0.10377 | train_rmse: 0.18122 | train_mse: 0.03284 | valid_rmsle: 0.00251 | valid_mae: 0.12266 | valid_rmse: 0.21981 | valid_mse: 0.04832 |  0:02:27s\n",
      "epoch 84 | loss: 0.02053 | train_rmsle: 0.00171 | train_mae: 0.13747 | train_rmse: 0.16934 | train_mse: 0.02868 | valid_rmsle: 0.00186 | valid_mae: 0.14166 | valid_rmse: 0.17726 | valid_mse: 0.03142 |  0:02:29s\n",
      "epoch 85 | loss: 0.02493 | train_rmsle: 0.00092 | train_mae: 0.09927 | train_rmse: 0.12796 | train_mse: 0.01637 | valid_rmsle: 0.00113 | valid_mae: 0.10884 | valid_rmse: 0.14278 | valid_mse: 0.02039 |  0:02:31s\n",
      "epoch 86 | loss: 0.01791 | train_rmsle: 0.00068 | train_mae: 0.08557 | train_rmse: 0.11107 | train_mse: 0.01234 | valid_rmsle: 0.00086 | valid_mae: 0.09519 | valid_rmse: 0.12508 | valid_mse: 0.01565 |  0:02:33s\n",
      "epoch 87 | loss: 0.02189 | train_rmsle: 0.00125 | train_mae: 0.12505 | train_rmse: 0.15359 | train_mse: 0.02359 | valid_rmsle: 0.00139 | valid_mae: 0.13097 | valid_rmse: 0.16127 | valid_mse: 0.02601 |  0:02:34s\n",
      "epoch 88 | loss: 0.02087 | train_rmsle: 0.00063 | train_mae: 0.0828  | train_rmse: 0.10706 | train_mse: 0.01146 | valid_rmsle: 0.0008  | valid_mae: 0.09264 | valid_rmse: 0.12069 | valid_mse: 0.01457 |  0:02:36s\n",
      "epoch 89 | loss: 0.02943 | train_rmsle: 0.01011 | train_mae: 0.28057 | train_rmse: 0.36021 | train_mse: 0.12975 | valid_rmsle: 0.01037 | valid_mae: 0.28635 | valid_rmse: 0.36613 | valid_mse: 0.13405 |  0:02:38s\n",
      "epoch 90 | loss: 0.02764 | train_rmsle: 0.00306 | train_mae: 0.17812 | train_rmse: 0.21373 | train_mse: 0.04568 | valid_rmsle: 0.00312 | valid_mae: 0.18057 | valid_rmse: 0.21765 | valid_mse: 0.04737 |  0:02:40s\n",
      "epoch 91 | loss: 0.0257  | train_rmsle: 0.00096 | train_mae: 0.10208 | train_rmse: 0.12994 | train_mse: 0.01689 | valid_rmsle: 0.0011  | valid_mae: 0.1096  | valid_rmse: 0.14106 | valid_mse: 0.0199  |  0:02:42s\n",
      "epoch 92 | loss: 0.01937 | train_rmsle: 0.00122 | train_mae: 0.11736 | train_rmse: 0.14435 | train_mse: 0.02084 | valid_rmsle: 0.00131 | valid_mae: 0.12165 | valid_rmse: 0.15094 | valid_mse: 0.02278 |  0:02:43s\n",
      "epoch 93 | loss: 0.01951 | train_rmsle: 0.00083 | train_mae: 0.09508 | train_rmse: 0.123   | train_mse: 0.01513 | valid_rmsle: 0.00099 | valid_mae: 0.10447 | valid_rmse: 0.13504 | valid_mse: 0.01823 |  0:02:45s\n",
      "epoch 94 | loss: 0.0199  | train_rmsle: 0.00071 | train_mae: 0.08663 | train_rmse: 0.11174 | train_mse: 0.01249 | valid_rmsle: 0.00087 | valid_mae: 0.09558 | valid_rmse: 0.12383 | valid_mse: 0.01534 |  0:02:47s\n",
      "epoch 95 | loss: 0.01661 | train_rmsle: 0.00078 | train_mae: 0.09348 | train_rmse: 0.11819 | train_mse: 0.01397 | valid_rmsle: 0.00093 | valid_mae: 0.10201 | valid_rmse: 0.12939 | valid_mse: 0.01674 |  0:02:48s\n",
      "epoch 96 | loss: 0.01751 | train_rmsle: 0.00108 | train_mae: 0.10866 | train_rmse: 0.13334 | train_mse: 0.01778 | valid_rmsle: 0.00119 | valid_mae: 0.1152  | valid_rmse: 0.14124 | valid_mse: 0.01995 |  0:02:50s\n",
      "epoch 97 | loss: 0.01903 | train_rmsle: 0.00072 | train_mae: 0.09079 | train_rmse: 0.11546 | train_mse: 0.01333 | valid_rmsle: 0.00082 | valid_mae: 0.0976  | valid_rmse: 0.12311 | valid_mse: 0.01516 |  0:02:51s\n",
      "epoch 98 | loss: 0.0172  | train_rmsle: 0.00079 | train_mae: 0.09464 | train_rmse: 0.11827 | train_mse: 0.01399 | valid_rmsle: 0.00089 | valid_mae: 0.1015  | valid_rmse: 0.12577 | valid_mse: 0.01582 |  0:02:53s\n",
      "epoch 99 | loss: 0.01654 | train_rmsle: 0.00065 | train_mae: 0.08387 | train_rmse: 0.10848 | train_mse: 0.01177 | valid_rmsle: 0.00078 | valid_mae: 0.09193 | valid_rmse: 0.11924 | valid_mse: 0.01422 |  0:02:54s\n",
      "epoch 100| loss: 0.01863 | train_rmsle: 0.00074 | train_mae: 0.09285 | train_rmse: 0.11696 | train_mse: 0.01368 | valid_rmsle: 0.00086 | valid_mae: 0.10076 | valid_rmse: 0.12617 | valid_mse: 0.01592 |  0:02:56s\n",
      "epoch 101| loss: 0.01504 | train_rmsle: 0.00059 | train_mae: 0.08169 | train_rmse: 0.10406 | train_mse: 0.01083 | valid_rmsle: 0.00072 | valid_mae: 0.09068 | valid_rmse: 0.11474 | valid_mse: 0.01317 |  0:02:57s\n",
      "epoch 102| loss: 0.01509 | train_rmsle: 0.00054 | train_mae: 0.07583 | train_rmse: 0.09784 | train_mse: 0.00957 | valid_rmsle: 0.00067 | valid_mae: 0.08455 | valid_rmse: 0.10976 | valid_mse: 0.01205 |  0:02:59s\n",
      "epoch 103| loss: 0.015   | train_rmsle: 0.0005  | train_mae: 0.07339 | train_rmse: 0.09456 | train_mse: 0.00894 | valid_rmsle: 0.00064 | valid_mae: 0.08275 | valid_rmse: 0.10791 | valid_mse: 0.01164 |  0:03:01s\n",
      "epoch 104| loss: 0.01457 | train_rmsle: 0.0005  | train_mae: 0.07321 | train_rmse: 0.09451 | train_mse: 0.00893 | valid_rmsle: 0.00064 | valid_mae: 0.08291 | valid_rmse: 0.10719 | valid_mse: 0.01149 |  0:03:03s\n",
      "epoch 105| loss: 0.01775 | train_rmsle: 0.0008  | train_mae: 0.09519 | train_rmse: 0.11713 | train_mse: 0.01372 | valid_rmsle: 0.00094 | valid_mae: 0.10298 | valid_rmse: 0.127   | valid_mse: 0.01613 |  0:03:04s\n",
      "epoch 106| loss: 0.01728 | train_rmsle: 0.00115 | train_mae: 0.11726 | train_rmse: 0.1407  | train_mse: 0.0198  | valid_rmsle: 0.00128 | valid_mae: 0.12397 | valid_rmse: 0.14895 | valid_mse: 0.02219 |  0:03:06s\n",
      "epoch 107| loss: 0.01905 | train_rmsle: 0.00067 | train_mae: 0.08389 | train_rmse: 0.11118 | train_mse: 0.01236 | valid_rmsle: 0.00083 | valid_mae: 0.09414 | valid_rmse: 0.12325 | valid_mse: 0.01519 |  0:03:08s\n",
      "epoch 108| loss: 0.01843 | train_rmsle: 0.00061 | train_mae: 0.08189 | train_rmse: 0.10648 | train_mse: 0.01134 | valid_rmsle: 0.00076 | valid_mae: 0.0916  | valid_rmse: 0.11893 | valid_mse: 0.01415 |  0:03:10s\n",
      "epoch 109| loss: 0.01487 | train_rmsle: 0.00053 | train_mae: 0.07527 | train_rmse: 0.0979  | train_mse: 0.00958 | valid_rmsle: 0.00066 | valid_mae: 0.084   | valid_rmse: 0.1092  | valid_mse: 0.01192 |  0:03:12s\n",
      "epoch 110| loss: 0.01556 | train_rmsle: 0.00074 | train_mae: 0.09366 | train_rmse: 0.11686 | train_mse: 0.01366 | valid_rmsle: 0.00085 | valid_mae: 0.10038 | valid_rmse: 0.12537 | valid_mse: 0.01572 |  0:03:13s\n",
      "epoch 111| loss: 0.01407 | train_rmsle: 0.00056 | train_mae: 0.07802 | train_rmse: 0.10007 | train_mse: 0.01001 | valid_rmsle: 0.00067 | valid_mae: 0.08528 | valid_rmse: 0.10932 | valid_mse: 0.01195 |  0:03:15s\n",
      "epoch 112| loss: 0.01497 | train_rmsle: 0.00066 | train_mae: 0.08722 | train_rmse: 0.11106 | train_mse: 0.01234 | valid_rmsle: 0.00078 | valid_mae: 0.09469 | valid_rmse: 0.11991 | valid_mse: 0.01438 |  0:03:17s\n",
      "epoch 113| loss: 0.0148  | train_rmsle: 0.00046 | train_mae: 0.06993 | train_rmse: 0.09079 | train_mse: 0.00824 | valid_rmsle: 0.00058 | valid_mae: 0.07883 | valid_rmse: 0.10134 | valid_mse: 0.01027 |  0:03:19s\n",
      "epoch 114| loss: 0.01387 | train_rmsle: 0.00059 | train_mae: 0.08169 | train_rmse: 0.10309 | train_mse: 0.01063 | valid_rmsle: 0.00074 | valid_mae: 0.09098 | valid_rmse: 0.11458 | valid_mse: 0.01313 |  0:03:20s\n",
      "epoch 115| loss: 0.0159  | train_rmsle: 0.00054 | train_mae: 0.07481 | train_rmse: 0.09699 | train_mse: 0.00941 | valid_rmsle: 0.00068 | valid_mae: 0.08418 | valid_rmse: 0.10901 | valid_mse: 0.01188 |  0:03:22s\n",
      "epoch 116| loss: 0.01471 | train_rmsle: 0.00069 | train_mae: 0.08192 | train_rmse: 0.10442 | train_mse: 0.0109  | valid_rmsle: 0.00081 | valid_mae: 0.09021 | valid_rmse: 0.11459 | valid_mse: 0.01313 |  0:03:24s\n",
      "epoch 117| loss: 0.01701 | train_rmsle: 0.00164 | train_mae: 0.13058 | train_rmse: 0.15727 | train_mse: 0.02473 | valid_rmsle: 0.00179 | valid_mae: 0.13363 | valid_rmse: 0.16403 | valid_mse: 0.0269  |  0:03:26s\n",
      "epoch 118| loss: 0.01934 | train_rmsle: 0.00065 | train_mae: 0.08546 | train_rmse: 0.10779 | train_mse: 0.01162 | valid_rmsle: 0.0008  | valid_mae: 0.0935  | valid_rmse: 0.11783 | valid_mse: 0.01388 |  0:03:27s\n",
      "epoch 119| loss: 0.01878 | train_rmsle: 0.00078 | train_mae: 0.0931  | train_rmse: 0.11538 | train_mse: 0.01331 | valid_rmsle: 0.00094 | valid_mae: 0.10093 | valid_rmse: 0.12651 | valid_mse: 0.01601 |  0:03:29s\n",
      "epoch 120| loss: 0.01857 | train_rmsle: 0.00103 | train_mae: 0.11051 | train_rmse: 0.13278 | train_mse: 0.01763 | valid_rmsle: 0.0012  | valid_mae: 0.11757 | valid_rmse: 0.14363 | valid_mse: 0.02063 |  0:03:31s\n",
      "epoch 121| loss: 0.01481 | train_rmsle: 0.00058 | train_mae: 0.07602 | train_rmse: 0.09679 | train_mse: 0.00937 | valid_rmsle: 0.00073 | valid_mae: 0.0862  | valid_rmse: 0.11028 | valid_mse: 0.01216 |  0:03:33s\n",
      "epoch 122| loss: 0.01284 | train_rmsle: 0.00064 | train_mae: 0.08175 | train_rmse: 0.10283 | train_mse: 0.01057 | valid_rmsle: 0.0008  | valid_mae: 0.09186 | valid_rmse: 0.11649 | valid_mse: 0.01357 |  0:03:35s\n",
      "epoch 123| loss: 0.0142  | train_rmsle: 0.00065 | train_mae: 0.08507 | train_rmse: 0.10536 | train_mse: 0.0111  | valid_rmsle: 0.00082 | valid_mae: 0.09377 | valid_rmse: 0.11725 | valid_mse: 0.01375 |  0:03:36s\n",
      "epoch 124| loss: 0.01261 | train_rmsle: 0.00063 | train_mae: 0.08503 | train_rmse: 0.10661 | train_mse: 0.01137 | valid_rmsle: 0.00076 | valid_mae: 0.09362 | valid_rmse: 0.11721 | valid_mse: 0.01374 |  0:03:38s\n",
      "epoch 125| loss: 0.01183 | train_rmsle: 0.00049 | train_mae: 0.07541 | train_rmse: 0.09536 | train_mse: 0.00909 | valid_rmsle: 0.00064 | valid_mae: 0.08534 | valid_rmse: 0.10752 | valid_mse: 0.01156 |  0:03:40s\n",
      "epoch 126| loss: 0.01488 | train_rmsle: 0.00065 | train_mae: 0.08644 | train_rmse: 0.1074  | train_mse: 0.01153 | valid_rmsle: 0.00082 | valid_mae: 0.09598 | valid_rmse: 0.12035 | valid_mse: 0.01448 |  0:03:42s\n",
      "epoch 127| loss: 0.01977 | train_rmsle: 0.00167 | train_mae: 0.13119 | train_rmse: 0.16691 | train_mse: 0.02786 | valid_rmsle: 0.00183 | valid_mae: 0.13988 | valid_rmse: 0.17702 | valid_mse: 0.03134 |  0:03:43s\n",
      "epoch 128| loss: 0.02891 | train_rmsle: 0.00141 | train_mae: 0.11445 | train_rmse: 0.14737 | train_mse: 0.02172 | valid_rmsle: 0.00166 | valid_mae: 0.12552 | valid_rmse: 0.16179 | valid_mse: 0.02618 |  0:03:45s\n",
      "epoch 129| loss: 0.02291 | train_rmsle: 0.00091 | train_mae: 0.09534 | train_rmse: 0.12241 | train_mse: 0.01498 | valid_rmsle: 0.00113 | valid_mae: 0.10647 | valid_rmse: 0.13746 | valid_mse: 0.0189  |  0:03:47s\n",
      "epoch 130| loss: 0.01855 | train_rmsle: 0.00093 | train_mae: 0.09549 | train_rmse: 0.12278 | train_mse: 0.01507 | valid_rmsle: 0.00113 | valid_mae: 0.10542 | valid_rmse: 0.13613 | valid_mse: 0.01853 |  0:03:49s\n",
      "epoch 131| loss: 0.02099 | train_rmsle: 0.00074 | train_mae: 0.08914 | train_rmse: 0.11354 | train_mse: 0.01289 | valid_rmsle: 0.00096 | valid_mae: 0.10019 | valid_rmse: 0.12856 | valid_mse: 0.01653 |  0:03:50s\n",
      "epoch 132| loss: 0.01796 | train_rmsle: 0.00064 | train_mae: 0.08059 | train_rmse: 0.10342 | train_mse: 0.0107  | valid_rmsle: 0.00082 | valid_mae: 0.09089 | valid_rmse: 0.11745 | valid_mse: 0.01379 |  0:03:52s\n",
      "epoch 133| loss: 0.01448 | train_rmsle: 0.00069 | train_mae: 0.0861  | train_rmse: 0.11082 | train_mse: 0.01228 | valid_rmsle: 0.00091 | valid_mae: 0.09738 | valid_rmse: 0.12744 | valid_mse: 0.01624 |  0:03:54s\n",
      "\n",
      "Early stopping occurred at epoch 133 with best_epoch = 113 and best_valid_mse = 0.01027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011874775249514729 RMSE: 0.10897144235768713 R2: 0.9474349455418727 MAE: 0.08537998864179489\n",
      "=====================================\n",
      "[53/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25926 | train_rmsle: 0.1698  | train_mae: 1.41421 | train_rmse: 1.49138 | train_mse: 2.22421 | valid_rmsle: 0.17066 | valid_mae: 1.41871 | valid_rmse: 1.49611 | valid_mse: 2.23836 |  0:00:01s\n",
      "epoch 1  | loss: 0.615   | train_rmsle: 0.05757 | train_mae: 0.86219 | train_rmse: 0.95513 | train_mse: 0.91227 | valid_rmsle: 0.05771 | valid_mae: 0.8638  | valid_rmse: 0.95817 | valid_mse: 0.91809 |  0:00:03s\n",
      "epoch 2  | loss: 0.37229 | train_rmsle: 0.03581 | train_mae: 0.68107 | train_rmse: 0.77372 | train_mse: 0.59864 | valid_rmsle: 0.03569 | valid_mae: 0.67999 | valid_rmse: 0.77532 | valid_mse: 0.60113 |  0:00:05s\n",
      "epoch 3  | loss: 0.30489 | train_rmsle: 0.02785 | train_mae: 0.59748 | train_rmse: 0.68865 | train_mse: 0.47423 | valid_rmsle: 0.02761 | valid_mae: 0.59716 | valid_rmse: 0.68921 | valid_mse: 0.47501 |  0:00:07s\n",
      "epoch 4  | loss: 0.29307 | train_rmsle: 0.0205  | train_mae: 0.50386 | train_rmse: 0.59237 | train_mse: 0.35091 | valid_rmsle: 0.02013 | valid_mae: 0.50435 | valid_rmse: 0.59132 | valid_mse: 0.34966 |  0:00:08s\n",
      "epoch 5  | loss: 0.26257 | train_rmsle: 0.02385 | train_mae: 0.54909 | train_rmse: 0.63919 | train_mse: 0.40856 | valid_rmsle: 0.02357 | valid_mae: 0.54975 | valid_rmse: 0.63941 | valid_mse: 0.40885 |  0:00:10s\n",
      "epoch 6  | loss: 0.24891 | train_rmsle: 0.02206 | train_mae: 0.52586 | train_rmse: 0.61494 | train_mse: 0.37815 | valid_rmsle: 0.02176 | valid_mae: 0.52654 | valid_rmse: 0.6149  | valid_mse: 0.37811 |  0:00:11s\n",
      "epoch 7  | loss: 0.24476 | train_rmsle: 0.02703 | train_mae: 0.58782 | train_rmse: 0.67904 | train_mse: 0.46109 | valid_rmsle: 0.02673 | valid_mae: 0.58753 | valid_rmse: 0.67855 | valid_mse: 0.46044 |  0:00:13s\n",
      "epoch 8  | loss: 0.24147 | train_rmsle: 0.01508 | train_mae: 0.40643 | train_rmse: 0.49965 | train_mse: 0.24965 | valid_rmsle: 0.01446 | valid_mae: 0.40461 | valid_rmse: 0.49408 | valid_mse: 0.24412 |  0:00:14s\n",
      "epoch 9  | loss: 0.23536 | train_rmsle: 0.01609 | train_mae: 0.42818 | train_rmse: 0.52048 | train_mse: 0.2709  | valid_rmsle: 0.01529 | valid_mae: 0.42345 | valid_rmse: 0.51223 | valid_mse: 0.26238 |  0:00:16s\n",
      "epoch 10 | loss: 0.22506 | train_rmsle: 0.01714 | train_mae: 0.44849 | train_rmse: 0.53893 | train_mse: 0.29045 | valid_rmsle: 0.0165  | valid_mae: 0.44438 | valid_rmse: 0.53308 | valid_mse: 0.28418 |  0:00:17s\n",
      "epoch 11 | loss: 0.22297 | train_rmsle: 0.01534 | train_mae: 0.41576 | train_rmse: 0.50658 | train_mse: 0.25663 | valid_rmsle: 0.01486 | valid_mae: 0.41722 | valid_rmse: 0.50338 | valid_mse: 0.25339 |  0:00:19s\n",
      "epoch 12 | loss: 0.22253 | train_rmsle: 0.01514 | train_mae: 0.40918 | train_rmse: 0.50044 | train_mse: 0.25044 | valid_rmsle: 0.01468 | valid_mae: 0.412   | valid_rmse: 0.49844 | valid_mse: 0.24844 |  0:00:21s\n",
      "epoch 13 | loss: 0.2249  | train_rmsle: 0.01433 | train_mae: 0.39309 | train_rmse: 0.48604 | train_mse: 0.23624 | valid_rmsle: 0.01374 | valid_mae: 0.39163 | valid_rmse: 0.48067 | valid_mse: 0.23104 |  0:00:23s\n",
      "epoch 14 | loss: 0.22603 | train_rmsle: 0.01342 | train_mae: 0.37064 | train_rmse: 0.46508 | train_mse: 0.2163  | valid_rmsle: 0.0128  | valid_mae: 0.37186 | valid_rmse: 0.45936 | valid_mse: 0.21101 |  0:00:24s\n",
      "epoch 15 | loss: 0.22563 | train_rmsle: 0.01329 | train_mae: 0.37156 | train_rmse: 0.46404 | train_mse: 0.21533 | valid_rmsle: 0.01302 | valid_mae: 0.37826 | valid_rmse: 0.46514 | valid_mse: 0.21636 |  0:00:26s\n",
      "epoch 16 | loss: 0.21356 | train_rmsle: 0.01372 | train_mae: 0.38431 | train_rmse: 0.47429 | train_mse: 0.22495 | valid_rmsle: 0.01307 | valid_mae: 0.37979 | valid_rmse: 0.46773 | valid_mse: 0.21877 |  0:00:28s\n",
      "epoch 17 | loss: 0.21045 | train_rmsle: 0.01425 | train_mae: 0.39801 | train_rmse: 0.48698 | train_mse: 0.23715 | valid_rmsle: 0.01376 | valid_mae: 0.39496 | valid_rmse: 0.48308 | valid_mse: 0.23336 |  0:00:30s\n",
      "epoch 18 | loss: 0.20869 | train_rmsle: 0.0138  | train_mae: 0.38748 | train_rmse: 0.4776  | train_mse: 0.2281  | valid_rmsle: 0.01324 | valid_mae: 0.38484 | valid_rmse: 0.47261 | valid_mse: 0.22336 |  0:00:31s\n",
      "epoch 19 | loss: 0.20807 | train_rmsle: 0.01392 | train_mae: 0.39194 | train_rmse: 0.48129 | train_mse: 0.23164 | valid_rmsle: 0.01341 | valid_mae: 0.38997 | valid_rmse: 0.47731 | valid_mse: 0.22783 |  0:00:33s\n",
      "epoch 20 | loss: 0.20878 | train_rmsle: 0.01291 | train_mae: 0.36439 | train_rmse: 0.45648 | train_mse: 0.20837 | valid_rmsle: 0.01239 | valid_mae: 0.36431 | valid_rmse: 0.45285 | valid_mse: 0.20508 |  0:00:35s\n",
      "epoch 21 | loss: 0.20235 | train_rmsle: 0.01348 | train_mae: 0.38109 | train_rmse: 0.47085 | train_mse: 0.2217  | valid_rmsle: 0.01317 | valid_mae: 0.38427 | valid_rmse: 0.47059 | valid_mse: 0.22146 |  0:00:37s\n",
      "epoch 22 | loss: 0.19835 | train_rmsle: 0.01287 | train_mae: 0.35511 | train_rmse: 0.45136 | train_mse: 0.20373 | valid_rmsle: 0.01223 | valid_mae: 0.35406 | valid_rmse: 0.44476 | valid_mse: 0.19781 |  0:00:38s\n",
      "epoch 23 | loss: 0.19853 | train_rmsle: 0.0131  | train_mae: 0.37229 | train_rmse: 0.46263 | train_mse: 0.21403 | valid_rmsle: 0.01285 | valid_mae: 0.37412 | valid_rmse: 0.46365 | valid_mse: 0.21498 |  0:00:40s\n",
      "epoch 24 | loss: 0.19783 | train_rmsle: 0.01307 | train_mae: 0.37256 | train_rmse: 0.46259 | train_mse: 0.21399 | valid_rmsle: 0.01264 | valid_mae: 0.37163 | valid_rmse: 0.45998 | valid_mse: 0.21158 |  0:00:42s\n",
      "epoch 25 | loss: 0.2009  | train_rmsle: 0.01282 | train_mae: 0.36223 | train_rmse: 0.45478 | train_mse: 0.20682 | valid_rmsle: 0.01254 | valid_mae: 0.36454 | valid_rmse: 0.45486 | valid_mse: 0.2069  |  0:00:44s\n",
      "epoch 26 | loss: 0.20755 | train_rmsle: 0.01265 | train_mae: 0.36094 | train_rmse: 0.45207 | train_mse: 0.20437 | valid_rmsle: 0.01238 | valid_mae: 0.36277 | valid_rmse: 0.45165 | valid_mse: 0.20399 |  0:00:45s\n",
      "epoch 27 | loss: 0.19456 | train_rmsle: 0.01246 | train_mae: 0.35354 | train_rmse: 0.44604 | train_mse: 0.19895 | valid_rmsle: 0.01226 | valid_mae: 0.35663 | valid_rmse: 0.4478  | valid_mse: 0.20052 |  0:00:47s\n",
      "epoch 28 | loss: 0.19575 | train_rmsle: 0.01242 | train_mae: 0.34767 | train_rmse: 0.44344 | train_mse: 0.19664 | valid_rmsle: 0.01206 | valid_mae: 0.35091 | valid_rmse: 0.44177 | valid_mse: 0.19516 |  0:00:49s\n",
      "epoch 29 | loss: 0.1952  | train_rmsle: 0.0122  | train_mae: 0.35261 | train_rmse: 0.44318 | train_mse: 0.19641 | valid_rmsle: 0.01196 | valid_mae: 0.35441 | valid_rmse: 0.4434  | valid_mse: 0.1966  |  0:00:51s\n",
      "epoch 30 | loss: 0.19324 | train_rmsle: 0.01226 | train_mae: 0.35032 | train_rmse: 0.44336 | train_mse: 0.19657 | valid_rmsle: 0.01206 | valid_mae: 0.35543 | valid_rmse: 0.44484 | valid_mse: 0.19788 |  0:00:52s\n",
      "epoch 31 | loss: 0.19038 | train_rmsle: 0.01246 | train_mae: 0.35235 | train_rmse: 0.44621 | train_mse: 0.1991  | valid_rmsle: 0.01234 | valid_mae: 0.35828 | valid_rmse: 0.44918 | valid_mse: 0.20176 |  0:00:54s\n",
      "epoch 32 | loss: 0.18915 | train_rmsle: 0.01226 | train_mae: 0.35653 | train_rmse: 0.4462  | train_mse: 0.19909 | valid_rmsle: 0.0119  | valid_mae: 0.35814 | valid_rmse: 0.44407 | valid_mse: 0.1972  |  0:00:56s\n",
      "epoch 33 | loss: 0.18676 | train_rmsle: 0.01213 | train_mae: 0.34491 | train_rmse: 0.43877 | train_mse: 0.19252 | valid_rmsle: 0.01169 | valid_mae: 0.34575 | valid_rmse: 0.43499 | valid_mse: 0.18921 |  0:00:58s\n",
      "epoch 34 | loss: 0.18905 | train_rmsle: 0.01219 | train_mae: 0.34339 | train_rmse: 0.43834 | train_mse: 0.19214 | valid_rmsle: 0.01209 | valid_mae: 0.34925 | valid_rmse: 0.44132 | valid_mse: 0.19476 |  0:01:00s\n",
      "epoch 35 | loss: 0.18175 | train_rmsle: 0.01159 | train_mae: 0.34477 | train_rmse: 0.43247 | train_mse: 0.18703 | valid_rmsle: 0.01195 | valid_mae: 0.35658 | valid_rmse: 0.44397 | valid_mse: 0.19711 |  0:01:01s\n",
      "epoch 36 | loss: 0.17912 | train_rmsle: 0.01146 | train_mae: 0.33709 | train_rmse: 0.42751 | train_mse: 0.18277 | valid_rmsle: 0.01176 | valid_mae: 0.34519 | valid_rmse: 0.43704 | valid_mse: 0.191   |  0:01:03s\n",
      "epoch 37 | loss: 0.17436 | train_rmsle: 0.01125 | train_mae: 0.33148 | train_rmse: 0.42237 | train_mse: 0.1784  | valid_rmsle: 0.01149 | valid_mae: 0.34114 | valid_rmse: 0.43183 | valid_mse: 0.18648 |  0:01:05s\n",
      "epoch 38 | loss: 0.17245 | train_rmsle: 0.01078 | train_mae: 0.33457 | train_rmse: 0.41909 | train_mse: 0.17564 | valid_rmsle: 0.01146 | valid_mae: 0.34884 | valid_rmse: 0.43711 | valid_mse: 0.19107 |  0:01:07s\n",
      "epoch 39 | loss: 0.16983 | train_rmsle: 0.01047 | train_mae: 0.3225  | train_rmse: 0.40921 | train_mse: 0.16745 | valid_rmsle: 0.01084 | valid_mae: 0.3314  | valid_rmse: 0.42097 | valid_mse: 0.17722 |  0:01:08s\n",
      "epoch 40 | loss: 0.16414 | train_rmsle: 0.01011 | train_mae: 0.3231  | train_rmse: 0.40598 | train_mse: 0.16482 | valid_rmsle: 0.01073 | valid_mae: 0.33494 | valid_rmse: 0.42182 | valid_mse: 0.17793 |  0:01:10s\n",
      "epoch 41 | loss: 0.16479 | train_rmsle: 0.01006 | train_mae: 0.31347 | train_rmse: 0.40034 | train_mse: 0.16027 | valid_rmsle: 0.01064 | valid_mae: 0.32805 | valid_rmse: 0.41626 | valid_mse: 0.17328 |  0:01:12s\n",
      "epoch 42 | loss: 0.15336 | train_rmsle: 0.00963 | train_mae: 0.30742 | train_rmse: 0.39226 | train_mse: 0.15387 | valid_rmsle: 0.01031 | valid_mae: 0.32391 | valid_rmse: 0.41072 | valid_mse: 0.16869 |  0:01:14s\n",
      "epoch 43 | loss: 0.1531  | train_rmsle: 0.00903 | train_mae: 0.2981  | train_rmse: 0.38028 | train_mse: 0.14462 | valid_rmsle: 0.00945 | valid_mae: 0.30989 | valid_rmse: 0.39334 | valid_mse: 0.15471 |  0:01:16s\n",
      "epoch 44 | loss: 0.14447 | train_rmsle: 0.0084  | train_mae: 0.28982 | train_rmse: 0.36838 | train_mse: 0.1357  | valid_rmsle: 0.00904 | valid_mae: 0.30518 | valid_rmse: 0.38636 | valid_mse: 0.14927 |  0:01:17s\n",
      "epoch 45 | loss: 0.13605 | train_rmsle: 0.00846 | train_mae: 0.28325 | train_rmse: 0.36637 | train_mse: 0.13422 | valid_rmsle: 0.00889 | valid_mae: 0.29812 | valid_rmse: 0.38071 | valid_mse: 0.14494 |  0:01:19s\n",
      "epoch 46 | loss: 0.13137 | train_rmsle: 0.00773 | train_mae: 0.2768  | train_rmse: 0.35303 | train_mse: 0.12463 | valid_rmsle: 0.00839 | valid_mae: 0.29544 | valid_rmse: 0.37246 | valid_mse: 0.13873 |  0:01:21s\n",
      "epoch 47 | loss: 0.1246  | train_rmsle: 0.00798 | train_mae: 0.27797 | train_rmse: 0.35804 | train_mse: 0.12819 | valid_rmsle: 0.00867 | valid_mae: 0.3022  | valid_rmse: 0.37921 | valid_mse: 0.1438  |  0:01:23s\n",
      "epoch 48 | loss: 0.12603 | train_rmsle: 0.00764 | train_mae: 0.26652 | train_rmse: 0.34679 | train_mse: 0.12027 | valid_rmsle: 0.00831 | valid_mae: 0.28941 | valid_rmse: 0.36873 | valid_mse: 0.13596 |  0:01:25s\n",
      "epoch 49 | loss: 0.11497 | train_rmsle: 0.00741 | train_mae: 0.26257 | train_rmse: 0.34134 | train_mse: 0.11651 | valid_rmsle: 0.00793 | valid_mae: 0.28205 | valid_rmse: 0.36006 | valid_mse: 0.12964 |  0:01:26s\n",
      "epoch 50 | loss: 0.11169 | train_rmsle: 0.00692 | train_mae: 0.25576 | train_rmse: 0.33072 | train_mse: 0.10938 | valid_rmsle: 0.00747 | valid_mae: 0.27268 | valid_rmse: 0.35094 | valid_mse: 0.12316 |  0:01:28s\n",
      "epoch 51 | loss: 0.10747 | train_rmsle: 0.00654 | train_mae: 0.24941 | train_rmse: 0.32178 | train_mse: 0.10354 | valid_rmsle: 0.00709 | valid_mae: 0.26627 | valid_rmse: 0.3408  | valid_mse: 0.11614 |  0:01:30s\n",
      "epoch 52 | loss: 0.10206 | train_rmsle: 0.00611 | train_mae: 0.24187 | train_rmse: 0.31209 | train_mse: 0.0974  | valid_rmsle: 0.00683 | valid_mae: 0.26386 | valid_rmse: 0.33616 | valid_mse: 0.113   |  0:01:32s\n",
      "epoch 53 | loss: 0.09786 | train_rmsle: 0.00649 | train_mae: 0.24558 | train_rmse: 0.31982 | train_mse: 0.10229 | valid_rmsle: 0.00737 | valid_mae: 0.27037 | valid_rmse: 0.3485  | valid_mse: 0.12145 |  0:01:34s\n",
      "epoch 54 | loss: 0.09611 | train_rmsle: 0.0056  | train_mae: 0.22939 | train_rmse: 0.29742 | train_mse: 0.08846 | valid_rmsle: 0.00641 | valid_mae: 0.25537 | valid_rmse: 0.32488 | valid_mse: 0.10555 |  0:01:35s\n",
      "epoch 55 | loss: 0.08892 | train_rmsle: 0.00529 | train_mae: 0.22503 | train_rmse: 0.29018 | train_mse: 0.08421 | valid_rmsle: 0.00607 | valid_mae: 0.24813 | valid_rmse: 0.31716 | valid_mse: 0.10059 |  0:01:37s\n",
      "epoch 56 | loss: 0.08531 | train_rmsle: 0.0051  | train_mae: 0.21993 | train_rmse: 0.28474 | train_mse: 0.08108 | valid_rmsle: 0.00593 | valid_mae: 0.24717 | valid_rmse: 0.31386 | valid_mse: 0.09851 |  0:01:39s\n",
      "epoch 57 | loss: 0.08268 | train_rmsle: 0.00478 | train_mae: 0.21336 | train_rmse: 0.27602 | train_mse: 0.07619 | valid_rmsle: 0.00563 | valid_mae: 0.24069 | valid_rmse: 0.30523 | valid_mse: 0.09316 |  0:01:41s\n",
      "epoch 58 | loss: 0.07912 | train_rmsle: 0.0046  | train_mae: 0.21104 | train_rmse: 0.27228 | train_mse: 0.07414 | valid_rmsle: 0.0055  | valid_mae: 0.2403  | valid_rmse: 0.30321 | valid_mse: 0.09193 |  0:01:42s\n",
      "epoch 59 | loss: 0.07537 | train_rmsle: 0.00453 | train_mae: 0.20947 | train_rmse: 0.2701  | train_mse: 0.07295 | valid_rmsle: 0.00526 | valid_mae: 0.23384 | valid_rmse: 0.29462 | valid_mse: 0.0868  |  0:01:44s\n",
      "epoch 60 | loss: 0.07231 | train_rmsle: 0.00427 | train_mae: 0.19834 | train_rmse: 0.25902 | train_mse: 0.06709 | valid_rmsle: 0.00503 | valid_mae: 0.22489 | valid_rmse: 0.28774 | valid_mse: 0.08279 |  0:01:46s\n",
      "epoch 61 | loss: 0.06838 | train_rmsle: 0.0043  | train_mae: 0.20063 | train_rmse: 0.26032 | train_mse: 0.06777 | valid_rmsle: 0.00509 | valid_mae: 0.22616 | valid_rmse: 0.28999 | valid_mse: 0.0841  |  0:01:48s\n",
      "epoch 62 | loss: 0.06687 | train_rmsle: 0.00404 | train_mae: 0.19384 | train_rmse: 0.25203 | train_mse: 0.06352 | valid_rmsle: 0.00485 | valid_mae: 0.21997 | valid_rmse: 0.28172 | valid_mse: 0.07937 |  0:01:49s\n",
      "epoch 63 | loss: 0.06425 | train_rmsle: 0.00398 | train_mae: 0.19129 | train_rmse: 0.24911 | train_mse: 0.06206 | valid_rmsle: 0.00474 | valid_mae: 0.21689 | valid_rmse: 0.27783 | valid_mse: 0.07719 |  0:01:51s\n",
      "epoch 64 | loss: 0.06324 | train_rmsle: 0.00365 | train_mae: 0.18663 | train_rmse: 0.24167 | train_mse: 0.0584  | valid_rmsle: 0.00445 | valid_mae: 0.21095 | valid_rmse: 0.27101 | valid_mse: 0.07345 |  0:01:53s\n",
      "epoch 65 | loss: 0.05978 | train_rmsle: 0.00355 | train_mae: 0.18382 | train_rmse: 0.23769 | train_mse: 0.0565  | valid_rmsle: 0.0043  | valid_mae: 0.21032 | valid_rmse: 0.26632 | valid_mse: 0.07093 |  0:01:55s\n",
      "epoch 66 | loss: 0.06012 | train_rmsle: 0.00356 | train_mae: 0.18234 | train_rmse: 0.23705 | train_mse: 0.05619 | valid_rmsle: 0.00415 | valid_mae: 0.20354 | valid_rmse: 0.25975 | valid_mse: 0.06747 |  0:01:56s\n",
      "epoch 67 | loss: 0.06052 | train_rmsle: 0.00314 | train_mae: 0.17575 | train_rmse: 0.22701 | train_mse: 0.05153 | valid_rmsle: 0.00371 | valid_mae: 0.19579 | valid_rmse: 0.24976 | valid_mse: 0.06238 |  0:01:58s\n",
      "epoch 68 | loss: 0.05616 | train_rmsle: 0.0032  | train_mae: 0.17787 | train_rmse: 0.22875 | train_mse: 0.05233 | valid_rmsle: 0.00387 | valid_mae: 0.19988 | valid_rmse: 0.25504 | valid_mse: 0.06505 |  0:02:00s\n",
      "epoch 69 | loss: 0.05049 | train_rmsle: 0.00292 | train_mae: 0.16774 | train_rmse: 0.2174  | train_mse: 0.04726 | valid_rmsle: 0.00374 | valid_mae: 0.19434 | valid_rmse: 0.24892 | valid_mse: 0.06196 |  0:02:02s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.06196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06275836458603642 RMSE: 0.25051619625492566 R2: 0.7221929019412114 MAE: 0.1948923778658883\n",
      "=====================================\n",
      "[54/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25926 | train_rmsle: 0.1698  | train_mae: 1.41421 | train_rmse: 1.49138 | train_mse: 2.22421 | valid_rmsle: 0.17066 | valid_mae: 1.41871 | valid_rmse: 1.49611 | valid_mse: 2.23836 |  0:00:01s\n",
      "epoch 1  | loss: 0.615   | train_rmsle: 0.05757 | train_mae: 0.86219 | train_rmse: 0.95513 | train_mse: 0.91227 | valid_rmsle: 0.05771 | valid_mae: 0.8638  | valid_rmse: 0.95817 | valid_mse: 0.91809 |  0:00:03s\n",
      "epoch 2  | loss: 0.37229 | train_rmsle: 0.03581 | train_mae: 0.68107 | train_rmse: 0.77372 | train_mse: 0.59864 | valid_rmsle: 0.03569 | valid_mae: 0.67999 | valid_rmse: 0.77532 | valid_mse: 0.60113 |  0:00:05s\n",
      "epoch 3  | loss: 0.30489 | train_rmsle: 0.02785 | train_mae: 0.59748 | train_rmse: 0.68865 | train_mse: 0.47423 | valid_rmsle: 0.02761 | valid_mae: 0.59716 | valid_rmse: 0.68921 | valid_mse: 0.47501 |  0:00:06s\n",
      "epoch 4  | loss: 0.29307 | train_rmsle: 0.0205  | train_mae: 0.50386 | train_rmse: 0.59237 | train_mse: 0.35091 | valid_rmsle: 0.02013 | valid_mae: 0.50435 | valid_rmse: 0.59132 | valid_mse: 0.34966 |  0:00:08s\n",
      "epoch 5  | loss: 0.26257 | train_rmsle: 0.02385 | train_mae: 0.54909 | train_rmse: 0.63919 | train_mse: 0.40856 | valid_rmsle: 0.02357 | valid_mae: 0.54975 | valid_rmse: 0.63941 | valid_mse: 0.40885 |  0:00:10s\n",
      "epoch 6  | loss: 0.24891 | train_rmsle: 0.02206 | train_mae: 0.52586 | train_rmse: 0.61494 | train_mse: 0.37815 | valid_rmsle: 0.02176 | valid_mae: 0.52654 | valid_rmse: 0.6149  | valid_mse: 0.37811 |  0:00:12s\n",
      "epoch 7  | loss: 0.24476 | train_rmsle: 0.02703 | train_mae: 0.58782 | train_rmse: 0.67904 | train_mse: 0.46109 | valid_rmsle: 0.02673 | valid_mae: 0.58753 | valid_rmse: 0.67855 | valid_mse: 0.46044 |  0:00:14s\n",
      "epoch 8  | loss: 0.24147 | train_rmsle: 0.01508 | train_mae: 0.40643 | train_rmse: 0.49965 | train_mse: 0.24965 | valid_rmsle: 0.01446 | valid_mae: 0.40461 | valid_rmse: 0.49408 | valid_mse: 0.24412 |  0:00:15s\n",
      "epoch 9  | loss: 0.23536 | train_rmsle: 0.01609 | train_mae: 0.42818 | train_rmse: 0.52048 | train_mse: 0.2709  | valid_rmsle: 0.01529 | valid_mae: 0.42345 | valid_rmse: 0.51223 | valid_mse: 0.26238 |  0:00:17s\n",
      "epoch 10 | loss: 0.22506 | train_rmsle: 0.01714 | train_mae: 0.44849 | train_rmse: 0.53893 | train_mse: 0.29045 | valid_rmsle: 0.0165  | valid_mae: 0.44438 | valid_rmse: 0.53308 | valid_mse: 0.28418 |  0:00:18s\n",
      "epoch 11 | loss: 0.22297 | train_rmsle: 0.01534 | train_mae: 0.41576 | train_rmse: 0.50658 | train_mse: 0.25663 | valid_rmsle: 0.01486 | valid_mae: 0.41722 | valid_rmse: 0.50338 | valid_mse: 0.25339 |  0:00:20s\n",
      "epoch 12 | loss: 0.22253 | train_rmsle: 0.01514 | train_mae: 0.40918 | train_rmse: 0.50044 | train_mse: 0.25044 | valid_rmsle: 0.01468 | valid_mae: 0.412   | valid_rmse: 0.49844 | valid_mse: 0.24844 |  0:00:21s\n",
      "epoch 13 | loss: 0.2249  | train_rmsle: 0.01433 | train_mae: 0.39309 | train_rmse: 0.48604 | train_mse: 0.23624 | valid_rmsle: 0.01374 | valid_mae: 0.39163 | valid_rmse: 0.48067 | valid_mse: 0.23104 |  0:00:23s\n",
      "epoch 14 | loss: 0.22603 | train_rmsle: 0.01342 | train_mae: 0.37064 | train_rmse: 0.46508 | train_mse: 0.2163  | valid_rmsle: 0.0128  | valid_mae: 0.37186 | valid_rmse: 0.45936 | valid_mse: 0.21101 |  0:00:24s\n",
      "epoch 15 | loss: 0.22563 | train_rmsle: 0.01329 | train_mae: 0.37156 | train_rmse: 0.46404 | train_mse: 0.21533 | valid_rmsle: 0.01302 | valid_mae: 0.37826 | valid_rmse: 0.46514 | valid_mse: 0.21636 |  0:00:26s\n",
      "epoch 16 | loss: 0.21356 | train_rmsle: 0.01372 | train_mae: 0.38431 | train_rmse: 0.47429 | train_mse: 0.22495 | valid_rmsle: 0.01307 | valid_mae: 0.37979 | valid_rmse: 0.46773 | valid_mse: 0.21877 |  0:00:28s\n",
      "epoch 17 | loss: 0.21045 | train_rmsle: 0.01425 | train_mae: 0.39801 | train_rmse: 0.48698 | train_mse: 0.23715 | valid_rmsle: 0.01376 | valid_mae: 0.39496 | valid_rmse: 0.48308 | valid_mse: 0.23336 |  0:00:30s\n",
      "epoch 18 | loss: 0.20869 | train_rmsle: 0.0138  | train_mae: 0.38748 | train_rmse: 0.4776  | train_mse: 0.2281  | valid_rmsle: 0.01324 | valid_mae: 0.38484 | valid_rmse: 0.47261 | valid_mse: 0.22336 |  0:00:31s\n",
      "epoch 19 | loss: 0.20807 | train_rmsle: 0.01392 | train_mae: 0.39194 | train_rmse: 0.48129 | train_mse: 0.23164 | valid_rmsle: 0.01341 | valid_mae: 0.38997 | valid_rmse: 0.47731 | valid_mse: 0.22783 |  0:00:33s\n",
      "epoch 20 | loss: 0.20878 | train_rmsle: 0.01291 | train_mae: 0.36439 | train_rmse: 0.45648 | train_mse: 0.20837 | valid_rmsle: 0.01239 | valid_mae: 0.36431 | valid_rmse: 0.45285 | valid_mse: 0.20508 |  0:00:35s\n",
      "epoch 21 | loss: 0.20235 | train_rmsle: 0.01348 | train_mae: 0.38109 | train_rmse: 0.47085 | train_mse: 0.2217  | valid_rmsle: 0.01317 | valid_mae: 0.38427 | valid_rmse: 0.47059 | valid_mse: 0.22146 |  0:00:37s\n",
      "epoch 22 | loss: 0.19835 | train_rmsle: 0.01287 | train_mae: 0.35511 | train_rmse: 0.45136 | train_mse: 0.20373 | valid_rmsle: 0.01223 | valid_mae: 0.35406 | valid_rmse: 0.44476 | valid_mse: 0.19781 |  0:00:38s\n",
      "epoch 23 | loss: 0.19853 | train_rmsle: 0.0131  | train_mae: 0.37229 | train_rmse: 0.46263 | train_mse: 0.21403 | valid_rmsle: 0.01285 | valid_mae: 0.37412 | valid_rmse: 0.46365 | valid_mse: 0.21498 |  0:00:40s\n",
      "epoch 24 | loss: 0.19783 | train_rmsle: 0.01307 | train_mae: 0.37256 | train_rmse: 0.46259 | train_mse: 0.21399 | valid_rmsle: 0.01264 | valid_mae: 0.37163 | valid_rmse: 0.45998 | valid_mse: 0.21158 |  0:00:42s\n",
      "epoch 25 | loss: 0.2009  | train_rmsle: 0.01282 | train_mae: 0.36223 | train_rmse: 0.45478 | train_mse: 0.20682 | valid_rmsle: 0.01254 | valid_mae: 0.36454 | valid_rmse: 0.45486 | valid_mse: 0.2069  |  0:00:44s\n",
      "epoch 26 | loss: 0.20755 | train_rmsle: 0.01265 | train_mae: 0.36094 | train_rmse: 0.45207 | train_mse: 0.20437 | valid_rmsle: 0.01238 | valid_mae: 0.36277 | valid_rmse: 0.45165 | valid_mse: 0.20399 |  0:00:45s\n",
      "epoch 27 | loss: 0.19456 | train_rmsle: 0.01246 | train_mae: 0.35354 | train_rmse: 0.44604 | train_mse: 0.19895 | valid_rmsle: 0.01226 | valid_mae: 0.35663 | valid_rmse: 0.4478  | valid_mse: 0.20052 |  0:00:47s\n",
      "epoch 28 | loss: 0.19575 | train_rmsle: 0.01242 | train_mae: 0.34767 | train_rmse: 0.44344 | train_mse: 0.19664 | valid_rmsle: 0.01206 | valid_mae: 0.35091 | valid_rmse: 0.44177 | valid_mse: 0.19516 |  0:00:49s\n",
      "epoch 29 | loss: 0.1952  | train_rmsle: 0.0122  | train_mae: 0.35261 | train_rmse: 0.44318 | train_mse: 0.19641 | valid_rmsle: 0.01196 | valid_mae: 0.35441 | valid_rmse: 0.4434  | valid_mse: 0.1966  |  0:00:51s\n",
      "epoch 30 | loss: 0.19324 | train_rmsle: 0.01226 | train_mae: 0.35032 | train_rmse: 0.44336 | train_mse: 0.19657 | valid_rmsle: 0.01206 | valid_mae: 0.35543 | valid_rmse: 0.44484 | valid_mse: 0.19788 |  0:00:53s\n",
      "epoch 31 | loss: 0.19038 | train_rmsle: 0.01246 | train_mae: 0.35235 | train_rmse: 0.44621 | train_mse: 0.1991  | valid_rmsle: 0.01234 | valid_mae: 0.35828 | valid_rmse: 0.44918 | valid_mse: 0.20176 |  0:00:54s\n",
      "epoch 32 | loss: 0.18915 | train_rmsle: 0.01226 | train_mae: 0.35653 | train_rmse: 0.4462  | train_mse: 0.19909 | valid_rmsle: 0.0119  | valid_mae: 0.35814 | valid_rmse: 0.44407 | valid_mse: 0.1972  |  0:00:56s\n",
      "epoch 33 | loss: 0.18676 | train_rmsle: 0.01213 | train_mae: 0.34491 | train_rmse: 0.43877 | train_mse: 0.19252 | valid_rmsle: 0.01169 | valid_mae: 0.34575 | valid_rmse: 0.43499 | valid_mse: 0.18921 |  0:00:58s\n",
      "epoch 34 | loss: 0.18905 | train_rmsle: 0.01219 | train_mae: 0.34339 | train_rmse: 0.43834 | train_mse: 0.19214 | valid_rmsle: 0.01209 | valid_mae: 0.34925 | valid_rmse: 0.44132 | valid_mse: 0.19476 |  0:01:00s\n",
      "epoch 35 | loss: 0.18175 | train_rmsle: 0.01159 | train_mae: 0.34477 | train_rmse: 0.43247 | train_mse: 0.18703 | valid_rmsle: 0.01195 | valid_mae: 0.35658 | valid_rmse: 0.44397 | valid_mse: 0.19711 |  0:01:01s\n",
      "epoch 36 | loss: 0.17912 | train_rmsle: 0.01146 | train_mae: 0.33709 | train_rmse: 0.42751 | train_mse: 0.18277 | valid_rmsle: 0.01176 | valid_mae: 0.34519 | valid_rmse: 0.43704 | valid_mse: 0.191   |  0:01:03s\n",
      "epoch 37 | loss: 0.17436 | train_rmsle: 0.01125 | train_mae: 0.33148 | train_rmse: 0.42237 | train_mse: 0.1784  | valid_rmsle: 0.01149 | valid_mae: 0.34114 | valid_rmse: 0.43183 | valid_mse: 0.18648 |  0:01:05s\n",
      "epoch 38 | loss: 0.17245 | train_rmsle: 0.01078 | train_mae: 0.33457 | train_rmse: 0.41909 | train_mse: 0.17564 | valid_rmsle: 0.01146 | valid_mae: 0.34884 | valid_rmse: 0.43711 | valid_mse: 0.19107 |  0:01:07s\n",
      "epoch 39 | loss: 0.16983 | train_rmsle: 0.01047 | train_mae: 0.3225  | train_rmse: 0.40921 | train_mse: 0.16745 | valid_rmsle: 0.01084 | valid_mae: 0.3314  | valid_rmse: 0.42097 | valid_mse: 0.17722 |  0:01:08s\n",
      "epoch 40 | loss: 0.16414 | train_rmsle: 0.01011 | train_mae: 0.3231  | train_rmse: 0.40598 | train_mse: 0.16482 | valid_rmsle: 0.01073 | valid_mae: 0.33494 | valid_rmse: 0.42182 | valid_mse: 0.17793 |  0:01:10s\n",
      "epoch 41 | loss: 0.16479 | train_rmsle: 0.01006 | train_mae: 0.31347 | train_rmse: 0.40034 | train_mse: 0.16027 | valid_rmsle: 0.01064 | valid_mae: 0.32805 | valid_rmse: 0.41626 | valid_mse: 0.17328 |  0:01:12s\n",
      "epoch 42 | loss: 0.15336 | train_rmsle: 0.00963 | train_mae: 0.30742 | train_rmse: 0.39226 | train_mse: 0.15387 | valid_rmsle: 0.01031 | valid_mae: 0.32391 | valid_rmse: 0.41072 | valid_mse: 0.16869 |  0:01:14s\n",
      "epoch 43 | loss: 0.1531  | train_rmsle: 0.00903 | train_mae: 0.2981  | train_rmse: 0.38028 | train_mse: 0.14462 | valid_rmsle: 0.00945 | valid_mae: 0.30989 | valid_rmse: 0.39334 | valid_mse: 0.15471 |  0:01:16s\n",
      "epoch 44 | loss: 0.14447 | train_rmsle: 0.0084  | train_mae: 0.28982 | train_rmse: 0.36838 | train_mse: 0.1357  | valid_rmsle: 0.00904 | valid_mae: 0.30518 | valid_rmse: 0.38636 | valid_mse: 0.14927 |  0:01:17s\n",
      "epoch 45 | loss: 0.13605 | train_rmsle: 0.00846 | train_mae: 0.28325 | train_rmse: 0.36637 | train_mse: 0.13422 | valid_rmsle: 0.00889 | valid_mae: 0.29812 | valid_rmse: 0.38071 | valid_mse: 0.14494 |  0:01:19s\n",
      "epoch 46 | loss: 0.13137 | train_rmsle: 0.00773 | train_mae: 0.2768  | train_rmse: 0.35303 | train_mse: 0.12463 | valid_rmsle: 0.00839 | valid_mae: 0.29544 | valid_rmse: 0.37246 | valid_mse: 0.13873 |  0:01:21s\n",
      "epoch 47 | loss: 0.1246  | train_rmsle: 0.00798 | train_mae: 0.27797 | train_rmse: 0.35804 | train_mse: 0.12819 | valid_rmsle: 0.00867 | valid_mae: 0.3022  | valid_rmse: 0.37921 | valid_mse: 0.1438  |  0:01:23s\n",
      "epoch 48 | loss: 0.12603 | train_rmsle: 0.00764 | train_mae: 0.26652 | train_rmse: 0.34679 | train_mse: 0.12027 | valid_rmsle: 0.00831 | valid_mae: 0.28941 | valid_rmse: 0.36873 | valid_mse: 0.13596 |  0:01:25s\n",
      "epoch 49 | loss: 0.11497 | train_rmsle: 0.00741 | train_mae: 0.26257 | train_rmse: 0.34134 | train_mse: 0.11651 | valid_rmsle: 0.00793 | valid_mae: 0.28205 | valid_rmse: 0.36006 | valid_mse: 0.12964 |  0:01:26s\n",
      "epoch 50 | loss: 0.11169 | train_rmsle: 0.00692 | train_mae: 0.25576 | train_rmse: 0.33072 | train_mse: 0.10938 | valid_rmsle: 0.00747 | valid_mae: 0.27268 | valid_rmse: 0.35094 | valid_mse: 0.12316 |  0:01:28s\n",
      "epoch 51 | loss: 0.10747 | train_rmsle: 0.00654 | train_mae: 0.24941 | train_rmse: 0.32178 | train_mse: 0.10354 | valid_rmsle: 0.00709 | valid_mae: 0.26627 | valid_rmse: 0.3408  | valid_mse: 0.11614 |  0:01:30s\n",
      "epoch 52 | loss: 0.10206 | train_rmsle: 0.00611 | train_mae: 0.24187 | train_rmse: 0.31209 | train_mse: 0.0974  | valid_rmsle: 0.00683 | valid_mae: 0.26386 | valid_rmse: 0.33616 | valid_mse: 0.113   |  0:01:32s\n",
      "epoch 53 | loss: 0.09786 | train_rmsle: 0.00649 | train_mae: 0.24558 | train_rmse: 0.31982 | train_mse: 0.10229 | valid_rmsle: 0.00737 | valid_mae: 0.27037 | valid_rmse: 0.3485  | valid_mse: 0.12145 |  0:01:33s\n",
      "epoch 54 | loss: 0.09611 | train_rmsle: 0.0056  | train_mae: 0.22939 | train_rmse: 0.29742 | train_mse: 0.08846 | valid_rmsle: 0.00641 | valid_mae: 0.25537 | valid_rmse: 0.32488 | valid_mse: 0.10555 |  0:01:35s\n",
      "epoch 55 | loss: 0.08892 | train_rmsle: 0.00529 | train_mae: 0.22503 | train_rmse: 0.29018 | train_mse: 0.08421 | valid_rmsle: 0.00607 | valid_mae: 0.24813 | valid_rmse: 0.31716 | valid_mse: 0.10059 |  0:01:37s\n",
      "epoch 56 | loss: 0.08531 | train_rmsle: 0.0051  | train_mae: 0.21993 | train_rmse: 0.28474 | train_mse: 0.08108 | valid_rmsle: 0.00593 | valid_mae: 0.24717 | valid_rmse: 0.31386 | valid_mse: 0.09851 |  0:01:39s\n",
      "epoch 57 | loss: 0.08268 | train_rmsle: 0.00478 | train_mae: 0.21336 | train_rmse: 0.27602 | train_mse: 0.07619 | valid_rmsle: 0.00563 | valid_mae: 0.24069 | valid_rmse: 0.30523 | valid_mse: 0.09316 |  0:01:40s\n",
      "epoch 58 | loss: 0.07912 | train_rmsle: 0.0046  | train_mae: 0.21104 | train_rmse: 0.27228 | train_mse: 0.07414 | valid_rmsle: 0.0055  | valid_mae: 0.2403  | valid_rmse: 0.30321 | valid_mse: 0.09193 |  0:01:42s\n",
      "epoch 59 | loss: 0.07537 | train_rmsle: 0.00453 | train_mae: 0.20947 | train_rmse: 0.2701  | train_mse: 0.07295 | valid_rmsle: 0.00526 | valid_mae: 0.23384 | valid_rmse: 0.29462 | valid_mse: 0.0868  |  0:01:44s\n",
      "epoch 60 | loss: 0.07231 | train_rmsle: 0.00427 | train_mae: 0.19834 | train_rmse: 0.25902 | train_mse: 0.06709 | valid_rmsle: 0.00503 | valid_mae: 0.22489 | valid_rmse: 0.28774 | valid_mse: 0.08279 |  0:01:46s\n",
      "epoch 61 | loss: 0.06838 | train_rmsle: 0.0043  | train_mae: 0.20063 | train_rmse: 0.26032 | train_mse: 0.06777 | valid_rmsle: 0.00509 | valid_mae: 0.22616 | valid_rmse: 0.28999 | valid_mse: 0.0841  |  0:01:47s\n",
      "epoch 62 | loss: 0.06687 | train_rmsle: 0.00404 | train_mae: 0.19384 | train_rmse: 0.25203 | train_mse: 0.06352 | valid_rmsle: 0.00485 | valid_mae: 0.21997 | valid_rmse: 0.28172 | valid_mse: 0.07937 |  0:01:49s\n",
      "epoch 63 | loss: 0.06425 | train_rmsle: 0.00398 | train_mae: 0.19129 | train_rmse: 0.24911 | train_mse: 0.06206 | valid_rmsle: 0.00474 | valid_mae: 0.21689 | valid_rmse: 0.27783 | valid_mse: 0.07719 |  0:01:51s\n",
      "epoch 64 | loss: 0.06324 | train_rmsle: 0.00365 | train_mae: 0.18663 | train_rmse: 0.24167 | train_mse: 0.0584  | valid_rmsle: 0.00445 | valid_mae: 0.21095 | valid_rmse: 0.27101 | valid_mse: 0.07345 |  0:01:53s\n",
      "epoch 65 | loss: 0.05978 | train_rmsle: 0.00355 | train_mae: 0.18382 | train_rmse: 0.23769 | train_mse: 0.0565  | valid_rmsle: 0.0043  | valid_mae: 0.21032 | valid_rmse: 0.26632 | valid_mse: 0.07093 |  0:01:54s\n",
      "epoch 66 | loss: 0.06012 | train_rmsle: 0.00356 | train_mae: 0.18234 | train_rmse: 0.23705 | train_mse: 0.05619 | valid_rmsle: 0.00415 | valid_mae: 0.20354 | valid_rmse: 0.25975 | valid_mse: 0.06747 |  0:01:56s\n",
      "epoch 67 | loss: 0.06052 | train_rmsle: 0.00314 | train_mae: 0.17575 | train_rmse: 0.22701 | train_mse: 0.05153 | valid_rmsle: 0.00371 | valid_mae: 0.19579 | valid_rmse: 0.24976 | valid_mse: 0.06238 |  0:01:58s\n",
      "epoch 68 | loss: 0.05616 | train_rmsle: 0.0032  | train_mae: 0.17787 | train_rmse: 0.22875 | train_mse: 0.05233 | valid_rmsle: 0.00387 | valid_mae: 0.19988 | valid_rmse: 0.25504 | valid_mse: 0.06505 |  0:02:00s\n",
      "epoch 69 | loss: 0.05049 | train_rmsle: 0.00292 | train_mae: 0.16774 | train_rmse: 0.2174  | train_mse: 0.04726 | valid_rmsle: 0.00374 | valid_mae: 0.19434 | valid_rmse: 0.24892 | valid_mse: 0.06196 |  0:02:01s\n",
      "epoch 70 | loss: 0.04953 | train_rmsle: 0.00279 | train_mae: 0.16727 | train_rmse: 0.2156  | train_mse: 0.04648 | valid_rmsle: 0.00358 | valid_mae: 0.19084 | valid_rmse: 0.24644 | valid_mse: 0.06073 |  0:02:03s\n",
      "epoch 71 | loss: 0.04946 | train_rmsle: 0.00267 | train_mae: 0.16093 | train_rmse: 0.20883 | train_mse: 0.04361 | valid_rmsle: 0.00338 | valid_mae: 0.18347 | valid_rmse: 0.23832 | valid_mse: 0.0568  |  0:02:05s\n",
      "epoch 72 | loss: 0.04646 | train_rmsle: 0.00282 | train_mae: 0.16367 | train_rmse: 0.21208 | train_mse: 0.04498 | valid_rmsle: 0.00344 | valid_mae: 0.18267 | valid_rmse: 0.23811 | valid_mse: 0.05669 |  0:02:07s\n",
      "epoch 73 | loss: 0.04691 | train_rmsle: 0.00258 | train_mae: 0.16154 | train_rmse: 0.20727 | train_mse: 0.04296 | valid_rmsle: 0.00325 | valid_mae: 0.18232 | valid_rmse: 0.23463 | valid_mse: 0.05505 |  0:02:09s\n",
      "epoch 74 | loss: 0.04614 | train_rmsle: 0.00242 | train_mae: 0.15402 | train_rmse: 0.19926 | train_mse: 0.03971 | valid_rmsle: 0.0031  | valid_mae: 0.17705 | valid_rmse: 0.22789 | valid_mse: 0.05194 |  0:02:10s\n",
      "epoch 75 | loss: 0.04088 | train_rmsle: 0.00212 | train_mae: 0.14695 | train_rmse: 0.18956 | train_mse: 0.03593 | valid_rmsle: 0.00282 | valid_mae: 0.16852 | valid_rmse: 0.21865 | valid_mse: 0.04781 |  0:02:12s\n",
      "epoch 76 | loss: 0.04193 | train_rmsle: 0.00216 | train_mae: 0.14751 | train_rmse: 0.19047 | train_mse: 0.03628 | valid_rmsle: 0.00287 | valid_mae: 0.17136 | valid_rmse: 0.22111 | valid_mse: 0.04889 |  0:02:14s\n",
      "epoch 77 | loss: 0.04086 | train_rmsle: 0.00211 | train_mae: 0.14598 | train_rmse: 0.18802 | train_mse: 0.03535 | valid_rmsle: 0.00282 | valid_mae: 0.16869 | valid_rmse: 0.21854 | valid_mse: 0.04776 |  0:02:16s\n",
      "epoch 78 | loss: 0.03822 | train_rmsle: 0.002   | train_mae: 0.14323 | train_rmse: 0.18481 | train_mse: 0.03416 | valid_rmsle: 0.00273 | valid_mae: 0.16687 | valid_rmse: 0.21607 | valid_mse: 0.04669 |  0:02:17s\n",
      "epoch 79 | loss: 0.0376  | train_rmsle: 0.00181 | train_mae: 0.13279 | train_rmse: 0.17403 | train_mse: 0.03029 | valid_rmsle: 0.00266 | valid_mae: 0.15953 | valid_rmse: 0.21065 | valid_mse: 0.04437 |  0:02:19s\n",
      "epoch 80 | loss: 0.03402 | train_rmsle: 0.00187 | train_mae: 0.13624 | train_rmse: 0.17669 | train_mse: 0.03122 | valid_rmsle: 0.00271 | valid_mae: 0.16239 | valid_rmse: 0.21318 | valid_mse: 0.04544 |  0:02:21s\n",
      "epoch 81 | loss: 0.03433 | train_rmsle: 0.00173 | train_mae: 0.13313 | train_rmse: 0.17329 | train_mse: 0.03003 | valid_rmsle: 0.00247 | valid_mae: 0.15777 | valid_rmse: 0.20584 | valid_mse: 0.04237 |  0:02:23s\n",
      "epoch 82 | loss: 0.03259 | train_rmsle: 0.00163 | train_mae: 0.12662 | train_rmse: 0.16602 | train_mse: 0.02756 | valid_rmsle: 0.00244 | valid_mae: 0.15306 | valid_rmse: 0.20297 | valid_mse: 0.0412  |  0:02:24s\n",
      "epoch 83 | loss: 0.03261 | train_rmsle: 0.00155 | train_mae: 0.12596 | train_rmse: 0.16383 | train_mse: 0.02684 | valid_rmsle: 0.00225 | valid_mae: 0.14924 | valid_rmse: 0.19635 | valid_mse: 0.03855 |  0:02:26s\n",
      "epoch 84 | loss: 0.03359 | train_rmsle: 0.00161 | train_mae: 0.12998 | train_rmse: 0.16799 | train_mse: 0.02822 | valid_rmsle: 0.00225 | valid_mae: 0.1523  | valid_rmse: 0.19802 | valid_mse: 0.03921 |  0:02:28s\n",
      "epoch 85 | loss: 0.03117 | train_rmsle: 0.00143 | train_mae: 0.11844 | train_rmse: 0.15531 | train_mse: 0.02412 | valid_rmsle: 0.00209 | valid_mae: 0.1425  | valid_rmse: 0.18817 | valid_mse: 0.03541 |  0:02:30s\n",
      "epoch 86 | loss: 0.02981 | train_rmsle: 0.00155 | train_mae: 0.12437 | train_rmse: 0.16207 | train_mse: 0.02627 | valid_rmsle: 0.00216 | valid_mae: 0.14584 | valid_rmse: 0.19146 | valid_mse: 0.03666 |  0:02:32s\n",
      "epoch 87 | loss: 0.03131 | train_rmsle: 0.00163 | train_mae: 0.1306  | train_rmse: 0.16816 | train_mse: 0.02828 | valid_rmsle: 0.00216 | valid_mae: 0.1498  | valid_rmse: 0.1938  | valid_mse: 0.03756 |  0:02:33s\n",
      "epoch 88 | loss: 0.02943 | train_rmsle: 0.00161 | train_mae: 0.13199 | train_rmse: 0.16841 | train_mse: 0.02836 | valid_rmsle: 0.00204 | valid_mae: 0.14859 | valid_rmse: 0.18996 | valid_mse: 0.03608 |  0:02:35s\n",
      "epoch 89 | loss: 0.02857 | train_rmsle: 0.00131 | train_mae: 0.11313 | train_rmse: 0.14908 | train_mse: 0.02222 | valid_rmsle: 0.00182 | valid_mae: 0.13542 | valid_rmse: 0.17615 | valid_mse: 0.03103 |  0:02:37s\n",
      "epoch 90 | loss: 0.02802 | train_rmsle: 0.00121 | train_mae: 0.1113  | train_rmse: 0.14592 | train_mse: 0.02129 | valid_rmsle: 0.00164 | valid_mae: 0.13225 | valid_rmse: 0.17087 | valid_mse: 0.0292  |  0:02:39s\n",
      "epoch 91 | loss: 0.02662 | train_rmsle: 0.00118 | train_mae: 0.10913 | train_rmse: 0.14324 | train_mse: 0.02052 | valid_rmsle: 0.00164 | valid_mae: 0.13214 | valid_rmse: 0.17111 | valid_mse: 0.02928 |  0:02:40s\n",
      "epoch 92 | loss: 0.02506 | train_rmsle: 0.00164 | train_mae: 0.12757 | train_rmse: 0.16641 | train_mse: 0.02769 | valid_rmsle: 0.00197 | valid_mae: 0.14708 | valid_rmse: 0.18771 | valid_mse: 0.03524 |  0:02:42s\n",
      "epoch 93 | loss: 0.02858 | train_rmsle: 0.00145 | train_mae: 0.12181 | train_rmse: 0.15894 | train_mse: 0.02526 | valid_rmsle: 0.00194 | valid_mae: 0.14121 | valid_rmse: 0.18528 | valid_mse: 0.03433 |  0:02:44s\n",
      "epoch 94 | loss: 0.0278  | train_rmsle: 0.00127 | train_mae: 0.11324 | train_rmse: 0.14762 | train_mse: 0.02179 | valid_rmsle: 0.0017  | valid_mae: 0.13487 | valid_rmse: 0.17369 | valid_mse: 0.03017 |  0:02:45s\n",
      "epoch 95 | loss: 0.02489 | train_rmsle: 0.00114 | train_mae: 0.10631 | train_rmse: 0.13988 | train_mse: 0.01957 | valid_rmsle: 0.0015  | valid_mae: 0.12659 | valid_rmse: 0.16401 | valid_mse: 0.0269  |  0:02:47s\n",
      "epoch 96 | loss: 0.02456 | train_rmsle: 0.0011  | train_mae: 0.10613 | train_rmse: 0.13918 | train_mse: 0.01937 | valid_rmsle: 0.00155 | valid_mae: 0.12895 | valid_rmse: 0.16648 | valid_mse: 0.02772 |  0:02:49s\n",
      "epoch 97 | loss: 0.02389 | train_rmsle: 0.00102 | train_mae: 0.10137 | train_rmse: 0.13392 | train_mse: 0.01793 | valid_rmsle: 0.00142 | valid_mae: 0.12304 | valid_rmse: 0.1601  | valid_mse: 0.02563 |  0:02:51s\n",
      "epoch 98 | loss: 0.02342 | train_rmsle: 0.00099 | train_mae: 0.09939 | train_rmse: 0.13124 | train_mse: 0.01722 | valid_rmsle: 0.00139 | valid_mae: 0.12203 | valid_rmse: 0.15754 | valid_mse: 0.02482 |  0:02:53s\n",
      "epoch 99 | loss: 0.02393 | train_rmsle: 0.00098 | train_mae: 0.09848 | train_rmse: 0.12981 | train_mse: 0.01685 | valid_rmsle: 0.0014  | valid_mae: 0.11932 | valid_rmse: 0.15706 | valid_mse: 0.02467 |  0:02:54s\n",
      "epoch 100| loss: 0.02329 | train_rmsle: 0.00107 | train_mae: 0.10177 | train_rmse: 0.13416 | train_mse: 0.018   | valid_rmsle: 0.00142 | valid_mae: 0.12233 | valid_rmse: 0.15895 | valid_mse: 0.02526 |  0:02:56s\n",
      "epoch 101| loss: 0.02139 | train_rmsle: 0.00097 | train_mae: 0.10231 | train_rmse: 0.13321 | train_mse: 0.01774 | valid_rmsle: 0.00137 | valid_mae: 0.12319 | valid_rmse: 0.15904 | valid_mse: 0.02529 |  0:02:58s\n",
      "epoch 102| loss: 0.02199 | train_rmsle: 0.00109 | train_mae: 0.10826 | train_rmse: 0.13894 | train_mse: 0.01931 | valid_rmsle: 0.00146 | valid_mae: 0.12796 | valid_rmse: 0.16291 | valid_mse: 0.02654 |  0:03:00s\n",
      "epoch 103| loss: 0.02415 | train_rmsle: 0.00103 | train_mae: 0.10493 | train_rmse: 0.13472 | train_mse: 0.01815 | valid_rmsle: 0.00139 | valid_mae: 0.12475 | valid_rmse: 0.15848 | valid_mse: 0.02512 |  0:03:01s\n",
      "epoch 104| loss: 0.02127 | train_rmsle: 0.00084 | train_mae: 0.09148 | train_rmse: 0.12125 | train_mse: 0.0147  | valid_rmsle: 0.00119 | valid_mae: 0.11118 | valid_rmse: 0.14722 | valid_mse: 0.02168 |  0:03:03s\n",
      "epoch 105| loss: 0.02021 | train_rmsle: 0.00078 | train_mae: 0.08872 | train_rmse: 0.11796 | train_mse: 0.01391 | valid_rmsle: 0.00118 | valid_mae: 0.11032 | valid_rmse: 0.14585 | valid_mse: 0.02127 |  0:03:05s\n",
      "epoch 106| loss: 0.01995 | train_rmsle: 0.00114 | train_mae: 0.11146 | train_rmse: 0.14227 | train_mse: 0.02024 | valid_rmsle: 0.00154 | valid_mae: 0.13016 | valid_rmse: 0.16718 | valid_mse: 0.02795 |  0:03:07s\n",
      "epoch 107| loss: 0.02006 | train_rmsle: 0.00077 | train_mae: 0.08688 | train_rmse: 0.11752 | train_mse: 0.01381 | valid_rmsle: 0.00122 | valid_mae: 0.11004 | valid_rmse: 0.14837 | valid_mse: 0.02201 |  0:03:08s\n",
      "epoch 108| loss: 0.01798 | train_rmsle: 0.00078 | train_mae: 0.08819 | train_rmse: 0.11636 | train_mse: 0.01354 | valid_rmsle: 0.0012  | valid_mae: 0.1107  | valid_rmse: 0.14518 | valid_mse: 0.02108 |  0:03:10s\n",
      "epoch 109| loss: 0.01782 | train_rmsle: 0.00075 | train_mae: 0.08775 | train_rmse: 0.11501 | train_mse: 0.01323 | valid_rmsle: 0.00116 | valid_mae: 0.10892 | valid_rmse: 0.14332 | valid_mse: 0.02054 |  0:03:12s\n",
      "epoch 110| loss: 0.02032 | train_rmsle: 0.00072 | train_mae: 0.08631 | train_rmse: 0.11408 | train_mse: 0.01301 | valid_rmsle: 0.00112 | valid_mae: 0.10682 | valid_rmse: 0.14276 | valid_mse: 0.02038 |  0:03:14s\n",
      "epoch 111| loss: 0.0184  | train_rmsle: 0.00069 | train_mae: 0.0844  | train_rmse: 0.112   | train_mse: 0.01254 | valid_rmsle: 0.00106 | valid_mae: 0.10436 | valid_rmse: 0.13957 | valid_mse: 0.01948 |  0:03:15s\n",
      "epoch 112| loss: 0.01841 | train_rmsle: 0.00098 | train_mae: 0.1013  | train_rmse: 0.13273 | train_mse: 0.01762 | valid_rmsle: 0.00138 | valid_mae: 0.12124 | valid_rmse: 0.15761 | valid_mse: 0.02484 |  0:03:17s\n",
      "epoch 113| loss: 0.01874 | train_rmsle: 0.00079 | train_mae: 0.08749 | train_rmse: 0.1163  | train_mse: 0.01353 | valid_rmsle: 0.0011  | valid_mae: 0.107   | valid_rmse: 0.13987 | valid_mse: 0.01956 |  0:03:18s\n",
      "epoch 114| loss: 0.01811 | train_rmsle: 0.00073 | train_mae: 0.08604 | train_rmse: 0.11339 | train_mse: 0.01286 | valid_rmsle: 0.00109 | valid_mae: 0.10682 | valid_rmse: 0.14097 | valid_mse: 0.01987 |  0:03:20s\n",
      "epoch 115| loss: 0.01818 | train_rmsle: 0.00065 | train_mae: 0.08165 | train_rmse: 0.10736 | train_mse: 0.01153 | valid_rmsle: 0.00106 | valid_mae: 0.103   | valid_rmse: 0.13731 | valid_mse: 0.01885 |  0:03:21s\n",
      "epoch 116| loss: 0.01843 | train_rmsle: 0.00078 | train_mae: 0.08845 | train_rmse: 0.11587 | train_mse: 0.01343 | valid_rmsle: 0.00119 | valid_mae: 0.10984 | valid_rmse: 0.14407 | valid_mse: 0.02075 |  0:03:23s\n",
      "epoch 117| loss: 0.01753 | train_rmsle: 0.00095 | train_mae: 0.10379 | train_rmse: 0.12914 | train_mse: 0.01668 | valid_rmsle: 0.00132 | valid_mae: 0.12207 | valid_rmse: 0.15431 | valid_mse: 0.02381 |  0:03:24s\n",
      "epoch 118| loss: 0.01932 | train_rmsle: 0.00102 | train_mae: 0.111   | train_rmse: 0.13828 | train_mse: 0.01912 | valid_rmsle: 0.00144 | valid_mae: 0.12779 | valid_rmse: 0.16413 | valid_mse: 0.02694 |  0:03:26s\n",
      "epoch 119| loss: 0.01785 | train_rmsle: 0.00057 | train_mae: 0.07753 | train_rmse: 0.10173 | train_mse: 0.01035 | valid_rmsle: 0.00095 | valid_mae: 0.09872 | valid_rmse: 0.13159 | valid_mse: 0.01732 |  0:03:28s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 119 and best_valid_mse = 0.01732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.018691792940581004 RMSE: 0.13671793203739224 R2: 0.917258634947063 MAE: 0.10235999678271215\n",
      "=====================================\n",
      "[55/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25926 | train_rmsle: 0.1698  | train_mae: 1.41421 | train_rmse: 1.49138 | train_mse: 2.22421 | valid_rmsle: 0.17066 | valid_mae: 1.41871 | valid_rmse: 1.49611 | valid_mse: 2.23836 |  0:00:01s\n",
      "epoch 1  | loss: 0.615   | train_rmsle: 0.05757 | train_mae: 0.86219 | train_rmse: 0.95513 | train_mse: 0.91227 | valid_rmsle: 0.05771 | valid_mae: 0.8638  | valid_rmse: 0.95817 | valid_mse: 0.91809 |  0:00:03s\n",
      "epoch 2  | loss: 0.37229 | train_rmsle: 0.03581 | train_mae: 0.68107 | train_rmse: 0.77372 | train_mse: 0.59864 | valid_rmsle: 0.03569 | valid_mae: 0.67999 | valid_rmse: 0.77532 | valid_mse: 0.60113 |  0:00:05s\n",
      "epoch 3  | loss: 0.30489 | train_rmsle: 0.02785 | train_mae: 0.59748 | train_rmse: 0.68865 | train_mse: 0.47423 | valid_rmsle: 0.02761 | valid_mae: 0.59716 | valid_rmse: 0.68921 | valid_mse: 0.47501 |  0:00:07s\n",
      "epoch 4  | loss: 0.29307 | train_rmsle: 0.0205  | train_mae: 0.50386 | train_rmse: 0.59237 | train_mse: 0.35091 | valid_rmsle: 0.02013 | valid_mae: 0.50435 | valid_rmse: 0.59132 | valid_mse: 0.34966 |  0:00:08s\n",
      "epoch 5  | loss: 0.26257 | train_rmsle: 0.02385 | train_mae: 0.54909 | train_rmse: 0.63919 | train_mse: 0.40856 | valid_rmsle: 0.02357 | valid_mae: 0.54975 | valid_rmse: 0.63941 | valid_mse: 0.40885 |  0:00:10s\n",
      "epoch 6  | loss: 0.24891 | train_rmsle: 0.02206 | train_mae: 0.52586 | train_rmse: 0.61494 | train_mse: 0.37815 | valid_rmsle: 0.02176 | valid_mae: 0.52654 | valid_rmse: 0.6149  | valid_mse: 0.37811 |  0:00:12s\n",
      "epoch 7  | loss: 0.24476 | train_rmsle: 0.02703 | train_mae: 0.58782 | train_rmse: 0.67904 | train_mse: 0.46109 | valid_rmsle: 0.02673 | valid_mae: 0.58753 | valid_rmse: 0.67855 | valid_mse: 0.46044 |  0:00:14s\n",
      "epoch 8  | loss: 0.24147 | train_rmsle: 0.01508 | train_mae: 0.40643 | train_rmse: 0.49965 | train_mse: 0.24965 | valid_rmsle: 0.01446 | valid_mae: 0.40461 | valid_rmse: 0.49408 | valid_mse: 0.24412 |  0:00:15s\n",
      "epoch 9  | loss: 0.23536 | train_rmsle: 0.01609 | train_mae: 0.42818 | train_rmse: 0.52048 | train_mse: 0.2709  | valid_rmsle: 0.01529 | valid_mae: 0.42345 | valid_rmse: 0.51223 | valid_mse: 0.26238 |  0:00:17s\n",
      "epoch 10 | loss: 0.22506 | train_rmsle: 0.01714 | train_mae: 0.44849 | train_rmse: 0.53893 | train_mse: 0.29045 | valid_rmsle: 0.0165  | valid_mae: 0.44438 | valid_rmse: 0.53308 | valid_mse: 0.28418 |  0:00:19s\n",
      "epoch 11 | loss: 0.22297 | train_rmsle: 0.01534 | train_mae: 0.41576 | train_rmse: 0.50658 | train_mse: 0.25663 | valid_rmsle: 0.01486 | valid_mae: 0.41722 | valid_rmse: 0.50338 | valid_mse: 0.25339 |  0:00:21s\n",
      "epoch 12 | loss: 0.22253 | train_rmsle: 0.01514 | train_mae: 0.40918 | train_rmse: 0.50044 | train_mse: 0.25044 | valid_rmsle: 0.01468 | valid_mae: 0.412   | valid_rmse: 0.49844 | valid_mse: 0.24844 |  0:00:22s\n",
      "epoch 13 | loss: 0.2249  | train_rmsle: 0.01433 | train_mae: 0.39309 | train_rmse: 0.48604 | train_mse: 0.23624 | valid_rmsle: 0.01374 | valid_mae: 0.39163 | valid_rmse: 0.48067 | valid_mse: 0.23104 |  0:00:24s\n",
      "epoch 14 | loss: 0.22603 | train_rmsle: 0.01342 | train_mae: 0.37064 | train_rmse: 0.46508 | train_mse: 0.2163  | valid_rmsle: 0.0128  | valid_mae: 0.37186 | valid_rmse: 0.45936 | valid_mse: 0.21101 |  0:00:26s\n",
      "epoch 15 | loss: 0.22563 | train_rmsle: 0.01329 | train_mae: 0.37156 | train_rmse: 0.46404 | train_mse: 0.21533 | valid_rmsle: 0.01302 | valid_mae: 0.37826 | valid_rmse: 0.46514 | valid_mse: 0.21636 |  0:00:28s\n",
      "epoch 16 | loss: 0.21356 | train_rmsle: 0.01372 | train_mae: 0.38431 | train_rmse: 0.47429 | train_mse: 0.22495 | valid_rmsle: 0.01307 | valid_mae: 0.37979 | valid_rmse: 0.46773 | valid_mse: 0.21877 |  0:00:30s\n",
      "epoch 17 | loss: 0.21045 | train_rmsle: 0.01425 | train_mae: 0.39801 | train_rmse: 0.48698 | train_mse: 0.23715 | valid_rmsle: 0.01376 | valid_mae: 0.39496 | valid_rmse: 0.48308 | valid_mse: 0.23336 |  0:00:31s\n",
      "epoch 18 | loss: 0.20869 | train_rmsle: 0.0138  | train_mae: 0.38748 | train_rmse: 0.4776  | train_mse: 0.2281  | valid_rmsle: 0.01324 | valid_mae: 0.38484 | valid_rmse: 0.47261 | valid_mse: 0.22336 |  0:00:33s\n",
      "epoch 19 | loss: 0.20807 | train_rmsle: 0.01392 | train_mae: 0.39194 | train_rmse: 0.48129 | train_mse: 0.23164 | valid_rmsle: 0.01341 | valid_mae: 0.38997 | valid_rmse: 0.47731 | valid_mse: 0.22783 |  0:00:35s\n",
      "epoch 20 | loss: 0.20878 | train_rmsle: 0.01291 | train_mae: 0.36439 | train_rmse: 0.45648 | train_mse: 0.20837 | valid_rmsle: 0.01239 | valid_mae: 0.36431 | valid_rmse: 0.45285 | valid_mse: 0.20508 |  0:00:37s\n",
      "epoch 21 | loss: 0.20235 | train_rmsle: 0.01348 | train_mae: 0.38109 | train_rmse: 0.47085 | train_mse: 0.2217  | valid_rmsle: 0.01317 | valid_mae: 0.38427 | valid_rmse: 0.47059 | valid_mse: 0.22146 |  0:00:38s\n",
      "epoch 22 | loss: 0.19835 | train_rmsle: 0.01287 | train_mae: 0.35511 | train_rmse: 0.45136 | train_mse: 0.20373 | valid_rmsle: 0.01223 | valid_mae: 0.35406 | valid_rmse: 0.44476 | valid_mse: 0.19781 |  0:00:40s\n",
      "epoch 23 | loss: 0.19853 | train_rmsle: 0.0131  | train_mae: 0.37229 | train_rmse: 0.46263 | train_mse: 0.21403 | valid_rmsle: 0.01285 | valid_mae: 0.37412 | valid_rmse: 0.46365 | valid_mse: 0.21498 |  0:00:42s\n",
      "epoch 24 | loss: 0.19783 | train_rmsle: 0.01307 | train_mae: 0.37256 | train_rmse: 0.46259 | train_mse: 0.21399 | valid_rmsle: 0.01264 | valid_mae: 0.37163 | valid_rmse: 0.45998 | valid_mse: 0.21158 |  0:00:44s\n",
      "epoch 25 | loss: 0.2009  | train_rmsle: 0.01282 | train_mae: 0.36223 | train_rmse: 0.45478 | train_mse: 0.20682 | valid_rmsle: 0.01254 | valid_mae: 0.36454 | valid_rmse: 0.45486 | valid_mse: 0.2069  |  0:00:45s\n",
      "epoch 26 | loss: 0.20755 | train_rmsle: 0.01265 | train_mae: 0.36094 | train_rmse: 0.45207 | train_mse: 0.20437 | valid_rmsle: 0.01238 | valid_mae: 0.36277 | valid_rmse: 0.45165 | valid_mse: 0.20399 |  0:00:47s\n",
      "epoch 27 | loss: 0.19456 | train_rmsle: 0.01246 | train_mae: 0.35354 | train_rmse: 0.44604 | train_mse: 0.19895 | valid_rmsle: 0.01226 | valid_mae: 0.35663 | valid_rmse: 0.4478  | valid_mse: 0.20052 |  0:00:49s\n",
      "epoch 28 | loss: 0.19575 | train_rmsle: 0.01242 | train_mae: 0.34767 | train_rmse: 0.44344 | train_mse: 0.19664 | valid_rmsle: 0.01206 | valid_mae: 0.35091 | valid_rmse: 0.44177 | valid_mse: 0.19516 |  0:00:51s\n",
      "epoch 29 | loss: 0.1952  | train_rmsle: 0.0122  | train_mae: 0.35261 | train_rmse: 0.44318 | train_mse: 0.19641 | valid_rmsle: 0.01196 | valid_mae: 0.35441 | valid_rmse: 0.4434  | valid_mse: 0.1966  |  0:00:52s\n",
      "epoch 30 | loss: 0.19324 | train_rmsle: 0.01226 | train_mae: 0.35032 | train_rmse: 0.44336 | train_mse: 0.19657 | valid_rmsle: 0.01206 | valid_mae: 0.35543 | valid_rmse: 0.44484 | valid_mse: 0.19788 |  0:00:54s\n",
      "epoch 31 | loss: 0.19038 | train_rmsle: 0.01246 | train_mae: 0.35235 | train_rmse: 0.44621 | train_mse: 0.1991  | valid_rmsle: 0.01234 | valid_mae: 0.35828 | valid_rmse: 0.44918 | valid_mse: 0.20176 |  0:00:56s\n",
      "epoch 32 | loss: 0.18915 | train_rmsle: 0.01226 | train_mae: 0.35653 | train_rmse: 0.4462  | train_mse: 0.19909 | valid_rmsle: 0.0119  | valid_mae: 0.35814 | valid_rmse: 0.44407 | valid_mse: 0.1972  |  0:00:58s\n",
      "epoch 33 | loss: 0.18676 | train_rmsle: 0.01213 | train_mae: 0.34491 | train_rmse: 0.43877 | train_mse: 0.19252 | valid_rmsle: 0.01169 | valid_mae: 0.34575 | valid_rmse: 0.43499 | valid_mse: 0.18921 |  0:00:59s\n",
      "epoch 34 | loss: 0.18905 | train_rmsle: 0.01219 | train_mae: 0.34339 | train_rmse: 0.43834 | train_mse: 0.19214 | valid_rmsle: 0.01209 | valid_mae: 0.34925 | valid_rmse: 0.44132 | valid_mse: 0.19476 |  0:01:01s\n",
      "epoch 35 | loss: 0.18175 | train_rmsle: 0.01159 | train_mae: 0.34477 | train_rmse: 0.43247 | train_mse: 0.18703 | valid_rmsle: 0.01195 | valid_mae: 0.35658 | valid_rmse: 0.44397 | valid_mse: 0.19711 |  0:01:03s\n",
      "epoch 36 | loss: 0.17912 | train_rmsle: 0.01146 | train_mae: 0.33709 | train_rmse: 0.42751 | train_mse: 0.18277 | valid_rmsle: 0.01176 | valid_mae: 0.34519 | valid_rmse: 0.43704 | valid_mse: 0.191   |  0:01:05s\n",
      "epoch 37 | loss: 0.17436 | train_rmsle: 0.01125 | train_mae: 0.33148 | train_rmse: 0.42237 | train_mse: 0.1784  | valid_rmsle: 0.01149 | valid_mae: 0.34114 | valid_rmse: 0.43183 | valid_mse: 0.18648 |  0:01:06s\n",
      "epoch 38 | loss: 0.17245 | train_rmsle: 0.01078 | train_mae: 0.33457 | train_rmse: 0.41909 | train_mse: 0.17564 | valid_rmsle: 0.01146 | valid_mae: 0.34884 | valid_rmse: 0.43711 | valid_mse: 0.19107 |  0:01:08s\n",
      "epoch 39 | loss: 0.16983 | train_rmsle: 0.01047 | train_mae: 0.3225  | train_rmse: 0.40921 | train_mse: 0.16745 | valid_rmsle: 0.01084 | valid_mae: 0.3314  | valid_rmse: 0.42097 | valid_mse: 0.17722 |  0:01:10s\n",
      "epoch 40 | loss: 0.16414 | train_rmsle: 0.01011 | train_mae: 0.3231  | train_rmse: 0.40598 | train_mse: 0.16482 | valid_rmsle: 0.01073 | valid_mae: 0.33494 | valid_rmse: 0.42182 | valid_mse: 0.17793 |  0:01:11s\n",
      "epoch 41 | loss: 0.16479 | train_rmsle: 0.01006 | train_mae: 0.31347 | train_rmse: 0.40034 | train_mse: 0.16027 | valid_rmsle: 0.01064 | valid_mae: 0.32805 | valid_rmse: 0.41626 | valid_mse: 0.17328 |  0:01:13s\n",
      "epoch 42 | loss: 0.15336 | train_rmsle: 0.00963 | train_mae: 0.30742 | train_rmse: 0.39226 | train_mse: 0.15387 | valid_rmsle: 0.01031 | valid_mae: 0.32391 | valid_rmse: 0.41072 | valid_mse: 0.16869 |  0:01:15s\n",
      "epoch 43 | loss: 0.1531  | train_rmsle: 0.00903 | train_mae: 0.2981  | train_rmse: 0.38028 | train_mse: 0.14462 | valid_rmsle: 0.00945 | valid_mae: 0.30989 | valid_rmse: 0.39334 | valid_mse: 0.15471 |  0:01:17s\n",
      "epoch 44 | loss: 0.14447 | train_rmsle: 0.0084  | train_mae: 0.28982 | train_rmse: 0.36838 | train_mse: 0.1357  | valid_rmsle: 0.00904 | valid_mae: 0.30518 | valid_rmse: 0.38636 | valid_mse: 0.14927 |  0:01:18s\n",
      "epoch 45 | loss: 0.13605 | train_rmsle: 0.00846 | train_mae: 0.28325 | train_rmse: 0.36637 | train_mse: 0.13422 | valid_rmsle: 0.00889 | valid_mae: 0.29812 | valid_rmse: 0.38071 | valid_mse: 0.14494 |  0:01:20s\n",
      "epoch 46 | loss: 0.13137 | train_rmsle: 0.00773 | train_mae: 0.2768  | train_rmse: 0.35303 | train_mse: 0.12463 | valid_rmsle: 0.00839 | valid_mae: 0.29544 | valid_rmse: 0.37246 | valid_mse: 0.13873 |  0:01:22s\n",
      "epoch 47 | loss: 0.1246  | train_rmsle: 0.00798 | train_mae: 0.27797 | train_rmse: 0.35804 | train_mse: 0.12819 | valid_rmsle: 0.00867 | valid_mae: 0.3022  | valid_rmse: 0.37921 | valid_mse: 0.1438  |  0:01:24s\n",
      "epoch 48 | loss: 0.12603 | train_rmsle: 0.00764 | train_mae: 0.26652 | train_rmse: 0.34679 | train_mse: 0.12027 | valid_rmsle: 0.00831 | valid_mae: 0.28941 | valid_rmse: 0.36873 | valid_mse: 0.13596 |  0:01:26s\n",
      "epoch 49 | loss: 0.11497 | train_rmsle: 0.00741 | train_mae: 0.26257 | train_rmse: 0.34134 | train_mse: 0.11651 | valid_rmsle: 0.00793 | valid_mae: 0.28205 | valid_rmse: 0.36006 | valid_mse: 0.12964 |  0:01:27s\n",
      "epoch 50 | loss: 0.11169 | train_rmsle: 0.00692 | train_mae: 0.25576 | train_rmse: 0.33072 | train_mse: 0.10938 | valid_rmsle: 0.00747 | valid_mae: 0.27268 | valid_rmse: 0.35094 | valid_mse: 0.12316 |  0:01:29s\n",
      "epoch 51 | loss: 0.10747 | train_rmsle: 0.00654 | train_mae: 0.24941 | train_rmse: 0.32178 | train_mse: 0.10354 | valid_rmsle: 0.00709 | valid_mae: 0.26627 | valid_rmse: 0.3408  | valid_mse: 0.11614 |  0:01:31s\n",
      "epoch 52 | loss: 0.10206 | train_rmsle: 0.00611 | train_mae: 0.24187 | train_rmse: 0.31209 | train_mse: 0.0974  | valid_rmsle: 0.00683 | valid_mae: 0.26386 | valid_rmse: 0.33616 | valid_mse: 0.113   |  0:01:33s\n",
      "epoch 53 | loss: 0.09786 | train_rmsle: 0.00649 | train_mae: 0.24558 | train_rmse: 0.31982 | train_mse: 0.10229 | valid_rmsle: 0.00737 | valid_mae: 0.27037 | valid_rmse: 0.3485  | valid_mse: 0.12145 |  0:01:34s\n",
      "epoch 54 | loss: 0.09611 | train_rmsle: 0.0056  | train_mae: 0.22939 | train_rmse: 0.29742 | train_mse: 0.08846 | valid_rmsle: 0.00641 | valid_mae: 0.25537 | valid_rmse: 0.32488 | valid_mse: 0.10555 |  0:01:36s\n",
      "epoch 55 | loss: 0.08892 | train_rmsle: 0.00529 | train_mae: 0.22503 | train_rmse: 0.29018 | train_mse: 0.08421 | valid_rmsle: 0.00607 | valid_mae: 0.24813 | valid_rmse: 0.31716 | valid_mse: 0.10059 |  0:01:38s\n",
      "epoch 56 | loss: 0.08531 | train_rmsle: 0.0051  | train_mae: 0.21993 | train_rmse: 0.28474 | train_mse: 0.08108 | valid_rmsle: 0.00593 | valid_mae: 0.24717 | valid_rmse: 0.31386 | valid_mse: 0.09851 |  0:01:40s\n",
      "epoch 57 | loss: 0.08268 | train_rmsle: 0.00478 | train_mae: 0.21336 | train_rmse: 0.27602 | train_mse: 0.07619 | valid_rmsle: 0.00563 | valid_mae: 0.24069 | valid_rmse: 0.30523 | valid_mse: 0.09316 |  0:01:41s\n",
      "epoch 58 | loss: 0.07912 | train_rmsle: 0.0046  | train_mae: 0.21104 | train_rmse: 0.27228 | train_mse: 0.07414 | valid_rmsle: 0.0055  | valid_mae: 0.2403  | valid_rmse: 0.30321 | valid_mse: 0.09193 |  0:01:43s\n",
      "epoch 59 | loss: 0.07537 | train_rmsle: 0.00453 | train_mae: 0.20947 | train_rmse: 0.2701  | train_mse: 0.07295 | valid_rmsle: 0.00526 | valid_mae: 0.23384 | valid_rmse: 0.29462 | valid_mse: 0.0868  |  0:01:45s\n",
      "epoch 60 | loss: 0.07231 | train_rmsle: 0.00427 | train_mae: 0.19834 | train_rmse: 0.25902 | train_mse: 0.06709 | valid_rmsle: 0.00503 | valid_mae: 0.22489 | valid_rmse: 0.28774 | valid_mse: 0.08279 |  0:01:47s\n",
      "epoch 61 | loss: 0.06838 | train_rmsle: 0.0043  | train_mae: 0.20063 | train_rmse: 0.26032 | train_mse: 0.06777 | valid_rmsle: 0.00509 | valid_mae: 0.22616 | valid_rmse: 0.28999 | valid_mse: 0.0841  |  0:01:49s\n",
      "epoch 62 | loss: 0.06687 | train_rmsle: 0.00404 | train_mae: 0.19384 | train_rmse: 0.25203 | train_mse: 0.06352 | valid_rmsle: 0.00485 | valid_mae: 0.21997 | valid_rmse: 0.28172 | valid_mse: 0.07937 |  0:01:50s\n",
      "epoch 63 | loss: 0.06425 | train_rmsle: 0.00398 | train_mae: 0.19129 | train_rmse: 0.24911 | train_mse: 0.06206 | valid_rmsle: 0.00474 | valid_mae: 0.21689 | valid_rmse: 0.27783 | valid_mse: 0.07719 |  0:01:52s\n",
      "epoch 64 | loss: 0.06324 | train_rmsle: 0.00365 | train_mae: 0.18663 | train_rmse: 0.24167 | train_mse: 0.0584  | valid_rmsle: 0.00445 | valid_mae: 0.21095 | valid_rmse: 0.27101 | valid_mse: 0.07345 |  0:01:54s\n",
      "epoch 65 | loss: 0.05978 | train_rmsle: 0.00355 | train_mae: 0.18382 | train_rmse: 0.23769 | train_mse: 0.0565  | valid_rmsle: 0.0043  | valid_mae: 0.21032 | valid_rmse: 0.26632 | valid_mse: 0.07093 |  0:01:56s\n",
      "epoch 66 | loss: 0.06012 | train_rmsle: 0.00356 | train_mae: 0.18234 | train_rmse: 0.23705 | train_mse: 0.05619 | valid_rmsle: 0.00415 | valid_mae: 0.20354 | valid_rmse: 0.25975 | valid_mse: 0.06747 |  0:01:58s\n",
      "epoch 67 | loss: 0.06052 | train_rmsle: 0.00314 | train_mae: 0.17575 | train_rmse: 0.22701 | train_mse: 0.05153 | valid_rmsle: 0.00371 | valid_mae: 0.19579 | valid_rmse: 0.24976 | valid_mse: 0.06238 |  0:01:59s\n",
      "epoch 68 | loss: 0.05616 | train_rmsle: 0.0032  | train_mae: 0.17787 | train_rmse: 0.22875 | train_mse: 0.05233 | valid_rmsle: 0.00387 | valid_mae: 0.19988 | valid_rmse: 0.25504 | valid_mse: 0.06505 |  0:02:01s\n",
      "epoch 69 | loss: 0.05049 | train_rmsle: 0.00292 | train_mae: 0.16774 | train_rmse: 0.2174  | train_mse: 0.04726 | valid_rmsle: 0.00374 | valid_mae: 0.19434 | valid_rmse: 0.24892 | valid_mse: 0.06196 |  0:02:03s\n",
      "epoch 70 | loss: 0.04953 | train_rmsle: 0.00279 | train_mae: 0.16727 | train_rmse: 0.2156  | train_mse: 0.04648 | valid_rmsle: 0.00358 | valid_mae: 0.19084 | valid_rmse: 0.24644 | valid_mse: 0.06073 |  0:02:05s\n",
      "epoch 71 | loss: 0.04946 | train_rmsle: 0.00267 | train_mae: 0.16093 | train_rmse: 0.20883 | train_mse: 0.04361 | valid_rmsle: 0.00338 | valid_mae: 0.18347 | valid_rmse: 0.23832 | valid_mse: 0.0568  |  0:02:06s\n",
      "epoch 72 | loss: 0.04646 | train_rmsle: 0.00282 | train_mae: 0.16367 | train_rmse: 0.21208 | train_mse: 0.04498 | valid_rmsle: 0.00344 | valid_mae: 0.18267 | valid_rmse: 0.23811 | valid_mse: 0.05669 |  0:02:08s\n",
      "epoch 73 | loss: 0.04691 | train_rmsle: 0.00258 | train_mae: 0.16154 | train_rmse: 0.20727 | train_mse: 0.04296 | valid_rmsle: 0.00325 | valid_mae: 0.18232 | valid_rmse: 0.23463 | valid_mse: 0.05505 |  0:02:10s\n",
      "epoch 74 | loss: 0.04614 | train_rmsle: 0.00242 | train_mae: 0.15402 | train_rmse: 0.19926 | train_mse: 0.03971 | valid_rmsle: 0.0031  | valid_mae: 0.17705 | valid_rmse: 0.22789 | valid_mse: 0.05194 |  0:02:12s\n",
      "epoch 75 | loss: 0.04088 | train_rmsle: 0.00212 | train_mae: 0.14695 | train_rmse: 0.18956 | train_mse: 0.03593 | valid_rmsle: 0.00282 | valid_mae: 0.16852 | valid_rmse: 0.21865 | valid_mse: 0.04781 |  0:02:13s\n",
      "epoch 76 | loss: 0.04193 | train_rmsle: 0.00216 | train_mae: 0.14751 | train_rmse: 0.19047 | train_mse: 0.03628 | valid_rmsle: 0.00287 | valid_mae: 0.17136 | valid_rmse: 0.22111 | valid_mse: 0.04889 |  0:02:15s\n",
      "epoch 77 | loss: 0.04086 | train_rmsle: 0.00211 | train_mae: 0.14598 | train_rmse: 0.18802 | train_mse: 0.03535 | valid_rmsle: 0.00282 | valid_mae: 0.16869 | valid_rmse: 0.21854 | valid_mse: 0.04776 |  0:02:17s\n",
      "epoch 78 | loss: 0.03822 | train_rmsle: 0.002   | train_mae: 0.14323 | train_rmse: 0.18481 | train_mse: 0.03416 | valid_rmsle: 0.00273 | valid_mae: 0.16687 | valid_rmse: 0.21607 | valid_mse: 0.04669 |  0:02:19s\n",
      "epoch 79 | loss: 0.0376  | train_rmsle: 0.00181 | train_mae: 0.13279 | train_rmse: 0.17403 | train_mse: 0.03029 | valid_rmsle: 0.00266 | valid_mae: 0.15953 | valid_rmse: 0.21065 | valid_mse: 0.04437 |  0:02:20s\n",
      "epoch 80 | loss: 0.03402 | train_rmsle: 0.00187 | train_mae: 0.13624 | train_rmse: 0.17669 | train_mse: 0.03122 | valid_rmsle: 0.00271 | valid_mae: 0.16239 | valid_rmse: 0.21318 | valid_mse: 0.04544 |  0:02:22s\n",
      "epoch 81 | loss: 0.03433 | train_rmsle: 0.00173 | train_mae: 0.13313 | train_rmse: 0.17329 | train_mse: 0.03003 | valid_rmsle: 0.00247 | valid_mae: 0.15777 | valid_rmse: 0.20584 | valid_mse: 0.04237 |  0:02:24s\n",
      "epoch 82 | loss: 0.03259 | train_rmsle: 0.00163 | train_mae: 0.12662 | train_rmse: 0.16602 | train_mse: 0.02756 | valid_rmsle: 0.00244 | valid_mae: 0.15306 | valid_rmse: 0.20297 | valid_mse: 0.0412  |  0:02:26s\n",
      "epoch 83 | loss: 0.03261 | train_rmsle: 0.00155 | train_mae: 0.12596 | train_rmse: 0.16383 | train_mse: 0.02684 | valid_rmsle: 0.00225 | valid_mae: 0.14924 | valid_rmse: 0.19635 | valid_mse: 0.03855 |  0:02:27s\n",
      "epoch 84 | loss: 0.03359 | train_rmsle: 0.00161 | train_mae: 0.12998 | train_rmse: 0.16799 | train_mse: 0.02822 | valid_rmsle: 0.00225 | valid_mae: 0.1523  | valid_rmse: 0.19802 | valid_mse: 0.03921 |  0:02:29s\n",
      "epoch 85 | loss: 0.03117 | train_rmsle: 0.00143 | train_mae: 0.11844 | train_rmse: 0.15531 | train_mse: 0.02412 | valid_rmsle: 0.00209 | valid_mae: 0.1425  | valid_rmse: 0.18817 | valid_mse: 0.03541 |  0:02:31s\n",
      "epoch 86 | loss: 0.02981 | train_rmsle: 0.00155 | train_mae: 0.12437 | train_rmse: 0.16207 | train_mse: 0.02627 | valid_rmsle: 0.00216 | valid_mae: 0.14584 | valid_rmse: 0.19146 | valid_mse: 0.03666 |  0:02:33s\n",
      "epoch 87 | loss: 0.03131 | train_rmsle: 0.00163 | train_mae: 0.1306  | train_rmse: 0.16816 | train_mse: 0.02828 | valid_rmsle: 0.00216 | valid_mae: 0.1498  | valid_rmse: 0.1938  | valid_mse: 0.03756 |  0:02:34s\n",
      "epoch 88 | loss: 0.02943 | train_rmsle: 0.00161 | train_mae: 0.13199 | train_rmse: 0.16841 | train_mse: 0.02836 | valid_rmsle: 0.00204 | valid_mae: 0.14859 | valid_rmse: 0.18996 | valid_mse: 0.03608 |  0:02:36s\n",
      "epoch 89 | loss: 0.02857 | train_rmsle: 0.00131 | train_mae: 0.11313 | train_rmse: 0.14908 | train_mse: 0.02222 | valid_rmsle: 0.00182 | valid_mae: 0.13542 | valid_rmse: 0.17615 | valid_mse: 0.03103 |  0:02:38s\n",
      "epoch 90 | loss: 0.02802 | train_rmsle: 0.00121 | train_mae: 0.1113  | train_rmse: 0.14592 | train_mse: 0.02129 | valid_rmsle: 0.00164 | valid_mae: 0.13225 | valid_rmse: 0.17087 | valid_mse: 0.0292  |  0:02:40s\n",
      "epoch 91 | loss: 0.02662 | train_rmsle: 0.00118 | train_mae: 0.10913 | train_rmse: 0.14324 | train_mse: 0.02052 | valid_rmsle: 0.00164 | valid_mae: 0.13214 | valid_rmse: 0.17111 | valid_mse: 0.02928 |  0:02:41s\n",
      "epoch 92 | loss: 0.02506 | train_rmsle: 0.00164 | train_mae: 0.12757 | train_rmse: 0.16641 | train_mse: 0.02769 | valid_rmsle: 0.00197 | valid_mae: 0.14708 | valid_rmse: 0.18771 | valid_mse: 0.03524 |  0:02:43s\n",
      "epoch 93 | loss: 0.02858 | train_rmsle: 0.00145 | train_mae: 0.12181 | train_rmse: 0.15894 | train_mse: 0.02526 | valid_rmsle: 0.00194 | valid_mae: 0.14121 | valid_rmse: 0.18528 | valid_mse: 0.03433 |  0:02:45s\n",
      "epoch 94 | loss: 0.0278  | train_rmsle: 0.00127 | train_mae: 0.11324 | train_rmse: 0.14762 | train_mse: 0.02179 | valid_rmsle: 0.0017  | valid_mae: 0.13487 | valid_rmse: 0.17369 | valid_mse: 0.03017 |  0:02:47s\n",
      "epoch 95 | loss: 0.02489 | train_rmsle: 0.00114 | train_mae: 0.10631 | train_rmse: 0.13988 | train_mse: 0.01957 | valid_rmsle: 0.0015  | valid_mae: 0.12659 | valid_rmse: 0.16401 | valid_mse: 0.0269  |  0:02:48s\n",
      "epoch 96 | loss: 0.02456 | train_rmsle: 0.0011  | train_mae: 0.10613 | train_rmse: 0.13918 | train_mse: 0.01937 | valid_rmsle: 0.00155 | valid_mae: 0.12895 | valid_rmse: 0.16648 | valid_mse: 0.02772 |  0:02:50s\n",
      "epoch 97 | loss: 0.02389 | train_rmsle: 0.00102 | train_mae: 0.10137 | train_rmse: 0.13392 | train_mse: 0.01793 | valid_rmsle: 0.00142 | valid_mae: 0.12304 | valid_rmse: 0.1601  | valid_mse: 0.02563 |  0:02:52s\n",
      "epoch 98 | loss: 0.02342 | train_rmsle: 0.00099 | train_mae: 0.09939 | train_rmse: 0.13124 | train_mse: 0.01722 | valid_rmsle: 0.00139 | valid_mae: 0.12203 | valid_rmse: 0.15754 | valid_mse: 0.02482 |  0:02:54s\n",
      "epoch 99 | loss: 0.02393 | train_rmsle: 0.00098 | train_mae: 0.09848 | train_rmse: 0.12981 | train_mse: 0.01685 | valid_rmsle: 0.0014  | valid_mae: 0.11932 | valid_rmse: 0.15706 | valid_mse: 0.02467 |  0:02:55s\n",
      "epoch 100| loss: 0.02329 | train_rmsle: 0.00107 | train_mae: 0.10177 | train_rmse: 0.13416 | train_mse: 0.018   | valid_rmsle: 0.00142 | valid_mae: 0.12233 | valid_rmse: 0.15895 | valid_mse: 0.02526 |  0:02:57s\n",
      "epoch 101| loss: 0.02139 | train_rmsle: 0.00097 | train_mae: 0.10231 | train_rmse: 0.13321 | train_mse: 0.01774 | valid_rmsle: 0.00137 | valid_mae: 0.12319 | valid_rmse: 0.15904 | valid_mse: 0.02529 |  0:02:59s\n",
      "epoch 102| loss: 0.02199 | train_rmsle: 0.00109 | train_mae: 0.10826 | train_rmse: 0.13894 | train_mse: 0.01931 | valid_rmsle: 0.00146 | valid_mae: 0.12796 | valid_rmse: 0.16291 | valid_mse: 0.02654 |  0:03:01s\n",
      "epoch 103| loss: 0.02415 | train_rmsle: 0.00103 | train_mae: 0.10493 | train_rmse: 0.13472 | train_mse: 0.01815 | valid_rmsle: 0.00139 | valid_mae: 0.12475 | valid_rmse: 0.15848 | valid_mse: 0.02512 |  0:03:02s\n",
      "epoch 104| loss: 0.02127 | train_rmsle: 0.00084 | train_mae: 0.09148 | train_rmse: 0.12125 | train_mse: 0.0147  | valid_rmsle: 0.00119 | valid_mae: 0.11118 | valid_rmse: 0.14722 | valid_mse: 0.02168 |  0:03:04s\n",
      "epoch 105| loss: 0.02021 | train_rmsle: 0.00078 | train_mae: 0.08872 | train_rmse: 0.11796 | train_mse: 0.01391 | valid_rmsle: 0.00118 | valid_mae: 0.11032 | valid_rmse: 0.14585 | valid_mse: 0.02127 |  0:03:06s\n",
      "epoch 106| loss: 0.01995 | train_rmsle: 0.00114 | train_mae: 0.11146 | train_rmse: 0.14227 | train_mse: 0.02024 | valid_rmsle: 0.00154 | valid_mae: 0.13016 | valid_rmse: 0.16718 | valid_mse: 0.02795 |  0:03:08s\n",
      "epoch 107| loss: 0.02006 | train_rmsle: 0.00077 | train_mae: 0.08688 | train_rmse: 0.11752 | train_mse: 0.01381 | valid_rmsle: 0.00122 | valid_mae: 0.11004 | valid_rmse: 0.14837 | valid_mse: 0.02201 |  0:03:09s\n",
      "epoch 108| loss: 0.01798 | train_rmsle: 0.00078 | train_mae: 0.08819 | train_rmse: 0.11636 | train_mse: 0.01354 | valid_rmsle: 0.0012  | valid_mae: 0.1107  | valid_rmse: 0.14518 | valid_mse: 0.02108 |  0:03:11s\n",
      "epoch 109| loss: 0.01782 | train_rmsle: 0.00075 | train_mae: 0.08775 | train_rmse: 0.11501 | train_mse: 0.01323 | valid_rmsle: 0.00116 | valid_mae: 0.10892 | valid_rmse: 0.14332 | valid_mse: 0.02054 |  0:03:13s\n",
      "epoch 110| loss: 0.02032 | train_rmsle: 0.00072 | train_mae: 0.08631 | train_rmse: 0.11408 | train_mse: 0.01301 | valid_rmsle: 0.00112 | valid_mae: 0.10682 | valid_rmse: 0.14276 | valid_mse: 0.02038 |  0:03:15s\n",
      "epoch 111| loss: 0.0184  | train_rmsle: 0.00069 | train_mae: 0.0844  | train_rmse: 0.112   | train_mse: 0.01254 | valid_rmsle: 0.00106 | valid_mae: 0.10436 | valid_rmse: 0.13957 | valid_mse: 0.01948 |  0:03:17s\n",
      "epoch 112| loss: 0.01841 | train_rmsle: 0.00098 | train_mae: 0.1013  | train_rmse: 0.13273 | train_mse: 0.01762 | valid_rmsle: 0.00138 | valid_mae: 0.12124 | valid_rmse: 0.15761 | valid_mse: 0.02484 |  0:03:18s\n",
      "epoch 113| loss: 0.01874 | train_rmsle: 0.00079 | train_mae: 0.08749 | train_rmse: 0.1163  | train_mse: 0.01353 | valid_rmsle: 0.0011  | valid_mae: 0.107   | valid_rmse: 0.13987 | valid_mse: 0.01956 |  0:03:20s\n",
      "epoch 114| loss: 0.01811 | train_rmsle: 0.00073 | train_mae: 0.08604 | train_rmse: 0.11339 | train_mse: 0.01286 | valid_rmsle: 0.00109 | valid_mae: 0.10682 | valid_rmse: 0.14097 | valid_mse: 0.01987 |  0:03:22s\n",
      "epoch 115| loss: 0.01818 | train_rmsle: 0.00065 | train_mae: 0.08165 | train_rmse: 0.10736 | train_mse: 0.01153 | valid_rmsle: 0.00106 | valid_mae: 0.103   | valid_rmse: 0.13731 | valid_mse: 0.01885 |  0:03:24s\n",
      "epoch 116| loss: 0.01843 | train_rmsle: 0.00078 | train_mae: 0.08845 | train_rmse: 0.11587 | train_mse: 0.01343 | valid_rmsle: 0.00119 | valid_mae: 0.10984 | valid_rmse: 0.14407 | valid_mse: 0.02075 |  0:03:25s\n",
      "epoch 117| loss: 0.01753 | train_rmsle: 0.00095 | train_mae: 0.10379 | train_rmse: 0.12914 | train_mse: 0.01668 | valid_rmsle: 0.00132 | valid_mae: 0.12207 | valid_rmse: 0.15431 | valid_mse: 0.02381 |  0:03:27s\n",
      "epoch 118| loss: 0.01932 | train_rmsle: 0.00102 | train_mae: 0.111   | train_rmse: 0.13828 | train_mse: 0.01912 | valid_rmsle: 0.00144 | valid_mae: 0.12779 | valid_rmse: 0.16413 | valid_mse: 0.02694 |  0:03:29s\n",
      "epoch 119| loss: 0.01785 | train_rmsle: 0.00057 | train_mae: 0.07753 | train_rmse: 0.10173 | train_mse: 0.01035 | valid_rmsle: 0.00095 | valid_mae: 0.09872 | valid_rmse: 0.13159 | valid_mse: 0.01732 |  0:03:30s\n",
      "epoch 120| loss: 0.01762 | train_rmsle: 0.00075 | train_mae: 0.08979 | train_rmse: 0.11438 | train_mse: 0.01308 | valid_rmsle: 0.00117 | valid_mae: 0.10914 | valid_rmse: 0.1431  | valid_mse: 0.02048 |  0:03:32s\n",
      "epoch 121| loss: 0.01673 | train_rmsle: 0.00063 | train_mae: 0.08202 | train_rmse: 0.10653 | train_mse: 0.01135 | valid_rmsle: 0.00103 | valid_mae: 0.10181 | valid_rmse: 0.13638 | valid_mse: 0.0186  |  0:03:34s\n",
      "epoch 122| loss: 0.01791 | train_rmsle: 0.00059 | train_mae: 0.07856 | train_rmse: 0.10257 | train_mse: 0.01052 | valid_rmsle: 0.00096 | valid_mae: 0.09872 | valid_rmse: 0.13201 | valid_mse: 0.01743 |  0:03:35s\n",
      "epoch 123| loss: 0.01535 | train_rmsle: 0.00055 | train_mae: 0.07447 | train_rmse: 0.09809 | train_mse: 0.00962 | valid_rmsle: 0.00088 | valid_mae: 0.09377 | valid_rmse: 0.12662 | valid_mse: 0.01603 |  0:03:37s\n",
      "epoch 124| loss: 0.01497 | train_rmsle: 0.00067 | train_mae: 0.08452 | train_rmse: 0.10905 | train_mse: 0.01189 | valid_rmsle: 0.00106 | valid_mae: 0.10524 | valid_rmse: 0.13768 | valid_mse: 0.01896 |  0:03:38s\n",
      "epoch 125| loss: 0.01471 | train_rmsle: 0.00058 | train_mae: 0.07889 | train_rmse: 0.10343 | train_mse: 0.0107  | valid_rmsle: 0.00092 | valid_mae: 0.10027 | valid_rmse: 0.13023 | valid_mse: 0.01696 |  0:03:40s\n",
      "epoch 126| loss: 0.0165  | train_rmsle: 0.00057 | train_mae: 0.07781 | train_rmse: 0.10184 | train_mse: 0.01037 | valid_rmsle: 0.00088 | valid_mae: 0.09721 | valid_rmse: 0.12725 | valid_mse: 0.01619 |  0:03:41s\n",
      "epoch 127| loss: 0.01517 | train_rmsle: 0.00054 | train_mae: 0.07286 | train_rmse: 0.09642 | train_mse: 0.0093  | valid_rmsle: 0.00083 | valid_mae: 0.09309 | valid_rmse: 0.12316 | valid_mse: 0.01517 |  0:03:43s\n",
      "epoch 128| loss: 0.01587 | train_rmsle: 0.00049 | train_mae: 0.0714  | train_rmse: 0.09424 | train_mse: 0.00888 | valid_rmsle: 0.00083 | valid_mae: 0.09238 | valid_rmse: 0.12266 | valid_mse: 0.01505 |  0:03:45s\n",
      "epoch 129| loss: 0.01553 | train_rmsle: 0.00053 | train_mae: 0.07432 | train_rmse: 0.09768 | train_mse: 0.00954 | valid_rmsle: 0.00088 | valid_mae: 0.09703 | valid_rmse: 0.12616 | valid_mse: 0.01592 |  0:03:46s\n",
      "epoch 130| loss: 0.01422 | train_rmsle: 0.00051 | train_mae: 0.07377 | train_rmse: 0.09636 | train_mse: 0.00929 | valid_rmsle: 0.00083 | valid_mae: 0.09333 | valid_rmse: 0.12319 | valid_mse: 0.01517 |  0:03:48s\n",
      "epoch 131| loss: 0.01658 | train_rmsle: 0.00047 | train_mae: 0.0705  | train_rmse: 0.09284 | train_mse: 0.00862 | valid_rmsle: 0.00077 | valid_mae: 0.09116 | valid_rmse: 0.11944 | valid_mse: 0.01427 |  0:03:50s\n",
      "epoch 132| loss: 0.01419 | train_rmsle: 0.00051 | train_mae: 0.07447 | train_rmse: 0.09724 | train_mse: 0.00946 | valid_rmsle: 0.00084 | valid_mae: 0.09577 | valid_rmse: 0.12485 | valid_mse: 0.01559 |  0:03:52s\n",
      "epoch 133| loss: 0.01318 | train_rmsle: 0.00052 | train_mae: 0.07376 | train_rmse: 0.09548 | train_mse: 0.00912 | valid_rmsle: 0.00085 | valid_mae: 0.09422 | valid_rmse: 0.12339 | valid_mse: 0.01523 |  0:03:53s\n",
      "epoch 134| loss: 0.01426 | train_rmsle: 0.00046 | train_mae: 0.06941 | train_rmse: 0.09049 | train_mse: 0.00819 | valid_rmsle: 0.00079 | valid_mae: 0.09082 | valid_rmse: 0.11932 | valid_mse: 0.01424 |  0:03:55s\n",
      "epoch 135| loss: 0.01376 | train_rmsle: 0.00046 | train_mae: 0.06791 | train_rmse: 0.08978 | train_mse: 0.00806 | valid_rmsle: 0.00079 | valid_mae: 0.08869 | valid_rmse: 0.11855 | valid_mse: 0.01405 |  0:03:57s\n",
      "epoch 136| loss: 0.01364 | train_rmsle: 0.00048 | train_mae: 0.07221 | train_rmse: 0.09329 | train_mse: 0.0087  | valid_rmsle: 0.00081 | valid_mae: 0.09425 | valid_rmse: 0.12197 | valid_mse: 0.01488 |  0:03:59s\n",
      "epoch 137| loss: 0.01421 | train_rmsle: 0.00044 | train_mae: 0.0671  | train_rmse: 0.08887 | train_mse: 0.0079  | valid_rmsle: 0.00077 | valid_mae: 0.08979 | valid_rmse: 0.11933 | valid_mse: 0.01424 |  0:04:00s\n",
      "epoch 138| loss: 0.01301 | train_rmsle: 0.00043 | train_mae: 0.0679  | train_rmse: 0.08871 | train_mse: 0.00787 | valid_rmsle: 0.00076 | valid_mae: 0.09037 | valid_rmse: 0.11771 | valid_mse: 0.01386 |  0:04:02s\n",
      "epoch 139| loss: 0.01356 | train_rmsle: 0.00045 | train_mae: 0.06897 | train_rmse: 0.08966 | train_mse: 0.00804 | valid_rmsle: 0.00074 | valid_mae: 0.09036 | valid_rmse: 0.11636 | valid_mse: 0.01354 |  0:04:04s\n",
      "epoch 140| loss: 0.01366 | train_rmsle: 0.00045 | train_mae: 0.06671 | train_rmse: 0.08806 | train_mse: 0.00776 | valid_rmsle: 0.00072 | valid_mae: 0.08713 | valid_rmse: 0.11469 | valid_mse: 0.01315 |  0:04:06s\n",
      "epoch 141| loss: 0.01375 | train_rmsle: 0.00046 | train_mae: 0.06884 | train_rmse: 0.08917 | train_mse: 0.00795 | valid_rmsle: 0.00077 | valid_mae: 0.09029 | valid_rmse: 0.11727 | valid_mse: 0.01375 |  0:04:07s\n",
      "epoch 142| loss: 0.01623 | train_rmsle: 0.0005  | train_mae: 0.07416 | train_rmse: 0.09527 | train_mse: 0.00908 | valid_rmsle: 0.00082 | valid_mae: 0.09514 | valid_rmse: 0.12249 | valid_mse: 0.015   |  0:04:09s\n",
      "epoch 143| loss: 0.01361 | train_rmsle: 0.00057 | train_mae: 0.07845 | train_rmse: 0.09999 | train_mse: 0.01    | valid_rmsle: 0.00084 | valid_mae: 0.09746 | valid_rmse: 0.12397 | valid_mse: 0.01537 |  0:04:11s\n",
      "epoch 144| loss: 0.0153  | train_rmsle: 0.00053 | train_mae: 0.07868 | train_rmse: 0.10064 | train_mse: 0.01013 | valid_rmsle: 0.00083 | valid_mae: 0.09774 | valid_rmse: 0.12443 | valid_mse: 0.01548 |  0:04:13s\n",
      "epoch 145| loss: 0.01275 | train_rmsle: 0.0004  | train_mae: 0.0641  | train_rmse: 0.0839  | train_mse: 0.00704 | valid_rmsle: 0.00071 | valid_mae: 0.0855  | valid_rmse: 0.1121  | valid_mse: 0.01257 |  0:04:14s\n",
      "epoch 146| loss: 0.01364 | train_rmsle: 0.00039 | train_mae: 0.06423 | train_rmse: 0.08412 | train_mse: 0.00708 | valid_rmsle: 0.00068 | valid_mae: 0.08398 | valid_rmse: 0.1107  | valid_mse: 0.01226 |  0:04:16s\n",
      "epoch 147| loss: 0.01261 | train_rmsle: 0.00055 | train_mae: 0.07414 | train_rmse: 0.09488 | train_mse: 0.009   | valid_rmsle: 0.00086 | valid_mae: 0.09496 | valid_rmse: 0.1218  | valid_mse: 0.01483 |  0:04:18s\n",
      "epoch 148| loss: 0.01437 | train_rmsle: 0.00049 | train_mae: 0.07286 | train_rmse: 0.09493 | train_mse: 0.00901 | valid_rmsle: 0.0008  | valid_mae: 0.09285 | valid_rmse: 0.12149 | valid_mse: 0.01476 |  0:04:20s\n",
      "epoch 149| loss: 0.01522 | train_rmsle: 0.00053 | train_mae: 0.07521 | train_rmse: 0.09765 | train_mse: 0.00954 | valid_rmsle: 0.00087 | valid_mae: 0.0953  | valid_rmse: 0.12627 | valid_mse: 0.01595 |  0:04:22s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 146 and best_valid_mse = 0.01226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.013513631990254989 RMSE: 0.11624814833043574 R2: 0.9401803582325591 MAE: 0.08634444351863413\n",
      "=====================================\n",
      "[56/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.25926 | train_rmsle: 0.1698  | train_mae: 1.41421 | train_rmse: 1.49138 | train_mse: 2.22421 | valid_rmsle: 0.17066 | valid_mae: 1.41871 | valid_rmse: 1.49611 | valid_mse: 2.23836 |  0:00:01s\n",
      "epoch 1  | loss: 0.615   | train_rmsle: 0.05757 | train_mae: 0.86219 | train_rmse: 0.95513 | train_mse: 0.91227 | valid_rmsle: 0.05771 | valid_mae: 0.8638  | valid_rmse: 0.95817 | valid_mse: 0.91809 |  0:00:03s\n",
      "epoch 2  | loss: 0.37229 | train_rmsle: 0.03581 | train_mae: 0.68107 | train_rmse: 0.77372 | train_mse: 0.59864 | valid_rmsle: 0.03569 | valid_mae: 0.67999 | valid_rmse: 0.77532 | valid_mse: 0.60113 |  0:00:05s\n",
      "epoch 3  | loss: 0.30489 | train_rmsle: 0.02785 | train_mae: 0.59748 | train_rmse: 0.68865 | train_mse: 0.47423 | valid_rmsle: 0.02761 | valid_mae: 0.59716 | valid_rmse: 0.68921 | valid_mse: 0.47501 |  0:00:06s\n",
      "epoch 4  | loss: 0.29307 | train_rmsle: 0.0205  | train_mae: 0.50386 | train_rmse: 0.59237 | train_mse: 0.35091 | valid_rmsle: 0.02013 | valid_mae: 0.50435 | valid_rmse: 0.59132 | valid_mse: 0.34966 |  0:00:08s\n",
      "epoch 5  | loss: 0.26257 | train_rmsle: 0.02385 | train_mae: 0.54909 | train_rmse: 0.63919 | train_mse: 0.40856 | valid_rmsle: 0.02357 | valid_mae: 0.54975 | valid_rmse: 0.63941 | valid_mse: 0.40885 |  0:00:10s\n",
      "epoch 6  | loss: 0.24891 | train_rmsle: 0.02206 | train_mae: 0.52586 | train_rmse: 0.61494 | train_mse: 0.37815 | valid_rmsle: 0.02176 | valid_mae: 0.52654 | valid_rmse: 0.6149  | valid_mse: 0.37811 |  0:00:12s\n",
      "epoch 7  | loss: 0.24476 | train_rmsle: 0.02703 | train_mae: 0.58782 | train_rmse: 0.67904 | train_mse: 0.46109 | valid_rmsle: 0.02673 | valid_mae: 0.58753 | valid_rmse: 0.67855 | valid_mse: 0.46044 |  0:00:14s\n",
      "epoch 8  | loss: 0.24147 | train_rmsle: 0.01508 | train_mae: 0.40643 | train_rmse: 0.49965 | train_mse: 0.24965 | valid_rmsle: 0.01446 | valid_mae: 0.40461 | valid_rmse: 0.49408 | valid_mse: 0.24412 |  0:00:15s\n",
      "epoch 9  | loss: 0.23536 | train_rmsle: 0.01609 | train_mae: 0.42818 | train_rmse: 0.52048 | train_mse: 0.2709  | valid_rmsle: 0.01529 | valid_mae: 0.42345 | valid_rmse: 0.51223 | valid_mse: 0.26238 |  0:00:17s\n",
      "epoch 10 | loss: 0.22506 | train_rmsle: 0.01714 | train_mae: 0.44849 | train_rmse: 0.53893 | train_mse: 0.29045 | valid_rmsle: 0.0165  | valid_mae: 0.44438 | valid_rmse: 0.53308 | valid_mse: 0.28418 |  0:00:19s\n",
      "epoch 11 | loss: 0.22297 | train_rmsle: 0.01534 | train_mae: 0.41576 | train_rmse: 0.50658 | train_mse: 0.25663 | valid_rmsle: 0.01486 | valid_mae: 0.41722 | valid_rmse: 0.50338 | valid_mse: 0.25339 |  0:00:20s\n",
      "epoch 12 | loss: 0.22253 | train_rmsle: 0.01514 | train_mae: 0.40918 | train_rmse: 0.50044 | train_mse: 0.25044 | valid_rmsle: 0.01468 | valid_mae: 0.412   | valid_rmse: 0.49844 | valid_mse: 0.24844 |  0:00:22s\n",
      "epoch 13 | loss: 0.2249  | train_rmsle: 0.01433 | train_mae: 0.39309 | train_rmse: 0.48604 | train_mse: 0.23624 | valid_rmsle: 0.01374 | valid_mae: 0.39163 | valid_rmse: 0.48067 | valid_mse: 0.23104 |  0:00:24s\n",
      "epoch 14 | loss: 0.22603 | train_rmsle: 0.01342 | train_mae: 0.37064 | train_rmse: 0.46508 | train_mse: 0.2163  | valid_rmsle: 0.0128  | valid_mae: 0.37186 | valid_rmse: 0.45936 | valid_mse: 0.21101 |  0:00:26s\n",
      "epoch 15 | loss: 0.22563 | train_rmsle: 0.01329 | train_mae: 0.37156 | train_rmse: 0.46404 | train_mse: 0.21533 | valid_rmsle: 0.01302 | valid_mae: 0.37826 | valid_rmse: 0.46514 | valid_mse: 0.21636 |  0:00:27s\n",
      "epoch 16 | loss: 0.21356 | train_rmsle: 0.01372 | train_mae: 0.38431 | train_rmse: 0.47429 | train_mse: 0.22495 | valid_rmsle: 0.01307 | valid_mae: 0.37979 | valid_rmse: 0.46773 | valid_mse: 0.21877 |  0:00:29s\n",
      "epoch 17 | loss: 0.21045 | train_rmsle: 0.01425 | train_mae: 0.39801 | train_rmse: 0.48698 | train_mse: 0.23715 | valid_rmsle: 0.01376 | valid_mae: 0.39496 | valid_rmse: 0.48308 | valid_mse: 0.23336 |  0:00:30s\n",
      "epoch 18 | loss: 0.20869 | train_rmsle: 0.0138  | train_mae: 0.38748 | train_rmse: 0.4776  | train_mse: 0.2281  | valid_rmsle: 0.01324 | valid_mae: 0.38484 | valid_rmse: 0.47261 | valid_mse: 0.22336 |  0:00:32s\n",
      "epoch 19 | loss: 0.20807 | train_rmsle: 0.01392 | train_mae: 0.39194 | train_rmse: 0.48129 | train_mse: 0.23164 | valid_rmsle: 0.01341 | valid_mae: 0.38997 | valid_rmse: 0.47731 | valid_mse: 0.22783 |  0:00:33s\n",
      "epoch 20 | loss: 0.20878 | train_rmsle: 0.01291 | train_mae: 0.36439 | train_rmse: 0.45648 | train_mse: 0.20837 | valid_rmsle: 0.01239 | valid_mae: 0.36431 | valid_rmse: 0.45285 | valid_mse: 0.20508 |  0:00:35s\n",
      "epoch 21 | loss: 0.20235 | train_rmsle: 0.01348 | train_mae: 0.38109 | train_rmse: 0.47085 | train_mse: 0.2217  | valid_rmsle: 0.01317 | valid_mae: 0.38427 | valid_rmse: 0.47059 | valid_mse: 0.22146 |  0:00:36s\n",
      "epoch 22 | loss: 0.19835 | train_rmsle: 0.01287 | train_mae: 0.35511 | train_rmse: 0.45136 | train_mse: 0.20373 | valid_rmsle: 0.01223 | valid_mae: 0.35406 | valid_rmse: 0.44476 | valid_mse: 0.19781 |  0:00:38s\n",
      "epoch 23 | loss: 0.19853 | train_rmsle: 0.0131  | train_mae: 0.37229 | train_rmse: 0.46263 | train_mse: 0.21403 | valid_rmsle: 0.01285 | valid_mae: 0.37412 | valid_rmse: 0.46365 | valid_mse: 0.21498 |  0:00:40s\n",
      "epoch 24 | loss: 0.19783 | train_rmsle: 0.01307 | train_mae: 0.37256 | train_rmse: 0.46259 | train_mse: 0.21399 | valid_rmsle: 0.01264 | valid_mae: 0.37163 | valid_rmse: 0.45998 | valid_mse: 0.21158 |  0:00:42s\n",
      "epoch 25 | loss: 0.2009  | train_rmsle: 0.01282 | train_mae: 0.36223 | train_rmse: 0.45478 | train_mse: 0.20682 | valid_rmsle: 0.01254 | valid_mae: 0.36454 | valid_rmse: 0.45486 | valid_mse: 0.2069  |  0:00:43s\n",
      "epoch 26 | loss: 0.20755 | train_rmsle: 0.01265 | train_mae: 0.36094 | train_rmse: 0.45207 | train_mse: 0.20437 | valid_rmsle: 0.01238 | valid_mae: 0.36277 | valid_rmse: 0.45165 | valid_mse: 0.20399 |  0:00:45s\n",
      "epoch 27 | loss: 0.19456 | train_rmsle: 0.01246 | train_mae: 0.35354 | train_rmse: 0.44604 | train_mse: 0.19895 | valid_rmsle: 0.01226 | valid_mae: 0.35663 | valid_rmse: 0.4478  | valid_mse: 0.20052 |  0:00:47s\n",
      "epoch 28 | loss: 0.19575 | train_rmsle: 0.01242 | train_mae: 0.34767 | train_rmse: 0.44344 | train_mse: 0.19664 | valid_rmsle: 0.01206 | valid_mae: 0.35091 | valid_rmse: 0.44177 | valid_mse: 0.19516 |  0:00:49s\n",
      "epoch 29 | loss: 0.1952  | train_rmsle: 0.0122  | train_mae: 0.35261 | train_rmse: 0.44318 | train_mse: 0.19641 | valid_rmsle: 0.01196 | valid_mae: 0.35441 | valid_rmse: 0.4434  | valid_mse: 0.1966  |  0:00:50s\n",
      "epoch 30 | loss: 0.19324 | train_rmsle: 0.01226 | train_mae: 0.35032 | train_rmse: 0.44336 | train_mse: 0.19657 | valid_rmsle: 0.01206 | valid_mae: 0.35543 | valid_rmse: 0.44484 | valid_mse: 0.19788 |  0:00:52s\n",
      "epoch 31 | loss: 0.19038 | train_rmsle: 0.01246 | train_mae: 0.35235 | train_rmse: 0.44621 | train_mse: 0.1991  | valid_rmsle: 0.01234 | valid_mae: 0.35828 | valid_rmse: 0.44918 | valid_mse: 0.20176 |  0:00:54s\n",
      "epoch 32 | loss: 0.18915 | train_rmsle: 0.01226 | train_mae: 0.35653 | train_rmse: 0.4462  | train_mse: 0.19909 | valid_rmsle: 0.0119  | valid_mae: 0.35814 | valid_rmse: 0.44407 | valid_mse: 0.1972  |  0:00:56s\n",
      "epoch 33 | loss: 0.18676 | train_rmsle: 0.01213 | train_mae: 0.34491 | train_rmse: 0.43877 | train_mse: 0.19252 | valid_rmsle: 0.01169 | valid_mae: 0.34575 | valid_rmse: 0.43499 | valid_mse: 0.18921 |  0:00:57s\n",
      "epoch 34 | loss: 0.18905 | train_rmsle: 0.01219 | train_mae: 0.34339 | train_rmse: 0.43834 | train_mse: 0.19214 | valid_rmsle: 0.01209 | valid_mae: 0.34925 | valid_rmse: 0.44132 | valid_mse: 0.19476 |  0:00:59s\n",
      "epoch 35 | loss: 0.18175 | train_rmsle: 0.01159 | train_mae: 0.34477 | train_rmse: 0.43247 | train_mse: 0.18703 | valid_rmsle: 0.01195 | valid_mae: 0.35658 | valid_rmse: 0.44397 | valid_mse: 0.19711 |  0:01:01s\n",
      "epoch 36 | loss: 0.17912 | train_rmsle: 0.01146 | train_mae: 0.33709 | train_rmse: 0.42751 | train_mse: 0.18277 | valid_rmsle: 0.01176 | valid_mae: 0.34519 | valid_rmse: 0.43704 | valid_mse: 0.191   |  0:01:03s\n",
      "epoch 37 | loss: 0.17436 | train_rmsle: 0.01125 | train_mae: 0.33148 | train_rmse: 0.42237 | train_mse: 0.1784  | valid_rmsle: 0.01149 | valid_mae: 0.34114 | valid_rmse: 0.43183 | valid_mse: 0.18648 |  0:01:05s\n",
      "epoch 38 | loss: 0.17245 | train_rmsle: 0.01078 | train_mae: 0.33457 | train_rmse: 0.41909 | train_mse: 0.17564 | valid_rmsle: 0.01146 | valid_mae: 0.34884 | valid_rmse: 0.43711 | valid_mse: 0.19107 |  0:01:06s\n",
      "epoch 39 | loss: 0.16983 | train_rmsle: 0.01047 | train_mae: 0.3225  | train_rmse: 0.40921 | train_mse: 0.16745 | valid_rmsle: 0.01084 | valid_mae: 0.3314  | valid_rmse: 0.42097 | valid_mse: 0.17722 |  0:01:08s\n",
      "epoch 40 | loss: 0.16414 | train_rmsle: 0.01011 | train_mae: 0.3231  | train_rmse: 0.40598 | train_mse: 0.16482 | valid_rmsle: 0.01073 | valid_mae: 0.33494 | valid_rmse: 0.42182 | valid_mse: 0.17793 |  0:01:10s\n",
      "epoch 41 | loss: 0.16479 | train_rmsle: 0.01006 | train_mae: 0.31347 | train_rmse: 0.40034 | train_mse: 0.16027 | valid_rmsle: 0.01064 | valid_mae: 0.32805 | valid_rmse: 0.41626 | valid_mse: 0.17328 |  0:01:12s\n",
      "epoch 42 | loss: 0.15336 | train_rmsle: 0.00963 | train_mae: 0.30742 | train_rmse: 0.39226 | train_mse: 0.15387 | valid_rmsle: 0.01031 | valid_mae: 0.32391 | valid_rmse: 0.41072 | valid_mse: 0.16869 |  0:01:13s\n",
      "epoch 43 | loss: 0.1531  | train_rmsle: 0.00903 | train_mae: 0.2981  | train_rmse: 0.38028 | train_mse: 0.14462 | valid_rmsle: 0.00945 | valid_mae: 0.30989 | valid_rmse: 0.39334 | valid_mse: 0.15471 |  0:01:15s\n",
      "epoch 44 | loss: 0.14447 | train_rmsle: 0.0084  | train_mae: 0.28982 | train_rmse: 0.36838 | train_mse: 0.1357  | valid_rmsle: 0.00904 | valid_mae: 0.30518 | valid_rmse: 0.38636 | valid_mse: 0.14927 |  0:01:17s\n",
      "epoch 45 | loss: 0.13605 | train_rmsle: 0.00846 | train_mae: 0.28325 | train_rmse: 0.36637 | train_mse: 0.13422 | valid_rmsle: 0.00889 | valid_mae: 0.29812 | valid_rmse: 0.38071 | valid_mse: 0.14494 |  0:01:19s\n",
      "epoch 46 | loss: 0.13137 | train_rmsle: 0.00773 | train_mae: 0.2768  | train_rmse: 0.35303 | train_mse: 0.12463 | valid_rmsle: 0.00839 | valid_mae: 0.29544 | valid_rmse: 0.37246 | valid_mse: 0.13873 |  0:01:20s\n",
      "epoch 47 | loss: 0.1246  | train_rmsle: 0.00798 | train_mae: 0.27797 | train_rmse: 0.35804 | train_mse: 0.12819 | valid_rmsle: 0.00867 | valid_mae: 0.3022  | valid_rmse: 0.37921 | valid_mse: 0.1438  |  0:01:22s\n",
      "epoch 48 | loss: 0.12603 | train_rmsle: 0.00764 | train_mae: 0.26652 | train_rmse: 0.34679 | train_mse: 0.12027 | valid_rmsle: 0.00831 | valid_mae: 0.28941 | valid_rmse: 0.36873 | valid_mse: 0.13596 |  0:01:24s\n",
      "epoch 49 | loss: 0.11497 | train_rmsle: 0.00741 | train_mae: 0.26257 | train_rmse: 0.34134 | train_mse: 0.11651 | valid_rmsle: 0.00793 | valid_mae: 0.28205 | valid_rmse: 0.36006 | valid_mse: 0.12964 |  0:01:26s\n",
      "epoch 50 | loss: 0.11169 | train_rmsle: 0.00692 | train_mae: 0.25576 | train_rmse: 0.33072 | train_mse: 0.10938 | valid_rmsle: 0.00747 | valid_mae: 0.27268 | valid_rmse: 0.35094 | valid_mse: 0.12316 |  0:01:28s\n",
      "epoch 51 | loss: 0.10747 | train_rmsle: 0.00654 | train_mae: 0.24941 | train_rmse: 0.32178 | train_mse: 0.10354 | valid_rmsle: 0.00709 | valid_mae: 0.26627 | valid_rmse: 0.3408  | valid_mse: 0.11614 |  0:01:29s\n",
      "epoch 52 | loss: 0.10206 | train_rmsle: 0.00611 | train_mae: 0.24187 | train_rmse: 0.31209 | train_mse: 0.0974  | valid_rmsle: 0.00683 | valid_mae: 0.26386 | valid_rmse: 0.33616 | valid_mse: 0.113   |  0:01:31s\n",
      "epoch 53 | loss: 0.09786 | train_rmsle: 0.00649 | train_mae: 0.24558 | train_rmse: 0.31982 | train_mse: 0.10229 | valid_rmsle: 0.00737 | valid_mae: 0.27037 | valid_rmse: 0.3485  | valid_mse: 0.12145 |  0:01:33s\n",
      "epoch 54 | loss: 0.09611 | train_rmsle: 0.0056  | train_mae: 0.22939 | train_rmse: 0.29742 | train_mse: 0.08846 | valid_rmsle: 0.00641 | valid_mae: 0.25537 | valid_rmse: 0.32488 | valid_mse: 0.10555 |  0:01:35s\n",
      "epoch 55 | loss: 0.08892 | train_rmsle: 0.00529 | train_mae: 0.22503 | train_rmse: 0.29018 | train_mse: 0.08421 | valid_rmsle: 0.00607 | valid_mae: 0.24813 | valid_rmse: 0.31716 | valid_mse: 0.10059 |  0:01:37s\n",
      "epoch 56 | loss: 0.08531 | train_rmsle: 0.0051  | train_mae: 0.21993 | train_rmse: 0.28474 | train_mse: 0.08108 | valid_rmsle: 0.00593 | valid_mae: 0.24717 | valid_rmse: 0.31386 | valid_mse: 0.09851 |  0:01:38s\n",
      "epoch 57 | loss: 0.08268 | train_rmsle: 0.00478 | train_mae: 0.21336 | train_rmse: 0.27602 | train_mse: 0.07619 | valid_rmsle: 0.00563 | valid_mae: 0.24069 | valid_rmse: 0.30523 | valid_mse: 0.09316 |  0:01:40s\n",
      "epoch 58 | loss: 0.07912 | train_rmsle: 0.0046  | train_mae: 0.21104 | train_rmse: 0.27228 | train_mse: 0.07414 | valid_rmsle: 0.0055  | valid_mae: 0.2403  | valid_rmse: 0.30321 | valid_mse: 0.09193 |  0:01:42s\n",
      "epoch 59 | loss: 0.07537 | train_rmsle: 0.00453 | train_mae: 0.20947 | train_rmse: 0.2701  | train_mse: 0.07295 | valid_rmsle: 0.00526 | valid_mae: 0.23384 | valid_rmse: 0.29462 | valid_mse: 0.0868  |  0:01:44s\n",
      "epoch 60 | loss: 0.07231 | train_rmsle: 0.00427 | train_mae: 0.19834 | train_rmse: 0.25902 | train_mse: 0.06709 | valid_rmsle: 0.00503 | valid_mae: 0.22489 | valid_rmse: 0.28774 | valid_mse: 0.08279 |  0:01:45s\n",
      "epoch 61 | loss: 0.06838 | train_rmsle: 0.0043  | train_mae: 0.20063 | train_rmse: 0.26032 | train_mse: 0.06777 | valid_rmsle: 0.00509 | valid_mae: 0.22616 | valid_rmse: 0.28999 | valid_mse: 0.0841  |  0:01:47s\n",
      "epoch 62 | loss: 0.06687 | train_rmsle: 0.00404 | train_mae: 0.19384 | train_rmse: 0.25203 | train_mse: 0.06352 | valid_rmsle: 0.00485 | valid_mae: 0.21997 | valid_rmse: 0.28172 | valid_mse: 0.07937 |  0:01:49s\n",
      "epoch 63 | loss: 0.06425 | train_rmsle: 0.00398 | train_mae: 0.19129 | train_rmse: 0.24911 | train_mse: 0.06206 | valid_rmsle: 0.00474 | valid_mae: 0.21689 | valid_rmse: 0.27783 | valid_mse: 0.07719 |  0:01:51s\n",
      "epoch 64 | loss: 0.06324 | train_rmsle: 0.00365 | train_mae: 0.18663 | train_rmse: 0.24167 | train_mse: 0.0584  | valid_rmsle: 0.00445 | valid_mae: 0.21095 | valid_rmse: 0.27101 | valid_mse: 0.07345 |  0:01:52s\n",
      "epoch 65 | loss: 0.05978 | train_rmsle: 0.00355 | train_mae: 0.18382 | train_rmse: 0.23769 | train_mse: 0.0565  | valid_rmsle: 0.0043  | valid_mae: 0.21032 | valid_rmse: 0.26632 | valid_mse: 0.07093 |  0:01:54s\n",
      "epoch 66 | loss: 0.06012 | train_rmsle: 0.00356 | train_mae: 0.18234 | train_rmse: 0.23705 | train_mse: 0.05619 | valid_rmsle: 0.00415 | valid_mae: 0.20354 | valid_rmse: 0.25975 | valid_mse: 0.06747 |  0:01:56s\n",
      "epoch 67 | loss: 0.06052 | train_rmsle: 0.00314 | train_mae: 0.17575 | train_rmse: 0.22701 | train_mse: 0.05153 | valid_rmsle: 0.00371 | valid_mae: 0.19579 | valid_rmse: 0.24976 | valid_mse: 0.06238 |  0:01:58s\n",
      "epoch 68 | loss: 0.05616 | train_rmsle: 0.0032  | train_mae: 0.17787 | train_rmse: 0.22875 | train_mse: 0.05233 | valid_rmsle: 0.00387 | valid_mae: 0.19988 | valid_rmse: 0.25504 | valid_mse: 0.06505 |  0:01:59s\n",
      "epoch 69 | loss: 0.05049 | train_rmsle: 0.00292 | train_mae: 0.16774 | train_rmse: 0.2174  | train_mse: 0.04726 | valid_rmsle: 0.00374 | valid_mae: 0.19434 | valid_rmse: 0.24892 | valid_mse: 0.06196 |  0:02:01s\n",
      "epoch 70 | loss: 0.04953 | train_rmsle: 0.00279 | train_mae: 0.16727 | train_rmse: 0.2156  | train_mse: 0.04648 | valid_rmsle: 0.00358 | valid_mae: 0.19084 | valid_rmse: 0.24644 | valid_mse: 0.06073 |  0:02:03s\n",
      "epoch 71 | loss: 0.04946 | train_rmsle: 0.00267 | train_mae: 0.16093 | train_rmse: 0.20883 | train_mse: 0.04361 | valid_rmsle: 0.00338 | valid_mae: 0.18347 | valid_rmse: 0.23832 | valid_mse: 0.0568  |  0:02:05s\n",
      "epoch 72 | loss: 0.04646 | train_rmsle: 0.00282 | train_mae: 0.16367 | train_rmse: 0.21208 | train_mse: 0.04498 | valid_rmsle: 0.00344 | valid_mae: 0.18267 | valid_rmse: 0.23811 | valid_mse: 0.05669 |  0:02:06s\n",
      "epoch 73 | loss: 0.04691 | train_rmsle: 0.00258 | train_mae: 0.16154 | train_rmse: 0.20727 | train_mse: 0.04296 | valid_rmsle: 0.00325 | valid_mae: 0.18232 | valid_rmse: 0.23463 | valid_mse: 0.05505 |  0:02:08s\n",
      "epoch 74 | loss: 0.04614 | train_rmsle: 0.00242 | train_mae: 0.15402 | train_rmse: 0.19926 | train_mse: 0.03971 | valid_rmsle: 0.0031  | valid_mae: 0.17705 | valid_rmse: 0.22789 | valid_mse: 0.05194 |  0:02:10s\n",
      "epoch 75 | loss: 0.04088 | train_rmsle: 0.00212 | train_mae: 0.14695 | train_rmse: 0.18956 | train_mse: 0.03593 | valid_rmsle: 0.00282 | valid_mae: 0.16852 | valid_rmse: 0.21865 | valid_mse: 0.04781 |  0:02:12s\n",
      "epoch 76 | loss: 0.04193 | train_rmsle: 0.00216 | train_mae: 0.14751 | train_rmse: 0.19047 | train_mse: 0.03628 | valid_rmsle: 0.00287 | valid_mae: 0.17136 | valid_rmse: 0.22111 | valid_mse: 0.04889 |  0:02:14s\n",
      "epoch 77 | loss: 0.04086 | train_rmsle: 0.00211 | train_mae: 0.14598 | train_rmse: 0.18802 | train_mse: 0.03535 | valid_rmsle: 0.00282 | valid_mae: 0.16869 | valid_rmse: 0.21854 | valid_mse: 0.04776 |  0:02:15s\n",
      "epoch 78 | loss: 0.03822 | train_rmsle: 0.002   | train_mae: 0.14323 | train_rmse: 0.18481 | train_mse: 0.03416 | valid_rmsle: 0.00273 | valid_mae: 0.16687 | valid_rmse: 0.21607 | valid_mse: 0.04669 |  0:02:17s\n",
      "epoch 79 | loss: 0.0376  | train_rmsle: 0.00181 | train_mae: 0.13279 | train_rmse: 0.17403 | train_mse: 0.03029 | valid_rmsle: 0.00266 | valid_mae: 0.15953 | valid_rmse: 0.21065 | valid_mse: 0.04437 |  0:02:19s\n",
      "epoch 80 | loss: 0.03402 | train_rmsle: 0.00187 | train_mae: 0.13624 | train_rmse: 0.17669 | train_mse: 0.03122 | valid_rmsle: 0.00271 | valid_mae: 0.16239 | valid_rmse: 0.21318 | valid_mse: 0.04544 |  0:02:21s\n",
      "epoch 81 | loss: 0.03433 | train_rmsle: 0.00173 | train_mae: 0.13313 | train_rmse: 0.17329 | train_mse: 0.03003 | valid_rmsle: 0.00247 | valid_mae: 0.15777 | valid_rmse: 0.20584 | valid_mse: 0.04237 |  0:02:22s\n",
      "epoch 82 | loss: 0.03259 | train_rmsle: 0.00163 | train_mae: 0.12662 | train_rmse: 0.16602 | train_mse: 0.02756 | valid_rmsle: 0.00244 | valid_mae: 0.15306 | valid_rmse: 0.20297 | valid_mse: 0.0412  |  0:02:24s\n",
      "epoch 83 | loss: 0.03261 | train_rmsle: 0.00155 | train_mae: 0.12596 | train_rmse: 0.16383 | train_mse: 0.02684 | valid_rmsle: 0.00225 | valid_mae: 0.14924 | valid_rmse: 0.19635 | valid_mse: 0.03855 |  0:02:26s\n",
      "epoch 84 | loss: 0.03359 | train_rmsle: 0.00161 | train_mae: 0.12998 | train_rmse: 0.16799 | train_mse: 0.02822 | valid_rmsle: 0.00225 | valid_mae: 0.1523  | valid_rmse: 0.19802 | valid_mse: 0.03921 |  0:02:28s\n",
      "epoch 85 | loss: 0.03117 | train_rmsle: 0.00143 | train_mae: 0.11844 | train_rmse: 0.15531 | train_mse: 0.02412 | valid_rmsle: 0.00209 | valid_mae: 0.1425  | valid_rmse: 0.18817 | valid_mse: 0.03541 |  0:02:29s\n",
      "epoch 86 | loss: 0.02981 | train_rmsle: 0.00155 | train_mae: 0.12437 | train_rmse: 0.16207 | train_mse: 0.02627 | valid_rmsle: 0.00216 | valid_mae: 0.14584 | valid_rmse: 0.19146 | valid_mse: 0.03666 |  0:02:31s\n",
      "epoch 87 | loss: 0.03131 | train_rmsle: 0.00163 | train_mae: 0.1306  | train_rmse: 0.16816 | train_mse: 0.02828 | valid_rmsle: 0.00216 | valid_mae: 0.1498  | valid_rmse: 0.1938  | valid_mse: 0.03756 |  0:02:33s\n",
      "epoch 88 | loss: 0.02943 | train_rmsle: 0.00161 | train_mae: 0.13199 | train_rmse: 0.16841 | train_mse: 0.02836 | valid_rmsle: 0.00204 | valid_mae: 0.14859 | valid_rmse: 0.18996 | valid_mse: 0.03608 |  0:02:35s\n",
      "epoch 89 | loss: 0.02857 | train_rmsle: 0.00131 | train_mae: 0.11313 | train_rmse: 0.14908 | train_mse: 0.02222 | valid_rmsle: 0.00182 | valid_mae: 0.13542 | valid_rmse: 0.17615 | valid_mse: 0.03103 |  0:02:36s\n",
      "epoch 90 | loss: 0.02802 | train_rmsle: 0.00121 | train_mae: 0.1113  | train_rmse: 0.14592 | train_mse: 0.02129 | valid_rmsle: 0.00164 | valid_mae: 0.13225 | valid_rmse: 0.17087 | valid_mse: 0.0292  |  0:02:38s\n",
      "epoch 91 | loss: 0.02662 | train_rmsle: 0.00118 | train_mae: 0.10913 | train_rmse: 0.14324 | train_mse: 0.02052 | valid_rmsle: 0.00164 | valid_mae: 0.13214 | valid_rmse: 0.17111 | valid_mse: 0.02928 |  0:02:40s\n",
      "epoch 92 | loss: 0.02506 | train_rmsle: 0.00164 | train_mae: 0.12757 | train_rmse: 0.16641 | train_mse: 0.02769 | valid_rmsle: 0.00197 | valid_mae: 0.14708 | valid_rmse: 0.18771 | valid_mse: 0.03524 |  0:02:42s\n",
      "epoch 93 | loss: 0.02858 | train_rmsle: 0.00145 | train_mae: 0.12181 | train_rmse: 0.15894 | train_mse: 0.02526 | valid_rmsle: 0.00194 | valid_mae: 0.14121 | valid_rmse: 0.18528 | valid_mse: 0.03433 |  0:02:43s\n",
      "epoch 94 | loss: 0.0278  | train_rmsle: 0.00127 | train_mae: 0.11324 | train_rmse: 0.14762 | train_mse: 0.02179 | valid_rmsle: 0.0017  | valid_mae: 0.13487 | valid_rmse: 0.17369 | valid_mse: 0.03017 |  0:02:45s\n",
      "epoch 95 | loss: 0.02489 | train_rmsle: 0.00114 | train_mae: 0.10631 | train_rmse: 0.13988 | train_mse: 0.01957 | valid_rmsle: 0.0015  | valid_mae: 0.12659 | valid_rmse: 0.16401 | valid_mse: 0.0269  |  0:02:47s\n",
      "epoch 96 | loss: 0.02456 | train_rmsle: 0.0011  | train_mae: 0.10613 | train_rmse: 0.13918 | train_mse: 0.01937 | valid_rmsle: 0.00155 | valid_mae: 0.12895 | valid_rmse: 0.16648 | valid_mse: 0.02772 |  0:02:48s\n",
      "epoch 97 | loss: 0.02389 | train_rmsle: 0.00102 | train_mae: 0.10137 | train_rmse: 0.13392 | train_mse: 0.01793 | valid_rmsle: 0.00142 | valid_mae: 0.12304 | valid_rmse: 0.1601  | valid_mse: 0.02563 |  0:02:50s\n",
      "epoch 98 | loss: 0.02342 | train_rmsle: 0.00099 | train_mae: 0.09939 | train_rmse: 0.13124 | train_mse: 0.01722 | valid_rmsle: 0.00139 | valid_mae: 0.12203 | valid_rmse: 0.15754 | valid_mse: 0.02482 |  0:02:51s\n",
      "epoch 99 | loss: 0.02393 | train_rmsle: 0.00098 | train_mae: 0.09848 | train_rmse: 0.12981 | train_mse: 0.01685 | valid_rmsle: 0.0014  | valid_mae: 0.11932 | valid_rmse: 0.15706 | valid_mse: 0.02467 |  0:02:53s\n",
      "epoch 100| loss: 0.02329 | train_rmsle: 0.00107 | train_mae: 0.10177 | train_rmse: 0.13416 | train_mse: 0.018   | valid_rmsle: 0.00142 | valid_mae: 0.12233 | valid_rmse: 0.15895 | valid_mse: 0.02526 |  0:02:54s\n",
      "epoch 101| loss: 0.02139 | train_rmsle: 0.00097 | train_mae: 0.10231 | train_rmse: 0.13321 | train_mse: 0.01774 | valid_rmsle: 0.00137 | valid_mae: 0.12319 | valid_rmse: 0.15904 | valid_mse: 0.02529 |  0:02:56s\n",
      "epoch 102| loss: 0.02199 | train_rmsle: 0.00109 | train_mae: 0.10826 | train_rmse: 0.13894 | train_mse: 0.01931 | valid_rmsle: 0.00146 | valid_mae: 0.12796 | valid_rmse: 0.16291 | valid_mse: 0.02654 |  0:02:57s\n",
      "epoch 103| loss: 0.02415 | train_rmsle: 0.00103 | train_mae: 0.10493 | train_rmse: 0.13472 | train_mse: 0.01815 | valid_rmsle: 0.00139 | valid_mae: 0.12475 | valid_rmse: 0.15848 | valid_mse: 0.02512 |  0:02:59s\n",
      "epoch 104| loss: 0.02127 | train_rmsle: 0.00084 | train_mae: 0.09148 | train_rmse: 0.12125 | train_mse: 0.0147  | valid_rmsle: 0.00119 | valid_mae: 0.11118 | valid_rmse: 0.14722 | valid_mse: 0.02168 |  0:03:01s\n",
      "epoch 105| loss: 0.02021 | train_rmsle: 0.00078 | train_mae: 0.08872 | train_rmse: 0.11796 | train_mse: 0.01391 | valid_rmsle: 0.00118 | valid_mae: 0.11032 | valid_rmse: 0.14585 | valid_mse: 0.02127 |  0:03:03s\n",
      "epoch 106| loss: 0.01995 | train_rmsle: 0.00114 | train_mae: 0.11146 | train_rmse: 0.14227 | train_mse: 0.02024 | valid_rmsle: 0.00154 | valid_mae: 0.13016 | valid_rmse: 0.16718 | valid_mse: 0.02795 |  0:03:04s\n",
      "epoch 107| loss: 0.02006 | train_rmsle: 0.00077 | train_mae: 0.08688 | train_rmse: 0.11752 | train_mse: 0.01381 | valid_rmsle: 0.00122 | valid_mae: 0.11004 | valid_rmse: 0.14837 | valid_mse: 0.02201 |  0:03:06s\n",
      "epoch 108| loss: 0.01798 | train_rmsle: 0.00078 | train_mae: 0.08819 | train_rmse: 0.11636 | train_mse: 0.01354 | valid_rmsle: 0.0012  | valid_mae: 0.1107  | valid_rmse: 0.14518 | valid_mse: 0.02108 |  0:03:08s\n",
      "epoch 109| loss: 0.01782 | train_rmsle: 0.00075 | train_mae: 0.08775 | train_rmse: 0.11501 | train_mse: 0.01323 | valid_rmsle: 0.00116 | valid_mae: 0.10892 | valid_rmse: 0.14332 | valid_mse: 0.02054 |  0:03:10s\n",
      "epoch 110| loss: 0.02032 | train_rmsle: 0.00072 | train_mae: 0.08631 | train_rmse: 0.11408 | train_mse: 0.01301 | valid_rmsle: 0.00112 | valid_mae: 0.10682 | valid_rmse: 0.14276 | valid_mse: 0.02038 |  0:03:11s\n",
      "epoch 111| loss: 0.0184  | train_rmsle: 0.00069 | train_mae: 0.0844  | train_rmse: 0.112   | train_mse: 0.01254 | valid_rmsle: 0.00106 | valid_mae: 0.10436 | valid_rmse: 0.13957 | valid_mse: 0.01948 |  0:03:13s\n",
      "epoch 112| loss: 0.01841 | train_rmsle: 0.00098 | train_mae: 0.1013  | train_rmse: 0.13273 | train_mse: 0.01762 | valid_rmsle: 0.00138 | valid_mae: 0.12124 | valid_rmse: 0.15761 | valid_mse: 0.02484 |  0:03:15s\n",
      "epoch 113| loss: 0.01874 | train_rmsle: 0.00079 | train_mae: 0.08749 | train_rmse: 0.1163  | train_mse: 0.01353 | valid_rmsle: 0.0011  | valid_mae: 0.107   | valid_rmse: 0.13987 | valid_mse: 0.01956 |  0:03:17s\n",
      "epoch 114| loss: 0.01811 | train_rmsle: 0.00073 | train_mae: 0.08604 | train_rmse: 0.11339 | train_mse: 0.01286 | valid_rmsle: 0.00109 | valid_mae: 0.10682 | valid_rmse: 0.14097 | valid_mse: 0.01987 |  0:03:19s\n",
      "epoch 115| loss: 0.01818 | train_rmsle: 0.00065 | train_mae: 0.08165 | train_rmse: 0.10736 | train_mse: 0.01153 | valid_rmsle: 0.00106 | valid_mae: 0.103   | valid_rmse: 0.13731 | valid_mse: 0.01885 |  0:03:20s\n",
      "epoch 116| loss: 0.01843 | train_rmsle: 0.00078 | train_mae: 0.08845 | train_rmse: 0.11587 | train_mse: 0.01343 | valid_rmsle: 0.00119 | valid_mae: 0.10984 | valid_rmse: 0.14407 | valid_mse: 0.02075 |  0:03:22s\n",
      "epoch 117| loss: 0.01753 | train_rmsle: 0.00095 | train_mae: 0.10379 | train_rmse: 0.12914 | train_mse: 0.01668 | valid_rmsle: 0.00132 | valid_mae: 0.12207 | valid_rmse: 0.15431 | valid_mse: 0.02381 |  0:03:24s\n",
      "epoch 118| loss: 0.01932 | train_rmsle: 0.00102 | train_mae: 0.111   | train_rmse: 0.13828 | train_mse: 0.01912 | valid_rmsle: 0.00144 | valid_mae: 0.12779 | valid_rmse: 0.16413 | valid_mse: 0.02694 |  0:03:26s\n",
      "epoch 119| loss: 0.01785 | train_rmsle: 0.00057 | train_mae: 0.07753 | train_rmse: 0.10173 | train_mse: 0.01035 | valid_rmsle: 0.00095 | valid_mae: 0.09872 | valid_rmse: 0.13159 | valid_mse: 0.01732 |  0:03:27s\n",
      "epoch 120| loss: 0.01762 | train_rmsle: 0.00075 | train_mae: 0.08979 | train_rmse: 0.11438 | train_mse: 0.01308 | valid_rmsle: 0.00117 | valid_mae: 0.10914 | valid_rmse: 0.1431  | valid_mse: 0.02048 |  0:03:29s\n",
      "epoch 121| loss: 0.01673 | train_rmsle: 0.00063 | train_mae: 0.08202 | train_rmse: 0.10653 | train_mse: 0.01135 | valid_rmsle: 0.00103 | valid_mae: 0.10181 | valid_rmse: 0.13638 | valid_mse: 0.0186  |  0:03:31s\n",
      "epoch 122| loss: 0.01791 | train_rmsle: 0.00059 | train_mae: 0.07856 | train_rmse: 0.10257 | train_mse: 0.01052 | valid_rmsle: 0.00096 | valid_mae: 0.09872 | valid_rmse: 0.13201 | valid_mse: 0.01743 |  0:03:33s\n",
      "epoch 123| loss: 0.01535 | train_rmsle: 0.00055 | train_mae: 0.07447 | train_rmse: 0.09809 | train_mse: 0.00962 | valid_rmsle: 0.00088 | valid_mae: 0.09377 | valid_rmse: 0.12662 | valid_mse: 0.01603 |  0:03:34s\n",
      "epoch 124| loss: 0.01497 | train_rmsle: 0.00067 | train_mae: 0.08452 | train_rmse: 0.10905 | train_mse: 0.01189 | valid_rmsle: 0.00106 | valid_mae: 0.10524 | valid_rmse: 0.13768 | valid_mse: 0.01896 |  0:03:36s\n",
      "epoch 125| loss: 0.01471 | train_rmsle: 0.00058 | train_mae: 0.07889 | train_rmse: 0.10343 | train_mse: 0.0107  | valid_rmsle: 0.00092 | valid_mae: 0.10027 | valid_rmse: 0.13023 | valid_mse: 0.01696 |  0:03:38s\n",
      "epoch 126| loss: 0.0165  | train_rmsle: 0.00057 | train_mae: 0.07781 | train_rmse: 0.10184 | train_mse: 0.01037 | valid_rmsle: 0.00088 | valid_mae: 0.09721 | valid_rmse: 0.12725 | valid_mse: 0.01619 |  0:03:40s\n",
      "epoch 127| loss: 0.01517 | train_rmsle: 0.00054 | train_mae: 0.07286 | train_rmse: 0.09642 | train_mse: 0.0093  | valid_rmsle: 0.00083 | valid_mae: 0.09309 | valid_rmse: 0.12316 | valid_mse: 0.01517 |  0:03:41s\n",
      "epoch 128| loss: 0.01587 | train_rmsle: 0.00049 | train_mae: 0.0714  | train_rmse: 0.09424 | train_mse: 0.00888 | valid_rmsle: 0.00083 | valid_mae: 0.09238 | valid_rmse: 0.12266 | valid_mse: 0.01505 |  0:03:43s\n",
      "epoch 129| loss: 0.01553 | train_rmsle: 0.00053 | train_mae: 0.07432 | train_rmse: 0.09768 | train_mse: 0.00954 | valid_rmsle: 0.00088 | valid_mae: 0.09703 | valid_rmse: 0.12616 | valid_mse: 0.01592 |  0:03:45s\n",
      "epoch 130| loss: 0.01422 | train_rmsle: 0.00051 | train_mae: 0.07377 | train_rmse: 0.09636 | train_mse: 0.00929 | valid_rmsle: 0.00083 | valid_mae: 0.09333 | valid_rmse: 0.12319 | valid_mse: 0.01517 |  0:03:47s\n",
      "epoch 131| loss: 0.01658 | train_rmsle: 0.00047 | train_mae: 0.0705  | train_rmse: 0.09284 | train_mse: 0.00862 | valid_rmsle: 0.00077 | valid_mae: 0.09116 | valid_rmse: 0.11944 | valid_mse: 0.01427 |  0:03:48s\n",
      "epoch 132| loss: 0.01419 | train_rmsle: 0.00051 | train_mae: 0.07447 | train_rmse: 0.09724 | train_mse: 0.00946 | valid_rmsle: 0.00084 | valid_mae: 0.09577 | valid_rmse: 0.12485 | valid_mse: 0.01559 |  0:03:50s\n",
      "epoch 133| loss: 0.01318 | train_rmsle: 0.00052 | train_mae: 0.07376 | train_rmse: 0.09548 | train_mse: 0.00912 | valid_rmsle: 0.00085 | valid_mae: 0.09422 | valid_rmse: 0.12339 | valid_mse: 0.01523 |  0:03:52s\n",
      "epoch 134| loss: 0.01426 | train_rmsle: 0.00046 | train_mae: 0.06941 | train_rmse: 0.09049 | train_mse: 0.00819 | valid_rmsle: 0.00079 | valid_mae: 0.09082 | valid_rmse: 0.11932 | valid_mse: 0.01424 |  0:03:54s\n",
      "epoch 135| loss: 0.01376 | train_rmsle: 0.00046 | train_mae: 0.06791 | train_rmse: 0.08978 | train_mse: 0.00806 | valid_rmsle: 0.00079 | valid_mae: 0.08869 | valid_rmse: 0.11855 | valid_mse: 0.01405 |  0:03:55s\n",
      "epoch 136| loss: 0.01364 | train_rmsle: 0.00048 | train_mae: 0.07221 | train_rmse: 0.09329 | train_mse: 0.0087  | valid_rmsle: 0.00081 | valid_mae: 0.09425 | valid_rmse: 0.12197 | valid_mse: 0.01488 |  0:03:57s\n",
      "epoch 137| loss: 0.01421 | train_rmsle: 0.00044 | train_mae: 0.0671  | train_rmse: 0.08887 | train_mse: 0.0079  | valid_rmsle: 0.00077 | valid_mae: 0.08979 | valid_rmse: 0.11933 | valid_mse: 0.01424 |  0:03:59s\n",
      "epoch 138| loss: 0.01301 | train_rmsle: 0.00043 | train_mae: 0.0679  | train_rmse: 0.08871 | train_mse: 0.00787 | valid_rmsle: 0.00076 | valid_mae: 0.09037 | valid_rmse: 0.11771 | valid_mse: 0.01386 |  0:04:01s\n",
      "epoch 139| loss: 0.01356 | train_rmsle: 0.00045 | train_mae: 0.06897 | train_rmse: 0.08966 | train_mse: 0.00804 | valid_rmsle: 0.00074 | valid_mae: 0.09036 | valid_rmse: 0.11636 | valid_mse: 0.01354 |  0:04:02s\n",
      "epoch 140| loss: 0.01366 | train_rmsle: 0.00045 | train_mae: 0.06671 | train_rmse: 0.08806 | train_mse: 0.00776 | valid_rmsle: 0.00072 | valid_mae: 0.08713 | valid_rmse: 0.11469 | valid_mse: 0.01315 |  0:04:04s\n",
      "epoch 141| loss: 0.01375 | train_rmsle: 0.00046 | train_mae: 0.06884 | train_rmse: 0.08917 | train_mse: 0.00795 | valid_rmsle: 0.00077 | valid_mae: 0.09029 | valid_rmse: 0.11727 | valid_mse: 0.01375 |  0:04:06s\n",
      "epoch 142| loss: 0.01623 | train_rmsle: 0.0005  | train_mae: 0.07416 | train_rmse: 0.09527 | train_mse: 0.00908 | valid_rmsle: 0.00082 | valid_mae: 0.09514 | valid_rmse: 0.12249 | valid_mse: 0.015   |  0:04:08s\n",
      "epoch 143| loss: 0.01361 | train_rmsle: 0.00057 | train_mae: 0.07845 | train_rmse: 0.09999 | train_mse: 0.01    | valid_rmsle: 0.00084 | valid_mae: 0.09746 | valid_rmse: 0.12397 | valid_mse: 0.01537 |  0:04:09s\n",
      "epoch 144| loss: 0.0153  | train_rmsle: 0.00053 | train_mae: 0.07868 | train_rmse: 0.10064 | train_mse: 0.01013 | valid_rmsle: 0.00083 | valid_mae: 0.09774 | valid_rmse: 0.12443 | valid_mse: 0.01548 |  0:04:11s\n",
      "epoch 145| loss: 0.01275 | train_rmsle: 0.0004  | train_mae: 0.0641  | train_rmse: 0.0839  | train_mse: 0.00704 | valid_rmsle: 0.00071 | valid_mae: 0.0855  | valid_rmse: 0.1121  | valid_mse: 0.01257 |  0:04:13s\n",
      "epoch 146| loss: 0.01364 | train_rmsle: 0.00039 | train_mae: 0.06423 | train_rmse: 0.08412 | train_mse: 0.00708 | valid_rmsle: 0.00068 | valid_mae: 0.08398 | valid_rmse: 0.1107  | valid_mse: 0.01226 |  0:04:15s\n",
      "epoch 147| loss: 0.01261 | train_rmsle: 0.00055 | train_mae: 0.07414 | train_rmse: 0.09488 | train_mse: 0.009   | valid_rmsle: 0.00086 | valid_mae: 0.09496 | valid_rmse: 0.1218  | valid_mse: 0.01483 |  0:04:16s\n",
      "epoch 148| loss: 0.01437 | train_rmsle: 0.00049 | train_mae: 0.07286 | train_rmse: 0.09493 | train_mse: 0.00901 | valid_rmsle: 0.0008  | valid_mae: 0.09285 | valid_rmse: 0.12149 | valid_mse: 0.01476 |  0:04:18s\n",
      "epoch 149| loss: 0.01522 | train_rmsle: 0.00053 | train_mae: 0.07521 | train_rmse: 0.09765 | train_mse: 0.00954 | valid_rmsle: 0.00087 | valid_mae: 0.0953  | valid_rmse: 0.12627 | valid_mse: 0.01595 |  0:04:20s\n",
      "epoch 150| loss: 0.01421 | train_rmsle: 0.00073 | train_mae: 0.09296 | train_rmse: 0.11546 | train_mse: 0.01333 | valid_rmsle: 0.00103 | valid_mae: 0.11144 | valid_rmse: 0.13793 | valid_mse: 0.01902 |  0:04:22s\n",
      "epoch 151| loss: 0.01657 | train_rmsle: 0.00057 | train_mae: 0.08005 | train_rmse: 0.10281 | train_mse: 0.01057 | valid_rmsle: 0.00087 | valid_mae: 0.101   | valid_rmse: 0.12805 | valid_mse: 0.0164  |  0:04:23s\n",
      "epoch 152| loss: 0.013   | train_rmsle: 0.00058 | train_mae: 0.07788 | train_rmse: 0.0996  | train_mse: 0.00992 | valid_rmsle: 0.00086 | valid_mae: 0.09667 | valid_rmse: 0.12511 | valid_mse: 0.01565 |  0:04:25s\n",
      "epoch 153| loss: 0.01394 | train_rmsle: 0.00063 | train_mae: 0.08625 | train_rmse: 0.10763 | train_mse: 0.01159 | valid_rmsle: 0.00095 | valid_mae: 0.1044  | valid_rmse: 0.13258 | valid_mse: 0.01758 |  0:04:27s\n",
      "epoch 154| loss: 0.01272 | train_rmsle: 0.00059 | train_mae: 0.08053 | train_rmse: 0.10055 | train_mse: 0.01011 | valid_rmsle: 0.00088 | valid_mae: 0.09802 | valid_rmse: 0.12527 | valid_mse: 0.01569 |  0:04:28s\n",
      "epoch 155| loss: 0.01388 | train_rmsle: 0.00039 | train_mae: 0.06418 | train_rmse: 0.08411 | train_mse: 0.00707 | valid_rmsle: 0.0007  | valid_mae: 0.0849  | valid_rmse: 0.11301 | valid_mse: 0.01277 |  0:04:30s\n",
      "epoch 156| loss: 0.01354 | train_rmsle: 0.00046 | train_mae: 0.06698 | train_rmse: 0.0872  | train_mse: 0.0076  | valid_rmsle: 0.00078 | valid_mae: 0.08701 | valid_rmse: 0.11577 | valid_mse: 0.0134  |  0:04:32s\n",
      "epoch 157| loss: 0.01372 | train_rmsle: 0.00045 | train_mae: 0.06665 | train_rmse: 0.08672 | train_mse: 0.00752 | valid_rmsle: 0.00077 | valid_mae: 0.08771 | valid_rmse: 0.1157  | valid_mse: 0.01339 |  0:04:34s\n",
      "epoch 158| loss: 0.01129 | train_rmsle: 0.00044 | train_mae: 0.07052 | train_rmse: 0.09103 | train_mse: 0.00829 | valid_rmsle: 0.00073 | valid_mae: 0.08987 | valid_rmse: 0.11679 | valid_mse: 0.01364 |  0:04:35s\n",
      "epoch 159| loss: 0.01345 | train_rmsle: 0.00037 | train_mae: 0.06208 | train_rmse: 0.08126 | train_mse: 0.0066  | valid_rmsle: 0.00068 | valid_mae: 0.08375 | valid_rmse: 0.11055 | valid_mse: 0.01222 |  0:04:37s\n",
      "epoch 160| loss: 0.01254 | train_rmsle: 0.00036 | train_mae: 0.06051 | train_rmse: 0.07935 | train_mse: 0.0063  | valid_rmsle: 0.00065 | valid_mae: 0.08189 | valid_rmse: 0.1075  | valid_mse: 0.01156 |  0:04:39s\n",
      "epoch 161| loss: 0.01243 | train_rmsle: 0.00039 | train_mae: 0.06231 | train_rmse: 0.08169 | train_mse: 0.00667 | valid_rmsle: 0.00069 | valid_mae: 0.08431 | valid_rmse: 0.11058 | valid_mse: 0.01223 |  0:04:41s\n",
      "epoch 162| loss: 0.01271 | train_rmsle: 0.00037 | train_mae: 0.06232 | train_rmse: 0.08129 | train_mse: 0.00661 | valid_rmsle: 0.00066 | valid_mae: 0.08342 | valid_rmse: 0.10895 | valid_mse: 0.01187 |  0:04:42s\n",
      "epoch 163| loss: 0.01243 | train_rmsle: 0.00035 | train_mae: 0.06198 | train_rmse: 0.07968 | train_mse: 0.00635 | valid_rmsle: 0.00062 | valid_mae: 0.0825  | valid_rmse: 0.10643 | valid_mse: 0.01133 |  0:04:44s\n",
      "epoch 164| loss: 0.01163 | train_rmsle: 0.00038 | train_mae: 0.06463 | train_rmse: 0.08416 | train_mse: 0.00708 | valid_rmsle: 0.00068 | valid_mae: 0.08486 | valid_rmse: 0.11158 | valid_mse: 0.01245 |  0:04:46s\n",
      "epoch 165| loss: 0.01363 | train_rmsle: 0.00053 | train_mae: 0.07671 | train_rmse: 0.09549 | train_mse: 0.00912 | valid_rmsle: 0.00082 | valid_mae: 0.09334 | valid_rmse: 0.11976 | valid_mse: 0.01434 |  0:04:48s\n",
      "epoch 166| loss: 0.01155 | train_rmsle: 0.0009  | train_mae: 0.10276 | train_rmse: 0.12186 | train_mse: 0.01485 | valid_rmsle: 0.00112 | valid_mae: 0.1153  | valid_rmse: 0.14031 | valid_mse: 0.01969 |  0:04:49s\n",
      "epoch 167| loss: 0.01246 | train_rmsle: 0.00034 | train_mae: 0.06055 | train_rmse: 0.0793  | train_mse: 0.00629 | valid_rmsle: 0.00061 | valid_mae: 0.08205 | valid_rmse: 0.10637 | valid_mse: 0.01131 |  0:04:51s\n",
      "epoch 168| loss: 0.01168 | train_rmsle: 0.00032 | train_mae: 0.05935 | train_rmse: 0.07712 | train_mse: 0.00595 | valid_rmsle: 0.00062 | valid_mae: 0.08183 | valid_rmse: 0.10713 | valid_mse: 0.01148 |  0:04:53s\n",
      "epoch 169| loss: 0.01141 | train_rmsle: 0.00036 | train_mae: 0.06133 | train_rmse: 0.0796  | train_mse: 0.00634 | valid_rmsle: 0.00064 | valid_mae: 0.08227 | valid_rmse: 0.10838 | valid_mse: 0.01175 |  0:04:55s\n",
      "epoch 170| loss: 0.01405 | train_rmsle: 0.00034 | train_mae: 0.05867 | train_rmse: 0.07682 | train_mse: 0.0059  | valid_rmsle: 0.00065 | valid_mae: 0.08177 | valid_rmse: 0.10808 | valid_mse: 0.01168 |  0:04:56s\n",
      "epoch 171| loss: 0.01162 | train_rmsle: 0.00047 | train_mae: 0.07402 | train_rmse: 0.09284 | train_mse: 0.00862 | valid_rmsle: 0.00075 | valid_mae: 0.09225 | valid_rmse: 0.11823 | valid_mse: 0.01398 |  0:04:58s\n",
      "epoch 172| loss: 0.01127 | train_rmsle: 0.0003  | train_mae: 0.05647 | train_rmse: 0.07339 | train_mse: 0.00539 | valid_rmsle: 0.0006  | valid_mae: 0.07944 | valid_rmse: 0.10483 | valid_mse: 0.01099 |  0:05:00s\n",
      "epoch 173| loss: 0.01141 | train_rmsle: 0.00036 | train_mae: 0.06151 | train_rmse: 0.07911 | train_mse: 0.00626 | valid_rmsle: 0.00065 | valid_mae: 0.08181 | valid_rmse: 0.10725 | valid_mse: 0.0115  |  0:05:02s\n",
      "epoch 174| loss: 0.01293 | train_rmsle: 0.00032 | train_mae: 0.05746 | train_rmse: 0.07493 | train_mse: 0.00561 | valid_rmsle: 0.0006  | valid_mae: 0.07981 | valid_rmse: 0.10434 | valid_mse: 0.01089 |  0:05:03s\n",
      "epoch 175| loss: 0.01354 | train_rmsle: 0.0005  | train_mae: 0.07432 | train_rmse: 0.09129 | train_mse: 0.00833 | valid_rmsle: 0.00075 | valid_mae: 0.09175 | valid_rmse: 0.11468 | valid_mse: 0.01315 |  0:05:05s\n",
      "epoch 176| loss: 0.01204 | train_rmsle: 0.00031 | train_mae: 0.05826 | train_rmse: 0.07549 | train_mse: 0.0057  | valid_rmsle: 0.00058 | valid_mae: 0.07966 | valid_rmse: 0.10307 | valid_mse: 0.01062 |  0:05:07s\n",
      "epoch 177| loss: 0.01125 | train_rmsle: 0.00059 | train_mae: 0.07504 | train_rmse: 0.09538 | train_mse: 0.0091  | valid_rmsle: 0.00087 | valid_mae: 0.09218 | valid_rmse: 0.11924 | valid_mse: 0.01422 |  0:05:09s\n",
      "epoch 178| loss: 0.01504 | train_rmsle: 0.00056 | train_mae: 0.08239 | train_rmse: 0.10134 | train_mse: 0.01027 | valid_rmsle: 0.00084 | valid_mae: 0.09711 | valid_rmse: 0.12385 | valid_mse: 0.01534 |  0:05:10s\n",
      "epoch 179| loss: 0.01496 | train_rmsle: 0.00035 | train_mae: 0.06052 | train_rmse: 0.07889 | train_mse: 0.00622 | valid_rmsle: 0.00063 | valid_mae: 0.08182 | valid_rmse: 0.10696 | valid_mse: 0.01144 |  0:05:12s\n",
      "epoch 180| loss: 0.01092 | train_rmsle: 0.0003  | train_mae: 0.05602 | train_rmse: 0.07374 | train_mse: 0.00544 | valid_rmsle: 0.00056 | valid_mae: 0.07774 | valid_rmse: 0.1014  | valid_mse: 0.01028 |  0:05:13s\n",
      "epoch 181| loss: 0.01192 | train_rmsle: 0.0003  | train_mae: 0.05615 | train_rmse: 0.07393 | train_mse: 0.00547 | valid_rmsle: 0.00056 | valid_mae: 0.07613 | valid_rmse: 0.10112 | valid_mse: 0.01023 |  0:05:15s\n",
      "epoch 182| loss: 0.01128 | train_rmsle: 0.00037 | train_mae: 0.06464 | train_rmse: 0.08137 | train_mse: 0.00662 | valid_rmsle: 0.00063 | valid_mae: 0.08487 | valid_rmse: 0.10633 | valid_mse: 0.01131 |  0:05:16s\n",
      "epoch 183| loss: 0.01089 | train_rmsle: 0.00049 | train_mae: 0.07147 | train_rmse: 0.0906  | train_mse: 0.00821 | valid_rmsle: 0.00069 | valid_mae: 0.0885  | valid_rmse: 0.11209 | valid_mse: 0.01256 |  0:05:18s\n",
      "epoch 184| loss: 0.00974 | train_rmsle: 0.00054 | train_mae: 0.07877 | train_rmse: 0.09628 | train_mse: 0.00927 | valid_rmsle: 0.00081 | valid_mae: 0.09669 | valid_rmse: 0.11913 | valid_mse: 0.01419 |  0:05:19s\n",
      "epoch 185| loss: 0.01072 | train_rmsle: 0.00029 | train_mae: 0.05594 | train_rmse: 0.07194 | train_mse: 0.00518 | valid_rmsle: 0.00056 | valid_mae: 0.07799 | valid_rmse: 0.10141 | valid_mse: 0.01028 |  0:05:21s\n",
      "epoch 186| loss: 0.01102 | train_rmsle: 0.00026 | train_mae: 0.0537  | train_rmse: 0.06974 | train_mse: 0.00486 | valid_rmsle: 0.00055 | valid_mae: 0.07709 | valid_rmse: 0.10054 | valid_mse: 0.01011 |  0:05:23s\n",
      "epoch 187| loss: 0.01088 | train_rmsle: 0.00031 | train_mae: 0.05667 | train_rmse: 0.07317 | train_mse: 0.00535 | valid_rmsle: 0.0006  | valid_mae: 0.08074 | valid_rmse: 0.10377 | valid_mse: 0.01077 |  0:05:25s\n",
      "epoch 188| loss: 0.01233 | train_rmsle: 0.00062 | train_mae: 0.08562 | train_rmse: 0.10327 | train_mse: 0.01066 | valid_rmsle: 0.00088 | valid_mae: 0.10135 | valid_rmse: 0.12447 | valid_mse: 0.01549 |  0:05:26s\n",
      "epoch 189| loss: 0.00978 | train_rmsle: 0.00027 | train_mae: 0.05418 | train_rmse: 0.07018 | train_mse: 0.00493 | valid_rmsle: 0.00056 | valid_mae: 0.07785 | valid_rmse: 0.1009  | valid_mse: 0.01018 |  0:05:28s\n",
      "epoch 190| loss: 0.01025 | train_rmsle: 0.00042 | train_mae: 0.07084 | train_rmse: 0.08892 | train_mse: 0.00791 | valid_rmsle: 0.0007  | valid_mae: 0.09074 | valid_rmse: 0.11412 | valid_mse: 0.01302 |  0:05:30s\n",
      "epoch 191| loss: 0.01041 | train_rmsle: 0.00027 | train_mae: 0.05447 | train_rmse: 0.07004 | train_mse: 0.00491 | valid_rmsle: 0.00056 | valid_mae: 0.07842 | valid_rmse: 0.10139 | valid_mse: 0.01028 |  0:05:32s\n",
      "epoch 192| loss: 0.01198 | train_rmsle: 0.00029 | train_mae: 0.05382 | train_rmse: 0.07048 | train_mse: 0.00497 | valid_rmsle: 0.00059 | valid_mae: 0.07704 | valid_rmse: 0.10153 | valid_mse: 0.01031 |  0:05:34s\n",
      "epoch 193| loss: 0.01193 | train_rmsle: 0.00048 | train_mae: 0.07298 | train_rmse: 0.08962 | train_mse: 0.00803 | valid_rmsle: 0.00078 | valid_mae: 0.08973 | valid_rmse: 0.11641 | valid_mse: 0.01355 |  0:05:35s\n",
      "epoch 194| loss: 0.00998 | train_rmsle: 0.00035 | train_mae: 0.06121 | train_rmse: 0.07866 | train_mse: 0.00619 | valid_rmsle: 0.00066 | valid_mae: 0.08168 | valid_rmse: 0.10969 | valid_mse: 0.01203 |  0:05:37s\n",
      "epoch 195| loss: 0.01031 | train_rmsle: 0.00028 | train_mae: 0.0545  | train_rmse: 0.07082 | train_mse: 0.00502 | valid_rmsle: 0.00059 | valid_mae: 0.07799 | valid_rmse: 0.10336 | valid_mse: 0.01068 |  0:05:39s\n",
      "epoch 196| loss: 0.01012 | train_rmsle: 0.00026 | train_mae: 0.0522  | train_rmse: 0.06815 | train_mse: 0.00465 | valid_rmsle: 0.00055 | valid_mae: 0.07623 | valid_rmse: 0.10009 | valid_mse: 0.01002 |  0:05:41s\n",
      "epoch 197| loss: 0.00914 | train_rmsle: 0.00025 | train_mae: 0.05064 | train_rmse: 0.06613 | train_mse: 0.00437 | valid_rmsle: 0.00053 | valid_mae: 0.07487 | valid_rmse: 0.09797 | valid_mse: 0.0096  |  0:05:42s\n",
      "epoch 198| loss: 0.00939 | train_rmsle: 0.00036 | train_mae: 0.06401 | train_rmse: 0.08044 | train_mse: 0.00647 | valid_rmsle: 0.00065 | valid_mae: 0.08578 | valid_rmse: 0.10833 | valid_mse: 0.01174 |  0:05:44s\n",
      "epoch 199| loss: 0.01158 | train_rmsle: 0.00024 | train_mae: 0.05132 | train_rmse: 0.06688 | train_mse: 0.00447 | valid_rmsle: 0.00054 | valid_mae: 0.07656 | valid_rmse: 0.09985 | valid_mse: 0.00997 |  0:05:46s\n",
      "epoch 200| loss: 0.01038 | train_rmsle: 0.00056 | train_mae: 0.08167 | train_rmse: 0.09863 | train_mse: 0.00973 | valid_rmsle: 0.00082 | valid_mae: 0.09871 | valid_rmse: 0.12125 | valid_mse: 0.0147  |  0:05:48s\n",
      "epoch 201| loss: 0.01054 | train_rmsle: 0.00032 | train_mae: 0.05394 | train_rmse: 0.07103 | train_mse: 0.00505 | valid_rmsle: 0.00061 | valid_mae: 0.07808 | valid_rmse: 0.10155 | valid_mse: 0.01031 |  0:05:50s\n",
      "epoch 202| loss: 0.01047 | train_rmsle: 0.00023 | train_mae: 0.04963 | train_rmse: 0.06461 | train_mse: 0.00417 | valid_rmsle: 0.00055 | valid_mae: 0.07578 | valid_rmse: 0.09901 | valid_mse: 0.0098  |  0:05:51s\n",
      "epoch 203| loss: 0.01057 | train_rmsle: 0.00025 | train_mae: 0.05215 | train_rmse: 0.06767 | train_mse: 0.00458 | valid_rmsle: 0.00057 | valid_mae: 0.07851 | valid_rmse: 0.10145 | valid_mse: 0.01029 |  0:05:53s\n",
      "epoch 204| loss: 0.00965 | train_rmsle: 0.00022 | train_mae: 0.04856 | train_rmse: 0.06346 | train_mse: 0.00403 | valid_rmsle: 0.00055 | valid_mae: 0.0756  | valid_rmse: 0.09984 | valid_mse: 0.00997 |  0:05:55s\n",
      "epoch 205| loss: 0.00999 | train_rmsle: 0.00023 | train_mae: 0.04957 | train_rmse: 0.06438 | train_mse: 0.00414 | valid_rmsle: 0.00054 | valid_mae: 0.07545 | valid_rmse: 0.09856 | valid_mse: 0.00971 |  0:05:57s\n",
      "epoch 206| loss: 0.00967 | train_rmsle: 0.00024 | train_mae: 0.05116 | train_rmse: 0.06603 | train_mse: 0.00436 | valid_rmsle: 0.00058 | valid_mae: 0.07687 | valid_rmse: 0.10226 | valid_mse: 0.01046 |  0:05:58s\n",
      "epoch 207| loss: 0.0126  | train_rmsle: 0.00058 | train_mae: 0.07875 | train_rmse: 0.10053 | train_mse: 0.01011 | valid_rmsle: 0.00088 | valid_mae: 0.09781 | valid_rmse: 0.12354 | valid_mse: 0.01526 |  0:06:00s\n",
      "epoch 208| loss: 0.01395 | train_rmsle: 0.00064 | train_mae: 0.07948 | train_rmse: 0.10005 | train_mse: 0.01001 | valid_rmsle: 0.00091 | valid_mae: 0.09839 | valid_rmse: 0.12382 | valid_mse: 0.01533 |  0:06:02s\n",
      "epoch 209| loss: 0.0124  | train_rmsle: 0.00053 | train_mae: 0.07693 | train_rmse: 0.09799 | train_mse: 0.0096  | valid_rmsle: 0.00087 | valid_mae: 0.09791 | valid_rmse: 0.12615 | valid_mse: 0.01591 |  0:06:04s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 197 and best_valid_mse = 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010340481997878953 RMSE: 0.10168816055902945 R2: 0.9542266705751753 MAE: 0.07635853459846426\n",
      "=====================================\n",
      "[57/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.0241  | train_rmsle: 0.42023 | train_mae: 2.02722 | train_rmse: 2.08462 | train_mse: 4.34565 | valid_rmsle: 0.42195 | valid_mae: 2.03366 | valid_rmse: 2.08989 | valid_mse: 4.36764 |  0:00:01s\n",
      "epoch 1  | loss: 1.26435 | train_rmsle: 0.08715 | train_mae: 1.04995 | train_rmse: 1.13899 | train_mse: 1.29731 | valid_rmsle: 0.08744 | valid_mae: 1.05208 | valid_rmse: 1.14235 | valid_mse: 1.30497 |  0:00:03s\n",
      "epoch 2  | loss: 0.66443 | train_rmsle: 0.03323 | train_mae: 0.65547 | train_rmse: 0.7478  | train_mse: 0.5592  | valid_rmsle: 0.03309 | valid_mae: 0.65463 | valid_rmse: 0.74927 | valid_mse: 0.5614  |  0:00:05s\n",
      "epoch 3  | loss: 0.46895 | train_rmsle: 0.0287  | train_mae: 0.60706 | train_rmse: 0.69852 | train_mse: 0.48793 | valid_rmsle: 0.02851 | valid_mae: 0.60685 | valid_rmse: 0.69957 | valid_mse: 0.4894  |  0:00:07s\n",
      "epoch 4  | loss: 0.36125 | train_rmsle: 0.02834 | train_mae: 0.60289 | train_rmse: 0.69434 | train_mse: 0.48211 | valid_rmsle: 0.02812 | valid_mae: 0.60293 | valid_rmse: 0.69501 | valid_mse: 0.48304 |  0:00:08s\n",
      "epoch 5  | loss: 0.31669 | train_rmsle: 0.02383 | train_mae: 0.5488  | train_rmse: 0.63874 | train_mse: 0.40799 | valid_rmsle: 0.02353 | valid_mae: 0.54919 | valid_rmse: 0.6387  | valid_mse: 0.40793 |  0:00:10s\n",
      "epoch 6  | loss: 0.2964  | train_rmsle: 0.01891 | train_mae: 0.4799  | train_rmse: 0.56781 | train_mse: 0.32241 | valid_rmsle: 0.01851 | valid_mae: 0.48074 | valid_rmse: 0.56651 | valid_mse: 0.32094 |  0:00:12s\n",
      "epoch 7  | loss: 0.26732 | train_rmsle: 0.02251 | train_mae: 0.53234 | train_rmse: 0.62113 | train_mse: 0.3858  | valid_rmsle: 0.02223 | valid_mae: 0.53328 | valid_rmse: 0.62123 | valid_mse: 0.38593 |  0:00:14s\n",
      "epoch 8  | loss: 0.24704 | train_rmsle: 0.01172 | train_mae: 0.36924 | train_rmse: 0.4417  | train_mse: 0.1951  | valid_rmsle: 0.01118 | valid_mae: 0.36263 | valid_rmse: 0.43568 | valid_mse: 0.18981 |  0:00:15s\n",
      "epoch 9  | loss: 0.20943 | train_rmsle: 0.014   | train_mae: 0.38085 | train_rmse: 0.46603 | train_mse: 0.21719 | valid_rmsle: 0.0129  | valid_mae: 0.36525 | valid_rmse: 0.44985 | valid_mse: 0.20236 |  0:00:17s\n",
      "epoch 10 | loss: 0.18553 | train_rmsle: 0.01022 | train_mae: 0.31879 | train_rmse: 0.39978 | train_mse: 0.15982 | valid_rmsle: 0.00939 | valid_mae: 0.30285 | valid_rmse: 0.38474 | valid_mse: 0.14803 |  0:00:19s\n",
      "epoch 11 | loss: 0.17548 | train_rmsle: 0.01212 | train_mae: 0.35383 | train_rmse: 0.43644 | train_mse: 0.19048 | valid_rmsle: 0.01144 | valid_mae: 0.34205 | valid_rmse: 0.42605 | valid_mse: 0.18152 |  0:00:21s\n",
      "epoch 12 | loss: 0.16351 | train_rmsle: 0.00863 | train_mae: 0.29061 | train_rmse: 0.36826 | train_mse: 0.13561 | valid_rmsle: 0.00785 | valid_mae: 0.275   | valid_rmse: 0.35271 | valid_mse: 0.1244  |  0:00:22s\n",
      "epoch 13 | loss: 0.16167 | train_rmsle: 0.00982 | train_mae: 0.32122 | train_rmse: 0.39621 | train_mse: 0.15698 | valid_rmsle: 0.00891 | valid_mae: 0.30545 | valid_rmse: 0.37867 | valid_mse: 0.14339 |  0:00:24s\n",
      "epoch 14 | loss: 0.15853 | train_rmsle: 0.00763 | train_mae: 0.27367 | train_rmse: 0.34561 | train_mse: 0.11945 | valid_rmsle: 0.00687 | valid_mae: 0.26087 | valid_rmse: 0.33148 | valid_mse: 0.10988 |  0:00:26s\n",
      "epoch 15 | loss: 0.1516  | train_rmsle: 0.00694 | train_mae: 0.24931 | train_rmse: 0.32541 | train_mse: 0.10589 | valid_rmsle: 0.00645 | valid_mae: 0.24186 | valid_rmse: 0.31818 | valid_mse: 0.10124 |  0:00:28s\n",
      "epoch 16 | loss: 0.15005 | train_rmsle: 0.00776 | train_mae: 0.27975 | train_rmse: 0.35031 | train_mse: 0.12272 | valid_rmsle: 0.00693 | valid_mae: 0.26661 | valid_rmse: 0.33434 | valid_mse: 0.11178 |  0:00:29s\n",
      "epoch 17 | loss: 0.13835 | train_rmsle: 0.007   | train_mae: 0.25865 | train_rmse: 0.32946 | train_mse: 0.10854 | valid_rmsle: 0.00627 | valid_mae: 0.24664 | valid_rmse: 0.31511 | valid_mse: 0.0993  |  0:00:31s\n",
      "epoch 18 | loss: 0.13278 | train_rmsle: 0.00708 | train_mae: 0.26002 | train_rmse: 0.33204 | train_mse: 0.11025 | valid_rmsle: 0.00651 | valid_mae: 0.25114 | valid_rmse: 0.32192 | valid_mse: 0.10363 |  0:00:33s\n",
      "epoch 19 | loss: 0.12889 | train_rmsle: 0.00859 | train_mae: 0.3011  | train_rmse: 0.37092 | train_mse: 0.13758 | valid_rmsle: 0.00785 | valid_mae: 0.28985 | valid_rmse: 0.3588  | valid_mse: 0.12874 |  0:00:35s\n",
      "epoch 20 | loss: 0.13035 | train_rmsle: 0.00655 | train_mae: 0.24273 | train_rmse: 0.3168  | train_mse: 0.10036 | valid_rmsle: 0.00608 | valid_mae: 0.23651 | valid_rmse: 0.30967 | valid_mse: 0.09589 |  0:00:36s\n",
      "epoch 21 | loss: 0.13171 | train_rmsle: 0.00649 | train_mae: 0.23863 | train_rmse: 0.31384 | train_mse: 0.0985  | valid_rmsle: 0.00624 | valid_mae: 0.23809 | valid_rmse: 0.31298 | valid_mse: 0.09796 |  0:00:38s\n",
      "epoch 22 | loss: 0.12033 | train_rmsle: 0.00803 | train_mae: 0.28513 | train_rmse: 0.35681 | train_mse: 0.12731 | valid_rmsle: 0.00771 | valid_mae: 0.28121 | valid_rmse: 0.35455 | valid_mse: 0.12571 |  0:00:40s\n",
      "epoch 23 | loss: 0.12204 | train_rmsle: 0.00682 | train_mae: 0.25047 | train_rmse: 0.32504 | train_mse: 0.10565 | valid_rmsle: 0.00641 | valid_mae: 0.24579 | valid_rmse: 0.31993 | valid_mse: 0.10236 |  0:00:42s\n",
      "epoch 24 | loss: 0.11541 | train_rmsle: 0.00747 | train_mae: 0.26702 | train_rmse: 0.34113 | train_mse: 0.11637 | valid_rmsle: 0.00682 | valid_mae: 0.25988 | valid_rmse: 0.33059 | valid_mse: 0.10929 |  0:00:43s\n",
      "epoch 25 | loss: 0.11375 | train_rmsle: 0.00671 | train_mae: 0.24079 | train_rmse: 0.31877 | train_mse: 0.10161 | valid_rmsle: 0.00643 | valid_mae: 0.23903 | valid_rmse: 0.31706 | valid_mse: 0.10052 |  0:00:45s\n",
      "epoch 26 | loss: 0.12679 | train_rmsle: 0.00692 | train_mae: 0.25595 | train_rmse: 0.32831 | train_mse: 0.10779 | valid_rmsle: 0.00639 | valid_mae: 0.24776 | valid_rmse: 0.3187  | valid_mse: 0.10157 |  0:00:47s\n",
      "epoch 27 | loss: 0.10713 | train_rmsle: 0.00661 | train_mae: 0.24581 | train_rmse: 0.31919 | train_mse: 0.10188 | valid_rmsle: 0.00651 | valid_mae: 0.2428  | valid_rmse: 0.32107 | valid_mse: 0.10309 |  0:00:49s\n",
      "epoch 28 | loss: 0.11204 | train_rmsle: 0.00749 | train_mae: 0.27517 | train_rmse: 0.34442 | train_mse: 0.11862 | valid_rmsle: 0.00709 | valid_mae: 0.26651 | valid_rmse: 0.33842 | valid_mse: 0.11453 |  0:00:50s\n",
      "epoch 29 | loss: 0.10882 | train_rmsle: 0.00719 | train_mae: 0.26917 | train_rmse: 0.3375  | train_mse: 0.11391 | valid_rmsle: 0.00728 | valid_mae: 0.27147 | valid_rmse: 0.34389 | valid_mse: 0.11826 |  0:00:52s\n",
      "epoch 30 | loss: 0.10866 | train_rmsle: 0.00671 | train_mae: 0.24326 | train_rmse: 0.31967 | train_mse: 0.10219 | valid_rmsle: 0.00639 | valid_mae: 0.24276 | valid_rmse: 0.31744 | valid_mse: 0.10077 |  0:00:54s\n",
      "epoch 31 | loss: 0.10314 | train_rmsle: 0.00657 | train_mae: 0.24303 | train_rmse: 0.31695 | train_mse: 0.10046 | valid_rmsle: 0.00666 | valid_mae: 0.24644 | valid_rmse: 0.32379 | valid_mse: 0.10484 |  0:00:56s\n",
      "epoch 32 | loss: 0.1011  | train_rmsle: 0.00722 | train_mae: 0.26568 | train_rmse: 0.33642 | train_mse: 0.11318 | valid_rmsle: 0.00691 | valid_mae: 0.26388 | valid_rmse: 0.33344 | valid_mse: 0.11118 |  0:00:58s\n",
      "epoch 33 | loss: 0.1013  | train_rmsle: 0.00637 | train_mae: 0.24156 | train_rmse: 0.31277 | train_mse: 0.09783 | valid_rmsle: 0.00614 | valid_mae: 0.23844 | valid_rmse: 0.31102 | valid_mse: 0.09673 |  0:00:59s\n",
      "epoch 34 | loss: 0.09938 | train_rmsle: 0.00612 | train_mae: 0.23299 | train_rmse: 0.3043  | train_mse: 0.0926  | valid_rmsle: 0.00595 | valid_mae: 0.23709 | valid_rmse: 0.30596 | valid_mse: 0.09361 |  0:01:01s\n",
      "epoch 35 | loss: 0.09737 | train_rmsle: 0.00636 | train_mae: 0.2456  | train_rmse: 0.31357 | train_mse: 0.09832 | valid_rmsle: 0.00601 | valid_mae: 0.24259 | valid_rmse: 0.30895 | valid_mse: 0.09545 |  0:01:03s\n",
      "epoch 36 | loss: 0.09423 | train_rmsle: 0.00609 | train_mae: 0.23554 | train_rmse: 0.30464 | train_mse: 0.0928  | valid_rmsle: 0.00605 | valid_mae: 0.23756 | valid_rmse: 0.30854 | valid_mse: 0.0952  |  0:01:05s\n",
      "epoch 37 | loss: 0.09532 | train_rmsle: 0.00633 | train_mae: 0.24695 | train_rmse: 0.31341 | train_mse: 0.09823 | valid_rmsle: 0.00629 | valid_mae: 0.24823 | valid_rmse: 0.31685 | valid_mse: 0.10039 |  0:01:06s\n",
      "epoch 38 | loss: 0.09129 | train_rmsle: 0.00647 | train_mae: 0.25187 | train_rmse: 0.31801 | train_mse: 0.10113 | valid_rmsle: 0.00628 | valid_mae: 0.25059 | valid_rmse: 0.31761 | valid_mse: 0.10088 |  0:01:08s\n",
      "epoch 39 | loss: 0.09285 | train_rmsle: 0.00613 | train_mae: 0.24012 | train_rmse: 0.3069  | train_mse: 0.09419 | valid_rmsle: 0.00602 | valid_mae: 0.24162 | valid_rmse: 0.30861 | valid_mse: 0.09524 |  0:01:10s\n",
      "epoch 40 | loss: 0.0951  | train_rmsle: 0.00579 | train_mae: 0.2239  | train_rmse: 0.29437 | train_mse: 0.08665 | valid_rmsle: 0.00577 | valid_mae: 0.22765 | valid_rmse: 0.30032 | valid_mse: 0.09019 |  0:01:11s\n",
      "epoch 41 | loss: 0.08883 | train_rmsle: 0.00577 | train_mae: 0.22759 | train_rmse: 0.29535 | train_mse: 0.08723 | valid_rmsle: 0.00576 | valid_mae: 0.2312  | valid_rmse: 0.30015 | valid_mse: 0.09009 |  0:01:13s\n",
      "epoch 42 | loss: 0.08877 | train_rmsle: 0.00575 | train_mae: 0.22614 | train_rmse: 0.29434 | train_mse: 0.08663 | valid_rmsle: 0.00585 | valid_mae: 0.23304 | valid_rmse: 0.30265 | valid_mse: 0.0916  |  0:01:14s\n",
      "epoch 43 | loss: 0.08989 | train_rmsle: 0.00573 | train_mae: 0.22405 | train_rmse: 0.29269 | train_mse: 0.08567 | valid_rmsle: 0.00585 | valid_mae: 0.2311  | valid_rmse: 0.30264 | valid_mse: 0.09159 |  0:01:16s\n",
      "epoch 44 | loss: 0.0888  | train_rmsle: 0.00592 | train_mae: 0.23421 | train_rmse: 0.30087 | train_mse: 0.09052 | valid_rmsle: 0.00586 | valid_mae: 0.23725 | valid_rmse: 0.30438 | valid_mse: 0.09265 |  0:01:18s\n",
      "epoch 45 | loss: 0.08801 | train_rmsle: 0.00574 | train_mae: 0.22327 | train_rmse: 0.29358 | train_mse: 0.08619 | valid_rmsle: 0.00576 | valid_mae: 0.22914 | valid_rmse: 0.30038 | valid_mse: 0.09023 |  0:01:19s\n",
      "epoch 46 | loss: 0.09283 | train_rmsle: 0.00571 | train_mae: 0.22528 | train_rmse: 0.29319 | train_mse: 0.08596 | valid_rmsle: 0.00567 | valid_mae: 0.22944 | valid_rmse: 0.298   | valid_mse: 0.08881 |  0:01:21s\n",
      "epoch 47 | loss: 0.09369 | train_rmsle: 0.0059  | train_mae: 0.23748 | train_rmse: 0.30176 | train_mse: 0.09106 | valid_rmsle: 0.00581 | valid_mae: 0.24088 | valid_rmse: 0.30457 | valid_mse: 0.09277 |  0:01:22s\n",
      "epoch 48 | loss: 0.08707 | train_rmsle: 0.00586 | train_mae: 0.22134 | train_rmse: 0.29464 | train_mse: 0.08681 | valid_rmsle: 0.00593 | valid_mae: 0.23075 | valid_rmse: 0.30346 | valid_mse: 0.09209 |  0:01:24s\n",
      "epoch 49 | loss: 0.08627 | train_rmsle: 0.00552 | train_mae: 0.2163  | train_rmse: 0.28573 | train_mse: 0.08164 | valid_rmsle: 0.0056  | valid_mae: 0.22412 | valid_rmse: 0.29474 | valid_mse: 0.08687 |  0:01:26s\n",
      "epoch 50 | loss: 0.0845  | train_rmsle: 0.00544 | train_mae: 0.21801 | train_rmse: 0.28514 | train_mse: 0.0813  | valid_rmsle: 0.00555 | valid_mae: 0.22623 | valid_rmse: 0.29393 | valid_mse: 0.0864  |  0:01:28s\n",
      "epoch 51 | loss: 0.08503 | train_rmsle: 0.00547 | train_mae: 0.22019 | train_rmse: 0.28643 | train_mse: 0.08204 | valid_rmsle: 0.00555 | valid_mae: 0.22697 | valid_rmse: 0.29473 | valid_mse: 0.08687 |  0:01:29s\n",
      "epoch 52 | loss: 0.08451 | train_rmsle: 0.00541 | train_mae: 0.21702 | train_rmse: 0.28358 | train_mse: 0.08042 | valid_rmsle: 0.00563 | valid_mae: 0.22622 | valid_rmse: 0.29647 | valid_mse: 0.08789 |  0:01:31s\n",
      "epoch 53 | loss: 0.08472 | train_rmsle: 0.00551 | train_mae: 0.2146  | train_rmse: 0.28511 | train_mse: 0.08129 | valid_rmsle: 0.00572 | valid_mae: 0.22478 | valid_rmse: 0.29714 | valid_mse: 0.08829 |  0:01:33s\n",
      "epoch 54 | loss: 0.08464 | train_rmsle: 0.00545 | train_mae: 0.22372 | train_rmse: 0.28748 | train_mse: 0.08265 | valid_rmsle: 0.00564 | valid_mae: 0.23126 | valid_rmse: 0.29827 | valid_mse: 0.08897 |  0:01:35s\n",
      "epoch 55 | loss: 0.08513 | train_rmsle: 0.00578 | train_mae: 0.23568 | train_rmse: 0.29847 | train_mse: 0.08908 | valid_rmsle: 0.00593 | valid_mae: 0.24176 | valid_rmse: 0.30723 | valid_mse: 0.09439 |  0:01:36s\n",
      "epoch 56 | loss: 0.08395 | train_rmsle: 0.00565 | train_mae: 0.23194 | train_rmse: 0.29444 | train_mse: 0.08669 | valid_rmsle: 0.00585 | valid_mae: 0.24016 | valid_rmse: 0.30479 | valid_mse: 0.0929  |  0:01:38s\n",
      "epoch 57 | loss: 0.08301 | train_rmsle: 0.00533 | train_mae: 0.21448 | train_rmse: 0.28088 | train_mse: 0.07889 | valid_rmsle: 0.00551 | valid_mae: 0.22439 | valid_rmse: 0.29212 | valid_mse: 0.08533 |  0:01:40s\n",
      "epoch 58 | loss: 0.08242 | train_rmsle: 0.00537 | train_mae: 0.21997 | train_rmse: 0.28499 | train_mse: 0.08122 | valid_rmsle: 0.00563 | valid_mae: 0.23028 | valid_rmse: 0.29715 | valid_mse: 0.0883  |  0:01:42s\n",
      "epoch 59 | loss: 0.08234 | train_rmsle: 0.00529 | train_mae: 0.21285 | train_rmse: 0.28013 | train_mse: 0.07847 | valid_rmsle: 0.00564 | valid_mae: 0.22378 | valid_rmse: 0.29832 | valid_mse: 0.08899 |  0:01:43s\n",
      "epoch 60 | loss: 0.08252 | train_rmsle: 0.00544 | train_mae: 0.21253 | train_rmse: 0.28314 | train_mse: 0.08017 | valid_rmsle: 0.00585 | valid_mae: 0.22608 | valid_rmse: 0.30203 | valid_mse: 0.09122 |  0:01:45s\n",
      "epoch 61 | loss: 0.08391 | train_rmsle: 0.00528 | train_mae: 0.2139  | train_rmse: 0.28048 | train_mse: 0.07867 | valid_rmsle: 0.00552 | valid_mae: 0.22404 | valid_rmse: 0.29338 | valid_mse: 0.08607 |  0:01:47s\n",
      "epoch 62 | loss: 0.08426 | train_rmsle: 0.00549 | train_mae: 0.22737 | train_rmse: 0.28989 | train_mse: 0.08403 | valid_rmsle: 0.00576 | valid_mae: 0.23471 | valid_rmse: 0.30199 | valid_mse: 0.0912  |  0:01:49s\n",
      "epoch 63 | loss: 0.08182 | train_rmsle: 0.00541 | train_mae: 0.21215 | train_rmse: 0.28211 | train_mse: 0.07959 | valid_rmsle: 0.00561 | valid_mae: 0.22109 | valid_rmse: 0.29296 | valid_mse: 0.08583 |  0:01:51s\n",
      "epoch 64 | loss: 0.08436 | train_rmsle: 0.00515 | train_mae: 0.21256 | train_rmse: 0.27729 | train_mse: 0.07689 | valid_rmsle: 0.00552 | valid_mae: 0.22339 | valid_rmse: 0.29266 | valid_mse: 0.08565 |  0:01:52s\n",
      "epoch 65 | loss: 0.08144 | train_rmsle: 0.00526 | train_mae: 0.21747 | train_rmse: 0.28129 | train_mse: 0.07913 | valid_rmsle: 0.00551 | valid_mae: 0.2263  | valid_rmse: 0.29337 | valid_mse: 0.08606 |  0:01:54s\n",
      "epoch 66 | loss: 0.08036 | train_rmsle: 0.0052  | train_mae: 0.21553 | train_rmse: 0.27932 | train_mse: 0.07802 | valid_rmsle: 0.00549 | valid_mae: 0.22551 | valid_rmse: 0.29285 | valid_mse: 0.08576 |  0:01:56s\n",
      "epoch 67 | loss: 0.08158 | train_rmsle: 0.00514 | train_mae: 0.21501 | train_rmse: 0.27802 | train_mse: 0.0773  | valid_rmsle: 0.00544 | valid_mae: 0.226   | valid_rmse: 0.29178 | valid_mse: 0.08513 |  0:01:58s\n",
      "epoch 68 | loss: 0.08034 | train_rmsle: 0.00511 | train_mae: 0.21218 | train_rmse: 0.27613 | train_mse: 0.07625 | valid_rmsle: 0.00543 | valid_mae: 0.22408 | valid_rmse: 0.29066 | valid_mse: 0.08448 |  0:01:59s\n",
      "epoch 69 | loss: 0.08024 | train_rmsle: 0.00508 | train_mae: 0.20939 | train_rmse: 0.27425 | train_mse: 0.07521 | valid_rmsle: 0.00546 | valid_mae: 0.22139 | valid_rmse: 0.28993 | valid_mse: 0.08406 |  0:02:01s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.08406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08864580726253707 RMSE: 0.2977344576338739 R2: 0.6075991681248587 MAE: 0.2255995692125559\n",
      "=====================================\n",
      "[58/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.0241  | train_rmsle: 0.42023 | train_mae: 2.02722 | train_rmse: 2.08462 | train_mse: 4.34565 | valid_rmsle: 0.42195 | valid_mae: 2.03366 | valid_rmse: 2.08989 | valid_mse: 4.36764 |  0:00:01s\n",
      "epoch 1  | loss: 1.26435 | train_rmsle: 0.08715 | train_mae: 1.04995 | train_rmse: 1.13899 | train_mse: 1.29731 | valid_rmsle: 0.08744 | valid_mae: 1.05208 | valid_rmse: 1.14235 | valid_mse: 1.30497 |  0:00:03s\n",
      "epoch 2  | loss: 0.66443 | train_rmsle: 0.03323 | train_mae: 0.65547 | train_rmse: 0.7478  | train_mse: 0.5592  | valid_rmsle: 0.03309 | valid_mae: 0.65463 | valid_rmse: 0.74927 | valid_mse: 0.5614  |  0:00:05s\n",
      "epoch 3  | loss: 0.46895 | train_rmsle: 0.0287  | train_mae: 0.60706 | train_rmse: 0.69852 | train_mse: 0.48793 | valid_rmsle: 0.02851 | valid_mae: 0.60685 | valid_rmse: 0.69957 | valid_mse: 0.4894  |  0:00:07s\n",
      "epoch 4  | loss: 0.36125 | train_rmsle: 0.02834 | train_mae: 0.60289 | train_rmse: 0.69434 | train_mse: 0.48211 | valid_rmsle: 0.02812 | valid_mae: 0.60293 | valid_rmse: 0.69501 | valid_mse: 0.48304 |  0:00:08s\n",
      "epoch 5  | loss: 0.31669 | train_rmsle: 0.02383 | train_mae: 0.5488  | train_rmse: 0.63874 | train_mse: 0.40799 | valid_rmsle: 0.02353 | valid_mae: 0.54919 | valid_rmse: 0.6387  | valid_mse: 0.40793 |  0:00:10s\n",
      "epoch 6  | loss: 0.2964  | train_rmsle: 0.01891 | train_mae: 0.4799  | train_rmse: 0.56781 | train_mse: 0.32241 | valid_rmsle: 0.01851 | valid_mae: 0.48074 | valid_rmse: 0.56651 | valid_mse: 0.32094 |  0:00:12s\n",
      "epoch 7  | loss: 0.26732 | train_rmsle: 0.02251 | train_mae: 0.53234 | train_rmse: 0.62113 | train_mse: 0.3858  | valid_rmsle: 0.02223 | valid_mae: 0.53328 | valid_rmse: 0.62123 | valid_mse: 0.38593 |  0:00:14s\n",
      "epoch 8  | loss: 0.24704 | train_rmsle: 0.01172 | train_mae: 0.36924 | train_rmse: 0.4417  | train_mse: 0.1951  | valid_rmsle: 0.01118 | valid_mae: 0.36263 | valid_rmse: 0.43568 | valid_mse: 0.18981 |  0:00:15s\n",
      "epoch 9  | loss: 0.20943 | train_rmsle: 0.014   | train_mae: 0.38085 | train_rmse: 0.46603 | train_mse: 0.21719 | valid_rmsle: 0.0129  | valid_mae: 0.36525 | valid_rmse: 0.44985 | valid_mse: 0.20236 |  0:00:17s\n",
      "epoch 10 | loss: 0.18553 | train_rmsle: 0.01022 | train_mae: 0.31879 | train_rmse: 0.39978 | train_mse: 0.15982 | valid_rmsle: 0.00939 | valid_mae: 0.30285 | valid_rmse: 0.38474 | valid_mse: 0.14803 |  0:00:19s\n",
      "epoch 11 | loss: 0.17548 | train_rmsle: 0.01212 | train_mae: 0.35383 | train_rmse: 0.43644 | train_mse: 0.19048 | valid_rmsle: 0.01144 | valid_mae: 0.34205 | valid_rmse: 0.42605 | valid_mse: 0.18152 |  0:00:21s\n",
      "epoch 12 | loss: 0.16351 | train_rmsle: 0.00863 | train_mae: 0.29061 | train_rmse: 0.36826 | train_mse: 0.13561 | valid_rmsle: 0.00785 | valid_mae: 0.275   | valid_rmse: 0.35271 | valid_mse: 0.1244  |  0:00:22s\n",
      "epoch 13 | loss: 0.16167 | train_rmsle: 0.00982 | train_mae: 0.32122 | train_rmse: 0.39621 | train_mse: 0.15698 | valid_rmsle: 0.00891 | valid_mae: 0.30545 | valid_rmse: 0.37867 | valid_mse: 0.14339 |  0:00:24s\n",
      "epoch 14 | loss: 0.15853 | train_rmsle: 0.00763 | train_mae: 0.27367 | train_rmse: 0.34561 | train_mse: 0.11945 | valid_rmsle: 0.00687 | valid_mae: 0.26087 | valid_rmse: 0.33148 | valid_mse: 0.10988 |  0:00:26s\n",
      "epoch 15 | loss: 0.1516  | train_rmsle: 0.00694 | train_mae: 0.24931 | train_rmse: 0.32541 | train_mse: 0.10589 | valid_rmsle: 0.00645 | valid_mae: 0.24186 | valid_rmse: 0.31818 | valid_mse: 0.10124 |  0:00:27s\n",
      "epoch 16 | loss: 0.15005 | train_rmsle: 0.00776 | train_mae: 0.27975 | train_rmse: 0.35031 | train_mse: 0.12272 | valid_rmsle: 0.00693 | valid_mae: 0.26661 | valid_rmse: 0.33434 | valid_mse: 0.11178 |  0:00:29s\n",
      "epoch 17 | loss: 0.13835 | train_rmsle: 0.007   | train_mae: 0.25865 | train_rmse: 0.32946 | train_mse: 0.10854 | valid_rmsle: 0.00627 | valid_mae: 0.24664 | valid_rmse: 0.31511 | valid_mse: 0.0993  |  0:00:30s\n",
      "epoch 18 | loss: 0.13278 | train_rmsle: 0.00708 | train_mae: 0.26002 | train_rmse: 0.33204 | train_mse: 0.11025 | valid_rmsle: 0.00651 | valid_mae: 0.25114 | valid_rmse: 0.32192 | valid_mse: 0.10363 |  0:00:32s\n",
      "epoch 19 | loss: 0.12889 | train_rmsle: 0.00859 | train_mae: 0.3011  | train_rmse: 0.37092 | train_mse: 0.13758 | valid_rmsle: 0.00785 | valid_mae: 0.28985 | valid_rmse: 0.3588  | valid_mse: 0.12874 |  0:00:33s\n",
      "epoch 20 | loss: 0.13035 | train_rmsle: 0.00655 | train_mae: 0.24273 | train_rmse: 0.3168  | train_mse: 0.10036 | valid_rmsle: 0.00608 | valid_mae: 0.23651 | valid_rmse: 0.30967 | valid_mse: 0.09589 |  0:00:35s\n",
      "epoch 21 | loss: 0.13171 | train_rmsle: 0.00649 | train_mae: 0.23863 | train_rmse: 0.31384 | train_mse: 0.0985  | valid_rmsle: 0.00624 | valid_mae: 0.23809 | valid_rmse: 0.31298 | valid_mse: 0.09796 |  0:00:37s\n",
      "epoch 22 | loss: 0.12033 | train_rmsle: 0.00803 | train_mae: 0.28513 | train_rmse: 0.35681 | train_mse: 0.12731 | valid_rmsle: 0.00771 | valid_mae: 0.28121 | valid_rmse: 0.35455 | valid_mse: 0.12571 |  0:00:38s\n",
      "epoch 23 | loss: 0.12204 | train_rmsle: 0.00682 | train_mae: 0.25047 | train_rmse: 0.32504 | train_mse: 0.10565 | valid_rmsle: 0.00641 | valid_mae: 0.24579 | valid_rmse: 0.31993 | valid_mse: 0.10236 |  0:00:40s\n",
      "epoch 24 | loss: 0.11541 | train_rmsle: 0.00747 | train_mae: 0.26702 | train_rmse: 0.34113 | train_mse: 0.11637 | valid_rmsle: 0.00682 | valid_mae: 0.25988 | valid_rmse: 0.33059 | valid_mse: 0.10929 |  0:00:42s\n",
      "epoch 25 | loss: 0.11375 | train_rmsle: 0.00671 | train_mae: 0.24079 | train_rmse: 0.31877 | train_mse: 0.10161 | valid_rmsle: 0.00643 | valid_mae: 0.23903 | valid_rmse: 0.31706 | valid_mse: 0.10052 |  0:00:44s\n",
      "epoch 26 | loss: 0.12679 | train_rmsle: 0.00692 | train_mae: 0.25595 | train_rmse: 0.32831 | train_mse: 0.10779 | valid_rmsle: 0.00639 | valid_mae: 0.24776 | valid_rmse: 0.3187  | valid_mse: 0.10157 |  0:00:45s\n",
      "epoch 27 | loss: 0.10713 | train_rmsle: 0.00661 | train_mae: 0.24581 | train_rmse: 0.31919 | train_mse: 0.10188 | valid_rmsle: 0.00651 | valid_mae: 0.2428  | valid_rmse: 0.32107 | valid_mse: 0.10309 |  0:00:47s\n",
      "epoch 28 | loss: 0.11204 | train_rmsle: 0.00749 | train_mae: 0.27517 | train_rmse: 0.34442 | train_mse: 0.11862 | valid_rmsle: 0.00709 | valid_mae: 0.26651 | valid_rmse: 0.33842 | valid_mse: 0.11453 |  0:00:49s\n",
      "epoch 29 | loss: 0.10882 | train_rmsle: 0.00719 | train_mae: 0.26917 | train_rmse: 0.3375  | train_mse: 0.11391 | valid_rmsle: 0.00728 | valid_mae: 0.27147 | valid_rmse: 0.34389 | valid_mse: 0.11826 |  0:00:51s\n",
      "epoch 30 | loss: 0.10866 | train_rmsle: 0.00671 | train_mae: 0.24326 | train_rmse: 0.31967 | train_mse: 0.10219 | valid_rmsle: 0.00639 | valid_mae: 0.24276 | valid_rmse: 0.31744 | valid_mse: 0.10077 |  0:00:52s\n",
      "epoch 31 | loss: 0.10314 | train_rmsle: 0.00657 | train_mae: 0.24303 | train_rmse: 0.31695 | train_mse: 0.10046 | valid_rmsle: 0.00666 | valid_mae: 0.24644 | valid_rmse: 0.32379 | valid_mse: 0.10484 |  0:00:54s\n",
      "epoch 32 | loss: 0.1011  | train_rmsle: 0.00722 | train_mae: 0.26568 | train_rmse: 0.33642 | train_mse: 0.11318 | valid_rmsle: 0.00691 | valid_mae: 0.26388 | valid_rmse: 0.33344 | valid_mse: 0.11118 |  0:00:56s\n",
      "epoch 33 | loss: 0.1013  | train_rmsle: 0.00637 | train_mae: 0.24156 | train_rmse: 0.31277 | train_mse: 0.09783 | valid_rmsle: 0.00614 | valid_mae: 0.23844 | valid_rmse: 0.31102 | valid_mse: 0.09673 |  0:00:58s\n",
      "epoch 34 | loss: 0.09938 | train_rmsle: 0.00612 | train_mae: 0.23299 | train_rmse: 0.3043  | train_mse: 0.0926  | valid_rmsle: 0.00595 | valid_mae: 0.23709 | valid_rmse: 0.30596 | valid_mse: 0.09361 |  0:00:59s\n",
      "epoch 35 | loss: 0.09737 | train_rmsle: 0.00636 | train_mae: 0.2456  | train_rmse: 0.31357 | train_mse: 0.09832 | valid_rmsle: 0.00601 | valid_mae: 0.24259 | valid_rmse: 0.30895 | valid_mse: 0.09545 |  0:01:01s\n",
      "epoch 36 | loss: 0.09423 | train_rmsle: 0.00609 | train_mae: 0.23554 | train_rmse: 0.30464 | train_mse: 0.0928  | valid_rmsle: 0.00605 | valid_mae: 0.23756 | valid_rmse: 0.30854 | valid_mse: 0.0952  |  0:01:03s\n",
      "epoch 37 | loss: 0.09532 | train_rmsle: 0.00633 | train_mae: 0.24695 | train_rmse: 0.31341 | train_mse: 0.09823 | valid_rmsle: 0.00629 | valid_mae: 0.24823 | valid_rmse: 0.31685 | valid_mse: 0.10039 |  0:01:05s\n",
      "epoch 38 | loss: 0.09129 | train_rmsle: 0.00647 | train_mae: 0.25187 | train_rmse: 0.31801 | train_mse: 0.10113 | valid_rmsle: 0.00628 | valid_mae: 0.25059 | valid_rmse: 0.31761 | valid_mse: 0.10088 |  0:01:06s\n",
      "epoch 39 | loss: 0.09285 | train_rmsle: 0.00613 | train_mae: 0.24012 | train_rmse: 0.3069  | train_mse: 0.09419 | valid_rmsle: 0.00602 | valid_mae: 0.24162 | valid_rmse: 0.30861 | valid_mse: 0.09524 |  0:01:08s\n",
      "epoch 40 | loss: 0.0951  | train_rmsle: 0.00579 | train_mae: 0.2239  | train_rmse: 0.29437 | train_mse: 0.08665 | valid_rmsle: 0.00577 | valid_mae: 0.22765 | valid_rmse: 0.30032 | valid_mse: 0.09019 |  0:01:10s\n",
      "epoch 41 | loss: 0.08883 | train_rmsle: 0.00577 | train_mae: 0.22759 | train_rmse: 0.29535 | train_mse: 0.08723 | valid_rmsle: 0.00576 | valid_mae: 0.2312  | valid_rmse: 0.30015 | valid_mse: 0.09009 |  0:01:12s\n",
      "epoch 42 | loss: 0.08877 | train_rmsle: 0.00575 | train_mae: 0.22614 | train_rmse: 0.29434 | train_mse: 0.08663 | valid_rmsle: 0.00585 | valid_mae: 0.23304 | valid_rmse: 0.30265 | valid_mse: 0.0916  |  0:01:13s\n",
      "epoch 43 | loss: 0.08989 | train_rmsle: 0.00573 | train_mae: 0.22405 | train_rmse: 0.29269 | train_mse: 0.08567 | valid_rmsle: 0.00585 | valid_mae: 0.2311  | valid_rmse: 0.30264 | valid_mse: 0.09159 |  0:01:15s\n",
      "epoch 44 | loss: 0.0888  | train_rmsle: 0.00592 | train_mae: 0.23421 | train_rmse: 0.30087 | train_mse: 0.09052 | valid_rmsle: 0.00586 | valid_mae: 0.23725 | valid_rmse: 0.30438 | valid_mse: 0.09265 |  0:01:17s\n",
      "epoch 45 | loss: 0.08801 | train_rmsle: 0.00574 | train_mae: 0.22327 | train_rmse: 0.29358 | train_mse: 0.08619 | valid_rmsle: 0.00576 | valid_mae: 0.22914 | valid_rmse: 0.30038 | valid_mse: 0.09023 |  0:01:19s\n",
      "epoch 46 | loss: 0.09283 | train_rmsle: 0.00571 | train_mae: 0.22528 | train_rmse: 0.29319 | train_mse: 0.08596 | valid_rmsle: 0.00567 | valid_mae: 0.22944 | valid_rmse: 0.298   | valid_mse: 0.08881 |  0:01:20s\n",
      "epoch 47 | loss: 0.09369 | train_rmsle: 0.0059  | train_mae: 0.23748 | train_rmse: 0.30176 | train_mse: 0.09106 | valid_rmsle: 0.00581 | valid_mae: 0.24088 | valid_rmse: 0.30457 | valid_mse: 0.09277 |  0:01:22s\n",
      "epoch 48 | loss: 0.08707 | train_rmsle: 0.00586 | train_mae: 0.22134 | train_rmse: 0.29464 | train_mse: 0.08681 | valid_rmsle: 0.00593 | valid_mae: 0.23075 | valid_rmse: 0.30346 | valid_mse: 0.09209 |  0:01:24s\n",
      "epoch 49 | loss: 0.08627 | train_rmsle: 0.00552 | train_mae: 0.2163  | train_rmse: 0.28573 | train_mse: 0.08164 | valid_rmsle: 0.0056  | valid_mae: 0.22412 | valid_rmse: 0.29474 | valid_mse: 0.08687 |  0:01:26s\n",
      "epoch 50 | loss: 0.0845  | train_rmsle: 0.00544 | train_mae: 0.21801 | train_rmse: 0.28514 | train_mse: 0.0813  | valid_rmsle: 0.00555 | valid_mae: 0.22623 | valid_rmse: 0.29393 | valid_mse: 0.0864  |  0:01:27s\n",
      "epoch 51 | loss: 0.08503 | train_rmsle: 0.00547 | train_mae: 0.22019 | train_rmse: 0.28643 | train_mse: 0.08204 | valid_rmsle: 0.00555 | valid_mae: 0.22697 | valid_rmse: 0.29473 | valid_mse: 0.08687 |  0:01:29s\n",
      "epoch 52 | loss: 0.08451 | train_rmsle: 0.00541 | train_mae: 0.21702 | train_rmse: 0.28358 | train_mse: 0.08042 | valid_rmsle: 0.00563 | valid_mae: 0.22622 | valid_rmse: 0.29647 | valid_mse: 0.08789 |  0:01:31s\n",
      "epoch 53 | loss: 0.08472 | train_rmsle: 0.00551 | train_mae: 0.2146  | train_rmse: 0.28511 | train_mse: 0.08129 | valid_rmsle: 0.00572 | valid_mae: 0.22478 | valid_rmse: 0.29714 | valid_mse: 0.08829 |  0:01:33s\n",
      "epoch 54 | loss: 0.08464 | train_rmsle: 0.00545 | train_mae: 0.22372 | train_rmse: 0.28748 | train_mse: 0.08265 | valid_rmsle: 0.00564 | valid_mae: 0.23126 | valid_rmse: 0.29827 | valid_mse: 0.08897 |  0:01:35s\n",
      "epoch 55 | loss: 0.08513 | train_rmsle: 0.00578 | train_mae: 0.23568 | train_rmse: 0.29847 | train_mse: 0.08908 | valid_rmsle: 0.00593 | valid_mae: 0.24176 | valid_rmse: 0.30723 | valid_mse: 0.09439 |  0:01:36s\n",
      "epoch 56 | loss: 0.08395 | train_rmsle: 0.00565 | train_mae: 0.23194 | train_rmse: 0.29444 | train_mse: 0.08669 | valid_rmsle: 0.00585 | valid_mae: 0.24016 | valid_rmse: 0.30479 | valid_mse: 0.0929  |  0:01:38s\n",
      "epoch 57 | loss: 0.08301 | train_rmsle: 0.00533 | train_mae: 0.21448 | train_rmse: 0.28088 | train_mse: 0.07889 | valid_rmsle: 0.00551 | valid_mae: 0.22439 | valid_rmse: 0.29212 | valid_mse: 0.08533 |  0:01:40s\n",
      "epoch 58 | loss: 0.08242 | train_rmsle: 0.00537 | train_mae: 0.21997 | train_rmse: 0.28499 | train_mse: 0.08122 | valid_rmsle: 0.00563 | valid_mae: 0.23028 | valid_rmse: 0.29715 | valid_mse: 0.0883  |  0:01:42s\n",
      "epoch 59 | loss: 0.08234 | train_rmsle: 0.00529 | train_mae: 0.21285 | train_rmse: 0.28013 | train_mse: 0.07847 | valid_rmsle: 0.00564 | valid_mae: 0.22378 | valid_rmse: 0.29832 | valid_mse: 0.08899 |  0:01:43s\n",
      "epoch 60 | loss: 0.08252 | train_rmsle: 0.00544 | train_mae: 0.21253 | train_rmse: 0.28314 | train_mse: 0.08017 | valid_rmsle: 0.00585 | valid_mae: 0.22608 | valid_rmse: 0.30203 | valid_mse: 0.09122 |  0:01:45s\n",
      "epoch 61 | loss: 0.08391 | train_rmsle: 0.00528 | train_mae: 0.2139  | train_rmse: 0.28048 | train_mse: 0.07867 | valid_rmsle: 0.00552 | valid_mae: 0.22404 | valid_rmse: 0.29338 | valid_mse: 0.08607 |  0:01:47s\n",
      "epoch 62 | loss: 0.08426 | train_rmsle: 0.00549 | train_mae: 0.22737 | train_rmse: 0.28989 | train_mse: 0.08403 | valid_rmsle: 0.00576 | valid_mae: 0.23471 | valid_rmse: 0.30199 | valid_mse: 0.0912  |  0:01:49s\n",
      "epoch 63 | loss: 0.08182 | train_rmsle: 0.00541 | train_mae: 0.21215 | train_rmse: 0.28211 | train_mse: 0.07959 | valid_rmsle: 0.00561 | valid_mae: 0.22109 | valid_rmse: 0.29296 | valid_mse: 0.08583 |  0:01:50s\n",
      "epoch 64 | loss: 0.08436 | train_rmsle: 0.00515 | train_mae: 0.21256 | train_rmse: 0.27729 | train_mse: 0.07689 | valid_rmsle: 0.00552 | valid_mae: 0.22339 | valid_rmse: 0.29266 | valid_mse: 0.08565 |  0:01:52s\n",
      "epoch 65 | loss: 0.08144 | train_rmsle: 0.00526 | train_mae: 0.21747 | train_rmse: 0.28129 | train_mse: 0.07913 | valid_rmsle: 0.00551 | valid_mae: 0.2263  | valid_rmse: 0.29337 | valid_mse: 0.08606 |  0:01:54s\n",
      "epoch 66 | loss: 0.08036 | train_rmsle: 0.0052  | train_mae: 0.21553 | train_rmse: 0.27932 | train_mse: 0.07802 | valid_rmsle: 0.00549 | valid_mae: 0.22551 | valid_rmse: 0.29285 | valid_mse: 0.08576 |  0:01:56s\n",
      "epoch 67 | loss: 0.08158 | train_rmsle: 0.00514 | train_mae: 0.21501 | train_rmse: 0.27802 | train_mse: 0.0773  | valid_rmsle: 0.00544 | valid_mae: 0.226   | valid_rmse: 0.29178 | valid_mse: 0.08513 |  0:01:57s\n",
      "epoch 68 | loss: 0.08034 | train_rmsle: 0.00511 | train_mae: 0.21218 | train_rmse: 0.27613 | train_mse: 0.07625 | valid_rmsle: 0.00543 | valid_mae: 0.22408 | valid_rmse: 0.29066 | valid_mse: 0.08448 |  0:01:59s\n",
      "epoch 69 | loss: 0.08024 | train_rmsle: 0.00508 | train_mae: 0.20939 | train_rmse: 0.27425 | train_mse: 0.07521 | valid_rmsle: 0.00546 | valid_mae: 0.22139 | valid_rmse: 0.28993 | valid_mse: 0.08406 |  0:02:00s\n",
      "epoch 70 | loss: 0.08176 | train_rmsle: 0.00506 | train_mae: 0.21216 | train_rmse: 0.27541 | train_mse: 0.07585 | valid_rmsle: 0.00556 | valid_mae: 0.22674 | valid_rmse: 0.29516 | valid_mse: 0.08712 |  0:02:02s\n",
      "epoch 71 | loss: 0.08304 | train_rmsle: 0.00512 | train_mae: 0.20653 | train_rmse: 0.27437 | train_mse: 0.07528 | valid_rmsle: 0.00564 | valid_mae: 0.22224 | valid_rmse: 0.29546 | valid_mse: 0.0873  |  0:02:03s\n",
      "epoch 72 | loss: 0.08027 | train_rmsle: 0.00499 | train_mae: 0.20825 | train_rmse: 0.27253 | train_mse: 0.07427 | valid_rmsle: 0.00557 | valid_mae: 0.22544 | valid_rmse: 0.29547 | valid_mse: 0.0873  |  0:02:05s\n",
      "epoch 73 | loss: 0.08024 | train_rmsle: 0.00513 | train_mae: 0.20582 | train_rmse: 0.27467 | train_mse: 0.07544 | valid_rmsle: 0.00587 | valid_mae: 0.22692 | valid_rmse: 0.30316 | valid_mse: 0.09191 |  0:02:06s\n",
      "epoch 74 | loss: 0.07978 | train_rmsle: 0.00492 | train_mae: 0.20605 | train_rmse: 0.27045 | train_mse: 0.07315 | valid_rmsle: 0.00559 | valid_mae: 0.22341 | valid_rmse: 0.29701 | valid_mse: 0.08821 |  0:02:08s\n",
      "epoch 75 | loss: 0.07829 | train_rmsle: 0.00504 | train_mae: 0.20532 | train_rmse: 0.27275 | train_mse: 0.07439 | valid_rmsle: 0.00574 | valid_mae: 0.2249  | valid_rmse: 0.30128 | valid_mse: 0.09077 |  0:02:10s\n",
      "epoch 76 | loss: 0.07861 | train_rmsle: 0.00487 | train_mae: 0.20578 | train_rmse: 0.26933 | train_mse: 0.07254 | valid_rmsle: 0.00549 | valid_mae: 0.22291 | valid_rmse: 0.29428 | valid_mse: 0.0866  |  0:02:11s\n",
      "epoch 77 | loss: 0.0769  | train_rmsle: 0.00486 | train_mae: 0.20322 | train_rmse: 0.26815 | train_mse: 0.0719  | valid_rmsle: 0.00561 | valid_mae: 0.22501 | valid_rmse: 0.29744 | valid_mse: 0.08847 |  0:02:13s\n",
      "epoch 78 | loss: 0.07637 | train_rmsle: 0.00482 | train_mae: 0.20354 | train_rmse: 0.26742 | train_mse: 0.07151 | valid_rmsle: 0.00546 | valid_mae: 0.22266 | valid_rmse: 0.29252 | valid_mse: 0.08557 |  0:02:15s\n",
      "epoch 79 | loss: 0.07739 | train_rmsle: 0.00509 | train_mae: 0.22016 | train_rmse: 0.28002 | train_mse: 0.07841 | valid_rmsle: 0.00568 | valid_mae: 0.23402 | valid_rmse: 0.30115 | valid_mse: 0.09069 |  0:02:17s\n",
      "epoch 80 | loss: 0.07676 | train_rmsle: 0.0048  | train_mae: 0.20384 | train_rmse: 0.26717 | train_mse: 0.07138 | valid_rmsle: 0.00546 | valid_mae: 0.22338 | valid_rmse: 0.29281 | valid_mse: 0.08574 |  0:02:18s\n",
      "epoch 81 | loss: 0.07613 | train_rmsle: 0.00476 | train_mae: 0.20236 | train_rmse: 0.26599 | train_mse: 0.07075 | valid_rmsle: 0.00541 | valid_mae: 0.22015 | valid_rmse: 0.29081 | valid_mse: 0.08457 |  0:02:20s\n",
      "epoch 82 | loss: 0.07479 | train_rmsle: 0.00477 | train_mae: 0.20059 | train_rmse: 0.26542 | train_mse: 0.07045 | valid_rmsle: 0.0055  | valid_mae: 0.22161 | valid_rmse: 0.29235 | valid_mse: 0.08547 |  0:02:22s\n",
      "epoch 83 | loss: 0.07661 | train_rmsle: 0.00473 | train_mae: 0.20005 | train_rmse: 0.26444 | train_mse: 0.06993 | valid_rmsle: 0.00547 | valid_mae: 0.22139 | valid_rmse: 0.29167 | valid_mse: 0.08507 |  0:02:24s\n",
      "epoch 84 | loss: 0.07663 | train_rmsle: 0.00466 | train_mae: 0.19955 | train_rmse: 0.26291 | train_mse: 0.06912 | valid_rmsle: 0.00547 | valid_mae: 0.22264 | valid_rmse: 0.29219 | valid_mse: 0.08538 |  0:02:25s\n",
      "epoch 85 | loss: 0.07654 | train_rmsle: 0.00464 | train_mae: 0.20029 | train_rmse: 0.26282 | train_mse: 0.06908 | valid_rmsle: 0.00542 | valid_mae: 0.22212 | valid_rmse: 0.29073 | valid_mse: 0.08452 |  0:02:27s\n",
      "epoch 86 | loss: 0.07411 | train_rmsle: 0.00476 | train_mae: 0.20861 | train_rmse: 0.26892 | train_mse: 0.07232 | valid_rmsle: 0.00552 | valid_mae: 0.22729 | valid_rmse: 0.29463 | valid_mse: 0.08681 |  0:02:29s\n",
      "epoch 87 | loss: 0.07547 | train_rmsle: 0.00469 | train_mae: 0.19948 | train_rmse: 0.26311 | train_mse: 0.06923 | valid_rmsle: 0.00557 | valid_mae: 0.22294 | valid_rmse: 0.29402 | valid_mse: 0.08645 |  0:02:31s\n",
      "epoch 88 | loss: 0.07457 | train_rmsle: 0.00472 | train_mae: 0.20838 | train_rmse: 0.26796 | train_mse: 0.07181 | valid_rmsle: 0.00557 | valid_mae: 0.2293  | valid_rmse: 0.29633 | valid_mse: 0.08781 |  0:02:32s\n",
      "epoch 89 | loss: 0.07363 | train_rmsle: 0.00458 | train_mae: 0.19628 | train_rmse: 0.26014 | train_mse: 0.06768 | valid_rmsle: 0.00554 | valid_mae: 0.22235 | valid_rmse: 0.2936  | valid_mse: 0.0862  |  0:02:34s\n",
      "\n",
      "Early stopping occurred at epoch 89 with best_epoch = 69 and best_valid_mse = 0.08406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08864580726253707 RMSE: 0.2977344576338739 R2: 0.6075991681248587 MAE: 0.2255995692125559\n",
      "=====================================\n",
      "[59/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.0241  | train_rmsle: 0.42023 | train_mae: 2.02722 | train_rmse: 2.08462 | train_mse: 4.34565 | valid_rmsle: 0.42195 | valid_mae: 2.03366 | valid_rmse: 2.08989 | valid_mse: 4.36764 |  0:00:01s\n",
      "epoch 1  | loss: 1.26435 | train_rmsle: 0.08715 | train_mae: 1.04995 | train_rmse: 1.13899 | train_mse: 1.29731 | valid_rmsle: 0.08744 | valid_mae: 1.05208 | valid_rmse: 1.14235 | valid_mse: 1.30497 |  0:00:03s\n",
      "epoch 2  | loss: 0.66443 | train_rmsle: 0.03323 | train_mae: 0.65547 | train_rmse: 0.7478  | train_mse: 0.5592  | valid_rmsle: 0.03309 | valid_mae: 0.65463 | valid_rmse: 0.74927 | valid_mse: 0.5614  |  0:00:05s\n",
      "epoch 3  | loss: 0.46895 | train_rmsle: 0.0287  | train_mae: 0.60706 | train_rmse: 0.69852 | train_mse: 0.48793 | valid_rmsle: 0.02851 | valid_mae: 0.60685 | valid_rmse: 0.69957 | valid_mse: 0.4894  |  0:00:07s\n",
      "epoch 4  | loss: 0.36125 | train_rmsle: 0.02834 | train_mae: 0.60289 | train_rmse: 0.69434 | train_mse: 0.48211 | valid_rmsle: 0.02812 | valid_mae: 0.60293 | valid_rmse: 0.69501 | valid_mse: 0.48304 |  0:00:08s\n",
      "epoch 5  | loss: 0.31669 | train_rmsle: 0.02383 | train_mae: 0.5488  | train_rmse: 0.63874 | train_mse: 0.40799 | valid_rmsle: 0.02353 | valid_mae: 0.54919 | valid_rmse: 0.6387  | valid_mse: 0.40793 |  0:00:10s\n",
      "epoch 6  | loss: 0.2964  | train_rmsle: 0.01891 | train_mae: 0.4799  | train_rmse: 0.56781 | train_mse: 0.32241 | valid_rmsle: 0.01851 | valid_mae: 0.48074 | valid_rmse: 0.56651 | valid_mse: 0.32094 |  0:00:12s\n",
      "epoch 7  | loss: 0.26732 | train_rmsle: 0.02251 | train_mae: 0.53234 | train_rmse: 0.62113 | train_mse: 0.3858  | valid_rmsle: 0.02223 | valid_mae: 0.53328 | valid_rmse: 0.62123 | valid_mse: 0.38593 |  0:00:14s\n",
      "epoch 8  | loss: 0.24704 | train_rmsle: 0.01172 | train_mae: 0.36924 | train_rmse: 0.4417  | train_mse: 0.1951  | valid_rmsle: 0.01118 | valid_mae: 0.36263 | valid_rmse: 0.43568 | valid_mse: 0.18981 |  0:00:15s\n",
      "epoch 9  | loss: 0.20943 | train_rmsle: 0.014   | train_mae: 0.38085 | train_rmse: 0.46603 | train_mse: 0.21719 | valid_rmsle: 0.0129  | valid_mae: 0.36525 | valid_rmse: 0.44985 | valid_mse: 0.20236 |  0:00:17s\n",
      "epoch 10 | loss: 0.18553 | train_rmsle: 0.01022 | train_mae: 0.31879 | train_rmse: 0.39978 | train_mse: 0.15982 | valid_rmsle: 0.00939 | valid_mae: 0.30285 | valid_rmse: 0.38474 | valid_mse: 0.14803 |  0:00:19s\n",
      "epoch 11 | loss: 0.17548 | train_rmsle: 0.01212 | train_mae: 0.35383 | train_rmse: 0.43644 | train_mse: 0.19048 | valid_rmsle: 0.01144 | valid_mae: 0.34205 | valid_rmse: 0.42605 | valid_mse: 0.18152 |  0:00:21s\n",
      "epoch 12 | loss: 0.16351 | train_rmsle: 0.00863 | train_mae: 0.29061 | train_rmse: 0.36826 | train_mse: 0.13561 | valid_rmsle: 0.00785 | valid_mae: 0.275   | valid_rmse: 0.35271 | valid_mse: 0.1244  |  0:00:23s\n",
      "epoch 13 | loss: 0.16167 | train_rmsle: 0.00982 | train_mae: 0.32122 | train_rmse: 0.39621 | train_mse: 0.15698 | valid_rmsle: 0.00891 | valid_mae: 0.30545 | valid_rmse: 0.37867 | valid_mse: 0.14339 |  0:00:24s\n",
      "epoch 14 | loss: 0.15853 | train_rmsle: 0.00763 | train_mae: 0.27367 | train_rmse: 0.34561 | train_mse: 0.11945 | valid_rmsle: 0.00687 | valid_mae: 0.26087 | valid_rmse: 0.33148 | valid_mse: 0.10988 |  0:00:26s\n",
      "epoch 15 | loss: 0.1516  | train_rmsle: 0.00694 | train_mae: 0.24931 | train_rmse: 0.32541 | train_mse: 0.10589 | valid_rmsle: 0.00645 | valid_mae: 0.24186 | valid_rmse: 0.31818 | valid_mse: 0.10124 |  0:00:28s\n",
      "epoch 16 | loss: 0.15005 | train_rmsle: 0.00776 | train_mae: 0.27975 | train_rmse: 0.35031 | train_mse: 0.12272 | valid_rmsle: 0.00693 | valid_mae: 0.26661 | valid_rmse: 0.33434 | valid_mse: 0.11178 |  0:00:30s\n",
      "epoch 17 | loss: 0.13835 | train_rmsle: 0.007   | train_mae: 0.25865 | train_rmse: 0.32946 | train_mse: 0.10854 | valid_rmsle: 0.00627 | valid_mae: 0.24664 | valid_rmse: 0.31511 | valid_mse: 0.0993  |  0:00:32s\n",
      "epoch 18 | loss: 0.13278 | train_rmsle: 0.00708 | train_mae: 0.26002 | train_rmse: 0.33204 | train_mse: 0.11025 | valid_rmsle: 0.00651 | valid_mae: 0.25114 | valid_rmse: 0.32192 | valid_mse: 0.10363 |  0:00:33s\n",
      "epoch 19 | loss: 0.12889 | train_rmsle: 0.00859 | train_mae: 0.3011  | train_rmse: 0.37092 | train_mse: 0.13758 | valid_rmsle: 0.00785 | valid_mae: 0.28985 | valid_rmse: 0.3588  | valid_mse: 0.12874 |  0:00:35s\n",
      "epoch 20 | loss: 0.13035 | train_rmsle: 0.00655 | train_mae: 0.24273 | train_rmse: 0.3168  | train_mse: 0.10036 | valid_rmsle: 0.00608 | valid_mae: 0.23651 | valid_rmse: 0.30967 | valid_mse: 0.09589 |  0:00:37s\n",
      "epoch 21 | loss: 0.13171 | train_rmsle: 0.00649 | train_mae: 0.23863 | train_rmse: 0.31384 | train_mse: 0.0985  | valid_rmsle: 0.00624 | valid_mae: 0.23809 | valid_rmse: 0.31298 | valid_mse: 0.09796 |  0:00:38s\n",
      "epoch 22 | loss: 0.12033 | train_rmsle: 0.00803 | train_mae: 0.28513 | train_rmse: 0.35681 | train_mse: 0.12731 | valid_rmsle: 0.00771 | valid_mae: 0.28121 | valid_rmse: 0.35455 | valid_mse: 0.12571 |  0:00:40s\n",
      "epoch 23 | loss: 0.12204 | train_rmsle: 0.00682 | train_mae: 0.25047 | train_rmse: 0.32504 | train_mse: 0.10565 | valid_rmsle: 0.00641 | valid_mae: 0.24579 | valid_rmse: 0.31993 | valid_mse: 0.10236 |  0:00:42s\n",
      "epoch 24 | loss: 0.11541 | train_rmsle: 0.00747 | train_mae: 0.26702 | train_rmse: 0.34113 | train_mse: 0.11637 | valid_rmsle: 0.00682 | valid_mae: 0.25988 | valid_rmse: 0.33059 | valid_mse: 0.10929 |  0:00:43s\n",
      "epoch 25 | loss: 0.11375 | train_rmsle: 0.00671 | train_mae: 0.24079 | train_rmse: 0.31877 | train_mse: 0.10161 | valid_rmsle: 0.00643 | valid_mae: 0.23903 | valid_rmse: 0.31706 | valid_mse: 0.10052 |  0:00:45s\n",
      "epoch 26 | loss: 0.12679 | train_rmsle: 0.00692 | train_mae: 0.25595 | train_rmse: 0.32831 | train_mse: 0.10779 | valid_rmsle: 0.00639 | valid_mae: 0.24776 | valid_rmse: 0.3187  | valid_mse: 0.10157 |  0:00:46s\n",
      "epoch 27 | loss: 0.10713 | train_rmsle: 0.00661 | train_mae: 0.24581 | train_rmse: 0.31919 | train_mse: 0.10188 | valid_rmsle: 0.00651 | valid_mae: 0.2428  | valid_rmse: 0.32107 | valid_mse: 0.10309 |  0:00:48s\n",
      "epoch 28 | loss: 0.11204 | train_rmsle: 0.00749 | train_mae: 0.27517 | train_rmse: 0.34442 | train_mse: 0.11862 | valid_rmsle: 0.00709 | valid_mae: 0.26651 | valid_rmse: 0.33842 | valid_mse: 0.11453 |  0:00:49s\n",
      "epoch 29 | loss: 0.10882 | train_rmsle: 0.00719 | train_mae: 0.26917 | train_rmse: 0.3375  | train_mse: 0.11391 | valid_rmsle: 0.00728 | valid_mae: 0.27147 | valid_rmse: 0.34389 | valid_mse: 0.11826 |  0:00:51s\n",
      "epoch 30 | loss: 0.10866 | train_rmsle: 0.00671 | train_mae: 0.24326 | train_rmse: 0.31967 | train_mse: 0.10219 | valid_rmsle: 0.00639 | valid_mae: 0.24276 | valid_rmse: 0.31744 | valid_mse: 0.10077 |  0:00:53s\n",
      "epoch 31 | loss: 0.10314 | train_rmsle: 0.00657 | train_mae: 0.24303 | train_rmse: 0.31695 | train_mse: 0.10046 | valid_rmsle: 0.00666 | valid_mae: 0.24644 | valid_rmse: 0.32379 | valid_mse: 0.10484 |  0:00:54s\n",
      "epoch 32 | loss: 0.1011  | train_rmsle: 0.00722 | train_mae: 0.26568 | train_rmse: 0.33642 | train_mse: 0.11318 | valid_rmsle: 0.00691 | valid_mae: 0.26388 | valid_rmse: 0.33344 | valid_mse: 0.11118 |  0:00:56s\n",
      "epoch 33 | loss: 0.1013  | train_rmsle: 0.00637 | train_mae: 0.24156 | train_rmse: 0.31277 | train_mse: 0.09783 | valid_rmsle: 0.00614 | valid_mae: 0.23844 | valid_rmse: 0.31102 | valid_mse: 0.09673 |  0:00:58s\n",
      "epoch 34 | loss: 0.09938 | train_rmsle: 0.00612 | train_mae: 0.23299 | train_rmse: 0.3043  | train_mse: 0.0926  | valid_rmsle: 0.00595 | valid_mae: 0.23709 | valid_rmse: 0.30596 | valid_mse: 0.09361 |  0:01:00s\n",
      "epoch 35 | loss: 0.09737 | train_rmsle: 0.00636 | train_mae: 0.2456  | train_rmse: 0.31357 | train_mse: 0.09832 | valid_rmsle: 0.00601 | valid_mae: 0.24259 | valid_rmse: 0.30895 | valid_mse: 0.09545 |  0:01:01s\n",
      "epoch 36 | loss: 0.09423 | train_rmsle: 0.00609 | train_mae: 0.23554 | train_rmse: 0.30464 | train_mse: 0.0928  | valid_rmsle: 0.00605 | valid_mae: 0.23756 | valid_rmse: 0.30854 | valid_mse: 0.0952  |  0:01:03s\n",
      "epoch 37 | loss: 0.09532 | train_rmsle: 0.00633 | train_mae: 0.24695 | train_rmse: 0.31341 | train_mse: 0.09823 | valid_rmsle: 0.00629 | valid_mae: 0.24823 | valid_rmse: 0.31685 | valid_mse: 0.10039 |  0:01:05s\n",
      "epoch 38 | loss: 0.09129 | train_rmsle: 0.00647 | train_mae: 0.25187 | train_rmse: 0.31801 | train_mse: 0.10113 | valid_rmsle: 0.00628 | valid_mae: 0.25059 | valid_rmse: 0.31761 | valid_mse: 0.10088 |  0:01:07s\n",
      "epoch 39 | loss: 0.09285 | train_rmsle: 0.00613 | train_mae: 0.24012 | train_rmse: 0.3069  | train_mse: 0.09419 | valid_rmsle: 0.00602 | valid_mae: 0.24162 | valid_rmse: 0.30861 | valid_mse: 0.09524 |  0:01:08s\n",
      "epoch 40 | loss: 0.0951  | train_rmsle: 0.00579 | train_mae: 0.2239  | train_rmse: 0.29437 | train_mse: 0.08665 | valid_rmsle: 0.00577 | valid_mae: 0.22765 | valid_rmse: 0.30032 | valid_mse: 0.09019 |  0:01:10s\n",
      "epoch 41 | loss: 0.08883 | train_rmsle: 0.00577 | train_mae: 0.22759 | train_rmse: 0.29535 | train_mse: 0.08723 | valid_rmsle: 0.00576 | valid_mae: 0.2312  | valid_rmse: 0.30015 | valid_mse: 0.09009 |  0:01:12s\n",
      "epoch 42 | loss: 0.08877 | train_rmsle: 0.00575 | train_mae: 0.22614 | train_rmse: 0.29434 | train_mse: 0.08663 | valid_rmsle: 0.00585 | valid_mae: 0.23304 | valid_rmse: 0.30265 | valid_mse: 0.0916  |  0:01:14s\n",
      "epoch 43 | loss: 0.08989 | train_rmsle: 0.00573 | train_mae: 0.22405 | train_rmse: 0.29269 | train_mse: 0.08567 | valid_rmsle: 0.00585 | valid_mae: 0.2311  | valid_rmse: 0.30264 | valid_mse: 0.09159 |  0:01:16s\n",
      "epoch 44 | loss: 0.0888  | train_rmsle: 0.00592 | train_mae: 0.23421 | train_rmse: 0.30087 | train_mse: 0.09052 | valid_rmsle: 0.00586 | valid_mae: 0.23725 | valid_rmse: 0.30438 | valid_mse: 0.09265 |  0:01:17s\n",
      "epoch 45 | loss: 0.08801 | train_rmsle: 0.00574 | train_mae: 0.22327 | train_rmse: 0.29358 | train_mse: 0.08619 | valid_rmsle: 0.00576 | valid_mae: 0.22914 | valid_rmse: 0.30038 | valid_mse: 0.09023 |  0:01:19s\n",
      "epoch 46 | loss: 0.09283 | train_rmsle: 0.00571 | train_mae: 0.22528 | train_rmse: 0.29319 | train_mse: 0.08596 | valid_rmsle: 0.00567 | valid_mae: 0.22944 | valid_rmse: 0.298   | valid_mse: 0.08881 |  0:01:21s\n",
      "epoch 47 | loss: 0.09369 | train_rmsle: 0.0059  | train_mae: 0.23748 | train_rmse: 0.30176 | train_mse: 0.09106 | valid_rmsle: 0.00581 | valid_mae: 0.24088 | valid_rmse: 0.30457 | valid_mse: 0.09277 |  0:01:23s\n",
      "epoch 48 | loss: 0.08707 | train_rmsle: 0.00586 | train_mae: 0.22134 | train_rmse: 0.29464 | train_mse: 0.08681 | valid_rmsle: 0.00593 | valid_mae: 0.23075 | valid_rmse: 0.30346 | valid_mse: 0.09209 |  0:01:24s\n",
      "epoch 49 | loss: 0.08627 | train_rmsle: 0.00552 | train_mae: 0.2163  | train_rmse: 0.28573 | train_mse: 0.08164 | valid_rmsle: 0.0056  | valid_mae: 0.22412 | valid_rmse: 0.29474 | valid_mse: 0.08687 |  0:01:26s\n",
      "epoch 50 | loss: 0.0845  | train_rmsle: 0.00544 | train_mae: 0.21801 | train_rmse: 0.28514 | train_mse: 0.0813  | valid_rmsle: 0.00555 | valid_mae: 0.22623 | valid_rmse: 0.29393 | valid_mse: 0.0864  |  0:01:28s\n",
      "epoch 51 | loss: 0.08503 | train_rmsle: 0.00547 | train_mae: 0.22019 | train_rmse: 0.28643 | train_mse: 0.08204 | valid_rmsle: 0.00555 | valid_mae: 0.22697 | valid_rmse: 0.29473 | valid_mse: 0.08687 |  0:01:30s\n",
      "epoch 52 | loss: 0.08451 | train_rmsle: 0.00541 | train_mae: 0.21702 | train_rmse: 0.28358 | train_mse: 0.08042 | valid_rmsle: 0.00563 | valid_mae: 0.22622 | valid_rmse: 0.29647 | valid_mse: 0.08789 |  0:01:32s\n",
      "epoch 53 | loss: 0.08472 | train_rmsle: 0.00551 | train_mae: 0.2146  | train_rmse: 0.28511 | train_mse: 0.08129 | valid_rmsle: 0.00572 | valid_mae: 0.22478 | valid_rmse: 0.29714 | valid_mse: 0.08829 |  0:01:33s\n",
      "epoch 54 | loss: 0.08464 | train_rmsle: 0.00545 | train_mae: 0.22372 | train_rmse: 0.28748 | train_mse: 0.08265 | valid_rmsle: 0.00564 | valid_mae: 0.23126 | valid_rmse: 0.29827 | valid_mse: 0.08897 |  0:01:35s\n",
      "epoch 55 | loss: 0.08513 | train_rmsle: 0.00578 | train_mae: 0.23568 | train_rmse: 0.29847 | train_mse: 0.08908 | valid_rmsle: 0.00593 | valid_mae: 0.24176 | valid_rmse: 0.30723 | valid_mse: 0.09439 |  0:01:37s\n",
      "epoch 56 | loss: 0.08395 | train_rmsle: 0.00565 | train_mae: 0.23194 | train_rmse: 0.29444 | train_mse: 0.08669 | valid_rmsle: 0.00585 | valid_mae: 0.24016 | valid_rmse: 0.30479 | valid_mse: 0.0929  |  0:01:38s\n",
      "epoch 57 | loss: 0.08301 | train_rmsle: 0.00533 | train_mae: 0.21448 | train_rmse: 0.28088 | train_mse: 0.07889 | valid_rmsle: 0.00551 | valid_mae: 0.22439 | valid_rmse: 0.29212 | valid_mse: 0.08533 |  0:01:40s\n",
      "epoch 58 | loss: 0.08242 | train_rmsle: 0.00537 | train_mae: 0.21997 | train_rmse: 0.28499 | train_mse: 0.08122 | valid_rmsle: 0.00563 | valid_mae: 0.23028 | valid_rmse: 0.29715 | valid_mse: 0.0883  |  0:01:42s\n",
      "epoch 59 | loss: 0.08234 | train_rmsle: 0.00529 | train_mae: 0.21285 | train_rmse: 0.28013 | train_mse: 0.07847 | valid_rmsle: 0.00564 | valid_mae: 0.22378 | valid_rmse: 0.29832 | valid_mse: 0.08899 |  0:01:44s\n",
      "epoch 60 | loss: 0.08252 | train_rmsle: 0.00544 | train_mae: 0.21253 | train_rmse: 0.28314 | train_mse: 0.08017 | valid_rmsle: 0.00585 | valid_mae: 0.22608 | valid_rmse: 0.30203 | valid_mse: 0.09122 |  0:01:46s\n",
      "epoch 61 | loss: 0.08391 | train_rmsle: 0.00528 | train_mae: 0.2139  | train_rmse: 0.28048 | train_mse: 0.07867 | valid_rmsle: 0.00552 | valid_mae: 0.22404 | valid_rmse: 0.29338 | valid_mse: 0.08607 |  0:01:47s\n",
      "epoch 62 | loss: 0.08426 | train_rmsle: 0.00549 | train_mae: 0.22737 | train_rmse: 0.28989 | train_mse: 0.08403 | valid_rmsle: 0.00576 | valid_mae: 0.23471 | valid_rmse: 0.30199 | valid_mse: 0.0912  |  0:01:49s\n",
      "epoch 63 | loss: 0.08182 | train_rmsle: 0.00541 | train_mae: 0.21215 | train_rmse: 0.28211 | train_mse: 0.07959 | valid_rmsle: 0.00561 | valid_mae: 0.22109 | valid_rmse: 0.29296 | valid_mse: 0.08583 |  0:01:51s\n",
      "epoch 64 | loss: 0.08436 | train_rmsle: 0.00515 | train_mae: 0.21256 | train_rmse: 0.27729 | train_mse: 0.07689 | valid_rmsle: 0.00552 | valid_mae: 0.22339 | valid_rmse: 0.29266 | valid_mse: 0.08565 |  0:01:53s\n",
      "epoch 65 | loss: 0.08144 | train_rmsle: 0.00526 | train_mae: 0.21747 | train_rmse: 0.28129 | train_mse: 0.07913 | valid_rmsle: 0.00551 | valid_mae: 0.2263  | valid_rmse: 0.29337 | valid_mse: 0.08606 |  0:01:54s\n",
      "epoch 66 | loss: 0.08036 | train_rmsle: 0.0052  | train_mae: 0.21553 | train_rmse: 0.27932 | train_mse: 0.07802 | valid_rmsle: 0.00549 | valid_mae: 0.22551 | valid_rmse: 0.29285 | valid_mse: 0.08576 |  0:01:56s\n",
      "epoch 67 | loss: 0.08158 | train_rmsle: 0.00514 | train_mae: 0.21501 | train_rmse: 0.27802 | train_mse: 0.0773  | valid_rmsle: 0.00544 | valid_mae: 0.226   | valid_rmse: 0.29178 | valid_mse: 0.08513 |  0:01:58s\n",
      "epoch 68 | loss: 0.08034 | train_rmsle: 0.00511 | train_mae: 0.21218 | train_rmse: 0.27613 | train_mse: 0.07625 | valid_rmsle: 0.00543 | valid_mae: 0.22408 | valid_rmse: 0.29066 | valid_mse: 0.08448 |  0:02:00s\n",
      "epoch 69 | loss: 0.08024 | train_rmsle: 0.00508 | train_mae: 0.20939 | train_rmse: 0.27425 | train_mse: 0.07521 | valid_rmsle: 0.00546 | valid_mae: 0.22139 | valid_rmse: 0.28993 | valid_mse: 0.08406 |  0:02:02s\n",
      "epoch 70 | loss: 0.08176 | train_rmsle: 0.00506 | train_mae: 0.21216 | train_rmse: 0.27541 | train_mse: 0.07585 | valid_rmsle: 0.00556 | valid_mae: 0.22674 | valid_rmse: 0.29516 | valid_mse: 0.08712 |  0:02:03s\n",
      "epoch 71 | loss: 0.08304 | train_rmsle: 0.00512 | train_mae: 0.20653 | train_rmse: 0.27437 | train_mse: 0.07528 | valid_rmsle: 0.00564 | valid_mae: 0.22224 | valid_rmse: 0.29546 | valid_mse: 0.0873  |  0:02:05s\n",
      "epoch 72 | loss: 0.08027 | train_rmsle: 0.00499 | train_mae: 0.20825 | train_rmse: 0.27253 | train_mse: 0.07427 | valid_rmsle: 0.00557 | valid_mae: 0.22544 | valid_rmse: 0.29547 | valid_mse: 0.0873  |  0:02:07s\n",
      "epoch 73 | loss: 0.08024 | train_rmsle: 0.00513 | train_mae: 0.20582 | train_rmse: 0.27467 | train_mse: 0.07544 | valid_rmsle: 0.00587 | valid_mae: 0.22692 | valid_rmse: 0.30316 | valid_mse: 0.09191 |  0:02:09s\n",
      "epoch 74 | loss: 0.07978 | train_rmsle: 0.00492 | train_mae: 0.20605 | train_rmse: 0.27045 | train_mse: 0.07315 | valid_rmsle: 0.00559 | valid_mae: 0.22341 | valid_rmse: 0.29701 | valid_mse: 0.08821 |  0:02:10s\n",
      "epoch 75 | loss: 0.07829 | train_rmsle: 0.00504 | train_mae: 0.20532 | train_rmse: 0.27275 | train_mse: 0.07439 | valid_rmsle: 0.00574 | valid_mae: 0.2249  | valid_rmse: 0.30128 | valid_mse: 0.09077 |  0:02:12s\n",
      "epoch 76 | loss: 0.07861 | train_rmsle: 0.00487 | train_mae: 0.20578 | train_rmse: 0.26933 | train_mse: 0.07254 | valid_rmsle: 0.00549 | valid_mae: 0.22291 | valid_rmse: 0.29428 | valid_mse: 0.0866  |  0:02:13s\n",
      "epoch 77 | loss: 0.0769  | train_rmsle: 0.00486 | train_mae: 0.20322 | train_rmse: 0.26815 | train_mse: 0.0719  | valid_rmsle: 0.00561 | valid_mae: 0.22501 | valid_rmse: 0.29744 | valid_mse: 0.08847 |  0:02:15s\n",
      "epoch 78 | loss: 0.07637 | train_rmsle: 0.00482 | train_mae: 0.20354 | train_rmse: 0.26742 | train_mse: 0.07151 | valid_rmsle: 0.00546 | valid_mae: 0.22266 | valid_rmse: 0.29252 | valid_mse: 0.08557 |  0:02:16s\n",
      "epoch 79 | loss: 0.07739 | train_rmsle: 0.00509 | train_mae: 0.22016 | train_rmse: 0.28002 | train_mse: 0.07841 | valid_rmsle: 0.00568 | valid_mae: 0.23402 | valid_rmse: 0.30115 | valid_mse: 0.09069 |  0:02:18s\n",
      "epoch 80 | loss: 0.07676 | train_rmsle: 0.0048  | train_mae: 0.20384 | train_rmse: 0.26717 | train_mse: 0.07138 | valid_rmsle: 0.00546 | valid_mae: 0.22338 | valid_rmse: 0.29281 | valid_mse: 0.08574 |  0:02:19s\n",
      "epoch 81 | loss: 0.07613 | train_rmsle: 0.00476 | train_mae: 0.20236 | train_rmse: 0.26599 | train_mse: 0.07075 | valid_rmsle: 0.00541 | valid_mae: 0.22015 | valid_rmse: 0.29081 | valid_mse: 0.08457 |  0:02:21s\n",
      "epoch 82 | loss: 0.07479 | train_rmsle: 0.00477 | train_mae: 0.20059 | train_rmse: 0.26542 | train_mse: 0.07045 | valid_rmsle: 0.0055  | valid_mae: 0.22161 | valid_rmse: 0.29235 | valid_mse: 0.08547 |  0:02:23s\n",
      "epoch 83 | loss: 0.07661 | train_rmsle: 0.00473 | train_mae: 0.20005 | train_rmse: 0.26444 | train_mse: 0.06993 | valid_rmsle: 0.00547 | valid_mae: 0.22139 | valid_rmse: 0.29167 | valid_mse: 0.08507 |  0:02:24s\n",
      "epoch 84 | loss: 0.07663 | train_rmsle: 0.00466 | train_mae: 0.19955 | train_rmse: 0.26291 | train_mse: 0.06912 | valid_rmsle: 0.00547 | valid_mae: 0.22264 | valid_rmse: 0.29219 | valid_mse: 0.08538 |  0:02:26s\n",
      "epoch 85 | loss: 0.07654 | train_rmsle: 0.00464 | train_mae: 0.20029 | train_rmse: 0.26282 | train_mse: 0.06908 | valid_rmsle: 0.00542 | valid_mae: 0.22212 | valid_rmse: 0.29073 | valid_mse: 0.08452 |  0:02:28s\n",
      "epoch 86 | loss: 0.07411 | train_rmsle: 0.00476 | train_mae: 0.20861 | train_rmse: 0.26892 | train_mse: 0.07232 | valid_rmsle: 0.00552 | valid_mae: 0.22729 | valid_rmse: 0.29463 | valid_mse: 0.08681 |  0:02:30s\n",
      "epoch 87 | loss: 0.07547 | train_rmsle: 0.00469 | train_mae: 0.19948 | train_rmse: 0.26311 | train_mse: 0.06923 | valid_rmsle: 0.00557 | valid_mae: 0.22294 | valid_rmse: 0.29402 | valid_mse: 0.08645 |  0:02:31s\n",
      "epoch 88 | loss: 0.07457 | train_rmsle: 0.00472 | train_mae: 0.20838 | train_rmse: 0.26796 | train_mse: 0.07181 | valid_rmsle: 0.00557 | valid_mae: 0.2293  | valid_rmse: 0.29633 | valid_mse: 0.08781 |  0:02:33s\n",
      "epoch 89 | loss: 0.07363 | train_rmsle: 0.00458 | train_mae: 0.19628 | train_rmse: 0.26014 | train_mse: 0.06768 | valid_rmsle: 0.00554 | valid_mae: 0.22235 | valid_rmse: 0.2936  | valid_mse: 0.0862  |  0:02:35s\n",
      "\n",
      "Early stopping occurred at epoch 89 with best_epoch = 69 and best_valid_mse = 0.08406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08864580726253707 RMSE: 0.2977344576338739 R2: 0.6075991681248587 MAE: 0.2255995692125559\n",
      "=====================================\n",
      "[60/108] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.0241  | train_rmsle: 0.42023 | train_mae: 2.02722 | train_rmse: 2.08462 | train_mse: 4.34565 | valid_rmsle: 0.42195 | valid_mae: 2.03366 | valid_rmse: 2.08989 | valid_mse: 4.36764 |  0:00:01s\n",
      "epoch 1  | loss: 1.26435 | train_rmsle: 0.08715 | train_mae: 1.04995 | train_rmse: 1.13899 | train_mse: 1.29731 | valid_rmsle: 0.08744 | valid_mae: 1.05208 | valid_rmse: 1.14235 | valid_mse: 1.30497 |  0:00:03s\n",
      "epoch 2  | loss: 0.66443 | train_rmsle: 0.03323 | train_mae: 0.65547 | train_rmse: 0.7478  | train_mse: 0.5592  | valid_rmsle: 0.03309 | valid_mae: 0.65463 | valid_rmse: 0.74927 | valid_mse: 0.5614  |  0:00:05s\n",
      "epoch 3  | loss: 0.46895 | train_rmsle: 0.0287  | train_mae: 0.60706 | train_rmse: 0.69852 | train_mse: 0.48793 | valid_rmsle: 0.02851 | valid_mae: 0.60685 | valid_rmse: 0.69957 | valid_mse: 0.4894  |  0:00:07s\n",
      "epoch 4  | loss: 0.36125 | train_rmsle: 0.02834 | train_mae: 0.60289 | train_rmse: 0.69434 | train_mse: 0.48211 | valid_rmsle: 0.02812 | valid_mae: 0.60293 | valid_rmse: 0.69501 | valid_mse: 0.48304 |  0:00:08s\n",
      "epoch 5  | loss: 0.31669 | train_rmsle: 0.02383 | train_mae: 0.5488  | train_rmse: 0.63874 | train_mse: 0.40799 | valid_rmsle: 0.02353 | valid_mae: 0.54919 | valid_rmse: 0.6387  | valid_mse: 0.40793 |  0:00:10s\n",
      "epoch 6  | loss: 0.2964  | train_rmsle: 0.01891 | train_mae: 0.4799  | train_rmse: 0.56781 | train_mse: 0.32241 | valid_rmsle: 0.01851 | valid_mae: 0.48074 | valid_rmse: 0.56651 | valid_mse: 0.32094 |  0:00:12s\n",
      "epoch 7  | loss: 0.26732 | train_rmsle: 0.02251 | train_mae: 0.53234 | train_rmse: 0.62113 | train_mse: 0.3858  | valid_rmsle: 0.02223 | valid_mae: 0.53328 | valid_rmse: 0.62123 | valid_mse: 0.38593 |  0:00:14s\n",
      "epoch 8  | loss: 0.24704 | train_rmsle: 0.01172 | train_mae: 0.36924 | train_rmse: 0.4417  | train_mse: 0.1951  | valid_rmsle: 0.01118 | valid_mae: 0.36263 | valid_rmse: 0.43568 | valid_mse: 0.18981 |  0:00:15s\n",
      "epoch 9  | loss: 0.20943 | train_rmsle: 0.014   | train_mae: 0.38085 | train_rmse: 0.46603 | train_mse: 0.21719 | valid_rmsle: 0.0129  | valid_mae: 0.36525 | valid_rmse: 0.44985 | valid_mse: 0.20236 |  0:00:17s\n",
      "epoch 10 | loss: 0.18553 | train_rmsle: 0.01022 | train_mae: 0.31879 | train_rmse: 0.39978 | train_mse: 0.15982 | valid_rmsle: 0.00939 | valid_mae: 0.30285 | valid_rmse: 0.38474 | valid_mse: 0.14803 |  0:00:19s\n",
      "epoch 11 | loss: 0.17548 | train_rmsle: 0.01212 | train_mae: 0.35383 | train_rmse: 0.43644 | train_mse: 0.19048 | valid_rmsle: 0.01144 | valid_mae: 0.34205 | valid_rmse: 0.42605 | valid_mse: 0.18152 |  0:00:21s\n",
      "epoch 12 | loss: 0.16351 | train_rmsle: 0.00863 | train_mae: 0.29061 | train_rmse: 0.36826 | train_mse: 0.13561 | valid_rmsle: 0.00785 | valid_mae: 0.275   | valid_rmse: 0.35271 | valid_mse: 0.1244  |  0:00:23s\n",
      "epoch 13 | loss: 0.16167 | train_rmsle: 0.00982 | train_mae: 0.32122 | train_rmse: 0.39621 | train_mse: 0.15698 | valid_rmsle: 0.00891 | valid_mae: 0.30545 | valid_rmse: 0.37867 | valid_mse: 0.14339 |  0:00:24s\n",
      "epoch 14 | loss: 0.15853 | train_rmsle: 0.00763 | train_mae: 0.27367 | train_rmse: 0.34561 | train_mse: 0.11945 | valid_rmsle: 0.00687 | valid_mae: 0.26087 | valid_rmse: 0.33148 | valid_mse: 0.10988 |  0:00:26s\n",
      "epoch 15 | loss: 0.1516  | train_rmsle: 0.00694 | train_mae: 0.24931 | train_rmse: 0.32541 | train_mse: 0.10589 | valid_rmsle: 0.00645 | valid_mae: 0.24186 | valid_rmse: 0.31818 | valid_mse: 0.10124 |  0:00:28s\n",
      "epoch 16 | loss: 0.15005 | train_rmsle: 0.00776 | train_mae: 0.27975 | train_rmse: 0.35031 | train_mse: 0.12272 | valid_rmsle: 0.00693 | valid_mae: 0.26661 | valid_rmse: 0.33434 | valid_mse: 0.11178 |  0:00:30s\n",
      "epoch 17 | loss: 0.13835 | train_rmsle: 0.007   | train_mae: 0.25865 | train_rmse: 0.32946 | train_mse: 0.10854 | valid_rmsle: 0.00627 | valid_mae: 0.24664 | valid_rmse: 0.31511 | valid_mse: 0.0993  |  0:00:31s\n",
      "epoch 18 | loss: 0.13278 | train_rmsle: 0.00708 | train_mae: 0.26002 | train_rmse: 0.33204 | train_mse: 0.11025 | valid_rmsle: 0.00651 | valid_mae: 0.25114 | valid_rmse: 0.32192 | valid_mse: 0.10363 |  0:00:33s\n",
      "epoch 19 | loss: 0.12889 | train_rmsle: 0.00859 | train_mae: 0.3011  | train_rmse: 0.37092 | train_mse: 0.13758 | valid_rmsle: 0.00785 | valid_mae: 0.28985 | valid_rmse: 0.3588  | valid_mse: 0.12874 |  0:00:35s\n",
      "epoch 20 | loss: 0.13035 | train_rmsle: 0.00655 | train_mae: 0.24273 | train_rmse: 0.3168  | train_mse: 0.10036 | valid_rmsle: 0.00608 | valid_mae: 0.23651 | valid_rmse: 0.30967 | valid_mse: 0.09589 |  0:00:37s\n",
      "epoch 21 | loss: 0.13171 | train_rmsle: 0.00649 | train_mae: 0.23863 | train_rmse: 0.31384 | train_mse: 0.0985  | valid_rmsle: 0.00624 | valid_mae: 0.23809 | valid_rmse: 0.31298 | valid_mse: 0.09796 |  0:00:38s\n",
      "epoch 22 | loss: 0.12033 | train_rmsle: 0.00803 | train_mae: 0.28513 | train_rmse: 0.35681 | train_mse: 0.12731 | valid_rmsle: 0.00771 | valid_mae: 0.28121 | valid_rmse: 0.35455 | valid_mse: 0.12571 |  0:00:40s\n",
      "epoch 23 | loss: 0.12204 | train_rmsle: 0.00682 | train_mae: 0.25047 | train_rmse: 0.32504 | train_mse: 0.10565 | valid_rmsle: 0.00641 | valid_mae: 0.24579 | valid_rmse: 0.31993 | valid_mse: 0.10236 |  0:00:42s\n",
      "epoch 24 | loss: 0.11541 | train_rmsle: 0.00747 | train_mae: 0.26702 | train_rmse: 0.34113 | train_mse: 0.11637 | valid_rmsle: 0.00682 | valid_mae: 0.25988 | valid_rmse: 0.33059 | valid_mse: 0.10929 |  0:00:44s\n",
      "epoch 25 | loss: 0.11375 | train_rmsle: 0.00671 | train_mae: 0.24079 | train_rmse: 0.31877 | train_mse: 0.10161 | valid_rmsle: 0.00643 | valid_mae: 0.23903 | valid_rmse: 0.31706 | valid_mse: 0.10052 |  0:00:45s\n",
      "epoch 26 | loss: 0.12679 | train_rmsle: 0.00692 | train_mae: 0.25595 | train_rmse: 0.32831 | train_mse: 0.10779 | valid_rmsle: 0.00639 | valid_mae: 0.24776 | valid_rmse: 0.3187  | valid_mse: 0.10157 |  0:00:47s\n",
      "epoch 27 | loss: 0.10713 | train_rmsle: 0.00661 | train_mae: 0.24581 | train_rmse: 0.31919 | train_mse: 0.10188 | valid_rmsle: 0.00651 | valid_mae: 0.2428  | valid_rmse: 0.32107 | valid_mse: 0.10309 |  0:00:49s\n",
      "epoch 28 | loss: 0.11204 | train_rmsle: 0.00749 | train_mae: 0.27517 | train_rmse: 0.34442 | train_mse: 0.11862 | valid_rmsle: 0.00709 | valid_mae: 0.26651 | valid_rmse: 0.33842 | valid_mse: 0.11453 |  0:00:51s\n",
      "epoch 29 | loss: 0.10882 | train_rmsle: 0.00719 | train_mae: 0.26917 | train_rmse: 0.3375  | train_mse: 0.11391 | valid_rmsle: 0.00728 | valid_mae: 0.27147 | valid_rmse: 0.34389 | valid_mse: 0.11826 |  0:00:53s\n",
      "epoch 30 | loss: 0.10866 | train_rmsle: 0.00671 | train_mae: 0.24326 | train_rmse: 0.31967 | train_mse: 0.10219 | valid_rmsle: 0.00639 | valid_mae: 0.24276 | valid_rmse: 0.31744 | valid_mse: 0.10077 |  0:00:54s\n",
      "epoch 31 | loss: 0.10314 | train_rmsle: 0.00657 | train_mae: 0.24303 | train_rmse: 0.31695 | train_mse: 0.10046 | valid_rmsle: 0.00666 | valid_mae: 0.24644 | valid_rmse: 0.32379 | valid_mse: 0.10484 |  0:00:56s\n",
      "epoch 32 | loss: 0.1011  | train_rmsle: 0.00722 | train_mae: 0.26568 | train_rmse: 0.33642 | train_mse: 0.11318 | valid_rmsle: 0.00691 | valid_mae: 0.26388 | valid_rmse: 0.33344 | valid_mse: 0.11118 |  0:00:58s\n",
      "epoch 33 | loss: 0.1013  | train_rmsle: 0.00637 | train_mae: 0.24156 | train_rmse: 0.31277 | train_mse: 0.09783 | valid_rmsle: 0.00614 | valid_mae: 0.23844 | valid_rmse: 0.31102 | valid_mse: 0.09673 |  0:01:00s\n",
      "epoch 34 | loss: 0.09938 | train_rmsle: 0.00612 | train_mae: 0.23299 | train_rmse: 0.3043  | train_mse: 0.0926  | valid_rmsle: 0.00595 | valid_mae: 0.23709 | valid_rmse: 0.30596 | valid_mse: 0.09361 |  0:01:01s\n",
      "epoch 35 | loss: 0.09737 | train_rmsle: 0.00636 | train_mae: 0.2456  | train_rmse: 0.31357 | train_mse: 0.09832 | valid_rmsle: 0.00601 | valid_mae: 0.24259 | valid_rmse: 0.30895 | valid_mse: 0.09545 |  0:01:03s\n",
      "epoch 36 | loss: 0.09423 | train_rmsle: 0.00609 | train_mae: 0.23554 | train_rmse: 0.30464 | train_mse: 0.0928  | valid_rmsle: 0.00605 | valid_mae: 0.23756 | valid_rmse: 0.30854 | valid_mse: 0.0952  |  0:01:05s\n",
      "epoch 37 | loss: 0.09532 | train_rmsle: 0.00633 | train_mae: 0.24695 | train_rmse: 0.31341 | train_mse: 0.09823 | valid_rmsle: 0.00629 | valid_mae: 0.24823 | valid_rmse: 0.31685 | valid_mse: 0.10039 |  0:01:07s\n",
      "epoch 38 | loss: 0.09129 | train_rmsle: 0.00647 | train_mae: 0.25187 | train_rmse: 0.31801 | train_mse: 0.10113 | valid_rmsle: 0.00628 | valid_mae: 0.25059 | valid_rmse: 0.31761 | valid_mse: 0.10088 |  0:01:08s\n",
      "epoch 39 | loss: 0.09285 | train_rmsle: 0.00613 | train_mae: 0.24012 | train_rmse: 0.3069  | train_mse: 0.09419 | valid_rmsle: 0.00602 | valid_mae: 0.24162 | valid_rmse: 0.30861 | valid_mse: 0.09524 |  0:01:10s\n",
      "epoch 40 | loss: 0.0951  | train_rmsle: 0.00579 | train_mae: 0.2239  | train_rmse: 0.29437 | train_mse: 0.08665 | valid_rmsle: 0.00577 | valid_mae: 0.22765 | valid_rmse: 0.30032 | valid_mse: 0.09019 |  0:01:11s\n",
      "epoch 41 | loss: 0.08883 | train_rmsle: 0.00577 | train_mae: 0.22759 | train_rmse: 0.29535 | train_mse: 0.08723 | valid_rmsle: 0.00576 | valid_mae: 0.2312  | valid_rmse: 0.30015 | valid_mse: 0.09009 |  0:01:13s\n",
      "epoch 42 | loss: 0.08877 | train_rmsle: 0.00575 | train_mae: 0.22614 | train_rmse: 0.29434 | train_mse: 0.08663 | valid_rmsle: 0.00585 | valid_mae: 0.23304 | valid_rmse: 0.30265 | valid_mse: 0.0916  |  0:01:14s\n",
      "epoch 43 | loss: 0.08989 | train_rmsle: 0.00573 | train_mae: 0.22405 | train_rmse: 0.29269 | train_mse: 0.08567 | valid_rmsle: 0.00585 | valid_mae: 0.2311  | valid_rmse: 0.30264 | valid_mse: 0.09159 |  0:01:16s\n",
      "epoch 44 | loss: 0.0888  | train_rmsle: 0.00592 | train_mae: 0.23421 | train_rmse: 0.30087 | train_mse: 0.09052 | valid_rmsle: 0.00586 | valid_mae: 0.23725 | valid_rmse: 0.30438 | valid_mse: 0.09265 |  0:01:17s\n",
      "epoch 45 | loss: 0.08801 | train_rmsle: 0.00574 | train_mae: 0.22327 | train_rmse: 0.29358 | train_mse: 0.08619 | valid_rmsle: 0.00576 | valid_mae: 0.22914 | valid_rmse: 0.30038 | valid_mse: 0.09023 |  0:01:19s\n",
      "epoch 46 | loss: 0.09283 | train_rmsle: 0.00571 | train_mae: 0.22528 | train_rmse: 0.29319 | train_mse: 0.08596 | valid_rmsle: 0.00567 | valid_mae: 0.22944 | valid_rmse: 0.298   | valid_mse: 0.08881 |  0:01:21s\n",
      "epoch 47 | loss: 0.09369 | train_rmsle: 0.0059  | train_mae: 0.23748 | train_rmse: 0.30176 | train_mse: 0.09106 | valid_rmsle: 0.00581 | valid_mae: 0.24088 | valid_rmse: 0.30457 | valid_mse: 0.09277 |  0:01:23s\n",
      "epoch 48 | loss: 0.08707 | train_rmsle: 0.00586 | train_mae: 0.22134 | train_rmse: 0.29464 | train_mse: 0.08681 | valid_rmsle: 0.00593 | valid_mae: 0.23075 | valid_rmse: 0.30346 | valid_mse: 0.09209 |  0:01:24s\n",
      "epoch 49 | loss: 0.08627 | train_rmsle: 0.00552 | train_mae: 0.2163  | train_rmse: 0.28573 | train_mse: 0.08164 | valid_rmsle: 0.0056  | valid_mae: 0.22412 | valid_rmse: 0.29474 | valid_mse: 0.08687 |  0:01:26s\n",
      "epoch 50 | loss: 0.0845  | train_rmsle: 0.00544 | train_mae: 0.21801 | train_rmse: 0.28514 | train_mse: 0.0813  | valid_rmsle: 0.00555 | valid_mae: 0.22623 | valid_rmse: 0.29393 | valid_mse: 0.0864  |  0:01:28s\n",
      "epoch 51 | loss: 0.08503 | train_rmsle: 0.00547 | train_mae: 0.22019 | train_rmse: 0.28643 | train_mse: 0.08204 | valid_rmsle: 0.00555 | valid_mae: 0.22697 | valid_rmse: 0.29473 | valid_mse: 0.08687 |  0:01:30s\n",
      "epoch 52 | loss: 0.08451 | train_rmsle: 0.00541 | train_mae: 0.21702 | train_rmse: 0.28358 | train_mse: 0.08042 | valid_rmsle: 0.00563 | valid_mae: 0.22622 | valid_rmse: 0.29647 | valid_mse: 0.08789 |  0:01:31s\n",
      "epoch 53 | loss: 0.08472 | train_rmsle: 0.00551 | train_mae: 0.2146  | train_rmse: 0.28511 | train_mse: 0.08129 | valid_rmsle: 0.00572 | valid_mae: 0.22478 | valid_rmse: 0.29714 | valid_mse: 0.08829 |  0:01:33s\n",
      "epoch 54 | loss: 0.08464 | train_rmsle: 0.00545 | train_mae: 0.22372 | train_rmse: 0.28748 | train_mse: 0.08265 | valid_rmsle: 0.00564 | valid_mae: 0.23126 | valid_rmse: 0.29827 | valid_mse: 0.08897 |  0:01:35s\n",
      "epoch 55 | loss: 0.08513 | train_rmsle: 0.00578 | train_mae: 0.23568 | train_rmse: 0.29847 | train_mse: 0.08908 | valid_rmsle: 0.00593 | valid_mae: 0.24176 | valid_rmse: 0.30723 | valid_mse: 0.09439 |  0:01:37s\n",
      "epoch 56 | loss: 0.08395 | train_rmsle: 0.00565 | train_mae: 0.23194 | train_rmse: 0.29444 | train_mse: 0.08669 | valid_rmsle: 0.00585 | valid_mae: 0.24016 | valid_rmse: 0.30479 | valid_mse: 0.0929  |  0:01:38s\n",
      "epoch 57 | loss: 0.08301 | train_rmsle: 0.00533 | train_mae: 0.21448 | train_rmse: 0.28088 | train_mse: 0.07889 | valid_rmsle: 0.00551 | valid_mae: 0.22439 | valid_rmse: 0.29212 | valid_mse: 0.08533 |  0:01:40s\n",
      "epoch 58 | loss: 0.08242 | train_rmsle: 0.00537 | train_mae: 0.21997 | train_rmse: 0.28499 | train_mse: 0.08122 | valid_rmsle: 0.00563 | valid_mae: 0.23028 | valid_rmse: 0.29715 | valid_mse: 0.0883  |  0:01:42s\n",
      "epoch 59 | loss: 0.08234 | train_rmsle: 0.00529 | train_mae: 0.21285 | train_rmse: 0.28013 | train_mse: 0.07847 | valid_rmsle: 0.00564 | valid_mae: 0.22378 | valid_rmse: 0.29832 | valid_mse: 0.08899 |  0:01:44s\n",
      "epoch 60 | loss: 0.08252 | train_rmsle: 0.00544 | train_mae: 0.21253 | train_rmse: 0.28314 | train_mse: 0.08017 | valid_rmsle: 0.00585 | valid_mae: 0.22608 | valid_rmse: 0.30203 | valid_mse: 0.09122 |  0:01:46s\n",
      "epoch 61 | loss: 0.08391 | train_rmsle: 0.00528 | train_mae: 0.2139  | train_rmse: 0.28048 | train_mse: 0.07867 | valid_rmsle: 0.00552 | valid_mae: 0.22404 | valid_rmse: 0.29338 | valid_mse: 0.08607 |  0:01:47s\n",
      "epoch 62 | loss: 0.08426 | train_rmsle: 0.00549 | train_mae: 0.22737 | train_rmse: 0.28989 | train_mse: 0.08403 | valid_rmsle: 0.00576 | valid_mae: 0.23471 | valid_rmse: 0.30199 | valid_mse: 0.0912  |  0:01:49s\n",
      "epoch 63 | loss: 0.08182 | train_rmsle: 0.00541 | train_mae: 0.21215 | train_rmse: 0.28211 | train_mse: 0.07959 | valid_rmsle: 0.00561 | valid_mae: 0.22109 | valid_rmse: 0.29296 | valid_mse: 0.08583 |  0:01:51s\n",
      "epoch 64 | loss: 0.08436 | train_rmsle: 0.00515 | train_mae: 0.21256 | train_rmse: 0.27729 | train_mse: 0.07689 | valid_rmsle: 0.00552 | valid_mae: 0.22339 | valid_rmse: 0.29266 | valid_mse: 0.08565 |  0:01:53s\n",
      "epoch 65 | loss: 0.08144 | train_rmsle: 0.00526 | train_mae: 0.21747 | train_rmse: 0.28129 | train_mse: 0.07913 | valid_rmsle: 0.00551 | valid_mae: 0.2263  | valid_rmse: 0.29337 | valid_mse: 0.08606 |  0:01:54s\n",
      "epoch 66 | loss: 0.08036 | train_rmsle: 0.0052  | train_mae: 0.21553 | train_rmse: 0.27932 | train_mse: 0.07802 | valid_rmsle: 0.00549 | valid_mae: 0.22551 | valid_rmse: 0.29285 | valid_mse: 0.08576 |  0:01:56s\n",
      "epoch 67 | loss: 0.08158 | train_rmsle: 0.00514 | train_mae: 0.21501 | train_rmse: 0.27802 | train_mse: 0.0773  | valid_rmsle: 0.00544 | valid_mae: 0.226   | valid_rmse: 0.29178 | valid_mse: 0.08513 |  0:01:58s\n",
      "epoch 68 | loss: 0.08034 | train_rmsle: 0.00511 | train_mae: 0.21218 | train_rmse: 0.27613 | train_mse: 0.07625 | valid_rmsle: 0.00543 | valid_mae: 0.22408 | valid_rmse: 0.29066 | valid_mse: 0.08448 |  0:02:00s\n",
      "epoch 69 | loss: 0.08024 | train_rmsle: 0.00508 | train_mae: 0.20939 | train_rmse: 0.27425 | train_mse: 0.07521 | valid_rmsle: 0.00546 | valid_mae: 0.22139 | valid_rmse: 0.28993 | valid_mse: 0.08406 |  0:02:01s\n",
      "epoch 70 | loss: 0.08176 | train_rmsle: 0.00506 | train_mae: 0.21216 | train_rmse: 0.27541 | train_mse: 0.07585 | valid_rmsle: 0.00556 | valid_mae: 0.22674 | valid_rmse: 0.29516 | valid_mse: 0.08712 |  0:02:03s\n",
      "epoch 71 | loss: 0.08304 | train_rmsle: 0.00512 | train_mae: 0.20653 | train_rmse: 0.27437 | train_mse: 0.07528 | valid_rmsle: 0.00564 | valid_mae: 0.22224 | valid_rmse: 0.29546 | valid_mse: 0.0873  |  0:02:05s\n",
      "epoch 72 | loss: 0.08027 | train_rmsle: 0.00499 | train_mae: 0.20825 | train_rmse: 0.27253 | train_mse: 0.07427 | valid_rmsle: 0.00557 | valid_mae: 0.22544 | valid_rmse: 0.29547 | valid_mse: 0.0873  |  0:02:07s\n",
      "epoch 73 | loss: 0.08024 | train_rmsle: 0.00513 | train_mae: 0.20582 | train_rmse: 0.27467 | train_mse: 0.07544 | valid_rmsle: 0.00587 | valid_mae: 0.22692 | valid_rmse: 0.30316 | valid_mse: 0.09191 |  0:02:09s\n",
      "epoch 74 | loss: 0.07978 | train_rmsle: 0.00492 | train_mae: 0.20605 | train_rmse: 0.27045 | train_mse: 0.07315 | valid_rmsle: 0.00559 | valid_mae: 0.22341 | valid_rmse: 0.29701 | valid_mse: 0.08821 |  0:02:10s\n",
      "epoch 75 | loss: 0.07829 | train_rmsle: 0.00504 | train_mae: 0.20532 | train_rmse: 0.27275 | train_mse: 0.07439 | valid_rmsle: 0.00574 | valid_mae: 0.2249  | valid_rmse: 0.30128 | valid_mse: 0.09077 |  0:02:12s\n",
      "epoch 76 | loss: 0.07861 | train_rmsle: 0.00487 | train_mae: 0.20578 | train_rmse: 0.26933 | train_mse: 0.07254 | valid_rmsle: 0.00549 | valid_mae: 0.22291 | valid_rmse: 0.29428 | valid_mse: 0.0866  |  0:02:14s\n",
      "epoch 77 | loss: 0.0769  | train_rmsle: 0.00486 | train_mae: 0.20322 | train_rmse: 0.26815 | train_mse: 0.0719  | valid_rmsle: 0.00561 | valid_mae: 0.22501 | valid_rmse: 0.29744 | valid_mse: 0.08847 |  0:02:16s\n",
      "epoch 78 | loss: 0.07637 | train_rmsle: 0.00482 | train_mae: 0.20354 | train_rmse: 0.26742 | train_mse: 0.07151 | valid_rmsle: 0.00546 | valid_mae: 0.22266 | valid_rmse: 0.29252 | valid_mse: 0.08557 |  0:02:17s\n",
      "epoch 79 | loss: 0.07739 | train_rmsle: 0.00509 | train_mae: 0.22016 | train_rmse: 0.28002 | train_mse: 0.07841 | valid_rmsle: 0.00568 | valid_mae: 0.23402 | valid_rmse: 0.30115 | valid_mse: 0.09069 |  0:02:19s\n",
      "epoch 80 | loss: 0.07676 | train_rmsle: 0.0048  | train_mae: 0.20384 | train_rmse: 0.26717 | train_mse: 0.07138 | valid_rmsle: 0.00546 | valid_mae: 0.22338 | valid_rmse: 0.29281 | valid_mse: 0.08574 |  0:02:21s\n",
      "epoch 81 | loss: 0.07613 | train_rmsle: 0.00476 | train_mae: 0.20236 | train_rmse: 0.26599 | train_mse: 0.07075 | valid_rmsle: 0.00541 | valid_mae: 0.22015 | valid_rmse: 0.29081 | valid_mse: 0.08457 |  0:02:23s\n",
      "epoch 82 | loss: 0.07479 | train_rmsle: 0.00477 | train_mae: 0.20059 | train_rmse: 0.26542 | train_mse: 0.07045 | valid_rmsle: 0.0055  | valid_mae: 0.22161 | valid_rmse: 0.29235 | valid_mse: 0.08547 |  0:02:24s\n",
      "epoch 83 | loss: 0.07661 | train_rmsle: 0.00473 | train_mae: 0.20005 | train_rmse: 0.26444 | train_mse: 0.06993 | valid_rmsle: 0.00547 | valid_mae: 0.22139 | valid_rmse: 0.29167 | valid_mse: 0.08507 |  0:02:26s\n",
      "epoch 84 | loss: 0.07663 | train_rmsle: 0.00466 | train_mae: 0.19955 | train_rmse: 0.26291 | train_mse: 0.06912 | valid_rmsle: 0.00547 | valid_mae: 0.22264 | valid_rmse: 0.29219 | valid_mse: 0.08538 |  0:02:28s\n",
      "epoch 85 | loss: 0.07654 | train_rmsle: 0.00464 | train_mae: 0.20029 | train_rmse: 0.26282 | train_mse: 0.06908 | valid_rmsle: 0.00542 | valid_mae: 0.22212 | valid_rmse: 0.29073 | valid_mse: 0.08452 |  0:02:30s\n",
      "epoch 86 | loss: 0.07411 | train_rmsle: 0.00476 | train_mae: 0.20861 | train_rmse: 0.26892 | train_mse: 0.07232 | valid_rmsle: 0.00552 | valid_mae: 0.22729 | valid_rmse: 0.29463 | valid_mse: 0.08681 |  0:02:31s\n",
      "epoch 87 | loss: 0.07547 | train_rmsle: 0.00469 | train_mae: 0.19948 | train_rmse: 0.26311 | train_mse: 0.06923 | valid_rmsle: 0.00557 | valid_mae: 0.22294 | valid_rmse: 0.29402 | valid_mse: 0.08645 |  0:02:33s\n",
      "epoch 88 | loss: 0.07457 | train_rmsle: 0.00472 | train_mae: 0.20838 | train_rmse: 0.26796 | train_mse: 0.07181 | valid_rmsle: 0.00557 | valid_mae: 0.2293  | valid_rmse: 0.29633 | valid_mse: 0.08781 |  0:02:35s\n",
      "epoch 89 | loss: 0.07363 | train_rmsle: 0.00458 | train_mae: 0.19628 | train_rmse: 0.26014 | train_mse: 0.06768 | valid_rmsle: 0.00554 | valid_mae: 0.22235 | valid_rmse: 0.2936  | valid_mse: 0.0862  |  0:02:37s\n",
      "\n",
      "Early stopping occurred at epoch 89 with best_epoch = 69 and best_valid_mse = 0.08406\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08864580726253707 RMSE: 0.2977344576338739 R2: 0.6075991681248587 MAE: 0.2255995692125559\n",
      "=====================================\n",
      "[61/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.74497 | train_rmsle: 0.15935 | train_mae: 1.37644 | train_rmse: 1.45453 | train_mse: 2.11566 | valid_rmsle: 0.16017 | valid_mae: 1.38076 | valid_rmse: 1.4592  | valid_mse: 2.12927 |  0:00:02s\n",
      "epoch 1  | loss: 0.576   | train_rmsle: 0.08746 | train_mae: 1.05207 | train_rmse: 1.14039 | train_mse: 1.30048 | valid_rmsle: 0.08774 | valid_mae: 1.05444 | valid_rmse: 1.14365 | valid_mse: 1.30793 |  0:00:04s\n",
      "epoch 2  | loss: 0.38487 | train_rmsle: 0.06944 | train_mae: 0.94363 | train_rmse: 1.03505 | train_mse: 1.07133 | valid_rmsle: 0.06969 | valid_mae: 0.9459  | valid_rmse: 1.03852 | valid_mse: 1.07853 |  0:00:06s\n",
      "epoch 3  | loss: 0.3946  | train_rmsle: 0.03068 | train_mae: 0.62862 | train_rmse: 0.72062 | train_mse: 0.51929 | valid_rmsle: 0.03053 | valid_mae: 0.62849 | valid_rmse: 0.72202 | valid_mse: 0.52131 |  0:00:08s\n",
      "epoch 4  | loss: 0.37912 | train_rmsle: 0.02773 | train_mae: 0.5964  | train_rmse: 0.68715 | train_mse: 0.47218 | valid_rmsle: 0.02761 | valid_mae: 0.59771 | valid_rmse: 0.68898 | valid_mse: 0.4747  |  0:00:11s\n",
      "epoch 5  | loss: 0.31791 | train_rmsle: 0.03534 | train_mae: 0.67489 | train_rmse: 0.76865 | train_mse: 0.59083 | valid_rmsle: 0.03536 | valid_mae: 0.67692 | valid_rmse: 0.7715  | valid_mse: 0.5952  |  0:00:13s\n",
      "epoch 6  | loss: 0.2562  | train_rmsle: 0.03801 | train_mae: 0.6998  | train_rmse: 0.79457 | train_mse: 0.63134 | valid_rmsle: 0.03785 | valid_mae: 0.69709 | valid_rmse: 0.79578 | valid_mse: 0.63326 |  0:00:15s\n",
      "epoch 7  | loss: 0.27039 | train_rmsle: 0.02739 | train_mae: 0.59123 | train_rmse: 0.68304 | train_mse: 0.46654 | valid_rmsle: 0.02717 | valid_mae: 0.59101 | valid_rmse: 0.68382 | valid_mse: 0.4676  |  0:00:17s\n",
      "epoch 8  | loss: 0.29747 | train_rmsle: 0.03763 | train_mae: 0.69852 | train_rmse: 0.79126 | train_mse: 0.62609 | valid_rmsle: 0.03735 | valid_mae: 0.69628 | valid_rmse: 0.79122 | valid_mse: 0.62602 |  0:00:20s\n",
      "epoch 9  | loss: 0.28916 | train_rmsle: 0.02251 | train_mae: 0.53218 | train_rmse: 0.62103 | train_mse: 0.38568 | valid_rmsle: 0.02215 | valid_mae: 0.53194 | valid_rmse: 0.61996 | valid_mse: 0.38435 |  0:00:22s\n",
      "epoch 10 | loss: 0.24046 | train_rmsle: 0.01968 | train_mae: 0.49156 | train_rmse: 0.5799  | train_mse: 0.33628 | valid_rmsle: 0.0193  | valid_mae: 0.49197 | valid_rmse: 0.57866 | valid_mse: 0.33484 |  0:00:24s\n",
      "epoch 11 | loss: 0.23517 | train_rmsle: 0.01623 | train_mae: 0.43218 | train_rmse: 0.52096 | train_mse: 0.2714  | valid_rmsle: 0.01574 | valid_mae: 0.43261 | valid_rmse: 0.51799 | valid_mse: 0.26831 |  0:00:26s\n",
      "epoch 12 | loss: 0.2321  | train_rmsle: 0.01915 | train_mae: 0.4839  | train_rmse: 0.57165 | train_mse: 0.32679 | valid_rmsle: 0.0188  | valid_mae: 0.48522 | valid_rmse: 0.57097 | valid_mse: 0.32601 |  0:00:28s\n",
      "epoch 13 | loss: 0.22989 | train_rmsle: 0.01587 | train_mae: 0.42402 | train_rmse: 0.51398 | train_mse: 0.26418 | valid_rmsle: 0.01533 | valid_mae: 0.4247  | valid_rmse: 0.51027 | valid_mse: 0.26038 |  0:00:31s\n",
      "epoch 14 | loss: 0.23473 | train_rmsle: 0.01555 | train_mae: 0.41731 | train_rmse: 0.5077  | train_mse: 0.25776 | valid_rmsle: 0.01507 | valid_mae: 0.41798 | valid_rmse: 0.50514 | valid_mse: 0.25516 |  0:00:33s\n",
      "epoch 15 | loss: 0.23186 | train_rmsle: 0.01668 | train_mae: 0.44019 | train_rmse: 0.52937 | train_mse: 0.28023 | valid_rmsle: 0.01628 | valid_mae: 0.4414  | valid_rmse: 0.52821 | valid_mse: 0.279   |  0:00:35s\n",
      "epoch 16 | loss: 0.23225 | train_rmsle: 0.01547 | train_mae: 0.41659 | train_rmse: 0.50665 | train_mse: 0.25669 | valid_rmsle: 0.015   | valid_mae: 0.41797 | valid_rmse: 0.50403 | valid_mse: 0.25405 |  0:00:37s\n",
      "epoch 17 | loss: 0.22486 | train_rmsle: 0.01559 | train_mae: 0.42034 | train_rmse: 0.50945 | train_mse: 0.25954 | valid_rmsle: 0.01516 | valid_mae: 0.42215 | valid_rmse: 0.50765 | valid_mse: 0.25771 |  0:00:39s\n",
      "epoch 18 | loss: 0.23232 | train_rmsle: 0.01849 | train_mae: 0.47464 | train_rmse: 0.56125 | train_mse: 0.31501 | valid_rmsle: 0.01814 | valid_mae: 0.47615 | valid_rmse: 0.56058 | valid_mse: 0.31425 |  0:00:42s\n",
      "epoch 19 | loss: 0.22708 | train_rmsle: 0.01444 | train_mae: 0.39027 | train_rmse: 0.48382 | train_mse: 0.23409 | valid_rmsle: 0.01389 | valid_mae: 0.39155 | valid_rmse: 0.48025 | valid_mse: 0.23064 |  0:00:44s\n",
      "epoch 20 | loss: 0.22713 | train_rmsle: 0.01436 | train_mae: 0.37623 | train_rmse: 0.47716 | train_mse: 0.22768 | valid_rmsle: 0.01365 | valid_mae: 0.3745  | valid_rmse: 0.47003 | valid_mse: 0.22093 |  0:00:46s\n",
      "epoch 21 | loss: 0.22027 | train_rmsle: 0.01419 | train_mae: 0.37783 | train_rmse: 0.4762  | train_mse: 0.22676 | valid_rmsle: 0.01381 | valid_mae: 0.38342 | valid_rmse: 0.47526 | valid_mse: 0.22587 |  0:00:48s\n",
      "epoch 22 | loss: 0.22117 | train_rmsle: 0.01406 | train_mae: 0.37748 | train_rmse: 0.47429 | train_mse: 0.22495 | valid_rmsle: 0.01366 | valid_mae: 0.38223 | valid_rmse: 0.47309 | valid_mse: 0.22381 |  0:00:50s\n",
      "epoch 23 | loss: 0.22468 | train_rmsle: 0.0151  | train_mae: 0.41344 | train_rmse: 0.50105 | train_mse: 0.25105 | valid_rmsle: 0.0147  | valid_mae: 0.41509 | valid_rmse: 0.4994  | valid_mse: 0.2494  |  0:00:53s\n",
      "epoch 24 | loss: 0.22041 | train_rmsle: 0.0141  | train_mae: 0.39526 | train_rmse: 0.48177 | train_mse: 0.2321  | valid_rmsle: 0.01339 | valid_mae: 0.39319 | valid_rmse: 0.47457 | valid_mse: 0.22521 |  0:00:55s\n",
      "epoch 25 | loss: 0.20996 | train_rmsle: 0.0126  | train_mae: 0.3592  | train_rmse: 0.44942 | train_mse: 0.20198 | valid_rmsle: 0.01201 | valid_mae: 0.36037 | valid_rmse: 0.44355 | valid_mse: 0.19673 |  0:00:57s\n",
      "epoch 26 | loss: 0.20797 | train_rmsle: 0.01213 | train_mae: 0.35732 | train_rmse: 0.44323 | train_mse: 0.19645 | valid_rmsle: 0.01172 | valid_mae: 0.36145 | valid_rmse: 0.4398  | valid_mse: 0.19343 |  0:00:59s\n",
      "epoch 27 | loss: 0.18698 | train_rmsle: 0.01097 | train_mae: 0.34037 | train_rmse: 0.42189 | train_mse: 0.17799 | valid_rmsle: 0.01072 | valid_mae: 0.34508 | valid_rmse: 0.42164 | valid_mse: 0.17778 |  0:01:01s\n",
      "epoch 28 | loss: 0.17233 | train_rmsle: 0.0095  | train_mae: 0.31185 | train_rmse: 0.39013 | train_mse: 0.1522  | valid_rmsle: 0.00941 | valid_mae: 0.31922 | valid_rmse: 0.39316 | valid_mse: 0.15457 |  0:01:04s\n",
      "epoch 29 | loss: 0.15498 | train_rmsle: 0.00887 | train_mae: 0.29005 | train_rmse: 0.37115 | train_mse: 0.13775 | valid_rmsle: 0.0087  | valid_mae: 0.29742 | valid_rmse: 0.37251 | valid_mse: 0.13876 |  0:01:06s\n",
      "epoch 30 | loss: 0.14326 | train_rmsle: 0.00917 | train_mae: 0.31167 | train_rmse: 0.38438 | train_mse: 0.14775 | valid_rmsle: 0.00894 | valid_mae: 0.31658 | valid_rmse: 0.385   | valid_mse: 0.14823 |  0:01:08s\n",
      "epoch 31 | loss: 0.12799 | train_rmsle: 0.00898 | train_mae: 0.30763 | train_rmse: 0.37941 | train_mse: 0.14395 | valid_rmsle: 0.00864 | valid_mae: 0.30639 | valid_rmse: 0.37615 | valid_mse: 0.14149 |  0:01:10s\n",
      "epoch 32 | loss: 0.12269 | train_rmsle: 0.00828 | train_mae: 0.2744  | train_rmse: 0.35809 | train_mse: 0.12823 | valid_rmsle: 0.0081  | valid_mae: 0.27737 | valid_rmse: 0.3591  | valid_mse: 0.12895 |  0:01:12s\n",
      "epoch 33 | loss: 0.1191  | train_rmsle: 0.00733 | train_mae: 0.26686 | train_rmse: 0.33823 | train_mse: 0.1144  | valid_rmsle: 0.00678 | valid_mae: 0.26433 | valid_rmse: 0.33066 | valid_mse: 0.10934 |  0:01:14s\n",
      "epoch 34 | loss: 0.11742 | train_rmsle: 0.00712 | train_mae: 0.26019 | train_rmse: 0.33226 | train_mse: 0.1104  | valid_rmsle: 0.00663 | valid_mae: 0.25694 | valid_rmse: 0.3258  | valid_mse: 0.10614 |  0:01:16s\n",
      "epoch 35 | loss: 0.10836 | train_rmsle: 0.00701 | train_mae: 0.2542  | train_rmse: 0.32828 | train_mse: 0.10777 | valid_rmsle: 0.00668 | valid_mae: 0.25227 | valid_rmse: 0.32623 | valid_mse: 0.10643 |  0:01:18s\n",
      "epoch 36 | loss: 0.10235 | train_rmsle: 0.00658 | train_mae: 0.25007 | train_rmse: 0.31901 | train_mse: 0.10177 | valid_rmsle: 0.0063  | valid_mae: 0.24874 | valid_rmse: 0.31765 | valid_mse: 0.1009  |  0:01:19s\n",
      "epoch 37 | loss: 0.09279 | train_rmsle: 0.00612 | train_mae: 0.24108 | train_rmse: 0.30786 | train_mse: 0.09478 | valid_rmsle: 0.00594 | valid_mae: 0.24291 | valid_rmse: 0.30896 | valid_mse: 0.09545 |  0:01:22s\n",
      "epoch 38 | loss: 0.08841 | train_rmsle: 0.00534 | train_mae: 0.22364 | train_rmse: 0.28729 | train_mse: 0.08253 | valid_rmsle: 0.00534 | valid_mae: 0.2289  | valid_rmse: 0.29344 | valid_mse: 0.08611 |  0:01:24s\n",
      "epoch 39 | loss: 0.07817 | train_rmsle: 0.00507 | train_mae: 0.22235 | train_rmse: 0.28249 | train_mse: 0.0798  | valid_rmsle: 0.00501 | valid_mae: 0.22823 | valid_rmse: 0.28633 | valid_mse: 0.08199 |  0:01:26s\n",
      "epoch 40 | loss: 0.07358 | train_rmsle: 0.00444 | train_mae: 0.19867 | train_rmse: 0.26003 | train_mse: 0.06762 | valid_rmsle: 0.00448 | valid_mae: 0.20557 | valid_rmse: 0.26756 | valid_mse: 0.07159 |  0:01:28s\n",
      "epoch 41 | loss: 0.0679  | train_rmsle: 0.00403 | train_mae: 0.19206 | train_rmse: 0.24937 | train_mse: 0.06219 | valid_rmsle: 0.00419 | valid_mae: 0.20156 | valid_rmse: 0.25996 | valid_mse: 0.06758 |  0:01:30s\n",
      "epoch 42 | loss: 0.06227 | train_rmsle: 0.00448 | train_mae: 0.21332 | train_rmse: 0.26958 | train_mse: 0.07267 | valid_rmsle: 0.00476 | valid_mae: 0.22572 | valid_rmse: 0.28246 | valid_mse: 0.07978 |  0:01:33s\n",
      "epoch 43 | loss: 0.06843 | train_rmsle: 0.00408 | train_mae: 0.20425 | train_rmse: 0.25802 | train_mse: 0.06657 | valid_rmsle: 0.00438 | valid_mae: 0.21705 | valid_rmse: 0.2722  | valid_mse: 0.07409 |  0:01:35s\n",
      "epoch 44 | loss: 0.06216 | train_rmsle: 0.00375 | train_mae: 0.193   | train_rmse: 0.24547 | train_mse: 0.06025 | valid_rmsle: 0.00403 | valid_mae: 0.20285 | valid_rmse: 0.25892 | valid_mse: 0.06704 |  0:01:37s\n",
      "epoch 45 | loss: 0.05988 | train_rmsle: 0.00354 | train_mae: 0.18902 | train_rmse: 0.24008 | train_mse: 0.05764 | valid_rmsle: 0.00392 | valid_mae: 0.20155 | valid_rmse: 0.25687 | valid_mse: 0.06598 |  0:01:39s\n",
      "epoch 46 | loss: 0.05411 | train_rmsle: 0.00301 | train_mae: 0.16896 | train_rmse: 0.21803 | train_mse: 0.04754 | valid_rmsle: 0.00334 | valid_mae: 0.18108 | valid_rmse: 0.23494 | valid_mse: 0.0552  |  0:01:42s\n",
      "epoch 47 | loss: 0.05352 | train_rmsle: 0.00308 | train_mae: 0.17486 | train_rmse: 0.22349 | train_mse: 0.04995 | valid_rmsle: 0.0034  | valid_mae: 0.1864  | valid_rmse: 0.23904 | valid_mse: 0.05714 |  0:01:44s\n",
      "epoch 48 | loss: 0.05186 | train_rmsle: 0.00364 | train_mae: 0.19672 | train_rmse: 0.24702 | train_mse: 0.06102 | valid_rmsle: 0.00403 | valid_mae: 0.2091  | valid_rmse: 0.26217 | valid_mse: 0.06873 |  0:01:46s\n",
      "epoch 49 | loss: 0.04604 | train_rmsle: 0.00244 | train_mae: 0.1567  | train_rmse: 0.20081 | train_mse: 0.04032 | valid_rmsle: 0.00282 | valid_mae: 0.17222 | valid_rmse: 0.21962 | valid_mse: 0.04823 |  0:01:48s\n",
      "epoch 50 | loss: 0.04362 | train_rmsle: 0.00254 | train_mae: 0.16513 | train_rmse: 0.20861 | train_mse: 0.04352 | valid_rmsle: 0.00297 | valid_mae: 0.17842 | valid_rmse: 0.22794 | valid_mse: 0.05196 |  0:01:50s\n",
      "epoch 51 | loss: 0.0413  | train_rmsle: 0.00227 | train_mae: 0.15022 | train_rmse: 0.1935  | train_mse: 0.03744 | valid_rmsle: 0.0026  | valid_mae: 0.16391 | valid_rmse: 0.21173 | valid_mse: 0.04483 |  0:01:53s\n",
      "epoch 52 | loss: 0.04036 | train_rmsle: 0.0022  | train_mae: 0.14863 | train_rmse: 0.19201 | train_mse: 0.03687 | valid_rmsle: 0.00254 | valid_mae: 0.16379 | valid_rmse: 0.20998 | valid_mse: 0.04409 |  0:01:55s\n",
      "epoch 53 | loss: 0.05199 | train_rmsle: 0.00427 | train_mae: 0.20824 | train_rmse: 0.26684 | train_mse: 0.0712  | valid_rmsle: 0.00462 | valid_mae: 0.21804 | valid_rmse: 0.28067 | valid_mse: 0.07877 |  0:01:57s\n",
      "epoch 54 | loss: 0.04754 | train_rmsle: 0.00365 | train_mae: 0.18867 | train_rmse: 0.23778 | train_mse: 0.05654 | valid_rmsle: 0.00402 | valid_mae: 0.20017 | valid_rmse: 0.25293 | valid_mse: 0.06397 |  0:01:59s\n",
      "epoch 55 | loss: 0.04636 | train_rmsle: 0.00264 | train_mae: 0.16311 | train_rmse: 0.21052 | train_mse: 0.04432 | valid_rmsle: 0.00301 | valid_mae: 0.17366 | valid_rmse: 0.22676 | valid_mse: 0.05142 |  0:02:02s\n",
      "epoch 56 | loss: 0.04871 | train_rmsle: 0.00441 | train_mae: 0.22596 | train_rmse: 0.27326 | train_mse: 0.07467 | valid_rmsle: 0.00475 | valid_mae: 0.23371 | valid_rmse: 0.28547 | valid_mse: 0.08149 |  0:02:04s\n",
      "epoch 57 | loss: 0.04426 | train_rmsle: 0.00245 | train_mae: 0.15582 | train_rmse: 0.20345 | train_mse: 0.04139 | valid_rmsle: 0.0028  | valid_mae: 0.16595 | valid_rmse: 0.21913 | valid_mse: 0.04802 |  0:02:06s\n",
      "epoch 58 | loss: 0.04137 | train_rmsle: 0.00447 | train_mae: 0.20575 | train_rmse: 0.26542 | train_mse: 0.07045 | valid_rmsle: 0.00455 | valid_mae: 0.21599 | valid_rmse: 0.27419 | valid_mse: 0.07518 |  0:02:08s\n",
      "epoch 59 | loss: 0.03759 | train_rmsle: 0.00194 | train_mae: 0.14083 | train_rmse: 0.18345 | train_mse: 0.03366 | valid_rmsle: 0.0022  | valid_mae: 0.1549  | valid_rmse: 0.19764 | valid_mse: 0.03906 |  0:02:10s\n",
      "epoch 60 | loss: 0.03816 | train_rmsle: 0.00181 | train_mae: 0.1403  | train_rmse: 0.18088 | train_mse: 0.03272 | valid_rmsle: 0.00205 | valid_mae: 0.15032 | valid_rmse: 0.19286 | valid_mse: 0.03719 |  0:02:12s\n",
      "epoch 61 | loss: 0.03948 | train_rmsle: 0.00159 | train_mae: 0.1308  | train_rmse: 0.16884 | train_mse: 0.02851 | valid_rmsle: 0.00185 | valid_mae: 0.14091 | valid_rmse: 0.18299 | valid_mse: 0.03348 |  0:02:15s\n",
      "epoch 62 | loss: 0.0313  | train_rmsle: 0.0015  | train_mae: 0.1275  | train_rmse: 0.16406 | train_mse: 0.02692 | valid_rmsle: 0.00171 | valid_mae: 0.13696 | valid_rmse: 0.17511 | valid_mse: 0.03066 |  0:02:17s\n",
      "epoch 63 | loss: 0.03199 | train_rmsle: 0.00142 | train_mae: 0.12386 | train_rmse: 0.15863 | train_mse: 0.02516 | valid_rmsle: 0.0016  | valid_mae: 0.13189 | valid_rmse: 0.16891 | valid_mse: 0.02853 |  0:02:19s\n",
      "epoch 64 | loss: 0.03071 | train_rmsle: 0.00148 | train_mae: 0.12574 | train_rmse: 0.16059 | train_mse: 0.02579 | valid_rmsle: 0.0017  | valid_mae: 0.13689 | valid_rmse: 0.1735  | valid_mse: 0.0301  |  0:02:21s\n",
      "epoch 65 | loss: 0.03283 | train_rmsle: 0.0014  | train_mae: 0.12285 | train_rmse: 0.15862 | train_mse: 0.02516 | valid_rmsle: 0.00174 | valid_mae: 0.13547 | valid_rmse: 0.1764  | valid_mse: 0.03112 |  0:02:24s\n",
      "epoch 66 | loss: 0.03    | train_rmsle: 0.00173 | train_mae: 0.1379  | train_rmse: 0.17758 | train_mse: 0.03153 | valid_rmsle: 0.00208 | valid_mae: 0.14898 | valid_rmse: 0.19336 | valid_mse: 0.03739 |  0:02:26s\n",
      "epoch 67 | loss: 0.0297  | train_rmsle: 0.00283 | train_mae: 0.15929 | train_rmse: 0.20087 | train_mse: 0.04035 | valid_rmsle: 0.00289 | valid_mae: 0.16868 | valid_rmse: 0.2094  | valid_mse: 0.04385 |  0:02:28s\n",
      "epoch 68 | loss: 0.02984 | train_rmsle: 0.00229 | train_mae: 0.14921 | train_rmse: 0.1894  | train_mse: 0.03587 | valid_rmsle: 0.00251 | valid_mae: 0.16149 | valid_rmse: 0.20432 | valid_mse: 0.04175 |  0:02:30s\n",
      "epoch 69 | loss: 0.03489 | train_rmsle: 0.00152 | train_mae: 0.12897 | train_rmse: 0.16416 | train_mse: 0.02695 | valid_rmsle: 0.0018  | valid_mae: 0.14089 | valid_rmse: 0.17987 | valid_mse: 0.03235 |  0:02:33s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 63 and best_valid_mse = 0.02853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.030015762877159555 RMSE: 0.17325057828809565 R2: 0.8671317833737859 MAE: 0.1355415289258456\n",
      "=====================================\n",
      "[62/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.74497 | train_rmsle: 0.15935 | train_mae: 1.37644 | train_rmse: 1.45453 | train_mse: 2.11566 | valid_rmsle: 0.16017 | valid_mae: 1.38076 | valid_rmse: 1.4592  | valid_mse: 2.12927 |  0:00:02s\n",
      "epoch 1  | loss: 0.576   | train_rmsle: 0.08746 | train_mae: 1.05207 | train_rmse: 1.14039 | train_mse: 1.30048 | valid_rmsle: 0.08774 | valid_mae: 1.05444 | valid_rmse: 1.14365 | valid_mse: 1.30793 |  0:00:04s\n",
      "epoch 2  | loss: 0.38487 | train_rmsle: 0.06944 | train_mae: 0.94363 | train_rmse: 1.03505 | train_mse: 1.07133 | valid_rmsle: 0.06969 | valid_mae: 0.9459  | valid_rmse: 1.03852 | valid_mse: 1.07853 |  0:00:06s\n",
      "epoch 3  | loss: 0.3946  | train_rmsle: 0.03068 | train_mae: 0.62862 | train_rmse: 0.72062 | train_mse: 0.51929 | valid_rmsle: 0.03053 | valid_mae: 0.62849 | valid_rmse: 0.72202 | valid_mse: 0.52131 |  0:00:08s\n",
      "epoch 4  | loss: 0.37912 | train_rmsle: 0.02773 | train_mae: 0.5964  | train_rmse: 0.68715 | train_mse: 0.47218 | valid_rmsle: 0.02761 | valid_mae: 0.59771 | valid_rmse: 0.68898 | valid_mse: 0.4747  |  0:00:11s\n",
      "epoch 5  | loss: 0.31791 | train_rmsle: 0.03534 | train_mae: 0.67489 | train_rmse: 0.76865 | train_mse: 0.59083 | valid_rmsle: 0.03536 | valid_mae: 0.67692 | valid_rmse: 0.7715  | valid_mse: 0.5952  |  0:00:13s\n",
      "epoch 6  | loss: 0.2562  | train_rmsle: 0.03801 | train_mae: 0.6998  | train_rmse: 0.79457 | train_mse: 0.63134 | valid_rmsle: 0.03785 | valid_mae: 0.69709 | valid_rmse: 0.79578 | valid_mse: 0.63326 |  0:00:15s\n",
      "epoch 7  | loss: 0.27039 | train_rmsle: 0.02739 | train_mae: 0.59123 | train_rmse: 0.68304 | train_mse: 0.46654 | valid_rmsle: 0.02717 | valid_mae: 0.59101 | valid_rmse: 0.68382 | valid_mse: 0.4676  |  0:00:17s\n",
      "epoch 8  | loss: 0.29747 | train_rmsle: 0.03763 | train_mae: 0.69852 | train_rmse: 0.79126 | train_mse: 0.62609 | valid_rmsle: 0.03735 | valid_mae: 0.69628 | valid_rmse: 0.79122 | valid_mse: 0.62602 |  0:00:20s\n",
      "epoch 9  | loss: 0.28916 | train_rmsle: 0.02251 | train_mae: 0.53218 | train_rmse: 0.62103 | train_mse: 0.38568 | valid_rmsle: 0.02215 | valid_mae: 0.53194 | valid_rmse: 0.61996 | valid_mse: 0.38435 |  0:00:22s\n",
      "epoch 10 | loss: 0.24046 | train_rmsle: 0.01968 | train_mae: 0.49156 | train_rmse: 0.5799  | train_mse: 0.33628 | valid_rmsle: 0.0193  | valid_mae: 0.49197 | valid_rmse: 0.57866 | valid_mse: 0.33484 |  0:00:24s\n",
      "epoch 11 | loss: 0.23517 | train_rmsle: 0.01623 | train_mae: 0.43218 | train_rmse: 0.52096 | train_mse: 0.2714  | valid_rmsle: 0.01574 | valid_mae: 0.43261 | valid_rmse: 0.51799 | valid_mse: 0.26831 |  0:00:26s\n",
      "epoch 12 | loss: 0.2321  | train_rmsle: 0.01915 | train_mae: 0.4839  | train_rmse: 0.57165 | train_mse: 0.32679 | valid_rmsle: 0.0188  | valid_mae: 0.48522 | valid_rmse: 0.57097 | valid_mse: 0.32601 |  0:00:28s\n",
      "epoch 13 | loss: 0.22989 | train_rmsle: 0.01587 | train_mae: 0.42402 | train_rmse: 0.51398 | train_mse: 0.26418 | valid_rmsle: 0.01533 | valid_mae: 0.4247  | valid_rmse: 0.51027 | valid_mse: 0.26038 |  0:00:31s\n",
      "epoch 14 | loss: 0.23473 | train_rmsle: 0.01555 | train_mae: 0.41731 | train_rmse: 0.5077  | train_mse: 0.25776 | valid_rmsle: 0.01507 | valid_mae: 0.41798 | valid_rmse: 0.50514 | valid_mse: 0.25516 |  0:00:33s\n",
      "epoch 15 | loss: 0.23186 | train_rmsle: 0.01668 | train_mae: 0.44019 | train_rmse: 0.52937 | train_mse: 0.28023 | valid_rmsle: 0.01628 | valid_mae: 0.4414  | valid_rmse: 0.52821 | valid_mse: 0.279   |  0:00:35s\n",
      "epoch 16 | loss: 0.23225 | train_rmsle: 0.01547 | train_mae: 0.41659 | train_rmse: 0.50665 | train_mse: 0.25669 | valid_rmsle: 0.015   | valid_mae: 0.41797 | valid_rmse: 0.50403 | valid_mse: 0.25405 |  0:00:37s\n",
      "epoch 17 | loss: 0.22486 | train_rmsle: 0.01559 | train_mae: 0.42034 | train_rmse: 0.50945 | train_mse: 0.25954 | valid_rmsle: 0.01516 | valid_mae: 0.42215 | valid_rmse: 0.50765 | valid_mse: 0.25771 |  0:00:40s\n",
      "epoch 18 | loss: 0.23232 | train_rmsle: 0.01849 | train_mae: 0.47464 | train_rmse: 0.56125 | train_mse: 0.31501 | valid_rmsle: 0.01814 | valid_mae: 0.47615 | valid_rmse: 0.56058 | valid_mse: 0.31425 |  0:00:42s\n",
      "epoch 19 | loss: 0.22708 | train_rmsle: 0.01444 | train_mae: 0.39027 | train_rmse: 0.48382 | train_mse: 0.23409 | valid_rmsle: 0.01389 | valid_mae: 0.39155 | valid_rmse: 0.48025 | valid_mse: 0.23064 |  0:00:44s\n",
      "epoch 20 | loss: 0.22713 | train_rmsle: 0.01436 | train_mae: 0.37623 | train_rmse: 0.47716 | train_mse: 0.22768 | valid_rmsle: 0.01365 | valid_mae: 0.3745  | valid_rmse: 0.47003 | valid_mse: 0.22093 |  0:00:46s\n",
      "epoch 21 | loss: 0.22027 | train_rmsle: 0.01419 | train_mae: 0.37783 | train_rmse: 0.4762  | train_mse: 0.22676 | valid_rmsle: 0.01381 | valid_mae: 0.38342 | valid_rmse: 0.47526 | valid_mse: 0.22587 |  0:00:49s\n",
      "epoch 22 | loss: 0.22117 | train_rmsle: 0.01406 | train_mae: 0.37748 | train_rmse: 0.47429 | train_mse: 0.22495 | valid_rmsle: 0.01366 | valid_mae: 0.38223 | valid_rmse: 0.47309 | valid_mse: 0.22381 |  0:00:51s\n",
      "epoch 23 | loss: 0.22468 | train_rmsle: 0.0151  | train_mae: 0.41344 | train_rmse: 0.50105 | train_mse: 0.25105 | valid_rmsle: 0.0147  | valid_mae: 0.41509 | valid_rmse: 0.4994  | valid_mse: 0.2494  |  0:00:53s\n",
      "epoch 24 | loss: 0.22041 | train_rmsle: 0.0141  | train_mae: 0.39526 | train_rmse: 0.48177 | train_mse: 0.2321  | valid_rmsle: 0.01339 | valid_mae: 0.39319 | valid_rmse: 0.47457 | valid_mse: 0.22521 |  0:00:55s\n",
      "epoch 25 | loss: 0.20996 | train_rmsle: 0.0126  | train_mae: 0.3592  | train_rmse: 0.44942 | train_mse: 0.20198 | valid_rmsle: 0.01201 | valid_mae: 0.36037 | valid_rmse: 0.44355 | valid_mse: 0.19673 |  0:00:57s\n",
      "epoch 26 | loss: 0.20797 | train_rmsle: 0.01213 | train_mae: 0.35732 | train_rmse: 0.44323 | train_mse: 0.19645 | valid_rmsle: 0.01172 | valid_mae: 0.36145 | valid_rmse: 0.4398  | valid_mse: 0.19343 |  0:01:00s\n",
      "epoch 27 | loss: 0.18698 | train_rmsle: 0.01097 | train_mae: 0.34037 | train_rmse: 0.42189 | train_mse: 0.17799 | valid_rmsle: 0.01072 | valid_mae: 0.34508 | valid_rmse: 0.42164 | valid_mse: 0.17778 |  0:01:02s\n",
      "epoch 28 | loss: 0.17233 | train_rmsle: 0.0095  | train_mae: 0.31185 | train_rmse: 0.39013 | train_mse: 0.1522  | valid_rmsle: 0.00941 | valid_mae: 0.31922 | valid_rmse: 0.39316 | valid_mse: 0.15457 |  0:01:04s\n",
      "epoch 29 | loss: 0.15498 | train_rmsle: 0.00887 | train_mae: 0.29005 | train_rmse: 0.37115 | train_mse: 0.13775 | valid_rmsle: 0.0087  | valid_mae: 0.29742 | valid_rmse: 0.37251 | valid_mse: 0.13876 |  0:01:06s\n",
      "epoch 30 | loss: 0.14326 | train_rmsle: 0.00917 | train_mae: 0.31167 | train_rmse: 0.38438 | train_mse: 0.14775 | valid_rmsle: 0.00894 | valid_mae: 0.31658 | valid_rmse: 0.385   | valid_mse: 0.14823 |  0:01:08s\n",
      "epoch 31 | loss: 0.12799 | train_rmsle: 0.00898 | train_mae: 0.30763 | train_rmse: 0.37941 | train_mse: 0.14395 | valid_rmsle: 0.00864 | valid_mae: 0.30639 | valid_rmse: 0.37615 | valid_mse: 0.14149 |  0:01:11s\n",
      "epoch 32 | loss: 0.12269 | train_rmsle: 0.00828 | train_mae: 0.2744  | train_rmse: 0.35809 | train_mse: 0.12823 | valid_rmsle: 0.0081  | valid_mae: 0.27737 | valid_rmse: 0.3591  | valid_mse: 0.12895 |  0:01:13s\n",
      "epoch 33 | loss: 0.1191  | train_rmsle: 0.00733 | train_mae: 0.26686 | train_rmse: 0.33823 | train_mse: 0.1144  | valid_rmsle: 0.00678 | valid_mae: 0.26433 | valid_rmse: 0.33066 | valid_mse: 0.10934 |  0:01:15s\n",
      "epoch 34 | loss: 0.11742 | train_rmsle: 0.00712 | train_mae: 0.26019 | train_rmse: 0.33226 | train_mse: 0.1104  | valid_rmsle: 0.00663 | valid_mae: 0.25694 | valid_rmse: 0.3258  | valid_mse: 0.10614 |  0:01:17s\n",
      "epoch 35 | loss: 0.10836 | train_rmsle: 0.00701 | train_mae: 0.2542  | train_rmse: 0.32828 | train_mse: 0.10777 | valid_rmsle: 0.00668 | valid_mae: 0.25227 | valid_rmse: 0.32623 | valid_mse: 0.10643 |  0:01:19s\n",
      "epoch 36 | loss: 0.10235 | train_rmsle: 0.00658 | train_mae: 0.25007 | train_rmse: 0.31901 | train_mse: 0.10177 | valid_rmsle: 0.0063  | valid_mae: 0.24874 | valid_rmse: 0.31765 | valid_mse: 0.1009  |  0:01:21s\n",
      "epoch 37 | loss: 0.09279 | train_rmsle: 0.00612 | train_mae: 0.24108 | train_rmse: 0.30786 | train_mse: 0.09478 | valid_rmsle: 0.00594 | valid_mae: 0.24291 | valid_rmse: 0.30896 | valid_mse: 0.09545 |  0:01:22s\n",
      "epoch 38 | loss: 0.08841 | train_rmsle: 0.00534 | train_mae: 0.22364 | train_rmse: 0.28729 | train_mse: 0.08253 | valid_rmsle: 0.00534 | valid_mae: 0.2289  | valid_rmse: 0.29344 | valid_mse: 0.08611 |  0:01:24s\n",
      "epoch 39 | loss: 0.07817 | train_rmsle: 0.00507 | train_mae: 0.22235 | train_rmse: 0.28249 | train_mse: 0.0798  | valid_rmsle: 0.00501 | valid_mae: 0.22823 | valid_rmse: 0.28633 | valid_mse: 0.08199 |  0:01:27s\n",
      "epoch 40 | loss: 0.07358 | train_rmsle: 0.00444 | train_mae: 0.19867 | train_rmse: 0.26003 | train_mse: 0.06762 | valid_rmsle: 0.00448 | valid_mae: 0.20557 | valid_rmse: 0.26756 | valid_mse: 0.07159 |  0:01:29s\n",
      "epoch 41 | loss: 0.0679  | train_rmsle: 0.00403 | train_mae: 0.19206 | train_rmse: 0.24937 | train_mse: 0.06219 | valid_rmsle: 0.00419 | valid_mae: 0.20156 | valid_rmse: 0.25996 | valid_mse: 0.06758 |  0:01:31s\n",
      "epoch 42 | loss: 0.06227 | train_rmsle: 0.00448 | train_mae: 0.21332 | train_rmse: 0.26958 | train_mse: 0.07267 | valid_rmsle: 0.00476 | valid_mae: 0.22572 | valid_rmse: 0.28246 | valid_mse: 0.07978 |  0:01:33s\n",
      "epoch 43 | loss: 0.06843 | train_rmsle: 0.00408 | train_mae: 0.20425 | train_rmse: 0.25802 | train_mse: 0.06657 | valid_rmsle: 0.00438 | valid_mae: 0.21705 | valid_rmse: 0.2722  | valid_mse: 0.07409 |  0:01:35s\n",
      "epoch 44 | loss: 0.06216 | train_rmsle: 0.00375 | train_mae: 0.193   | train_rmse: 0.24547 | train_mse: 0.06025 | valid_rmsle: 0.00403 | valid_mae: 0.20285 | valid_rmse: 0.25892 | valid_mse: 0.06704 |  0:01:38s\n",
      "epoch 45 | loss: 0.05988 | train_rmsle: 0.00354 | train_mae: 0.18902 | train_rmse: 0.24008 | train_mse: 0.05764 | valid_rmsle: 0.00392 | valid_mae: 0.20155 | valid_rmse: 0.25687 | valid_mse: 0.06598 |  0:01:40s\n",
      "epoch 46 | loss: 0.05411 | train_rmsle: 0.00301 | train_mae: 0.16896 | train_rmse: 0.21803 | train_mse: 0.04754 | valid_rmsle: 0.00334 | valid_mae: 0.18108 | valid_rmse: 0.23494 | valid_mse: 0.0552  |  0:01:42s\n",
      "epoch 47 | loss: 0.05352 | train_rmsle: 0.00308 | train_mae: 0.17486 | train_rmse: 0.22349 | train_mse: 0.04995 | valid_rmsle: 0.0034  | valid_mae: 0.1864  | valid_rmse: 0.23904 | valid_mse: 0.05714 |  0:01:44s\n",
      "epoch 48 | loss: 0.05186 | train_rmsle: 0.00364 | train_mae: 0.19672 | train_rmse: 0.24702 | train_mse: 0.06102 | valid_rmsle: 0.00403 | valid_mae: 0.2091  | valid_rmse: 0.26217 | valid_mse: 0.06873 |  0:01:47s\n",
      "epoch 49 | loss: 0.04604 | train_rmsle: 0.00244 | train_mae: 0.1567  | train_rmse: 0.20081 | train_mse: 0.04032 | valid_rmsle: 0.00282 | valid_mae: 0.17222 | valid_rmse: 0.21962 | valid_mse: 0.04823 |  0:01:49s\n",
      "epoch 50 | loss: 0.04362 | train_rmsle: 0.00254 | train_mae: 0.16513 | train_rmse: 0.20861 | train_mse: 0.04352 | valid_rmsle: 0.00297 | valid_mae: 0.17842 | valid_rmse: 0.22794 | valid_mse: 0.05196 |  0:01:51s\n",
      "epoch 51 | loss: 0.0413  | train_rmsle: 0.00227 | train_mae: 0.15022 | train_rmse: 0.1935  | train_mse: 0.03744 | valid_rmsle: 0.0026  | valid_mae: 0.16391 | valid_rmse: 0.21173 | valid_mse: 0.04483 |  0:01:53s\n",
      "epoch 52 | loss: 0.04036 | train_rmsle: 0.0022  | train_mae: 0.14863 | train_rmse: 0.19201 | train_mse: 0.03687 | valid_rmsle: 0.00254 | valid_mae: 0.16379 | valid_rmse: 0.20998 | valid_mse: 0.04409 |  0:01:55s\n",
      "epoch 53 | loss: 0.05199 | train_rmsle: 0.00427 | train_mae: 0.20824 | train_rmse: 0.26684 | train_mse: 0.0712  | valid_rmsle: 0.00462 | valid_mae: 0.21804 | valid_rmse: 0.28067 | valid_mse: 0.07877 |  0:01:58s\n",
      "epoch 54 | loss: 0.04754 | train_rmsle: 0.00365 | train_mae: 0.18867 | train_rmse: 0.23778 | train_mse: 0.05654 | valid_rmsle: 0.00402 | valid_mae: 0.20017 | valid_rmse: 0.25293 | valid_mse: 0.06397 |  0:02:00s\n",
      "epoch 55 | loss: 0.04636 | train_rmsle: 0.00264 | train_mae: 0.16311 | train_rmse: 0.21052 | train_mse: 0.04432 | valid_rmsle: 0.00301 | valid_mae: 0.17366 | valid_rmse: 0.22676 | valid_mse: 0.05142 |  0:02:02s\n",
      "epoch 56 | loss: 0.04871 | train_rmsle: 0.00441 | train_mae: 0.22596 | train_rmse: 0.27326 | train_mse: 0.07467 | valid_rmsle: 0.00475 | valid_mae: 0.23371 | valid_rmse: 0.28547 | valid_mse: 0.08149 |  0:02:04s\n",
      "epoch 57 | loss: 0.04426 | train_rmsle: 0.00245 | train_mae: 0.15582 | train_rmse: 0.20345 | train_mse: 0.04139 | valid_rmsle: 0.0028  | valid_mae: 0.16595 | valid_rmse: 0.21913 | valid_mse: 0.04802 |  0:02:06s\n",
      "epoch 58 | loss: 0.04137 | train_rmsle: 0.00447 | train_mae: 0.20575 | train_rmse: 0.26542 | train_mse: 0.07045 | valid_rmsle: 0.00455 | valid_mae: 0.21599 | valid_rmse: 0.27419 | valid_mse: 0.07518 |  0:02:09s\n",
      "epoch 59 | loss: 0.03759 | train_rmsle: 0.00194 | train_mae: 0.14083 | train_rmse: 0.18345 | train_mse: 0.03366 | valid_rmsle: 0.0022  | valid_mae: 0.1549  | valid_rmse: 0.19764 | valid_mse: 0.03906 |  0:02:11s\n",
      "epoch 60 | loss: 0.03816 | train_rmsle: 0.00181 | train_mae: 0.1403  | train_rmse: 0.18088 | train_mse: 0.03272 | valid_rmsle: 0.00205 | valid_mae: 0.15032 | valid_rmse: 0.19286 | valid_mse: 0.03719 |  0:02:13s\n",
      "epoch 61 | loss: 0.03948 | train_rmsle: 0.00159 | train_mae: 0.1308  | train_rmse: 0.16884 | train_mse: 0.02851 | valid_rmsle: 0.00185 | valid_mae: 0.14091 | valid_rmse: 0.18299 | valid_mse: 0.03348 |  0:02:15s\n",
      "epoch 62 | loss: 0.0313  | train_rmsle: 0.0015  | train_mae: 0.1275  | train_rmse: 0.16406 | train_mse: 0.02692 | valid_rmsle: 0.00171 | valid_mae: 0.13696 | valid_rmse: 0.17511 | valid_mse: 0.03066 |  0:02:17s\n",
      "epoch 63 | loss: 0.03199 | train_rmsle: 0.00142 | train_mae: 0.12386 | train_rmse: 0.15863 | train_mse: 0.02516 | valid_rmsle: 0.0016  | valid_mae: 0.13189 | valid_rmse: 0.16891 | valid_mse: 0.02853 |  0:02:20s\n",
      "epoch 64 | loss: 0.03071 | train_rmsle: 0.00148 | train_mae: 0.12574 | train_rmse: 0.16059 | train_mse: 0.02579 | valid_rmsle: 0.0017  | valid_mae: 0.13689 | valid_rmse: 0.1735  | valid_mse: 0.0301  |  0:02:22s\n",
      "epoch 65 | loss: 0.03283 | train_rmsle: 0.0014  | train_mae: 0.12285 | train_rmse: 0.15862 | train_mse: 0.02516 | valid_rmsle: 0.00174 | valid_mae: 0.13547 | valid_rmse: 0.1764  | valid_mse: 0.03112 |  0:02:24s\n",
      "epoch 66 | loss: 0.03    | train_rmsle: 0.00173 | train_mae: 0.1379  | train_rmse: 0.17758 | train_mse: 0.03153 | valid_rmsle: 0.00208 | valid_mae: 0.14898 | valid_rmse: 0.19336 | valid_mse: 0.03739 |  0:02:26s\n",
      "epoch 67 | loss: 0.0297  | train_rmsle: 0.00283 | train_mae: 0.15929 | train_rmse: 0.20087 | train_mse: 0.04035 | valid_rmsle: 0.00289 | valid_mae: 0.16868 | valid_rmse: 0.2094  | valid_mse: 0.04385 |  0:02:28s\n",
      "epoch 68 | loss: 0.02984 | train_rmsle: 0.00229 | train_mae: 0.14921 | train_rmse: 0.1894  | train_mse: 0.03587 | valid_rmsle: 0.00251 | valid_mae: 0.16149 | valid_rmse: 0.20432 | valid_mse: 0.04175 |  0:02:31s\n",
      "epoch 69 | loss: 0.03489 | train_rmsle: 0.00152 | train_mae: 0.12897 | train_rmse: 0.16416 | train_mse: 0.02695 | valid_rmsle: 0.0018  | valid_mae: 0.14089 | valid_rmse: 0.17987 | valid_mse: 0.03235 |  0:02:33s\n",
      "epoch 70 | loss: 0.03332 | train_rmsle: 0.00316 | train_mae: 0.17572 | train_rmse: 0.21587 | train_mse: 0.0466  | valid_rmsle: 0.0033  | valid_mae: 0.18383 | valid_rmse: 0.22429 | valid_mse: 0.05031 |  0:02:35s\n",
      "epoch 71 | loss: 0.03416 | train_rmsle: 0.00221 | train_mae: 0.15482 | train_rmse: 0.19662 | train_mse: 0.03866 | valid_rmsle: 0.00237 | valid_mae: 0.15938 | valid_rmse: 0.20573 | valid_mse: 0.04233 |  0:02:37s\n",
      "epoch 72 | loss: 0.03346 | train_rmsle: 0.00232 | train_mae: 0.16063 | train_rmse: 0.19955 | train_mse: 0.03982 | valid_rmsle: 0.00256 | valid_mae: 0.17128 | valid_rmse: 0.2118  | valid_mse: 0.04486 |  0:02:39s\n",
      "epoch 73 | loss: 0.03217 | train_rmsle: 0.00143 | train_mae: 0.12531 | train_rmse: 0.15899 | train_mse: 0.02528 | valid_rmsle: 0.00173 | valid_mae: 0.13688 | valid_rmse: 0.17592 | valid_mse: 0.03095 |  0:02:42s\n",
      "epoch 74 | loss: 0.02738 | train_rmsle: 0.00124 | train_mae: 0.1175  | train_rmse: 0.14946 | train_mse: 0.02234 | valid_rmsle: 0.00157 | valid_mae: 0.13144 | valid_rmse: 0.1682  | valid_mse: 0.02829 |  0:02:44s\n",
      "epoch 75 | loss: 0.02598 | train_rmsle: 0.00123 | train_mae: 0.11789 | train_rmse: 0.14936 | train_mse: 0.02231 | valid_rmsle: 0.00158 | valid_mae: 0.13316 | valid_rmse: 0.16907 | valid_mse: 0.02858 |  0:02:46s\n",
      "epoch 76 | loss: 0.02635 | train_rmsle: 0.00252 | train_mae: 0.17141 | train_rmse: 0.20473 | train_mse: 0.04192 | valid_rmsle: 0.00285 | valid_mae: 0.18361 | valid_rmse: 0.21914 | valid_mse: 0.04802 |  0:02:48s\n",
      "epoch 77 | loss: 0.02741 | train_rmsle: 0.0013  | train_mae: 0.12067 | train_rmse: 0.15112 | train_mse: 0.02284 | valid_rmsle: 0.00163 | valid_mae: 0.13451 | valid_rmse: 0.16911 | valid_mse: 0.0286  |  0:02:50s\n",
      "epoch 78 | loss: 0.02335 | train_rmsle: 0.00237 | train_mae: 0.13484 | train_rmse: 0.17873 | train_mse: 0.03194 | valid_rmsle: 0.00278 | valid_mae: 0.1436  | valid_rmse: 0.19541 | valid_mse: 0.03819 |  0:02:53s\n",
      "epoch 79 | loss: 0.02825 | train_rmsle: 0.00108 | train_mae: 0.10611 | train_rmse: 0.13526 | train_mse: 0.0183  | valid_rmsle: 0.00133 | valid_mae: 0.11892 | valid_rmse: 0.15182 | valid_mse: 0.02305 |  0:02:55s\n",
      "epoch 80 | loss: 0.02202 | train_rmsle: 0.00114 | train_mae: 0.10855 | train_rmse: 0.13776 | train_mse: 0.01898 | valid_rmsle: 0.00131 | valid_mae: 0.11719 | valid_rmse: 0.14966 | valid_mse: 0.0224  |  0:02:57s\n",
      "epoch 81 | loss: 0.02289 | train_rmsle: 0.00094 | train_mae: 0.10172 | train_rmse: 0.12917 | train_mse: 0.01668 | valid_rmsle: 0.00117 | valid_mae: 0.11457 | valid_rmse: 0.1447  | valid_mse: 0.02094 |  0:02:59s\n",
      "epoch 82 | loss: 0.02165 | train_rmsle: 0.00104 | train_mae: 0.10317 | train_rmse: 0.13101 | train_mse: 0.01716 | valid_rmsle: 0.00125 | valid_mae: 0.1127  | valid_rmse: 0.14489 | valid_mse: 0.02099 |  0:03:01s\n",
      "epoch 83 | loss: 0.02065 | train_rmsle: 0.00121 | train_mae: 0.11631 | train_rmse: 0.14469 | train_mse: 0.02093 | valid_rmsle: 0.00149 | valid_mae: 0.13038 | valid_rmse: 0.16063 | valid_mse: 0.0258  |  0:03:04s\n",
      "epoch 84 | loss: 0.0187  | train_rmsle: 0.00109 | train_mae: 0.10585 | train_rmse: 0.13258 | train_mse: 0.01758 | valid_rmsle: 0.00135 | valid_mae: 0.11772 | valid_rmse: 0.1483  | valid_mse: 0.02199 |  0:03:06s\n",
      "epoch 85 | loss: 0.01815 | train_rmsle: 0.00177 | train_mae: 0.13777 | train_rmse: 0.1696  | train_mse: 0.02876 | valid_rmsle: 0.00206 | valid_mae: 0.14943 | valid_rmse: 0.18442 | valid_mse: 0.03401 |  0:03:08s\n",
      "epoch 86 | loss: 0.02097 | train_rmsle: 0.00228 | train_mae: 0.14293 | train_rmse: 0.18    | train_mse: 0.0324  | valid_rmsle: 0.00263 | valid_mae: 0.1545  | valid_rmse: 0.19506 | valid_mse: 0.03805 |  0:03:10s\n",
      "epoch 87 | loss: 0.02083 | train_rmsle: 0.00367 | train_mae: 0.17324 | train_rmse: 0.21896 | train_mse: 0.04794 | valid_rmsle: 0.00408 | valid_mae: 0.18541 | valid_rmse: 0.23301 | valid_mse: 0.0543  |  0:03:13s\n",
      "epoch 88 | loss: 0.02033 | train_rmsle: 0.00104 | train_mae: 0.1078  | train_rmse: 0.13797 | train_mse: 0.01904 | valid_rmsle: 0.00127 | valid_mae: 0.11675 | valid_rmse: 0.15279 | valid_mse: 0.02334 |  0:03:15s\n",
      "epoch 89 | loss: 0.02855 | train_rmsle: 0.00146 | train_mae: 0.11939 | train_rmse: 0.14945 | train_mse: 0.02233 | valid_rmsle: 0.00168 | valid_mae: 0.12938 | valid_rmse: 0.1613  | valid_mse: 0.02602 |  0:03:17s\n",
      "epoch 90 | loss: 0.02375 | train_rmsle: 0.00157 | train_mae: 0.13569 | train_rmse: 0.16349 | train_mse: 0.02673 | valid_rmsle: 0.00178 | valid_mae: 0.14475 | valid_rmse: 0.17402 | valid_mse: 0.03028 |  0:03:19s\n",
      "epoch 91 | loss: 0.02017 | train_rmsle: 0.00094 | train_mae: 0.1027  | train_rmse: 0.12822 | train_mse: 0.01644 | valid_rmsle: 0.00112 | valid_mae: 0.11322 | valid_rmse: 0.14019 | valid_mse: 0.01965 |  0:03:21s\n",
      "epoch 92 | loss: 0.01828 | train_rmsle: 0.00066 | train_mae: 0.08479 | train_rmse: 0.10881 | train_mse: 0.01184 | valid_rmsle: 0.00084 | valid_mae: 0.09434 | valid_rmse: 0.12248 | valid_mse: 0.015   |  0:03:24s\n",
      "epoch 93 | loss: 0.02062 | train_rmsle: 0.0016  | train_mae: 0.14328 | train_rmse: 0.17344 | train_mse: 0.03008 | valid_rmsle: 0.00173 | valid_mae: 0.14918 | valid_rmse: 0.18038 | valid_mse: 0.03254 |  0:03:26s\n",
      "epoch 94 | loss: 0.02869 | train_rmsle: 0.00089 | train_mae: 0.10173 | train_rmse: 0.12821 | train_mse: 0.01644 | valid_rmsle: 0.00104 | valid_mae: 0.11079 | valid_rmse: 0.13855 | valid_mse: 0.0192  |  0:03:28s\n",
      "epoch 95 | loss: 0.01927 | train_rmsle: 0.00069 | train_mae: 0.08609 | train_rmse: 0.11007 | train_mse: 0.01212 | valid_rmsle: 0.00085 | valid_mae: 0.09699 | valid_rmse: 0.12271 | valid_mse: 0.01506 |  0:03:30s\n",
      "epoch 96 | loss: 0.01803 | train_rmsle: 0.00065 | train_mae: 0.0844  | train_rmse: 0.10772 | train_mse: 0.0116  | valid_rmsle: 0.00084 | valid_mae: 0.09541 | valid_rmse: 0.12182 | valid_mse: 0.01484 |  0:03:32s\n",
      "epoch 97 | loss: 0.01619 | train_rmsle: 0.00058 | train_mae: 0.0803  | train_rmse: 0.10269 | train_mse: 0.01055 | valid_rmsle: 0.00076 | valid_mae: 0.09058 | valid_rmse: 0.11687 | valid_mse: 0.01366 |  0:03:35s\n",
      "epoch 98 | loss: 0.01533 | train_rmsle: 0.00076 | train_mae: 0.09429 | train_rmse: 0.11936 | train_mse: 0.01425 | valid_rmsle: 0.00091 | valid_mae: 0.10292 | valid_rmse: 0.12994 | valid_mse: 0.01688 |  0:03:37s\n",
      "epoch 99 | loss: 0.01509 | train_rmsle: 0.0006  | train_mae: 0.07958 | train_rmse: 0.10176 | train_mse: 0.01035 | valid_rmsle: 0.00075 | valid_mae: 0.08873 | valid_rmse: 0.11431 | valid_mse: 0.01307 |  0:03:39s\n",
      "epoch 100| loss: 0.01629 | train_rmsle: 0.00053 | train_mae: 0.07643 | train_rmse: 0.09767 | train_mse: 0.00954 | valid_rmsle: 0.00071 | valid_mae: 0.08623 | valid_rmse: 0.11191 | valid_mse: 0.01252 |  0:03:41s\n",
      "epoch 101| loss: 0.01542 | train_rmsle: 0.00131 | train_mae: 0.12513 | train_rmse: 0.1488  | train_mse: 0.02214 | valid_rmsle: 0.00146 | valid_mae: 0.13173 | valid_rmse: 0.15758 | valid_mse: 0.02483 |  0:03:43s\n",
      "epoch 102| loss: 0.02027 | train_rmsle: 0.00821 | train_mae: 0.21014 | train_rmse: 0.29893 | train_mse: 0.08936 | valid_rmsle: 0.00802 | valid_mae: 0.21358 | valid_rmse: 0.29844 | valid_mse: 0.08907 |  0:03:45s\n",
      "epoch 103| loss: 0.02318 | train_rmsle: 0.00176 | train_mae: 0.12678 | train_rmse: 0.1616  | train_mse: 0.02611 | valid_rmsle: 0.00197 | valid_mae: 0.13363 | valid_rmse: 0.17248 | valid_mse: 0.02975 |  0:03:48s\n",
      "epoch 104| loss: 0.0208  | train_rmsle: 0.001   | train_mae: 0.09691 | train_rmse: 0.12533 | train_mse: 0.01571 | valid_rmsle: 0.00122 | valid_mae: 0.10719 | valid_rmse: 0.13873 | valid_mse: 0.01925 |  0:03:50s\n",
      "epoch 105| loss: 0.02047 | train_rmsle: 0.00101 | train_mae: 0.10918 | train_rmse: 0.13727 | train_mse: 0.01884 | valid_rmsle: 0.00118 | valid_mae: 0.11774 | valid_rmse: 0.1475  | valid_mse: 0.02176 |  0:03:52s\n",
      "epoch 106| loss: 0.01738 | train_rmsle: 0.00073 | train_mae: 0.08885 | train_rmse: 0.11415 | train_mse: 0.01303 | valid_rmsle: 0.00091 | valid_mae: 0.10004 | valid_rmse: 0.12733 | valid_mse: 0.01621 |  0:03:54s\n",
      "epoch 107| loss: 0.01637 | train_rmsle: 0.00103 | train_mae: 0.09772 | train_rmse: 0.12475 | train_mse: 0.01556 | valid_rmsle: 0.0012  | valid_mae: 0.10804 | valid_rmse: 0.1371  | valid_mse: 0.0188  |  0:03:56s\n",
      "epoch 108| loss: 0.01594 | train_rmsle: 0.00075 | train_mae: 0.08869 | train_rmse: 0.1131  | train_mse: 0.01279 | valid_rmsle: 0.00092 | valid_mae: 0.09994 | valid_rmse: 0.12599 | valid_mse: 0.01587 |  0:03:59s\n",
      "epoch 109| loss: 0.01994 | train_rmsle: 0.00169 | train_mae: 0.14124 | train_rmse: 0.16625 | train_mse: 0.02764 | valid_rmsle: 0.00189 | valid_mae: 0.14813 | valid_rmse: 0.178   | valid_mse: 0.03168 |  0:04:01s\n",
      "epoch 110| loss: 0.02002 | train_rmsle: 0.00067 | train_mae: 0.08403 | train_rmse: 0.10693 | train_mse: 0.01143 | valid_rmsle: 0.00086 | valid_mae: 0.09512 | valid_rmse: 0.12173 | valid_mse: 0.01482 |  0:04:03s\n",
      "epoch 111| loss: 0.01545 | train_rmsle: 0.0005  | train_mae: 0.0718  | train_rmse: 0.09285 | train_mse: 0.00862 | valid_rmsle: 0.00066 | valid_mae: 0.08334 | valid_rmse: 0.10705 | valid_mse: 0.01146 |  0:04:05s\n",
      "epoch 112| loss: 0.01407 | train_rmsle: 0.00053 | train_mae: 0.07641 | train_rmse: 0.09844 | train_mse: 0.00969 | valid_rmsle: 0.00072 | valid_mae: 0.08743 | valid_rmse: 0.11367 | valid_mse: 0.01292 |  0:04:07s\n",
      "epoch 113| loss: 0.0163  | train_rmsle: 0.00058 | train_mae: 0.08058 | train_rmse: 0.10192 | train_mse: 0.01039 | valid_rmsle: 0.00071 | valid_mae: 0.08967 | valid_rmse: 0.11202 | valid_mse: 0.01255 |  0:04:09s\n",
      "epoch 114| loss: 0.01337 | train_rmsle: 0.00069 | train_mae: 0.0895  | train_rmse: 0.11143 | train_mse: 0.01242 | valid_rmsle: 0.00081 | valid_mae: 0.09649 | valid_rmse: 0.12075 | valid_mse: 0.01458 |  0:04:11s\n",
      "epoch 115| loss: 0.01374 | train_rmsle: 0.00047 | train_mae: 0.07092 | train_rmse: 0.09048 | train_mse: 0.00819 | valid_rmsle: 0.0006  | valid_mae: 0.07942 | valid_rmse: 0.10154 | valid_mse: 0.01031 |  0:04:13s\n",
      "epoch 116| loss: 0.0149  | train_rmsle: 0.00081 | train_mae: 0.09182 | train_rmse: 0.11439 | train_mse: 0.01308 | valid_rmsle: 0.00091 | valid_mae: 0.09815 | valid_rmse: 0.12246 | valid_mse: 0.015   |  0:04:15s\n",
      "epoch 117| loss: 0.01306 | train_rmsle: 0.00094 | train_mae: 0.10882 | train_rmse: 0.13265 | train_mse: 0.0176  | valid_rmsle: 0.00106 | valid_mae: 0.11584 | valid_rmse: 0.14081 | valid_mse: 0.01983 |  0:04:17s\n",
      "epoch 118| loss: 0.01476 | train_rmsle: 0.00069 | train_mae: 0.09002 | train_rmse: 0.11358 | train_mse: 0.0129  | valid_rmsle: 0.00082 | valid_mae: 0.09883 | valid_rmse: 0.12319 | valid_mse: 0.01517 |  0:04:19s\n",
      "epoch 119| loss: 0.01833 | train_rmsle: 0.00313 | train_mae: 0.16259 | train_rmse: 0.21749 | train_mse: 0.0473  | valid_rmsle: 0.00304 | valid_mae: 0.16204 | valid_rmse: 0.21625 | valid_mse: 0.04676 |  0:04:21s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 115 and best_valid_mse = 0.01031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0107312294857083 RMSE: 0.1035916477603687 R2: 0.9524969820088199 MAE: 0.08327417851273673\n",
      "=====================================\n",
      "[63/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.74497 | train_rmsle: 0.15935 | train_mae: 1.37644 | train_rmse: 1.45453 | train_mse: 2.11566 | valid_rmsle: 0.16017 | valid_mae: 1.38076 | valid_rmse: 1.4592  | valid_mse: 2.12927 |  0:00:02s\n",
      "epoch 1  | loss: 0.576   | train_rmsle: 0.08746 | train_mae: 1.05207 | train_rmse: 1.14039 | train_mse: 1.30048 | valid_rmsle: 0.08774 | valid_mae: 1.05444 | valid_rmse: 1.14365 | valid_mse: 1.30793 |  0:00:04s\n",
      "epoch 2  | loss: 0.38487 | train_rmsle: 0.06944 | train_mae: 0.94363 | train_rmse: 1.03505 | train_mse: 1.07133 | valid_rmsle: 0.06969 | valid_mae: 0.9459  | valid_rmse: 1.03852 | valid_mse: 1.07853 |  0:00:06s\n",
      "epoch 3  | loss: 0.3946  | train_rmsle: 0.03068 | train_mae: 0.62862 | train_rmse: 0.72062 | train_mse: 0.51929 | valid_rmsle: 0.03053 | valid_mae: 0.62849 | valid_rmse: 0.72202 | valid_mse: 0.52131 |  0:00:08s\n",
      "epoch 4  | loss: 0.37912 | train_rmsle: 0.02773 | train_mae: 0.5964  | train_rmse: 0.68715 | train_mse: 0.47218 | valid_rmsle: 0.02761 | valid_mae: 0.59771 | valid_rmse: 0.68898 | valid_mse: 0.4747  |  0:00:11s\n",
      "epoch 5  | loss: 0.31791 | train_rmsle: 0.03534 | train_mae: 0.67489 | train_rmse: 0.76865 | train_mse: 0.59083 | valid_rmsle: 0.03536 | valid_mae: 0.67692 | valid_rmse: 0.7715  | valid_mse: 0.5952  |  0:00:13s\n",
      "epoch 6  | loss: 0.2562  | train_rmsle: 0.03801 | train_mae: 0.6998  | train_rmse: 0.79457 | train_mse: 0.63134 | valid_rmsle: 0.03785 | valid_mae: 0.69709 | valid_rmse: 0.79578 | valid_mse: 0.63326 |  0:00:15s\n",
      "epoch 7  | loss: 0.27039 | train_rmsle: 0.02739 | train_mae: 0.59123 | train_rmse: 0.68304 | train_mse: 0.46654 | valid_rmsle: 0.02717 | valid_mae: 0.59101 | valid_rmse: 0.68382 | valid_mse: 0.4676  |  0:00:17s\n",
      "epoch 8  | loss: 0.29747 | train_rmsle: 0.03763 | train_mae: 0.69852 | train_rmse: 0.79126 | train_mse: 0.62609 | valid_rmsle: 0.03735 | valid_mae: 0.69628 | valid_rmse: 0.79122 | valid_mse: 0.62602 |  0:00:19s\n",
      "epoch 9  | loss: 0.28916 | train_rmsle: 0.02251 | train_mae: 0.53218 | train_rmse: 0.62103 | train_mse: 0.38568 | valid_rmsle: 0.02215 | valid_mae: 0.53194 | valid_rmse: 0.61996 | valid_mse: 0.38435 |  0:00:21s\n",
      "epoch 10 | loss: 0.24046 | train_rmsle: 0.01968 | train_mae: 0.49156 | train_rmse: 0.5799  | train_mse: 0.33628 | valid_rmsle: 0.0193  | valid_mae: 0.49197 | valid_rmse: 0.57866 | valid_mse: 0.33484 |  0:00:24s\n",
      "epoch 11 | loss: 0.23517 | train_rmsle: 0.01623 | train_mae: 0.43218 | train_rmse: 0.52096 | train_mse: 0.2714  | valid_rmsle: 0.01574 | valid_mae: 0.43261 | valid_rmse: 0.51799 | valid_mse: 0.26831 |  0:00:26s\n",
      "epoch 12 | loss: 0.2321  | train_rmsle: 0.01915 | train_mae: 0.4839  | train_rmse: 0.57165 | train_mse: 0.32679 | valid_rmsle: 0.0188  | valid_mae: 0.48522 | valid_rmse: 0.57097 | valid_mse: 0.32601 |  0:00:28s\n",
      "epoch 13 | loss: 0.22989 | train_rmsle: 0.01587 | train_mae: 0.42402 | train_rmse: 0.51398 | train_mse: 0.26418 | valid_rmsle: 0.01533 | valid_mae: 0.4247  | valid_rmse: 0.51027 | valid_mse: 0.26038 |  0:00:30s\n",
      "epoch 14 | loss: 0.23473 | train_rmsle: 0.01555 | train_mae: 0.41731 | train_rmse: 0.5077  | train_mse: 0.25776 | valid_rmsle: 0.01507 | valid_mae: 0.41798 | valid_rmse: 0.50514 | valid_mse: 0.25516 |  0:00:33s\n",
      "epoch 15 | loss: 0.23186 | train_rmsle: 0.01668 | train_mae: 0.44019 | train_rmse: 0.52937 | train_mse: 0.28023 | valid_rmsle: 0.01628 | valid_mae: 0.4414  | valid_rmse: 0.52821 | valid_mse: 0.279   |  0:00:35s\n",
      "epoch 16 | loss: 0.23225 | train_rmsle: 0.01547 | train_mae: 0.41659 | train_rmse: 0.50665 | train_mse: 0.25669 | valid_rmsle: 0.015   | valid_mae: 0.41797 | valid_rmse: 0.50403 | valid_mse: 0.25405 |  0:00:37s\n",
      "epoch 17 | loss: 0.22486 | train_rmsle: 0.01559 | train_mae: 0.42034 | train_rmse: 0.50945 | train_mse: 0.25954 | valid_rmsle: 0.01516 | valid_mae: 0.42215 | valid_rmse: 0.50765 | valid_mse: 0.25771 |  0:00:39s\n",
      "epoch 18 | loss: 0.23232 | train_rmsle: 0.01849 | train_mae: 0.47464 | train_rmse: 0.56125 | train_mse: 0.31501 | valid_rmsle: 0.01814 | valid_mae: 0.47615 | valid_rmse: 0.56058 | valid_mse: 0.31425 |  0:00:41s\n",
      "epoch 19 | loss: 0.22708 | train_rmsle: 0.01444 | train_mae: 0.39027 | train_rmse: 0.48382 | train_mse: 0.23409 | valid_rmsle: 0.01389 | valid_mae: 0.39155 | valid_rmse: 0.48025 | valid_mse: 0.23064 |  0:00:43s\n",
      "epoch 20 | loss: 0.22713 | train_rmsle: 0.01436 | train_mae: 0.37623 | train_rmse: 0.47716 | train_mse: 0.22768 | valid_rmsle: 0.01365 | valid_mae: 0.3745  | valid_rmse: 0.47003 | valid_mse: 0.22093 |  0:00:46s\n",
      "epoch 21 | loss: 0.22027 | train_rmsle: 0.01419 | train_mae: 0.37783 | train_rmse: 0.4762  | train_mse: 0.22676 | valid_rmsle: 0.01381 | valid_mae: 0.38342 | valid_rmse: 0.47526 | valid_mse: 0.22587 |  0:00:48s\n",
      "epoch 22 | loss: 0.22117 | train_rmsle: 0.01406 | train_mae: 0.37748 | train_rmse: 0.47429 | train_mse: 0.22495 | valid_rmsle: 0.01366 | valid_mae: 0.38223 | valid_rmse: 0.47309 | valid_mse: 0.22381 |  0:00:50s\n",
      "epoch 23 | loss: 0.22468 | train_rmsle: 0.0151  | train_mae: 0.41344 | train_rmse: 0.50105 | train_mse: 0.25105 | valid_rmsle: 0.0147  | valid_mae: 0.41509 | valid_rmse: 0.4994  | valid_mse: 0.2494  |  0:00:51s\n",
      "epoch 24 | loss: 0.22041 | train_rmsle: 0.0141  | train_mae: 0.39526 | train_rmse: 0.48177 | train_mse: 0.2321  | valid_rmsle: 0.01339 | valid_mae: 0.39319 | valid_rmse: 0.47457 | valid_mse: 0.22521 |  0:00:53s\n",
      "epoch 25 | loss: 0.20996 | train_rmsle: 0.0126  | train_mae: 0.3592  | train_rmse: 0.44942 | train_mse: 0.20198 | valid_rmsle: 0.01201 | valid_mae: 0.36037 | valid_rmse: 0.44355 | valid_mse: 0.19673 |  0:00:55s\n",
      "epoch 26 | loss: 0.20797 | train_rmsle: 0.01213 | train_mae: 0.35732 | train_rmse: 0.44323 | train_mse: 0.19645 | valid_rmsle: 0.01172 | valid_mae: 0.36145 | valid_rmse: 0.4398  | valid_mse: 0.19343 |  0:00:57s\n",
      "epoch 27 | loss: 0.18698 | train_rmsle: 0.01097 | train_mae: 0.34037 | train_rmse: 0.42189 | train_mse: 0.17799 | valid_rmsle: 0.01072 | valid_mae: 0.34508 | valid_rmse: 0.42164 | valid_mse: 0.17778 |  0:00:59s\n",
      "epoch 28 | loss: 0.17233 | train_rmsle: 0.0095  | train_mae: 0.31185 | train_rmse: 0.39013 | train_mse: 0.1522  | valid_rmsle: 0.00941 | valid_mae: 0.31922 | valid_rmse: 0.39316 | valid_mse: 0.15457 |  0:01:01s\n",
      "epoch 29 | loss: 0.15498 | train_rmsle: 0.00887 | train_mae: 0.29005 | train_rmse: 0.37115 | train_mse: 0.13775 | valid_rmsle: 0.0087  | valid_mae: 0.29742 | valid_rmse: 0.37251 | valid_mse: 0.13876 |  0:01:04s\n",
      "epoch 30 | loss: 0.14326 | train_rmsle: 0.00917 | train_mae: 0.31167 | train_rmse: 0.38438 | train_mse: 0.14775 | valid_rmsle: 0.00894 | valid_mae: 0.31658 | valid_rmse: 0.385   | valid_mse: 0.14823 |  0:01:06s\n",
      "epoch 31 | loss: 0.12799 | train_rmsle: 0.00898 | train_mae: 0.30763 | train_rmse: 0.37941 | train_mse: 0.14395 | valid_rmsle: 0.00864 | valid_mae: 0.30639 | valid_rmse: 0.37615 | valid_mse: 0.14149 |  0:01:08s\n",
      "epoch 32 | loss: 0.12269 | train_rmsle: 0.00828 | train_mae: 0.2744  | train_rmse: 0.35809 | train_mse: 0.12823 | valid_rmsle: 0.0081  | valid_mae: 0.27737 | valid_rmse: 0.3591  | valid_mse: 0.12895 |  0:01:10s\n",
      "epoch 33 | loss: 0.1191  | train_rmsle: 0.00733 | train_mae: 0.26686 | train_rmse: 0.33823 | train_mse: 0.1144  | valid_rmsle: 0.00678 | valid_mae: 0.26433 | valid_rmse: 0.33066 | valid_mse: 0.10934 |  0:01:12s\n",
      "epoch 34 | loss: 0.11742 | train_rmsle: 0.00712 | train_mae: 0.26019 | train_rmse: 0.33226 | train_mse: 0.1104  | valid_rmsle: 0.00663 | valid_mae: 0.25694 | valid_rmse: 0.3258  | valid_mse: 0.10614 |  0:01:15s\n",
      "epoch 35 | loss: 0.10836 | train_rmsle: 0.00701 | train_mae: 0.2542  | train_rmse: 0.32828 | train_mse: 0.10777 | valid_rmsle: 0.00668 | valid_mae: 0.25227 | valid_rmse: 0.32623 | valid_mse: 0.10643 |  0:01:17s\n",
      "epoch 36 | loss: 0.10235 | train_rmsle: 0.00658 | train_mae: 0.25007 | train_rmse: 0.31901 | train_mse: 0.10177 | valid_rmsle: 0.0063  | valid_mae: 0.24874 | valid_rmse: 0.31765 | valid_mse: 0.1009  |  0:01:19s\n",
      "epoch 37 | loss: 0.09279 | train_rmsle: 0.00612 | train_mae: 0.24108 | train_rmse: 0.30786 | train_mse: 0.09478 | valid_rmsle: 0.00594 | valid_mae: 0.24291 | valid_rmse: 0.30896 | valid_mse: 0.09545 |  0:01:21s\n",
      "epoch 38 | loss: 0.08841 | train_rmsle: 0.00534 | train_mae: 0.22364 | train_rmse: 0.28729 | train_mse: 0.08253 | valid_rmsle: 0.00534 | valid_mae: 0.2289  | valid_rmse: 0.29344 | valid_mse: 0.08611 |  0:01:24s\n",
      "epoch 39 | loss: 0.07817 | train_rmsle: 0.00507 | train_mae: 0.22235 | train_rmse: 0.28249 | train_mse: 0.0798  | valid_rmsle: 0.00501 | valid_mae: 0.22823 | valid_rmse: 0.28633 | valid_mse: 0.08199 |  0:01:26s\n",
      "epoch 40 | loss: 0.07358 | train_rmsle: 0.00444 | train_mae: 0.19867 | train_rmse: 0.26003 | train_mse: 0.06762 | valid_rmsle: 0.00448 | valid_mae: 0.20557 | valid_rmse: 0.26756 | valid_mse: 0.07159 |  0:01:28s\n",
      "epoch 41 | loss: 0.0679  | train_rmsle: 0.00403 | train_mae: 0.19206 | train_rmse: 0.24937 | train_mse: 0.06219 | valid_rmsle: 0.00419 | valid_mae: 0.20156 | valid_rmse: 0.25996 | valid_mse: 0.06758 |  0:01:30s\n",
      "epoch 42 | loss: 0.06227 | train_rmsle: 0.00448 | train_mae: 0.21332 | train_rmse: 0.26958 | train_mse: 0.07267 | valid_rmsle: 0.00476 | valid_mae: 0.22572 | valid_rmse: 0.28246 | valid_mse: 0.07978 |  0:01:32s\n",
      "epoch 43 | loss: 0.06843 | train_rmsle: 0.00408 | train_mae: 0.20425 | train_rmse: 0.25802 | train_mse: 0.06657 | valid_rmsle: 0.00438 | valid_mae: 0.21705 | valid_rmse: 0.2722  | valid_mse: 0.07409 |  0:01:35s\n",
      "epoch 44 | loss: 0.06216 | train_rmsle: 0.00375 | train_mae: 0.193   | train_rmse: 0.24547 | train_mse: 0.06025 | valid_rmsle: 0.00403 | valid_mae: 0.20285 | valid_rmse: 0.25892 | valid_mse: 0.06704 |  0:01:37s\n",
      "epoch 45 | loss: 0.05988 | train_rmsle: 0.00354 | train_mae: 0.18902 | train_rmse: 0.24008 | train_mse: 0.05764 | valid_rmsle: 0.00392 | valid_mae: 0.20155 | valid_rmse: 0.25687 | valid_mse: 0.06598 |  0:01:39s\n",
      "epoch 46 | loss: 0.05411 | train_rmsle: 0.00301 | train_mae: 0.16896 | train_rmse: 0.21803 | train_mse: 0.04754 | valid_rmsle: 0.00334 | valid_mae: 0.18108 | valid_rmse: 0.23494 | valid_mse: 0.0552  |  0:01:41s\n",
      "epoch 47 | loss: 0.05352 | train_rmsle: 0.00308 | train_mae: 0.17486 | train_rmse: 0.22349 | train_mse: 0.04995 | valid_rmsle: 0.0034  | valid_mae: 0.1864  | valid_rmse: 0.23904 | valid_mse: 0.05714 |  0:01:44s\n",
      "epoch 48 | loss: 0.05186 | train_rmsle: 0.00364 | train_mae: 0.19672 | train_rmse: 0.24702 | train_mse: 0.06102 | valid_rmsle: 0.00403 | valid_mae: 0.2091  | valid_rmse: 0.26217 | valid_mse: 0.06873 |  0:01:46s\n",
      "epoch 49 | loss: 0.04604 | train_rmsle: 0.00244 | train_mae: 0.1567  | train_rmse: 0.20081 | train_mse: 0.04032 | valid_rmsle: 0.00282 | valid_mae: 0.17222 | valid_rmse: 0.21962 | valid_mse: 0.04823 |  0:01:48s\n",
      "epoch 50 | loss: 0.04362 | train_rmsle: 0.00254 | train_mae: 0.16513 | train_rmse: 0.20861 | train_mse: 0.04352 | valid_rmsle: 0.00297 | valid_mae: 0.17842 | valid_rmse: 0.22794 | valid_mse: 0.05196 |  0:01:50s\n",
      "epoch 51 | loss: 0.0413  | train_rmsle: 0.00227 | train_mae: 0.15022 | train_rmse: 0.1935  | train_mse: 0.03744 | valid_rmsle: 0.0026  | valid_mae: 0.16391 | valid_rmse: 0.21173 | valid_mse: 0.04483 |  0:01:52s\n",
      "epoch 52 | loss: 0.04036 | train_rmsle: 0.0022  | train_mae: 0.14863 | train_rmse: 0.19201 | train_mse: 0.03687 | valid_rmsle: 0.00254 | valid_mae: 0.16379 | valid_rmse: 0.20998 | valid_mse: 0.04409 |  0:01:54s\n",
      "epoch 53 | loss: 0.05199 | train_rmsle: 0.00427 | train_mae: 0.20824 | train_rmse: 0.26684 | train_mse: 0.0712  | valid_rmsle: 0.00462 | valid_mae: 0.21804 | valid_rmse: 0.28067 | valid_mse: 0.07877 |  0:01:57s\n",
      "epoch 54 | loss: 0.04754 | train_rmsle: 0.00365 | train_mae: 0.18867 | train_rmse: 0.23778 | train_mse: 0.05654 | valid_rmsle: 0.00402 | valid_mae: 0.20017 | valid_rmse: 0.25293 | valid_mse: 0.06397 |  0:01:59s\n",
      "epoch 55 | loss: 0.04636 | train_rmsle: 0.00264 | train_mae: 0.16311 | train_rmse: 0.21052 | train_mse: 0.04432 | valid_rmsle: 0.00301 | valid_mae: 0.17366 | valid_rmse: 0.22676 | valid_mse: 0.05142 |  0:02:01s\n",
      "epoch 56 | loss: 0.04871 | train_rmsle: 0.00441 | train_mae: 0.22596 | train_rmse: 0.27326 | train_mse: 0.07467 | valid_rmsle: 0.00475 | valid_mae: 0.23371 | valid_rmse: 0.28547 | valid_mse: 0.08149 |  0:02:03s\n",
      "epoch 57 | loss: 0.04426 | train_rmsle: 0.00245 | train_mae: 0.15582 | train_rmse: 0.20345 | train_mse: 0.04139 | valid_rmsle: 0.0028  | valid_mae: 0.16595 | valid_rmse: 0.21913 | valid_mse: 0.04802 |  0:02:05s\n",
      "epoch 58 | loss: 0.04137 | train_rmsle: 0.00447 | train_mae: 0.20575 | train_rmse: 0.26542 | train_mse: 0.07045 | valid_rmsle: 0.00455 | valid_mae: 0.21599 | valid_rmse: 0.27419 | valid_mse: 0.07518 |  0:02:07s\n",
      "epoch 59 | loss: 0.03759 | train_rmsle: 0.00194 | train_mae: 0.14083 | train_rmse: 0.18345 | train_mse: 0.03366 | valid_rmsle: 0.0022  | valid_mae: 0.1549  | valid_rmse: 0.19764 | valid_mse: 0.03906 |  0:02:09s\n",
      "epoch 60 | loss: 0.03816 | train_rmsle: 0.00181 | train_mae: 0.1403  | train_rmse: 0.18088 | train_mse: 0.03272 | valid_rmsle: 0.00205 | valid_mae: 0.15032 | valid_rmse: 0.19286 | valid_mse: 0.03719 |  0:02:11s\n",
      "epoch 61 | loss: 0.03948 | train_rmsle: 0.00159 | train_mae: 0.1308  | train_rmse: 0.16884 | train_mse: 0.02851 | valid_rmsle: 0.00185 | valid_mae: 0.14091 | valid_rmse: 0.18299 | valid_mse: 0.03348 |  0:02:13s\n",
      "epoch 62 | loss: 0.0313  | train_rmsle: 0.0015  | train_mae: 0.1275  | train_rmse: 0.16406 | train_mse: 0.02692 | valid_rmsle: 0.00171 | valid_mae: 0.13696 | valid_rmse: 0.17511 | valid_mse: 0.03066 |  0:02:15s\n",
      "epoch 63 | loss: 0.03199 | train_rmsle: 0.00142 | train_mae: 0.12386 | train_rmse: 0.15863 | train_mse: 0.02516 | valid_rmsle: 0.0016  | valid_mae: 0.13189 | valid_rmse: 0.16891 | valid_mse: 0.02853 |  0:02:17s\n",
      "epoch 64 | loss: 0.03071 | train_rmsle: 0.00148 | train_mae: 0.12574 | train_rmse: 0.16059 | train_mse: 0.02579 | valid_rmsle: 0.0017  | valid_mae: 0.13689 | valid_rmse: 0.1735  | valid_mse: 0.0301  |  0:02:19s\n",
      "epoch 65 | loss: 0.03283 | train_rmsle: 0.0014  | train_mae: 0.12285 | train_rmse: 0.15862 | train_mse: 0.02516 | valid_rmsle: 0.00174 | valid_mae: 0.13547 | valid_rmse: 0.1764  | valid_mse: 0.03112 |  0:02:21s\n",
      "epoch 66 | loss: 0.03    | train_rmsle: 0.00173 | train_mae: 0.1379  | train_rmse: 0.17758 | train_mse: 0.03153 | valid_rmsle: 0.00208 | valid_mae: 0.14898 | valid_rmse: 0.19336 | valid_mse: 0.03739 |  0:02:24s\n",
      "epoch 67 | loss: 0.0297  | train_rmsle: 0.00283 | train_mae: 0.15929 | train_rmse: 0.20087 | train_mse: 0.04035 | valid_rmsle: 0.00289 | valid_mae: 0.16868 | valid_rmse: 0.2094  | valid_mse: 0.04385 |  0:02:26s\n",
      "epoch 68 | loss: 0.02984 | train_rmsle: 0.00229 | train_mae: 0.14921 | train_rmse: 0.1894  | train_mse: 0.03587 | valid_rmsle: 0.00251 | valid_mae: 0.16149 | valid_rmse: 0.20432 | valid_mse: 0.04175 |  0:02:28s\n",
      "epoch 69 | loss: 0.03489 | train_rmsle: 0.00152 | train_mae: 0.12897 | train_rmse: 0.16416 | train_mse: 0.02695 | valid_rmsle: 0.0018  | valid_mae: 0.14089 | valid_rmse: 0.17987 | valid_mse: 0.03235 |  0:02:30s\n",
      "epoch 70 | loss: 0.03332 | train_rmsle: 0.00316 | train_mae: 0.17572 | train_rmse: 0.21587 | train_mse: 0.0466  | valid_rmsle: 0.0033  | valid_mae: 0.18383 | valid_rmse: 0.22429 | valid_mse: 0.05031 |  0:02:32s\n",
      "epoch 71 | loss: 0.03416 | train_rmsle: 0.00221 | train_mae: 0.15482 | train_rmse: 0.19662 | train_mse: 0.03866 | valid_rmsle: 0.00237 | valid_mae: 0.15938 | valid_rmse: 0.20573 | valid_mse: 0.04233 |  0:02:35s\n",
      "epoch 72 | loss: 0.03346 | train_rmsle: 0.00232 | train_mae: 0.16063 | train_rmse: 0.19955 | train_mse: 0.03982 | valid_rmsle: 0.00256 | valid_mae: 0.17128 | valid_rmse: 0.2118  | valid_mse: 0.04486 |  0:02:37s\n",
      "epoch 73 | loss: 0.03217 | train_rmsle: 0.00143 | train_mae: 0.12531 | train_rmse: 0.15899 | train_mse: 0.02528 | valid_rmsle: 0.00173 | valid_mae: 0.13688 | valid_rmse: 0.17592 | valid_mse: 0.03095 |  0:02:39s\n",
      "epoch 74 | loss: 0.02738 | train_rmsle: 0.00124 | train_mae: 0.1175  | train_rmse: 0.14946 | train_mse: 0.02234 | valid_rmsle: 0.00157 | valid_mae: 0.13144 | valid_rmse: 0.1682  | valid_mse: 0.02829 |  0:02:41s\n",
      "epoch 75 | loss: 0.02598 | train_rmsle: 0.00123 | train_mae: 0.11789 | train_rmse: 0.14936 | train_mse: 0.02231 | valid_rmsle: 0.00158 | valid_mae: 0.13316 | valid_rmse: 0.16907 | valid_mse: 0.02858 |  0:02:43s\n",
      "epoch 76 | loss: 0.02635 | train_rmsle: 0.00252 | train_mae: 0.17141 | train_rmse: 0.20473 | train_mse: 0.04192 | valid_rmsle: 0.00285 | valid_mae: 0.18361 | valid_rmse: 0.21914 | valid_mse: 0.04802 |  0:02:46s\n",
      "epoch 77 | loss: 0.02741 | train_rmsle: 0.0013  | train_mae: 0.12067 | train_rmse: 0.15112 | train_mse: 0.02284 | valid_rmsle: 0.00163 | valid_mae: 0.13451 | valid_rmse: 0.16911 | valid_mse: 0.0286  |  0:02:48s\n",
      "epoch 78 | loss: 0.02335 | train_rmsle: 0.00237 | train_mae: 0.13484 | train_rmse: 0.17873 | train_mse: 0.03194 | valid_rmsle: 0.00278 | valid_mae: 0.1436  | valid_rmse: 0.19541 | valid_mse: 0.03819 |  0:02:50s\n",
      "epoch 79 | loss: 0.02825 | train_rmsle: 0.00108 | train_mae: 0.10611 | train_rmse: 0.13526 | train_mse: 0.0183  | valid_rmsle: 0.00133 | valid_mae: 0.11892 | valid_rmse: 0.15182 | valid_mse: 0.02305 |  0:02:52s\n",
      "epoch 80 | loss: 0.02202 | train_rmsle: 0.00114 | train_mae: 0.10855 | train_rmse: 0.13776 | train_mse: 0.01898 | valid_rmsle: 0.00131 | valid_mae: 0.11719 | valid_rmse: 0.14966 | valid_mse: 0.0224  |  0:02:54s\n",
      "epoch 81 | loss: 0.02289 | train_rmsle: 0.00094 | train_mae: 0.10172 | train_rmse: 0.12917 | train_mse: 0.01668 | valid_rmsle: 0.00117 | valid_mae: 0.11457 | valid_rmse: 0.1447  | valid_mse: 0.02094 |  0:02:57s\n",
      "epoch 82 | loss: 0.02165 | train_rmsle: 0.00104 | train_mae: 0.10317 | train_rmse: 0.13101 | train_mse: 0.01716 | valid_rmsle: 0.00125 | valid_mae: 0.1127  | valid_rmse: 0.14489 | valid_mse: 0.02099 |  0:02:59s\n",
      "epoch 83 | loss: 0.02065 | train_rmsle: 0.00121 | train_mae: 0.11631 | train_rmse: 0.14469 | train_mse: 0.02093 | valid_rmsle: 0.00149 | valid_mae: 0.13038 | valid_rmse: 0.16063 | valid_mse: 0.0258  |  0:03:01s\n",
      "epoch 84 | loss: 0.0187  | train_rmsle: 0.00109 | train_mae: 0.10585 | train_rmse: 0.13258 | train_mse: 0.01758 | valid_rmsle: 0.00135 | valid_mae: 0.11772 | valid_rmse: 0.1483  | valid_mse: 0.02199 |  0:03:03s\n",
      "epoch 85 | loss: 0.01815 | train_rmsle: 0.00177 | train_mae: 0.13777 | train_rmse: 0.1696  | train_mse: 0.02876 | valid_rmsle: 0.00206 | valid_mae: 0.14943 | valid_rmse: 0.18442 | valid_mse: 0.03401 |  0:03:06s\n",
      "epoch 86 | loss: 0.02097 | train_rmsle: 0.00228 | train_mae: 0.14293 | train_rmse: 0.18    | train_mse: 0.0324  | valid_rmsle: 0.00263 | valid_mae: 0.1545  | valid_rmse: 0.19506 | valid_mse: 0.03805 |  0:03:08s\n",
      "epoch 87 | loss: 0.02083 | train_rmsle: 0.00367 | train_mae: 0.17324 | train_rmse: 0.21896 | train_mse: 0.04794 | valid_rmsle: 0.00408 | valid_mae: 0.18541 | valid_rmse: 0.23301 | valid_mse: 0.0543  |  0:03:10s\n",
      "epoch 88 | loss: 0.02033 | train_rmsle: 0.00104 | train_mae: 0.1078  | train_rmse: 0.13797 | train_mse: 0.01904 | valid_rmsle: 0.00127 | valid_mae: 0.11675 | valid_rmse: 0.15279 | valid_mse: 0.02334 |  0:03:12s\n",
      "epoch 89 | loss: 0.02855 | train_rmsle: 0.00146 | train_mae: 0.11939 | train_rmse: 0.14945 | train_mse: 0.02233 | valid_rmsle: 0.00168 | valid_mae: 0.12938 | valid_rmse: 0.1613  | valid_mse: 0.02602 |  0:03:14s\n",
      "epoch 90 | loss: 0.02375 | train_rmsle: 0.00157 | train_mae: 0.13569 | train_rmse: 0.16349 | train_mse: 0.02673 | valid_rmsle: 0.00178 | valid_mae: 0.14475 | valid_rmse: 0.17402 | valid_mse: 0.03028 |  0:03:17s\n",
      "epoch 91 | loss: 0.02017 | train_rmsle: 0.00094 | train_mae: 0.1027  | train_rmse: 0.12822 | train_mse: 0.01644 | valid_rmsle: 0.00112 | valid_mae: 0.11322 | valid_rmse: 0.14019 | valid_mse: 0.01965 |  0:03:19s\n",
      "epoch 92 | loss: 0.01828 | train_rmsle: 0.00066 | train_mae: 0.08479 | train_rmse: 0.10881 | train_mse: 0.01184 | valid_rmsle: 0.00084 | valid_mae: 0.09434 | valid_rmse: 0.12248 | valid_mse: 0.015   |  0:03:21s\n",
      "epoch 93 | loss: 0.02062 | train_rmsle: 0.0016  | train_mae: 0.14328 | train_rmse: 0.17344 | train_mse: 0.03008 | valid_rmsle: 0.00173 | valid_mae: 0.14918 | valid_rmse: 0.18038 | valid_mse: 0.03254 |  0:03:23s\n",
      "epoch 94 | loss: 0.02869 | train_rmsle: 0.00089 | train_mae: 0.10173 | train_rmse: 0.12821 | train_mse: 0.01644 | valid_rmsle: 0.00104 | valid_mae: 0.11079 | valid_rmse: 0.13855 | valid_mse: 0.0192  |  0:03:25s\n",
      "epoch 95 | loss: 0.01927 | train_rmsle: 0.00069 | train_mae: 0.08609 | train_rmse: 0.11007 | train_mse: 0.01212 | valid_rmsle: 0.00085 | valid_mae: 0.09699 | valid_rmse: 0.12271 | valid_mse: 0.01506 |  0:03:27s\n",
      "epoch 96 | loss: 0.01803 | train_rmsle: 0.00065 | train_mae: 0.0844  | train_rmse: 0.10772 | train_mse: 0.0116  | valid_rmsle: 0.00084 | valid_mae: 0.09541 | valid_rmse: 0.12182 | valid_mse: 0.01484 |  0:03:29s\n",
      "epoch 97 | loss: 0.01619 | train_rmsle: 0.00058 | train_mae: 0.0803  | train_rmse: 0.10269 | train_mse: 0.01055 | valid_rmsle: 0.00076 | valid_mae: 0.09058 | valid_rmse: 0.11687 | valid_mse: 0.01366 |  0:03:31s\n",
      "epoch 98 | loss: 0.01533 | train_rmsle: 0.00076 | train_mae: 0.09429 | train_rmse: 0.11936 | train_mse: 0.01425 | valid_rmsle: 0.00091 | valid_mae: 0.10292 | valid_rmse: 0.12994 | valid_mse: 0.01688 |  0:03:32s\n",
      "epoch 99 | loss: 0.01509 | train_rmsle: 0.0006  | train_mae: 0.07958 | train_rmse: 0.10176 | train_mse: 0.01035 | valid_rmsle: 0.00075 | valid_mae: 0.08873 | valid_rmse: 0.11431 | valid_mse: 0.01307 |  0:03:35s\n",
      "epoch 100| loss: 0.01629 | train_rmsle: 0.00053 | train_mae: 0.07643 | train_rmse: 0.09767 | train_mse: 0.00954 | valid_rmsle: 0.00071 | valid_mae: 0.08623 | valid_rmse: 0.11191 | valid_mse: 0.01252 |  0:03:37s\n",
      "epoch 101| loss: 0.01542 | train_rmsle: 0.00131 | train_mae: 0.12513 | train_rmse: 0.1488  | train_mse: 0.02214 | valid_rmsle: 0.00146 | valid_mae: 0.13173 | valid_rmse: 0.15758 | valid_mse: 0.02483 |  0:03:39s\n",
      "epoch 102| loss: 0.02027 | train_rmsle: 0.00821 | train_mae: 0.21014 | train_rmse: 0.29893 | train_mse: 0.08936 | valid_rmsle: 0.00802 | valid_mae: 0.21358 | valid_rmse: 0.29844 | valid_mse: 0.08907 |  0:03:41s\n",
      "epoch 103| loss: 0.02318 | train_rmsle: 0.00176 | train_mae: 0.12678 | train_rmse: 0.1616  | train_mse: 0.02611 | valid_rmsle: 0.00197 | valid_mae: 0.13363 | valid_rmse: 0.17248 | valid_mse: 0.02975 |  0:03:43s\n",
      "epoch 104| loss: 0.0208  | train_rmsle: 0.001   | train_mae: 0.09691 | train_rmse: 0.12533 | train_mse: 0.01571 | valid_rmsle: 0.00122 | valid_mae: 0.10719 | valid_rmse: 0.13873 | valid_mse: 0.01925 |  0:03:46s\n",
      "epoch 105| loss: 0.02047 | train_rmsle: 0.00101 | train_mae: 0.10918 | train_rmse: 0.13727 | train_mse: 0.01884 | valid_rmsle: 0.00118 | valid_mae: 0.11774 | valid_rmse: 0.1475  | valid_mse: 0.02176 |  0:03:48s\n",
      "epoch 106| loss: 0.01738 | train_rmsle: 0.00073 | train_mae: 0.08885 | train_rmse: 0.11415 | train_mse: 0.01303 | valid_rmsle: 0.00091 | valid_mae: 0.10004 | valid_rmse: 0.12733 | valid_mse: 0.01621 |  0:03:50s\n",
      "epoch 107| loss: 0.01637 | train_rmsle: 0.00103 | train_mae: 0.09772 | train_rmse: 0.12475 | train_mse: 0.01556 | valid_rmsle: 0.0012  | valid_mae: 0.10804 | valid_rmse: 0.1371  | valid_mse: 0.0188  |  0:03:52s\n",
      "epoch 108| loss: 0.01594 | train_rmsle: 0.00075 | train_mae: 0.08869 | train_rmse: 0.1131  | train_mse: 0.01279 | valid_rmsle: 0.00092 | valid_mae: 0.09994 | valid_rmse: 0.12599 | valid_mse: 0.01587 |  0:03:54s\n",
      "epoch 109| loss: 0.01994 | train_rmsle: 0.00169 | train_mae: 0.14124 | train_rmse: 0.16625 | train_mse: 0.02764 | valid_rmsle: 0.00189 | valid_mae: 0.14813 | valid_rmse: 0.178   | valid_mse: 0.03168 |  0:03:56s\n",
      "epoch 110| loss: 0.02002 | train_rmsle: 0.00067 | train_mae: 0.08403 | train_rmse: 0.10693 | train_mse: 0.01143 | valid_rmsle: 0.00086 | valid_mae: 0.09512 | valid_rmse: 0.12173 | valid_mse: 0.01482 |  0:03:59s\n",
      "epoch 111| loss: 0.01545 | train_rmsle: 0.0005  | train_mae: 0.0718  | train_rmse: 0.09285 | train_mse: 0.00862 | valid_rmsle: 0.00066 | valid_mae: 0.08334 | valid_rmse: 0.10705 | valid_mse: 0.01146 |  0:04:01s\n",
      "epoch 112| loss: 0.01407 | train_rmsle: 0.00053 | train_mae: 0.07641 | train_rmse: 0.09844 | train_mse: 0.00969 | valid_rmsle: 0.00072 | valid_mae: 0.08743 | valid_rmse: 0.11367 | valid_mse: 0.01292 |  0:04:03s\n",
      "epoch 113| loss: 0.0163  | train_rmsle: 0.00058 | train_mae: 0.08058 | train_rmse: 0.10192 | train_mse: 0.01039 | valid_rmsle: 0.00071 | valid_mae: 0.08967 | valid_rmse: 0.11202 | valid_mse: 0.01255 |  0:04:05s\n",
      "epoch 114| loss: 0.01337 | train_rmsle: 0.00069 | train_mae: 0.0895  | train_rmse: 0.11143 | train_mse: 0.01242 | valid_rmsle: 0.00081 | valid_mae: 0.09649 | valid_rmse: 0.12075 | valid_mse: 0.01458 |  0:04:07s\n",
      "epoch 115| loss: 0.01374 | train_rmsle: 0.00047 | train_mae: 0.07092 | train_rmse: 0.09048 | train_mse: 0.00819 | valid_rmsle: 0.0006  | valid_mae: 0.07942 | valid_rmse: 0.10154 | valid_mse: 0.01031 |  0:04:10s\n",
      "epoch 116| loss: 0.0149  | train_rmsle: 0.00081 | train_mae: 0.09182 | train_rmse: 0.11439 | train_mse: 0.01308 | valid_rmsle: 0.00091 | valid_mae: 0.09815 | valid_rmse: 0.12246 | valid_mse: 0.015   |  0:04:12s\n",
      "epoch 117| loss: 0.01306 | train_rmsle: 0.00094 | train_mae: 0.10882 | train_rmse: 0.13265 | train_mse: 0.0176  | valid_rmsle: 0.00106 | valid_mae: 0.11584 | valid_rmse: 0.14081 | valid_mse: 0.01983 |  0:04:14s\n",
      "epoch 118| loss: 0.01476 | train_rmsle: 0.00069 | train_mae: 0.09002 | train_rmse: 0.11358 | train_mse: 0.0129  | valid_rmsle: 0.00082 | valid_mae: 0.09883 | valid_rmse: 0.12319 | valid_mse: 0.01517 |  0:04:16s\n",
      "epoch 119| loss: 0.01833 | train_rmsle: 0.00313 | train_mae: 0.16259 | train_rmse: 0.21749 | train_mse: 0.0473  | valid_rmsle: 0.00304 | valid_mae: 0.16204 | valid_rmse: 0.21625 | valid_mse: 0.04676 |  0:04:18s\n",
      "epoch 120| loss: 0.01988 | train_rmsle: 0.00137 | train_mae: 0.10607 | train_rmse: 0.13811 | train_mse: 0.01908 | valid_rmsle: 0.00145 | valid_mae: 0.11254 | valid_rmse: 0.14464 | valid_mse: 0.02092 |  0:04:21s\n",
      "epoch 121| loss: 0.02062 | train_rmsle: 0.00071 | train_mae: 0.08483 | train_rmse: 0.10929 | train_mse: 0.01194 | valid_rmsle: 0.00085 | valid_mae: 0.09468 | valid_rmse: 0.12025 | valid_mse: 0.01446 |  0:04:23s\n",
      "epoch 122| loss: 0.01515 | train_rmsle: 0.00071 | train_mae: 0.08782 | train_rmse: 0.11213 | train_mse: 0.01257 | valid_rmsle: 0.00085 | valid_mae: 0.09738 | valid_rmse: 0.12328 | valid_mse: 0.0152  |  0:04:25s\n",
      "epoch 123| loss: 0.02151 | train_rmsle: 0.00174 | train_mae: 0.15085 | train_rmse: 0.17486 | train_mse: 0.03058 | valid_rmsle: 0.00187 | valid_mae: 0.15296 | valid_rmse: 0.18044 | valid_mse: 0.03256 |  0:04:27s\n",
      "epoch 124| loss: 0.01805 | train_rmsle: 0.00068 | train_mae: 0.08451 | train_rmse: 0.10809 | train_mse: 0.01168 | valid_rmsle: 0.0008  | valid_mae: 0.09224 | valid_rmse: 0.11769 | valid_mse: 0.01385 |  0:04:30s\n",
      "epoch 125| loss: 0.02229 | train_rmsle: 0.00051 | train_mae: 0.07318 | train_rmse: 0.09425 | train_mse: 0.00888 | valid_rmsle: 0.00065 | valid_mae: 0.08317 | valid_rmse: 0.10625 | valid_mse: 0.01129 |  0:04:32s\n",
      "epoch 126| loss: 0.01686 | train_rmsle: 0.00072 | train_mae: 0.08825 | train_rmse: 0.11169 | train_mse: 0.01247 | valid_rmsle: 0.00091 | valid_mae: 0.0992  | valid_rmse: 0.12576 | valid_mse: 0.01582 |  0:04:34s\n",
      "epoch 127| loss: 0.01735 | train_rmsle: 0.00061 | train_mae: 0.08213 | train_rmse: 0.10512 | train_mse: 0.01105 | valid_rmsle: 0.00077 | valid_mae: 0.09054 | valid_rmse: 0.11662 | valid_mse: 0.0136  |  0:04:36s\n",
      "epoch 128| loss: 0.01783 | train_rmsle: 0.00065 | train_mae: 0.0868  | train_rmse: 0.11012 | train_mse: 0.01213 | valid_rmsle: 0.0008  | valid_mae: 0.09504 | valid_rmse: 0.121   | valid_mse: 0.01464 |  0:04:38s\n",
      "epoch 129| loss: 0.0169  | train_rmsle: 0.00127 | train_mae: 0.11879 | train_rmse: 0.15338 | train_mse: 0.02352 | valid_rmsle: 0.0014  | valid_mae: 0.12584 | valid_rmse: 0.16032 | valid_mse: 0.0257  |  0:04:41s\n",
      "epoch 130| loss: 0.02304 | train_rmsle: 0.00105 | train_mae: 0.10786 | train_rmse: 0.13883 | train_mse: 0.01927 | valid_rmsle: 0.00121 | valid_mae: 0.11585 | valid_rmse: 0.14764 | valid_mse: 0.0218  |  0:04:42s\n",
      "epoch 131| loss: 0.02347 | train_rmsle: 0.00501 | train_mae: 0.17925 | train_rmse: 0.23984 | train_mse: 0.05753 | valid_rmsle: 0.00513 | valid_mae: 0.18188 | valid_rmse: 0.24293 | valid_mse: 0.05901 |  0:04:44s\n",
      "epoch 132| loss: 0.02288 | train_rmsle: 0.00318 | train_mae: 0.15875 | train_rmse: 0.20225 | train_mse: 0.04091 | valid_rmsle: 0.00329 | valid_mae: 0.16168 | valid_rmse: 0.2075  | valid_mse: 0.04306 |  0:04:46s\n",
      "epoch 133| loss: 0.02046 | train_rmsle: 0.00235 | train_mae: 0.13251 | train_rmse: 0.17665 | train_mse: 0.03121 | valid_rmsle: 0.0024  | valid_mae: 0.13865 | valid_rmse: 0.18376 | valid_mse: 0.03377 |  0:04:48s\n",
      "epoch 134| loss: 0.01913 | train_rmsle: 0.00159 | train_mae: 0.1204  | train_rmse: 0.15093 | train_mse: 0.02278 | valid_rmsle: 0.00178 | valid_mae: 0.12598 | valid_rmse: 0.16058 | valid_mse: 0.02578 |  0:04:50s\n",
      "epoch 135| loss: 0.01839 | train_rmsle: 0.00064 | train_mae: 0.08389 | train_rmse: 0.10717 | train_mse: 0.01149 | valid_rmsle: 0.0008  | valid_mae: 0.09329 | valid_rmse: 0.11942 | valid_mse: 0.01426 |  0:04:52s\n",
      "\n",
      "Early stopping occurred at epoch 135 with best_epoch = 115 and best_valid_mse = 0.01031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0107312294857083 RMSE: 0.1035916477603687 R2: 0.9524969820088199 MAE: 0.08327417851273673\n",
      "=====================================\n",
      "[64/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.74497 | train_rmsle: 0.15935 | train_mae: 1.37644 | train_rmse: 1.45453 | train_mse: 2.11566 | valid_rmsle: 0.16017 | valid_mae: 1.38076 | valid_rmse: 1.4592  | valid_mse: 2.12927 |  0:00:01s\n",
      "epoch 1  | loss: 0.576   | train_rmsle: 0.08746 | train_mae: 1.05207 | train_rmse: 1.14039 | train_mse: 1.30048 | valid_rmsle: 0.08774 | valid_mae: 1.05444 | valid_rmse: 1.14365 | valid_mse: 1.30793 |  0:00:03s\n",
      "epoch 2  | loss: 0.38487 | train_rmsle: 0.06944 | train_mae: 0.94363 | train_rmse: 1.03505 | train_mse: 1.07133 | valid_rmsle: 0.06969 | valid_mae: 0.9459  | valid_rmse: 1.03852 | valid_mse: 1.07853 |  0:00:05s\n",
      "epoch 3  | loss: 0.3946  | train_rmsle: 0.03068 | train_mae: 0.62862 | train_rmse: 0.72062 | train_mse: 0.51929 | valid_rmsle: 0.03053 | valid_mae: 0.62849 | valid_rmse: 0.72202 | valid_mse: 0.52131 |  0:00:07s\n",
      "epoch 4  | loss: 0.37912 | train_rmsle: 0.02773 | train_mae: 0.5964  | train_rmse: 0.68715 | train_mse: 0.47218 | valid_rmsle: 0.02761 | valid_mae: 0.59771 | valid_rmse: 0.68898 | valid_mse: 0.4747  |  0:00:08s\n",
      "epoch 5  | loss: 0.31791 | train_rmsle: 0.03534 | train_mae: 0.67489 | train_rmse: 0.76865 | train_mse: 0.59083 | valid_rmsle: 0.03536 | valid_mae: 0.67692 | valid_rmse: 0.7715  | valid_mse: 0.5952  |  0:00:10s\n",
      "epoch 6  | loss: 0.2562  | train_rmsle: 0.03801 | train_mae: 0.6998  | train_rmse: 0.79457 | train_mse: 0.63134 | valid_rmsle: 0.03785 | valid_mae: 0.69709 | valid_rmse: 0.79578 | valid_mse: 0.63326 |  0:00:12s\n",
      "epoch 7  | loss: 0.27039 | train_rmsle: 0.02739 | train_mae: 0.59123 | train_rmse: 0.68304 | train_mse: 0.46654 | valid_rmsle: 0.02717 | valid_mae: 0.59101 | valid_rmse: 0.68382 | valid_mse: 0.4676  |  0:00:14s\n",
      "epoch 8  | loss: 0.29747 | train_rmsle: 0.03763 | train_mae: 0.69852 | train_rmse: 0.79126 | train_mse: 0.62609 | valid_rmsle: 0.03735 | valid_mae: 0.69628 | valid_rmse: 0.79122 | valid_mse: 0.62602 |  0:00:16s\n",
      "epoch 9  | loss: 0.28916 | train_rmsle: 0.02251 | train_mae: 0.53218 | train_rmse: 0.62103 | train_mse: 0.38568 | valid_rmsle: 0.02215 | valid_mae: 0.53194 | valid_rmse: 0.61996 | valid_mse: 0.38435 |  0:00:17s\n",
      "epoch 10 | loss: 0.24046 | train_rmsle: 0.01968 | train_mae: 0.49156 | train_rmse: 0.5799  | train_mse: 0.33628 | valid_rmsle: 0.0193  | valid_mae: 0.49197 | valid_rmse: 0.57866 | valid_mse: 0.33484 |  0:00:19s\n",
      "epoch 11 | loss: 0.23517 | train_rmsle: 0.01623 | train_mae: 0.43218 | train_rmse: 0.52096 | train_mse: 0.2714  | valid_rmsle: 0.01574 | valid_mae: 0.43261 | valid_rmse: 0.51799 | valid_mse: 0.26831 |  0:00:21s\n",
      "epoch 12 | loss: 0.2321  | train_rmsle: 0.01915 | train_mae: 0.4839  | train_rmse: 0.57165 | train_mse: 0.32679 | valid_rmsle: 0.0188  | valid_mae: 0.48522 | valid_rmse: 0.57097 | valid_mse: 0.32601 |  0:00:23s\n",
      "epoch 13 | loss: 0.22989 | train_rmsle: 0.01587 | train_mae: 0.42402 | train_rmse: 0.51398 | train_mse: 0.26418 | valid_rmsle: 0.01533 | valid_mae: 0.4247  | valid_rmse: 0.51027 | valid_mse: 0.26038 |  0:00:25s\n",
      "epoch 14 | loss: 0.23473 | train_rmsle: 0.01555 | train_mae: 0.41731 | train_rmse: 0.5077  | train_mse: 0.25776 | valid_rmsle: 0.01507 | valid_mae: 0.41798 | valid_rmse: 0.50514 | valid_mse: 0.25516 |  0:00:26s\n",
      "epoch 15 | loss: 0.23186 | train_rmsle: 0.01668 | train_mae: 0.44019 | train_rmse: 0.52937 | train_mse: 0.28023 | valid_rmsle: 0.01628 | valid_mae: 0.4414  | valid_rmse: 0.52821 | valid_mse: 0.279   |  0:00:28s\n",
      "epoch 16 | loss: 0.23225 | train_rmsle: 0.01547 | train_mae: 0.41659 | train_rmse: 0.50665 | train_mse: 0.25669 | valid_rmsle: 0.015   | valid_mae: 0.41797 | valid_rmse: 0.50403 | valid_mse: 0.25405 |  0:00:30s\n",
      "epoch 17 | loss: 0.22486 | train_rmsle: 0.01559 | train_mae: 0.42034 | train_rmse: 0.50945 | train_mse: 0.25954 | valid_rmsle: 0.01516 | valid_mae: 0.42215 | valid_rmse: 0.50765 | valid_mse: 0.25771 |  0:00:32s\n",
      "epoch 18 | loss: 0.23232 | train_rmsle: 0.01849 | train_mae: 0.47464 | train_rmse: 0.56125 | train_mse: 0.31501 | valid_rmsle: 0.01814 | valid_mae: 0.47615 | valid_rmse: 0.56058 | valid_mse: 0.31425 |  0:00:33s\n",
      "epoch 19 | loss: 0.22708 | train_rmsle: 0.01444 | train_mae: 0.39027 | train_rmse: 0.48382 | train_mse: 0.23409 | valid_rmsle: 0.01389 | valid_mae: 0.39155 | valid_rmse: 0.48025 | valid_mse: 0.23064 |  0:00:35s\n",
      "epoch 20 | loss: 0.22713 | train_rmsle: 0.01436 | train_mae: 0.37623 | train_rmse: 0.47716 | train_mse: 0.22768 | valid_rmsle: 0.01365 | valid_mae: 0.3745  | valid_rmse: 0.47003 | valid_mse: 0.22093 |  0:00:37s\n",
      "epoch 21 | loss: 0.22027 | train_rmsle: 0.01419 | train_mae: 0.37783 | train_rmse: 0.4762  | train_mse: 0.22676 | valid_rmsle: 0.01381 | valid_mae: 0.38342 | valid_rmse: 0.47526 | valid_mse: 0.22587 |  0:00:39s\n",
      "epoch 22 | loss: 0.22117 | train_rmsle: 0.01406 | train_mae: 0.37748 | train_rmse: 0.47429 | train_mse: 0.22495 | valid_rmsle: 0.01366 | valid_mae: 0.38223 | valid_rmse: 0.47309 | valid_mse: 0.22381 |  0:00:41s\n",
      "epoch 23 | loss: 0.22468 | train_rmsle: 0.0151  | train_mae: 0.41344 | train_rmse: 0.50105 | train_mse: 0.25105 | valid_rmsle: 0.0147  | valid_mae: 0.41509 | valid_rmse: 0.4994  | valid_mse: 0.2494  |  0:00:42s\n",
      "epoch 24 | loss: 0.22041 | train_rmsle: 0.0141  | train_mae: 0.39526 | train_rmse: 0.48177 | train_mse: 0.2321  | valid_rmsle: 0.01339 | valid_mae: 0.39319 | valid_rmse: 0.47457 | valid_mse: 0.22521 |  0:00:44s\n",
      "epoch 25 | loss: 0.20996 | train_rmsle: 0.0126  | train_mae: 0.3592  | train_rmse: 0.44942 | train_mse: 0.20198 | valid_rmsle: 0.01201 | valid_mae: 0.36037 | valid_rmse: 0.44355 | valid_mse: 0.19673 |  0:00:46s\n",
      "epoch 26 | loss: 0.20797 | train_rmsle: 0.01213 | train_mae: 0.35732 | train_rmse: 0.44323 | train_mse: 0.19645 | valid_rmsle: 0.01172 | valid_mae: 0.36145 | valid_rmse: 0.4398  | valid_mse: 0.19343 |  0:00:48s\n",
      "epoch 27 | loss: 0.18698 | train_rmsle: 0.01097 | train_mae: 0.34037 | train_rmse: 0.42189 | train_mse: 0.17799 | valid_rmsle: 0.01072 | valid_mae: 0.34508 | valid_rmse: 0.42164 | valid_mse: 0.17778 |  0:00:50s\n",
      "epoch 28 | loss: 0.17233 | train_rmsle: 0.0095  | train_mae: 0.31185 | train_rmse: 0.39013 | train_mse: 0.1522  | valid_rmsle: 0.00941 | valid_mae: 0.31922 | valid_rmse: 0.39316 | valid_mse: 0.15457 |  0:00:51s\n",
      "epoch 29 | loss: 0.15498 | train_rmsle: 0.00887 | train_mae: 0.29005 | train_rmse: 0.37115 | train_mse: 0.13775 | valid_rmsle: 0.0087  | valid_mae: 0.29742 | valid_rmse: 0.37251 | valid_mse: 0.13876 |  0:00:53s\n",
      "epoch 30 | loss: 0.14326 | train_rmsle: 0.00917 | train_mae: 0.31167 | train_rmse: 0.38438 | train_mse: 0.14775 | valid_rmsle: 0.00894 | valid_mae: 0.31658 | valid_rmse: 0.385   | valid_mse: 0.14823 |  0:00:55s\n",
      "epoch 31 | loss: 0.12799 | train_rmsle: 0.00898 | train_mae: 0.30763 | train_rmse: 0.37941 | train_mse: 0.14395 | valid_rmsle: 0.00864 | valid_mae: 0.30639 | valid_rmse: 0.37615 | valid_mse: 0.14149 |  0:00:57s\n",
      "epoch 32 | loss: 0.12269 | train_rmsle: 0.00828 | train_mae: 0.2744  | train_rmse: 0.35809 | train_mse: 0.12823 | valid_rmsle: 0.0081  | valid_mae: 0.27737 | valid_rmse: 0.3591  | valid_mse: 0.12895 |  0:00:58s\n",
      "epoch 33 | loss: 0.1191  | train_rmsle: 0.00733 | train_mae: 0.26686 | train_rmse: 0.33823 | train_mse: 0.1144  | valid_rmsle: 0.00678 | valid_mae: 0.26433 | valid_rmse: 0.33066 | valid_mse: 0.10934 |  0:01:00s\n",
      "epoch 34 | loss: 0.11742 | train_rmsle: 0.00712 | train_mae: 0.26019 | train_rmse: 0.33226 | train_mse: 0.1104  | valid_rmsle: 0.00663 | valid_mae: 0.25694 | valid_rmse: 0.3258  | valid_mse: 0.10614 |  0:01:02s\n",
      "epoch 35 | loss: 0.10836 | train_rmsle: 0.00701 | train_mae: 0.2542  | train_rmse: 0.32828 | train_mse: 0.10777 | valid_rmsle: 0.00668 | valid_mae: 0.25227 | valid_rmse: 0.32623 | valid_mse: 0.10643 |  0:01:04s\n",
      "epoch 36 | loss: 0.10235 | train_rmsle: 0.00658 | train_mae: 0.25007 | train_rmse: 0.31901 | train_mse: 0.10177 | valid_rmsle: 0.0063  | valid_mae: 0.24874 | valid_rmse: 0.31765 | valid_mse: 0.1009  |  0:01:06s\n",
      "epoch 37 | loss: 0.09279 | train_rmsle: 0.00612 | train_mae: 0.24108 | train_rmse: 0.30786 | train_mse: 0.09478 | valid_rmsle: 0.00594 | valid_mae: 0.24291 | valid_rmse: 0.30896 | valid_mse: 0.09545 |  0:01:07s\n",
      "epoch 38 | loss: 0.08841 | train_rmsle: 0.00534 | train_mae: 0.22364 | train_rmse: 0.28729 | train_mse: 0.08253 | valid_rmsle: 0.00534 | valid_mae: 0.2289  | valid_rmse: 0.29344 | valid_mse: 0.08611 |  0:01:09s\n",
      "epoch 39 | loss: 0.07817 | train_rmsle: 0.00507 | train_mae: 0.22235 | train_rmse: 0.28249 | train_mse: 0.0798  | valid_rmsle: 0.00501 | valid_mae: 0.22823 | valid_rmse: 0.28633 | valid_mse: 0.08199 |  0:01:11s\n",
      "epoch 40 | loss: 0.07358 | train_rmsle: 0.00444 | train_mae: 0.19867 | train_rmse: 0.26003 | train_mse: 0.06762 | valid_rmsle: 0.00448 | valid_mae: 0.20557 | valid_rmse: 0.26756 | valid_mse: 0.07159 |  0:01:13s\n",
      "epoch 41 | loss: 0.0679  | train_rmsle: 0.00403 | train_mae: 0.19206 | train_rmse: 0.24937 | train_mse: 0.06219 | valid_rmsle: 0.00419 | valid_mae: 0.20156 | valid_rmse: 0.25996 | valid_mse: 0.06758 |  0:01:14s\n",
      "epoch 42 | loss: 0.06227 | train_rmsle: 0.00448 | train_mae: 0.21332 | train_rmse: 0.26958 | train_mse: 0.07267 | valid_rmsle: 0.00476 | valid_mae: 0.22572 | valid_rmse: 0.28246 | valid_mse: 0.07978 |  0:01:16s\n",
      "epoch 43 | loss: 0.06843 | train_rmsle: 0.00408 | train_mae: 0.20425 | train_rmse: 0.25802 | train_mse: 0.06657 | valid_rmsle: 0.00438 | valid_mae: 0.21705 | valid_rmse: 0.2722  | valid_mse: 0.07409 |  0:01:18s\n",
      "epoch 44 | loss: 0.06216 | train_rmsle: 0.00375 | train_mae: 0.193   | train_rmse: 0.24547 | train_mse: 0.06025 | valid_rmsle: 0.00403 | valid_mae: 0.20285 | valid_rmse: 0.25892 | valid_mse: 0.06704 |  0:01:20s\n",
      "epoch 45 | loss: 0.05988 | train_rmsle: 0.00354 | train_mae: 0.18902 | train_rmse: 0.24008 | train_mse: 0.05764 | valid_rmsle: 0.00392 | valid_mae: 0.20155 | valid_rmse: 0.25687 | valid_mse: 0.06598 |  0:01:22s\n",
      "epoch 46 | loss: 0.05411 | train_rmsle: 0.00301 | train_mae: 0.16896 | train_rmse: 0.21803 | train_mse: 0.04754 | valid_rmsle: 0.00334 | valid_mae: 0.18108 | valid_rmse: 0.23494 | valid_mse: 0.0552  |  0:01:23s\n",
      "epoch 47 | loss: 0.05352 | train_rmsle: 0.00308 | train_mae: 0.17486 | train_rmse: 0.22349 | train_mse: 0.04995 | valid_rmsle: 0.0034  | valid_mae: 0.1864  | valid_rmse: 0.23904 | valid_mse: 0.05714 |  0:01:25s\n",
      "epoch 48 | loss: 0.05186 | train_rmsle: 0.00364 | train_mae: 0.19672 | train_rmse: 0.24702 | train_mse: 0.06102 | valid_rmsle: 0.00403 | valid_mae: 0.2091  | valid_rmse: 0.26217 | valid_mse: 0.06873 |  0:01:27s\n",
      "epoch 49 | loss: 0.04604 | train_rmsle: 0.00244 | train_mae: 0.1567  | train_rmse: 0.20081 | train_mse: 0.04032 | valid_rmsle: 0.00282 | valid_mae: 0.17222 | valid_rmse: 0.21962 | valid_mse: 0.04823 |  0:01:29s\n",
      "epoch 50 | loss: 0.04362 | train_rmsle: 0.00254 | train_mae: 0.16513 | train_rmse: 0.20861 | train_mse: 0.04352 | valid_rmsle: 0.00297 | valid_mae: 0.17842 | valid_rmse: 0.22794 | valid_mse: 0.05196 |  0:01:31s\n",
      "epoch 51 | loss: 0.0413  | train_rmsle: 0.00227 | train_mae: 0.15022 | train_rmse: 0.1935  | train_mse: 0.03744 | valid_rmsle: 0.0026  | valid_mae: 0.16391 | valid_rmse: 0.21173 | valid_mse: 0.04483 |  0:01:32s\n",
      "epoch 52 | loss: 0.04036 | train_rmsle: 0.0022  | train_mae: 0.14863 | train_rmse: 0.19201 | train_mse: 0.03687 | valid_rmsle: 0.00254 | valid_mae: 0.16379 | valid_rmse: 0.20998 | valid_mse: 0.04409 |  0:01:34s\n",
      "epoch 53 | loss: 0.05199 | train_rmsle: 0.00427 | train_mae: 0.20824 | train_rmse: 0.26684 | train_mse: 0.0712  | valid_rmsle: 0.00462 | valid_mae: 0.21804 | valid_rmse: 0.28067 | valid_mse: 0.07877 |  0:01:36s\n",
      "epoch 54 | loss: 0.04754 | train_rmsle: 0.00365 | train_mae: 0.18867 | train_rmse: 0.23778 | train_mse: 0.05654 | valid_rmsle: 0.00402 | valid_mae: 0.20017 | valid_rmse: 0.25293 | valid_mse: 0.06397 |  0:01:38s\n",
      "epoch 55 | loss: 0.04636 | train_rmsle: 0.00264 | train_mae: 0.16311 | train_rmse: 0.21052 | train_mse: 0.04432 | valid_rmsle: 0.00301 | valid_mae: 0.17366 | valid_rmse: 0.22676 | valid_mse: 0.05142 |  0:01:39s\n",
      "epoch 56 | loss: 0.04871 | train_rmsle: 0.00441 | train_mae: 0.22596 | train_rmse: 0.27326 | train_mse: 0.07467 | valid_rmsle: 0.00475 | valid_mae: 0.23371 | valid_rmse: 0.28547 | valid_mse: 0.08149 |  0:01:41s\n",
      "epoch 57 | loss: 0.04426 | train_rmsle: 0.00245 | train_mae: 0.15582 | train_rmse: 0.20345 | train_mse: 0.04139 | valid_rmsle: 0.0028  | valid_mae: 0.16595 | valid_rmse: 0.21913 | valid_mse: 0.04802 |  0:01:43s\n",
      "epoch 58 | loss: 0.04137 | train_rmsle: 0.00447 | train_mae: 0.20575 | train_rmse: 0.26542 | train_mse: 0.07045 | valid_rmsle: 0.00455 | valid_mae: 0.21599 | valid_rmse: 0.27419 | valid_mse: 0.07518 |  0:01:45s\n",
      "epoch 59 | loss: 0.03759 | train_rmsle: 0.00194 | train_mae: 0.14083 | train_rmse: 0.18345 | train_mse: 0.03366 | valid_rmsle: 0.0022  | valid_mae: 0.1549  | valid_rmse: 0.19764 | valid_mse: 0.03906 |  0:01:47s\n",
      "epoch 60 | loss: 0.03816 | train_rmsle: 0.00181 | train_mae: 0.1403  | train_rmse: 0.18088 | train_mse: 0.03272 | valid_rmsle: 0.00205 | valid_mae: 0.15032 | valid_rmse: 0.19286 | valid_mse: 0.03719 |  0:01:48s\n",
      "epoch 61 | loss: 0.03948 | train_rmsle: 0.00159 | train_mae: 0.1308  | train_rmse: 0.16884 | train_mse: 0.02851 | valid_rmsle: 0.00185 | valid_mae: 0.14091 | valid_rmse: 0.18299 | valid_mse: 0.03348 |  0:01:50s\n",
      "epoch 62 | loss: 0.0313  | train_rmsle: 0.0015  | train_mae: 0.1275  | train_rmse: 0.16406 | train_mse: 0.02692 | valid_rmsle: 0.00171 | valid_mae: 0.13696 | valid_rmse: 0.17511 | valid_mse: 0.03066 |  0:01:52s\n",
      "epoch 63 | loss: 0.03199 | train_rmsle: 0.00142 | train_mae: 0.12386 | train_rmse: 0.15863 | train_mse: 0.02516 | valid_rmsle: 0.0016  | valid_mae: 0.13189 | valid_rmse: 0.16891 | valid_mse: 0.02853 |  0:01:54s\n",
      "epoch 64 | loss: 0.03071 | train_rmsle: 0.00148 | train_mae: 0.12574 | train_rmse: 0.16059 | train_mse: 0.02579 | valid_rmsle: 0.0017  | valid_mae: 0.13689 | valid_rmse: 0.1735  | valid_mse: 0.0301  |  0:01:55s\n",
      "epoch 65 | loss: 0.03283 | train_rmsle: 0.0014  | train_mae: 0.12285 | train_rmse: 0.15862 | train_mse: 0.02516 | valid_rmsle: 0.00174 | valid_mae: 0.13547 | valid_rmse: 0.1764  | valid_mse: 0.03112 |  0:01:57s\n",
      "epoch 66 | loss: 0.03    | train_rmsle: 0.00173 | train_mae: 0.1379  | train_rmse: 0.17758 | train_mse: 0.03153 | valid_rmsle: 0.00208 | valid_mae: 0.14898 | valid_rmse: 0.19336 | valid_mse: 0.03739 |  0:01:59s\n",
      "epoch 67 | loss: 0.0297  | train_rmsle: 0.00283 | train_mae: 0.15929 | train_rmse: 0.20087 | train_mse: 0.04035 | valid_rmsle: 0.00289 | valid_mae: 0.16868 | valid_rmse: 0.2094  | valid_mse: 0.04385 |  0:02:01s\n",
      "epoch 68 | loss: 0.02984 | train_rmsle: 0.00229 | train_mae: 0.14921 | train_rmse: 0.1894  | train_mse: 0.03587 | valid_rmsle: 0.00251 | valid_mae: 0.16149 | valid_rmse: 0.20432 | valid_mse: 0.04175 |  0:02:03s\n",
      "epoch 69 | loss: 0.03489 | train_rmsle: 0.00152 | train_mae: 0.12897 | train_rmse: 0.16416 | train_mse: 0.02695 | valid_rmsle: 0.0018  | valid_mae: 0.14089 | valid_rmse: 0.17987 | valid_mse: 0.03235 |  0:02:04s\n",
      "epoch 70 | loss: 0.03332 | train_rmsle: 0.00316 | train_mae: 0.17572 | train_rmse: 0.21587 | train_mse: 0.0466  | valid_rmsle: 0.0033  | valid_mae: 0.18383 | valid_rmse: 0.22429 | valid_mse: 0.05031 |  0:02:06s\n",
      "epoch 71 | loss: 0.03416 | train_rmsle: 0.00221 | train_mae: 0.15482 | train_rmse: 0.19662 | train_mse: 0.03866 | valid_rmsle: 0.00237 | valid_mae: 0.15938 | valid_rmse: 0.20573 | valid_mse: 0.04233 |  0:02:08s\n",
      "epoch 72 | loss: 0.03346 | train_rmsle: 0.00232 | train_mae: 0.16063 | train_rmse: 0.19955 | train_mse: 0.03982 | valid_rmsle: 0.00256 | valid_mae: 0.17128 | valid_rmse: 0.2118  | valid_mse: 0.04486 |  0:02:10s\n",
      "epoch 73 | loss: 0.03217 | train_rmsle: 0.00143 | train_mae: 0.12531 | train_rmse: 0.15899 | train_mse: 0.02528 | valid_rmsle: 0.00173 | valid_mae: 0.13688 | valid_rmse: 0.17592 | valid_mse: 0.03095 |  0:02:11s\n",
      "epoch 74 | loss: 0.02738 | train_rmsle: 0.00124 | train_mae: 0.1175  | train_rmse: 0.14946 | train_mse: 0.02234 | valid_rmsle: 0.00157 | valid_mae: 0.13144 | valid_rmse: 0.1682  | valid_mse: 0.02829 |  0:02:13s\n",
      "epoch 75 | loss: 0.02598 | train_rmsle: 0.00123 | train_mae: 0.11789 | train_rmse: 0.14936 | train_mse: 0.02231 | valid_rmsle: 0.00158 | valid_mae: 0.13316 | valid_rmse: 0.16907 | valid_mse: 0.02858 |  0:02:15s\n",
      "epoch 76 | loss: 0.02635 | train_rmsle: 0.00252 | train_mae: 0.17141 | train_rmse: 0.20473 | train_mse: 0.04192 | valid_rmsle: 0.00285 | valid_mae: 0.18361 | valid_rmse: 0.21914 | valid_mse: 0.04802 |  0:02:17s\n",
      "epoch 77 | loss: 0.02741 | train_rmsle: 0.0013  | train_mae: 0.12067 | train_rmse: 0.15112 | train_mse: 0.02284 | valid_rmsle: 0.00163 | valid_mae: 0.13451 | valid_rmse: 0.16911 | valid_mse: 0.0286  |  0:02:19s\n",
      "epoch 78 | loss: 0.02335 | train_rmsle: 0.00237 | train_mae: 0.13484 | train_rmse: 0.17873 | train_mse: 0.03194 | valid_rmsle: 0.00278 | valid_mae: 0.1436  | valid_rmse: 0.19541 | valid_mse: 0.03819 |  0:02:20s\n",
      "epoch 79 | loss: 0.02825 | train_rmsle: 0.00108 | train_mae: 0.10611 | train_rmse: 0.13526 | train_mse: 0.0183  | valid_rmsle: 0.00133 | valid_mae: 0.11892 | valid_rmse: 0.15182 | valid_mse: 0.02305 |  0:02:22s\n",
      "epoch 80 | loss: 0.02202 | train_rmsle: 0.00114 | train_mae: 0.10855 | train_rmse: 0.13776 | train_mse: 0.01898 | valid_rmsle: 0.00131 | valid_mae: 0.11719 | valid_rmse: 0.14966 | valid_mse: 0.0224  |  0:02:24s\n",
      "epoch 81 | loss: 0.02289 | train_rmsle: 0.00094 | train_mae: 0.10172 | train_rmse: 0.12917 | train_mse: 0.01668 | valid_rmsle: 0.00117 | valid_mae: 0.11457 | valid_rmse: 0.1447  | valid_mse: 0.02094 |  0:02:26s\n",
      "epoch 82 | loss: 0.02165 | train_rmsle: 0.00104 | train_mae: 0.10317 | train_rmse: 0.13101 | train_mse: 0.01716 | valid_rmsle: 0.00125 | valid_mae: 0.1127  | valid_rmse: 0.14489 | valid_mse: 0.02099 |  0:02:27s\n",
      "epoch 83 | loss: 0.02065 | train_rmsle: 0.00121 | train_mae: 0.11631 | train_rmse: 0.14469 | train_mse: 0.02093 | valid_rmsle: 0.00149 | valid_mae: 0.13038 | valid_rmse: 0.16063 | valid_mse: 0.0258  |  0:02:29s\n",
      "epoch 84 | loss: 0.0187  | train_rmsle: 0.00109 | train_mae: 0.10585 | train_rmse: 0.13258 | train_mse: 0.01758 | valid_rmsle: 0.00135 | valid_mae: 0.11772 | valid_rmse: 0.1483  | valid_mse: 0.02199 |  0:02:31s\n",
      "epoch 85 | loss: 0.01815 | train_rmsle: 0.00177 | train_mae: 0.13777 | train_rmse: 0.1696  | train_mse: 0.02876 | valid_rmsle: 0.00206 | valid_mae: 0.14943 | valid_rmse: 0.18442 | valid_mse: 0.03401 |  0:02:33s\n",
      "epoch 86 | loss: 0.02097 | train_rmsle: 0.00228 | train_mae: 0.14293 | train_rmse: 0.18    | train_mse: 0.0324  | valid_rmsle: 0.00263 | valid_mae: 0.1545  | valid_rmse: 0.19506 | valid_mse: 0.03805 |  0:02:35s\n",
      "epoch 87 | loss: 0.02083 | train_rmsle: 0.00367 | train_mae: 0.17324 | train_rmse: 0.21896 | train_mse: 0.04794 | valid_rmsle: 0.00408 | valid_mae: 0.18541 | valid_rmse: 0.23301 | valid_mse: 0.0543  |  0:02:36s\n",
      "epoch 88 | loss: 0.02033 | train_rmsle: 0.00104 | train_mae: 0.1078  | train_rmse: 0.13797 | train_mse: 0.01904 | valid_rmsle: 0.00127 | valid_mae: 0.11675 | valid_rmse: 0.15279 | valid_mse: 0.02334 |  0:02:38s\n",
      "epoch 89 | loss: 0.02855 | train_rmsle: 0.00146 | train_mae: 0.11939 | train_rmse: 0.14945 | train_mse: 0.02233 | valid_rmsle: 0.00168 | valid_mae: 0.12938 | valid_rmse: 0.1613  | valid_mse: 0.02602 |  0:02:40s\n",
      "epoch 90 | loss: 0.02375 | train_rmsle: 0.00157 | train_mae: 0.13569 | train_rmse: 0.16349 | train_mse: 0.02673 | valid_rmsle: 0.00178 | valid_mae: 0.14475 | valid_rmse: 0.17402 | valid_mse: 0.03028 |  0:02:42s\n",
      "epoch 91 | loss: 0.02017 | train_rmsle: 0.00094 | train_mae: 0.1027  | train_rmse: 0.12822 | train_mse: 0.01644 | valid_rmsle: 0.00112 | valid_mae: 0.11322 | valid_rmse: 0.14019 | valid_mse: 0.01965 |  0:02:43s\n",
      "epoch 92 | loss: 0.01828 | train_rmsle: 0.00066 | train_mae: 0.08479 | train_rmse: 0.10881 | train_mse: 0.01184 | valid_rmsle: 0.00084 | valid_mae: 0.09434 | valid_rmse: 0.12248 | valid_mse: 0.015   |  0:02:45s\n",
      "epoch 93 | loss: 0.02062 | train_rmsle: 0.0016  | train_mae: 0.14328 | train_rmse: 0.17344 | train_mse: 0.03008 | valid_rmsle: 0.00173 | valid_mae: 0.14918 | valid_rmse: 0.18038 | valid_mse: 0.03254 |  0:02:47s\n",
      "epoch 94 | loss: 0.02869 | train_rmsle: 0.00089 | train_mae: 0.10173 | train_rmse: 0.12821 | train_mse: 0.01644 | valid_rmsle: 0.00104 | valid_mae: 0.11079 | valid_rmse: 0.13855 | valid_mse: 0.0192  |  0:02:49s\n",
      "epoch 95 | loss: 0.01927 | train_rmsle: 0.00069 | train_mae: 0.08609 | train_rmse: 0.11007 | train_mse: 0.01212 | valid_rmsle: 0.00085 | valid_mae: 0.09699 | valid_rmse: 0.12271 | valid_mse: 0.01506 |  0:02:51s\n",
      "epoch 96 | loss: 0.01803 | train_rmsle: 0.00065 | train_mae: 0.0844  | train_rmse: 0.10772 | train_mse: 0.0116  | valid_rmsle: 0.00084 | valid_mae: 0.09541 | valid_rmse: 0.12182 | valid_mse: 0.01484 |  0:02:52s\n",
      "epoch 97 | loss: 0.01619 | train_rmsle: 0.00058 | train_mae: 0.0803  | train_rmse: 0.10269 | train_mse: 0.01055 | valid_rmsle: 0.00076 | valid_mae: 0.09058 | valid_rmse: 0.11687 | valid_mse: 0.01366 |  0:02:54s\n",
      "epoch 98 | loss: 0.01533 | train_rmsle: 0.00076 | train_mae: 0.09429 | train_rmse: 0.11936 | train_mse: 0.01425 | valid_rmsle: 0.00091 | valid_mae: 0.10292 | valid_rmse: 0.12994 | valid_mse: 0.01688 |  0:02:56s\n",
      "epoch 99 | loss: 0.01509 | train_rmsle: 0.0006  | train_mae: 0.07958 | train_rmse: 0.10176 | train_mse: 0.01035 | valid_rmsle: 0.00075 | valid_mae: 0.08873 | valid_rmse: 0.11431 | valid_mse: 0.01307 |  0:02:58s\n",
      "epoch 100| loss: 0.01629 | train_rmsle: 0.00053 | train_mae: 0.07643 | train_rmse: 0.09767 | train_mse: 0.00954 | valid_rmsle: 0.00071 | valid_mae: 0.08623 | valid_rmse: 0.11191 | valid_mse: 0.01252 |  0:03:00s\n",
      "epoch 101| loss: 0.01542 | train_rmsle: 0.00131 | train_mae: 0.12513 | train_rmse: 0.1488  | train_mse: 0.02214 | valid_rmsle: 0.00146 | valid_mae: 0.13173 | valid_rmse: 0.15758 | valid_mse: 0.02483 |  0:03:01s\n",
      "epoch 102| loss: 0.02027 | train_rmsle: 0.00821 | train_mae: 0.21014 | train_rmse: 0.29893 | train_mse: 0.08936 | valid_rmsle: 0.00802 | valid_mae: 0.21358 | valid_rmse: 0.29844 | valid_mse: 0.08907 |  0:03:03s\n",
      "epoch 103| loss: 0.02318 | train_rmsle: 0.00176 | train_mae: 0.12678 | train_rmse: 0.1616  | train_mse: 0.02611 | valid_rmsle: 0.00197 | valid_mae: 0.13363 | valid_rmse: 0.17248 | valid_mse: 0.02975 |  0:03:05s\n",
      "epoch 104| loss: 0.0208  | train_rmsle: 0.001   | train_mae: 0.09691 | train_rmse: 0.12533 | train_mse: 0.01571 | valid_rmsle: 0.00122 | valid_mae: 0.10719 | valid_rmse: 0.13873 | valid_mse: 0.01925 |  0:03:07s\n",
      "epoch 105| loss: 0.02047 | train_rmsle: 0.00101 | train_mae: 0.10918 | train_rmse: 0.13727 | train_mse: 0.01884 | valid_rmsle: 0.00118 | valid_mae: 0.11774 | valid_rmse: 0.1475  | valid_mse: 0.02176 |  0:03:08s\n",
      "epoch 106| loss: 0.01738 | train_rmsle: 0.00073 | train_mae: 0.08885 | train_rmse: 0.11415 | train_mse: 0.01303 | valid_rmsle: 0.00091 | valid_mae: 0.10004 | valid_rmse: 0.12733 | valid_mse: 0.01621 |  0:03:10s\n",
      "epoch 107| loss: 0.01637 | train_rmsle: 0.00103 | train_mae: 0.09772 | train_rmse: 0.12475 | train_mse: 0.01556 | valid_rmsle: 0.0012  | valid_mae: 0.10804 | valid_rmse: 0.1371  | valid_mse: 0.0188  |  0:03:12s\n",
      "epoch 108| loss: 0.01594 | train_rmsle: 0.00075 | train_mae: 0.08869 | train_rmse: 0.1131  | train_mse: 0.01279 | valid_rmsle: 0.00092 | valid_mae: 0.09994 | valid_rmse: 0.12599 | valid_mse: 0.01587 |  0:03:14s\n",
      "epoch 109| loss: 0.01994 | train_rmsle: 0.00169 | train_mae: 0.14124 | train_rmse: 0.16625 | train_mse: 0.02764 | valid_rmsle: 0.00189 | valid_mae: 0.14813 | valid_rmse: 0.178   | valid_mse: 0.03168 |  0:03:16s\n",
      "epoch 110| loss: 0.02002 | train_rmsle: 0.00067 | train_mae: 0.08403 | train_rmse: 0.10693 | train_mse: 0.01143 | valid_rmsle: 0.00086 | valid_mae: 0.09512 | valid_rmse: 0.12173 | valid_mse: 0.01482 |  0:03:17s\n",
      "epoch 111| loss: 0.01545 | train_rmsle: 0.0005  | train_mae: 0.0718  | train_rmse: 0.09285 | train_mse: 0.00862 | valid_rmsle: 0.00066 | valid_mae: 0.08334 | valid_rmse: 0.10705 | valid_mse: 0.01146 |  0:03:19s\n",
      "epoch 112| loss: 0.01407 | train_rmsle: 0.00053 | train_mae: 0.07641 | train_rmse: 0.09844 | train_mse: 0.00969 | valid_rmsle: 0.00072 | valid_mae: 0.08743 | valid_rmse: 0.11367 | valid_mse: 0.01292 |  0:03:21s\n",
      "epoch 113| loss: 0.0163  | train_rmsle: 0.00058 | train_mae: 0.08058 | train_rmse: 0.10192 | train_mse: 0.01039 | valid_rmsle: 0.00071 | valid_mae: 0.08967 | valid_rmse: 0.11202 | valid_mse: 0.01255 |  0:03:23s\n",
      "epoch 114| loss: 0.01337 | train_rmsle: 0.00069 | train_mae: 0.0895  | train_rmse: 0.11143 | train_mse: 0.01242 | valid_rmsle: 0.00081 | valid_mae: 0.09649 | valid_rmse: 0.12075 | valid_mse: 0.01458 |  0:03:24s\n",
      "epoch 115| loss: 0.01374 | train_rmsle: 0.00047 | train_mae: 0.07092 | train_rmse: 0.09048 | train_mse: 0.00819 | valid_rmsle: 0.0006  | valid_mae: 0.07942 | valid_rmse: 0.10154 | valid_mse: 0.01031 |  0:03:26s\n",
      "epoch 116| loss: 0.0149  | train_rmsle: 0.00081 | train_mae: 0.09182 | train_rmse: 0.11439 | train_mse: 0.01308 | valid_rmsle: 0.00091 | valid_mae: 0.09815 | valid_rmse: 0.12246 | valid_mse: 0.015   |  0:03:28s\n",
      "epoch 117| loss: 0.01306 | train_rmsle: 0.00094 | train_mae: 0.10882 | train_rmse: 0.13265 | train_mse: 0.0176  | valid_rmsle: 0.00106 | valid_mae: 0.11584 | valid_rmse: 0.14081 | valid_mse: 0.01983 |  0:03:30s\n",
      "epoch 118| loss: 0.01476 | train_rmsle: 0.00069 | train_mae: 0.09002 | train_rmse: 0.11358 | train_mse: 0.0129  | valid_rmsle: 0.00082 | valid_mae: 0.09883 | valid_rmse: 0.12319 | valid_mse: 0.01517 |  0:03:31s\n",
      "epoch 119| loss: 0.01833 | train_rmsle: 0.00313 | train_mae: 0.16259 | train_rmse: 0.21749 | train_mse: 0.0473  | valid_rmsle: 0.00304 | valid_mae: 0.16204 | valid_rmse: 0.21625 | valid_mse: 0.04676 |  0:03:33s\n",
      "epoch 120| loss: 0.01988 | train_rmsle: 0.00137 | train_mae: 0.10607 | train_rmse: 0.13811 | train_mse: 0.01908 | valid_rmsle: 0.00145 | valid_mae: 0.11254 | valid_rmse: 0.14464 | valid_mse: 0.02092 |  0:03:35s\n",
      "epoch 121| loss: 0.02062 | train_rmsle: 0.00071 | train_mae: 0.08483 | train_rmse: 0.10929 | train_mse: 0.01194 | valid_rmsle: 0.00085 | valid_mae: 0.09468 | valid_rmse: 0.12025 | valid_mse: 0.01446 |  0:03:37s\n",
      "epoch 122| loss: 0.01515 | train_rmsle: 0.00071 | train_mae: 0.08782 | train_rmse: 0.11213 | train_mse: 0.01257 | valid_rmsle: 0.00085 | valid_mae: 0.09738 | valid_rmse: 0.12328 | valid_mse: 0.0152  |  0:03:38s\n",
      "epoch 123| loss: 0.02151 | train_rmsle: 0.00174 | train_mae: 0.15085 | train_rmse: 0.17486 | train_mse: 0.03058 | valid_rmsle: 0.00187 | valid_mae: 0.15296 | valid_rmse: 0.18044 | valid_mse: 0.03256 |  0:03:40s\n",
      "epoch 124| loss: 0.01805 | train_rmsle: 0.00068 | train_mae: 0.08451 | train_rmse: 0.10809 | train_mse: 0.01168 | valid_rmsle: 0.0008  | valid_mae: 0.09224 | valid_rmse: 0.11769 | valid_mse: 0.01385 |  0:03:42s\n",
      "epoch 125| loss: 0.02229 | train_rmsle: 0.00051 | train_mae: 0.07318 | train_rmse: 0.09425 | train_mse: 0.00888 | valid_rmsle: 0.00065 | valid_mae: 0.08317 | valid_rmse: 0.10625 | valid_mse: 0.01129 |  0:03:44s\n",
      "epoch 126| loss: 0.01686 | train_rmsle: 0.00072 | train_mae: 0.08825 | train_rmse: 0.11169 | train_mse: 0.01247 | valid_rmsle: 0.00091 | valid_mae: 0.0992  | valid_rmse: 0.12576 | valid_mse: 0.01582 |  0:03:46s\n",
      "epoch 127| loss: 0.01735 | train_rmsle: 0.00061 | train_mae: 0.08213 | train_rmse: 0.10512 | train_mse: 0.01105 | valid_rmsle: 0.00077 | valid_mae: 0.09054 | valid_rmse: 0.11662 | valid_mse: 0.0136  |  0:03:47s\n",
      "epoch 128| loss: 0.01783 | train_rmsle: 0.00065 | train_mae: 0.0868  | train_rmse: 0.11012 | train_mse: 0.01213 | valid_rmsle: 0.0008  | valid_mae: 0.09504 | valid_rmse: 0.121   | valid_mse: 0.01464 |  0:03:49s\n",
      "epoch 129| loss: 0.0169  | train_rmsle: 0.00127 | train_mae: 0.11879 | train_rmse: 0.15338 | train_mse: 0.02352 | valid_rmsle: 0.0014  | valid_mae: 0.12584 | valid_rmse: 0.16032 | valid_mse: 0.0257  |  0:03:51s\n",
      "epoch 130| loss: 0.02304 | train_rmsle: 0.00105 | train_mae: 0.10786 | train_rmse: 0.13883 | train_mse: 0.01927 | valid_rmsle: 0.00121 | valid_mae: 0.11585 | valid_rmse: 0.14764 | valid_mse: 0.0218  |  0:03:53s\n",
      "epoch 131| loss: 0.02347 | train_rmsle: 0.00501 | train_mae: 0.17925 | train_rmse: 0.23984 | train_mse: 0.05753 | valid_rmsle: 0.00513 | valid_mae: 0.18188 | valid_rmse: 0.24293 | valid_mse: 0.05901 |  0:03:54s\n",
      "epoch 132| loss: 0.02288 | train_rmsle: 0.00318 | train_mae: 0.15875 | train_rmse: 0.20225 | train_mse: 0.04091 | valid_rmsle: 0.00329 | valid_mae: 0.16168 | valid_rmse: 0.2075  | valid_mse: 0.04306 |  0:03:56s\n",
      "epoch 133| loss: 0.02046 | train_rmsle: 0.00235 | train_mae: 0.13251 | train_rmse: 0.17665 | train_mse: 0.03121 | valid_rmsle: 0.0024  | valid_mae: 0.13865 | valid_rmse: 0.18376 | valid_mse: 0.03377 |  0:03:58s\n",
      "epoch 134| loss: 0.01913 | train_rmsle: 0.00159 | train_mae: 0.1204  | train_rmse: 0.15093 | train_mse: 0.02278 | valid_rmsle: 0.00178 | valid_mae: 0.12598 | valid_rmse: 0.16058 | valid_mse: 0.02578 |  0:04:00s\n",
      "epoch 135| loss: 0.01839 | train_rmsle: 0.00064 | train_mae: 0.08389 | train_rmse: 0.10717 | train_mse: 0.01149 | valid_rmsle: 0.0008  | valid_mae: 0.09329 | valid_rmse: 0.11942 | valid_mse: 0.01426 |  0:04:02s\n",
      "\n",
      "Early stopping occurred at epoch 135 with best_epoch = 115 and best_valid_mse = 0.01031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0107312294857083 RMSE: 0.1035916477603687 R2: 0.9524969820088199 MAE: 0.08327417851273673\n",
      "=====================================\n",
      "[65/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.80104 | train_rmsle: 0.28098 | train_mae: 1.73958 | train_rmse: 1.80559 | train_mse: 3.26014 | valid_rmsle: 0.2819  | valid_mae: 1.74488 | valid_rmse: 1.80973 | valid_mse: 3.27511 |  0:00:01s\n",
      "epoch 1  | loss: 1.04399 | train_rmsle: 0.06962 | train_mae: 0.94459 | train_rmse: 1.03616 | train_mse: 1.07364 | valid_rmsle: 0.06999 | valid_mae: 0.94733 | valid_rmse: 1.04043 | valid_mse: 1.0825  |  0:00:03s\n",
      "epoch 2  | loss: 0.47282 | train_rmsle: 0.04067 | train_mae: 0.7268  | train_rmse: 0.81963 | train_mse: 0.6718  | valid_rmsle: 0.04066 | valid_mae: 0.7268  | valid_rmse: 0.82203 | valid_mse: 0.67574 |  0:00:05s\n",
      "epoch 3  | loss: 0.3402  | train_rmsle: 0.034   | train_mae: 0.66309 | train_rmse: 0.7557  | train_mse: 0.57108 | valid_rmsle: 0.03398 | valid_mae: 0.66318 | valid_rmse: 0.75829 | valid_mse: 0.57501 |  0:00:07s\n",
      "epoch 4  | loss: 0.2865  | train_rmsle: 0.02597 | train_mae: 0.57541 | train_rmse: 0.66598 | train_mse: 0.44353 | valid_rmsle: 0.0258  | valid_mae: 0.57651 | valid_rmse: 0.66735 | valid_mse: 0.44536 |  0:00:08s\n",
      "epoch 5  | loss: 0.28439 | train_rmsle: 0.02069 | train_mae: 0.50647 | train_rmse: 0.59502 | train_mse: 0.35405 | valid_rmsle: 0.02041 | valid_mae: 0.50816 | valid_rmse: 0.59534 | valid_mse: 0.35443 |  0:00:10s\n",
      "epoch 6  | loss: 0.25697 | train_rmsle: 0.02503 | train_mae: 0.56391 | train_rmse: 0.65415 | train_mse: 0.42792 | valid_rmsle: 0.02478 | valid_mae: 0.5644  | valid_rmse: 0.65467 | valid_mse: 0.4286  |  0:00:12s\n",
      "epoch 7  | loss: 0.29194 | train_rmsle: 0.02045 | train_mae: 0.50319 | train_rmse: 0.59137 | train_mse: 0.34972 | valid_rmsle: 0.02006 | valid_mae: 0.50376 | valid_rmse: 0.5901  | valid_mse: 0.34822 |  0:00:14s\n",
      "epoch 8  | loss: 0.24267 | train_rmsle: 0.02051 | train_mae: 0.50441 | train_rmse: 0.59227 | train_mse: 0.35079 | valid_rmsle: 0.02017 | valid_mae: 0.50684 | valid_rmse: 0.59171 | valid_mse: 0.35012 |  0:00:16s\n",
      "epoch 9  | loss: 0.24518 | train_rmsle: 0.01997 | train_mae: 0.49602 | train_rmse: 0.58432 | train_mse: 0.34143 | valid_rmsle: 0.01955 | valid_mae: 0.49649 | valid_rmse: 0.58262 | valid_mse: 0.33945 |  0:00:17s\n",
      "epoch 10 | loss: 0.25758 | train_rmsle: 0.02885 | train_mae: 0.60842 | train_rmse: 0.70009 | train_mse: 0.49012 | valid_rmsle: 0.02861 | valid_mae: 0.60752 | valid_rmse: 0.70055 | valid_mse: 0.49076 |  0:00:19s\n",
      "epoch 11 | loss: 0.25914 | train_rmsle: 0.0173  | train_mae: 0.45257 | train_rmse: 0.54075 | train_mse: 0.29241 | valid_rmsle: 0.01684 | valid_mae: 0.4539  | valid_rmse: 0.53838 | valid_mse: 0.28985 |  0:00:21s\n",
      "epoch 12 | loss: 0.23867 | train_rmsle: 0.01657 | train_mae: 0.43929 | train_rmse: 0.52763 | train_mse: 0.27839 | valid_rmsle: 0.01612 | valid_mae: 0.44079 | valid_rmse: 0.5256  | valid_mse: 0.27625 |  0:00:23s\n",
      "epoch 13 | loss: 0.29092 | train_rmsle: 0.01917 | train_mae: 0.48308 | train_rmse: 0.57182 | train_mse: 0.32698 | valid_rmsle: 0.01865 | valid_mae: 0.48182 | valid_rmse: 0.56894 | valid_mse: 0.32369 |  0:00:25s\n",
      "epoch 14 | loss: 0.24759 | train_rmsle: 0.01563 | train_mae: 0.41855 | train_rmse: 0.50902 | train_mse: 0.2591  | valid_rmsle: 0.01505 | valid_mae: 0.41735 | valid_rmse: 0.50474 | valid_mse: 0.25476 |  0:00:26s\n",
      "epoch 15 | loss: 0.23645 | train_rmsle: 0.01515 | train_mae: 0.40687 | train_rmse: 0.49864 | train_mse: 0.24864 | valid_rmsle: 0.01453 | valid_mae: 0.40633 | valid_rmse: 0.49371 | valid_mse: 0.24375 |  0:00:28s\n",
      "epoch 16 | loss: 0.24176 | train_rmsle: 0.01517 | train_mae: 0.40876 | train_rmse: 0.5005  | train_mse: 0.2505  | valid_rmsle: 0.01476 | valid_mae: 0.4103  | valid_rmse: 0.49897 | valid_mse: 0.24897 |  0:00:30s\n",
      "epoch 17 | loss: 0.2315  | train_rmsle: 0.01468 | train_mae: 0.39108 | train_rmse: 0.48681 | train_mse: 0.23698 | valid_rmsle: 0.0142  | valid_mae: 0.39263 | valid_rmse: 0.48395 | valid_mse: 0.2342  |  0:00:32s\n",
      "epoch 18 | loss: 0.33858 | train_rmsle: 0.02048 | train_mae: 0.43316 | train_rmse: 0.57429 | train_mse: 0.32981 | valid_rmsle: 0.0198  | valid_mae: 0.43136 | valid_rmse: 0.56908 | valid_mse: 0.32385 |  0:00:33s\n",
      "epoch 19 | loss: 0.2916  | train_rmsle: 0.01477 | train_mae: 0.39491 | train_rmse: 0.49005 | train_mse: 0.24015 | valid_rmsle: 0.01444 | valid_mae: 0.3973  | valid_rmse: 0.49013 | valid_mse: 0.24023 |  0:00:35s\n",
      "epoch 20 | loss: 0.24085 | train_rmsle: 0.0179  | train_mae: 0.46229 | train_rmse: 0.55111 | train_mse: 0.30373 | valid_rmsle: 0.01743 | valid_mae: 0.46252 | valid_rmse: 0.54837 | valid_mse: 0.30071 |  0:00:37s\n",
      "epoch 21 | loss: 0.23799 | train_rmsle: 0.01717 | train_mae: 0.44942 | train_rmse: 0.53871 | train_mse: 0.29021 | valid_rmsle: 0.01676 | valid_mae: 0.4501  | valid_rmse: 0.53658 | valid_mse: 0.28792 |  0:00:39s\n",
      "epoch 22 | loss: 0.22881 | train_rmsle: 0.01536 | train_mae: 0.41284 | train_rmse: 0.5042  | train_mse: 0.25422 | valid_rmsle: 0.01504 | valid_mae: 0.41405 | valid_rmse: 0.50373 | valid_mse: 0.25374 |  0:00:41s\n",
      "epoch 23 | loss: 0.23588 | train_rmsle: 0.01458 | train_mae: 0.38333 | train_rmse: 0.483   | train_mse: 0.23329 | valid_rmsle: 0.01403 | valid_mae: 0.38329 | valid_rmse: 0.47913 | valid_mse: 0.22956 |  0:00:42s\n",
      "epoch 24 | loss: 0.23964 | train_rmsle: 0.01497 | train_mae: 0.40315 | train_rmse: 0.49551 | train_mse: 0.24553 | valid_rmsle: 0.01433 | valid_mae: 0.40134 | valid_rmse: 0.49011 | valid_mse: 0.2402  |  0:00:44s\n",
      "epoch 25 | loss: 0.22378 | train_rmsle: 0.01506 | train_mae: 0.4073  | train_rmse: 0.49811 | train_mse: 0.24811 | valid_rmsle: 0.01443 | valid_mae: 0.4052  | valid_rmse: 0.49274 | valid_mse: 0.24279 |  0:00:46s\n",
      "epoch 26 | loss: 0.23102 | train_rmsle: 0.01433 | train_mae: 0.38379 | train_rmse: 0.47985 | train_mse: 0.23025 | valid_rmsle: 0.01389 | valid_mae: 0.38444 | valid_rmse: 0.47778 | valid_mse: 0.22827 |  0:00:48s\n",
      "epoch 27 | loss: 0.2263  | train_rmsle: 0.01656 | train_mae: 0.43901 | train_rmse: 0.5288  | train_mse: 0.27963 | valid_rmsle: 0.01601 | valid_mae: 0.43699 | valid_rmse: 0.52469 | valid_mse: 0.2753  |  0:00:49s\n",
      "epoch 28 | loss: 0.23071 | train_rmsle: 0.01448 | train_mae: 0.37524 | train_rmse: 0.4781  | train_mse: 0.22858 | valid_rmsle: 0.01388 | valid_mae: 0.37311 | valid_rmse: 0.47333 | valid_mse: 0.22404 |  0:00:51s\n",
      "epoch 29 | loss: 0.22307 | train_rmsle: 0.01419 | train_mae: 0.3797  | train_rmse: 0.47664 | train_mse: 0.22719 | valid_rmsle: 0.01365 | valid_mae: 0.37944 | valid_rmse: 0.47318 | valid_mse: 0.2239  |  0:00:53s\n",
      "epoch 30 | loss: 0.2185  | train_rmsle: 0.01422 | train_mae: 0.38141 | train_rmse: 0.47788 | train_mse: 0.22837 | valid_rmsle: 0.01368 | valid_mae: 0.38279 | valid_rmse: 0.4747  | valid_mse: 0.22534 |  0:00:55s\n",
      "epoch 31 | loss: 0.22262 | train_rmsle: 0.01419 | train_mae: 0.38184 | train_rmse: 0.47752 | train_mse: 0.22803 | valid_rmsle: 0.01388 | valid_mae: 0.38535 | valid_rmse: 0.4781  | valid_mse: 0.22858 |  0:00:56s\n",
      "epoch 32 | loss: 0.22171 | train_rmsle: 0.01443 | train_mae: 0.39271 | train_rmse: 0.48534 | train_mse: 0.23556 | valid_rmsle: 0.01399 | valid_mae: 0.39525 | valid_rmse: 0.48328 | valid_mse: 0.23356 |  0:00:58s\n",
      "epoch 33 | loss: 0.23101 | train_rmsle: 0.01454 | train_mae: 0.37358 | train_rmse: 0.47899 | train_mse: 0.22943 | valid_rmsle: 0.01386 | valid_mae: 0.37119 | valid_rmse: 0.47271 | valid_mse: 0.22346 |  0:01:00s\n",
      "epoch 34 | loss: 0.2203  | train_rmsle: 0.01411 | train_mae: 0.3864  | train_rmse: 0.47897 | train_mse: 0.22941 | valid_rmsle: 0.0138  | valid_mae: 0.38812 | valid_rmse: 0.47894 | valid_mse: 0.22938 |  0:01:02s\n",
      "epoch 35 | loss: 0.22183 | train_rmsle: 0.01414 | train_mae: 0.37803 | train_rmse: 0.4753  | train_mse: 0.22591 | valid_rmsle: 0.01362 | valid_mae: 0.37467 | valid_rmse: 0.47161 | valid_mse: 0.22242 |  0:01:04s\n",
      "epoch 36 | loss: 0.22484 | train_rmsle: 0.01403 | train_mae: 0.37545 | train_rmse: 0.47377 | train_mse: 0.22446 | valid_rmsle: 0.01379 | valid_mae: 0.37931 | valid_rmse: 0.47459 | valid_mse: 0.22523 |  0:01:05s\n",
      "epoch 37 | loss: 0.22596 | train_rmsle: 0.01491 | train_mae: 0.37404 | train_rmse: 0.48448 | train_mse: 0.23472 | valid_rmsle: 0.01466 | valid_mae: 0.3825  | valid_rmse: 0.48623 | valid_mse: 0.23642 |  0:01:07s\n",
      "epoch 38 | loss: 0.21975 | train_rmsle: 0.0139  | train_mae: 0.37326 | train_rmse: 0.47142 | train_mse: 0.22224 | valid_rmsle: 0.01364 | valid_mae: 0.37644 | valid_rmse: 0.4725  | valid_mse: 0.22326 |  0:01:09s\n",
      "epoch 39 | loss: 0.21465 | train_rmsle: 0.01395 | train_mae: 0.38309 | train_rmse: 0.4763  | train_mse: 0.22686 | valid_rmsle: 0.01364 | valid_mae: 0.38588 | valid_rmse: 0.47669 | valid_mse: 0.22723 |  0:01:11s\n",
      "epoch 40 | loss: 0.21606 | train_rmsle: 0.01402 | train_mae: 0.3774  | train_rmse: 0.47419 | train_mse: 0.22486 | valid_rmsle: 0.01342 | valid_mae: 0.37657 | valid_rmse: 0.47014 | valid_mse: 0.22103 |  0:01:12s\n",
      "epoch 41 | loss: 0.21571 | train_rmsle: 0.01415 | train_mae: 0.37146 | train_rmse: 0.47324 | train_mse: 0.22395 | valid_rmsle: 0.01401 | valid_mae: 0.37773 | valid_rmse: 0.4766  | valid_mse: 0.22715 |  0:01:14s\n",
      "epoch 42 | loss: 0.21428 | train_rmsle: 0.01397 | train_mae: 0.38075 | train_rmse: 0.47494 | train_mse: 0.22557 | valid_rmsle: 0.01373 | valid_mae: 0.38496 | valid_rmse: 0.47643 | valid_mse: 0.22698 |  0:01:16s\n",
      "epoch 43 | loss: 0.21615 | train_rmsle: 0.01409 | train_mae: 0.38607 | train_rmse: 0.4788  | train_mse: 0.22925 | valid_rmsle: 0.01399 | valid_mae: 0.39181 | valid_rmse: 0.48318 | valid_mse: 0.23346 |  0:01:18s\n",
      "epoch 44 | loss: 0.21215 | train_rmsle: 0.01389 | train_mae: 0.37274 | train_rmse: 0.47057 | train_mse: 0.22144 | valid_rmsle: 0.01369 | valid_mae: 0.37967 | valid_rmse: 0.47369 | valid_mse: 0.22438 |  0:01:20s\n",
      "epoch 45 | loss: 0.21783 | train_rmsle: 0.01415 | train_mae: 0.37131 | train_rmse: 0.47337 | train_mse: 0.22408 | valid_rmsle: 0.01394 | valid_mae: 0.3766  | valid_rmse: 0.47606 | valid_mse: 0.22663 |  0:01:21s\n",
      "epoch 46 | loss: 0.21562 | train_rmsle: 0.01458 | train_mae: 0.37136 | train_rmse: 0.47879 | train_mse: 0.22924 | valid_rmsle: 0.01429 | valid_mae: 0.3737  | valid_rmse: 0.47989 | valid_mse: 0.23029 |  0:01:23s\n",
      "epoch 47 | loss: 0.21505 | train_rmsle: 0.01394 | train_mae: 0.37063 | train_rmse: 0.4704  | train_mse: 0.22128 | valid_rmsle: 0.0138  | valid_mae: 0.37573 | valid_rmse: 0.47421 | valid_mse: 0.22488 |  0:01:25s\n",
      "epoch 48 | loss: 0.21547 | train_rmsle: 0.01392 | train_mae: 0.36953 | train_rmse: 0.46965 | train_mse: 0.22057 | valid_rmsle: 0.01378 | valid_mae: 0.37661 | valid_rmse: 0.47579 | valid_mse: 0.22638 |  0:01:27s\n",
      "epoch 49 | loss: 0.21446 | train_rmsle: 0.01412 | train_mae: 0.36833 | train_rmse: 0.47167 | train_mse: 0.22247 | valid_rmsle: 0.01387 | valid_mae: 0.37474 | valid_rmse: 0.47541 | valid_mse: 0.22601 |  0:01:28s\n",
      "epoch 50 | loss: 0.21298 | train_rmsle: 0.01412 | train_mae: 0.36899 | train_rmse: 0.47172 | train_mse: 0.22252 | valid_rmsle: 0.01371 | valid_mae: 0.37236 | valid_rmse: 0.47109 | valid_mse: 0.22192 |  0:01:30s\n",
      "epoch 51 | loss: 0.21565 | train_rmsle: 0.01376 | train_mae: 0.37915 | train_rmse: 0.47209 | train_mse: 0.22287 | valid_rmsle: 0.01365 | valid_mae: 0.38611 | valid_rmse: 0.47607 | valid_mse: 0.22664 |  0:01:32s\n",
      "epoch 52 | loss: 0.2132  | train_rmsle: 0.01415 | train_mae: 0.36935 | train_rmse: 0.47282 | train_mse: 0.22356 | valid_rmsle: 0.01392 | valid_mae: 0.37384 | valid_rmse: 0.4755  | valid_mse: 0.2261  |  0:01:34s\n",
      "epoch 53 | loss: 0.21349 | train_rmsle: 0.01381 | train_mae: 0.37014 | train_rmse: 0.46858 | train_mse: 0.21957 | valid_rmsle: 0.01377 | valid_mae: 0.37903 | valid_rmse: 0.47493 | valid_mse: 0.22556 |  0:01:35s\n",
      "epoch 54 | loss: 0.21131 | train_rmsle: 0.01368 | train_mae: 0.37309 | train_rmse: 0.46835 | train_mse: 0.21936 | valid_rmsle: 0.0135  | valid_mae: 0.38023 | valid_rmse: 0.47192 | valid_mse: 0.2227  |  0:01:37s\n",
      "epoch 55 | loss: 0.21072 | train_rmsle: 0.01374 | train_mae: 0.37276 | train_rmse: 0.46893 | train_mse: 0.21989 | valid_rmsle: 0.01361 | valid_mae: 0.38143 | valid_rmse: 0.47348 | valid_mse: 0.22419 |  0:01:39s\n",
      "epoch 56 | loss: 0.21296 | train_rmsle: 0.01389 | train_mae: 0.36551 | train_rmse: 0.4683  | train_mse: 0.21931 | valid_rmsle: 0.01375 | valid_mae: 0.37518 | valid_rmse: 0.47301 | valid_mse: 0.22374 |  0:01:41s\n",
      "epoch 57 | loss: 0.2133  | train_rmsle: 0.01375 | train_mae: 0.36629 | train_rmse: 0.4669  | train_mse: 0.218   | valid_rmsle: 0.01363 | valid_mae: 0.37779 | valid_rmse: 0.47232 | valid_mse: 0.22309 |  0:01:42s\n",
      "epoch 58 | loss: 0.2099  | train_rmsle: 0.01376 | train_mae: 0.36793 | train_rmse: 0.46723 | train_mse: 0.2183  | valid_rmsle: 0.01347 | valid_mae: 0.37468 | valid_rmse: 0.4691  | valid_mse: 0.22005 |  0:01:44s\n",
      "epoch 59 | loss: 0.20836 | train_rmsle: 0.01357 | train_mae: 0.36794 | train_rmse: 0.46467 | train_mse: 0.21592 | valid_rmsle: 0.01345 | valid_mae: 0.37567 | valid_rmse: 0.46929 | valid_mse: 0.22024 |  0:01:46s\n",
      "epoch 60 | loss: 0.21009 | train_rmsle: 0.01347 | train_mae: 0.36822 | train_rmse: 0.46367 | train_mse: 0.21499 | valid_rmsle: 0.01349 | valid_mae: 0.38024 | valid_rmse: 0.4707  | valid_mse: 0.22156 |  0:01:48s\n",
      "epoch 61 | loss: 0.21027 | train_rmsle: 0.01404 | train_mae: 0.36455 | train_rmse: 0.46949 | train_mse: 0.22042 | valid_rmsle: 0.01399 | valid_mae: 0.37692 | valid_rmse: 0.47578 | valid_mse: 0.22636 |  0:01:50s\n",
      "epoch 62 | loss: 0.20737 | train_rmsle: 0.01397 | train_mae: 0.36534 | train_rmse: 0.46893 | train_mse: 0.2199  | valid_rmsle: 0.01375 | valid_mae: 0.3738  | valid_rmse: 0.47157 | valid_mse: 0.22238 |  0:01:51s\n",
      "epoch 63 | loss: 0.20585 | train_rmsle: 0.01341 | train_mae: 0.36204 | train_rmse: 0.46063 | train_mse: 0.21218 | valid_rmsle: 0.01343 | valid_mae: 0.37443 | valid_rmse: 0.46733 | valid_mse: 0.2184  |  0:01:53s\n",
      "epoch 64 | loss: 0.20477 | train_rmsle: 0.01341 | train_mae: 0.36383 | train_rmse: 0.46156 | train_mse: 0.21303 | valid_rmsle: 0.0133  | valid_mae: 0.3713  | valid_rmse: 0.46549 | valid_mse: 0.21668 |  0:01:55s\n",
      "epoch 65 | loss: 0.2048  | train_rmsle: 0.01326 | train_mae: 0.3644  | train_rmse: 0.45994 | train_mse: 0.21154 | valid_rmsle: 0.01343 | valid_mae: 0.37819 | valid_rmse: 0.46921 | valid_mse: 0.22016 |  0:01:57s\n",
      "epoch 66 | loss: 0.20466 | train_rmsle: 0.01336 | train_mae: 0.35928 | train_rmse: 0.45909 | train_mse: 0.21076 | valid_rmsle: 0.01344 | valid_mae: 0.37014 | valid_rmse: 0.46705 | valid_mse: 0.21813 |  0:01:59s\n",
      "epoch 67 | loss: 0.20234 | train_rmsle: 0.01301 | train_mae: 0.36481 | train_rmse: 0.4572  | train_mse: 0.20903 | valid_rmsle: 0.01319 | valid_mae: 0.37613 | valid_rmse: 0.46631 | valid_mse: 0.21744 |  0:02:00s\n",
      "epoch 68 | loss: 0.19959 | train_rmsle: 0.01348 | train_mae: 0.35448 | train_rmse: 0.45894 | train_mse: 0.21063 | valid_rmsle: 0.01358 | valid_mae: 0.37099 | valid_rmse: 0.46832 | valid_mse: 0.21932 |  0:02:02s\n",
      "epoch 69 | loss: 0.19682 | train_rmsle: 0.01299 | train_mae: 0.35235 | train_rmse: 0.45165 | train_mse: 0.20399 | valid_rmsle: 0.01296 | valid_mae: 0.36356 | valid_rmse: 0.45789 | valid_mse: 0.20966 |  0:02:04s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.20966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1995461369318657 RMSE: 0.4467058729543028 R2: 0.11668614063570615 MAE: 0.34963977839925064\n",
      "=====================================\n",
      "[66/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.80104 | train_rmsle: 0.28098 | train_mae: 1.73958 | train_rmse: 1.80559 | train_mse: 3.26014 | valid_rmsle: 0.2819  | valid_mae: 1.74488 | valid_rmse: 1.80973 | valid_mse: 3.27511 |  0:00:01s\n",
      "epoch 1  | loss: 1.04399 | train_rmsle: 0.06962 | train_mae: 0.94459 | train_rmse: 1.03616 | train_mse: 1.07364 | valid_rmsle: 0.06999 | valid_mae: 0.94733 | valid_rmse: 1.04043 | valid_mse: 1.0825  |  0:00:03s\n",
      "epoch 2  | loss: 0.47282 | train_rmsle: 0.04067 | train_mae: 0.7268  | train_rmse: 0.81963 | train_mse: 0.6718  | valid_rmsle: 0.04066 | valid_mae: 0.7268  | valid_rmse: 0.82203 | valid_mse: 0.67574 |  0:00:05s\n",
      "epoch 3  | loss: 0.3402  | train_rmsle: 0.034   | train_mae: 0.66309 | train_rmse: 0.7557  | train_mse: 0.57108 | valid_rmsle: 0.03398 | valid_mae: 0.66318 | valid_rmse: 0.75829 | valid_mse: 0.57501 |  0:00:07s\n",
      "epoch 4  | loss: 0.2865  | train_rmsle: 0.02597 | train_mae: 0.57541 | train_rmse: 0.66598 | train_mse: 0.44353 | valid_rmsle: 0.0258  | valid_mae: 0.57651 | valid_rmse: 0.66735 | valid_mse: 0.44536 |  0:00:09s\n",
      "epoch 5  | loss: 0.28439 | train_rmsle: 0.02069 | train_mae: 0.50647 | train_rmse: 0.59502 | train_mse: 0.35405 | valid_rmsle: 0.02041 | valid_mae: 0.50816 | valid_rmse: 0.59534 | valid_mse: 0.35443 |  0:00:10s\n",
      "epoch 6  | loss: 0.25697 | train_rmsle: 0.02503 | train_mae: 0.56391 | train_rmse: 0.65415 | train_mse: 0.42792 | valid_rmsle: 0.02478 | valid_mae: 0.5644  | valid_rmse: 0.65467 | valid_mse: 0.4286  |  0:00:12s\n",
      "epoch 7  | loss: 0.29194 | train_rmsle: 0.02045 | train_mae: 0.50319 | train_rmse: 0.59137 | train_mse: 0.34972 | valid_rmsle: 0.02006 | valid_mae: 0.50376 | valid_rmse: 0.5901  | valid_mse: 0.34822 |  0:00:14s\n",
      "epoch 8  | loss: 0.24267 | train_rmsle: 0.02051 | train_mae: 0.50441 | train_rmse: 0.59227 | train_mse: 0.35079 | valid_rmsle: 0.02017 | valid_mae: 0.50684 | valid_rmse: 0.59171 | valid_mse: 0.35012 |  0:00:16s\n",
      "epoch 9  | loss: 0.24518 | train_rmsle: 0.01997 | train_mae: 0.49602 | train_rmse: 0.58432 | train_mse: 0.34143 | valid_rmsle: 0.01955 | valid_mae: 0.49649 | valid_rmse: 0.58262 | valid_mse: 0.33945 |  0:00:17s\n",
      "epoch 10 | loss: 0.25758 | train_rmsle: 0.02885 | train_mae: 0.60842 | train_rmse: 0.70009 | train_mse: 0.49012 | valid_rmsle: 0.02861 | valid_mae: 0.60752 | valid_rmse: 0.70055 | valid_mse: 0.49076 |  0:00:19s\n",
      "epoch 11 | loss: 0.25914 | train_rmsle: 0.0173  | train_mae: 0.45257 | train_rmse: 0.54075 | train_mse: 0.29241 | valid_rmsle: 0.01684 | valid_mae: 0.4539  | valid_rmse: 0.53838 | valid_mse: 0.28985 |  0:00:21s\n",
      "epoch 12 | loss: 0.23867 | train_rmsle: 0.01657 | train_mae: 0.43929 | train_rmse: 0.52763 | train_mse: 0.27839 | valid_rmsle: 0.01612 | valid_mae: 0.44079 | valid_rmse: 0.5256  | valid_mse: 0.27625 |  0:00:23s\n",
      "epoch 13 | loss: 0.29092 | train_rmsle: 0.01917 | train_mae: 0.48308 | train_rmse: 0.57182 | train_mse: 0.32698 | valid_rmsle: 0.01865 | valid_mae: 0.48182 | valid_rmse: 0.56894 | valid_mse: 0.32369 |  0:00:25s\n",
      "epoch 14 | loss: 0.24759 | train_rmsle: 0.01563 | train_mae: 0.41855 | train_rmse: 0.50902 | train_mse: 0.2591  | valid_rmsle: 0.01505 | valid_mae: 0.41735 | valid_rmse: 0.50474 | valid_mse: 0.25476 |  0:00:26s\n",
      "epoch 15 | loss: 0.23645 | train_rmsle: 0.01515 | train_mae: 0.40687 | train_rmse: 0.49864 | train_mse: 0.24864 | valid_rmsle: 0.01453 | valid_mae: 0.40633 | valid_rmse: 0.49371 | valid_mse: 0.24375 |  0:00:28s\n",
      "epoch 16 | loss: 0.24176 | train_rmsle: 0.01517 | train_mae: 0.40876 | train_rmse: 0.5005  | train_mse: 0.2505  | valid_rmsle: 0.01476 | valid_mae: 0.4103  | valid_rmse: 0.49897 | valid_mse: 0.24897 |  0:00:30s\n",
      "epoch 17 | loss: 0.2315  | train_rmsle: 0.01468 | train_mae: 0.39108 | train_rmse: 0.48681 | train_mse: 0.23698 | valid_rmsle: 0.0142  | valid_mae: 0.39263 | valid_rmse: 0.48395 | valid_mse: 0.2342  |  0:00:32s\n",
      "epoch 18 | loss: 0.33858 | train_rmsle: 0.02048 | train_mae: 0.43316 | train_rmse: 0.57429 | train_mse: 0.32981 | valid_rmsle: 0.0198  | valid_mae: 0.43136 | valid_rmse: 0.56908 | valid_mse: 0.32385 |  0:00:33s\n",
      "epoch 19 | loss: 0.2916  | train_rmsle: 0.01477 | train_mae: 0.39491 | train_rmse: 0.49005 | train_mse: 0.24015 | valid_rmsle: 0.01444 | valid_mae: 0.3973  | valid_rmse: 0.49013 | valid_mse: 0.24023 |  0:00:35s\n",
      "epoch 20 | loss: 0.24085 | train_rmsle: 0.0179  | train_mae: 0.46229 | train_rmse: 0.55111 | train_mse: 0.30373 | valid_rmsle: 0.01743 | valid_mae: 0.46252 | valid_rmse: 0.54837 | valid_mse: 0.30071 |  0:00:37s\n",
      "epoch 21 | loss: 0.23799 | train_rmsle: 0.01717 | train_mae: 0.44942 | train_rmse: 0.53871 | train_mse: 0.29021 | valid_rmsle: 0.01676 | valid_mae: 0.4501  | valid_rmse: 0.53658 | valid_mse: 0.28792 |  0:00:39s\n",
      "epoch 22 | loss: 0.22881 | train_rmsle: 0.01536 | train_mae: 0.41284 | train_rmse: 0.5042  | train_mse: 0.25422 | valid_rmsle: 0.01504 | valid_mae: 0.41405 | valid_rmse: 0.50373 | valid_mse: 0.25374 |  0:00:41s\n",
      "epoch 23 | loss: 0.23588 | train_rmsle: 0.01458 | train_mae: 0.38333 | train_rmse: 0.483   | train_mse: 0.23329 | valid_rmsle: 0.01403 | valid_mae: 0.38329 | valid_rmse: 0.47913 | valid_mse: 0.22956 |  0:00:42s\n",
      "epoch 24 | loss: 0.23964 | train_rmsle: 0.01497 | train_mae: 0.40315 | train_rmse: 0.49551 | train_mse: 0.24553 | valid_rmsle: 0.01433 | valid_mae: 0.40134 | valid_rmse: 0.49011 | valid_mse: 0.2402  |  0:00:44s\n",
      "epoch 25 | loss: 0.22378 | train_rmsle: 0.01506 | train_mae: 0.4073  | train_rmse: 0.49811 | train_mse: 0.24811 | valid_rmsle: 0.01443 | valid_mae: 0.4052  | valid_rmse: 0.49274 | valid_mse: 0.24279 |  0:00:46s\n",
      "epoch 26 | loss: 0.23102 | train_rmsle: 0.01433 | train_mae: 0.38379 | train_rmse: 0.47985 | train_mse: 0.23025 | valid_rmsle: 0.01389 | valid_mae: 0.38444 | valid_rmse: 0.47778 | valid_mse: 0.22827 |  0:00:48s\n",
      "epoch 27 | loss: 0.2263  | train_rmsle: 0.01656 | train_mae: 0.43901 | train_rmse: 0.5288  | train_mse: 0.27963 | valid_rmsle: 0.01601 | valid_mae: 0.43699 | valid_rmse: 0.52469 | valid_mse: 0.2753  |  0:00:49s\n",
      "epoch 28 | loss: 0.23071 | train_rmsle: 0.01448 | train_mae: 0.37524 | train_rmse: 0.4781  | train_mse: 0.22858 | valid_rmsle: 0.01388 | valid_mae: 0.37311 | valid_rmse: 0.47333 | valid_mse: 0.22404 |  0:00:51s\n",
      "epoch 29 | loss: 0.22307 | train_rmsle: 0.01419 | train_mae: 0.3797  | train_rmse: 0.47664 | train_mse: 0.22719 | valid_rmsle: 0.01365 | valid_mae: 0.37944 | valid_rmse: 0.47318 | valid_mse: 0.2239  |  0:00:53s\n",
      "epoch 30 | loss: 0.2185  | train_rmsle: 0.01422 | train_mae: 0.38141 | train_rmse: 0.47788 | train_mse: 0.22837 | valid_rmsle: 0.01368 | valid_mae: 0.38279 | valid_rmse: 0.4747  | valid_mse: 0.22534 |  0:00:55s\n",
      "epoch 31 | loss: 0.22262 | train_rmsle: 0.01419 | train_mae: 0.38184 | train_rmse: 0.47752 | train_mse: 0.22803 | valid_rmsle: 0.01388 | valid_mae: 0.38535 | valid_rmse: 0.4781  | valid_mse: 0.22858 |  0:00:57s\n",
      "epoch 32 | loss: 0.22171 | train_rmsle: 0.01443 | train_mae: 0.39271 | train_rmse: 0.48534 | train_mse: 0.23556 | valid_rmsle: 0.01399 | valid_mae: 0.39525 | valid_rmse: 0.48328 | valid_mse: 0.23356 |  0:00:58s\n",
      "epoch 33 | loss: 0.23101 | train_rmsle: 0.01454 | train_mae: 0.37358 | train_rmse: 0.47899 | train_mse: 0.22943 | valid_rmsle: 0.01386 | valid_mae: 0.37119 | valid_rmse: 0.47271 | valid_mse: 0.22346 |  0:01:00s\n",
      "epoch 34 | loss: 0.2203  | train_rmsle: 0.01411 | train_mae: 0.3864  | train_rmse: 0.47897 | train_mse: 0.22941 | valid_rmsle: 0.0138  | valid_mae: 0.38812 | valid_rmse: 0.47894 | valid_mse: 0.22938 |  0:01:02s\n",
      "epoch 35 | loss: 0.22183 | train_rmsle: 0.01414 | train_mae: 0.37803 | train_rmse: 0.4753  | train_mse: 0.22591 | valid_rmsle: 0.01362 | valid_mae: 0.37467 | valid_rmse: 0.47161 | valid_mse: 0.22242 |  0:01:04s\n",
      "epoch 36 | loss: 0.22484 | train_rmsle: 0.01403 | train_mae: 0.37545 | train_rmse: 0.47377 | train_mse: 0.22446 | valid_rmsle: 0.01379 | valid_mae: 0.37931 | valid_rmse: 0.47459 | valid_mse: 0.22523 |  0:01:06s\n",
      "epoch 37 | loss: 0.22596 | train_rmsle: 0.01491 | train_mae: 0.37404 | train_rmse: 0.48448 | train_mse: 0.23472 | valid_rmsle: 0.01466 | valid_mae: 0.3825  | valid_rmse: 0.48623 | valid_mse: 0.23642 |  0:01:07s\n",
      "epoch 38 | loss: 0.21975 | train_rmsle: 0.0139  | train_mae: 0.37326 | train_rmse: 0.47142 | train_mse: 0.22224 | valid_rmsle: 0.01364 | valid_mae: 0.37644 | valid_rmse: 0.4725  | valid_mse: 0.22326 |  0:01:09s\n",
      "epoch 39 | loss: 0.21465 | train_rmsle: 0.01395 | train_mae: 0.38309 | train_rmse: 0.4763  | train_mse: 0.22686 | valid_rmsle: 0.01364 | valid_mae: 0.38588 | valid_rmse: 0.47669 | valid_mse: 0.22723 |  0:01:11s\n",
      "epoch 40 | loss: 0.21606 | train_rmsle: 0.01402 | train_mae: 0.3774  | train_rmse: 0.47419 | train_mse: 0.22486 | valid_rmsle: 0.01342 | valid_mae: 0.37657 | valid_rmse: 0.47014 | valid_mse: 0.22103 |  0:01:13s\n",
      "epoch 41 | loss: 0.21571 | train_rmsle: 0.01415 | train_mae: 0.37146 | train_rmse: 0.47324 | train_mse: 0.22395 | valid_rmsle: 0.01401 | valid_mae: 0.37773 | valid_rmse: 0.4766  | valid_mse: 0.22715 |  0:01:14s\n",
      "epoch 42 | loss: 0.21428 | train_rmsle: 0.01397 | train_mae: 0.38075 | train_rmse: 0.47494 | train_mse: 0.22557 | valid_rmsle: 0.01373 | valid_mae: 0.38496 | valid_rmse: 0.47643 | valid_mse: 0.22698 |  0:01:16s\n",
      "epoch 43 | loss: 0.21615 | train_rmsle: 0.01409 | train_mae: 0.38607 | train_rmse: 0.4788  | train_mse: 0.22925 | valid_rmsle: 0.01399 | valid_mae: 0.39181 | valid_rmse: 0.48318 | valid_mse: 0.23346 |  0:01:18s\n",
      "epoch 44 | loss: 0.21215 | train_rmsle: 0.01389 | train_mae: 0.37274 | train_rmse: 0.47057 | train_mse: 0.22144 | valid_rmsle: 0.01369 | valid_mae: 0.37967 | valid_rmse: 0.47369 | valid_mse: 0.22438 |  0:01:20s\n",
      "epoch 45 | loss: 0.21783 | train_rmsle: 0.01415 | train_mae: 0.37131 | train_rmse: 0.47337 | train_mse: 0.22408 | valid_rmsle: 0.01394 | valid_mae: 0.3766  | valid_rmse: 0.47606 | valid_mse: 0.22663 |  0:01:21s\n",
      "epoch 46 | loss: 0.21562 | train_rmsle: 0.01458 | train_mae: 0.37136 | train_rmse: 0.47879 | train_mse: 0.22924 | valid_rmsle: 0.01429 | valid_mae: 0.3737  | valid_rmse: 0.47989 | valid_mse: 0.23029 |  0:01:23s\n",
      "epoch 47 | loss: 0.21505 | train_rmsle: 0.01394 | train_mae: 0.37063 | train_rmse: 0.4704  | train_mse: 0.22128 | valid_rmsle: 0.0138  | valid_mae: 0.37573 | valid_rmse: 0.47421 | valid_mse: 0.22488 |  0:01:25s\n",
      "epoch 48 | loss: 0.21547 | train_rmsle: 0.01392 | train_mae: 0.36953 | train_rmse: 0.46965 | train_mse: 0.22057 | valid_rmsle: 0.01378 | valid_mae: 0.37661 | valid_rmse: 0.47579 | valid_mse: 0.22638 |  0:01:27s\n",
      "epoch 49 | loss: 0.21446 | train_rmsle: 0.01412 | train_mae: 0.36833 | train_rmse: 0.47167 | train_mse: 0.22247 | valid_rmsle: 0.01387 | valid_mae: 0.37474 | valid_rmse: 0.47541 | valid_mse: 0.22601 |  0:01:28s\n",
      "epoch 50 | loss: 0.21298 | train_rmsle: 0.01412 | train_mae: 0.36899 | train_rmse: 0.47172 | train_mse: 0.22252 | valid_rmsle: 0.01371 | valid_mae: 0.37236 | valid_rmse: 0.47109 | valid_mse: 0.22192 |  0:01:30s\n",
      "epoch 51 | loss: 0.21565 | train_rmsle: 0.01376 | train_mae: 0.37915 | train_rmse: 0.47209 | train_mse: 0.22287 | valid_rmsle: 0.01365 | valid_mae: 0.38611 | valid_rmse: 0.47607 | valid_mse: 0.22664 |  0:01:32s\n",
      "epoch 52 | loss: 0.2132  | train_rmsle: 0.01415 | train_mae: 0.36935 | train_rmse: 0.47282 | train_mse: 0.22356 | valid_rmsle: 0.01392 | valid_mae: 0.37384 | valid_rmse: 0.4755  | valid_mse: 0.2261  |  0:01:34s\n",
      "epoch 53 | loss: 0.21349 | train_rmsle: 0.01381 | train_mae: 0.37014 | train_rmse: 0.46858 | train_mse: 0.21957 | valid_rmsle: 0.01377 | valid_mae: 0.37903 | valid_rmse: 0.47493 | valid_mse: 0.22556 |  0:01:36s\n",
      "epoch 54 | loss: 0.21131 | train_rmsle: 0.01368 | train_mae: 0.37309 | train_rmse: 0.46835 | train_mse: 0.21936 | valid_rmsle: 0.0135  | valid_mae: 0.38023 | valid_rmse: 0.47192 | valid_mse: 0.2227  |  0:01:37s\n",
      "epoch 55 | loss: 0.21072 | train_rmsle: 0.01374 | train_mae: 0.37276 | train_rmse: 0.46893 | train_mse: 0.21989 | valid_rmsle: 0.01361 | valid_mae: 0.38143 | valid_rmse: 0.47348 | valid_mse: 0.22419 |  0:01:39s\n",
      "epoch 56 | loss: 0.21296 | train_rmsle: 0.01389 | train_mae: 0.36551 | train_rmse: 0.4683  | train_mse: 0.21931 | valid_rmsle: 0.01375 | valid_mae: 0.37518 | valid_rmse: 0.47301 | valid_mse: 0.22374 |  0:01:41s\n",
      "epoch 57 | loss: 0.2133  | train_rmsle: 0.01375 | train_mae: 0.36629 | train_rmse: 0.4669  | train_mse: 0.218   | valid_rmsle: 0.01363 | valid_mae: 0.37779 | valid_rmse: 0.47232 | valid_mse: 0.22309 |  0:01:43s\n",
      "epoch 58 | loss: 0.2099  | train_rmsle: 0.01376 | train_mae: 0.36793 | train_rmse: 0.46723 | train_mse: 0.2183  | valid_rmsle: 0.01347 | valid_mae: 0.37468 | valid_rmse: 0.4691  | valid_mse: 0.22005 |  0:01:44s\n",
      "epoch 59 | loss: 0.20836 | train_rmsle: 0.01357 | train_mae: 0.36794 | train_rmse: 0.46467 | train_mse: 0.21592 | valid_rmsle: 0.01345 | valid_mae: 0.37567 | valid_rmse: 0.46929 | valid_mse: 0.22024 |  0:01:46s\n",
      "epoch 60 | loss: 0.21009 | train_rmsle: 0.01347 | train_mae: 0.36822 | train_rmse: 0.46367 | train_mse: 0.21499 | valid_rmsle: 0.01349 | valid_mae: 0.38024 | valid_rmse: 0.4707  | valid_mse: 0.22156 |  0:01:48s\n",
      "epoch 61 | loss: 0.21027 | train_rmsle: 0.01404 | train_mae: 0.36455 | train_rmse: 0.46949 | train_mse: 0.22042 | valid_rmsle: 0.01399 | valid_mae: 0.37692 | valid_rmse: 0.47578 | valid_mse: 0.22636 |  0:01:50s\n",
      "epoch 62 | loss: 0.20737 | train_rmsle: 0.01397 | train_mae: 0.36534 | train_rmse: 0.46893 | train_mse: 0.2199  | valid_rmsle: 0.01375 | valid_mae: 0.3738  | valid_rmse: 0.47157 | valid_mse: 0.22238 |  0:01:51s\n",
      "epoch 63 | loss: 0.20585 | train_rmsle: 0.01341 | train_mae: 0.36204 | train_rmse: 0.46063 | train_mse: 0.21218 | valid_rmsle: 0.01343 | valid_mae: 0.37443 | valid_rmse: 0.46733 | valid_mse: 0.2184  |  0:01:53s\n",
      "epoch 64 | loss: 0.20477 | train_rmsle: 0.01341 | train_mae: 0.36383 | train_rmse: 0.46156 | train_mse: 0.21303 | valid_rmsle: 0.0133  | valid_mae: 0.3713  | valid_rmse: 0.46549 | valid_mse: 0.21668 |  0:01:55s\n",
      "epoch 65 | loss: 0.2048  | train_rmsle: 0.01326 | train_mae: 0.3644  | train_rmse: 0.45994 | train_mse: 0.21154 | valid_rmsle: 0.01343 | valid_mae: 0.37819 | valid_rmse: 0.46921 | valid_mse: 0.22016 |  0:01:57s\n",
      "epoch 66 | loss: 0.20466 | train_rmsle: 0.01336 | train_mae: 0.35928 | train_rmse: 0.45909 | train_mse: 0.21076 | valid_rmsle: 0.01344 | valid_mae: 0.37014 | valid_rmse: 0.46705 | valid_mse: 0.21813 |  0:01:59s\n",
      "epoch 67 | loss: 0.20234 | train_rmsle: 0.01301 | train_mae: 0.36481 | train_rmse: 0.4572  | train_mse: 0.20903 | valid_rmsle: 0.01319 | valid_mae: 0.37613 | valid_rmse: 0.46631 | valid_mse: 0.21744 |  0:02:00s\n",
      "epoch 68 | loss: 0.19959 | train_rmsle: 0.01348 | train_mae: 0.35448 | train_rmse: 0.45894 | train_mse: 0.21063 | valid_rmsle: 0.01358 | valid_mae: 0.37099 | valid_rmse: 0.46832 | valid_mse: 0.21932 |  0:02:02s\n",
      "epoch 69 | loss: 0.19682 | train_rmsle: 0.01299 | train_mae: 0.35235 | train_rmse: 0.45165 | train_mse: 0.20399 | valid_rmsle: 0.01296 | valid_mae: 0.36356 | valid_rmse: 0.45789 | valid_mse: 0.20966 |  0:02:04s\n",
      "epoch 70 | loss: 0.19394 | train_rmsle: 0.01318 | train_mae: 0.37749 | train_rmse: 0.46536 | train_mse: 0.21656 | valid_rmsle: 0.01362 | valid_mae: 0.39443 | valid_rmse: 0.47909 | valid_mse: 0.22952 |  0:02:06s\n",
      "epoch 71 | loss: 0.19118 | train_rmsle: 0.0129  | train_mae: 0.34607 | train_rmse: 0.44884 | train_mse: 0.20146 | valid_rmsle: 0.01325 | valid_mae: 0.36476 | valid_rmse: 0.46287 | valid_mse: 0.21425 |  0:02:08s\n",
      "epoch 72 | loss: 0.18811 | train_rmsle: 0.01194 | train_mae: 0.33978 | train_rmse: 0.43407 | train_mse: 0.18841 | valid_rmsle: 0.01252 | valid_mae: 0.3599  | valid_rmse: 0.45232 | valid_mse: 0.2046  |  0:02:09s\n",
      "epoch 73 | loss: 0.18563 | train_rmsle: 0.01173 | train_mae: 0.34165 | train_rmse: 0.43261 | train_mse: 0.18715 | valid_rmsle: 0.01228 | valid_mae: 0.36009 | valid_rmse: 0.44954 | valid_mse: 0.20208 |  0:02:11s\n",
      "epoch 74 | loss: 0.18446 | train_rmsle: 0.01167 | train_mae: 0.34427 | train_rmse: 0.43268 | train_mse: 0.18721 | valid_rmsle: 0.01227 | valid_mae: 0.36307 | valid_rmse: 0.4503  | valid_mse: 0.20277 |  0:02:13s\n",
      "epoch 75 | loss: 0.17827 | train_rmsle: 0.0114  | train_mae: 0.32856 | train_rmse: 0.42304 | train_mse: 0.17896 | valid_rmsle: 0.01214 | valid_mae: 0.35238 | valid_rmse: 0.44483 | valid_mse: 0.19787 |  0:02:15s\n",
      "epoch 76 | loss: 0.17177 | train_rmsle: 0.01085 | train_mae: 0.32579 | train_rmse: 0.4147  | train_mse: 0.17198 | valid_rmsle: 0.01166 | valid_mae: 0.35124 | valid_rmse: 0.4375  | valid_mse: 0.1914  |  0:02:16s\n",
      "epoch 77 | loss: 0.16741 | train_rmsle: 0.01065 | train_mae: 0.32081 | train_rmse: 0.41018 | train_mse: 0.16825 | valid_rmsle: 0.0115  | valid_mae: 0.34694 | valid_rmse: 0.43373 | valid_mse: 0.18812 |  0:02:18s\n",
      "epoch 78 | loss: 0.16407 | train_rmsle: 0.0104  | train_mae: 0.31674 | train_rmse: 0.40482 | train_mse: 0.16388 | valid_rmsle: 0.01134 | valid_mae: 0.34341 | valid_rmse: 0.43045 | valid_mse: 0.18528 |  0:02:20s\n",
      "epoch 79 | loss: 0.16032 | train_rmsle: 0.01047 | train_mae: 0.31849 | train_rmse: 0.40625 | train_mse: 0.16504 | valid_rmsle: 0.01177 | valid_mae: 0.34746 | valid_rmse: 0.43854 | valid_mse: 0.19232 |  0:02:22s\n",
      "epoch 80 | loss: 0.15796 | train_rmsle: 0.0102  | train_mae: 0.31552 | train_rmse: 0.4015  | train_mse: 0.1612  | valid_rmsle: 0.01124 | valid_mae: 0.34011 | valid_rmse: 0.42967 | valid_mse: 0.18461 |  0:02:24s\n",
      "epoch 81 | loss: 0.15556 | train_rmsle: 0.00997 | train_mae: 0.31749 | train_rmse: 0.39925 | train_mse: 0.1594  | valid_rmsle: 0.01049 | valid_mae: 0.33401 | valid_rmse: 0.41632 | valid_mse: 0.17332 |  0:02:25s\n",
      "epoch 82 | loss: 0.15227 | train_rmsle: 0.00985 | train_mae: 0.31701 | train_rmse: 0.39788 | train_mse: 0.15831 | valid_rmsle: 0.01041 | valid_mae: 0.33045 | valid_rmse: 0.41633 | valid_mse: 0.17333 |  0:02:27s\n",
      "epoch 83 | loss: 0.1509  | train_rmsle: 0.00924 | train_mae: 0.3001  | train_rmse: 0.38225 | train_mse: 0.14612 | valid_rmsle: 0.00969 | valid_mae: 0.31193 | valid_rmse: 0.40071 | valid_mse: 0.16057 |  0:02:29s\n",
      "epoch 84 | loss: 0.14052 | train_rmsle: 0.00898 | train_mae: 0.29851 | train_rmse: 0.37794 | train_mse: 0.14284 | valid_rmsle: 0.00994 | valid_mae: 0.3162  | valid_rmse: 0.41136 | valid_mse: 0.16921 |  0:02:31s\n",
      "epoch 85 | loss: 0.13276 | train_rmsle: 0.00837 | train_mae: 0.28257 | train_rmse: 0.36231 | train_mse: 0.13127 | valid_rmsle: 0.00905 | valid_mae: 0.29948 | valid_rmse: 0.3874  | valid_mse: 0.15008 |  0:02:33s\n",
      "epoch 86 | loss: 0.12802 | train_rmsle: 0.00788 | train_mae: 0.27836 | train_rmse: 0.35429 | train_mse: 0.12552 | valid_rmsle: 0.00811 | valid_mae: 0.2909  | valid_rmse: 0.36672 | valid_mse: 0.13448 |  0:02:34s\n",
      "epoch 87 | loss: 0.12378 | train_rmsle: 0.00754 | train_mae: 0.27183 | train_rmse: 0.34609 | train_mse: 0.11978 | valid_rmsle: 0.00787 | valid_mae: 0.28921 | valid_rmse: 0.35979 | valid_mse: 0.12945 |  0:02:36s\n",
      "epoch 88 | loss: 0.11807 | train_rmsle: 0.00725 | train_mae: 0.26344 | train_rmse: 0.3378  | train_mse: 0.11411 | valid_rmsle: 0.00747 | valid_mae: 0.27703 | valid_rmse: 0.35085 | valid_mse: 0.12309 |  0:02:38s\n",
      "epoch 89 | loss: 0.11614 | train_rmsle: 0.00705 | train_mae: 0.2574  | train_rmse: 0.33253 | train_mse: 0.11058 | valid_rmsle: 0.00739 | valid_mae: 0.27178 | valid_rmse: 0.35024 | valid_mse: 0.12267 |  0:02:40s\n",
      "epoch 90 | loss: 0.1078  | train_rmsle: 0.00674 | train_mae: 0.26065 | train_rmse: 0.32888 | train_mse: 0.10816 | valid_rmsle: 0.00692 | valid_mae: 0.2688  | valid_rmse: 0.34174 | valid_mse: 0.11679 |  0:02:41s\n",
      "epoch 91 | loss: 0.10347 | train_rmsle: 0.0067  | train_mae: 0.26061 | train_rmse: 0.32817 | train_mse: 0.1077  | valid_rmsle: 0.0069  | valid_mae: 0.26736 | valid_rmse: 0.3393  | valid_mse: 0.11512 |  0:02:43s\n",
      "epoch 92 | loss: 0.10103 | train_rmsle: 0.00634 | train_mae: 0.24172 | train_rmse: 0.31387 | train_mse: 0.09852 | valid_rmsle: 0.00659 | valid_mae: 0.25342 | valid_rmse: 0.326   | valid_mse: 0.10628 |  0:02:45s\n",
      "epoch 93 | loss: 0.09841 | train_rmsle: 0.00616 | train_mae: 0.23768 | train_rmse: 0.31006 | train_mse: 0.09614 | valid_rmsle: 0.00653 | valid_mae: 0.25359 | valid_rmse: 0.32666 | valid_mse: 0.10671 |  0:02:47s\n",
      "epoch 94 | loss: 0.09569 | train_rmsle: 0.00568 | train_mae: 0.23549 | train_rmse: 0.30084 | train_mse: 0.09051 | valid_rmsle: 0.00599 | valid_mae: 0.24815 | valid_rmse: 0.31447 | valid_mse: 0.09889 |  0:02:49s\n",
      "epoch 95 | loss: 0.08914 | train_rmsle: 0.00543 | train_mae: 0.2267  | train_rmse: 0.29248 | train_mse: 0.08555 | valid_rmsle: 0.00597 | valid_mae: 0.24447 | valid_rmse: 0.31341 | valid_mse: 0.09823 |  0:02:50s\n",
      "epoch 96 | loss: 0.08361 | train_rmsle: 0.00501 | train_mae: 0.216   | train_rmse: 0.28031 | train_mse: 0.07857 | valid_rmsle: 0.00573 | valid_mae: 0.2381  | valid_rmse: 0.31051 | valid_mse: 0.09642 |  0:02:52s\n",
      "epoch 97 | loss: 0.07969 | train_rmsle: 0.00481 | train_mae: 0.21215 | train_rmse: 0.2754  | train_mse: 0.07585 | valid_rmsle: 0.00547 | valid_mae: 0.23317 | valid_rmse: 0.30421 | valid_mse: 0.09254 |  0:02:54s\n",
      "epoch 98 | loss: 0.07544 | train_rmsle: 0.00507 | train_mae: 0.22737 | train_rmse: 0.28679 | train_mse: 0.08225 | valid_rmsle: 0.00533 | valid_mae: 0.2378  | valid_rmse: 0.30098 | valid_mse: 0.09059 |  0:02:56s\n",
      "epoch 99 | loss: 0.07379 | train_rmsle: 0.00441 | train_mae: 0.20685 | train_rmse: 0.26495 | train_mse: 0.0702  | valid_rmsle: 0.00483 | valid_mae: 0.22515 | valid_rmse: 0.28379 | valid_mse: 0.08054 |  0:02:58s\n",
      "epoch 100| loss: 0.07322 | train_rmsle: 0.00421 | train_mae: 0.20341 | train_rmse: 0.26006 | train_mse: 0.06763 | valid_rmsle: 0.00469 | valid_mae: 0.22178 | valid_rmse: 0.27975 | valid_mse: 0.07826 |  0:02:59s\n",
      "epoch 101| loss: 0.06755 | train_rmsle: 0.00414 | train_mae: 0.19627 | train_rmse: 0.25525 | train_mse: 0.06515 | valid_rmsle: 0.00466 | valid_mae: 0.21915 | valid_rmse: 0.2775  | valid_mse: 0.07701 |  0:03:01s\n",
      "epoch 102| loss: 0.06375 | train_rmsle: 0.0037  | train_mae: 0.19037 | train_rmse: 0.24367 | train_mse: 0.05938 | valid_rmsle: 0.00418 | valid_mae: 0.20929 | valid_rmse: 0.26496 | valid_mse: 0.0702  |  0:03:03s\n",
      "epoch 103| loss: 0.05955 | train_rmsle: 0.00341 | train_mae: 0.18021 | train_rmse: 0.23295 | train_mse: 0.05427 | valid_rmsle: 0.00391 | valid_mae: 0.20092 | valid_rmse: 0.25592 | valid_mse: 0.06549 |  0:03:05s\n",
      "epoch 104| loss: 0.05802 | train_rmsle: 0.00319 | train_mae: 0.17399 | train_rmse: 0.22507 | train_mse: 0.05066 | valid_rmsle: 0.00365 | valid_mae: 0.19553 | valid_rmse: 0.24717 | valid_mse: 0.06109 |  0:03:06s\n",
      "epoch 105| loss: 0.05701 | train_rmsle: 0.00408 | train_mae: 0.21233 | train_rmse: 0.26284 | train_mse: 0.06909 | valid_rmsle: 0.00456 | valid_mae: 0.2267  | valid_rmse: 0.28134 | valid_mse: 0.07915 |  0:03:08s\n",
      "epoch 106| loss: 0.05958 | train_rmsle: 0.00303 | train_mae: 0.17303 | train_rmse: 0.22133 | train_mse: 0.04899 | valid_rmsle: 0.00357 | valid_mae: 0.19346 | valid_rmse: 0.24538 | valid_mse: 0.06021 |  0:03:10s\n",
      "epoch 107| loss: 0.05097 | train_rmsle: 0.00287 | train_mae: 0.16874 | train_rmse: 0.21592 | train_mse: 0.04662 | valid_rmsle: 0.00334 | valid_mae: 0.18738 | valid_rmse: 0.2375  | valid_mse: 0.05641 |  0:03:12s\n",
      "epoch 108| loss: 0.04962 | train_rmsle: 0.00294 | train_mae: 0.17597 | train_rmse: 0.22239 | train_mse: 0.04946 | valid_rmsle: 0.00335 | valid_mae: 0.19225 | valid_rmse: 0.24121 | valid_mse: 0.05818 |  0:03:14s\n",
      "epoch 109| loss: 0.04867 | train_rmsle: 0.00265 | train_mae: 0.159   | train_rmse: 0.20628 | train_mse: 0.04255 | valid_rmsle: 0.00305 | valid_mae: 0.17862 | valid_rmse: 0.22689 | valid_mse: 0.05148 |  0:03:15s\n",
      "epoch 110| loss: 0.04564 | train_rmsle: 0.00233 | train_mae: 0.15197 | train_rmse: 0.1963  | train_mse: 0.03853 | valid_rmsle: 0.00272 | valid_mae: 0.17074 | valid_rmse: 0.21657 | valid_mse: 0.0469  |  0:03:17s\n",
      "epoch 111| loss: 0.04252 | train_rmsle: 0.00236 | train_mae: 0.15178 | train_rmse: 0.1973  | train_mse: 0.03893 | valid_rmsle: 0.00272 | valid_mae: 0.17063 | valid_rmse: 0.21672 | valid_mse: 0.04697 |  0:03:19s\n",
      "epoch 112| loss: 0.04389 | train_rmsle: 0.0025  | train_mae: 0.1585  | train_rmse: 0.20517 | train_mse: 0.0421  | valid_rmsle: 0.00285 | valid_mae: 0.1744  | valid_rmse: 0.22285 | valid_mse: 0.04966 |  0:03:21s\n",
      "epoch 113| loss: 0.04202 | train_rmsle: 0.00215 | train_mae: 0.14787 | train_rmse: 0.1909  | train_mse: 0.03644 | valid_rmsle: 0.00249 | valid_mae: 0.16665 | valid_rmse: 0.20945 | valid_mse: 0.04387 |  0:03:23s\n",
      "epoch 114| loss: 0.0392  | train_rmsle: 0.00214 | train_mae: 0.15112 | train_rmse: 0.19361 | train_mse: 0.03748 | valid_rmsle: 0.00259 | valid_mae: 0.16962 | valid_rmse: 0.21474 | valid_mse: 0.04611 |  0:03:24s\n",
      "epoch 115| loss: 0.04083 | train_rmsle: 0.00208 | train_mae: 0.14457 | train_rmse: 0.18769 | train_mse: 0.03523 | valid_rmsle: 0.0024  | valid_mae: 0.16135 | valid_rmse: 0.20602 | valid_mse: 0.04244 |  0:03:26s\n",
      "epoch 116| loss: 0.03931 | train_rmsle: 0.00185 | train_mae: 0.13722 | train_rmse: 0.17776 | train_mse: 0.0316  | valid_rmsle: 0.00219 | valid_mae: 0.15429 | valid_rmse: 0.19663 | valid_mse: 0.03866 |  0:03:28s\n",
      "epoch 117| loss: 0.03702 | train_rmsle: 0.00189 | train_mae: 0.14207 | train_rmse: 0.18272 | train_mse: 0.03339 | valid_rmsle: 0.00223 | valid_mae: 0.15895 | valid_rmse: 0.20156 | valid_mse: 0.04062 |  0:03:30s\n",
      "epoch 118| loss: 0.03937 | train_rmsle: 0.00173 | train_mae: 0.13316 | train_rmse: 0.17306 | train_mse: 0.02995 | valid_rmsle: 0.00202 | valid_mae: 0.14938 | valid_rmse: 0.18999 | valid_mse: 0.03609 |  0:03:31s\n",
      "epoch 119| loss: 0.03426 | train_rmsle: 0.00204 | train_mae: 0.14412 | train_rmse: 0.18391 | train_mse: 0.03382 | valid_rmsle: 0.00228 | valid_mae: 0.15851 | valid_rmse: 0.20001 | valid_mse: 0.04001 |  0:03:33s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 118 and best_valid_mse = 0.03609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.04063724315144155 RMSE: 0.20158681294033484 R2: 0.8201145828531804 MAE: 0.15241730387870076\n",
      "=====================================\n",
      "[67/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.80104 | train_rmsle: 0.28098 | train_mae: 1.73958 | train_rmse: 1.80559 | train_mse: 3.26014 | valid_rmsle: 0.2819  | valid_mae: 1.74488 | valid_rmse: 1.80973 | valid_mse: 3.27511 |  0:00:01s\n",
      "epoch 1  | loss: 1.04399 | train_rmsle: 0.06962 | train_mae: 0.94459 | train_rmse: 1.03616 | train_mse: 1.07364 | valid_rmsle: 0.06999 | valid_mae: 0.94733 | valid_rmse: 1.04043 | valid_mse: 1.0825  |  0:00:03s\n",
      "epoch 2  | loss: 0.47282 | train_rmsle: 0.04067 | train_mae: 0.7268  | train_rmse: 0.81963 | train_mse: 0.6718  | valid_rmsle: 0.04066 | valid_mae: 0.7268  | valid_rmse: 0.82203 | valid_mse: 0.67574 |  0:00:05s\n",
      "epoch 3  | loss: 0.3402  | train_rmsle: 0.034   | train_mae: 0.66309 | train_rmse: 0.7557  | train_mse: 0.57108 | valid_rmsle: 0.03398 | valid_mae: 0.66318 | valid_rmse: 0.75829 | valid_mse: 0.57501 |  0:00:07s\n",
      "epoch 4  | loss: 0.2865  | train_rmsle: 0.02597 | train_mae: 0.57541 | train_rmse: 0.66598 | train_mse: 0.44353 | valid_rmsle: 0.0258  | valid_mae: 0.57651 | valid_rmse: 0.66735 | valid_mse: 0.44536 |  0:00:09s\n",
      "epoch 5  | loss: 0.28439 | train_rmsle: 0.02069 | train_mae: 0.50647 | train_rmse: 0.59502 | train_mse: 0.35405 | valid_rmsle: 0.02041 | valid_mae: 0.50816 | valid_rmse: 0.59534 | valid_mse: 0.35443 |  0:00:10s\n",
      "epoch 6  | loss: 0.25697 | train_rmsle: 0.02503 | train_mae: 0.56391 | train_rmse: 0.65415 | train_mse: 0.42792 | valid_rmsle: 0.02478 | valid_mae: 0.5644  | valid_rmse: 0.65467 | valid_mse: 0.4286  |  0:00:12s\n",
      "epoch 7  | loss: 0.29194 | train_rmsle: 0.02045 | train_mae: 0.50319 | train_rmse: 0.59137 | train_mse: 0.34972 | valid_rmsle: 0.02006 | valid_mae: 0.50376 | valid_rmse: 0.5901  | valid_mse: 0.34822 |  0:00:14s\n",
      "epoch 8  | loss: 0.24267 | train_rmsle: 0.02051 | train_mae: 0.50441 | train_rmse: 0.59227 | train_mse: 0.35079 | valid_rmsle: 0.02017 | valid_mae: 0.50684 | valid_rmse: 0.59171 | valid_mse: 0.35012 |  0:00:16s\n",
      "epoch 9  | loss: 0.24518 | train_rmsle: 0.01997 | train_mae: 0.49602 | train_rmse: 0.58432 | train_mse: 0.34143 | valid_rmsle: 0.01955 | valid_mae: 0.49649 | valid_rmse: 0.58262 | valid_mse: 0.33945 |  0:00:18s\n",
      "epoch 10 | loss: 0.25758 | train_rmsle: 0.02885 | train_mae: 0.60842 | train_rmse: 0.70009 | train_mse: 0.49012 | valid_rmsle: 0.02861 | valid_mae: 0.60752 | valid_rmse: 0.70055 | valid_mse: 0.49076 |  0:00:19s\n",
      "epoch 11 | loss: 0.25914 | train_rmsle: 0.0173  | train_mae: 0.45257 | train_rmse: 0.54075 | train_mse: 0.29241 | valid_rmsle: 0.01684 | valid_mae: 0.4539  | valid_rmse: 0.53838 | valid_mse: 0.28985 |  0:00:21s\n",
      "epoch 12 | loss: 0.23867 | train_rmsle: 0.01657 | train_mae: 0.43929 | train_rmse: 0.52763 | train_mse: 0.27839 | valid_rmsle: 0.01612 | valid_mae: 0.44079 | valid_rmse: 0.5256  | valid_mse: 0.27625 |  0:00:23s\n",
      "epoch 13 | loss: 0.29092 | train_rmsle: 0.01917 | train_mae: 0.48308 | train_rmse: 0.57182 | train_mse: 0.32698 | valid_rmsle: 0.01865 | valid_mae: 0.48182 | valid_rmse: 0.56894 | valid_mse: 0.32369 |  0:00:25s\n",
      "epoch 14 | loss: 0.24759 | train_rmsle: 0.01563 | train_mae: 0.41855 | train_rmse: 0.50902 | train_mse: 0.2591  | valid_rmsle: 0.01505 | valid_mae: 0.41735 | valid_rmse: 0.50474 | valid_mse: 0.25476 |  0:00:26s\n",
      "epoch 15 | loss: 0.23645 | train_rmsle: 0.01515 | train_mae: 0.40687 | train_rmse: 0.49864 | train_mse: 0.24864 | valid_rmsle: 0.01453 | valid_mae: 0.40633 | valid_rmse: 0.49371 | valid_mse: 0.24375 |  0:00:28s\n",
      "epoch 16 | loss: 0.24176 | train_rmsle: 0.01517 | train_mae: 0.40876 | train_rmse: 0.5005  | train_mse: 0.2505  | valid_rmsle: 0.01476 | valid_mae: 0.4103  | valid_rmse: 0.49897 | valid_mse: 0.24897 |  0:00:30s\n",
      "epoch 17 | loss: 0.2315  | train_rmsle: 0.01468 | train_mae: 0.39108 | train_rmse: 0.48681 | train_mse: 0.23698 | valid_rmsle: 0.0142  | valid_mae: 0.39263 | valid_rmse: 0.48395 | valid_mse: 0.2342  |  0:00:32s\n",
      "epoch 18 | loss: 0.33858 | train_rmsle: 0.02048 | train_mae: 0.43316 | train_rmse: 0.57429 | train_mse: 0.32981 | valid_rmsle: 0.0198  | valid_mae: 0.43136 | valid_rmse: 0.56908 | valid_mse: 0.32385 |  0:00:34s\n",
      "epoch 19 | loss: 0.2916  | train_rmsle: 0.01477 | train_mae: 0.39491 | train_rmse: 0.49005 | train_mse: 0.24015 | valid_rmsle: 0.01444 | valid_mae: 0.3973  | valid_rmse: 0.49013 | valid_mse: 0.24023 |  0:00:35s\n",
      "epoch 20 | loss: 0.24085 | train_rmsle: 0.0179  | train_mae: 0.46229 | train_rmse: 0.55111 | train_mse: 0.30373 | valid_rmsle: 0.01743 | valid_mae: 0.46252 | valid_rmse: 0.54837 | valid_mse: 0.30071 |  0:00:37s\n",
      "epoch 21 | loss: 0.23799 | train_rmsle: 0.01717 | train_mae: 0.44942 | train_rmse: 0.53871 | train_mse: 0.29021 | valid_rmsle: 0.01676 | valid_mae: 0.4501  | valid_rmse: 0.53658 | valid_mse: 0.28792 |  0:00:39s\n",
      "epoch 22 | loss: 0.22881 | train_rmsle: 0.01536 | train_mae: 0.41284 | train_rmse: 0.5042  | train_mse: 0.25422 | valid_rmsle: 0.01504 | valid_mae: 0.41405 | valid_rmse: 0.50373 | valid_mse: 0.25374 |  0:00:41s\n",
      "epoch 23 | loss: 0.23588 | train_rmsle: 0.01458 | train_mae: 0.38333 | train_rmse: 0.483   | train_mse: 0.23329 | valid_rmsle: 0.01403 | valid_mae: 0.38329 | valid_rmse: 0.47913 | valid_mse: 0.22956 |  0:00:42s\n",
      "epoch 24 | loss: 0.23964 | train_rmsle: 0.01497 | train_mae: 0.40315 | train_rmse: 0.49551 | train_mse: 0.24553 | valid_rmsle: 0.01433 | valid_mae: 0.40134 | valid_rmse: 0.49011 | valid_mse: 0.2402  |  0:00:44s\n",
      "epoch 25 | loss: 0.22378 | train_rmsle: 0.01506 | train_mae: 0.4073  | train_rmse: 0.49811 | train_mse: 0.24811 | valid_rmsle: 0.01443 | valid_mae: 0.4052  | valid_rmse: 0.49274 | valid_mse: 0.24279 |  0:00:46s\n",
      "epoch 26 | loss: 0.23102 | train_rmsle: 0.01433 | train_mae: 0.38379 | train_rmse: 0.47985 | train_mse: 0.23025 | valid_rmsle: 0.01389 | valid_mae: 0.38444 | valid_rmse: 0.47778 | valid_mse: 0.22827 |  0:00:48s\n",
      "epoch 27 | loss: 0.2263  | train_rmsle: 0.01656 | train_mae: 0.43901 | train_rmse: 0.5288  | train_mse: 0.27963 | valid_rmsle: 0.01601 | valid_mae: 0.43699 | valid_rmse: 0.52469 | valid_mse: 0.2753  |  0:00:50s\n",
      "epoch 28 | loss: 0.23071 | train_rmsle: 0.01448 | train_mae: 0.37524 | train_rmse: 0.4781  | train_mse: 0.22858 | valid_rmsle: 0.01388 | valid_mae: 0.37311 | valid_rmse: 0.47333 | valid_mse: 0.22404 |  0:00:51s\n",
      "epoch 29 | loss: 0.22307 | train_rmsle: 0.01419 | train_mae: 0.3797  | train_rmse: 0.47664 | train_mse: 0.22719 | valid_rmsle: 0.01365 | valid_mae: 0.37944 | valid_rmse: 0.47318 | valid_mse: 0.2239  |  0:00:53s\n",
      "epoch 30 | loss: 0.2185  | train_rmsle: 0.01422 | train_mae: 0.38141 | train_rmse: 0.47788 | train_mse: 0.22837 | valid_rmsle: 0.01368 | valid_mae: 0.38279 | valid_rmse: 0.4747  | valid_mse: 0.22534 |  0:00:55s\n",
      "epoch 31 | loss: 0.22262 | train_rmsle: 0.01419 | train_mae: 0.38184 | train_rmse: 0.47752 | train_mse: 0.22803 | valid_rmsle: 0.01388 | valid_mae: 0.38535 | valid_rmse: 0.4781  | valid_mse: 0.22858 |  0:00:57s\n",
      "epoch 32 | loss: 0.22171 | train_rmsle: 0.01443 | train_mae: 0.39271 | train_rmse: 0.48534 | train_mse: 0.23556 | valid_rmsle: 0.01399 | valid_mae: 0.39525 | valid_rmse: 0.48328 | valid_mse: 0.23356 |  0:00:58s\n",
      "epoch 33 | loss: 0.23101 | train_rmsle: 0.01454 | train_mae: 0.37358 | train_rmse: 0.47899 | train_mse: 0.22943 | valid_rmsle: 0.01386 | valid_mae: 0.37119 | valid_rmse: 0.47271 | valid_mse: 0.22346 |  0:01:00s\n",
      "epoch 34 | loss: 0.2203  | train_rmsle: 0.01411 | train_mae: 0.3864  | train_rmse: 0.47897 | train_mse: 0.22941 | valid_rmsle: 0.0138  | valid_mae: 0.38812 | valid_rmse: 0.47894 | valid_mse: 0.22938 |  0:01:02s\n",
      "epoch 35 | loss: 0.22183 | train_rmsle: 0.01414 | train_mae: 0.37803 | train_rmse: 0.4753  | train_mse: 0.22591 | valid_rmsle: 0.01362 | valid_mae: 0.37467 | valid_rmse: 0.47161 | valid_mse: 0.22242 |  0:01:04s\n",
      "epoch 36 | loss: 0.22484 | train_rmsle: 0.01403 | train_mae: 0.37545 | train_rmse: 0.47377 | train_mse: 0.22446 | valid_rmsle: 0.01379 | valid_mae: 0.37931 | valid_rmse: 0.47459 | valid_mse: 0.22523 |  0:01:06s\n",
      "epoch 37 | loss: 0.22596 | train_rmsle: 0.01491 | train_mae: 0.37404 | train_rmse: 0.48448 | train_mse: 0.23472 | valid_rmsle: 0.01466 | valid_mae: 0.3825  | valid_rmse: 0.48623 | valid_mse: 0.23642 |  0:01:07s\n",
      "epoch 38 | loss: 0.21975 | train_rmsle: 0.0139  | train_mae: 0.37326 | train_rmse: 0.47142 | train_mse: 0.22224 | valid_rmsle: 0.01364 | valid_mae: 0.37644 | valid_rmse: 0.4725  | valid_mse: 0.22326 |  0:01:09s\n",
      "epoch 39 | loss: 0.21465 | train_rmsle: 0.01395 | train_mae: 0.38309 | train_rmse: 0.4763  | train_mse: 0.22686 | valid_rmsle: 0.01364 | valid_mae: 0.38588 | valid_rmse: 0.47669 | valid_mse: 0.22723 |  0:01:11s\n",
      "epoch 40 | loss: 0.21606 | train_rmsle: 0.01402 | train_mae: 0.3774  | train_rmse: 0.47419 | train_mse: 0.22486 | valid_rmsle: 0.01342 | valid_mae: 0.37657 | valid_rmse: 0.47014 | valid_mse: 0.22103 |  0:01:13s\n",
      "epoch 41 | loss: 0.21571 | train_rmsle: 0.01415 | train_mae: 0.37146 | train_rmse: 0.47324 | train_mse: 0.22395 | valid_rmsle: 0.01401 | valid_mae: 0.37773 | valid_rmse: 0.4766  | valid_mse: 0.22715 |  0:01:15s\n",
      "epoch 42 | loss: 0.21428 | train_rmsle: 0.01397 | train_mae: 0.38075 | train_rmse: 0.47494 | train_mse: 0.22557 | valid_rmsle: 0.01373 | valid_mae: 0.38496 | valid_rmse: 0.47643 | valid_mse: 0.22698 |  0:01:16s\n",
      "epoch 43 | loss: 0.21615 | train_rmsle: 0.01409 | train_mae: 0.38607 | train_rmse: 0.4788  | train_mse: 0.22925 | valid_rmsle: 0.01399 | valid_mae: 0.39181 | valid_rmse: 0.48318 | valid_mse: 0.23346 |  0:01:18s\n",
      "epoch 44 | loss: 0.21215 | train_rmsle: 0.01389 | train_mae: 0.37274 | train_rmse: 0.47057 | train_mse: 0.22144 | valid_rmsle: 0.01369 | valid_mae: 0.37967 | valid_rmse: 0.47369 | valid_mse: 0.22438 |  0:01:20s\n",
      "epoch 45 | loss: 0.21783 | train_rmsle: 0.01415 | train_mae: 0.37131 | train_rmse: 0.47337 | train_mse: 0.22408 | valid_rmsle: 0.01394 | valid_mae: 0.3766  | valid_rmse: 0.47606 | valid_mse: 0.22663 |  0:01:22s\n",
      "epoch 46 | loss: 0.21562 | train_rmsle: 0.01458 | train_mae: 0.37136 | train_rmse: 0.47879 | train_mse: 0.22924 | valid_rmsle: 0.01429 | valid_mae: 0.3737  | valid_rmse: 0.47989 | valid_mse: 0.23029 |  0:01:23s\n",
      "epoch 47 | loss: 0.21505 | train_rmsle: 0.01394 | train_mae: 0.37063 | train_rmse: 0.4704  | train_mse: 0.22128 | valid_rmsle: 0.0138  | valid_mae: 0.37573 | valid_rmse: 0.47421 | valid_mse: 0.22488 |  0:01:25s\n",
      "epoch 48 | loss: 0.21547 | train_rmsle: 0.01392 | train_mae: 0.36953 | train_rmse: 0.46965 | train_mse: 0.22057 | valid_rmsle: 0.01378 | valid_mae: 0.37661 | valid_rmse: 0.47579 | valid_mse: 0.22638 |  0:01:27s\n",
      "epoch 49 | loss: 0.21446 | train_rmsle: 0.01412 | train_mae: 0.36833 | train_rmse: 0.47167 | train_mse: 0.22247 | valid_rmsle: 0.01387 | valid_mae: 0.37474 | valid_rmse: 0.47541 | valid_mse: 0.22601 |  0:01:29s\n",
      "epoch 50 | loss: 0.21298 | train_rmsle: 0.01412 | train_mae: 0.36899 | train_rmse: 0.47172 | train_mse: 0.22252 | valid_rmsle: 0.01371 | valid_mae: 0.37236 | valid_rmse: 0.47109 | valid_mse: 0.22192 |  0:01:30s\n",
      "epoch 51 | loss: 0.21565 | train_rmsle: 0.01376 | train_mae: 0.37915 | train_rmse: 0.47209 | train_mse: 0.22287 | valid_rmsle: 0.01365 | valid_mae: 0.38611 | valid_rmse: 0.47607 | valid_mse: 0.22664 |  0:01:32s\n",
      "epoch 52 | loss: 0.2132  | train_rmsle: 0.01415 | train_mae: 0.36935 | train_rmse: 0.47282 | train_mse: 0.22356 | valid_rmsle: 0.01392 | valid_mae: 0.37384 | valid_rmse: 0.4755  | valid_mse: 0.2261  |  0:01:34s\n",
      "epoch 53 | loss: 0.21349 | train_rmsle: 0.01381 | train_mae: 0.37014 | train_rmse: 0.46858 | train_mse: 0.21957 | valid_rmsle: 0.01377 | valid_mae: 0.37903 | valid_rmse: 0.47493 | valid_mse: 0.22556 |  0:01:36s\n",
      "epoch 54 | loss: 0.21131 | train_rmsle: 0.01368 | train_mae: 0.37309 | train_rmse: 0.46835 | train_mse: 0.21936 | valid_rmsle: 0.0135  | valid_mae: 0.38023 | valid_rmse: 0.47192 | valid_mse: 0.2227  |  0:01:38s\n",
      "epoch 55 | loss: 0.21072 | train_rmsle: 0.01374 | train_mae: 0.37276 | train_rmse: 0.46893 | train_mse: 0.21989 | valid_rmsle: 0.01361 | valid_mae: 0.38143 | valid_rmse: 0.47348 | valid_mse: 0.22419 |  0:01:39s\n",
      "epoch 56 | loss: 0.21296 | train_rmsle: 0.01389 | train_mae: 0.36551 | train_rmse: 0.4683  | train_mse: 0.21931 | valid_rmsle: 0.01375 | valid_mae: 0.37518 | valid_rmse: 0.47301 | valid_mse: 0.22374 |  0:01:41s\n",
      "epoch 57 | loss: 0.2133  | train_rmsle: 0.01375 | train_mae: 0.36629 | train_rmse: 0.4669  | train_mse: 0.218   | valid_rmsle: 0.01363 | valid_mae: 0.37779 | valid_rmse: 0.47232 | valid_mse: 0.22309 |  0:01:43s\n",
      "epoch 58 | loss: 0.2099  | train_rmsle: 0.01376 | train_mae: 0.36793 | train_rmse: 0.46723 | train_mse: 0.2183  | valid_rmsle: 0.01347 | valid_mae: 0.37468 | valid_rmse: 0.4691  | valid_mse: 0.22005 |  0:01:45s\n",
      "epoch 59 | loss: 0.20836 | train_rmsle: 0.01357 | train_mae: 0.36794 | train_rmse: 0.46467 | train_mse: 0.21592 | valid_rmsle: 0.01345 | valid_mae: 0.37567 | valid_rmse: 0.46929 | valid_mse: 0.22024 |  0:01:47s\n",
      "epoch 60 | loss: 0.21009 | train_rmsle: 0.01347 | train_mae: 0.36822 | train_rmse: 0.46367 | train_mse: 0.21499 | valid_rmsle: 0.01349 | valid_mae: 0.38024 | valid_rmse: 0.4707  | valid_mse: 0.22156 |  0:01:48s\n",
      "epoch 61 | loss: 0.21027 | train_rmsle: 0.01404 | train_mae: 0.36455 | train_rmse: 0.46949 | train_mse: 0.22042 | valid_rmsle: 0.01399 | valid_mae: 0.37692 | valid_rmse: 0.47578 | valid_mse: 0.22636 |  0:01:50s\n",
      "epoch 62 | loss: 0.20737 | train_rmsle: 0.01397 | train_mae: 0.36534 | train_rmse: 0.46893 | train_mse: 0.2199  | valid_rmsle: 0.01375 | valid_mae: 0.3738  | valid_rmse: 0.47157 | valid_mse: 0.22238 |  0:01:52s\n",
      "epoch 63 | loss: 0.20585 | train_rmsle: 0.01341 | train_mae: 0.36204 | train_rmse: 0.46063 | train_mse: 0.21218 | valid_rmsle: 0.01343 | valid_mae: 0.37443 | valid_rmse: 0.46733 | valid_mse: 0.2184  |  0:01:54s\n",
      "epoch 64 | loss: 0.20477 | train_rmsle: 0.01341 | train_mae: 0.36383 | train_rmse: 0.46156 | train_mse: 0.21303 | valid_rmsle: 0.0133  | valid_mae: 0.3713  | valid_rmse: 0.46549 | valid_mse: 0.21668 |  0:01:55s\n",
      "epoch 65 | loss: 0.2048  | train_rmsle: 0.01326 | train_mae: 0.3644  | train_rmse: 0.45994 | train_mse: 0.21154 | valid_rmsle: 0.01343 | valid_mae: 0.37819 | valid_rmse: 0.46921 | valid_mse: 0.22016 |  0:01:57s\n",
      "epoch 66 | loss: 0.20466 | train_rmsle: 0.01336 | train_mae: 0.35928 | train_rmse: 0.45909 | train_mse: 0.21076 | valid_rmsle: 0.01344 | valid_mae: 0.37014 | valid_rmse: 0.46705 | valid_mse: 0.21813 |  0:01:59s\n",
      "epoch 67 | loss: 0.20234 | train_rmsle: 0.01301 | train_mae: 0.36481 | train_rmse: 0.4572  | train_mse: 0.20903 | valid_rmsle: 0.01319 | valid_mae: 0.37613 | valid_rmse: 0.46631 | valid_mse: 0.21744 |  0:02:01s\n",
      "epoch 68 | loss: 0.19959 | train_rmsle: 0.01348 | train_mae: 0.35448 | train_rmse: 0.45894 | train_mse: 0.21063 | valid_rmsle: 0.01358 | valid_mae: 0.37099 | valid_rmse: 0.46832 | valid_mse: 0.21932 |  0:02:02s\n",
      "epoch 69 | loss: 0.19682 | train_rmsle: 0.01299 | train_mae: 0.35235 | train_rmse: 0.45165 | train_mse: 0.20399 | valid_rmsle: 0.01296 | valid_mae: 0.36356 | valid_rmse: 0.45789 | valid_mse: 0.20966 |  0:02:04s\n",
      "epoch 70 | loss: 0.19394 | train_rmsle: 0.01318 | train_mae: 0.37749 | train_rmse: 0.46536 | train_mse: 0.21656 | valid_rmsle: 0.01362 | valid_mae: 0.39443 | valid_rmse: 0.47909 | valid_mse: 0.22952 |  0:02:06s\n",
      "epoch 71 | loss: 0.19118 | train_rmsle: 0.0129  | train_mae: 0.34607 | train_rmse: 0.44884 | train_mse: 0.20146 | valid_rmsle: 0.01325 | valid_mae: 0.36476 | valid_rmse: 0.46287 | valid_mse: 0.21425 |  0:02:08s\n",
      "epoch 72 | loss: 0.18811 | train_rmsle: 0.01194 | train_mae: 0.33978 | train_rmse: 0.43407 | train_mse: 0.18841 | valid_rmsle: 0.01252 | valid_mae: 0.3599  | valid_rmse: 0.45232 | valid_mse: 0.2046  |  0:02:09s\n",
      "epoch 73 | loss: 0.18563 | train_rmsle: 0.01173 | train_mae: 0.34165 | train_rmse: 0.43261 | train_mse: 0.18715 | valid_rmsle: 0.01228 | valid_mae: 0.36009 | valid_rmse: 0.44954 | valid_mse: 0.20208 |  0:02:11s\n",
      "epoch 74 | loss: 0.18446 | train_rmsle: 0.01167 | train_mae: 0.34427 | train_rmse: 0.43268 | train_mse: 0.18721 | valid_rmsle: 0.01227 | valid_mae: 0.36307 | valid_rmse: 0.4503  | valid_mse: 0.20277 |  0:02:13s\n",
      "epoch 75 | loss: 0.17827 | train_rmsle: 0.0114  | train_mae: 0.32856 | train_rmse: 0.42304 | train_mse: 0.17896 | valid_rmsle: 0.01214 | valid_mae: 0.35238 | valid_rmse: 0.44483 | valid_mse: 0.19787 |  0:02:15s\n",
      "epoch 76 | loss: 0.17177 | train_rmsle: 0.01085 | train_mae: 0.32579 | train_rmse: 0.4147  | train_mse: 0.17198 | valid_rmsle: 0.01166 | valid_mae: 0.35124 | valid_rmse: 0.4375  | valid_mse: 0.1914  |  0:02:17s\n",
      "epoch 77 | loss: 0.16741 | train_rmsle: 0.01065 | train_mae: 0.32081 | train_rmse: 0.41018 | train_mse: 0.16825 | valid_rmsle: 0.0115  | valid_mae: 0.34694 | valid_rmse: 0.43373 | valid_mse: 0.18812 |  0:02:18s\n",
      "epoch 78 | loss: 0.16407 | train_rmsle: 0.0104  | train_mae: 0.31674 | train_rmse: 0.40482 | train_mse: 0.16388 | valid_rmsle: 0.01134 | valid_mae: 0.34341 | valid_rmse: 0.43045 | valid_mse: 0.18528 |  0:02:20s\n",
      "epoch 79 | loss: 0.16032 | train_rmsle: 0.01047 | train_mae: 0.31849 | train_rmse: 0.40625 | train_mse: 0.16504 | valid_rmsle: 0.01177 | valid_mae: 0.34746 | valid_rmse: 0.43854 | valid_mse: 0.19232 |  0:02:22s\n",
      "epoch 80 | loss: 0.15796 | train_rmsle: 0.0102  | train_mae: 0.31552 | train_rmse: 0.4015  | train_mse: 0.1612  | valid_rmsle: 0.01124 | valid_mae: 0.34011 | valid_rmse: 0.42967 | valid_mse: 0.18461 |  0:02:24s\n",
      "epoch 81 | loss: 0.15556 | train_rmsle: 0.00997 | train_mae: 0.31749 | train_rmse: 0.39925 | train_mse: 0.1594  | valid_rmsle: 0.01049 | valid_mae: 0.33401 | valid_rmse: 0.41632 | valid_mse: 0.17332 |  0:02:25s\n",
      "epoch 82 | loss: 0.15227 | train_rmsle: 0.00985 | train_mae: 0.31701 | train_rmse: 0.39788 | train_mse: 0.15831 | valid_rmsle: 0.01041 | valid_mae: 0.33045 | valid_rmse: 0.41633 | valid_mse: 0.17333 |  0:02:27s\n",
      "epoch 83 | loss: 0.1509  | train_rmsle: 0.00924 | train_mae: 0.3001  | train_rmse: 0.38225 | train_mse: 0.14612 | valid_rmsle: 0.00969 | valid_mae: 0.31193 | valid_rmse: 0.40071 | valid_mse: 0.16057 |  0:02:29s\n",
      "epoch 84 | loss: 0.14052 | train_rmsle: 0.00898 | train_mae: 0.29851 | train_rmse: 0.37794 | train_mse: 0.14284 | valid_rmsle: 0.00994 | valid_mae: 0.3162  | valid_rmse: 0.41136 | valid_mse: 0.16921 |  0:02:31s\n",
      "epoch 85 | loss: 0.13276 | train_rmsle: 0.00837 | train_mae: 0.28257 | train_rmse: 0.36231 | train_mse: 0.13127 | valid_rmsle: 0.00905 | valid_mae: 0.29948 | valid_rmse: 0.3874  | valid_mse: 0.15008 |  0:02:33s\n",
      "epoch 86 | loss: 0.12802 | train_rmsle: 0.00788 | train_mae: 0.27836 | train_rmse: 0.35429 | train_mse: 0.12552 | valid_rmsle: 0.00811 | valid_mae: 0.2909  | valid_rmse: 0.36672 | valid_mse: 0.13448 |  0:02:34s\n",
      "epoch 87 | loss: 0.12378 | train_rmsle: 0.00754 | train_mae: 0.27183 | train_rmse: 0.34609 | train_mse: 0.11978 | valid_rmsle: 0.00787 | valid_mae: 0.28921 | valid_rmse: 0.35979 | valid_mse: 0.12945 |  0:02:36s\n",
      "epoch 88 | loss: 0.11807 | train_rmsle: 0.00725 | train_mae: 0.26344 | train_rmse: 0.3378  | train_mse: 0.11411 | valid_rmsle: 0.00747 | valid_mae: 0.27703 | valid_rmse: 0.35085 | valid_mse: 0.12309 |  0:02:38s\n",
      "epoch 89 | loss: 0.11614 | train_rmsle: 0.00705 | train_mae: 0.2574  | train_rmse: 0.33253 | train_mse: 0.11058 | valid_rmsle: 0.00739 | valid_mae: 0.27178 | valid_rmse: 0.35024 | valid_mse: 0.12267 |  0:02:40s\n",
      "epoch 90 | loss: 0.1078  | train_rmsle: 0.00674 | train_mae: 0.26065 | train_rmse: 0.32888 | train_mse: 0.10816 | valid_rmsle: 0.00692 | valid_mae: 0.2688  | valid_rmse: 0.34174 | valid_mse: 0.11679 |  0:02:42s\n",
      "epoch 91 | loss: 0.10347 | train_rmsle: 0.0067  | train_mae: 0.26061 | train_rmse: 0.32817 | train_mse: 0.1077  | valid_rmsle: 0.0069  | valid_mae: 0.26736 | valid_rmse: 0.3393  | valid_mse: 0.11512 |  0:02:43s\n",
      "epoch 92 | loss: 0.10103 | train_rmsle: 0.00634 | train_mae: 0.24172 | train_rmse: 0.31387 | train_mse: 0.09852 | valid_rmsle: 0.00659 | valid_mae: 0.25342 | valid_rmse: 0.326   | valid_mse: 0.10628 |  0:02:45s\n",
      "epoch 93 | loss: 0.09841 | train_rmsle: 0.00616 | train_mae: 0.23768 | train_rmse: 0.31006 | train_mse: 0.09614 | valid_rmsle: 0.00653 | valid_mae: 0.25359 | valid_rmse: 0.32666 | valid_mse: 0.10671 |  0:02:47s\n",
      "epoch 94 | loss: 0.09569 | train_rmsle: 0.00568 | train_mae: 0.23549 | train_rmse: 0.30084 | train_mse: 0.09051 | valid_rmsle: 0.00599 | valid_mae: 0.24815 | valid_rmse: 0.31447 | valid_mse: 0.09889 |  0:02:49s\n",
      "epoch 95 | loss: 0.08914 | train_rmsle: 0.00543 | train_mae: 0.2267  | train_rmse: 0.29248 | train_mse: 0.08555 | valid_rmsle: 0.00597 | valid_mae: 0.24447 | valid_rmse: 0.31341 | valid_mse: 0.09823 |  0:02:51s\n",
      "epoch 96 | loss: 0.08361 | train_rmsle: 0.00501 | train_mae: 0.216   | train_rmse: 0.28031 | train_mse: 0.07857 | valid_rmsle: 0.00573 | valid_mae: 0.2381  | valid_rmse: 0.31051 | valid_mse: 0.09642 |  0:02:52s\n",
      "epoch 97 | loss: 0.07969 | train_rmsle: 0.00481 | train_mae: 0.21215 | train_rmse: 0.2754  | train_mse: 0.07585 | valid_rmsle: 0.00547 | valid_mae: 0.23317 | valid_rmse: 0.30421 | valid_mse: 0.09254 |  0:02:54s\n",
      "epoch 98 | loss: 0.07544 | train_rmsle: 0.00507 | train_mae: 0.22737 | train_rmse: 0.28679 | train_mse: 0.08225 | valid_rmsle: 0.00533 | valid_mae: 0.2378  | valid_rmse: 0.30098 | valid_mse: 0.09059 |  0:02:56s\n",
      "epoch 99 | loss: 0.07379 | train_rmsle: 0.00441 | train_mae: 0.20685 | train_rmse: 0.26495 | train_mse: 0.0702  | valid_rmsle: 0.00483 | valid_mae: 0.22515 | valid_rmse: 0.28379 | valid_mse: 0.08054 |  0:02:58s\n",
      "epoch 100| loss: 0.07322 | train_rmsle: 0.00421 | train_mae: 0.20341 | train_rmse: 0.26006 | train_mse: 0.06763 | valid_rmsle: 0.00469 | valid_mae: 0.22178 | valid_rmse: 0.27975 | valid_mse: 0.07826 |  0:02:59s\n",
      "epoch 101| loss: 0.06755 | train_rmsle: 0.00414 | train_mae: 0.19627 | train_rmse: 0.25525 | train_mse: 0.06515 | valid_rmsle: 0.00466 | valid_mae: 0.21915 | valid_rmse: 0.2775  | valid_mse: 0.07701 |  0:03:01s\n",
      "epoch 102| loss: 0.06375 | train_rmsle: 0.0037  | train_mae: 0.19037 | train_rmse: 0.24367 | train_mse: 0.05938 | valid_rmsle: 0.00418 | valid_mae: 0.20929 | valid_rmse: 0.26496 | valid_mse: 0.0702  |  0:03:03s\n",
      "epoch 103| loss: 0.05955 | train_rmsle: 0.00341 | train_mae: 0.18021 | train_rmse: 0.23295 | train_mse: 0.05427 | valid_rmsle: 0.00391 | valid_mae: 0.20092 | valid_rmse: 0.25592 | valid_mse: 0.06549 |  0:03:05s\n",
      "epoch 104| loss: 0.05802 | train_rmsle: 0.00319 | train_mae: 0.17399 | train_rmse: 0.22507 | train_mse: 0.05066 | valid_rmsle: 0.00365 | valid_mae: 0.19553 | valid_rmse: 0.24717 | valid_mse: 0.06109 |  0:03:07s\n",
      "epoch 105| loss: 0.05701 | train_rmsle: 0.00408 | train_mae: 0.21233 | train_rmse: 0.26284 | train_mse: 0.06909 | valid_rmsle: 0.00456 | valid_mae: 0.2267  | valid_rmse: 0.28134 | valid_mse: 0.07915 |  0:03:08s\n",
      "epoch 106| loss: 0.05958 | train_rmsle: 0.00303 | train_mae: 0.17303 | train_rmse: 0.22133 | train_mse: 0.04899 | valid_rmsle: 0.00357 | valid_mae: 0.19346 | valid_rmse: 0.24538 | valid_mse: 0.06021 |  0:03:10s\n",
      "epoch 107| loss: 0.05097 | train_rmsle: 0.00287 | train_mae: 0.16874 | train_rmse: 0.21592 | train_mse: 0.04662 | valid_rmsle: 0.00334 | valid_mae: 0.18738 | valid_rmse: 0.2375  | valid_mse: 0.05641 |  0:03:12s\n",
      "epoch 108| loss: 0.04962 | train_rmsle: 0.00294 | train_mae: 0.17597 | train_rmse: 0.22239 | train_mse: 0.04946 | valid_rmsle: 0.00335 | valid_mae: 0.19225 | valid_rmse: 0.24121 | valid_mse: 0.05818 |  0:03:14s\n",
      "epoch 109| loss: 0.04867 | train_rmsle: 0.00265 | train_mae: 0.159   | train_rmse: 0.20628 | train_mse: 0.04255 | valid_rmsle: 0.00305 | valid_mae: 0.17862 | valid_rmse: 0.22689 | valid_mse: 0.05148 |  0:03:16s\n",
      "epoch 110| loss: 0.04564 | train_rmsle: 0.00233 | train_mae: 0.15197 | train_rmse: 0.1963  | train_mse: 0.03853 | valid_rmsle: 0.00272 | valid_mae: 0.17074 | valid_rmse: 0.21657 | valid_mse: 0.0469  |  0:03:17s\n",
      "epoch 111| loss: 0.04252 | train_rmsle: 0.00236 | train_mae: 0.15178 | train_rmse: 0.1973  | train_mse: 0.03893 | valid_rmsle: 0.00272 | valid_mae: 0.17063 | valid_rmse: 0.21672 | valid_mse: 0.04697 |  0:03:19s\n",
      "epoch 112| loss: 0.04389 | train_rmsle: 0.0025  | train_mae: 0.1585  | train_rmse: 0.20517 | train_mse: 0.0421  | valid_rmsle: 0.00285 | valid_mae: 0.1744  | valid_rmse: 0.22285 | valid_mse: 0.04966 |  0:03:21s\n",
      "epoch 113| loss: 0.04202 | train_rmsle: 0.00215 | train_mae: 0.14787 | train_rmse: 0.1909  | train_mse: 0.03644 | valid_rmsle: 0.00249 | valid_mae: 0.16665 | valid_rmse: 0.20945 | valid_mse: 0.04387 |  0:03:23s\n",
      "epoch 114| loss: 0.0392  | train_rmsle: 0.00214 | train_mae: 0.15112 | train_rmse: 0.19361 | train_mse: 0.03748 | valid_rmsle: 0.00259 | valid_mae: 0.16962 | valid_rmse: 0.21474 | valid_mse: 0.04611 |  0:03:24s\n",
      "epoch 115| loss: 0.04083 | train_rmsle: 0.00208 | train_mae: 0.14457 | train_rmse: 0.18769 | train_mse: 0.03523 | valid_rmsle: 0.0024  | valid_mae: 0.16135 | valid_rmse: 0.20602 | valid_mse: 0.04244 |  0:03:26s\n",
      "epoch 116| loss: 0.03931 | train_rmsle: 0.00185 | train_mae: 0.13722 | train_rmse: 0.17776 | train_mse: 0.0316  | valid_rmsle: 0.00219 | valid_mae: 0.15429 | valid_rmse: 0.19663 | valid_mse: 0.03866 |  0:03:28s\n",
      "epoch 117| loss: 0.03702 | train_rmsle: 0.00189 | train_mae: 0.14207 | train_rmse: 0.18272 | train_mse: 0.03339 | valid_rmsle: 0.00223 | valid_mae: 0.15895 | valid_rmse: 0.20156 | valid_mse: 0.04062 |  0:03:30s\n",
      "epoch 118| loss: 0.03937 | train_rmsle: 0.00173 | train_mae: 0.13316 | train_rmse: 0.17306 | train_mse: 0.02995 | valid_rmsle: 0.00202 | valid_mae: 0.14938 | valid_rmse: 0.18999 | valid_mse: 0.03609 |  0:03:32s\n",
      "epoch 119| loss: 0.03426 | train_rmsle: 0.00204 | train_mae: 0.14412 | train_rmse: 0.18391 | train_mse: 0.03382 | valid_rmsle: 0.00228 | valid_mae: 0.15851 | valid_rmse: 0.20001 | valid_mse: 0.04001 |  0:03:33s\n",
      "epoch 120| loss: 0.03465 | train_rmsle: 0.00182 | train_mae: 0.13668 | train_rmse: 0.17417 | train_mse: 0.03033 | valid_rmsle: 0.00213 | valid_mae: 0.15259 | valid_rmse: 0.19382 | valid_mse: 0.03757 |  0:03:35s\n",
      "epoch 121| loss: 0.03337 | train_rmsle: 0.00172 | train_mae: 0.13554 | train_rmse: 0.17225 | train_mse: 0.02967 | valid_rmsle: 0.00204 | valid_mae: 0.15101 | valid_rmse: 0.19167 | valid_mse: 0.03674 |  0:03:37s\n",
      "epoch 122| loss: 0.03003 | train_rmsle: 0.00205 | train_mae: 0.1442  | train_rmse: 0.18125 | train_mse: 0.03285 | valid_rmsle: 0.00226 | valid_mae: 0.15695 | valid_rmse: 0.19663 | valid_mse: 0.03866 |  0:03:39s\n",
      "epoch 123| loss: 0.03603 | train_rmsle: 0.00148 | train_mae: 0.12527 | train_rmse: 0.16175 | train_mse: 0.02616 | valid_rmsle: 0.00186 | valid_mae: 0.14515 | valid_rmse: 0.18357 | valid_mse: 0.0337  |  0:03:41s\n",
      "epoch 124| loss: 0.03105 | train_rmsle: 0.00231 | train_mae: 0.15162 | train_rmse: 0.19018 | train_mse: 0.03617 | valid_rmsle: 0.00246 | valid_mae: 0.16241 | valid_rmse: 0.2027  | valid_mse: 0.04109 |  0:03:42s\n",
      "epoch 125| loss: 0.03612 | train_rmsle: 0.00303 | train_mae: 0.17284 | train_rmse: 0.21524 | train_mse: 0.04633 | valid_rmsle: 0.00307 | valid_mae: 0.18091 | valid_rmse: 0.22297 | valid_mse: 0.04972 |  0:03:44s\n",
      "epoch 126| loss: 0.03527 | train_rmsle: 0.00356 | train_mae: 0.18006 | train_rmse: 0.22476 | train_mse: 0.05052 | valid_rmsle: 0.00354 | valid_mae: 0.18841 | valid_rmse: 0.23145 | valid_mse: 0.05357 |  0:03:46s\n",
      "epoch 127| loss: 0.03113 | train_rmsle: 0.00141 | train_mae: 0.12076 | train_rmse: 0.15623 | train_mse: 0.02441 | valid_rmsle: 0.00162 | valid_mae: 0.13567 | valid_rmse: 0.17129 | valid_mse: 0.02934 |  0:03:48s\n",
      "epoch 128| loss: 0.03242 | train_rmsle: 0.00135 | train_mae: 0.12025 | train_rmse: 0.15538 | train_mse: 0.02414 | valid_rmsle: 0.00161 | valid_mae: 0.13596 | valid_rmse: 0.17118 | valid_mse: 0.0293  |  0:03:49s\n",
      "epoch 129| loss: 0.02946 | train_rmsle: 0.00131 | train_mae: 0.11892 | train_rmse: 0.15376 | train_mse: 0.02364 | valid_rmsle: 0.00161 | valid_mae: 0.13486 | valid_rmse: 0.17184 | valid_mse: 0.02953 |  0:03:51s\n",
      "epoch 130| loss: 0.028   | train_rmsle: 0.00119 | train_mae: 0.11303 | train_rmse: 0.14688 | train_mse: 0.02157 | valid_rmsle: 0.0015  | valid_mae: 0.1299  | valid_rmse: 0.16611 | valid_mse: 0.02759 |  0:03:53s\n",
      "epoch 131| loss: 0.02838 | train_rmsle: 0.00129 | train_mae: 0.11828 | train_rmse: 0.15283 | train_mse: 0.02336 | valid_rmsle: 0.00151 | valid_mae: 0.13023 | valid_rmse: 0.1666  | valid_mse: 0.02776 |  0:03:55s\n",
      "epoch 132| loss: 0.02775 | train_rmsle: 0.0015  | train_mae: 0.12947 | train_rmse: 0.16319 | train_mse: 0.02663 | valid_rmsle: 0.00172 | valid_mae: 0.14133 | valid_rmse: 0.17731 | valid_mse: 0.03144 |  0:03:57s\n",
      "epoch 133| loss: 0.02536 | train_rmsle: 0.00132 | train_mae: 0.1171  | train_rmse: 0.14976 | train_mse: 0.02243 | valid_rmsle: 0.00156 | valid_mae: 0.13088 | valid_rmse: 0.16471 | valid_mse: 0.02713 |  0:03:58s\n",
      "epoch 134| loss: 0.02525 | train_rmsle: 0.00109 | train_mae: 0.10812 | train_rmse: 0.14008 | train_mse: 0.01962 | valid_rmsle: 0.00138 | valid_mae: 0.12538 | valid_rmse: 0.15888 | valid_mse: 0.02524 |  0:04:00s\n",
      "epoch 135| loss: 0.02558 | train_rmsle: 0.00119 | train_mae: 0.11581 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00145 | valid_mae: 0.12974 | valid_rmse: 0.16379 | valid_mse: 0.02683 |  0:04:02s\n",
      "epoch 136| loss: 0.02462 | train_rmsle: 0.00133 | train_mae: 0.12395 | train_rmse: 0.15671 | train_mse: 0.02456 | valid_rmsle: 0.00163 | valid_mae: 0.13841 | valid_rmse: 0.17416 | valid_mse: 0.03033 |  0:04:04s\n",
      "epoch 137| loss: 0.02447 | train_rmsle: 0.00127 | train_mae: 0.11673 | train_rmse: 0.14641 | train_mse: 0.02144 | valid_rmsle: 0.00149 | valid_mae: 0.12951 | valid_rmse: 0.16113 | valid_mse: 0.02596 |  0:04:05s\n",
      "epoch 138| loss: 0.02311 | train_rmsle: 0.00102 | train_mae: 0.10501 | train_rmse: 0.13395 | train_mse: 0.01794 | valid_rmsle: 0.00127 | valid_mae: 0.11889 | valid_rmse: 0.15088 | valid_mse: 0.02277 |  0:04:07s\n",
      "epoch 139| loss: 0.02319 | train_rmsle: 0.00104 | train_mae: 0.10712 | train_rmse: 0.13579 | train_mse: 0.01844 | valid_rmsle: 0.0013  | valid_mae: 0.1231  | valid_rmse: 0.15359 | valid_mse: 0.02359 |  0:04:09s\n",
      "epoch 140| loss: 0.02182 | train_rmsle: 0.00091 | train_mae: 0.099   | train_rmse: 0.12698 | train_mse: 0.01612 | valid_rmsle: 0.00117 | valid_mae: 0.11453 | valid_rmse: 0.1456  | valid_mse: 0.0212  |  0:04:11s\n",
      "epoch 141| loss: 0.02282 | train_rmsle: 0.00175 | train_mae: 0.14038 | train_rmse: 0.17002 | train_mse: 0.02891 | valid_rmsle: 0.00199 | valid_mae: 0.15199 | valid_rmse: 0.18411 | valid_mse: 0.0339  |  0:04:13s\n",
      "epoch 142| loss: 0.02336 | train_rmsle: 0.0012  | train_mae: 0.11239 | train_rmse: 0.14159 | train_mse: 0.02005 | valid_rmsle: 0.00142 | valid_mae: 0.12502 | valid_rmse: 0.15683 | valid_mse: 0.0246  |  0:04:14s\n",
      "epoch 143| loss: 0.02452 | train_rmsle: 0.00134 | train_mae: 0.12167 | train_rmse: 0.15048 | train_mse: 0.02264 | valid_rmsle: 0.0016  | valid_mae: 0.13464 | valid_rmse: 0.16666 | valid_mse: 0.02777 |  0:04:16s\n",
      "epoch 144| loss: 0.02087 | train_rmsle: 0.00086 | train_mae: 0.09674 | train_rmse: 0.12548 | train_mse: 0.01575 | valid_rmsle: 0.00109 | valid_mae: 0.11111 | valid_rmse: 0.14151 | valid_mse: 0.02003 |  0:04:18s\n",
      "epoch 145| loss: 0.02077 | train_rmsle: 0.00085 | train_mae: 0.09516 | train_rmse: 0.12335 | train_mse: 0.01522 | valid_rmsle: 0.00105 | valid_mae: 0.10805 | valid_rmse: 0.13814 | valid_mse: 0.01908 |  0:04:20s\n",
      "epoch 146| loss: 0.02306 | train_rmsle: 0.00106 | train_mae: 0.1106  | train_rmse: 0.14023 | train_mse: 0.01966 | valid_rmsle: 0.00132 | valid_mae: 0.12599 | valid_rmse: 0.15625 | valid_mse: 0.02441 |  0:04:21s\n",
      "epoch 147| loss: 0.02175 | train_rmsle: 0.00131 | train_mae: 0.1127  | train_rmse: 0.14339 | train_mse: 0.02056 | valid_rmsle: 0.00157 | valid_mae: 0.12566 | valid_rmse: 0.15939 | valid_mse: 0.02541 |  0:04:23s\n",
      "epoch 148| loss: 0.02128 | train_rmsle: 0.00096 | train_mae: 0.10229 | train_rmse: 0.12979 | train_mse: 0.01685 | valid_rmsle: 0.00118 | valid_mae: 0.1151  | valid_rmse: 0.14488 | valid_mse: 0.02099 |  0:04:25s\n",
      "epoch 149| loss: 0.02036 | train_rmsle: 0.00081 | train_mae: 0.09402 | train_rmse: 0.12065 | train_mse: 0.01456 | valid_rmsle: 0.00102 | valid_mae: 0.10654 | valid_rmse: 0.1361  | valid_mse: 0.01852 |  0:04:27s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 149 and best_valid_mse = 0.01852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.02505011712241674 RMSE: 0.15827228791679465 R2: 0.8891127837744875 MAE: 0.10555471970798974\n",
      "=====================================\n",
      "[68/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.80104 | train_rmsle: 0.28098 | train_mae: 1.73958 | train_rmse: 1.80559 | train_mse: 3.26014 | valid_rmsle: 0.2819  | valid_mae: 1.74488 | valid_rmse: 1.80973 | valid_mse: 3.27511 |  0:00:01s\n",
      "epoch 1  | loss: 1.04399 | train_rmsle: 0.06962 | train_mae: 0.94459 | train_rmse: 1.03616 | train_mse: 1.07364 | valid_rmsle: 0.06999 | valid_mae: 0.94733 | valid_rmse: 1.04043 | valid_mse: 1.0825  |  0:00:03s\n",
      "epoch 2  | loss: 0.47282 | train_rmsle: 0.04067 | train_mae: 0.7268  | train_rmse: 0.81963 | train_mse: 0.6718  | valid_rmsle: 0.04066 | valid_mae: 0.7268  | valid_rmse: 0.82203 | valid_mse: 0.67574 |  0:00:05s\n",
      "epoch 3  | loss: 0.3402  | train_rmsle: 0.034   | train_mae: 0.66309 | train_rmse: 0.7557  | train_mse: 0.57108 | valid_rmsle: 0.03398 | valid_mae: 0.66318 | valid_rmse: 0.75829 | valid_mse: 0.57501 |  0:00:07s\n",
      "epoch 4  | loss: 0.2865  | train_rmsle: 0.02597 | train_mae: 0.57541 | train_rmse: 0.66598 | train_mse: 0.44353 | valid_rmsle: 0.0258  | valid_mae: 0.57651 | valid_rmse: 0.66735 | valid_mse: 0.44536 |  0:00:08s\n",
      "epoch 5  | loss: 0.28439 | train_rmsle: 0.02069 | train_mae: 0.50647 | train_rmse: 0.59502 | train_mse: 0.35405 | valid_rmsle: 0.02041 | valid_mae: 0.50816 | valid_rmse: 0.59534 | valid_mse: 0.35443 |  0:00:10s\n",
      "epoch 6  | loss: 0.25697 | train_rmsle: 0.02503 | train_mae: 0.56391 | train_rmse: 0.65415 | train_mse: 0.42792 | valid_rmsle: 0.02478 | valid_mae: 0.5644  | valid_rmse: 0.65467 | valid_mse: 0.4286  |  0:00:12s\n",
      "epoch 7  | loss: 0.29194 | train_rmsle: 0.02045 | train_mae: 0.50319 | train_rmse: 0.59137 | train_mse: 0.34972 | valid_rmsle: 0.02006 | valid_mae: 0.50376 | valid_rmse: 0.5901  | valid_mse: 0.34822 |  0:00:14s\n",
      "epoch 8  | loss: 0.24267 | train_rmsle: 0.02051 | train_mae: 0.50441 | train_rmse: 0.59227 | train_mse: 0.35079 | valid_rmsle: 0.02017 | valid_mae: 0.50684 | valid_rmse: 0.59171 | valid_mse: 0.35012 |  0:00:16s\n",
      "epoch 9  | loss: 0.24518 | train_rmsle: 0.01997 | train_mae: 0.49602 | train_rmse: 0.58432 | train_mse: 0.34143 | valid_rmsle: 0.01955 | valid_mae: 0.49649 | valid_rmse: 0.58262 | valid_mse: 0.33945 |  0:00:17s\n",
      "epoch 10 | loss: 0.25758 | train_rmsle: 0.02885 | train_mae: 0.60842 | train_rmse: 0.70009 | train_mse: 0.49012 | valid_rmsle: 0.02861 | valid_mae: 0.60752 | valid_rmse: 0.70055 | valid_mse: 0.49076 |  0:00:19s\n",
      "epoch 11 | loss: 0.25914 | train_rmsle: 0.0173  | train_mae: 0.45257 | train_rmse: 0.54075 | train_mse: 0.29241 | valid_rmsle: 0.01684 | valid_mae: 0.4539  | valid_rmse: 0.53838 | valid_mse: 0.28985 |  0:00:21s\n",
      "epoch 12 | loss: 0.23867 | train_rmsle: 0.01657 | train_mae: 0.43929 | train_rmse: 0.52763 | train_mse: 0.27839 | valid_rmsle: 0.01612 | valid_mae: 0.44079 | valid_rmse: 0.5256  | valid_mse: 0.27625 |  0:00:23s\n",
      "epoch 13 | loss: 0.29092 | train_rmsle: 0.01917 | train_mae: 0.48308 | train_rmse: 0.57182 | train_mse: 0.32698 | valid_rmsle: 0.01865 | valid_mae: 0.48182 | valid_rmse: 0.56894 | valid_mse: 0.32369 |  0:00:24s\n",
      "epoch 14 | loss: 0.24759 | train_rmsle: 0.01563 | train_mae: 0.41855 | train_rmse: 0.50902 | train_mse: 0.2591  | valid_rmsle: 0.01505 | valid_mae: 0.41735 | valid_rmse: 0.50474 | valid_mse: 0.25476 |  0:00:26s\n",
      "epoch 15 | loss: 0.23645 | train_rmsle: 0.01515 | train_mae: 0.40687 | train_rmse: 0.49864 | train_mse: 0.24864 | valid_rmsle: 0.01453 | valid_mae: 0.40633 | valid_rmse: 0.49371 | valid_mse: 0.24375 |  0:00:28s\n",
      "epoch 16 | loss: 0.24176 | train_rmsle: 0.01517 | train_mae: 0.40876 | train_rmse: 0.5005  | train_mse: 0.2505  | valid_rmsle: 0.01476 | valid_mae: 0.4103  | valid_rmse: 0.49897 | valid_mse: 0.24897 |  0:00:30s\n",
      "epoch 17 | loss: 0.2315  | train_rmsle: 0.01468 | train_mae: 0.39108 | train_rmse: 0.48681 | train_mse: 0.23698 | valid_rmsle: 0.0142  | valid_mae: 0.39263 | valid_rmse: 0.48395 | valid_mse: 0.2342  |  0:00:32s\n",
      "epoch 18 | loss: 0.33858 | train_rmsle: 0.02048 | train_mae: 0.43316 | train_rmse: 0.57429 | train_mse: 0.32981 | valid_rmsle: 0.0198  | valid_mae: 0.43136 | valid_rmse: 0.56908 | valid_mse: 0.32385 |  0:00:33s\n",
      "epoch 19 | loss: 0.2916  | train_rmsle: 0.01477 | train_mae: 0.39491 | train_rmse: 0.49005 | train_mse: 0.24015 | valid_rmsle: 0.01444 | valid_mae: 0.3973  | valid_rmse: 0.49013 | valid_mse: 0.24023 |  0:00:35s\n",
      "epoch 20 | loss: 0.24085 | train_rmsle: 0.0179  | train_mae: 0.46229 | train_rmse: 0.55111 | train_mse: 0.30373 | valid_rmsle: 0.01743 | valid_mae: 0.46252 | valid_rmse: 0.54837 | valid_mse: 0.30071 |  0:00:37s\n",
      "epoch 21 | loss: 0.23799 | train_rmsle: 0.01717 | train_mae: 0.44942 | train_rmse: 0.53871 | train_mse: 0.29021 | valid_rmsle: 0.01676 | valid_mae: 0.4501  | valid_rmse: 0.53658 | valid_mse: 0.28792 |  0:00:39s\n",
      "epoch 22 | loss: 0.22881 | train_rmsle: 0.01536 | train_mae: 0.41284 | train_rmse: 0.5042  | train_mse: 0.25422 | valid_rmsle: 0.01504 | valid_mae: 0.41405 | valid_rmse: 0.50373 | valid_mse: 0.25374 |  0:00:40s\n",
      "epoch 23 | loss: 0.23588 | train_rmsle: 0.01458 | train_mae: 0.38333 | train_rmse: 0.483   | train_mse: 0.23329 | valid_rmsle: 0.01403 | valid_mae: 0.38329 | valid_rmse: 0.47913 | valid_mse: 0.22956 |  0:00:42s\n",
      "epoch 24 | loss: 0.23964 | train_rmsle: 0.01497 | train_mae: 0.40315 | train_rmse: 0.49551 | train_mse: 0.24553 | valid_rmsle: 0.01433 | valid_mae: 0.40134 | valid_rmse: 0.49011 | valid_mse: 0.2402  |  0:00:44s\n",
      "epoch 25 | loss: 0.22378 | train_rmsle: 0.01506 | train_mae: 0.4073  | train_rmse: 0.49811 | train_mse: 0.24811 | valid_rmsle: 0.01443 | valid_mae: 0.4052  | valid_rmse: 0.49274 | valid_mse: 0.24279 |  0:00:46s\n",
      "epoch 26 | loss: 0.23102 | train_rmsle: 0.01433 | train_mae: 0.38379 | train_rmse: 0.47985 | train_mse: 0.23025 | valid_rmsle: 0.01389 | valid_mae: 0.38444 | valid_rmse: 0.47778 | valid_mse: 0.22827 |  0:00:47s\n",
      "epoch 27 | loss: 0.2263  | train_rmsle: 0.01656 | train_mae: 0.43901 | train_rmse: 0.5288  | train_mse: 0.27963 | valid_rmsle: 0.01601 | valid_mae: 0.43699 | valid_rmse: 0.52469 | valid_mse: 0.2753  |  0:00:49s\n",
      "epoch 28 | loss: 0.23071 | train_rmsle: 0.01448 | train_mae: 0.37524 | train_rmse: 0.4781  | train_mse: 0.22858 | valid_rmsle: 0.01388 | valid_mae: 0.37311 | valid_rmse: 0.47333 | valid_mse: 0.22404 |  0:00:51s\n",
      "epoch 29 | loss: 0.22307 | train_rmsle: 0.01419 | train_mae: 0.3797  | train_rmse: 0.47664 | train_mse: 0.22719 | valid_rmsle: 0.01365 | valid_mae: 0.37944 | valid_rmse: 0.47318 | valid_mse: 0.2239  |  0:00:53s\n",
      "epoch 30 | loss: 0.2185  | train_rmsle: 0.01422 | train_mae: 0.38141 | train_rmse: 0.47788 | train_mse: 0.22837 | valid_rmsle: 0.01368 | valid_mae: 0.38279 | valid_rmse: 0.4747  | valid_mse: 0.22534 |  0:00:55s\n",
      "epoch 31 | loss: 0.22262 | train_rmsle: 0.01419 | train_mae: 0.38184 | train_rmse: 0.47752 | train_mse: 0.22803 | valid_rmsle: 0.01388 | valid_mae: 0.38535 | valid_rmse: 0.4781  | valid_mse: 0.22858 |  0:00:56s\n",
      "epoch 32 | loss: 0.22171 | train_rmsle: 0.01443 | train_mae: 0.39271 | train_rmse: 0.48534 | train_mse: 0.23556 | valid_rmsle: 0.01399 | valid_mae: 0.39525 | valid_rmse: 0.48328 | valid_mse: 0.23356 |  0:00:58s\n",
      "epoch 33 | loss: 0.23101 | train_rmsle: 0.01454 | train_mae: 0.37358 | train_rmse: 0.47899 | train_mse: 0.22943 | valid_rmsle: 0.01386 | valid_mae: 0.37119 | valid_rmse: 0.47271 | valid_mse: 0.22346 |  0:01:00s\n",
      "epoch 34 | loss: 0.2203  | train_rmsle: 0.01411 | train_mae: 0.3864  | train_rmse: 0.47897 | train_mse: 0.22941 | valid_rmsle: 0.0138  | valid_mae: 0.38812 | valid_rmse: 0.47894 | valid_mse: 0.22938 |  0:01:02s\n",
      "epoch 35 | loss: 0.22183 | train_rmsle: 0.01414 | train_mae: 0.37803 | train_rmse: 0.4753  | train_mse: 0.22591 | valid_rmsle: 0.01362 | valid_mae: 0.37467 | valid_rmse: 0.47161 | valid_mse: 0.22242 |  0:01:03s\n",
      "epoch 36 | loss: 0.22484 | train_rmsle: 0.01403 | train_mae: 0.37545 | train_rmse: 0.47377 | train_mse: 0.22446 | valid_rmsle: 0.01379 | valid_mae: 0.37931 | valid_rmse: 0.47459 | valid_mse: 0.22523 |  0:01:05s\n",
      "epoch 37 | loss: 0.22596 | train_rmsle: 0.01491 | train_mae: 0.37404 | train_rmse: 0.48448 | train_mse: 0.23472 | valid_rmsle: 0.01466 | valid_mae: 0.3825  | valid_rmse: 0.48623 | valid_mse: 0.23642 |  0:01:07s\n",
      "epoch 38 | loss: 0.21975 | train_rmsle: 0.0139  | train_mae: 0.37326 | train_rmse: 0.47142 | train_mse: 0.22224 | valid_rmsle: 0.01364 | valid_mae: 0.37644 | valid_rmse: 0.4725  | valid_mse: 0.22326 |  0:01:09s\n",
      "epoch 39 | loss: 0.21465 | train_rmsle: 0.01395 | train_mae: 0.38309 | train_rmse: 0.4763  | train_mse: 0.22686 | valid_rmsle: 0.01364 | valid_mae: 0.38588 | valid_rmse: 0.47669 | valid_mse: 0.22723 |  0:01:11s\n",
      "epoch 40 | loss: 0.21606 | train_rmsle: 0.01402 | train_mae: 0.3774  | train_rmse: 0.47419 | train_mse: 0.22486 | valid_rmsle: 0.01342 | valid_mae: 0.37657 | valid_rmse: 0.47014 | valid_mse: 0.22103 |  0:01:12s\n",
      "epoch 41 | loss: 0.21571 | train_rmsle: 0.01415 | train_mae: 0.37146 | train_rmse: 0.47324 | train_mse: 0.22395 | valid_rmsle: 0.01401 | valid_mae: 0.37773 | valid_rmse: 0.4766  | valid_mse: 0.22715 |  0:01:14s\n",
      "epoch 42 | loss: 0.21428 | train_rmsle: 0.01397 | train_mae: 0.38075 | train_rmse: 0.47494 | train_mse: 0.22557 | valid_rmsle: 0.01373 | valid_mae: 0.38496 | valid_rmse: 0.47643 | valid_mse: 0.22698 |  0:01:16s\n",
      "epoch 43 | loss: 0.21615 | train_rmsle: 0.01409 | train_mae: 0.38607 | train_rmse: 0.4788  | train_mse: 0.22925 | valid_rmsle: 0.01399 | valid_mae: 0.39181 | valid_rmse: 0.48318 | valid_mse: 0.23346 |  0:01:18s\n",
      "epoch 44 | loss: 0.21215 | train_rmsle: 0.01389 | train_mae: 0.37274 | train_rmse: 0.47057 | train_mse: 0.22144 | valid_rmsle: 0.01369 | valid_mae: 0.37967 | valid_rmse: 0.47369 | valid_mse: 0.22438 |  0:01:19s\n",
      "epoch 45 | loss: 0.21783 | train_rmsle: 0.01415 | train_mae: 0.37131 | train_rmse: 0.47337 | train_mse: 0.22408 | valid_rmsle: 0.01394 | valid_mae: 0.3766  | valid_rmse: 0.47606 | valid_mse: 0.22663 |  0:01:21s\n",
      "epoch 46 | loss: 0.21562 | train_rmsle: 0.01458 | train_mae: 0.37136 | train_rmse: 0.47879 | train_mse: 0.22924 | valid_rmsle: 0.01429 | valid_mae: 0.3737  | valid_rmse: 0.47989 | valid_mse: 0.23029 |  0:01:23s\n",
      "epoch 47 | loss: 0.21505 | train_rmsle: 0.01394 | train_mae: 0.37063 | train_rmse: 0.4704  | train_mse: 0.22128 | valid_rmsle: 0.0138  | valid_mae: 0.37573 | valid_rmse: 0.47421 | valid_mse: 0.22488 |  0:01:25s\n",
      "epoch 48 | loss: 0.21547 | train_rmsle: 0.01392 | train_mae: 0.36953 | train_rmse: 0.46965 | train_mse: 0.22057 | valid_rmsle: 0.01378 | valid_mae: 0.37661 | valid_rmse: 0.47579 | valid_mse: 0.22638 |  0:01:27s\n",
      "epoch 49 | loss: 0.21446 | train_rmsle: 0.01412 | train_mae: 0.36833 | train_rmse: 0.47167 | train_mse: 0.22247 | valid_rmsle: 0.01387 | valid_mae: 0.37474 | valid_rmse: 0.47541 | valid_mse: 0.22601 |  0:01:28s\n",
      "epoch 50 | loss: 0.21298 | train_rmsle: 0.01412 | train_mae: 0.36899 | train_rmse: 0.47172 | train_mse: 0.22252 | valid_rmsle: 0.01371 | valid_mae: 0.37236 | valid_rmse: 0.47109 | valid_mse: 0.22192 |  0:01:30s\n",
      "epoch 51 | loss: 0.21565 | train_rmsle: 0.01376 | train_mae: 0.37915 | train_rmse: 0.47209 | train_mse: 0.22287 | valid_rmsle: 0.01365 | valid_mae: 0.38611 | valid_rmse: 0.47607 | valid_mse: 0.22664 |  0:01:32s\n",
      "epoch 52 | loss: 0.2132  | train_rmsle: 0.01415 | train_mae: 0.36935 | train_rmse: 0.47282 | train_mse: 0.22356 | valid_rmsle: 0.01392 | valid_mae: 0.37384 | valid_rmse: 0.4755  | valid_mse: 0.2261  |  0:01:34s\n",
      "epoch 53 | loss: 0.21349 | train_rmsle: 0.01381 | train_mae: 0.37014 | train_rmse: 0.46858 | train_mse: 0.21957 | valid_rmsle: 0.01377 | valid_mae: 0.37903 | valid_rmse: 0.47493 | valid_mse: 0.22556 |  0:01:35s\n",
      "epoch 54 | loss: 0.21131 | train_rmsle: 0.01368 | train_mae: 0.37309 | train_rmse: 0.46835 | train_mse: 0.21936 | valid_rmsle: 0.0135  | valid_mae: 0.38023 | valid_rmse: 0.47192 | valid_mse: 0.2227  |  0:01:37s\n",
      "epoch 55 | loss: 0.21072 | train_rmsle: 0.01374 | train_mae: 0.37276 | train_rmse: 0.46893 | train_mse: 0.21989 | valid_rmsle: 0.01361 | valid_mae: 0.38143 | valid_rmse: 0.47348 | valid_mse: 0.22419 |  0:01:39s\n",
      "epoch 56 | loss: 0.21296 | train_rmsle: 0.01389 | train_mae: 0.36551 | train_rmse: 0.4683  | train_mse: 0.21931 | valid_rmsle: 0.01375 | valid_mae: 0.37518 | valid_rmse: 0.47301 | valid_mse: 0.22374 |  0:01:41s\n",
      "epoch 57 | loss: 0.2133  | train_rmsle: 0.01375 | train_mae: 0.36629 | train_rmse: 0.4669  | train_mse: 0.218   | valid_rmsle: 0.01363 | valid_mae: 0.37779 | valid_rmse: 0.47232 | valid_mse: 0.22309 |  0:01:42s\n",
      "epoch 58 | loss: 0.2099  | train_rmsle: 0.01376 | train_mae: 0.36793 | train_rmse: 0.46723 | train_mse: 0.2183  | valid_rmsle: 0.01347 | valid_mae: 0.37468 | valid_rmse: 0.4691  | valid_mse: 0.22005 |  0:01:44s\n",
      "epoch 59 | loss: 0.20836 | train_rmsle: 0.01357 | train_mae: 0.36794 | train_rmse: 0.46467 | train_mse: 0.21592 | valid_rmsle: 0.01345 | valid_mae: 0.37567 | valid_rmse: 0.46929 | valid_mse: 0.22024 |  0:01:46s\n",
      "epoch 60 | loss: 0.21009 | train_rmsle: 0.01347 | train_mae: 0.36822 | train_rmse: 0.46367 | train_mse: 0.21499 | valid_rmsle: 0.01349 | valid_mae: 0.38024 | valid_rmse: 0.4707  | valid_mse: 0.22156 |  0:01:48s\n",
      "epoch 61 | loss: 0.21027 | train_rmsle: 0.01404 | train_mae: 0.36455 | train_rmse: 0.46949 | train_mse: 0.22042 | valid_rmsle: 0.01399 | valid_mae: 0.37692 | valid_rmse: 0.47578 | valid_mse: 0.22636 |  0:01:50s\n",
      "epoch 62 | loss: 0.20737 | train_rmsle: 0.01397 | train_mae: 0.36534 | train_rmse: 0.46893 | train_mse: 0.2199  | valid_rmsle: 0.01375 | valid_mae: 0.3738  | valid_rmse: 0.47157 | valid_mse: 0.22238 |  0:01:51s\n",
      "epoch 63 | loss: 0.20585 | train_rmsle: 0.01341 | train_mae: 0.36204 | train_rmse: 0.46063 | train_mse: 0.21218 | valid_rmsle: 0.01343 | valid_mae: 0.37443 | valid_rmse: 0.46733 | valid_mse: 0.2184  |  0:01:53s\n",
      "epoch 64 | loss: 0.20477 | train_rmsle: 0.01341 | train_mae: 0.36383 | train_rmse: 0.46156 | train_mse: 0.21303 | valid_rmsle: 0.0133  | valid_mae: 0.3713  | valid_rmse: 0.46549 | valid_mse: 0.21668 |  0:01:55s\n",
      "epoch 65 | loss: 0.2048  | train_rmsle: 0.01326 | train_mae: 0.3644  | train_rmse: 0.45994 | train_mse: 0.21154 | valid_rmsle: 0.01343 | valid_mae: 0.37819 | valid_rmse: 0.46921 | valid_mse: 0.22016 |  0:01:57s\n",
      "epoch 66 | loss: 0.20466 | train_rmsle: 0.01336 | train_mae: 0.35928 | train_rmse: 0.45909 | train_mse: 0.21076 | valid_rmsle: 0.01344 | valid_mae: 0.37014 | valid_rmse: 0.46705 | valid_mse: 0.21813 |  0:01:58s\n",
      "epoch 67 | loss: 0.20234 | train_rmsle: 0.01301 | train_mae: 0.36481 | train_rmse: 0.4572  | train_mse: 0.20903 | valid_rmsle: 0.01319 | valid_mae: 0.37613 | valid_rmse: 0.46631 | valid_mse: 0.21744 |  0:02:00s\n",
      "epoch 68 | loss: 0.19959 | train_rmsle: 0.01348 | train_mae: 0.35448 | train_rmse: 0.45894 | train_mse: 0.21063 | valid_rmsle: 0.01358 | valid_mae: 0.37099 | valid_rmse: 0.46832 | valid_mse: 0.21932 |  0:02:02s\n",
      "epoch 69 | loss: 0.19682 | train_rmsle: 0.01299 | train_mae: 0.35235 | train_rmse: 0.45165 | train_mse: 0.20399 | valid_rmsle: 0.01296 | valid_mae: 0.36356 | valid_rmse: 0.45789 | valid_mse: 0.20966 |  0:02:04s\n",
      "epoch 70 | loss: 0.19394 | train_rmsle: 0.01318 | train_mae: 0.37749 | train_rmse: 0.46536 | train_mse: 0.21656 | valid_rmsle: 0.01362 | valid_mae: 0.39443 | valid_rmse: 0.47909 | valid_mse: 0.22952 |  0:02:06s\n",
      "epoch 71 | loss: 0.19118 | train_rmsle: 0.0129  | train_mae: 0.34607 | train_rmse: 0.44884 | train_mse: 0.20146 | valid_rmsle: 0.01325 | valid_mae: 0.36476 | valid_rmse: 0.46287 | valid_mse: 0.21425 |  0:02:07s\n",
      "epoch 72 | loss: 0.18811 | train_rmsle: 0.01194 | train_mae: 0.33978 | train_rmse: 0.43407 | train_mse: 0.18841 | valid_rmsle: 0.01252 | valid_mae: 0.3599  | valid_rmse: 0.45232 | valid_mse: 0.2046  |  0:02:09s\n",
      "epoch 73 | loss: 0.18563 | train_rmsle: 0.01173 | train_mae: 0.34165 | train_rmse: 0.43261 | train_mse: 0.18715 | valid_rmsle: 0.01228 | valid_mae: 0.36009 | valid_rmse: 0.44954 | valid_mse: 0.20208 |  0:02:11s\n",
      "epoch 74 | loss: 0.18446 | train_rmsle: 0.01167 | train_mae: 0.34427 | train_rmse: 0.43268 | train_mse: 0.18721 | valid_rmsle: 0.01227 | valid_mae: 0.36307 | valid_rmse: 0.4503  | valid_mse: 0.20277 |  0:02:13s\n",
      "epoch 75 | loss: 0.17827 | train_rmsle: 0.0114  | train_mae: 0.32856 | train_rmse: 0.42304 | train_mse: 0.17896 | valid_rmsle: 0.01214 | valid_mae: 0.35238 | valid_rmse: 0.44483 | valid_mse: 0.19787 |  0:02:15s\n",
      "epoch 76 | loss: 0.17177 | train_rmsle: 0.01085 | train_mae: 0.32579 | train_rmse: 0.4147  | train_mse: 0.17198 | valid_rmsle: 0.01166 | valid_mae: 0.35124 | valid_rmse: 0.4375  | valid_mse: 0.1914  |  0:02:16s\n",
      "epoch 77 | loss: 0.16741 | train_rmsle: 0.01065 | train_mae: 0.32081 | train_rmse: 0.41018 | train_mse: 0.16825 | valid_rmsle: 0.0115  | valid_mae: 0.34694 | valid_rmse: 0.43373 | valid_mse: 0.18812 |  0:02:18s\n",
      "epoch 78 | loss: 0.16407 | train_rmsle: 0.0104  | train_mae: 0.31674 | train_rmse: 0.40482 | train_mse: 0.16388 | valid_rmsle: 0.01134 | valid_mae: 0.34341 | valid_rmse: 0.43045 | valid_mse: 0.18528 |  0:02:20s\n",
      "epoch 79 | loss: 0.16032 | train_rmsle: 0.01047 | train_mae: 0.31849 | train_rmse: 0.40625 | train_mse: 0.16504 | valid_rmsle: 0.01177 | valid_mae: 0.34746 | valid_rmse: 0.43854 | valid_mse: 0.19232 |  0:02:22s\n",
      "epoch 80 | loss: 0.15796 | train_rmsle: 0.0102  | train_mae: 0.31552 | train_rmse: 0.4015  | train_mse: 0.1612  | valid_rmsle: 0.01124 | valid_mae: 0.34011 | valid_rmse: 0.42967 | valid_mse: 0.18461 |  0:02:24s\n",
      "epoch 81 | loss: 0.15556 | train_rmsle: 0.00997 | train_mae: 0.31749 | train_rmse: 0.39925 | train_mse: 0.1594  | valid_rmsle: 0.01049 | valid_mae: 0.33401 | valid_rmse: 0.41632 | valid_mse: 0.17332 |  0:02:25s\n",
      "epoch 82 | loss: 0.15227 | train_rmsle: 0.00985 | train_mae: 0.31701 | train_rmse: 0.39788 | train_mse: 0.15831 | valid_rmsle: 0.01041 | valid_mae: 0.33045 | valid_rmse: 0.41633 | valid_mse: 0.17333 |  0:02:27s\n",
      "epoch 83 | loss: 0.1509  | train_rmsle: 0.00924 | train_mae: 0.3001  | train_rmse: 0.38225 | train_mse: 0.14612 | valid_rmsle: 0.00969 | valid_mae: 0.31193 | valid_rmse: 0.40071 | valid_mse: 0.16057 |  0:02:29s\n",
      "epoch 84 | loss: 0.14052 | train_rmsle: 0.00898 | train_mae: 0.29851 | train_rmse: 0.37794 | train_mse: 0.14284 | valid_rmsle: 0.00994 | valid_mae: 0.3162  | valid_rmse: 0.41136 | valid_mse: 0.16921 |  0:02:31s\n",
      "epoch 85 | loss: 0.13276 | train_rmsle: 0.00837 | train_mae: 0.28257 | train_rmse: 0.36231 | train_mse: 0.13127 | valid_rmsle: 0.00905 | valid_mae: 0.29948 | valid_rmse: 0.3874  | valid_mse: 0.15008 |  0:02:32s\n",
      "epoch 86 | loss: 0.12802 | train_rmsle: 0.00788 | train_mae: 0.27836 | train_rmse: 0.35429 | train_mse: 0.12552 | valid_rmsle: 0.00811 | valid_mae: 0.2909  | valid_rmse: 0.36672 | valid_mse: 0.13448 |  0:02:34s\n",
      "epoch 87 | loss: 0.12378 | train_rmsle: 0.00754 | train_mae: 0.27183 | train_rmse: 0.34609 | train_mse: 0.11978 | valid_rmsle: 0.00787 | valid_mae: 0.28921 | valid_rmse: 0.35979 | valid_mse: 0.12945 |  0:02:36s\n",
      "epoch 88 | loss: 0.11807 | train_rmsle: 0.00725 | train_mae: 0.26344 | train_rmse: 0.3378  | train_mse: 0.11411 | valid_rmsle: 0.00747 | valid_mae: 0.27703 | valid_rmse: 0.35085 | valid_mse: 0.12309 |  0:02:38s\n",
      "epoch 89 | loss: 0.11614 | train_rmsle: 0.00705 | train_mae: 0.2574  | train_rmse: 0.33253 | train_mse: 0.11058 | valid_rmsle: 0.00739 | valid_mae: 0.27178 | valid_rmse: 0.35024 | valid_mse: 0.12267 |  0:02:40s\n",
      "epoch 90 | loss: 0.1078  | train_rmsle: 0.00674 | train_mae: 0.26065 | train_rmse: 0.32888 | train_mse: 0.10816 | valid_rmsle: 0.00692 | valid_mae: 0.2688  | valid_rmse: 0.34174 | valid_mse: 0.11679 |  0:02:41s\n",
      "epoch 91 | loss: 0.10347 | train_rmsle: 0.0067  | train_mae: 0.26061 | train_rmse: 0.32817 | train_mse: 0.1077  | valid_rmsle: 0.0069  | valid_mae: 0.26736 | valid_rmse: 0.3393  | valid_mse: 0.11512 |  0:02:43s\n",
      "epoch 92 | loss: 0.10103 | train_rmsle: 0.00634 | train_mae: 0.24172 | train_rmse: 0.31387 | train_mse: 0.09852 | valid_rmsle: 0.00659 | valid_mae: 0.25342 | valid_rmse: 0.326   | valid_mse: 0.10628 |  0:02:45s\n",
      "epoch 93 | loss: 0.09841 | train_rmsle: 0.00616 | train_mae: 0.23768 | train_rmse: 0.31006 | train_mse: 0.09614 | valid_rmsle: 0.00653 | valid_mae: 0.25359 | valid_rmse: 0.32666 | valid_mse: 0.10671 |  0:02:47s\n",
      "epoch 94 | loss: 0.09569 | train_rmsle: 0.00568 | train_mae: 0.23549 | train_rmse: 0.30084 | train_mse: 0.09051 | valid_rmsle: 0.00599 | valid_mae: 0.24815 | valid_rmse: 0.31447 | valid_mse: 0.09889 |  0:02:48s\n",
      "epoch 95 | loss: 0.08914 | train_rmsle: 0.00543 | train_mae: 0.2267  | train_rmse: 0.29248 | train_mse: 0.08555 | valid_rmsle: 0.00597 | valid_mae: 0.24447 | valid_rmse: 0.31341 | valid_mse: 0.09823 |  0:02:50s\n",
      "epoch 96 | loss: 0.08361 | train_rmsle: 0.00501 | train_mae: 0.216   | train_rmse: 0.28031 | train_mse: 0.07857 | valid_rmsle: 0.00573 | valid_mae: 0.2381  | valid_rmse: 0.31051 | valid_mse: 0.09642 |  0:02:52s\n",
      "epoch 97 | loss: 0.07969 | train_rmsle: 0.00481 | train_mae: 0.21215 | train_rmse: 0.2754  | train_mse: 0.07585 | valid_rmsle: 0.00547 | valid_mae: 0.23317 | valid_rmse: 0.30421 | valid_mse: 0.09254 |  0:02:54s\n",
      "epoch 98 | loss: 0.07544 | train_rmsle: 0.00507 | train_mae: 0.22737 | train_rmse: 0.28679 | train_mse: 0.08225 | valid_rmsle: 0.00533 | valid_mae: 0.2378  | valid_rmse: 0.30098 | valid_mse: 0.09059 |  0:02:56s\n",
      "epoch 99 | loss: 0.07379 | train_rmsle: 0.00441 | train_mae: 0.20685 | train_rmse: 0.26495 | train_mse: 0.0702  | valid_rmsle: 0.00483 | valid_mae: 0.22515 | valid_rmse: 0.28379 | valid_mse: 0.08054 |  0:02:57s\n",
      "epoch 100| loss: 0.07322 | train_rmsle: 0.00421 | train_mae: 0.20341 | train_rmse: 0.26006 | train_mse: 0.06763 | valid_rmsle: 0.00469 | valid_mae: 0.22178 | valid_rmse: 0.27975 | valid_mse: 0.07826 |  0:02:59s\n",
      "epoch 101| loss: 0.06755 | train_rmsle: 0.00414 | train_mae: 0.19627 | train_rmse: 0.25525 | train_mse: 0.06515 | valid_rmsle: 0.00466 | valid_mae: 0.21915 | valid_rmse: 0.2775  | valid_mse: 0.07701 |  0:03:01s\n",
      "epoch 102| loss: 0.06375 | train_rmsle: 0.0037  | train_mae: 0.19037 | train_rmse: 0.24367 | train_mse: 0.05938 | valid_rmsle: 0.00418 | valid_mae: 0.20929 | valid_rmse: 0.26496 | valid_mse: 0.0702  |  0:03:03s\n",
      "epoch 103| loss: 0.05955 | train_rmsle: 0.00341 | train_mae: 0.18021 | train_rmse: 0.23295 | train_mse: 0.05427 | valid_rmsle: 0.00391 | valid_mae: 0.20092 | valid_rmse: 0.25592 | valid_mse: 0.06549 |  0:03:05s\n",
      "epoch 104| loss: 0.05802 | train_rmsle: 0.00319 | train_mae: 0.17399 | train_rmse: 0.22507 | train_mse: 0.05066 | valid_rmsle: 0.00365 | valid_mae: 0.19553 | valid_rmse: 0.24717 | valid_mse: 0.06109 |  0:03:06s\n",
      "epoch 105| loss: 0.05701 | train_rmsle: 0.00408 | train_mae: 0.21233 | train_rmse: 0.26284 | train_mse: 0.06909 | valid_rmsle: 0.00456 | valid_mae: 0.2267  | valid_rmse: 0.28134 | valid_mse: 0.07915 |  0:03:08s\n",
      "epoch 106| loss: 0.05958 | train_rmsle: 0.00303 | train_mae: 0.17303 | train_rmse: 0.22133 | train_mse: 0.04899 | valid_rmsle: 0.00357 | valid_mae: 0.19346 | valid_rmse: 0.24538 | valid_mse: 0.06021 |  0:03:10s\n",
      "epoch 107| loss: 0.05097 | train_rmsle: 0.00287 | train_mae: 0.16874 | train_rmse: 0.21592 | train_mse: 0.04662 | valid_rmsle: 0.00334 | valid_mae: 0.18738 | valid_rmse: 0.2375  | valid_mse: 0.05641 |  0:03:12s\n",
      "epoch 108| loss: 0.04962 | train_rmsle: 0.00294 | train_mae: 0.17597 | train_rmse: 0.22239 | train_mse: 0.04946 | valid_rmsle: 0.00335 | valid_mae: 0.19225 | valid_rmse: 0.24121 | valid_mse: 0.05818 |  0:03:14s\n",
      "epoch 109| loss: 0.04867 | train_rmsle: 0.00265 | train_mae: 0.159   | train_rmse: 0.20628 | train_mse: 0.04255 | valid_rmsle: 0.00305 | valid_mae: 0.17862 | valid_rmse: 0.22689 | valid_mse: 0.05148 |  0:03:15s\n",
      "epoch 110| loss: 0.04564 | train_rmsle: 0.00233 | train_mae: 0.15197 | train_rmse: 0.1963  | train_mse: 0.03853 | valid_rmsle: 0.00272 | valid_mae: 0.17074 | valid_rmse: 0.21657 | valid_mse: 0.0469  |  0:03:17s\n",
      "epoch 111| loss: 0.04252 | train_rmsle: 0.00236 | train_mae: 0.15178 | train_rmse: 0.1973  | train_mse: 0.03893 | valid_rmsle: 0.00272 | valid_mae: 0.17063 | valid_rmse: 0.21672 | valid_mse: 0.04697 |  0:03:19s\n",
      "epoch 112| loss: 0.04389 | train_rmsle: 0.0025  | train_mae: 0.1585  | train_rmse: 0.20517 | train_mse: 0.0421  | valid_rmsle: 0.00285 | valid_mae: 0.1744  | valid_rmse: 0.22285 | valid_mse: 0.04966 |  0:03:21s\n",
      "epoch 113| loss: 0.04202 | train_rmsle: 0.00215 | train_mae: 0.14787 | train_rmse: 0.1909  | train_mse: 0.03644 | valid_rmsle: 0.00249 | valid_mae: 0.16665 | valid_rmse: 0.20945 | valid_mse: 0.04387 |  0:03:22s\n",
      "epoch 114| loss: 0.0392  | train_rmsle: 0.00214 | train_mae: 0.15112 | train_rmse: 0.19361 | train_mse: 0.03748 | valid_rmsle: 0.00259 | valid_mae: 0.16962 | valid_rmse: 0.21474 | valid_mse: 0.04611 |  0:03:24s\n",
      "epoch 115| loss: 0.04083 | train_rmsle: 0.00208 | train_mae: 0.14457 | train_rmse: 0.18769 | train_mse: 0.03523 | valid_rmsle: 0.0024  | valid_mae: 0.16135 | valid_rmse: 0.20602 | valid_mse: 0.04244 |  0:03:26s\n",
      "epoch 116| loss: 0.03931 | train_rmsle: 0.00185 | train_mae: 0.13722 | train_rmse: 0.17776 | train_mse: 0.0316  | valid_rmsle: 0.00219 | valid_mae: 0.15429 | valid_rmse: 0.19663 | valid_mse: 0.03866 |  0:03:28s\n",
      "epoch 117| loss: 0.03702 | train_rmsle: 0.00189 | train_mae: 0.14207 | train_rmse: 0.18272 | train_mse: 0.03339 | valid_rmsle: 0.00223 | valid_mae: 0.15895 | valid_rmse: 0.20156 | valid_mse: 0.04062 |  0:03:29s\n",
      "epoch 118| loss: 0.03937 | train_rmsle: 0.00173 | train_mae: 0.13316 | train_rmse: 0.17306 | train_mse: 0.02995 | valid_rmsle: 0.00202 | valid_mae: 0.14938 | valid_rmse: 0.18999 | valid_mse: 0.03609 |  0:03:31s\n",
      "epoch 119| loss: 0.03426 | train_rmsle: 0.00204 | train_mae: 0.14412 | train_rmse: 0.18391 | train_mse: 0.03382 | valid_rmsle: 0.00228 | valid_mae: 0.15851 | valid_rmse: 0.20001 | valid_mse: 0.04001 |  0:03:33s\n",
      "epoch 120| loss: 0.03465 | train_rmsle: 0.00182 | train_mae: 0.13668 | train_rmse: 0.17417 | train_mse: 0.03033 | valid_rmsle: 0.00213 | valid_mae: 0.15259 | valid_rmse: 0.19382 | valid_mse: 0.03757 |  0:03:35s\n",
      "epoch 121| loss: 0.03337 | train_rmsle: 0.00172 | train_mae: 0.13554 | train_rmse: 0.17225 | train_mse: 0.02967 | valid_rmsle: 0.00204 | valid_mae: 0.15101 | valid_rmse: 0.19167 | valid_mse: 0.03674 |  0:03:37s\n",
      "epoch 122| loss: 0.03003 | train_rmsle: 0.00205 | train_mae: 0.1442  | train_rmse: 0.18125 | train_mse: 0.03285 | valid_rmsle: 0.00226 | valid_mae: 0.15695 | valid_rmse: 0.19663 | valid_mse: 0.03866 |  0:03:38s\n",
      "epoch 123| loss: 0.03603 | train_rmsle: 0.00148 | train_mae: 0.12527 | train_rmse: 0.16175 | train_mse: 0.02616 | valid_rmsle: 0.00186 | valid_mae: 0.14515 | valid_rmse: 0.18357 | valid_mse: 0.0337  |  0:03:40s\n",
      "epoch 124| loss: 0.03105 | train_rmsle: 0.00231 | train_mae: 0.15162 | train_rmse: 0.19018 | train_mse: 0.03617 | valid_rmsle: 0.00246 | valid_mae: 0.16241 | valid_rmse: 0.2027  | valid_mse: 0.04109 |  0:03:42s\n",
      "epoch 125| loss: 0.03612 | train_rmsle: 0.00303 | train_mae: 0.17284 | train_rmse: 0.21524 | train_mse: 0.04633 | valid_rmsle: 0.00307 | valid_mae: 0.18091 | valid_rmse: 0.22297 | valid_mse: 0.04972 |  0:03:44s\n",
      "epoch 126| loss: 0.03527 | train_rmsle: 0.00356 | train_mae: 0.18006 | train_rmse: 0.22476 | train_mse: 0.05052 | valid_rmsle: 0.00354 | valid_mae: 0.18841 | valid_rmse: 0.23145 | valid_mse: 0.05357 |  0:03:45s\n",
      "epoch 127| loss: 0.03113 | train_rmsle: 0.00141 | train_mae: 0.12076 | train_rmse: 0.15623 | train_mse: 0.02441 | valid_rmsle: 0.00162 | valid_mae: 0.13567 | valid_rmse: 0.17129 | valid_mse: 0.02934 |  0:03:47s\n",
      "epoch 128| loss: 0.03242 | train_rmsle: 0.00135 | train_mae: 0.12025 | train_rmse: 0.15538 | train_mse: 0.02414 | valid_rmsle: 0.00161 | valid_mae: 0.13596 | valid_rmse: 0.17118 | valid_mse: 0.0293  |  0:03:49s\n",
      "epoch 129| loss: 0.02946 | train_rmsle: 0.00131 | train_mae: 0.11892 | train_rmse: 0.15376 | train_mse: 0.02364 | valid_rmsle: 0.00161 | valid_mae: 0.13486 | valid_rmse: 0.17184 | valid_mse: 0.02953 |  0:03:51s\n",
      "epoch 130| loss: 0.028   | train_rmsle: 0.00119 | train_mae: 0.11303 | train_rmse: 0.14688 | train_mse: 0.02157 | valid_rmsle: 0.0015  | valid_mae: 0.1299  | valid_rmse: 0.16611 | valid_mse: 0.02759 |  0:03:52s\n",
      "epoch 131| loss: 0.02838 | train_rmsle: 0.00129 | train_mae: 0.11828 | train_rmse: 0.15283 | train_mse: 0.02336 | valid_rmsle: 0.00151 | valid_mae: 0.13023 | valid_rmse: 0.1666  | valid_mse: 0.02776 |  0:03:54s\n",
      "epoch 132| loss: 0.02775 | train_rmsle: 0.0015  | train_mae: 0.12947 | train_rmse: 0.16319 | train_mse: 0.02663 | valid_rmsle: 0.00172 | valid_mae: 0.14133 | valid_rmse: 0.17731 | valid_mse: 0.03144 |  0:03:56s\n",
      "epoch 133| loss: 0.02536 | train_rmsle: 0.00132 | train_mae: 0.1171  | train_rmse: 0.14976 | train_mse: 0.02243 | valid_rmsle: 0.00156 | valid_mae: 0.13088 | valid_rmse: 0.16471 | valid_mse: 0.02713 |  0:03:58s\n",
      "epoch 134| loss: 0.02525 | train_rmsle: 0.00109 | train_mae: 0.10812 | train_rmse: 0.14008 | train_mse: 0.01962 | valid_rmsle: 0.00138 | valid_mae: 0.12538 | valid_rmse: 0.15888 | valid_mse: 0.02524 |  0:04:00s\n",
      "epoch 135| loss: 0.02558 | train_rmsle: 0.00119 | train_mae: 0.11581 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00145 | valid_mae: 0.12974 | valid_rmse: 0.16379 | valid_mse: 0.02683 |  0:04:01s\n",
      "epoch 136| loss: 0.02462 | train_rmsle: 0.00133 | train_mae: 0.12395 | train_rmse: 0.15671 | train_mse: 0.02456 | valid_rmsle: 0.00163 | valid_mae: 0.13841 | valid_rmse: 0.17416 | valid_mse: 0.03033 |  0:04:03s\n",
      "epoch 137| loss: 0.02447 | train_rmsle: 0.00127 | train_mae: 0.11673 | train_rmse: 0.14641 | train_mse: 0.02144 | valid_rmsle: 0.00149 | valid_mae: 0.12951 | valid_rmse: 0.16113 | valid_mse: 0.02596 |  0:04:05s\n",
      "epoch 138| loss: 0.02311 | train_rmsle: 0.00102 | train_mae: 0.10501 | train_rmse: 0.13395 | train_mse: 0.01794 | valid_rmsle: 0.00127 | valid_mae: 0.11889 | valid_rmse: 0.15088 | valid_mse: 0.02277 |  0:04:07s\n",
      "epoch 139| loss: 0.02319 | train_rmsle: 0.00104 | train_mae: 0.10712 | train_rmse: 0.13579 | train_mse: 0.01844 | valid_rmsle: 0.0013  | valid_mae: 0.1231  | valid_rmse: 0.15359 | valid_mse: 0.02359 |  0:04:08s\n",
      "epoch 140| loss: 0.02182 | train_rmsle: 0.00091 | train_mae: 0.099   | train_rmse: 0.12698 | train_mse: 0.01612 | valid_rmsle: 0.00117 | valid_mae: 0.11453 | valid_rmse: 0.1456  | valid_mse: 0.0212  |  0:04:10s\n",
      "epoch 141| loss: 0.02282 | train_rmsle: 0.00175 | train_mae: 0.14038 | train_rmse: 0.17002 | train_mse: 0.02891 | valid_rmsle: 0.00199 | valid_mae: 0.15199 | valid_rmse: 0.18411 | valid_mse: 0.0339  |  0:04:12s\n",
      "epoch 142| loss: 0.02336 | train_rmsle: 0.0012  | train_mae: 0.11239 | train_rmse: 0.14159 | train_mse: 0.02005 | valid_rmsle: 0.00142 | valid_mae: 0.12502 | valid_rmse: 0.15683 | valid_mse: 0.0246  |  0:04:14s\n",
      "epoch 143| loss: 0.02452 | train_rmsle: 0.00134 | train_mae: 0.12167 | train_rmse: 0.15048 | train_mse: 0.02264 | valid_rmsle: 0.0016  | valid_mae: 0.13464 | valid_rmse: 0.16666 | valid_mse: 0.02777 |  0:04:16s\n",
      "epoch 144| loss: 0.02087 | train_rmsle: 0.00086 | train_mae: 0.09674 | train_rmse: 0.12548 | train_mse: 0.01575 | valid_rmsle: 0.00109 | valid_mae: 0.11111 | valid_rmse: 0.14151 | valid_mse: 0.02003 |  0:04:17s\n",
      "epoch 145| loss: 0.02077 | train_rmsle: 0.00085 | train_mae: 0.09516 | train_rmse: 0.12335 | train_mse: 0.01522 | valid_rmsle: 0.00105 | valid_mae: 0.10805 | valid_rmse: 0.13814 | valid_mse: 0.01908 |  0:04:19s\n",
      "epoch 146| loss: 0.02306 | train_rmsle: 0.00106 | train_mae: 0.1106  | train_rmse: 0.14023 | train_mse: 0.01966 | valid_rmsle: 0.00132 | valid_mae: 0.12599 | valid_rmse: 0.15625 | valid_mse: 0.02441 |  0:04:21s\n",
      "epoch 147| loss: 0.02175 | train_rmsle: 0.00131 | train_mae: 0.1127  | train_rmse: 0.14339 | train_mse: 0.02056 | valid_rmsle: 0.00157 | valid_mae: 0.12566 | valid_rmse: 0.15939 | valid_mse: 0.02541 |  0:04:23s\n",
      "epoch 148| loss: 0.02128 | train_rmsle: 0.00096 | train_mae: 0.10229 | train_rmse: 0.12979 | train_mse: 0.01685 | valid_rmsle: 0.00118 | valid_mae: 0.1151  | valid_rmse: 0.14488 | valid_mse: 0.02099 |  0:04:24s\n",
      "epoch 149| loss: 0.02036 | train_rmsle: 0.00081 | train_mae: 0.09402 | train_rmse: 0.12065 | train_mse: 0.01456 | valid_rmsle: 0.00102 | valid_mae: 0.10654 | valid_rmse: 0.1361  | valid_mse: 0.01852 |  0:04:26s\n",
      "epoch 150| loss: 0.02055 | train_rmsle: 0.00197 | train_mae: 0.13641 | train_rmse: 0.16984 | train_mse: 0.02885 | valid_rmsle: 0.00205 | valid_mae: 0.14182 | valid_rmse: 0.17655 | valid_mse: 0.03117 |  0:04:28s\n",
      "epoch 151| loss: 0.02133 | train_rmsle: 0.00112 | train_mae: 0.10839 | train_rmse: 0.13702 | train_mse: 0.01877 | valid_rmsle: 0.0013  | valid_mae: 0.11799 | valid_rmse: 0.14987 | valid_mse: 0.02246 |  0:04:30s\n",
      "epoch 152| loss: 0.01892 | train_rmsle: 0.00079 | train_mae: 0.09216 | train_rmse: 0.11979 | train_mse: 0.01435 | valid_rmsle: 0.00099 | valid_mae: 0.1035  | valid_rmse: 0.13484 | valid_mse: 0.01818 |  0:04:31s\n",
      "epoch 153| loss: 0.01799 | train_rmsle: 0.00091 | train_mae: 0.09715 | train_rmse: 0.12398 | train_mse: 0.01537 | valid_rmsle: 0.0011  | valid_mae: 0.10923 | valid_rmse: 0.13796 | valid_mse: 0.01903 |  0:04:33s\n",
      "epoch 154| loss: 0.02033 | train_rmsle: 0.00133 | train_mae: 0.12374 | train_rmse: 0.1506  | train_mse: 0.02268 | valid_rmsle: 0.00154 | valid_mae: 0.13482 | valid_rmse: 0.16406 | valid_mse: 0.02692 |  0:04:35s\n",
      "epoch 155| loss: 0.0211  | train_rmsle: 0.001   | train_mae: 0.10554 | train_rmse: 0.13152 | train_mse: 0.0173  | valid_rmsle: 0.00122 | valid_mae: 0.11756 | valid_rmse: 0.14667 | valid_mse: 0.02151 |  0:04:37s\n",
      "epoch 156| loss: 0.02001 | train_rmsle: 0.00072 | train_mae: 0.08803 | train_rmse: 0.11296 | train_mse: 0.01276 | valid_rmsle: 0.00094 | valid_mae: 0.1022  | valid_rmse: 0.13077 | valid_mse: 0.0171  |  0:04:38s\n",
      "epoch 157| loss: 0.01972 | train_rmsle: 0.00087 | train_mae: 0.09518 | train_rmse: 0.12227 | train_mse: 0.01495 | valid_rmsle: 0.0011  | valid_mae: 0.10746 | valid_rmse: 0.13872 | valid_mse: 0.01924 |  0:04:40s\n",
      "epoch 158| loss: 0.01889 | train_rmsle: 0.00076 | train_mae: 0.09065 | train_rmse: 0.11753 | train_mse: 0.01381 | valid_rmsle: 0.00098 | valid_mae: 0.1024  | valid_rmse: 0.13365 | valid_mse: 0.01786 |  0:04:42s\n",
      "epoch 159| loss: 0.01966 | train_rmsle: 0.00079 | train_mae: 0.09472 | train_rmse: 0.12022 | train_mse: 0.01445 | valid_rmsle: 0.001   | valid_mae: 0.107   | valid_rmse: 0.13537 | valid_mse: 0.01833 |  0:04:44s\n",
      "epoch 160| loss: 0.01736 | train_rmsle: 0.00113 | train_mae: 0.10913 | train_rmse: 0.13488 | train_mse: 0.01819 | valid_rmsle: 0.00134 | valid_mae: 0.12031 | valid_rmse: 0.1488  | valid_mse: 0.02214 |  0:04:46s\n",
      "epoch 161| loss: 0.01642 | train_rmsle: 0.00088 | train_mae: 0.09863 | train_rmse: 0.1224  | train_mse: 0.01498 | valid_rmsle: 0.00109 | valid_mae: 0.11039 | valid_rmse: 0.13784 | valid_mse: 0.019   |  0:04:47s\n",
      "epoch 162| loss: 0.01806 | train_rmsle: 0.00146 | train_mae: 0.13107 | train_rmse: 0.1558  | train_mse: 0.02427 | valid_rmsle: 0.00167 | valid_mae: 0.14073 | valid_rmse: 0.16861 | valid_mse: 0.02843 |  0:04:49s\n",
      "epoch 163| loss: 0.01706 | train_rmsle: 0.00078 | train_mae: 0.09251 | train_rmse: 0.11573 | train_mse: 0.01339 | valid_rmsle: 0.00101 | valid_mae: 0.10515 | valid_rmse: 0.13286 | valid_mse: 0.01765 |  0:04:51s\n",
      "epoch 164| loss: 0.01519 | train_rmsle: 0.0007  | train_mae: 0.08924 | train_rmse: 0.11342 | train_mse: 0.01286 | valid_rmsle: 0.00095 | valid_mae: 0.10472 | valid_rmse: 0.13263 | valid_mse: 0.01759 |  0:04:53s\n",
      "epoch 165| loss: 0.01627 | train_rmsle: 0.00085 | train_mae: 0.09439 | train_rmse: 0.11783 | train_mse: 0.01388 | valid_rmsle: 0.00106 | valid_mae: 0.10696 | valid_rmse: 0.13397 | valid_mse: 0.01795 |  0:04:54s\n",
      "epoch 166| loss: 0.01474 | train_rmsle: 0.00058 | train_mae: 0.07828 | train_rmse: 0.10194 | train_mse: 0.01039 | valid_rmsle: 0.00081 | valid_mae: 0.09363 | valid_rmse: 0.12087 | valid_mse: 0.01461 |  0:04:56s\n",
      "epoch 167| loss: 0.01688 | train_rmsle: 0.00081 | train_mae: 0.08787 | train_rmse: 0.11317 | train_mse: 0.01281 | valid_rmsle: 0.00104 | valid_mae: 0.10272 | valid_rmse: 0.13074 | valid_mse: 0.01709 |  0:04:58s\n",
      "epoch 168| loss: 0.01557 | train_rmsle: 0.00059 | train_mae: 0.07974 | train_rmse: 0.10386 | train_mse: 0.01079 | valid_rmsle: 0.00081 | valid_mae: 0.09333 | valid_rmse: 0.12187 | valid_mse: 0.01485 |  0:05:00s\n",
      "epoch 169| loss: 0.0171  | train_rmsle: 0.00056 | train_mae: 0.07868 | train_rmse: 0.10205 | train_mse: 0.01041 | valid_rmsle: 0.00077 | valid_mae: 0.09185 | valid_rmse: 0.11977 | valid_mse: 0.01434 |  0:05:01s\n",
      "epoch 170| loss: 0.01702 | train_rmsle: 0.00096 | train_mae: 0.10614 | train_rmse: 0.12947 | train_mse: 0.01676 | valid_rmsle: 0.00115 | valid_mae: 0.11629 | valid_rmse: 0.1426  | valid_mse: 0.02033 |  0:05:03s\n",
      "epoch 171| loss: 0.01601 | train_rmsle: 0.0008  | train_mae: 0.08975 | train_rmse: 0.11298 | train_mse: 0.01277 | valid_rmsle: 0.00098 | valid_mae: 0.10149 | valid_rmse: 0.12843 | valid_mse: 0.01649 |  0:05:05s\n",
      "epoch 172| loss: 0.01687 | train_rmsle: 0.0014  | train_mae: 0.1098  | train_rmse: 0.139   | train_mse: 0.01932 | valid_rmsle: 0.00151 | valid_mae: 0.11838 | valid_rmse: 0.14838 | valid_mse: 0.02202 |  0:05:07s\n",
      "epoch 173| loss: 0.0154  | train_rmsle: 0.00194 | train_mae: 0.12737 | train_rmse: 0.161   | train_mse: 0.02592 | valid_rmsle: 0.002   | valid_mae: 0.13498 | valid_rmse: 0.16713 | valid_mse: 0.02793 |  0:05:09s\n",
      "epoch 174| loss: 0.01679 | train_rmsle: 0.00058 | train_mae: 0.07931 | train_rmse: 0.10248 | train_mse: 0.0105  | valid_rmsle: 0.00074 | valid_mae: 0.09082 | valid_rmse: 0.11618 | valid_mse: 0.0135  |  0:05:10s\n",
      "epoch 175| loss: 0.0151  | train_rmsle: 0.00063 | train_mae: 0.08052 | train_rmse: 0.10399 | train_mse: 0.01081 | valid_rmsle: 0.00079 | valid_mae: 0.09138 | valid_rmse: 0.11792 | valid_mse: 0.0139  |  0:05:12s\n",
      "epoch 176| loss: 0.01511 | train_rmsle: 0.00055 | train_mae: 0.0766  | train_rmse: 0.09925 | train_mse: 0.00985 | valid_rmsle: 0.00075 | valid_mae: 0.09118 | valid_rmse: 0.11615 | valid_mse: 0.01349 |  0:05:14s\n",
      "epoch 177| loss: 0.01512 | train_rmsle: 0.00087 | train_mae: 0.08978 | train_rmse: 0.11539 | train_mse: 0.01331 | valid_rmsle: 0.00106 | valid_mae: 0.10316 | valid_rmse: 0.13105 | valid_mse: 0.01717 |  0:05:16s\n",
      "epoch 178| loss: 0.01546 | train_rmsle: 0.00097 | train_mae: 0.09761 | train_rmse: 0.12193 | train_mse: 0.01487 | valid_rmsle: 0.00111 | valid_mae: 0.10619 | valid_rmse: 0.13332 | valid_mse: 0.01777 |  0:05:17s\n",
      "epoch 179| loss: 0.01389 | train_rmsle: 0.00056 | train_mae: 0.07868 | train_rmse: 0.10088 | train_mse: 0.01018 | valid_rmsle: 0.00074 | valid_mae: 0.09056 | valid_rmse: 0.11655 | valid_mse: 0.01358 |  0:05:19s\n",
      "epoch 180| loss: 0.0143  | train_rmsle: 0.00056 | train_mae: 0.07689 | train_rmse: 0.0989  | train_mse: 0.00978 | valid_rmsle: 0.00076 | valid_mae: 0.09098 | valid_rmse: 0.11662 | valid_mse: 0.0136  |  0:05:21s\n",
      "epoch 181| loss: 0.01347 | train_rmsle: 0.00059 | train_mae: 0.08146 | train_rmse: 0.10259 | train_mse: 0.01052 | valid_rmsle: 0.00078 | valid_mae: 0.0935  | valid_rmse: 0.1181  | valid_mse: 0.01395 |  0:05:23s\n",
      "epoch 182| loss: 0.01732 | train_rmsle: 0.00108 | train_mae: 0.10536 | train_rmse: 0.13325 | train_mse: 0.01776 | valid_rmsle: 0.00124 | valid_mae: 0.11413 | valid_rmse: 0.14472 | valid_mse: 0.02094 |  0:05:24s\n",
      "epoch 183| loss: 0.01841 | train_rmsle: 0.00064 | train_mae: 0.08478 | train_rmse: 0.10682 | train_mse: 0.01141 | valid_rmsle: 0.00085 | valid_mae: 0.09722 | valid_rmse: 0.12335 | valid_mse: 0.01522 |  0:05:26s\n",
      "epoch 184| loss: 0.01384 | train_rmsle: 0.00056 | train_mae: 0.07835 | train_rmse: 0.10072 | train_mse: 0.01014 | valid_rmsle: 0.00074 | valid_mae: 0.08944 | valid_rmse: 0.11577 | valid_mse: 0.0134  |  0:05:28s\n",
      "epoch 185| loss: 0.01614 | train_rmsle: 0.00049 | train_mae: 0.07285 | train_rmse: 0.0946  | train_mse: 0.00895 | valid_rmsle: 0.00069 | valid_mae: 0.08669 | valid_rmse: 0.11268 | valid_mse: 0.0127  |  0:05:30s\n",
      "epoch 186| loss: 0.01719 | train_rmsle: 0.00092 | train_mae: 0.09315 | train_rmse: 0.1176  | train_mse: 0.01383 | valid_rmsle: 0.00107 | valid_mae: 0.10423 | valid_rmse: 0.13068 | valid_mse: 0.01708 |  0:05:32s\n",
      "epoch 187| loss: 0.01434 | train_rmsle: 0.00092 | train_mae: 0.09858 | train_rmse: 0.12156 | train_mse: 0.01478 | valid_rmsle: 0.00109 | valid_mae: 0.11044 | valid_rmse: 0.13528 | valid_mse: 0.0183  |  0:05:33s\n",
      "epoch 188| loss: 0.01365 | train_rmsle: 0.00056 | train_mae: 0.07589 | train_rmse: 0.0979  | train_mse: 0.00958 | valid_rmsle: 0.00076 | valid_mae: 0.09094 | valid_rmse: 0.11612 | valid_mse: 0.01348 |  0:05:35s\n",
      "epoch 189| loss: 0.01411 | train_rmsle: 0.00051 | train_mae: 0.07451 | train_rmse: 0.09589 | train_mse: 0.0092  | valid_rmsle: 0.0007  | valid_mae: 0.08854 | valid_rmse: 0.11307 | valid_mse: 0.01278 |  0:05:37s\n",
      "epoch 190| loss: 0.01393 | train_rmsle: 0.0009  | train_mae: 0.09217 | train_rmse: 0.11744 | train_mse: 0.01379 | valid_rmsle: 0.0011  | valid_mae: 0.10539 | valid_rmse: 0.13259 | valid_mse: 0.01758 |  0:05:39s\n",
      "epoch 191| loss: 0.01492 | train_rmsle: 0.002   | train_mae: 0.14925 | train_rmse: 0.17446 | train_mse: 0.03044 | valid_rmsle: 0.00207 | valid_mae: 0.15405 | valid_rmse: 0.17992 | valid_mse: 0.03237 |  0:05:41s\n",
      "epoch 192| loss: 0.0157  | train_rmsle: 0.00052 | train_mae: 0.07426 | train_rmse: 0.09457 | train_mse: 0.00894 | valid_rmsle: 0.00069 | valid_mae: 0.08611 | valid_rmse: 0.11036 | valid_mse: 0.01218 |  0:05:42s\n",
      "epoch 193| loss: 0.01434 | train_rmsle: 0.00095 | train_mae: 0.09789 | train_rmse: 0.12353 | train_mse: 0.01526 | valid_rmsle: 0.00112 | valid_mae: 0.11076 | valid_rmse: 0.13713 | valid_mse: 0.01881 |  0:05:44s\n",
      "epoch 194| loss: 0.01355 | train_rmsle: 0.00045 | train_mae: 0.06962 | train_rmse: 0.09048 | train_mse: 0.00819 | valid_rmsle: 0.00066 | valid_mae: 0.08501 | valid_rmse: 0.10944 | valid_mse: 0.01198 |  0:05:46s\n",
      "epoch 195| loss: 0.01321 | train_rmsle: 0.00043 | train_mae: 0.06774 | train_rmse: 0.08806 | train_mse: 0.00776 | valid_rmsle: 0.00061 | valid_mae: 0.0811  | valid_rmse: 0.10606 | valid_mse: 0.01125 |  0:05:48s\n",
      "epoch 196| loss: 0.01634 | train_rmsle: 0.00093 | train_mae: 0.1098  | train_rmse: 0.13253 | train_mse: 0.01756 | valid_rmsle: 0.00112 | valid_mae: 0.12037 | valid_rmse: 0.14592 | valid_mse: 0.02129 |  0:05:49s\n",
      "epoch 197| loss: 0.01401 | train_rmsle: 0.00058 | train_mae: 0.08258 | train_rmse: 0.10269 | train_mse: 0.01054 | valid_rmsle: 0.00077 | valid_mae: 0.09537 | valid_rmse: 0.11871 | valid_mse: 0.01409 |  0:05:51s\n",
      "epoch 198| loss: 0.01257 | train_rmsle: 0.00044 | train_mae: 0.06836 | train_rmse: 0.08787 | train_mse: 0.00772 | valid_rmsle: 0.00062 | valid_mae: 0.08288 | valid_rmse: 0.10583 | valid_mse: 0.0112  |  0:05:53s\n",
      "epoch 199| loss: 0.01372 | train_rmsle: 0.00052 | train_mae: 0.07457 | train_rmse: 0.09367 | train_mse: 0.00877 | valid_rmsle: 0.0007  | valid_mae: 0.08739 | valid_rmse: 0.11017 | valid_mse: 0.01214 |  0:05:55s\n",
      "epoch 200| loss: 0.01237 | train_rmsle: 0.00042 | train_mae: 0.06571 | train_rmse: 0.08478 | train_mse: 0.00719 | valid_rmsle: 0.00061 | valid_mae: 0.08102 | valid_rmse: 0.10464 | valid_mse: 0.01095 |  0:05:57s\n",
      "epoch 201| loss: 0.014   | train_rmsle: 0.00081 | train_mae: 0.09789 | train_rmse: 0.11803 | train_mse: 0.01393 | valid_rmsle: 0.00097 | valid_mae: 0.10759 | valid_rmse: 0.13068 | valid_mse: 0.01708 |  0:05:58s\n",
      "epoch 202| loss: 0.01405 | train_rmsle: 0.00057 | train_mae: 0.07461 | train_rmse: 0.09462 | train_mse: 0.00895 | valid_rmsle: 0.00073 | valid_mae: 0.08563 | valid_rmse: 0.10933 | valid_mse: 0.01195 |  0:06:00s\n",
      "epoch 203| loss: 0.01331 | train_rmsle: 0.00072 | train_mae: 0.09456 | train_rmse: 0.1142  | train_mse: 0.01304 | valid_rmsle: 0.00091 | valid_mae: 0.10543 | valid_rmse: 0.12835 | valid_mse: 0.01647 |  0:06:02s\n",
      "epoch 204| loss: 0.01435 | train_rmsle: 0.00073 | train_mae: 0.08469 | train_rmse: 0.10733 | train_mse: 0.01152 | valid_rmsle: 0.00089 | valid_mae: 0.09508 | valid_rmse: 0.1215  | valid_mse: 0.01476 |  0:06:04s\n",
      "epoch 205| loss: 0.0124  | train_rmsle: 0.00067 | train_mae: 0.07879 | train_rmse: 0.10055 | train_mse: 0.01011 | valid_rmsle: 0.00084 | valid_mae: 0.09118 | valid_rmse: 0.11597 | valid_mse: 0.01345 |  0:06:06s\n",
      "epoch 206| loss: 0.01256 | train_rmsle: 0.00046 | train_mae: 0.07112 | train_rmse: 0.08956 | train_mse: 0.00802 | valid_rmsle: 0.00061 | valid_mae: 0.08256 | valid_rmse: 0.10485 | valid_mse: 0.01099 |  0:06:07s\n",
      "epoch 207| loss: 0.01191 | train_rmsle: 0.00049 | train_mae: 0.07035 | train_rmse: 0.08918 | train_mse: 0.00795 | valid_rmsle: 0.00064 | valid_mae: 0.08061 | valid_rmse: 0.10362 | valid_mse: 0.01074 |  0:06:09s\n",
      "epoch 208| loss: 0.01082 | train_rmsle: 0.00041 | train_mae: 0.06863 | train_rmse: 0.0868  | train_mse: 0.00753 | valid_rmsle: 0.00058 | valid_mae: 0.08111 | valid_rmse: 0.10285 | valid_mse: 0.01058 |  0:06:11s\n",
      "epoch 209| loss: 0.01112 | train_rmsle: 0.00043 | train_mae: 0.06843 | train_rmse: 0.0869  | train_mse: 0.00755 | valid_rmsle: 0.00061 | valid_mae: 0.08211 | valid_rmse: 0.10421 | valid_mse: 0.01086 |  0:06:13s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 208 and best_valid_mse = 0.01058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010654781508760477 RMSE: 0.1032220010887237 R2: 0.9528353877459423 MAE: 0.08117098887953542\n",
      "=====================================\n",
      "[69/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.58556 | train_rmsle: 0.47641 | train_mae: 2.12101 | train_rmse: 2.17582 | train_mse: 4.73417 | valid_rmsle: 0.47809 | valid_mae: 2.12734 | valid_rmse: 2.1808  | valid_mse: 4.75588 |  0:00:01s\n",
      "epoch 1  | loss: 2.3397  | train_rmsle: 0.12747 | train_mae: 1.24805 | train_rmse: 1.331   | train_mse: 1.77156 | valid_rmsle: 0.12817 | valid_mae: 1.25198 | valid_rmse: 1.33565 | valid_mse: 1.78397 |  0:00:03s\n",
      "epoch 2  | loss: 1.12693 | train_rmsle: 0.04271 | train_mae: 0.74476 | train_rmse: 0.83771 | train_mse: 0.70176 | valid_rmsle: 0.04282 | valid_mae: 0.74587 | valid_rmse: 0.84104 | valid_mse: 0.70735 |  0:00:05s\n",
      "epoch 3  | loss: 0.68481 | train_rmsle: 0.03856 | train_mae: 0.70806 | train_rmse: 0.79965 | train_mse: 0.63943 | valid_rmsle: 0.03876 | valid_mae: 0.71039 | valid_rmse: 0.80419 | valid_mse: 0.64673 |  0:00:07s\n",
      "epoch 4  | loss: 0.48549 | train_rmsle: 0.02893 | train_mae: 0.60994 | train_rmse: 0.7008  | train_mse: 0.49112 | valid_rmsle: 0.02884 | valid_mae: 0.61089 | valid_rmse: 0.70296 | valid_mse: 0.49415 |  0:00:09s\n",
      "epoch 5  | loss: 0.39529 | train_rmsle: 0.02431 | train_mae: 0.55532 | train_rmse: 0.64493 | train_mse: 0.41593 | valid_rmsle: 0.02412 | valid_mae: 0.55688 | valid_rmse: 0.6461  | valid_mse: 0.41744 |  0:00:10s\n",
      "epoch 6  | loss: 0.34371 | train_rmsle: 0.01967 | train_mae: 0.49216 | train_rmse: 0.57962 | train_mse: 0.33596 | valid_rmsle: 0.01937 | valid_mae: 0.49371 | valid_rmse: 0.57973 | valid_mse: 0.33609 |  0:00:12s\n",
      "epoch 7  | loss: 0.31357 | train_rmsle: 0.01747 | train_mae: 0.45625 | train_rmse: 0.54359 | train_mse: 0.29549 | valid_rmsle: 0.01706 | valid_mae: 0.45796 | valid_rmse: 0.54216 | valid_mse: 0.29393 |  0:00:14s\n",
      "epoch 8  | loss: 0.29123 | train_rmsle: 0.01718 | train_mae: 0.4523  | train_rmse: 0.53903 | train_mse: 0.29056 | valid_rmsle: 0.01679 | valid_mae: 0.4538  | valid_rmse: 0.53775 | valid_mse: 0.28917 |  0:00:16s\n",
      "epoch 9  | loss: 0.27053 | train_rmsle: 0.01634 | train_mae: 0.43559 | train_rmse: 0.52333 | train_mse: 0.27387 | valid_rmsle: 0.01597 | valid_mae: 0.43713 | valid_rmse: 0.52264 | valid_mse: 0.27315 |  0:00:18s\n",
      "epoch 10 | loss: 0.27103 | train_rmsle: 0.02057 | train_mae: 0.50655 | train_rmse: 0.59356 | train_mse: 0.35231 | valid_rmsle: 0.0203  | valid_mae: 0.5088  | valid_rmse: 0.59408 | valid_mse: 0.35293 |  0:00:19s\n",
      "epoch 11 | loss: 0.24806 | train_rmsle: 0.01002 | train_mae: 0.32105 | train_rmse: 0.40064 | train_mse: 0.16051 | valid_rmsle: 0.00894 | valid_mae: 0.30628 | valid_rmse: 0.38573 | valid_mse: 0.14878 |  0:00:21s\n",
      "epoch 12 | loss: 0.20274 | train_rmsle: 0.00948 | train_mae: 0.30345 | train_rmse: 0.38482 | train_mse: 0.14809 | valid_rmsle: 0.00862 | valid_mae: 0.29002 | valid_rmse: 0.37032 | valid_mse: 0.13714 |  0:00:23s\n",
      "epoch 13 | loss: 0.18758 | train_rmsle: 0.00873 | train_mae: 0.29047 | train_rmse: 0.36861 | train_mse: 0.13588 | valid_rmsle: 0.00782 | valid_mae: 0.27568 | valid_rmse: 0.35246 | valid_mse: 0.12422 |  0:00:25s\n",
      "epoch 14 | loss: 0.17264 | train_rmsle: 0.00872 | train_mae: 0.29127 | train_rmse: 0.36931 | train_mse: 0.13639 | valid_rmsle: 0.00772 | valid_mae: 0.27666 | valid_rmse: 0.35147 | valid_mse: 0.12353 |  0:00:27s\n",
      "epoch 15 | loss: 0.16545 | train_rmsle: 0.00824 | train_mae: 0.28596 | train_rmse: 0.3604  | train_mse: 0.12989 | valid_rmsle: 0.00779 | valid_mae: 0.27969 | valid_rmse: 0.35593 | valid_mse: 0.12668 |  0:00:28s\n",
      "epoch 16 | loss: 0.16878 | train_rmsle: 0.00756 | train_mae: 0.26995 | train_rmse: 0.34295 | train_mse: 0.11761 | valid_rmsle: 0.00684 | valid_mae: 0.25772 | valid_rmse: 0.33017 | valid_mse: 0.10901 |  0:00:30s\n",
      "epoch 17 | loss: 0.1556  | train_rmsle: 0.00741 | train_mae: 0.2619  | train_rmse: 0.33766 | train_mse: 0.11401 | valid_rmsle: 0.00675 | valid_mae: 0.25096 | valid_rmse: 0.32679 | valid_mse: 0.10679 |  0:00:32s\n",
      "epoch 18 | loss: 0.15617 | train_rmsle: 0.00898 | train_mae: 0.28937 | train_rmse: 0.37803 | train_mse: 0.14291 | valid_rmsle: 0.00843 | valid_mae: 0.29008 | valid_rmse: 0.37213 | valid_mse: 0.13848 |  0:00:34s\n",
      "epoch 19 | loss: 0.20371 | train_rmsle: 0.00775 | train_mae: 0.26106 | train_rmse: 0.34453 | train_mse: 0.1187  | valid_rmsle: 0.00708 | valid_mae: 0.25345 | valid_rmse: 0.33268 | valid_mse: 0.11068 |  0:00:35s\n",
      "epoch 20 | loss: 0.15289 | train_rmsle: 0.00833 | train_mae: 0.28819 | train_rmse: 0.36302 | train_mse: 0.13178 | valid_rmsle: 0.00761 | valid_mae: 0.27564 | valid_rmse: 0.35047 | valid_mse: 0.12283 |  0:00:37s\n",
      "epoch 21 | loss: 0.1453  | train_rmsle: 0.0085  | train_mae: 0.2946  | train_rmse: 0.36775 | train_mse: 0.13524 | valid_rmsle: 0.00786 | valid_mae: 0.285   | valid_rmse: 0.35767 | valid_mse: 0.12793 |  0:00:39s\n",
      "epoch 22 | loss: 0.13891 | train_rmsle: 0.00783 | train_mae: 0.26525 | train_rmse: 0.34765 | train_mse: 0.12086 | valid_rmsle: 0.00728 | valid_mae: 0.25808 | valid_rmse: 0.34002 | valid_mse: 0.11562 |  0:00:41s\n",
      "epoch 23 | loss: 0.14962 | train_rmsle: 0.01053 | train_mae: 0.33916 | train_rmse: 0.414   | train_mse: 0.17139 | valid_rmsle: 0.01006 | valid_mae: 0.33269 | valid_rmse: 0.4083  | valid_mse: 0.16671 |  0:00:42s\n",
      "epoch 24 | loss: 0.15513 | train_rmsle: 0.01153 | train_mae: 0.36436 | train_rmse: 0.43598 | train_mse: 0.19008 | valid_rmsle: 0.01096 | valid_mae: 0.35748 | valid_rmse: 0.42808 | valid_mse: 0.18326 |  0:00:44s\n",
      "epoch 25 | loss: 0.17048 | train_rmsle: 0.00779 | train_mae: 0.26893 | train_rmse: 0.34748 | train_mse: 0.12074 | valid_rmsle: 0.00699 | valid_mae: 0.25571 | valid_rmse: 0.33316 | valid_mse: 0.11099 |  0:00:46s\n",
      "epoch 26 | loss: 0.13098 | train_rmsle: 0.00745 | train_mae: 0.25789 | train_rmse: 0.33765 | train_mse: 0.11401 | valid_rmsle: 0.007   | valid_mae: 0.24773 | valid_rmse: 0.33059 | valid_mse: 0.10929 |  0:00:48s\n",
      "epoch 27 | loss: 0.13574 | train_rmsle: 0.00842 | train_mae: 0.28854 | train_rmse: 0.36448 | train_mse: 0.13284 | valid_rmsle: 0.00772 | valid_mae: 0.27772 | valid_rmse: 0.35242 | valid_mse: 0.1242  |  0:00:50s\n",
      "epoch 28 | loss: 0.16869 | train_rmsle: 0.01038 | train_mae: 0.33994 | train_rmse: 0.41125 | train_mse: 0.16912 | valid_rmsle: 0.00981 | valid_mae: 0.33141 | valid_rmse: 0.40299 | valid_mse: 0.1624  |  0:00:51s\n",
      "epoch 29 | loss: 0.28532 | train_rmsle: 0.00994 | train_mae: 0.29904 | train_rmse: 0.39743 | train_mse: 0.15795 | valid_rmsle: 0.00949 | valid_mae: 0.29922 | valid_rmse: 0.39234 | valid_mse: 0.15393 |  0:00:53s\n",
      "epoch 30 | loss: 0.20346 | train_rmsle: 0.00744 | train_mae: 0.2558  | train_rmse: 0.33785 | train_mse: 0.11414 | valid_rmsle: 0.00679 | valid_mae: 0.24539 | valid_rmse: 0.32523 | valid_mse: 0.10577 |  0:00:55s\n",
      "epoch 31 | loss: 0.13057 | train_rmsle: 0.0078  | train_mae: 0.27268 | train_rmse: 0.34934 | train_mse: 0.12204 | valid_rmsle: 0.00693 | valid_mae: 0.25932 | valid_rmse: 0.3327  | valid_mse: 0.11069 |  0:00:57s\n",
      "epoch 32 | loss: 0.15595 | train_rmsle: 0.00848 | train_mae: 0.29361 | train_rmse: 0.36708 | train_mse: 0.13475 | valid_rmsle: 0.00776 | valid_mae: 0.28051 | valid_rmse: 0.35415 | valid_mse: 0.12542 |  0:00:58s\n",
      "epoch 33 | loss: 0.12074 | train_rmsle: 0.00935 | train_mae: 0.31229 | train_rmse: 0.38681 | train_mse: 0.14962 | valid_rmsle: 0.00866 | valid_mae: 0.30008 | valid_rmse: 0.37612 | valid_mse: 0.14147 |  0:01:00s\n",
      "epoch 34 | loss: 0.12541 | train_rmsle: 0.00862 | train_mae: 0.30029 | train_rmse: 0.37157 | train_mse: 0.13807 | valid_rmsle: 0.00807 | valid_mae: 0.29181 | valid_rmse: 0.3631  | valid_mse: 0.13184 |  0:01:02s\n",
      "epoch 35 | loss: 0.14115 | train_rmsle: 0.0087  | train_mae: 0.30299 | train_rmse: 0.37379 | train_mse: 0.13972 | valid_rmsle: 0.00835 | valid_mae: 0.29858 | valid_rmse: 0.37049 | valid_mse: 0.13727 |  0:01:04s\n",
      "epoch 36 | loss: 0.12238 | train_rmsle: 0.00722 | train_mae: 0.25161 | train_rmse: 0.33076 | train_mse: 0.1094  | valid_rmsle: 0.00669 | valid_mae: 0.24345 | valid_rmse: 0.3229  | valid_mse: 0.10427 |  0:01:06s\n",
      "epoch 37 | loss: 0.118   | train_rmsle: 0.00793 | train_mae: 0.27838 | train_rmse: 0.35251 | train_mse: 0.12426 | valid_rmsle: 0.00757 | valid_mae: 0.26996 | valid_rmse: 0.34735 | valid_mse: 0.12065 |  0:01:07s\n",
      "epoch 38 | loss: 0.12132 | train_rmsle: 0.00752 | train_mae: 0.26873 | train_rmse: 0.34246 | train_mse: 0.11728 | valid_rmsle: 0.00685 | valid_mae: 0.25788 | valid_rmse: 0.33122 | valid_mse: 0.1097  |  0:01:09s\n",
      "epoch 39 | loss: 0.11361 | train_rmsle: 0.00726 | train_mae: 0.25944 | train_rmse: 0.3343  | train_mse: 0.11175 | valid_rmsle: 0.00688 | valid_mae: 0.2537  | valid_rmse: 0.33048 | valid_mse: 0.10922 |  0:01:11s\n",
      "epoch 40 | loss: 0.11525 | train_rmsle: 0.00806 | train_mae: 0.28277 | train_rmse: 0.35654 | train_mse: 0.12712 | valid_rmsle: 0.00739 | valid_mae: 0.27398 | valid_rmse: 0.34611 | valid_mse: 0.1198  |  0:01:13s\n",
      "epoch 41 | loss: 0.11394 | train_rmsle: 0.00725 | train_mae: 0.25599 | train_rmse: 0.33356 | train_mse: 0.11126 | valid_rmsle: 0.0068  | valid_mae: 0.2501  | valid_rmse: 0.32713 | valid_mse: 0.10701 |  0:01:14s\n",
      "epoch 42 | loss: 0.11421 | train_rmsle: 0.00762 | train_mae: 0.26591 | train_rmse: 0.34356 | train_mse: 0.11803 | valid_rmsle: 0.007   | valid_mae: 0.25804 | valid_rmse: 0.33483 | valid_mse: 0.11211 |  0:01:16s\n",
      "epoch 43 | loss: 0.11782 | train_rmsle: 0.00727 | train_mae: 0.26124 | train_rmse: 0.33522 | train_mse: 0.11237 | valid_rmsle: 0.0071  | valid_mae: 0.25878 | valid_rmse: 0.33648 | valid_mse: 0.11322 |  0:01:18s\n",
      "epoch 44 | loss: 0.10998 | train_rmsle: 0.00723 | train_mae: 0.25301 | train_rmse: 0.33245 | train_mse: 0.11052 | valid_rmsle: 0.00663 | valid_mae: 0.2454  | valid_rmse: 0.32305 | valid_mse: 0.10436 |  0:01:20s\n",
      "epoch 45 | loss: 0.11091 | train_rmsle: 0.00706 | train_mae: 0.25196 | train_rmse: 0.32846 | train_mse: 0.10789 | valid_rmsle: 0.00677 | valid_mae: 0.24868 | valid_rmse: 0.32731 | valid_mse: 0.10713 |  0:01:21s\n",
      "epoch 46 | loss: 0.10807 | train_rmsle: 0.00694 | train_mae: 0.2474  | train_rmse: 0.32435 | train_mse: 0.1052  | valid_rmsle: 0.00655 | valid_mae: 0.24186 | valid_rmse: 0.31987 | valid_mse: 0.10232 |  0:01:23s\n",
      "epoch 47 | loss: 0.11175 | train_rmsle: 0.008   | train_mae: 0.28228 | train_rmse: 0.3551  | train_mse: 0.12609 | valid_rmsle: 0.00741 | valid_mae: 0.27314 | valid_rmse: 0.3455  | valid_mse: 0.11937 |  0:01:25s\n",
      "epoch 48 | loss: 0.10851 | train_rmsle: 0.00686 | train_mae: 0.24567 | train_rmse: 0.32267 | train_mse: 0.10412 | valid_rmsle: 0.0063  | valid_mae: 0.23783 | valid_rmse: 0.3128  | valid_mse: 0.09784 |  0:01:27s\n",
      "epoch 49 | loss: 0.10691 | train_rmsle: 0.00726 | train_mae: 0.26429 | train_rmse: 0.33565 | train_mse: 0.11266 | valid_rmsle: 0.00673 | valid_mae: 0.25537 | valid_rmse: 0.32692 | valid_mse: 0.10688 |  0:01:29s\n",
      "epoch 50 | loss: 0.10578 | train_rmsle: 0.00699 | train_mae: 0.25493 | train_rmse: 0.32724 | train_mse: 0.10709 | valid_rmsle: 0.00644 | valid_mae: 0.24584 | valid_rmse: 0.3176  | valid_mse: 0.10087 |  0:01:30s\n",
      "epoch 51 | loss: 0.11104 | train_rmsle: 0.00714 | train_mae: 0.24747 | train_rmse: 0.32856 | train_mse: 0.10795 | valid_rmsle: 0.00677 | valid_mae: 0.24483 | valid_rmse: 0.3244  | valid_mse: 0.10524 |  0:01:32s\n",
      "epoch 52 | loss: 0.10615 | train_rmsle: 0.00678 | train_mae: 0.2447  | train_rmse: 0.32047 | train_mse: 0.1027  | valid_rmsle: 0.00637 | valid_mae: 0.23742 | valid_rmse: 0.31441 | valid_mse: 0.09886 |  0:01:34s\n",
      "epoch 53 | loss: 0.10524 | train_rmsle: 0.00682 | train_mae: 0.2474  | train_rmse: 0.32216 | train_mse: 0.10379 | valid_rmsle: 0.00625 | valid_mae: 0.23757 | valid_rmse: 0.31253 | valid_mse: 0.09768 |  0:01:36s\n",
      "epoch 54 | loss: 0.10326 | train_rmsle: 0.00701 | train_mae: 0.25511 | train_rmse: 0.32822 | train_mse: 0.10773 | valid_rmsle: 0.00652 | valid_mae: 0.244   | valid_rmse: 0.31909 | valid_mse: 0.10182 |  0:01:37s\n",
      "epoch 55 | loss: 0.10297 | train_rmsle: 0.00681 | train_mae: 0.24953 | train_rmse: 0.3222  | train_mse: 0.10381 | valid_rmsle: 0.00629 | valid_mae: 0.24172 | valid_rmse: 0.31418 | valid_mse: 0.09871 |  0:01:39s\n",
      "epoch 56 | loss: 0.10153 | train_rmsle: 0.00667 | train_mae: 0.24368 | train_rmse: 0.31789 | train_mse: 0.10105 | valid_rmsle: 0.00612 | valid_mae: 0.2327  | valid_rmse: 0.30744 | valid_mse: 0.09452 |  0:01:41s\n",
      "epoch 57 | loss: 0.10506 | train_rmsle: 0.00745 | train_mae: 0.27222 | train_rmse: 0.34189 | train_mse: 0.11689 | valid_rmsle: 0.00676 | valid_mae: 0.25947 | valid_rmse: 0.32906 | valid_mse: 0.10828 |  0:01:43s\n",
      "epoch 58 | loss: 0.10172 | train_rmsle: 0.00678 | train_mae: 0.24918 | train_rmse: 0.32168 | train_mse: 0.10348 | valid_rmsle: 0.00624 | valid_mae: 0.23946 | valid_rmse: 0.31204 | valid_mse: 0.09737 |  0:01:44s\n",
      "epoch 59 | loss: 0.10102 | train_rmsle: 0.00671 | train_mae: 0.24416 | train_rmse: 0.31808 | train_mse: 0.10118 | valid_rmsle: 0.00622 | valid_mae: 0.23565 | valid_rmse: 0.31055 | valid_mse: 0.09644 |  0:01:46s\n",
      "epoch 60 | loss: 0.10349 | train_rmsle: 0.00666 | train_mae: 0.24104 | train_rmse: 0.31595 | train_mse: 0.09982 | valid_rmsle: 0.00618 | valid_mae: 0.23447 | valid_rmse: 0.30858 | valid_mse: 0.09522 |  0:01:48s\n",
      "epoch 61 | loss: 0.10428 | train_rmsle: 0.00671 | train_mae: 0.24772 | train_rmse: 0.31939 | train_mse: 0.10201 | valid_rmsle: 0.00618 | valid_mae: 0.23907 | valid_rmse: 0.3105  | valid_mse: 0.09641 |  0:01:50s\n",
      "epoch 62 | loss: 0.10216 | train_rmsle: 0.00671 | train_mae: 0.24883 | train_rmse: 0.32012 | train_mse: 0.10248 | valid_rmsle: 0.00629 | valid_mae: 0.2427  | valid_rmse: 0.3145  | valid_mse: 0.09891 |  0:01:52s\n",
      "epoch 63 | loss: 0.10123 | train_rmsle: 0.00659 | train_mae: 0.23998 | train_rmse: 0.31442 | train_mse: 0.09886 | valid_rmsle: 0.00612 | valid_mae: 0.23277 | valid_rmse: 0.3073  | valid_mse: 0.09443 |  0:01:53s\n",
      "epoch 64 | loss: 0.10327 | train_rmsle: 0.00668 | train_mae: 0.2481  | train_rmse: 0.31898 | train_mse: 0.10175 | valid_rmsle: 0.00615 | valid_mae: 0.23947 | valid_rmse: 0.30989 | valid_mse: 0.09603 |  0:01:55s\n",
      "epoch 65 | loss: 0.10271 | train_rmsle: 0.00657 | train_mae: 0.23978 | train_rmse: 0.31393 | train_mse: 0.09855 | valid_rmsle: 0.00618 | valid_mae: 0.23318 | valid_rmse: 0.30856 | valid_mse: 0.09521 |  0:01:57s\n",
      "epoch 66 | loss: 0.10104 | train_rmsle: 0.00664 | train_mae: 0.23926 | train_rmse: 0.31552 | train_mse: 0.09955 | valid_rmsle: 0.00626 | valid_mae: 0.23451 | valid_rmse: 0.3107  | valid_mse: 0.09654 |  0:01:59s\n",
      "epoch 67 | loss: 0.10053 | train_rmsle: 0.0069  | train_mae: 0.25796 | train_rmse: 0.32694 | train_mse: 0.10689 | valid_rmsle: 0.0064  | valid_mae: 0.25101 | valid_rmse: 0.3186  | valid_mse: 0.1015  |  0:02:00s\n",
      "epoch 68 | loss: 0.09974 | train_rmsle: 0.00664 | train_mae: 0.24242 | train_rmse: 0.31613 | train_mse: 0.09994 | valid_rmsle: 0.0062  | valid_mae: 0.23929 | valid_rmse: 0.30984 | valid_mse: 0.096   |  0:02:02s\n",
      "epoch 69 | loss: 0.10004 | train_rmsle: 0.00659 | train_mae: 0.24162 | train_rmse: 0.3151  | train_mse: 0.09929 | valid_rmsle: 0.00613 | valid_mae: 0.2363  | valid_rmse: 0.30825 | valid_mse: 0.09502 |  0:02:04s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 63 and best_valid_mse = 0.09443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10081430739049327 RMSE: 0.31751268855038417 R2: 0.5537339068075225 MAE: 0.24148156224374623\n",
      "=====================================\n",
      "[70/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.58556 | train_rmsle: 0.47641 | train_mae: 2.12101 | train_rmse: 2.17582 | train_mse: 4.73417 | valid_rmsle: 0.47809 | valid_mae: 2.12734 | valid_rmse: 2.1808  | valid_mse: 4.75588 |  0:00:01s\n",
      "epoch 1  | loss: 2.3397  | train_rmsle: 0.12747 | train_mae: 1.24805 | train_rmse: 1.331   | train_mse: 1.77156 | valid_rmsle: 0.12817 | valid_mae: 1.25198 | valid_rmse: 1.33565 | valid_mse: 1.78397 |  0:00:03s\n",
      "epoch 2  | loss: 1.12693 | train_rmsle: 0.04271 | train_mae: 0.74476 | train_rmse: 0.83771 | train_mse: 0.70176 | valid_rmsle: 0.04282 | valid_mae: 0.74587 | valid_rmse: 0.84104 | valid_mse: 0.70735 |  0:00:05s\n",
      "epoch 3  | loss: 0.68481 | train_rmsle: 0.03856 | train_mae: 0.70806 | train_rmse: 0.79965 | train_mse: 0.63943 | valid_rmsle: 0.03876 | valid_mae: 0.71039 | valid_rmse: 0.80419 | valid_mse: 0.64673 |  0:00:07s\n",
      "epoch 4  | loss: 0.48549 | train_rmsle: 0.02893 | train_mae: 0.60994 | train_rmse: 0.7008  | train_mse: 0.49112 | valid_rmsle: 0.02884 | valid_mae: 0.61089 | valid_rmse: 0.70296 | valid_mse: 0.49415 |  0:00:08s\n",
      "epoch 5  | loss: 0.39529 | train_rmsle: 0.02431 | train_mae: 0.55532 | train_rmse: 0.64493 | train_mse: 0.41593 | valid_rmsle: 0.02412 | valid_mae: 0.55688 | valid_rmse: 0.6461  | valid_mse: 0.41744 |  0:00:10s\n",
      "epoch 6  | loss: 0.34371 | train_rmsle: 0.01967 | train_mae: 0.49216 | train_rmse: 0.57962 | train_mse: 0.33596 | valid_rmsle: 0.01937 | valid_mae: 0.49371 | valid_rmse: 0.57973 | valid_mse: 0.33609 |  0:00:12s\n",
      "epoch 7  | loss: 0.31357 | train_rmsle: 0.01747 | train_mae: 0.45625 | train_rmse: 0.54359 | train_mse: 0.29549 | valid_rmsle: 0.01706 | valid_mae: 0.45796 | valid_rmse: 0.54216 | valid_mse: 0.29393 |  0:00:14s\n",
      "epoch 8  | loss: 0.29123 | train_rmsle: 0.01718 | train_mae: 0.4523  | train_rmse: 0.53903 | train_mse: 0.29056 | valid_rmsle: 0.01679 | valid_mae: 0.4538  | valid_rmse: 0.53775 | valid_mse: 0.28917 |  0:00:16s\n",
      "epoch 9  | loss: 0.27053 | train_rmsle: 0.01634 | train_mae: 0.43559 | train_rmse: 0.52333 | train_mse: 0.27387 | valid_rmsle: 0.01597 | valid_mae: 0.43713 | valid_rmse: 0.52264 | valid_mse: 0.27315 |  0:00:17s\n",
      "epoch 10 | loss: 0.27103 | train_rmsle: 0.02057 | train_mae: 0.50655 | train_rmse: 0.59356 | train_mse: 0.35231 | valid_rmsle: 0.0203  | valid_mae: 0.5088  | valid_rmse: 0.59408 | valid_mse: 0.35293 |  0:00:19s\n",
      "epoch 11 | loss: 0.24806 | train_rmsle: 0.01002 | train_mae: 0.32105 | train_rmse: 0.40064 | train_mse: 0.16051 | valid_rmsle: 0.00894 | valid_mae: 0.30628 | valid_rmse: 0.38573 | valid_mse: 0.14878 |  0:00:21s\n",
      "epoch 12 | loss: 0.20274 | train_rmsle: 0.00948 | train_mae: 0.30345 | train_rmse: 0.38482 | train_mse: 0.14809 | valid_rmsle: 0.00862 | valid_mae: 0.29002 | valid_rmse: 0.37032 | valid_mse: 0.13714 |  0:00:23s\n",
      "epoch 13 | loss: 0.18758 | train_rmsle: 0.00873 | train_mae: 0.29047 | train_rmse: 0.36861 | train_mse: 0.13588 | valid_rmsle: 0.00782 | valid_mae: 0.27568 | valid_rmse: 0.35246 | valid_mse: 0.12422 |  0:00:25s\n",
      "epoch 14 | loss: 0.17264 | train_rmsle: 0.00872 | train_mae: 0.29127 | train_rmse: 0.36931 | train_mse: 0.13639 | valid_rmsle: 0.00772 | valid_mae: 0.27666 | valid_rmse: 0.35147 | valid_mse: 0.12353 |  0:00:26s\n",
      "epoch 15 | loss: 0.16545 | train_rmsle: 0.00824 | train_mae: 0.28596 | train_rmse: 0.3604  | train_mse: 0.12989 | valid_rmsle: 0.00779 | valid_mae: 0.27969 | valid_rmse: 0.35593 | valid_mse: 0.12668 |  0:00:28s\n",
      "epoch 16 | loss: 0.16878 | train_rmsle: 0.00756 | train_mae: 0.26995 | train_rmse: 0.34295 | train_mse: 0.11761 | valid_rmsle: 0.00684 | valid_mae: 0.25772 | valid_rmse: 0.33017 | valid_mse: 0.10901 |  0:00:30s\n",
      "epoch 17 | loss: 0.1556  | train_rmsle: 0.00741 | train_mae: 0.2619  | train_rmse: 0.33766 | train_mse: 0.11401 | valid_rmsle: 0.00675 | valid_mae: 0.25096 | valid_rmse: 0.32679 | valid_mse: 0.10679 |  0:00:32s\n",
      "epoch 18 | loss: 0.15617 | train_rmsle: 0.00898 | train_mae: 0.28937 | train_rmse: 0.37803 | train_mse: 0.14291 | valid_rmsle: 0.00843 | valid_mae: 0.29008 | valid_rmse: 0.37213 | valid_mse: 0.13848 |  0:00:33s\n",
      "epoch 19 | loss: 0.20371 | train_rmsle: 0.00775 | train_mae: 0.26106 | train_rmse: 0.34453 | train_mse: 0.1187  | valid_rmsle: 0.00708 | valid_mae: 0.25345 | valid_rmse: 0.33268 | valid_mse: 0.11068 |  0:00:35s\n",
      "epoch 20 | loss: 0.15289 | train_rmsle: 0.00833 | train_mae: 0.28819 | train_rmse: 0.36302 | train_mse: 0.13178 | valid_rmsle: 0.00761 | valid_mae: 0.27564 | valid_rmse: 0.35047 | valid_mse: 0.12283 |  0:00:37s\n",
      "epoch 21 | loss: 0.1453  | train_rmsle: 0.0085  | train_mae: 0.2946  | train_rmse: 0.36775 | train_mse: 0.13524 | valid_rmsle: 0.00786 | valid_mae: 0.285   | valid_rmse: 0.35767 | valid_mse: 0.12793 |  0:00:39s\n",
      "epoch 22 | loss: 0.13891 | train_rmsle: 0.00783 | train_mae: 0.26525 | train_rmse: 0.34765 | train_mse: 0.12086 | valid_rmsle: 0.00728 | valid_mae: 0.25808 | valid_rmse: 0.34002 | valid_mse: 0.11562 |  0:00:41s\n",
      "epoch 23 | loss: 0.14962 | train_rmsle: 0.01053 | train_mae: 0.33916 | train_rmse: 0.414   | train_mse: 0.17139 | valid_rmsle: 0.01006 | valid_mae: 0.33269 | valid_rmse: 0.4083  | valid_mse: 0.16671 |  0:00:42s\n",
      "epoch 24 | loss: 0.15513 | train_rmsle: 0.01153 | train_mae: 0.36436 | train_rmse: 0.43598 | train_mse: 0.19008 | valid_rmsle: 0.01096 | valid_mae: 0.35748 | valid_rmse: 0.42808 | valid_mse: 0.18326 |  0:00:44s\n",
      "epoch 25 | loss: 0.17048 | train_rmsle: 0.00779 | train_mae: 0.26893 | train_rmse: 0.34748 | train_mse: 0.12074 | valid_rmsle: 0.00699 | valid_mae: 0.25571 | valid_rmse: 0.33316 | valid_mse: 0.11099 |  0:00:46s\n",
      "epoch 26 | loss: 0.13098 | train_rmsle: 0.00745 | train_mae: 0.25789 | train_rmse: 0.33765 | train_mse: 0.11401 | valid_rmsle: 0.007   | valid_mae: 0.24773 | valid_rmse: 0.33059 | valid_mse: 0.10929 |  0:00:48s\n",
      "epoch 27 | loss: 0.13574 | train_rmsle: 0.00842 | train_mae: 0.28854 | train_rmse: 0.36448 | train_mse: 0.13284 | valid_rmsle: 0.00772 | valid_mae: 0.27772 | valid_rmse: 0.35242 | valid_mse: 0.1242  |  0:00:49s\n",
      "epoch 28 | loss: 0.16869 | train_rmsle: 0.01038 | train_mae: 0.33994 | train_rmse: 0.41125 | train_mse: 0.16912 | valid_rmsle: 0.00981 | valid_mae: 0.33141 | valid_rmse: 0.40299 | valid_mse: 0.1624  |  0:00:51s\n",
      "epoch 29 | loss: 0.28532 | train_rmsle: 0.00994 | train_mae: 0.29904 | train_rmse: 0.39743 | train_mse: 0.15795 | valid_rmsle: 0.00949 | valid_mae: 0.29922 | valid_rmse: 0.39234 | valid_mse: 0.15393 |  0:00:53s\n",
      "epoch 30 | loss: 0.20346 | train_rmsle: 0.00744 | train_mae: 0.2558  | train_rmse: 0.33785 | train_mse: 0.11414 | valid_rmsle: 0.00679 | valid_mae: 0.24539 | valid_rmse: 0.32523 | valid_mse: 0.10577 |  0:00:55s\n",
      "epoch 31 | loss: 0.13057 | train_rmsle: 0.0078  | train_mae: 0.27268 | train_rmse: 0.34934 | train_mse: 0.12204 | valid_rmsle: 0.00693 | valid_mae: 0.25932 | valid_rmse: 0.3327  | valid_mse: 0.11069 |  0:00:57s\n",
      "epoch 32 | loss: 0.15595 | train_rmsle: 0.00848 | train_mae: 0.29361 | train_rmse: 0.36708 | train_mse: 0.13475 | valid_rmsle: 0.00776 | valid_mae: 0.28051 | valid_rmse: 0.35415 | valid_mse: 0.12542 |  0:00:58s\n",
      "epoch 33 | loss: 0.12074 | train_rmsle: 0.00935 | train_mae: 0.31229 | train_rmse: 0.38681 | train_mse: 0.14962 | valid_rmsle: 0.00866 | valid_mae: 0.30008 | valid_rmse: 0.37612 | valid_mse: 0.14147 |  0:01:00s\n",
      "epoch 34 | loss: 0.12541 | train_rmsle: 0.00862 | train_mae: 0.30029 | train_rmse: 0.37157 | train_mse: 0.13807 | valid_rmsle: 0.00807 | valid_mae: 0.29181 | valid_rmse: 0.3631  | valid_mse: 0.13184 |  0:01:02s\n",
      "epoch 35 | loss: 0.14115 | train_rmsle: 0.0087  | train_mae: 0.30299 | train_rmse: 0.37379 | train_mse: 0.13972 | valid_rmsle: 0.00835 | valid_mae: 0.29858 | valid_rmse: 0.37049 | valid_mse: 0.13727 |  0:01:04s\n",
      "epoch 36 | loss: 0.12238 | train_rmsle: 0.00722 | train_mae: 0.25161 | train_rmse: 0.33076 | train_mse: 0.1094  | valid_rmsle: 0.00669 | valid_mae: 0.24345 | valid_rmse: 0.3229  | valid_mse: 0.10427 |  0:01:05s\n",
      "epoch 37 | loss: 0.118   | train_rmsle: 0.00793 | train_mae: 0.27838 | train_rmse: 0.35251 | train_mse: 0.12426 | valid_rmsle: 0.00757 | valid_mae: 0.26996 | valid_rmse: 0.34735 | valid_mse: 0.12065 |  0:01:07s\n",
      "epoch 38 | loss: 0.12132 | train_rmsle: 0.00752 | train_mae: 0.26873 | train_rmse: 0.34246 | train_mse: 0.11728 | valid_rmsle: 0.00685 | valid_mae: 0.25788 | valid_rmse: 0.33122 | valid_mse: 0.1097  |  0:01:09s\n",
      "epoch 39 | loss: 0.11361 | train_rmsle: 0.00726 | train_mae: 0.25944 | train_rmse: 0.3343  | train_mse: 0.11175 | valid_rmsle: 0.00688 | valid_mae: 0.2537  | valid_rmse: 0.33048 | valid_mse: 0.10922 |  0:01:11s\n",
      "epoch 40 | loss: 0.11525 | train_rmsle: 0.00806 | train_mae: 0.28277 | train_rmse: 0.35654 | train_mse: 0.12712 | valid_rmsle: 0.00739 | valid_mae: 0.27398 | valid_rmse: 0.34611 | valid_mse: 0.1198  |  0:01:13s\n",
      "epoch 41 | loss: 0.11394 | train_rmsle: 0.00725 | train_mae: 0.25599 | train_rmse: 0.33356 | train_mse: 0.11126 | valid_rmsle: 0.0068  | valid_mae: 0.2501  | valid_rmse: 0.32713 | valid_mse: 0.10701 |  0:01:14s\n",
      "epoch 42 | loss: 0.11421 | train_rmsle: 0.00762 | train_mae: 0.26591 | train_rmse: 0.34356 | train_mse: 0.11803 | valid_rmsle: 0.007   | valid_mae: 0.25804 | valid_rmse: 0.33483 | valid_mse: 0.11211 |  0:01:16s\n",
      "epoch 43 | loss: 0.11782 | train_rmsle: 0.00727 | train_mae: 0.26124 | train_rmse: 0.33522 | train_mse: 0.11237 | valid_rmsle: 0.0071  | valid_mae: 0.25878 | valid_rmse: 0.33648 | valid_mse: 0.11322 |  0:01:18s\n",
      "epoch 44 | loss: 0.10998 | train_rmsle: 0.00723 | train_mae: 0.25301 | train_rmse: 0.33245 | train_mse: 0.11052 | valid_rmsle: 0.00663 | valid_mae: 0.2454  | valid_rmse: 0.32305 | valid_mse: 0.10436 |  0:01:20s\n",
      "epoch 45 | loss: 0.11091 | train_rmsle: 0.00706 | train_mae: 0.25196 | train_rmse: 0.32846 | train_mse: 0.10789 | valid_rmsle: 0.00677 | valid_mae: 0.24868 | valid_rmse: 0.32731 | valid_mse: 0.10713 |  0:01:21s\n",
      "epoch 46 | loss: 0.10807 | train_rmsle: 0.00694 | train_mae: 0.2474  | train_rmse: 0.32435 | train_mse: 0.1052  | valid_rmsle: 0.00655 | valid_mae: 0.24186 | valid_rmse: 0.31987 | valid_mse: 0.10232 |  0:01:23s\n",
      "epoch 47 | loss: 0.11175 | train_rmsle: 0.008   | train_mae: 0.28228 | train_rmse: 0.3551  | train_mse: 0.12609 | valid_rmsle: 0.00741 | valid_mae: 0.27314 | valid_rmse: 0.3455  | valid_mse: 0.11937 |  0:01:25s\n",
      "epoch 48 | loss: 0.10851 | train_rmsle: 0.00686 | train_mae: 0.24567 | train_rmse: 0.32267 | train_mse: 0.10412 | valid_rmsle: 0.0063  | valid_mae: 0.23783 | valid_rmse: 0.3128  | valid_mse: 0.09784 |  0:01:27s\n",
      "epoch 49 | loss: 0.10691 | train_rmsle: 0.00726 | train_mae: 0.26429 | train_rmse: 0.33565 | train_mse: 0.11266 | valid_rmsle: 0.00673 | valid_mae: 0.25537 | valid_rmse: 0.32692 | valid_mse: 0.10688 |  0:01:29s\n",
      "epoch 50 | loss: 0.10578 | train_rmsle: 0.00699 | train_mae: 0.25493 | train_rmse: 0.32724 | train_mse: 0.10709 | valid_rmsle: 0.00644 | valid_mae: 0.24584 | valid_rmse: 0.3176  | valid_mse: 0.10087 |  0:01:30s\n",
      "epoch 51 | loss: 0.11104 | train_rmsle: 0.00714 | train_mae: 0.24747 | train_rmse: 0.32856 | train_mse: 0.10795 | valid_rmsle: 0.00677 | valid_mae: 0.24483 | valid_rmse: 0.3244  | valid_mse: 0.10524 |  0:01:32s\n",
      "epoch 52 | loss: 0.10615 | train_rmsle: 0.00678 | train_mae: 0.2447  | train_rmse: 0.32047 | train_mse: 0.1027  | valid_rmsle: 0.00637 | valid_mae: 0.23742 | valid_rmse: 0.31441 | valid_mse: 0.09886 |  0:01:34s\n",
      "epoch 53 | loss: 0.10524 | train_rmsle: 0.00682 | train_mae: 0.2474  | train_rmse: 0.32216 | train_mse: 0.10379 | valid_rmsle: 0.00625 | valid_mae: 0.23757 | valid_rmse: 0.31253 | valid_mse: 0.09768 |  0:01:36s\n",
      "epoch 54 | loss: 0.10326 | train_rmsle: 0.00701 | train_mae: 0.25511 | train_rmse: 0.32822 | train_mse: 0.10773 | valid_rmsle: 0.00652 | valid_mae: 0.244   | valid_rmse: 0.31909 | valid_mse: 0.10182 |  0:01:38s\n",
      "epoch 55 | loss: 0.10297 | train_rmsle: 0.00681 | train_mae: 0.24953 | train_rmse: 0.3222  | train_mse: 0.10381 | valid_rmsle: 0.00629 | valid_mae: 0.24172 | valid_rmse: 0.31418 | valid_mse: 0.09871 |  0:01:39s\n",
      "epoch 56 | loss: 0.10153 | train_rmsle: 0.00667 | train_mae: 0.24368 | train_rmse: 0.31789 | train_mse: 0.10105 | valid_rmsle: 0.00612 | valid_mae: 0.2327  | valid_rmse: 0.30744 | valid_mse: 0.09452 |  0:01:41s\n",
      "epoch 57 | loss: 0.10506 | train_rmsle: 0.00745 | train_mae: 0.27222 | train_rmse: 0.34189 | train_mse: 0.11689 | valid_rmsle: 0.00676 | valid_mae: 0.25947 | valid_rmse: 0.32906 | valid_mse: 0.10828 |  0:01:43s\n",
      "epoch 58 | loss: 0.10172 | train_rmsle: 0.00678 | train_mae: 0.24918 | train_rmse: 0.32168 | train_mse: 0.10348 | valid_rmsle: 0.00624 | valid_mae: 0.23946 | valid_rmse: 0.31204 | valid_mse: 0.09737 |  0:01:45s\n",
      "epoch 59 | loss: 0.10102 | train_rmsle: 0.00671 | train_mae: 0.24416 | train_rmse: 0.31808 | train_mse: 0.10118 | valid_rmsle: 0.00622 | valid_mae: 0.23565 | valid_rmse: 0.31055 | valid_mse: 0.09644 |  0:01:46s\n",
      "epoch 60 | loss: 0.10349 | train_rmsle: 0.00666 | train_mae: 0.24104 | train_rmse: 0.31595 | train_mse: 0.09982 | valid_rmsle: 0.00618 | valid_mae: 0.23447 | valid_rmse: 0.30858 | valid_mse: 0.09522 |  0:01:48s\n",
      "epoch 61 | loss: 0.10428 | train_rmsle: 0.00671 | train_mae: 0.24772 | train_rmse: 0.31939 | train_mse: 0.10201 | valid_rmsle: 0.00618 | valid_mae: 0.23907 | valid_rmse: 0.3105  | valid_mse: 0.09641 |  0:01:50s\n",
      "epoch 62 | loss: 0.10216 | train_rmsle: 0.00671 | train_mae: 0.24883 | train_rmse: 0.32012 | train_mse: 0.10248 | valid_rmsle: 0.00629 | valid_mae: 0.2427  | valid_rmse: 0.3145  | valid_mse: 0.09891 |  0:01:52s\n",
      "epoch 63 | loss: 0.10123 | train_rmsle: 0.00659 | train_mae: 0.23998 | train_rmse: 0.31442 | train_mse: 0.09886 | valid_rmsle: 0.00612 | valid_mae: 0.23277 | valid_rmse: 0.3073  | valid_mse: 0.09443 |  0:01:54s\n",
      "epoch 64 | loss: 0.10327 | train_rmsle: 0.00668 | train_mae: 0.2481  | train_rmse: 0.31898 | train_mse: 0.10175 | valid_rmsle: 0.00615 | valid_mae: 0.23947 | valid_rmse: 0.30989 | valid_mse: 0.09603 |  0:01:55s\n",
      "epoch 65 | loss: 0.10271 | train_rmsle: 0.00657 | train_mae: 0.23978 | train_rmse: 0.31393 | train_mse: 0.09855 | valid_rmsle: 0.00618 | valid_mae: 0.23318 | valid_rmse: 0.30856 | valid_mse: 0.09521 |  0:01:57s\n",
      "epoch 66 | loss: 0.10104 | train_rmsle: 0.00664 | train_mae: 0.23926 | train_rmse: 0.31552 | train_mse: 0.09955 | valid_rmsle: 0.00626 | valid_mae: 0.23451 | valid_rmse: 0.3107  | valid_mse: 0.09654 |  0:01:59s\n",
      "epoch 67 | loss: 0.10053 | train_rmsle: 0.0069  | train_mae: 0.25796 | train_rmse: 0.32694 | train_mse: 0.10689 | valid_rmsle: 0.0064  | valid_mae: 0.25101 | valid_rmse: 0.3186  | valid_mse: 0.1015  |  0:02:01s\n",
      "epoch 68 | loss: 0.09974 | train_rmsle: 0.00664 | train_mae: 0.24242 | train_rmse: 0.31613 | train_mse: 0.09994 | valid_rmsle: 0.0062  | valid_mae: 0.23929 | valid_rmse: 0.30984 | valid_mse: 0.096   |  0:02:02s\n",
      "epoch 69 | loss: 0.10004 | train_rmsle: 0.00659 | train_mae: 0.24162 | train_rmse: 0.3151  | train_mse: 0.09929 | valid_rmsle: 0.00613 | valid_mae: 0.2363  | valid_rmse: 0.30825 | valid_mse: 0.09502 |  0:02:04s\n",
      "epoch 70 | loss: 0.09911 | train_rmsle: 0.00662 | train_mae: 0.24394 | train_rmse: 0.31698 | train_mse: 0.10048 | valid_rmsle: 0.00612 | valid_mae: 0.23657 | valid_rmse: 0.30882 | valid_mse: 0.09537 |  0:02:06s\n",
      "epoch 71 | loss: 0.10025 | train_rmsle: 0.0072  | train_mae: 0.24515 | train_rmse: 0.32793 | train_mse: 0.10754 | valid_rmsle: 0.00687 | valid_mae: 0.24478 | valid_rmse: 0.32526 | valid_mse: 0.10579 |  0:02:08s\n",
      "epoch 72 | loss: 0.10075 | train_rmsle: 0.0066  | train_mae: 0.24081 | train_rmse: 0.31471 | train_mse: 0.09904 | valid_rmsle: 0.00619 | valid_mae: 0.23419 | valid_rmse: 0.30909 | valid_mse: 0.09554 |  0:02:09s\n",
      "epoch 73 | loss: 0.10028 | train_rmsle: 0.0066  | train_mae: 0.243   | train_rmse: 0.31626 | train_mse: 0.10002 | valid_rmsle: 0.00619 | valid_mae: 0.23574 | valid_rmse: 0.31037 | valid_mse: 0.09633 |  0:02:11s\n",
      "epoch 74 | loss: 0.10124 | train_rmsle: 0.00675 | train_mae: 0.25169 | train_rmse: 0.32222 | train_mse: 0.10382 | valid_rmsle: 0.00633 | valid_mae: 0.24509 | valid_rmse: 0.31605 | valid_mse: 0.09989 |  0:02:13s\n",
      "epoch 75 | loss: 0.09998 | train_rmsle: 0.00648 | train_mae: 0.24104 | train_rmse: 0.31347 | train_mse: 0.09826 | valid_rmsle: 0.00613 | valid_mae: 0.23532 | valid_rmse: 0.30885 | valid_mse: 0.09539 |  0:02:15s\n",
      "epoch 76 | loss: 0.09878 | train_rmsle: 0.0065  | train_mae: 0.24113 | train_rmse: 0.31342 | train_mse: 0.09823 | valid_rmsle: 0.00613 | valid_mae: 0.23496 | valid_rmse: 0.30859 | valid_mse: 0.09523 |  0:02:17s\n",
      "epoch 77 | loss: 0.09789 | train_rmsle: 0.00657 | train_mae: 0.24281 | train_rmse: 0.31496 | train_mse: 0.0992  | valid_rmsle: 0.00615 | valid_mae: 0.23573 | valid_rmse: 0.30846 | valid_mse: 0.09515 |  0:02:18s\n",
      "epoch 78 | loss: 0.09967 | train_rmsle: 0.00677 | train_mae: 0.25348 | train_rmse: 0.32295 | train_mse: 0.1043  | valid_rmsle: 0.00633 | valid_mae: 0.24541 | valid_rmse: 0.31617 | valid_mse: 0.09996 |  0:02:20s\n",
      "epoch 79 | loss: 0.09804 | train_rmsle: 0.00662 | train_mae: 0.24048 | train_rmse: 0.31496 | train_mse: 0.0992  | valid_rmsle: 0.00618 | valid_mae: 0.2352  | valid_rmse: 0.30894 | valid_mse: 0.09544 |  0:02:22s\n",
      "epoch 80 | loss: 0.09827 | train_rmsle: 0.00654 | train_mae: 0.24129 | train_rmse: 0.31393 | train_mse: 0.09855 | valid_rmsle: 0.00604 | valid_mae: 0.23427 | valid_rmse: 0.3057  | valid_mse: 0.09345 |  0:02:24s\n",
      "epoch 81 | loss: 0.09943 | train_rmsle: 0.00657 | train_mae: 0.24671 | train_rmse: 0.31663 | train_mse: 0.10026 | valid_rmsle: 0.0061  | valid_mae: 0.24009 | valid_rmse: 0.30897 | valid_mse: 0.09546 |  0:02:25s\n",
      "epoch 82 | loss: 0.09833 | train_rmsle: 0.00672 | train_mae: 0.25377 | train_rmse: 0.32235 | train_mse: 0.10391 | valid_rmsle: 0.00626 | valid_mae: 0.24664 | valid_rmse: 0.31522 | valid_mse: 0.09936 |  0:02:27s\n",
      "epoch 83 | loss: 0.09998 | train_rmsle: 0.00662 | train_mae: 0.23556 | train_rmse: 0.3134  | train_mse: 0.09822 | valid_rmsle: 0.00625 | valid_mae: 0.23436 | valid_rmse: 0.30966 | valid_mse: 0.09589 |  0:02:29s\n",
      "epoch 84 | loss: 0.09733 | train_rmsle: 0.0064  | train_mae: 0.23767 | train_rmse: 0.3105  | train_mse: 0.09641 | valid_rmsle: 0.00603 | valid_mae: 0.2335  | valid_rmse: 0.30542 | valid_mse: 0.09328 |  0:02:31s\n",
      "epoch 85 | loss: 0.09681 | train_rmsle: 0.00669 | train_mae: 0.25229 | train_rmse: 0.32123 | train_mse: 0.10319 | valid_rmsle: 0.00619 | valid_mae: 0.24448 | valid_rmse: 0.31281 | valid_mse: 0.09785 |  0:02:33s\n",
      "epoch 86 | loss: 0.10026 | train_rmsle: 0.00644 | train_mae: 0.23439 | train_rmse: 0.31014 | train_mse: 0.09619 | valid_rmsle: 0.00614 | valid_mae: 0.23375 | valid_rmse: 0.30791 | valid_mse: 0.09481 |  0:02:34s\n",
      "epoch 87 | loss: 0.09771 | train_rmsle: 0.00637 | train_mae: 0.2383  | train_rmse: 0.31008 | train_mse: 0.09615 | valid_rmsle: 0.006   | valid_mae: 0.23513 | valid_rmse: 0.30517 | valid_mse: 0.09313 |  0:02:36s\n",
      "epoch 88 | loss: 0.09887 | train_rmsle: 0.00644 | train_mae: 0.24045 | train_rmse: 0.31196 | train_mse: 0.09732 | valid_rmsle: 0.00605 | valid_mae: 0.23694 | valid_rmse: 0.30653 | valid_mse: 0.09396 |  0:02:38s\n",
      "epoch 89 | loss: 0.10003 | train_rmsle: 0.00644 | train_mae: 0.24312 | train_rmse: 0.31326 | train_mse: 0.09813 | valid_rmsle: 0.00603 | valid_mae: 0.2363  | valid_rmse: 0.30672 | valid_mse: 0.09408 |  0:02:40s\n",
      "epoch 90 | loss: 0.09928 | train_rmsle: 0.00644 | train_mae: 0.24239 | train_rmse: 0.31311 | train_mse: 0.09804 | valid_rmsle: 0.00611 | valid_mae: 0.23757 | valid_rmse: 0.30861 | valid_mse: 0.09524 |  0:02:41s\n",
      "epoch 91 | loss: 0.09694 | train_rmsle: 0.00652 | train_mae: 0.2473  | train_rmse: 0.31684 | train_mse: 0.10039 | valid_rmsle: 0.00615 | valid_mae: 0.2401  | valid_rmse: 0.31116 | valid_mse: 0.09682 |  0:02:43s\n",
      "epoch 92 | loss: 0.09653 | train_rmsle: 0.00641 | train_mae: 0.24259 | train_rmse: 0.31318 | train_mse: 0.09808 | valid_rmsle: 0.00603 | valid_mae: 0.23557 | valid_rmse: 0.30746 | valid_mse: 0.09453 |  0:02:45s\n",
      "epoch 93 | loss: 0.09607 | train_rmsle: 0.0064  | train_mae: 0.243   | train_rmse: 0.31286 | train_mse: 0.09788 | valid_rmsle: 0.00619 | valid_mae: 0.2406  | valid_rmse: 0.31157 | valid_mse: 0.09708 |  0:02:47s\n",
      "epoch 94 | loss: 0.09908 | train_rmsle: 0.00631 | train_mae: 0.23554 | train_rmse: 0.30872 | train_mse: 0.09531 | valid_rmsle: 0.00615 | valid_mae: 0.23366 | valid_rmse: 0.30873 | valid_mse: 0.09532 |  0:02:48s\n",
      "epoch 95 | loss: 0.09682 | train_rmsle: 0.00631 | train_mae: 0.23758 | train_rmse: 0.30916 | train_mse: 0.09558 | valid_rmsle: 0.00609 | valid_mae: 0.23521 | valid_rmse: 0.30772 | valid_mse: 0.09469 |  0:02:50s\n",
      "epoch 96 | loss: 0.09601 | train_rmsle: 0.00639 | train_mae: 0.23723 | train_rmse: 0.31005 | train_mse: 0.09613 | valid_rmsle: 0.00623 | valid_mae: 0.23741 | valid_rmse: 0.3108  | valid_mse: 0.0966  |  0:02:52s\n",
      "epoch 97 | loss: 0.09709 | train_rmsle: 0.00637 | train_mae: 0.2349  | train_rmse: 0.3087  | train_mse: 0.0953  | valid_rmsle: 0.00622 | valid_mae: 0.23544 | valid_rmse: 0.30995 | valid_mse: 0.09607 |  0:02:54s\n",
      "epoch 98 | loss: 0.09582 | train_rmsle: 0.00695 | train_mae: 0.26239 | train_rmse: 0.3304  | train_mse: 0.10917 | valid_rmsle: 0.00658 | valid_mae: 0.25566 | valid_rmse: 0.32454 | valid_mse: 0.10533 |  0:02:56s\n",
      "epoch 99 | loss: 0.09837 | train_rmsle: 0.00647 | train_mae: 0.23615 | train_rmse: 0.31129 | train_mse: 0.0969  | valid_rmsle: 0.00623 | valid_mae: 0.23486 | valid_rmse: 0.30977 | valid_mse: 0.09596 |  0:02:57s\n",
      "epoch 100| loss: 0.09987 | train_rmsle: 0.00628 | train_mae: 0.2367  | train_rmse: 0.30863 | train_mse: 0.09525 | valid_rmsle: 0.0059  | valid_mae: 0.23199 | valid_rmse: 0.30344 | valid_mse: 0.09207 |  0:02:59s\n",
      "epoch 101| loss: 0.09679 | train_rmsle: 0.00626 | train_mae: 0.2341  | train_rmse: 0.30696 | train_mse: 0.09423 | valid_rmsle: 0.00598 | valid_mae: 0.23337 | valid_rmse: 0.30456 | valid_mse: 0.09275 |  0:03:01s\n",
      "epoch 102| loss: 0.09957 | train_rmsle: 0.00633 | train_mae: 0.23255 | train_rmse: 0.30733 | train_mse: 0.09445 | valid_rmsle: 0.00612 | valid_mae: 0.23368 | valid_rmse: 0.30674 | valid_mse: 0.09409 |  0:03:03s\n",
      "epoch 103| loss: 0.09806 | train_rmsle: 0.00651 | train_mae: 0.24629 | train_rmse: 0.31615 | train_mse: 0.09995 | valid_rmsle: 0.00627 | valid_mae: 0.24385 | valid_rmse: 0.314   | valid_mse: 0.0986  |  0:03:04s\n",
      "epoch 104| loss: 0.09663 | train_rmsle: 0.0063  | train_mae: 0.23369 | train_rmse: 0.307   | train_mse: 0.09425 | valid_rmsle: 0.00605 | valid_mae: 0.23321 | valid_rmse: 0.30565 | valid_mse: 0.09342 |  0:03:06s\n",
      "epoch 105| loss: 0.09637 | train_rmsle: 0.00627 | train_mae: 0.23459 | train_rmse: 0.30686 | train_mse: 0.09416 | valid_rmsle: 0.00607 | valid_mae: 0.23493 | valid_rmse: 0.30684 | valid_mse: 0.09415 |  0:03:08s\n",
      "epoch 106| loss: 0.09572 | train_rmsle: 0.00624 | train_mae: 0.23679 | train_rmse: 0.30717 | train_mse: 0.09435 | valid_rmsle: 0.00593 | valid_mae: 0.23384 | valid_rmse: 0.30361 | valid_mse: 0.09218 |  0:03:10s\n",
      "epoch 107| loss: 0.09438 | train_rmsle: 0.00624 | train_mae: 0.23699 | train_rmse: 0.30716 | train_mse: 0.09435 | valid_rmsle: 0.00599 | valid_mae: 0.23612 | valid_rmse: 0.30547 | valid_mse: 0.09331 |  0:03:11s\n",
      "epoch 108| loss: 0.0943  | train_rmsle: 0.00629 | train_mae: 0.23526 | train_rmse: 0.30705 | train_mse: 0.09428 | valid_rmsle: 0.00602 | valid_mae: 0.23392 | valid_rmse: 0.30462 | valid_mse: 0.09279 |  0:03:13s\n",
      "epoch 109| loss: 0.09489 | train_rmsle: 0.00622 | train_mae: 0.23702 | train_rmse: 0.30693 | train_mse: 0.09421 | valid_rmsle: 0.00596 | valid_mae: 0.23684 | valid_rmse: 0.30469 | valid_mse: 0.09284 |  0:03:15s\n",
      "epoch 110| loss: 0.09491 | train_rmsle: 0.00623 | train_mae: 0.23614 | train_rmse: 0.30684 | train_mse: 0.09415 | valid_rmsle: 0.00611 | valid_mae: 0.23604 | valid_rmse: 0.30795 | valid_mse: 0.09483 |  0:03:17s\n",
      "epoch 111| loss: 0.09522 | train_rmsle: 0.00627 | train_mae: 0.24097 | train_rmse: 0.30947 | train_mse: 0.09577 | valid_rmsle: 0.00606 | valid_mae: 0.23866 | valid_rmse: 0.30824 | valid_mse: 0.09501 |  0:03:19s\n",
      "epoch 112| loss: 0.09596 | train_rmsle: 0.00617 | train_mae: 0.23373 | train_rmse: 0.30513 | train_mse: 0.0931  | valid_rmsle: 0.00599 | valid_mae: 0.23351 | valid_rmse: 0.30462 | valid_mse: 0.09279 |  0:03:20s\n",
      "epoch 113| loss: 0.09573 | train_rmsle: 0.00627 | train_mae: 0.23327 | train_rmse: 0.30654 | train_mse: 0.09397 | valid_rmsle: 0.00606 | valid_mae: 0.23245 | valid_rmse: 0.30614 | valid_mse: 0.09372 |  0:03:22s\n",
      "epoch 114| loss: 0.09513 | train_rmsle: 0.0062  | train_mae: 0.23183 | train_rmse: 0.30492 | train_mse: 0.09298 | valid_rmsle: 0.00603 | valid_mae: 0.23212 | valid_rmse: 0.30493 | valid_mse: 0.09298 |  0:03:24s\n",
      "epoch 115| loss: 0.0975  | train_rmsle: 0.00623 | train_mae: 0.24162 | train_rmse: 0.3097  | train_mse: 0.09591 | valid_rmsle: 0.00599 | valid_mae: 0.23785 | valid_rmse: 0.30691 | valid_mse: 0.09419 |  0:03:26s\n",
      "epoch 116| loss: 0.09463 | train_rmsle: 0.00616 | train_mae: 0.23308 | train_rmse: 0.30442 | train_mse: 0.09267 | valid_rmsle: 0.00604 | valid_mae: 0.23286 | valid_rmse: 0.30531 | valid_mse: 0.09321 |  0:03:28s\n",
      "epoch 117| loss: 0.09276 | train_rmsle: 0.00612 | train_mae: 0.23759 | train_rmse: 0.30603 | train_mse: 0.09366 | valid_rmsle: 0.00599 | valid_mae: 0.23638 | valid_rmse: 0.30648 | valid_mse: 0.09393 |  0:03:29s\n",
      "epoch 118| loss: 0.09911 | train_rmsle: 0.00624 | train_mae: 0.2415  | train_rmse: 0.30984 | train_mse: 0.096   | valid_rmsle: 0.00607 | valid_mae: 0.23972 | valid_rmse: 0.30896 | valid_mse: 0.09545 |  0:03:31s\n",
      "epoch 119| loss: 0.09322 | train_rmsle: 0.00606 | train_mae: 0.23443 | train_rmse: 0.30344 | train_mse: 0.09207 | valid_rmsle: 0.00597 | valid_mae: 0.23465 | valid_rmse: 0.30508 | valid_mse: 0.09308 |  0:03:33s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 100 and best_valid_mse = 0.09207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1011863916006707 RMSE: 0.31809808487425806 R2: 0.5520868333800246 MAE: 0.24316794364495786\n",
      "=====================================\n",
      "[71/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.58556 | train_rmsle: 0.47641 | train_mae: 2.12101 | train_rmse: 2.17582 | train_mse: 4.73417 | valid_rmsle: 0.47809 | valid_mae: 2.12734 | valid_rmse: 2.1808  | valid_mse: 4.75588 |  0:00:01s\n",
      "epoch 1  | loss: 2.3397  | train_rmsle: 0.12747 | train_mae: 1.24805 | train_rmse: 1.331   | train_mse: 1.77156 | valid_rmsle: 0.12817 | valid_mae: 1.25198 | valid_rmse: 1.33565 | valid_mse: 1.78397 |  0:00:03s\n",
      "epoch 2  | loss: 1.12693 | train_rmsle: 0.04271 | train_mae: 0.74476 | train_rmse: 0.83771 | train_mse: 0.70176 | valid_rmsle: 0.04282 | valid_mae: 0.74587 | valid_rmse: 0.84104 | valid_mse: 0.70735 |  0:00:05s\n",
      "epoch 3  | loss: 0.68481 | train_rmsle: 0.03856 | train_mae: 0.70806 | train_rmse: 0.79965 | train_mse: 0.63943 | valid_rmsle: 0.03876 | valid_mae: 0.71039 | valid_rmse: 0.80419 | valid_mse: 0.64673 |  0:00:07s\n",
      "epoch 4  | loss: 0.48549 | train_rmsle: 0.02893 | train_mae: 0.60994 | train_rmse: 0.7008  | train_mse: 0.49112 | valid_rmsle: 0.02884 | valid_mae: 0.61089 | valid_rmse: 0.70296 | valid_mse: 0.49415 |  0:00:09s\n",
      "epoch 5  | loss: 0.39529 | train_rmsle: 0.02431 | train_mae: 0.55532 | train_rmse: 0.64493 | train_mse: 0.41593 | valid_rmsle: 0.02412 | valid_mae: 0.55688 | valid_rmse: 0.6461  | valid_mse: 0.41744 |  0:00:10s\n",
      "epoch 6  | loss: 0.34371 | train_rmsle: 0.01967 | train_mae: 0.49216 | train_rmse: 0.57962 | train_mse: 0.33596 | valid_rmsle: 0.01937 | valid_mae: 0.49371 | valid_rmse: 0.57973 | valid_mse: 0.33609 |  0:00:12s\n",
      "epoch 7  | loss: 0.31357 | train_rmsle: 0.01747 | train_mae: 0.45625 | train_rmse: 0.54359 | train_mse: 0.29549 | valid_rmsle: 0.01706 | valid_mae: 0.45796 | valid_rmse: 0.54216 | valid_mse: 0.29393 |  0:00:14s\n",
      "epoch 8  | loss: 0.29123 | train_rmsle: 0.01718 | train_mae: 0.4523  | train_rmse: 0.53903 | train_mse: 0.29056 | valid_rmsle: 0.01679 | valid_mae: 0.4538  | valid_rmse: 0.53775 | valid_mse: 0.28917 |  0:00:16s\n",
      "epoch 9  | loss: 0.27053 | train_rmsle: 0.01634 | train_mae: 0.43559 | train_rmse: 0.52333 | train_mse: 0.27387 | valid_rmsle: 0.01597 | valid_mae: 0.43713 | valid_rmse: 0.52264 | valid_mse: 0.27315 |  0:00:17s\n",
      "epoch 10 | loss: 0.27103 | train_rmsle: 0.02057 | train_mae: 0.50655 | train_rmse: 0.59356 | train_mse: 0.35231 | valid_rmsle: 0.0203  | valid_mae: 0.5088  | valid_rmse: 0.59408 | valid_mse: 0.35293 |  0:00:19s\n",
      "epoch 11 | loss: 0.24806 | train_rmsle: 0.01002 | train_mae: 0.32105 | train_rmse: 0.40064 | train_mse: 0.16051 | valid_rmsle: 0.00894 | valid_mae: 0.30628 | valid_rmse: 0.38573 | valid_mse: 0.14878 |  0:00:21s\n",
      "epoch 12 | loss: 0.20274 | train_rmsle: 0.00948 | train_mae: 0.30345 | train_rmse: 0.38482 | train_mse: 0.14809 | valid_rmsle: 0.00862 | valid_mae: 0.29002 | valid_rmse: 0.37032 | valid_mse: 0.13714 |  0:00:23s\n",
      "epoch 13 | loss: 0.18758 | train_rmsle: 0.00873 | train_mae: 0.29047 | train_rmse: 0.36861 | train_mse: 0.13588 | valid_rmsle: 0.00782 | valid_mae: 0.27568 | valid_rmse: 0.35246 | valid_mse: 0.12422 |  0:00:25s\n",
      "epoch 14 | loss: 0.17264 | train_rmsle: 0.00872 | train_mae: 0.29127 | train_rmse: 0.36931 | train_mse: 0.13639 | valid_rmsle: 0.00772 | valid_mae: 0.27666 | valid_rmse: 0.35147 | valid_mse: 0.12353 |  0:00:26s\n",
      "epoch 15 | loss: 0.16545 | train_rmsle: 0.00824 | train_mae: 0.28596 | train_rmse: 0.3604  | train_mse: 0.12989 | valid_rmsle: 0.00779 | valid_mae: 0.27969 | valid_rmse: 0.35593 | valid_mse: 0.12668 |  0:00:28s\n",
      "epoch 16 | loss: 0.16878 | train_rmsle: 0.00756 | train_mae: 0.26995 | train_rmse: 0.34295 | train_mse: 0.11761 | valid_rmsle: 0.00684 | valid_mae: 0.25772 | valid_rmse: 0.33017 | valid_mse: 0.10901 |  0:00:30s\n",
      "epoch 17 | loss: 0.1556  | train_rmsle: 0.00741 | train_mae: 0.2619  | train_rmse: 0.33766 | train_mse: 0.11401 | valid_rmsle: 0.00675 | valid_mae: 0.25096 | valid_rmse: 0.32679 | valid_mse: 0.10679 |  0:00:32s\n",
      "epoch 18 | loss: 0.15617 | train_rmsle: 0.00898 | train_mae: 0.28937 | train_rmse: 0.37803 | train_mse: 0.14291 | valid_rmsle: 0.00843 | valid_mae: 0.29008 | valid_rmse: 0.37213 | valid_mse: 0.13848 |  0:00:34s\n",
      "epoch 19 | loss: 0.20371 | train_rmsle: 0.00775 | train_mae: 0.26106 | train_rmse: 0.34453 | train_mse: 0.1187  | valid_rmsle: 0.00708 | valid_mae: 0.25345 | valid_rmse: 0.33268 | valid_mse: 0.11068 |  0:00:35s\n",
      "epoch 20 | loss: 0.15289 | train_rmsle: 0.00833 | train_mae: 0.28819 | train_rmse: 0.36302 | train_mse: 0.13178 | valid_rmsle: 0.00761 | valid_mae: 0.27564 | valid_rmse: 0.35047 | valid_mse: 0.12283 |  0:00:37s\n",
      "epoch 21 | loss: 0.1453  | train_rmsle: 0.0085  | train_mae: 0.2946  | train_rmse: 0.36775 | train_mse: 0.13524 | valid_rmsle: 0.00786 | valid_mae: 0.285   | valid_rmse: 0.35767 | valid_mse: 0.12793 |  0:00:39s\n",
      "epoch 22 | loss: 0.13891 | train_rmsle: 0.00783 | train_mae: 0.26525 | train_rmse: 0.34765 | train_mse: 0.12086 | valid_rmsle: 0.00728 | valid_mae: 0.25808 | valid_rmse: 0.34002 | valid_mse: 0.11562 |  0:00:41s\n",
      "epoch 23 | loss: 0.14962 | train_rmsle: 0.01053 | train_mae: 0.33916 | train_rmse: 0.414   | train_mse: 0.17139 | valid_rmsle: 0.01006 | valid_mae: 0.33269 | valid_rmse: 0.4083  | valid_mse: 0.16671 |  0:00:42s\n",
      "epoch 24 | loss: 0.15513 | train_rmsle: 0.01153 | train_mae: 0.36436 | train_rmse: 0.43598 | train_mse: 0.19008 | valid_rmsle: 0.01096 | valid_mae: 0.35748 | valid_rmse: 0.42808 | valid_mse: 0.18326 |  0:00:44s\n",
      "epoch 25 | loss: 0.17048 | train_rmsle: 0.00779 | train_mae: 0.26893 | train_rmse: 0.34748 | train_mse: 0.12074 | valid_rmsle: 0.00699 | valid_mae: 0.25571 | valid_rmse: 0.33316 | valid_mse: 0.11099 |  0:00:46s\n",
      "epoch 26 | loss: 0.13098 | train_rmsle: 0.00745 | train_mae: 0.25789 | train_rmse: 0.33765 | train_mse: 0.11401 | valid_rmsle: 0.007   | valid_mae: 0.24773 | valid_rmse: 0.33059 | valid_mse: 0.10929 |  0:00:48s\n",
      "epoch 27 | loss: 0.13574 | train_rmsle: 0.00842 | train_mae: 0.28854 | train_rmse: 0.36448 | train_mse: 0.13284 | valid_rmsle: 0.00772 | valid_mae: 0.27772 | valid_rmse: 0.35242 | valid_mse: 0.1242  |  0:00:50s\n",
      "epoch 28 | loss: 0.16869 | train_rmsle: 0.01038 | train_mae: 0.33994 | train_rmse: 0.41125 | train_mse: 0.16912 | valid_rmsle: 0.00981 | valid_mae: 0.33141 | valid_rmse: 0.40299 | valid_mse: 0.1624  |  0:00:51s\n",
      "epoch 29 | loss: 0.28532 | train_rmsle: 0.00994 | train_mae: 0.29904 | train_rmse: 0.39743 | train_mse: 0.15795 | valid_rmsle: 0.00949 | valid_mae: 0.29922 | valid_rmse: 0.39234 | valid_mse: 0.15393 |  0:00:53s\n",
      "epoch 30 | loss: 0.20346 | train_rmsle: 0.00744 | train_mae: 0.2558  | train_rmse: 0.33785 | train_mse: 0.11414 | valid_rmsle: 0.00679 | valid_mae: 0.24539 | valid_rmse: 0.32523 | valid_mse: 0.10577 |  0:00:55s\n",
      "epoch 31 | loss: 0.13057 | train_rmsle: 0.0078  | train_mae: 0.27268 | train_rmse: 0.34934 | train_mse: 0.12204 | valid_rmsle: 0.00693 | valid_mae: 0.25932 | valid_rmse: 0.3327  | valid_mse: 0.11069 |  0:00:57s\n",
      "epoch 32 | loss: 0.15595 | train_rmsle: 0.00848 | train_mae: 0.29361 | train_rmse: 0.36708 | train_mse: 0.13475 | valid_rmsle: 0.00776 | valid_mae: 0.28051 | valid_rmse: 0.35415 | valid_mse: 0.12542 |  0:00:58s\n",
      "epoch 33 | loss: 0.12074 | train_rmsle: 0.00935 | train_mae: 0.31229 | train_rmse: 0.38681 | train_mse: 0.14962 | valid_rmsle: 0.00866 | valid_mae: 0.30008 | valid_rmse: 0.37612 | valid_mse: 0.14147 |  0:01:00s\n",
      "epoch 34 | loss: 0.12541 | train_rmsle: 0.00862 | train_mae: 0.30029 | train_rmse: 0.37157 | train_mse: 0.13807 | valid_rmsle: 0.00807 | valid_mae: 0.29181 | valid_rmse: 0.3631  | valid_mse: 0.13184 |  0:01:02s\n",
      "epoch 35 | loss: 0.14115 | train_rmsle: 0.0087  | train_mae: 0.30299 | train_rmse: 0.37379 | train_mse: 0.13972 | valid_rmsle: 0.00835 | valid_mae: 0.29858 | valid_rmse: 0.37049 | valid_mse: 0.13727 |  0:01:04s\n",
      "epoch 36 | loss: 0.12238 | train_rmsle: 0.00722 | train_mae: 0.25161 | train_rmse: 0.33076 | train_mse: 0.1094  | valid_rmsle: 0.00669 | valid_mae: 0.24345 | valid_rmse: 0.3229  | valid_mse: 0.10427 |  0:01:05s\n",
      "epoch 37 | loss: 0.118   | train_rmsle: 0.00793 | train_mae: 0.27838 | train_rmse: 0.35251 | train_mse: 0.12426 | valid_rmsle: 0.00757 | valid_mae: 0.26996 | valid_rmse: 0.34735 | valid_mse: 0.12065 |  0:01:07s\n",
      "epoch 38 | loss: 0.12132 | train_rmsle: 0.00752 | train_mae: 0.26873 | train_rmse: 0.34246 | train_mse: 0.11728 | valid_rmsle: 0.00685 | valid_mae: 0.25788 | valid_rmse: 0.33122 | valid_mse: 0.1097  |  0:01:09s\n",
      "epoch 39 | loss: 0.11361 | train_rmsle: 0.00726 | train_mae: 0.25944 | train_rmse: 0.3343  | train_mse: 0.11175 | valid_rmsle: 0.00688 | valid_mae: 0.2537  | valid_rmse: 0.33048 | valid_mse: 0.10922 |  0:01:11s\n",
      "epoch 40 | loss: 0.11525 | train_rmsle: 0.00806 | train_mae: 0.28277 | train_rmse: 0.35654 | train_mse: 0.12712 | valid_rmsle: 0.00739 | valid_mae: 0.27398 | valid_rmse: 0.34611 | valid_mse: 0.1198  |  0:01:12s\n",
      "epoch 41 | loss: 0.11394 | train_rmsle: 0.00725 | train_mae: 0.25599 | train_rmse: 0.33356 | train_mse: 0.11126 | valid_rmsle: 0.0068  | valid_mae: 0.2501  | valid_rmse: 0.32713 | valid_mse: 0.10701 |  0:01:14s\n",
      "epoch 42 | loss: 0.11421 | train_rmsle: 0.00762 | train_mae: 0.26591 | train_rmse: 0.34356 | train_mse: 0.11803 | valid_rmsle: 0.007   | valid_mae: 0.25804 | valid_rmse: 0.33483 | valid_mse: 0.11211 |  0:01:16s\n",
      "epoch 43 | loss: 0.11782 | train_rmsle: 0.00727 | train_mae: 0.26124 | train_rmse: 0.33522 | train_mse: 0.11237 | valid_rmsle: 0.0071  | valid_mae: 0.25878 | valid_rmse: 0.33648 | valid_mse: 0.11322 |  0:01:18s\n",
      "epoch 44 | loss: 0.10998 | train_rmsle: 0.00723 | train_mae: 0.25301 | train_rmse: 0.33245 | train_mse: 0.11052 | valid_rmsle: 0.00663 | valid_mae: 0.2454  | valid_rmse: 0.32305 | valid_mse: 0.10436 |  0:01:20s\n",
      "epoch 45 | loss: 0.11091 | train_rmsle: 0.00706 | train_mae: 0.25196 | train_rmse: 0.32846 | train_mse: 0.10789 | valid_rmsle: 0.00677 | valid_mae: 0.24868 | valid_rmse: 0.32731 | valid_mse: 0.10713 |  0:01:21s\n",
      "epoch 46 | loss: 0.10807 | train_rmsle: 0.00694 | train_mae: 0.2474  | train_rmse: 0.32435 | train_mse: 0.1052  | valid_rmsle: 0.00655 | valid_mae: 0.24186 | valid_rmse: 0.31987 | valid_mse: 0.10232 |  0:01:23s\n",
      "epoch 47 | loss: 0.11175 | train_rmsle: 0.008   | train_mae: 0.28228 | train_rmse: 0.3551  | train_mse: 0.12609 | valid_rmsle: 0.00741 | valid_mae: 0.27314 | valid_rmse: 0.3455  | valid_mse: 0.11937 |  0:01:25s\n",
      "epoch 48 | loss: 0.10851 | train_rmsle: 0.00686 | train_mae: 0.24567 | train_rmse: 0.32267 | train_mse: 0.10412 | valid_rmsle: 0.0063  | valid_mae: 0.23783 | valid_rmse: 0.3128  | valid_mse: 0.09784 |  0:01:27s\n",
      "epoch 49 | loss: 0.10691 | train_rmsle: 0.00726 | train_mae: 0.26429 | train_rmse: 0.33565 | train_mse: 0.11266 | valid_rmsle: 0.00673 | valid_mae: 0.25537 | valid_rmse: 0.32692 | valid_mse: 0.10688 |  0:01:28s\n",
      "epoch 50 | loss: 0.10578 | train_rmsle: 0.00699 | train_mae: 0.25493 | train_rmse: 0.32724 | train_mse: 0.10709 | valid_rmsle: 0.00644 | valid_mae: 0.24584 | valid_rmse: 0.3176  | valid_mse: 0.10087 |  0:01:30s\n",
      "epoch 51 | loss: 0.11104 | train_rmsle: 0.00714 | train_mae: 0.24747 | train_rmse: 0.32856 | train_mse: 0.10795 | valid_rmsle: 0.00677 | valid_mae: 0.24483 | valid_rmse: 0.3244  | valid_mse: 0.10524 |  0:01:32s\n",
      "epoch 52 | loss: 0.10615 | train_rmsle: 0.00678 | train_mae: 0.2447  | train_rmse: 0.32047 | train_mse: 0.1027  | valid_rmsle: 0.00637 | valid_mae: 0.23742 | valid_rmse: 0.31441 | valid_mse: 0.09886 |  0:01:34s\n",
      "epoch 53 | loss: 0.10524 | train_rmsle: 0.00682 | train_mae: 0.2474  | train_rmse: 0.32216 | train_mse: 0.10379 | valid_rmsle: 0.00625 | valid_mae: 0.23757 | valid_rmse: 0.31253 | valid_mse: 0.09768 |  0:01:36s\n",
      "epoch 54 | loss: 0.10326 | train_rmsle: 0.00701 | train_mae: 0.25511 | train_rmse: 0.32822 | train_mse: 0.10773 | valid_rmsle: 0.00652 | valid_mae: 0.244   | valid_rmse: 0.31909 | valid_mse: 0.10182 |  0:01:37s\n",
      "epoch 55 | loss: 0.10297 | train_rmsle: 0.00681 | train_mae: 0.24953 | train_rmse: 0.3222  | train_mse: 0.10381 | valid_rmsle: 0.00629 | valid_mae: 0.24172 | valid_rmse: 0.31418 | valid_mse: 0.09871 |  0:01:39s\n",
      "epoch 56 | loss: 0.10153 | train_rmsle: 0.00667 | train_mae: 0.24368 | train_rmse: 0.31789 | train_mse: 0.10105 | valid_rmsle: 0.00612 | valid_mae: 0.2327  | valid_rmse: 0.30744 | valid_mse: 0.09452 |  0:01:41s\n",
      "epoch 57 | loss: 0.10506 | train_rmsle: 0.00745 | train_mae: 0.27222 | train_rmse: 0.34189 | train_mse: 0.11689 | valid_rmsle: 0.00676 | valid_mae: 0.25947 | valid_rmse: 0.32906 | valid_mse: 0.10828 |  0:01:43s\n",
      "epoch 58 | loss: 0.10172 | train_rmsle: 0.00678 | train_mae: 0.24918 | train_rmse: 0.32168 | train_mse: 0.10348 | valid_rmsle: 0.00624 | valid_mae: 0.23946 | valid_rmse: 0.31204 | valid_mse: 0.09737 |  0:01:45s\n",
      "epoch 59 | loss: 0.10102 | train_rmsle: 0.00671 | train_mae: 0.24416 | train_rmse: 0.31808 | train_mse: 0.10118 | valid_rmsle: 0.00622 | valid_mae: 0.23565 | valid_rmse: 0.31055 | valid_mse: 0.09644 |  0:01:46s\n",
      "epoch 60 | loss: 0.10349 | train_rmsle: 0.00666 | train_mae: 0.24104 | train_rmse: 0.31595 | train_mse: 0.09982 | valid_rmsle: 0.00618 | valid_mae: 0.23447 | valid_rmse: 0.30858 | valid_mse: 0.09522 |  0:01:48s\n",
      "epoch 61 | loss: 0.10428 | train_rmsle: 0.00671 | train_mae: 0.24772 | train_rmse: 0.31939 | train_mse: 0.10201 | valid_rmsle: 0.00618 | valid_mae: 0.23907 | valid_rmse: 0.3105  | valid_mse: 0.09641 |  0:01:50s\n",
      "epoch 62 | loss: 0.10216 | train_rmsle: 0.00671 | train_mae: 0.24883 | train_rmse: 0.32012 | train_mse: 0.10248 | valid_rmsle: 0.00629 | valid_mae: 0.2427  | valid_rmse: 0.3145  | valid_mse: 0.09891 |  0:01:52s\n",
      "epoch 63 | loss: 0.10123 | train_rmsle: 0.00659 | train_mae: 0.23998 | train_rmse: 0.31442 | train_mse: 0.09886 | valid_rmsle: 0.00612 | valid_mae: 0.23277 | valid_rmse: 0.3073  | valid_mse: 0.09443 |  0:01:53s\n",
      "epoch 64 | loss: 0.10327 | train_rmsle: 0.00668 | train_mae: 0.2481  | train_rmse: 0.31898 | train_mse: 0.10175 | valid_rmsle: 0.00615 | valid_mae: 0.23947 | valid_rmse: 0.30989 | valid_mse: 0.09603 |  0:01:55s\n",
      "epoch 65 | loss: 0.10271 | train_rmsle: 0.00657 | train_mae: 0.23978 | train_rmse: 0.31393 | train_mse: 0.09855 | valid_rmsle: 0.00618 | valid_mae: 0.23318 | valid_rmse: 0.30856 | valid_mse: 0.09521 |  0:01:57s\n",
      "epoch 66 | loss: 0.10104 | train_rmsle: 0.00664 | train_mae: 0.23926 | train_rmse: 0.31552 | train_mse: 0.09955 | valid_rmsle: 0.00626 | valid_mae: 0.23451 | valid_rmse: 0.3107  | valid_mse: 0.09654 |  0:01:59s\n",
      "epoch 67 | loss: 0.10053 | train_rmsle: 0.0069  | train_mae: 0.25796 | train_rmse: 0.32694 | train_mse: 0.10689 | valid_rmsle: 0.0064  | valid_mae: 0.25101 | valid_rmse: 0.3186  | valid_mse: 0.1015  |  0:02:01s\n",
      "epoch 68 | loss: 0.09974 | train_rmsle: 0.00664 | train_mae: 0.24242 | train_rmse: 0.31613 | train_mse: 0.09994 | valid_rmsle: 0.0062  | valid_mae: 0.23929 | valid_rmse: 0.30984 | valid_mse: 0.096   |  0:02:02s\n",
      "epoch 69 | loss: 0.10004 | train_rmsle: 0.00659 | train_mae: 0.24162 | train_rmse: 0.3151  | train_mse: 0.09929 | valid_rmsle: 0.00613 | valid_mae: 0.2363  | valid_rmse: 0.30825 | valid_mse: 0.09502 |  0:02:04s\n",
      "epoch 70 | loss: 0.09911 | train_rmsle: 0.00662 | train_mae: 0.24394 | train_rmse: 0.31698 | train_mse: 0.10048 | valid_rmsle: 0.00612 | valid_mae: 0.23657 | valid_rmse: 0.30882 | valid_mse: 0.09537 |  0:02:06s\n",
      "epoch 71 | loss: 0.10025 | train_rmsle: 0.0072  | train_mae: 0.24515 | train_rmse: 0.32793 | train_mse: 0.10754 | valid_rmsle: 0.00687 | valid_mae: 0.24478 | valid_rmse: 0.32526 | valid_mse: 0.10579 |  0:02:08s\n",
      "epoch 72 | loss: 0.10075 | train_rmsle: 0.0066  | train_mae: 0.24081 | train_rmse: 0.31471 | train_mse: 0.09904 | valid_rmsle: 0.00619 | valid_mae: 0.23419 | valid_rmse: 0.30909 | valid_mse: 0.09554 |  0:02:10s\n",
      "epoch 73 | loss: 0.10028 | train_rmsle: 0.0066  | train_mae: 0.243   | train_rmse: 0.31626 | train_mse: 0.10002 | valid_rmsle: 0.00619 | valid_mae: 0.23574 | valid_rmse: 0.31037 | valid_mse: 0.09633 |  0:02:11s\n",
      "epoch 74 | loss: 0.10124 | train_rmsle: 0.00675 | train_mae: 0.25169 | train_rmse: 0.32222 | train_mse: 0.10382 | valid_rmsle: 0.00633 | valid_mae: 0.24509 | valid_rmse: 0.31605 | valid_mse: 0.09989 |  0:02:13s\n",
      "epoch 75 | loss: 0.09998 | train_rmsle: 0.00648 | train_mae: 0.24104 | train_rmse: 0.31347 | train_mse: 0.09826 | valid_rmsle: 0.00613 | valid_mae: 0.23532 | valid_rmse: 0.30885 | valid_mse: 0.09539 |  0:02:15s\n",
      "epoch 76 | loss: 0.09878 | train_rmsle: 0.0065  | train_mae: 0.24113 | train_rmse: 0.31342 | train_mse: 0.09823 | valid_rmsle: 0.00613 | valid_mae: 0.23496 | valid_rmse: 0.30859 | valid_mse: 0.09523 |  0:02:17s\n",
      "epoch 77 | loss: 0.09789 | train_rmsle: 0.00657 | train_mae: 0.24281 | train_rmse: 0.31496 | train_mse: 0.0992  | valid_rmsle: 0.00615 | valid_mae: 0.23573 | valid_rmse: 0.30846 | valid_mse: 0.09515 |  0:02:18s\n",
      "epoch 78 | loss: 0.09967 | train_rmsle: 0.00677 | train_mae: 0.25348 | train_rmse: 0.32295 | train_mse: 0.1043  | valid_rmsle: 0.00633 | valid_mae: 0.24541 | valid_rmse: 0.31617 | valid_mse: 0.09996 |  0:02:20s\n",
      "epoch 79 | loss: 0.09804 | train_rmsle: 0.00662 | train_mae: 0.24048 | train_rmse: 0.31496 | train_mse: 0.0992  | valid_rmsle: 0.00618 | valid_mae: 0.2352  | valid_rmse: 0.30894 | valid_mse: 0.09544 |  0:02:22s\n",
      "epoch 80 | loss: 0.09827 | train_rmsle: 0.00654 | train_mae: 0.24129 | train_rmse: 0.31393 | train_mse: 0.09855 | valid_rmsle: 0.00604 | valid_mae: 0.23427 | valid_rmse: 0.3057  | valid_mse: 0.09345 |  0:02:24s\n",
      "epoch 81 | loss: 0.09943 | train_rmsle: 0.00657 | train_mae: 0.24671 | train_rmse: 0.31663 | train_mse: 0.10026 | valid_rmsle: 0.0061  | valid_mae: 0.24009 | valid_rmse: 0.30897 | valid_mse: 0.09546 |  0:02:25s\n",
      "epoch 82 | loss: 0.09833 | train_rmsle: 0.00672 | train_mae: 0.25377 | train_rmse: 0.32235 | train_mse: 0.10391 | valid_rmsle: 0.00626 | valid_mae: 0.24664 | valid_rmse: 0.31522 | valid_mse: 0.09936 |  0:02:27s\n",
      "epoch 83 | loss: 0.09998 | train_rmsle: 0.00662 | train_mae: 0.23556 | train_rmse: 0.3134  | train_mse: 0.09822 | valid_rmsle: 0.00625 | valid_mae: 0.23436 | valid_rmse: 0.30966 | valid_mse: 0.09589 |  0:02:29s\n",
      "epoch 84 | loss: 0.09733 | train_rmsle: 0.0064  | train_mae: 0.23767 | train_rmse: 0.3105  | train_mse: 0.09641 | valid_rmsle: 0.00603 | valid_mae: 0.2335  | valid_rmse: 0.30542 | valid_mse: 0.09328 |  0:02:31s\n",
      "epoch 85 | loss: 0.09681 | train_rmsle: 0.00669 | train_mae: 0.25229 | train_rmse: 0.32123 | train_mse: 0.10319 | valid_rmsle: 0.00619 | valid_mae: 0.24448 | valid_rmse: 0.31281 | valid_mse: 0.09785 |  0:02:33s\n",
      "epoch 86 | loss: 0.10026 | train_rmsle: 0.00644 | train_mae: 0.23439 | train_rmse: 0.31014 | train_mse: 0.09619 | valid_rmsle: 0.00614 | valid_mae: 0.23375 | valid_rmse: 0.30791 | valid_mse: 0.09481 |  0:02:34s\n",
      "epoch 87 | loss: 0.09771 | train_rmsle: 0.00637 | train_mae: 0.2383  | train_rmse: 0.31008 | train_mse: 0.09615 | valid_rmsle: 0.006   | valid_mae: 0.23513 | valid_rmse: 0.30517 | valid_mse: 0.09313 |  0:02:36s\n",
      "epoch 88 | loss: 0.09887 | train_rmsle: 0.00644 | train_mae: 0.24045 | train_rmse: 0.31196 | train_mse: 0.09732 | valid_rmsle: 0.00605 | valid_mae: 0.23694 | valid_rmse: 0.30653 | valid_mse: 0.09396 |  0:02:38s\n",
      "epoch 89 | loss: 0.10003 | train_rmsle: 0.00644 | train_mae: 0.24312 | train_rmse: 0.31326 | train_mse: 0.09813 | valid_rmsle: 0.00603 | valid_mae: 0.2363  | valid_rmse: 0.30672 | valid_mse: 0.09408 |  0:02:40s\n",
      "epoch 90 | loss: 0.09928 | train_rmsle: 0.00644 | train_mae: 0.24239 | train_rmse: 0.31311 | train_mse: 0.09804 | valid_rmsle: 0.00611 | valid_mae: 0.23757 | valid_rmse: 0.30861 | valid_mse: 0.09524 |  0:02:42s\n",
      "epoch 91 | loss: 0.09694 | train_rmsle: 0.00652 | train_mae: 0.2473  | train_rmse: 0.31684 | train_mse: 0.10039 | valid_rmsle: 0.00615 | valid_mae: 0.2401  | valid_rmse: 0.31116 | valid_mse: 0.09682 |  0:02:43s\n",
      "epoch 92 | loss: 0.09653 | train_rmsle: 0.00641 | train_mae: 0.24259 | train_rmse: 0.31318 | train_mse: 0.09808 | valid_rmsle: 0.00603 | valid_mae: 0.23557 | valid_rmse: 0.30746 | valid_mse: 0.09453 |  0:02:45s\n",
      "epoch 93 | loss: 0.09607 | train_rmsle: 0.0064  | train_mae: 0.243   | train_rmse: 0.31286 | train_mse: 0.09788 | valid_rmsle: 0.00619 | valid_mae: 0.2406  | valid_rmse: 0.31157 | valid_mse: 0.09708 |  0:02:47s\n",
      "epoch 94 | loss: 0.09908 | train_rmsle: 0.00631 | train_mae: 0.23554 | train_rmse: 0.30872 | train_mse: 0.09531 | valid_rmsle: 0.00615 | valid_mae: 0.23366 | valid_rmse: 0.30873 | valid_mse: 0.09532 |  0:02:49s\n",
      "epoch 95 | loss: 0.09682 | train_rmsle: 0.00631 | train_mae: 0.23758 | train_rmse: 0.30916 | train_mse: 0.09558 | valid_rmsle: 0.00609 | valid_mae: 0.23521 | valid_rmse: 0.30772 | valid_mse: 0.09469 |  0:02:50s\n",
      "epoch 96 | loss: 0.09601 | train_rmsle: 0.00639 | train_mae: 0.23723 | train_rmse: 0.31005 | train_mse: 0.09613 | valid_rmsle: 0.00623 | valid_mae: 0.23741 | valid_rmse: 0.3108  | valid_mse: 0.0966  |  0:02:52s\n",
      "epoch 97 | loss: 0.09709 | train_rmsle: 0.00637 | train_mae: 0.2349  | train_rmse: 0.3087  | train_mse: 0.0953  | valid_rmsle: 0.00622 | valid_mae: 0.23544 | valid_rmse: 0.30995 | valid_mse: 0.09607 |  0:02:54s\n",
      "epoch 98 | loss: 0.09582 | train_rmsle: 0.00695 | train_mae: 0.26239 | train_rmse: 0.3304  | train_mse: 0.10917 | valid_rmsle: 0.00658 | valid_mae: 0.25566 | valid_rmse: 0.32454 | valid_mse: 0.10533 |  0:02:56s\n",
      "epoch 99 | loss: 0.09837 | train_rmsle: 0.00647 | train_mae: 0.23615 | train_rmse: 0.31129 | train_mse: 0.0969  | valid_rmsle: 0.00623 | valid_mae: 0.23486 | valid_rmse: 0.30977 | valid_mse: 0.09596 |  0:02:57s\n",
      "epoch 100| loss: 0.09987 | train_rmsle: 0.00628 | train_mae: 0.2367  | train_rmse: 0.30863 | train_mse: 0.09525 | valid_rmsle: 0.0059  | valid_mae: 0.23199 | valid_rmse: 0.30344 | valid_mse: 0.09207 |  0:02:59s\n",
      "epoch 101| loss: 0.09679 | train_rmsle: 0.00626 | train_mae: 0.2341  | train_rmse: 0.30696 | train_mse: 0.09423 | valid_rmsle: 0.00598 | valid_mae: 0.23337 | valid_rmse: 0.30456 | valid_mse: 0.09275 |  0:03:01s\n",
      "epoch 102| loss: 0.09957 | train_rmsle: 0.00633 | train_mae: 0.23255 | train_rmse: 0.30733 | train_mse: 0.09445 | valid_rmsle: 0.00612 | valid_mae: 0.23368 | valid_rmse: 0.30674 | valid_mse: 0.09409 |  0:03:03s\n",
      "epoch 103| loss: 0.09806 | train_rmsle: 0.00651 | train_mae: 0.24629 | train_rmse: 0.31615 | train_mse: 0.09995 | valid_rmsle: 0.00627 | valid_mae: 0.24385 | valid_rmse: 0.314   | valid_mse: 0.0986  |  0:03:05s\n",
      "epoch 104| loss: 0.09663 | train_rmsle: 0.0063  | train_mae: 0.23369 | train_rmse: 0.307   | train_mse: 0.09425 | valid_rmsle: 0.00605 | valid_mae: 0.23321 | valid_rmse: 0.30565 | valid_mse: 0.09342 |  0:03:06s\n",
      "epoch 105| loss: 0.09637 | train_rmsle: 0.00627 | train_mae: 0.23459 | train_rmse: 0.30686 | train_mse: 0.09416 | valid_rmsle: 0.00607 | valid_mae: 0.23493 | valid_rmse: 0.30684 | valid_mse: 0.09415 |  0:03:08s\n",
      "epoch 106| loss: 0.09572 | train_rmsle: 0.00624 | train_mae: 0.23679 | train_rmse: 0.30717 | train_mse: 0.09435 | valid_rmsle: 0.00593 | valid_mae: 0.23384 | valid_rmse: 0.30361 | valid_mse: 0.09218 |  0:03:10s\n",
      "epoch 107| loss: 0.09438 | train_rmsle: 0.00624 | train_mae: 0.23699 | train_rmse: 0.30716 | train_mse: 0.09435 | valid_rmsle: 0.00599 | valid_mae: 0.23612 | valid_rmse: 0.30547 | valid_mse: 0.09331 |  0:03:12s\n",
      "epoch 108| loss: 0.0943  | train_rmsle: 0.00629 | train_mae: 0.23526 | train_rmse: 0.30705 | train_mse: 0.09428 | valid_rmsle: 0.00602 | valid_mae: 0.23392 | valid_rmse: 0.30462 | valid_mse: 0.09279 |  0:03:13s\n",
      "epoch 109| loss: 0.09489 | train_rmsle: 0.00622 | train_mae: 0.23702 | train_rmse: 0.30693 | train_mse: 0.09421 | valid_rmsle: 0.00596 | valid_mae: 0.23684 | valid_rmse: 0.30469 | valid_mse: 0.09284 |  0:03:15s\n",
      "epoch 110| loss: 0.09491 | train_rmsle: 0.00623 | train_mae: 0.23614 | train_rmse: 0.30684 | train_mse: 0.09415 | valid_rmsle: 0.00611 | valid_mae: 0.23604 | valid_rmse: 0.30795 | valid_mse: 0.09483 |  0:03:17s\n",
      "epoch 111| loss: 0.09522 | train_rmsle: 0.00627 | train_mae: 0.24097 | train_rmse: 0.30947 | train_mse: 0.09577 | valid_rmsle: 0.00606 | valid_mae: 0.23866 | valid_rmse: 0.30824 | valid_mse: 0.09501 |  0:03:19s\n",
      "epoch 112| loss: 0.09596 | train_rmsle: 0.00617 | train_mae: 0.23373 | train_rmse: 0.30513 | train_mse: 0.0931  | valid_rmsle: 0.00599 | valid_mae: 0.23351 | valid_rmse: 0.30462 | valid_mse: 0.09279 |  0:03:21s\n",
      "epoch 113| loss: 0.09573 | train_rmsle: 0.00627 | train_mae: 0.23327 | train_rmse: 0.30654 | train_mse: 0.09397 | valid_rmsle: 0.00606 | valid_mae: 0.23245 | valid_rmse: 0.30614 | valid_mse: 0.09372 |  0:03:22s\n",
      "epoch 114| loss: 0.09513 | train_rmsle: 0.0062  | train_mae: 0.23183 | train_rmse: 0.30492 | train_mse: 0.09298 | valid_rmsle: 0.00603 | valid_mae: 0.23212 | valid_rmse: 0.30493 | valid_mse: 0.09298 |  0:03:24s\n",
      "epoch 115| loss: 0.0975  | train_rmsle: 0.00623 | train_mae: 0.24162 | train_rmse: 0.3097  | train_mse: 0.09591 | valid_rmsle: 0.00599 | valid_mae: 0.23785 | valid_rmse: 0.30691 | valid_mse: 0.09419 |  0:03:26s\n",
      "epoch 116| loss: 0.09463 | train_rmsle: 0.00616 | train_mae: 0.23308 | train_rmse: 0.30442 | train_mse: 0.09267 | valid_rmsle: 0.00604 | valid_mae: 0.23286 | valid_rmse: 0.30531 | valid_mse: 0.09321 |  0:03:28s\n",
      "epoch 117| loss: 0.09276 | train_rmsle: 0.00612 | train_mae: 0.23759 | train_rmse: 0.30603 | train_mse: 0.09366 | valid_rmsle: 0.00599 | valid_mae: 0.23638 | valid_rmse: 0.30648 | valid_mse: 0.09393 |  0:03:29s\n",
      "epoch 118| loss: 0.09911 | train_rmsle: 0.00624 | train_mae: 0.2415  | train_rmse: 0.30984 | train_mse: 0.096   | valid_rmsle: 0.00607 | valid_mae: 0.23972 | valid_rmse: 0.30896 | valid_mse: 0.09545 |  0:03:31s\n",
      "epoch 119| loss: 0.09322 | train_rmsle: 0.00606 | train_mae: 0.23443 | train_rmse: 0.30344 | train_mse: 0.09207 | valid_rmsle: 0.00597 | valid_mae: 0.23465 | valid_rmse: 0.30508 | valid_mse: 0.09308 |  0:03:33s\n",
      "epoch 120| loss: 0.09382 | train_rmsle: 0.00597 | train_mae: 0.2307  | train_rmse: 0.30067 | train_mse: 0.0904  | valid_rmsle: 0.00594 | valid_mae: 0.23254 | valid_rmse: 0.30364 | valid_mse: 0.09219 |  0:03:35s\n",
      "\n",
      "Early stopping occurred at epoch 120 with best_epoch = 100 and best_valid_mse = 0.09207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1011863916006707 RMSE: 0.31809808487425806 R2: 0.5520868333800246 MAE: 0.24316794364495786\n",
      "=====================================\n",
      "[72/108] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.58556 | train_rmsle: 0.47641 | train_mae: 2.12101 | train_rmse: 2.17582 | train_mse: 4.73417 | valid_rmsle: 0.47809 | valid_mae: 2.12734 | valid_rmse: 2.1808  | valid_mse: 4.75588 |  0:00:02s\n",
      "epoch 1  | loss: 2.3397  | train_rmsle: 0.12747 | train_mae: 1.24805 | train_rmse: 1.331   | train_mse: 1.77156 | valid_rmsle: 0.12817 | valid_mae: 1.25198 | valid_rmse: 1.33565 | valid_mse: 1.78397 |  0:00:03s\n",
      "epoch 2  | loss: 1.12693 | train_rmsle: 0.04271 | train_mae: 0.74476 | train_rmse: 0.83771 | train_mse: 0.70176 | valid_rmsle: 0.04282 | valid_mae: 0.74587 | valid_rmse: 0.84104 | valid_mse: 0.70735 |  0:00:05s\n",
      "epoch 3  | loss: 0.68481 | train_rmsle: 0.03856 | train_mae: 0.70806 | train_rmse: 0.79965 | train_mse: 0.63943 | valid_rmsle: 0.03876 | valid_mae: 0.71039 | valid_rmse: 0.80419 | valid_mse: 0.64673 |  0:00:07s\n",
      "epoch 4  | loss: 0.48549 | train_rmsle: 0.02893 | train_mae: 0.60994 | train_rmse: 0.7008  | train_mse: 0.49112 | valid_rmsle: 0.02884 | valid_mae: 0.61089 | valid_rmse: 0.70296 | valid_mse: 0.49415 |  0:00:09s\n",
      "epoch 5  | loss: 0.39529 | train_rmsle: 0.02431 | train_mae: 0.55532 | train_rmse: 0.64493 | train_mse: 0.41593 | valid_rmsle: 0.02412 | valid_mae: 0.55688 | valid_rmse: 0.6461  | valid_mse: 0.41744 |  0:00:11s\n",
      "epoch 6  | loss: 0.34371 | train_rmsle: 0.01967 | train_mae: 0.49216 | train_rmse: 0.57962 | train_mse: 0.33596 | valid_rmsle: 0.01937 | valid_mae: 0.49371 | valid_rmse: 0.57973 | valid_mse: 0.33609 |  0:00:12s\n",
      "epoch 7  | loss: 0.31357 | train_rmsle: 0.01747 | train_mae: 0.45625 | train_rmse: 0.54359 | train_mse: 0.29549 | valid_rmsle: 0.01706 | valid_mae: 0.45796 | valid_rmse: 0.54216 | valid_mse: 0.29393 |  0:00:14s\n",
      "epoch 8  | loss: 0.29123 | train_rmsle: 0.01718 | train_mae: 0.4523  | train_rmse: 0.53903 | train_mse: 0.29056 | valid_rmsle: 0.01679 | valid_mae: 0.4538  | valid_rmse: 0.53775 | valid_mse: 0.28917 |  0:00:16s\n",
      "epoch 9  | loss: 0.27053 | train_rmsle: 0.01634 | train_mae: 0.43559 | train_rmse: 0.52333 | train_mse: 0.27387 | valid_rmsle: 0.01597 | valid_mae: 0.43713 | valid_rmse: 0.52264 | valid_mse: 0.27315 |  0:00:18s\n",
      "epoch 10 | loss: 0.27103 | train_rmsle: 0.02057 | train_mae: 0.50655 | train_rmse: 0.59356 | train_mse: 0.35231 | valid_rmsle: 0.0203  | valid_mae: 0.5088  | valid_rmse: 0.59408 | valid_mse: 0.35293 |  0:00:20s\n",
      "epoch 11 | loss: 0.24806 | train_rmsle: 0.01002 | train_mae: 0.32105 | train_rmse: 0.40064 | train_mse: 0.16051 | valid_rmsle: 0.00894 | valid_mae: 0.30628 | valid_rmse: 0.38573 | valid_mse: 0.14878 |  0:00:21s\n",
      "epoch 12 | loss: 0.20274 | train_rmsle: 0.00948 | train_mae: 0.30345 | train_rmse: 0.38482 | train_mse: 0.14809 | valid_rmsle: 0.00862 | valid_mae: 0.29002 | valid_rmse: 0.37032 | valid_mse: 0.13714 |  0:00:23s\n",
      "epoch 13 | loss: 0.18758 | train_rmsle: 0.00873 | train_mae: 0.29047 | train_rmse: 0.36861 | train_mse: 0.13588 | valid_rmsle: 0.00782 | valid_mae: 0.27568 | valid_rmse: 0.35246 | valid_mse: 0.12422 |  0:00:25s\n",
      "epoch 14 | loss: 0.17264 | train_rmsle: 0.00872 | train_mae: 0.29127 | train_rmse: 0.36931 | train_mse: 0.13639 | valid_rmsle: 0.00772 | valid_mae: 0.27666 | valid_rmse: 0.35147 | valid_mse: 0.12353 |  0:00:27s\n",
      "epoch 15 | loss: 0.16545 | train_rmsle: 0.00824 | train_mae: 0.28596 | train_rmse: 0.3604  | train_mse: 0.12989 | valid_rmsle: 0.00779 | valid_mae: 0.27969 | valid_rmse: 0.35593 | valid_mse: 0.12668 |  0:00:29s\n",
      "epoch 16 | loss: 0.16878 | train_rmsle: 0.00756 | train_mae: 0.26995 | train_rmse: 0.34295 | train_mse: 0.11761 | valid_rmsle: 0.00684 | valid_mae: 0.25772 | valid_rmse: 0.33017 | valid_mse: 0.10901 |  0:00:30s\n",
      "epoch 17 | loss: 0.1556  | train_rmsle: 0.00741 | train_mae: 0.2619  | train_rmse: 0.33766 | train_mse: 0.11401 | valid_rmsle: 0.00675 | valid_mae: 0.25096 | valid_rmse: 0.32679 | valid_mse: 0.10679 |  0:00:32s\n",
      "epoch 18 | loss: 0.15617 | train_rmsle: 0.00898 | train_mae: 0.28937 | train_rmse: 0.37803 | train_mse: 0.14291 | valid_rmsle: 0.00843 | valid_mae: 0.29008 | valid_rmse: 0.37213 | valid_mse: 0.13848 |  0:00:34s\n",
      "epoch 19 | loss: 0.20371 | train_rmsle: 0.00775 | train_mae: 0.26106 | train_rmse: 0.34453 | train_mse: 0.1187  | valid_rmsle: 0.00708 | valid_mae: 0.25345 | valid_rmse: 0.33268 | valid_mse: 0.11068 |  0:00:36s\n",
      "epoch 20 | loss: 0.15289 | train_rmsle: 0.00833 | train_mae: 0.28819 | train_rmse: 0.36302 | train_mse: 0.13178 | valid_rmsle: 0.00761 | valid_mae: 0.27564 | valid_rmse: 0.35047 | valid_mse: 0.12283 |  0:00:37s\n",
      "epoch 21 | loss: 0.1453  | train_rmsle: 0.0085  | train_mae: 0.2946  | train_rmse: 0.36775 | train_mse: 0.13524 | valid_rmsle: 0.00786 | valid_mae: 0.285   | valid_rmse: 0.35767 | valid_mse: 0.12793 |  0:00:39s\n",
      "epoch 22 | loss: 0.13891 | train_rmsle: 0.00783 | train_mae: 0.26525 | train_rmse: 0.34765 | train_mse: 0.12086 | valid_rmsle: 0.00728 | valid_mae: 0.25808 | valid_rmse: 0.34002 | valid_mse: 0.11562 |  0:00:41s\n",
      "epoch 23 | loss: 0.14962 | train_rmsle: 0.01053 | train_mae: 0.33916 | train_rmse: 0.414   | train_mse: 0.17139 | valid_rmsle: 0.01006 | valid_mae: 0.33269 | valid_rmse: 0.4083  | valid_mse: 0.16671 |  0:00:43s\n",
      "epoch 24 | loss: 0.15513 | train_rmsle: 0.01153 | train_mae: 0.36436 | train_rmse: 0.43598 | train_mse: 0.19008 | valid_rmsle: 0.01096 | valid_mae: 0.35748 | valid_rmse: 0.42808 | valid_mse: 0.18326 |  0:00:45s\n",
      "epoch 25 | loss: 0.17048 | train_rmsle: 0.00779 | train_mae: 0.26893 | train_rmse: 0.34748 | train_mse: 0.12074 | valid_rmsle: 0.00699 | valid_mae: 0.25571 | valid_rmse: 0.33316 | valid_mse: 0.11099 |  0:00:46s\n",
      "epoch 26 | loss: 0.13098 | train_rmsle: 0.00745 | train_mae: 0.25789 | train_rmse: 0.33765 | train_mse: 0.11401 | valid_rmsle: 0.007   | valid_mae: 0.24773 | valid_rmse: 0.33059 | valid_mse: 0.10929 |  0:00:48s\n",
      "epoch 27 | loss: 0.13574 | train_rmsle: 0.00842 | train_mae: 0.28854 | train_rmse: 0.36448 | train_mse: 0.13284 | valid_rmsle: 0.00772 | valid_mae: 0.27772 | valid_rmse: 0.35242 | valid_mse: 0.1242  |  0:00:50s\n",
      "epoch 28 | loss: 0.16869 | train_rmsle: 0.01038 | train_mae: 0.33994 | train_rmse: 0.41125 | train_mse: 0.16912 | valid_rmsle: 0.00981 | valid_mae: 0.33141 | valid_rmse: 0.40299 | valid_mse: 0.1624  |  0:00:52s\n",
      "epoch 29 | loss: 0.28532 | train_rmsle: 0.00994 | train_mae: 0.29904 | train_rmse: 0.39743 | train_mse: 0.15795 | valid_rmsle: 0.00949 | valid_mae: 0.29922 | valid_rmse: 0.39234 | valid_mse: 0.15393 |  0:00:54s\n",
      "epoch 30 | loss: 0.20346 | train_rmsle: 0.00744 | train_mae: 0.2558  | train_rmse: 0.33785 | train_mse: 0.11414 | valid_rmsle: 0.00679 | valid_mae: 0.24539 | valid_rmse: 0.32523 | valid_mse: 0.10577 |  0:00:55s\n",
      "epoch 31 | loss: 0.13057 | train_rmsle: 0.0078  | train_mae: 0.27268 | train_rmse: 0.34934 | train_mse: 0.12204 | valid_rmsle: 0.00693 | valid_mae: 0.25932 | valid_rmse: 0.3327  | valid_mse: 0.11069 |  0:00:57s\n",
      "epoch 32 | loss: 0.15595 | train_rmsle: 0.00848 | train_mae: 0.29361 | train_rmse: 0.36708 | train_mse: 0.13475 | valid_rmsle: 0.00776 | valid_mae: 0.28051 | valid_rmse: 0.35415 | valid_mse: 0.12542 |  0:00:59s\n",
      "epoch 33 | loss: 0.12074 | train_rmsle: 0.00935 | train_mae: 0.31229 | train_rmse: 0.38681 | train_mse: 0.14962 | valid_rmsle: 0.00866 | valid_mae: 0.30008 | valid_rmse: 0.37612 | valid_mse: 0.14147 |  0:01:01s\n",
      "epoch 34 | loss: 0.12541 | train_rmsle: 0.00862 | train_mae: 0.30029 | train_rmse: 0.37157 | train_mse: 0.13807 | valid_rmsle: 0.00807 | valid_mae: 0.29181 | valid_rmse: 0.3631  | valid_mse: 0.13184 |  0:01:02s\n",
      "epoch 35 | loss: 0.14115 | train_rmsle: 0.0087  | train_mae: 0.30299 | train_rmse: 0.37379 | train_mse: 0.13972 | valid_rmsle: 0.00835 | valid_mae: 0.29858 | valid_rmse: 0.37049 | valid_mse: 0.13727 |  0:01:04s\n",
      "epoch 36 | loss: 0.12238 | train_rmsle: 0.00722 | train_mae: 0.25161 | train_rmse: 0.33076 | train_mse: 0.1094  | valid_rmsle: 0.00669 | valid_mae: 0.24345 | valid_rmse: 0.3229  | valid_mse: 0.10427 |  0:01:06s\n",
      "epoch 37 | loss: 0.118   | train_rmsle: 0.00793 | train_mae: 0.27838 | train_rmse: 0.35251 | train_mse: 0.12426 | valid_rmsle: 0.00757 | valid_mae: 0.26996 | valid_rmse: 0.34735 | valid_mse: 0.12065 |  0:01:08s\n",
      "epoch 38 | loss: 0.12132 | train_rmsle: 0.00752 | train_mae: 0.26873 | train_rmse: 0.34246 | train_mse: 0.11728 | valid_rmsle: 0.00685 | valid_mae: 0.25788 | valid_rmse: 0.33122 | valid_mse: 0.1097  |  0:01:10s\n",
      "epoch 39 | loss: 0.11361 | train_rmsle: 0.00726 | train_mae: 0.25944 | train_rmse: 0.3343  | train_mse: 0.11175 | valid_rmsle: 0.00688 | valid_mae: 0.2537  | valid_rmse: 0.33048 | valid_mse: 0.10922 |  0:01:11s\n",
      "epoch 40 | loss: 0.11525 | train_rmsle: 0.00806 | train_mae: 0.28277 | train_rmse: 0.35654 | train_mse: 0.12712 | valid_rmsle: 0.00739 | valid_mae: 0.27398 | valid_rmse: 0.34611 | valid_mse: 0.1198  |  0:01:13s\n",
      "epoch 41 | loss: 0.11394 | train_rmsle: 0.00725 | train_mae: 0.25599 | train_rmse: 0.33356 | train_mse: 0.11126 | valid_rmsle: 0.0068  | valid_mae: 0.2501  | valid_rmse: 0.32713 | valid_mse: 0.10701 |  0:01:15s\n",
      "epoch 42 | loss: 0.11421 | train_rmsle: 0.00762 | train_mae: 0.26591 | train_rmse: 0.34356 | train_mse: 0.11803 | valid_rmsle: 0.007   | valid_mae: 0.25804 | valid_rmse: 0.33483 | valid_mse: 0.11211 |  0:01:17s\n",
      "epoch 43 | loss: 0.11782 | train_rmsle: 0.00727 | train_mae: 0.26124 | train_rmse: 0.33522 | train_mse: 0.11237 | valid_rmsle: 0.0071  | valid_mae: 0.25878 | valid_rmse: 0.33648 | valid_mse: 0.11322 |  0:01:18s\n",
      "epoch 44 | loss: 0.10998 | train_rmsle: 0.00723 | train_mae: 0.25301 | train_rmse: 0.33245 | train_mse: 0.11052 | valid_rmsle: 0.00663 | valid_mae: 0.2454  | valid_rmse: 0.32305 | valid_mse: 0.10436 |  0:01:20s\n",
      "epoch 45 | loss: 0.11091 | train_rmsle: 0.00706 | train_mae: 0.25196 | train_rmse: 0.32846 | train_mse: 0.10789 | valid_rmsle: 0.00677 | valid_mae: 0.24868 | valid_rmse: 0.32731 | valid_mse: 0.10713 |  0:01:22s\n",
      "epoch 46 | loss: 0.10807 | train_rmsle: 0.00694 | train_mae: 0.2474  | train_rmse: 0.32435 | train_mse: 0.1052  | valid_rmsle: 0.00655 | valid_mae: 0.24186 | valid_rmse: 0.31987 | valid_mse: 0.10232 |  0:01:24s\n",
      "epoch 47 | loss: 0.11175 | train_rmsle: 0.008   | train_mae: 0.28228 | train_rmse: 0.3551  | train_mse: 0.12609 | valid_rmsle: 0.00741 | valid_mae: 0.27314 | valid_rmse: 0.3455  | valid_mse: 0.11937 |  0:01:26s\n",
      "epoch 48 | loss: 0.10851 | train_rmsle: 0.00686 | train_mae: 0.24567 | train_rmse: 0.32267 | train_mse: 0.10412 | valid_rmsle: 0.0063  | valid_mae: 0.23783 | valid_rmse: 0.3128  | valid_mse: 0.09784 |  0:01:27s\n",
      "epoch 49 | loss: 0.10691 | train_rmsle: 0.00726 | train_mae: 0.26429 | train_rmse: 0.33565 | train_mse: 0.11266 | valid_rmsle: 0.00673 | valid_mae: 0.25537 | valid_rmse: 0.32692 | valid_mse: 0.10688 |  0:01:29s\n",
      "epoch 50 | loss: 0.10578 | train_rmsle: 0.00699 | train_mae: 0.25493 | train_rmse: 0.32724 | train_mse: 0.10709 | valid_rmsle: 0.00644 | valid_mae: 0.24584 | valid_rmse: 0.3176  | valid_mse: 0.10087 |  0:01:31s\n",
      "epoch 51 | loss: 0.11104 | train_rmsle: 0.00714 | train_mae: 0.24747 | train_rmse: 0.32856 | train_mse: 0.10795 | valid_rmsle: 0.00677 | valid_mae: 0.24483 | valid_rmse: 0.3244  | valid_mse: 0.10524 |  0:01:33s\n",
      "epoch 52 | loss: 0.10615 | train_rmsle: 0.00678 | train_mae: 0.2447  | train_rmse: 0.32047 | train_mse: 0.1027  | valid_rmsle: 0.00637 | valid_mae: 0.23742 | valid_rmse: 0.31441 | valid_mse: 0.09886 |  0:01:34s\n",
      "epoch 53 | loss: 0.10524 | train_rmsle: 0.00682 | train_mae: 0.2474  | train_rmse: 0.32216 | train_mse: 0.10379 | valid_rmsle: 0.00625 | valid_mae: 0.23757 | valid_rmse: 0.31253 | valid_mse: 0.09768 |  0:01:36s\n",
      "epoch 54 | loss: 0.10326 | train_rmsle: 0.00701 | train_mae: 0.25511 | train_rmse: 0.32822 | train_mse: 0.10773 | valid_rmsle: 0.00652 | valid_mae: 0.244   | valid_rmse: 0.31909 | valid_mse: 0.10182 |  0:01:38s\n",
      "epoch 55 | loss: 0.10297 | train_rmsle: 0.00681 | train_mae: 0.24953 | train_rmse: 0.3222  | train_mse: 0.10381 | valid_rmsle: 0.00629 | valid_mae: 0.24172 | valid_rmse: 0.31418 | valid_mse: 0.09871 |  0:01:40s\n",
      "epoch 56 | loss: 0.10153 | train_rmsle: 0.00667 | train_mae: 0.24368 | train_rmse: 0.31789 | train_mse: 0.10105 | valid_rmsle: 0.00612 | valid_mae: 0.2327  | valid_rmse: 0.30744 | valid_mse: 0.09452 |  0:01:42s\n",
      "epoch 57 | loss: 0.10506 | train_rmsle: 0.00745 | train_mae: 0.27222 | train_rmse: 0.34189 | train_mse: 0.11689 | valid_rmsle: 0.00676 | valid_mae: 0.25947 | valid_rmse: 0.32906 | valid_mse: 0.10828 |  0:01:43s\n",
      "epoch 58 | loss: 0.10172 | train_rmsle: 0.00678 | train_mae: 0.24918 | train_rmse: 0.32168 | train_mse: 0.10348 | valid_rmsle: 0.00624 | valid_mae: 0.23946 | valid_rmse: 0.31204 | valid_mse: 0.09737 |  0:01:45s\n",
      "epoch 59 | loss: 0.10102 | train_rmsle: 0.00671 | train_mae: 0.24416 | train_rmse: 0.31808 | train_mse: 0.10118 | valid_rmsle: 0.00622 | valid_mae: 0.23565 | valid_rmse: 0.31055 | valid_mse: 0.09644 |  0:01:47s\n",
      "epoch 60 | loss: 0.10349 | train_rmsle: 0.00666 | train_mae: 0.24104 | train_rmse: 0.31595 | train_mse: 0.09982 | valid_rmsle: 0.00618 | valid_mae: 0.23447 | valid_rmse: 0.30858 | valid_mse: 0.09522 |  0:01:49s\n",
      "epoch 61 | loss: 0.10428 | train_rmsle: 0.00671 | train_mae: 0.24772 | train_rmse: 0.31939 | train_mse: 0.10201 | valid_rmsle: 0.00618 | valid_mae: 0.23907 | valid_rmse: 0.3105  | valid_mse: 0.09641 |  0:01:50s\n",
      "epoch 62 | loss: 0.10216 | train_rmsle: 0.00671 | train_mae: 0.24883 | train_rmse: 0.32012 | train_mse: 0.10248 | valid_rmsle: 0.00629 | valid_mae: 0.2427  | valid_rmse: 0.3145  | valid_mse: 0.09891 |  0:01:52s\n",
      "epoch 63 | loss: 0.10123 | train_rmsle: 0.00659 | train_mae: 0.23998 | train_rmse: 0.31442 | train_mse: 0.09886 | valid_rmsle: 0.00612 | valid_mae: 0.23277 | valid_rmse: 0.3073  | valid_mse: 0.09443 |  0:01:54s\n",
      "epoch 64 | loss: 0.10327 | train_rmsle: 0.00668 | train_mae: 0.2481  | train_rmse: 0.31898 | train_mse: 0.10175 | valid_rmsle: 0.00615 | valid_mae: 0.23947 | valid_rmse: 0.30989 | valid_mse: 0.09603 |  0:01:56s\n",
      "epoch 65 | loss: 0.10271 | train_rmsle: 0.00657 | train_mae: 0.23978 | train_rmse: 0.31393 | train_mse: 0.09855 | valid_rmsle: 0.00618 | valid_mae: 0.23318 | valid_rmse: 0.30856 | valid_mse: 0.09521 |  0:01:58s\n",
      "epoch 66 | loss: 0.10104 | train_rmsle: 0.00664 | train_mae: 0.23926 | train_rmse: 0.31552 | train_mse: 0.09955 | valid_rmsle: 0.00626 | valid_mae: 0.23451 | valid_rmse: 0.3107  | valid_mse: 0.09654 |  0:01:59s\n",
      "epoch 67 | loss: 0.10053 | train_rmsle: 0.0069  | train_mae: 0.25796 | train_rmse: 0.32694 | train_mse: 0.10689 | valid_rmsle: 0.0064  | valid_mae: 0.25101 | valid_rmse: 0.3186  | valid_mse: 0.1015  |  0:02:01s\n",
      "epoch 68 | loss: 0.09974 | train_rmsle: 0.00664 | train_mae: 0.24242 | train_rmse: 0.31613 | train_mse: 0.09994 | valid_rmsle: 0.0062  | valid_mae: 0.23929 | valid_rmse: 0.30984 | valid_mse: 0.096   |  0:02:03s\n",
      "epoch 69 | loss: 0.10004 | train_rmsle: 0.00659 | train_mae: 0.24162 | train_rmse: 0.3151  | train_mse: 0.09929 | valid_rmsle: 0.00613 | valid_mae: 0.2363  | valid_rmse: 0.30825 | valid_mse: 0.09502 |  0:02:05s\n",
      "epoch 70 | loss: 0.09911 | train_rmsle: 0.00662 | train_mae: 0.24394 | train_rmse: 0.31698 | train_mse: 0.10048 | valid_rmsle: 0.00612 | valid_mae: 0.23657 | valid_rmse: 0.30882 | valid_mse: 0.09537 |  0:02:06s\n",
      "epoch 71 | loss: 0.10025 | train_rmsle: 0.0072  | train_mae: 0.24515 | train_rmse: 0.32793 | train_mse: 0.10754 | valid_rmsle: 0.00687 | valid_mae: 0.24478 | valid_rmse: 0.32526 | valid_mse: 0.10579 |  0:02:08s\n",
      "epoch 72 | loss: 0.10075 | train_rmsle: 0.0066  | train_mae: 0.24081 | train_rmse: 0.31471 | train_mse: 0.09904 | valid_rmsle: 0.00619 | valid_mae: 0.23419 | valid_rmse: 0.30909 | valid_mse: 0.09554 |  0:02:10s\n",
      "epoch 73 | loss: 0.10028 | train_rmsle: 0.0066  | train_mae: 0.243   | train_rmse: 0.31626 | train_mse: 0.10002 | valid_rmsle: 0.00619 | valid_mae: 0.23574 | valid_rmse: 0.31037 | valid_mse: 0.09633 |  0:02:12s\n",
      "epoch 74 | loss: 0.10124 | train_rmsle: 0.00675 | train_mae: 0.25169 | train_rmse: 0.32222 | train_mse: 0.10382 | valid_rmsle: 0.00633 | valid_mae: 0.24509 | valid_rmse: 0.31605 | valid_mse: 0.09989 |  0:02:14s\n",
      "epoch 75 | loss: 0.09998 | train_rmsle: 0.00648 | train_mae: 0.24104 | train_rmse: 0.31347 | train_mse: 0.09826 | valid_rmsle: 0.00613 | valid_mae: 0.23532 | valid_rmse: 0.30885 | valid_mse: 0.09539 |  0:02:15s\n",
      "epoch 76 | loss: 0.09878 | train_rmsle: 0.0065  | train_mae: 0.24113 | train_rmse: 0.31342 | train_mse: 0.09823 | valid_rmsle: 0.00613 | valid_mae: 0.23496 | valid_rmse: 0.30859 | valid_mse: 0.09523 |  0:02:17s\n",
      "epoch 77 | loss: 0.09789 | train_rmsle: 0.00657 | train_mae: 0.24281 | train_rmse: 0.31496 | train_mse: 0.0992  | valid_rmsle: 0.00615 | valid_mae: 0.23573 | valid_rmse: 0.30846 | valid_mse: 0.09515 |  0:02:19s\n",
      "epoch 78 | loss: 0.09967 | train_rmsle: 0.00677 | train_mae: 0.25348 | train_rmse: 0.32295 | train_mse: 0.1043  | valid_rmsle: 0.00633 | valid_mae: 0.24541 | valid_rmse: 0.31617 | valid_mse: 0.09996 |  0:02:21s\n",
      "epoch 79 | loss: 0.09804 | train_rmsle: 0.00662 | train_mae: 0.24048 | train_rmse: 0.31496 | train_mse: 0.0992  | valid_rmsle: 0.00618 | valid_mae: 0.2352  | valid_rmse: 0.30894 | valid_mse: 0.09544 |  0:02:23s\n",
      "epoch 80 | loss: 0.09827 | train_rmsle: 0.00654 | train_mae: 0.24129 | train_rmse: 0.31393 | train_mse: 0.09855 | valid_rmsle: 0.00604 | valid_mae: 0.23427 | valid_rmse: 0.3057  | valid_mse: 0.09345 |  0:02:24s\n",
      "epoch 81 | loss: 0.09943 | train_rmsle: 0.00657 | train_mae: 0.24671 | train_rmse: 0.31663 | train_mse: 0.10026 | valid_rmsle: 0.0061  | valid_mae: 0.24009 | valid_rmse: 0.30897 | valid_mse: 0.09546 |  0:02:26s\n",
      "epoch 82 | loss: 0.09833 | train_rmsle: 0.00672 | train_mae: 0.25377 | train_rmse: 0.32235 | train_mse: 0.10391 | valid_rmsle: 0.00626 | valid_mae: 0.24664 | valid_rmse: 0.31522 | valid_mse: 0.09936 |  0:02:28s\n",
      "epoch 83 | loss: 0.09998 | train_rmsle: 0.00662 | train_mae: 0.23556 | train_rmse: 0.3134  | train_mse: 0.09822 | valid_rmsle: 0.00625 | valid_mae: 0.23436 | valid_rmse: 0.30966 | valid_mse: 0.09589 |  0:02:30s\n",
      "epoch 84 | loss: 0.09733 | train_rmsle: 0.0064  | train_mae: 0.23767 | train_rmse: 0.3105  | train_mse: 0.09641 | valid_rmsle: 0.00603 | valid_mae: 0.2335  | valid_rmse: 0.30542 | valid_mse: 0.09328 |  0:02:31s\n",
      "epoch 85 | loss: 0.09681 | train_rmsle: 0.00669 | train_mae: 0.25229 | train_rmse: 0.32123 | train_mse: 0.10319 | valid_rmsle: 0.00619 | valid_mae: 0.24448 | valid_rmse: 0.31281 | valid_mse: 0.09785 |  0:02:33s\n",
      "epoch 86 | loss: 0.10026 | train_rmsle: 0.00644 | train_mae: 0.23439 | train_rmse: 0.31014 | train_mse: 0.09619 | valid_rmsle: 0.00614 | valid_mae: 0.23375 | valid_rmse: 0.30791 | valid_mse: 0.09481 |  0:02:35s\n",
      "epoch 87 | loss: 0.09771 | train_rmsle: 0.00637 | train_mae: 0.2383  | train_rmse: 0.31008 | train_mse: 0.09615 | valid_rmsle: 0.006   | valid_mae: 0.23513 | valid_rmse: 0.30517 | valid_mse: 0.09313 |  0:02:37s\n",
      "epoch 88 | loss: 0.09887 | train_rmsle: 0.00644 | train_mae: 0.24045 | train_rmse: 0.31196 | train_mse: 0.09732 | valid_rmsle: 0.00605 | valid_mae: 0.23694 | valid_rmse: 0.30653 | valid_mse: 0.09396 |  0:02:39s\n",
      "epoch 89 | loss: 0.10003 | train_rmsle: 0.00644 | train_mae: 0.24312 | train_rmse: 0.31326 | train_mse: 0.09813 | valid_rmsle: 0.00603 | valid_mae: 0.2363  | valid_rmse: 0.30672 | valid_mse: 0.09408 |  0:02:40s\n",
      "epoch 90 | loss: 0.09928 | train_rmsle: 0.00644 | train_mae: 0.24239 | train_rmse: 0.31311 | train_mse: 0.09804 | valid_rmsle: 0.00611 | valid_mae: 0.23757 | valid_rmse: 0.30861 | valid_mse: 0.09524 |  0:02:42s\n",
      "epoch 91 | loss: 0.09694 | train_rmsle: 0.00652 | train_mae: 0.2473  | train_rmse: 0.31684 | train_mse: 0.10039 | valid_rmsle: 0.00615 | valid_mae: 0.2401  | valid_rmse: 0.31116 | valid_mse: 0.09682 |  0:02:44s\n",
      "epoch 92 | loss: 0.09653 | train_rmsle: 0.00641 | train_mae: 0.24259 | train_rmse: 0.31318 | train_mse: 0.09808 | valid_rmsle: 0.00603 | valid_mae: 0.23557 | valid_rmse: 0.30746 | valid_mse: 0.09453 |  0:02:46s\n",
      "epoch 93 | loss: 0.09607 | train_rmsle: 0.0064  | train_mae: 0.243   | train_rmse: 0.31286 | train_mse: 0.09788 | valid_rmsle: 0.00619 | valid_mae: 0.2406  | valid_rmse: 0.31157 | valid_mse: 0.09708 |  0:02:47s\n",
      "epoch 94 | loss: 0.09908 | train_rmsle: 0.00631 | train_mae: 0.23554 | train_rmse: 0.30872 | train_mse: 0.09531 | valid_rmsle: 0.00615 | valid_mae: 0.23366 | valid_rmse: 0.30873 | valid_mse: 0.09532 |  0:02:49s\n",
      "epoch 95 | loss: 0.09682 | train_rmsle: 0.00631 | train_mae: 0.23758 | train_rmse: 0.30916 | train_mse: 0.09558 | valid_rmsle: 0.00609 | valid_mae: 0.23521 | valid_rmse: 0.30772 | valid_mse: 0.09469 |  0:02:51s\n",
      "epoch 96 | loss: 0.09601 | train_rmsle: 0.00639 | train_mae: 0.23723 | train_rmse: 0.31005 | train_mse: 0.09613 | valid_rmsle: 0.00623 | valid_mae: 0.23741 | valid_rmse: 0.3108  | valid_mse: 0.0966  |  0:02:53s\n",
      "epoch 97 | loss: 0.09709 | train_rmsle: 0.00637 | train_mae: 0.2349  | train_rmse: 0.3087  | train_mse: 0.0953  | valid_rmsle: 0.00622 | valid_mae: 0.23544 | valid_rmse: 0.30995 | valid_mse: 0.09607 |  0:02:55s\n",
      "epoch 98 | loss: 0.09582 | train_rmsle: 0.00695 | train_mae: 0.26239 | train_rmse: 0.3304  | train_mse: 0.10917 | valid_rmsle: 0.00658 | valid_mae: 0.25566 | valid_rmse: 0.32454 | valid_mse: 0.10533 |  0:02:56s\n",
      "epoch 99 | loss: 0.09837 | train_rmsle: 0.00647 | train_mae: 0.23615 | train_rmse: 0.31129 | train_mse: 0.0969  | valid_rmsle: 0.00623 | valid_mae: 0.23486 | valid_rmse: 0.30977 | valid_mse: 0.09596 |  0:02:58s\n",
      "epoch 100| loss: 0.09987 | train_rmsle: 0.00628 | train_mae: 0.2367  | train_rmse: 0.30863 | train_mse: 0.09525 | valid_rmsle: 0.0059  | valid_mae: 0.23199 | valid_rmse: 0.30344 | valid_mse: 0.09207 |  0:03:00s\n",
      "epoch 101| loss: 0.09679 | train_rmsle: 0.00626 | train_mae: 0.2341  | train_rmse: 0.30696 | train_mse: 0.09423 | valid_rmsle: 0.00598 | valid_mae: 0.23337 | valid_rmse: 0.30456 | valid_mse: 0.09275 |  0:03:02s\n",
      "epoch 102| loss: 0.09957 | train_rmsle: 0.00633 | train_mae: 0.23255 | train_rmse: 0.30733 | train_mse: 0.09445 | valid_rmsle: 0.00612 | valid_mae: 0.23368 | valid_rmse: 0.30674 | valid_mse: 0.09409 |  0:03:04s\n",
      "epoch 103| loss: 0.09806 | train_rmsle: 0.00651 | train_mae: 0.24629 | train_rmse: 0.31615 | train_mse: 0.09995 | valid_rmsle: 0.00627 | valid_mae: 0.24385 | valid_rmse: 0.314   | valid_mse: 0.0986  |  0:03:05s\n",
      "epoch 104| loss: 0.09663 | train_rmsle: 0.0063  | train_mae: 0.23369 | train_rmse: 0.307   | train_mse: 0.09425 | valid_rmsle: 0.00605 | valid_mae: 0.23321 | valid_rmse: 0.30565 | valid_mse: 0.09342 |  0:03:07s\n",
      "epoch 105| loss: 0.09637 | train_rmsle: 0.00627 | train_mae: 0.23459 | train_rmse: 0.30686 | train_mse: 0.09416 | valid_rmsle: 0.00607 | valid_mae: 0.23493 | valid_rmse: 0.30684 | valid_mse: 0.09415 |  0:03:09s\n",
      "epoch 106| loss: 0.09572 | train_rmsle: 0.00624 | train_mae: 0.23679 | train_rmse: 0.30717 | train_mse: 0.09435 | valid_rmsle: 0.00593 | valid_mae: 0.23384 | valid_rmse: 0.30361 | valid_mse: 0.09218 |  0:03:11s\n",
      "epoch 107| loss: 0.09438 | train_rmsle: 0.00624 | train_mae: 0.23699 | train_rmse: 0.30716 | train_mse: 0.09435 | valid_rmsle: 0.00599 | valid_mae: 0.23612 | valid_rmse: 0.30547 | valid_mse: 0.09331 |  0:03:12s\n",
      "epoch 108| loss: 0.0943  | train_rmsle: 0.00629 | train_mae: 0.23526 | train_rmse: 0.30705 | train_mse: 0.09428 | valid_rmsle: 0.00602 | valid_mae: 0.23392 | valid_rmse: 0.30462 | valid_mse: 0.09279 |  0:03:14s\n",
      "epoch 109| loss: 0.09489 | train_rmsle: 0.00622 | train_mae: 0.23702 | train_rmse: 0.30693 | train_mse: 0.09421 | valid_rmsle: 0.00596 | valid_mae: 0.23684 | valid_rmse: 0.30469 | valid_mse: 0.09284 |  0:03:16s\n",
      "epoch 110| loss: 0.09491 | train_rmsle: 0.00623 | train_mae: 0.23614 | train_rmse: 0.30684 | train_mse: 0.09415 | valid_rmsle: 0.00611 | valid_mae: 0.23604 | valid_rmse: 0.30795 | valid_mse: 0.09483 |  0:03:18s\n",
      "epoch 111| loss: 0.09522 | train_rmsle: 0.00627 | train_mae: 0.24097 | train_rmse: 0.30947 | train_mse: 0.09577 | valid_rmsle: 0.00606 | valid_mae: 0.23866 | valid_rmse: 0.30824 | valid_mse: 0.09501 |  0:03:20s\n",
      "epoch 112| loss: 0.09596 | train_rmsle: 0.00617 | train_mae: 0.23373 | train_rmse: 0.30513 | train_mse: 0.0931  | valid_rmsle: 0.00599 | valid_mae: 0.23351 | valid_rmse: 0.30462 | valid_mse: 0.09279 |  0:03:21s\n",
      "epoch 113| loss: 0.09573 | train_rmsle: 0.00627 | train_mae: 0.23327 | train_rmse: 0.30654 | train_mse: 0.09397 | valid_rmsle: 0.00606 | valid_mae: 0.23245 | valid_rmse: 0.30614 | valid_mse: 0.09372 |  0:03:23s\n",
      "epoch 114| loss: 0.09513 | train_rmsle: 0.0062  | train_mae: 0.23183 | train_rmse: 0.30492 | train_mse: 0.09298 | valid_rmsle: 0.00603 | valid_mae: 0.23212 | valid_rmse: 0.30493 | valid_mse: 0.09298 |  0:03:25s\n",
      "epoch 115| loss: 0.0975  | train_rmsle: 0.00623 | train_mae: 0.24162 | train_rmse: 0.3097  | train_mse: 0.09591 | valid_rmsle: 0.00599 | valid_mae: 0.23785 | valid_rmse: 0.30691 | valid_mse: 0.09419 |  0:03:27s\n",
      "epoch 116| loss: 0.09463 | train_rmsle: 0.00616 | train_mae: 0.23308 | train_rmse: 0.30442 | train_mse: 0.09267 | valid_rmsle: 0.00604 | valid_mae: 0.23286 | valid_rmse: 0.30531 | valid_mse: 0.09321 |  0:03:28s\n",
      "epoch 117| loss: 0.09276 | train_rmsle: 0.00612 | train_mae: 0.23759 | train_rmse: 0.30603 | train_mse: 0.09366 | valid_rmsle: 0.00599 | valid_mae: 0.23638 | valid_rmse: 0.30648 | valid_mse: 0.09393 |  0:03:30s\n",
      "epoch 118| loss: 0.09911 | train_rmsle: 0.00624 | train_mae: 0.2415  | train_rmse: 0.30984 | train_mse: 0.096   | valid_rmsle: 0.00607 | valid_mae: 0.23972 | valid_rmse: 0.30896 | valid_mse: 0.09545 |  0:03:32s\n",
      "epoch 119| loss: 0.09322 | train_rmsle: 0.00606 | train_mae: 0.23443 | train_rmse: 0.30344 | train_mse: 0.09207 | valid_rmsle: 0.00597 | valid_mae: 0.23465 | valid_rmse: 0.30508 | valid_mse: 0.09308 |  0:03:34s\n",
      "epoch 120| loss: 0.09382 | train_rmsle: 0.00597 | train_mae: 0.2307  | train_rmse: 0.30067 | train_mse: 0.0904  | valid_rmsle: 0.00594 | valid_mae: 0.23254 | valid_rmse: 0.30364 | valid_mse: 0.09219 |  0:03:36s\n",
      "\n",
      "Early stopping occurred at epoch 120 with best_epoch = 100 and best_valid_mse = 0.09207\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1011863916006707 RMSE: 0.31809808487425806 R2: 0.5520868333800246 MAE: 0.24316794364495786\n",
      "=====================================\n",
      "[73/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.2155  | train_rmsle: 0.29421 | train_mae: 1.77156 | train_rmse: 1.83625 | train_mse: 3.37182 | valid_rmsle: 0.2946  | valid_mae: 1.77586 | valid_rmse: 1.83905 | valid_mse: 3.38209 |  0:00:01s\n",
      "epoch 1  | loss: 0.55652 | train_rmsle: 0.18138 | train_mae: 1.45494 | train_rmse: 1.53022 | train_mse: 2.34156 | valid_rmsle: 0.18231 | valid_mae: 1.45983 | valid_rmse: 1.53503 | valid_mse: 2.35631 |  0:00:02s\n",
      "epoch 2  | loss: 0.31222 | train_rmsle: 0.08749 | train_mae: 1.0515  | train_rmse: 1.14064 | train_mse: 1.30106 | valid_rmsle: 0.08791 | valid_mae: 1.05458 | valid_rmse: 1.14469 | valid_mse: 1.31032 |  0:00:03s\n",
      "epoch 3  | loss: 0.26067 | train_rmsle: 0.04778 | train_mae: 0.78799 | train_rmse: 0.88016 | train_mse: 0.77468 | valid_rmsle: 0.04773 | valid_mae: 0.7878  | valid_rmse: 0.88204 | valid_mse: 0.77799 |  0:00:04s\n",
      "epoch 4  | loss: 0.23257 | train_rmsle: 0.03007 | train_mae: 0.62276 | train_rmse: 0.71375 | train_mse: 0.50943 | valid_rmsle: 0.02979 | valid_mae: 0.62207 | valid_rmse: 0.71375 | valid_mse: 0.50944 |  0:00:05s\n",
      "epoch 5  | loss: 0.2242  | train_rmsle: 0.01861 | train_mae: 0.476   | train_rmse: 0.56347 | train_mse: 0.3175  | valid_rmsle: 0.01832 | valid_mae: 0.47826 | valid_rmse: 0.56358 | valid_mse: 0.31762 |  0:00:06s\n",
      "epoch 6  | loss: 0.21821 | train_rmsle: 0.0174  | train_mae: 0.45645 | train_rmse: 0.54421 | train_mse: 0.29617 | valid_rmsle: 0.01702 | valid_mae: 0.4578  | valid_rmse: 0.54256 | valid_mse: 0.29437 |  0:00:07s\n",
      "epoch 7  | loss: 0.22083 | train_rmsle: 0.02095 | train_mae: 0.51079 | train_rmse: 0.59989 | train_mse: 0.35986 | valid_rmsle: 0.0206  | valid_mae: 0.51161 | valid_rmse: 0.59849 | valid_mse: 0.35819 |  0:00:08s\n",
      "epoch 8  | loss: 0.22938 | train_rmsle: 0.01479 | train_mae: 0.40928 | train_rmse: 0.49716 | train_mse: 0.24717 | valid_rmsle: 0.01444 | valid_mae: 0.41082 | valid_rmse: 0.49643 | valid_mse: 0.24645 |  0:00:09s\n",
      "epoch 9  | loss: 0.21044 | train_rmsle: 0.01368 | train_mae: 0.38531 | train_rmse: 0.47398 | train_mse: 0.22465 | valid_rmsle: 0.01349 | valid_mae: 0.39031 | valid_rmse: 0.47643 | valid_mse: 0.22698 |  0:00:10s\n",
      "epoch 10 | loss: 0.20528 | train_rmsle: 0.01454 | train_mae: 0.40642 | train_rmse: 0.49373 | train_mse: 0.24377 | valid_rmsle: 0.01465 | valid_mae: 0.41213 | valid_rmse: 0.50037 | valid_mse: 0.25037 |  0:00:11s\n",
      "epoch 11 | loss: 0.20287 | train_rmsle: 0.01353 | train_mae: 0.39097 | train_rmse: 0.4773  | train_mse: 0.22781 | valid_rmsle: 0.01377 | valid_mae: 0.3968  | valid_rmse: 0.4864  | valid_mse: 0.23659 |  0:00:13s\n",
      "epoch 12 | loss: 0.19711 | train_rmsle: 0.01115 | train_mae: 0.34441 | train_rmse: 0.42614 | train_mse: 0.18159 | valid_rmsle: 0.01103 | valid_mae: 0.34871 | valid_rmse: 0.42961 | valid_mse: 0.18456 |  0:00:14s\n",
      "epoch 13 | loss: 0.18554 | train_rmsle: 0.01057 | train_mae: 0.33728 | train_rmse: 0.41803 | train_mse: 0.17475 | valid_rmsle: 0.01066 | valid_mae: 0.34573 | valid_rmse: 0.42509 | valid_mse: 0.1807  |  0:00:15s\n",
      "epoch 14 | loss: 0.173   | train_rmsle: 0.00828 | train_mae: 0.29115 | train_rmse: 0.36542 | train_mse: 0.13353 | valid_rmsle: 0.00811 | valid_mae: 0.29179 | valid_rmse: 0.3662  | valid_mse: 0.1341  |  0:00:16s\n",
      "epoch 15 | loss: 0.15734 | train_rmsle: 0.00987 | train_mae: 0.34353 | train_rmse: 0.41318 | train_mse: 0.17072 | valid_rmsle: 0.00968 | valid_mae: 0.34125 | valid_rmse: 0.41209 | valid_mse: 0.16982 |  0:00:17s\n",
      "epoch 16 | loss: 0.13573 | train_rmsle: 0.00816 | train_mae: 0.30458 | train_rmse: 0.37464 | train_mse: 0.14036 | valid_rmsle: 0.00826 | valid_mae: 0.30579 | valid_rmse: 0.3778  | valid_mse: 0.14274 |  0:00:18s\n",
      "epoch 17 | loss: 0.11473 | train_rmsle: 0.00729 | train_mae: 0.28538 | train_rmse: 0.35314 | train_mse: 0.12471 | valid_rmsle: 0.00748 | valid_mae: 0.28999 | valid_rmse: 0.35813 | valid_mse: 0.12825 |  0:00:19s\n",
      "epoch 18 | loss: 0.09655 | train_rmsle: 0.00682 | train_mae: 0.2792  | train_rmse: 0.34121 | train_mse: 0.11643 | valid_rmsle: 0.00688 | valid_mae: 0.2814  | valid_rmse: 0.34369 | valid_mse: 0.11812 |  0:00:20s\n",
      "epoch 19 | loss: 0.08762 | train_rmsle: 0.00577 | train_mae: 0.25033 | train_rmse: 0.3119  | train_mse: 0.09728 | valid_rmsle: 0.00606 | valid_mae: 0.25705 | valid_rmse: 0.32098 | valid_mse: 0.10303 |  0:00:21s\n",
      "epoch 20 | loss: 0.08152 | train_rmsle: 0.00585 | train_mae: 0.2565  | train_rmse: 0.31528 | train_mse: 0.0994  | valid_rmsle: 0.00603 | valid_mae: 0.25912 | valid_rmse: 0.32143 | valid_mse: 0.10332 |  0:00:22s\n",
      "epoch 21 | loss: 0.07248 | train_rmsle: 0.00445 | train_mae: 0.21627 | train_rmse: 0.27126 | train_mse: 0.07358 | valid_rmsle: 0.00453 | valid_mae: 0.22005 | valid_rmse: 0.27616 | valid_mse: 0.07626 |  0:00:24s\n",
      "epoch 22 | loss: 0.06752 | train_rmsle: 0.00409 | train_mae: 0.20573 | train_rmse: 0.25913 | train_mse: 0.06715 | valid_rmsle: 0.0041  | valid_mae: 0.20932 | valid_rmse: 0.26278 | valid_mse: 0.06906 |  0:00:25s\n",
      "epoch 23 | loss: 0.06426 | train_rmsle: 0.00501 | train_mae: 0.23523 | train_rmse: 0.29049 | train_mse: 0.08438 | valid_rmsle: 0.00526 | valid_mae: 0.23845 | valid_rmse: 0.29925 | valid_mse: 0.08955 |  0:00:26s\n",
      "epoch 24 | loss: 0.05709 | train_rmsle: 0.00389 | train_mae: 0.20206 | train_rmse: 0.25309 | train_mse: 0.06406 | valid_rmsle: 0.00406 | valid_mae: 0.20365 | valid_rmse: 0.26067 | valid_mse: 0.06795 |  0:00:27s\n",
      "epoch 25 | loss: 0.05457 | train_rmsle: 0.00315 | train_mae: 0.18239 | train_rmse: 0.22979 | train_mse: 0.0528  | valid_rmsle: 0.00327 | valid_mae: 0.18693 | valid_rmse: 0.23708 | valid_mse: 0.05621 |  0:00:28s\n",
      "epoch 26 | loss: 0.05101 | train_rmsle: 0.00247 | train_mae: 0.15861 | train_rmse: 0.20292 | train_mse: 0.04118 | valid_rmsle: 0.00256 | valid_mae: 0.16302 | valid_rmse: 0.20944 | valid_mse: 0.04386 |  0:00:29s\n",
      "epoch 27 | loss: 0.04733 | train_rmsle: 0.00225 | train_mae: 0.15001 | train_rmse: 0.19296 | train_mse: 0.03723 | valid_rmsle: 0.00238 | valid_mae: 0.15716 | valid_rmse: 0.20233 | valid_mse: 0.04094 |  0:00:30s\n",
      "epoch 28 | loss: 0.04517 | train_rmsle: 0.00221 | train_mae: 0.1486  | train_rmse: 0.19173 | train_mse: 0.03676 | valid_rmsle: 0.00246 | valid_mae: 0.16015 | valid_rmse: 0.20534 | valid_mse: 0.04216 |  0:00:31s\n",
      "epoch 29 | loss: 0.04221 | train_rmsle: 0.00208 | train_mae: 0.14403 | train_rmse: 0.18736 | train_mse: 0.0351  | valid_rmsle: 0.00234 | valid_mae: 0.15711 | valid_rmse: 0.20165 | valid_mse: 0.04066 |  0:00:32s\n",
      "epoch 30 | loss: 0.03853 | train_rmsle: 0.00181 | train_mae: 0.13447 | train_rmse: 0.17454 | train_mse: 0.03046 | valid_rmsle: 0.00203 | valid_mae: 0.1463  | valid_rmse: 0.18763 | valid_mse: 0.0352  |  0:00:33s\n",
      "epoch 31 | loss: 0.03707 | train_rmsle: 0.00171 | train_mae: 0.13087 | train_rmse: 0.16802 | train_mse: 0.02823 | valid_rmsle: 0.00193 | valid_mae: 0.1421  | valid_rmse: 0.18173 | valid_mse: 0.03303 |  0:00:35s\n",
      "epoch 32 | loss: 0.03388 | train_rmsle: 0.00168 | train_mae: 0.13094 | train_rmse: 0.16755 | train_mse: 0.02807 | valid_rmsle: 0.00185 | valid_mae: 0.13883 | valid_rmse: 0.1788  | valid_mse: 0.03197 |  0:00:36s\n",
      "epoch 33 | loss: 0.03295 | train_rmsle: 0.00151 | train_mae: 0.11919 | train_rmse: 0.15767 | train_mse: 0.02486 | valid_rmsle: 0.00184 | valid_mae: 0.13772 | valid_rmse: 0.17818 | valid_mse: 0.03175 |  0:00:37s\n",
      "epoch 34 | loss: 0.03077 | train_rmsle: 0.00137 | train_mae: 0.11456 | train_rmse: 0.15088 | train_mse: 0.02277 | valid_rmsle: 0.00173 | valid_mae: 0.13491 | valid_rmse: 0.1734  | valid_mse: 0.03007 |  0:00:38s\n",
      "epoch 35 | loss: 0.02844 | train_rmsle: 0.00123 | train_mae: 0.10965 | train_rmse: 0.14452 | train_mse: 0.02089 | valid_rmsle: 0.00157 | valid_mae: 0.12835 | valid_rmse: 0.16694 | valid_mse: 0.02787 |  0:00:39s\n",
      "epoch 36 | loss: 0.03045 | train_rmsle: 0.00135 | train_mae: 0.11615 | train_rmse: 0.15208 | train_mse: 0.02313 | valid_rmsle: 0.00168 | valid_mae: 0.13412 | valid_rmse: 0.17348 | valid_mse: 0.03009 |  0:00:40s\n",
      "epoch 37 | loss: 0.02624 | train_rmsle: 0.0015  | train_mae: 0.12169 | train_rmse: 0.15771 | train_mse: 0.02487 | valid_rmsle: 0.0018  | valid_mae: 0.13816 | valid_rmse: 0.17644 | valid_mse: 0.03113 |  0:00:41s\n",
      "epoch 38 | loss: 0.02569 | train_rmsle: 0.00179 | train_mae: 0.14248 | train_rmse: 0.17645 | train_mse: 0.03114 | valid_rmsle: 0.00211 | valid_mae: 0.15368 | valid_rmse: 0.1944  | valid_mse: 0.03779 |  0:00:42s\n",
      "epoch 39 | loss: 0.02871 | train_rmsle: 0.00099 | train_mae: 0.09852 | train_rmse: 0.13168 | train_mse: 0.01734 | valid_rmsle: 0.00139 | valid_mae: 0.12166 | valid_rmse: 0.158   | valid_mse: 0.02496 |  0:00:43s\n",
      "epoch 40 | loss: 0.02326 | train_rmsle: 0.00109 | train_mae: 0.10408 | train_rmse: 0.13554 | train_mse: 0.01837 | valid_rmsle: 0.00139 | valid_mae: 0.12291 | valid_rmse: 0.15661 | valid_mse: 0.02453 |  0:00:44s\n",
      "epoch 41 | loss: 0.024   | train_rmsle: 0.00096 | train_mae: 0.09743 | train_rmse: 0.12873 | train_mse: 0.01657 | valid_rmsle: 0.00132 | valid_mae: 0.11889 | valid_rmse: 0.15382 | valid_mse: 0.02366 |  0:00:46s\n",
      "epoch 42 | loss: 0.02262 | train_rmsle: 0.00091 | train_mae: 0.09504 | train_rmse: 0.12522 | train_mse: 0.01568 | valid_rmsle: 0.00129 | valid_mae: 0.11641 | valid_rmse: 0.15133 | valid_mse: 0.0229  |  0:00:47s\n",
      "epoch 43 | loss: 0.02177 | train_rmsle: 0.00085 | train_mae: 0.0913  | train_rmse: 0.12205 | train_mse: 0.0149  | valid_rmsle: 0.00125 | valid_mae: 0.11637 | valid_rmse: 0.14984 | valid_mse: 0.02245 |  0:00:48s\n",
      "epoch 44 | loss: 0.0222  | train_rmsle: 0.00099 | train_mae: 0.10285 | train_rmse: 0.1321  | train_mse: 0.01745 | valid_rmsle: 0.00134 | valid_mae: 0.12085 | valid_rmse: 0.15542 | valid_mse: 0.02416 |  0:00:49s\n",
      "epoch 45 | loss: 0.02112 | train_rmsle: 0.00085 | train_mae: 0.08986 | train_rmse: 0.12032 | train_mse: 0.01448 | valid_rmsle: 0.00131 | valid_mae: 0.1177  | valid_rmse: 0.15104 | valid_mse: 0.02281 |  0:00:50s\n",
      "epoch 46 | loss: 0.02141 | train_rmsle: 0.00075 | train_mae: 0.08578 | train_rmse: 0.11605 | train_mse: 0.01347 | valid_rmsle: 0.00118 | valid_mae: 0.11186 | valid_rmse: 0.14569 | valid_mse: 0.02123 |  0:00:51s\n",
      "epoch 47 | loss: 0.01909 | train_rmsle: 0.00077 | train_mae: 0.08768 | train_rmse: 0.11638 | train_mse: 0.01354 | valid_rmsle: 0.0012  | valid_mae: 0.11392 | valid_rmse: 0.14708 | valid_mse: 0.02163 |  0:00:52s\n",
      "epoch 48 | loss: 0.01994 | train_rmsle: 0.00092 | train_mae: 0.09923 | train_rmse: 0.12853 | train_mse: 0.01652 | valid_rmsle: 0.00138 | valid_mae: 0.12529 | valid_rmse: 0.159   | valid_mse: 0.02528 |  0:00:53s\n",
      "epoch 49 | loss: 0.01904 | train_rmsle: 0.00064 | train_mae: 0.07815 | train_rmse: 0.10573 | train_mse: 0.01118 | valid_rmsle: 0.00107 | valid_mae: 0.10625 | valid_rmse: 0.13886 | valid_mse: 0.01928 |  0:00:54s\n",
      "epoch 50 | loss: 0.01799 | train_rmsle: 0.00064 | train_mae: 0.07809 | train_rmse: 0.1062  | train_mse: 0.01128 | valid_rmsle: 0.00106 | valid_mae: 0.10562 | valid_rmse: 0.1381  | valid_mse: 0.01907 |  0:00:55s\n",
      "epoch 51 | loss: 0.01738 | train_rmsle: 0.00105 | train_mae: 0.1094  | train_rmse: 0.13432 | train_mse: 0.01804 | valid_rmsle: 0.00148 | valid_mae: 0.12837 | valid_rmse: 0.16182 | valid_mse: 0.02619 |  0:00:56s\n",
      "epoch 52 | loss: 0.0242  | train_rmsle: 0.00106 | train_mae: 0.10526 | train_rmse: 0.13275 | train_mse: 0.01762 | valid_rmsle: 0.00159 | valid_mae: 0.12885 | valid_rmse: 0.16556 | valid_mse: 0.02741 |  0:00:58s\n",
      "epoch 53 | loss: 0.02045 | train_rmsle: 0.00085 | train_mae: 0.08273 | train_rmse: 0.11746 | train_mse: 0.0138  | valid_rmsle: 0.00135 | valid_mae: 0.1108  | valid_rmse: 0.1513  | valid_mse: 0.02289 |  0:00:59s\n",
      "epoch 54 | loss: 0.02016 | train_rmsle: 0.00116 | train_mae: 0.11838 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00157 | valid_mae: 0.13486 | valid_rmse: 0.17147 | valid_mse: 0.0294  |  0:01:00s\n",
      "epoch 55 | loss: 0.01841 | train_rmsle: 0.00058 | train_mae: 0.07578 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00099 | valid_mae: 0.1025  | valid_rmse: 0.13446 | valid_mse: 0.01808 |  0:01:01s\n",
      "epoch 56 | loss: 0.0161  | train_rmsle: 0.00065 | train_mae: 0.07923 | train_rmse: 0.10638 | train_mse: 0.01132 | valid_rmsle: 0.00106 | valid_mae: 0.10562 | valid_rmse: 0.13728 | valid_mse: 0.01885 |  0:01:02s\n",
      "epoch 57 | loss: 0.01521 | train_rmsle: 0.00056 | train_mae: 0.07342 | train_rmse: 0.0971  | train_mse: 0.00943 | valid_rmsle: 0.00098 | valid_mae: 0.10094 | valid_rmse: 0.1319  | valid_mse: 0.0174  |  0:01:03s\n",
      "epoch 58 | loss: 0.0149  | train_rmsle: 0.00049 | train_mae: 0.06868 | train_rmse: 0.09191 | train_mse: 0.00845 | valid_rmsle: 0.00092 | valid_mae: 0.09662 | valid_rmse: 0.12803 | valid_mse: 0.01639 |  0:01:04s\n",
      "epoch 59 | loss: 0.01449 | train_rmsle: 0.00049 | train_mae: 0.06928 | train_rmse: 0.09197 | train_mse: 0.00846 | valid_rmsle: 0.0009  | valid_mae: 0.09668 | valid_rmse: 0.12715 | valid_mse: 0.01617 |  0:01:05s\n",
      "epoch 60 | loss: 0.01417 | train_rmsle: 0.0007  | train_mae: 0.08991 | train_rmse: 0.11524 | train_mse: 0.01328 | valid_rmsle: 0.00112 | valid_mae: 0.11363 | valid_rmse: 0.14538 | valid_mse: 0.02114 |  0:01:06s\n",
      "epoch 61 | loss: 0.01627 | train_rmsle: 0.00048 | train_mae: 0.06875 | train_rmse: 0.09059 | train_mse: 0.00821 | valid_rmsle: 0.00087 | valid_mae: 0.09474 | valid_rmse: 0.12417 | valid_mse: 0.01542 |  0:01:07s\n",
      "epoch 62 | loss: 0.01374 | train_rmsle: 0.0005  | train_mae: 0.07178 | train_rmse: 0.09485 | train_mse: 0.009   | valid_rmsle: 0.00088 | valid_mae: 0.09755 | valid_rmse: 0.12629 | valid_mse: 0.01595 |  0:01:09s\n",
      "epoch 63 | loss: 0.01461 | train_rmsle: 0.00063 | train_mae: 0.07918 | train_rmse: 0.10355 | train_mse: 0.01072 | valid_rmsle: 0.00102 | valid_mae: 0.10455 | valid_rmse: 0.13381 | valid_mse: 0.01791 |  0:01:10s\n",
      "epoch 64 | loss: 0.01675 | train_rmsle: 0.0006  | train_mae: 0.07811 | train_rmse: 0.10297 | train_mse: 0.0106  | valid_rmsle: 0.00103 | valid_mae: 0.10458 | valid_rmse: 0.13639 | valid_mse: 0.0186  |  0:01:11s\n",
      "epoch 65 | loss: 0.01735 | train_rmsle: 0.00147 | train_mae: 0.13071 | train_rmse: 0.15792 | train_mse: 0.02494 | valid_rmsle: 0.00185 | valid_mae: 0.14572 | valid_rmse: 0.17968 | valid_mse: 0.03228 |  0:01:12s\n",
      "epoch 66 | loss: 0.02068 | train_rmsle: 0.00063 | train_mae: 0.08248 | train_rmse: 0.10746 | train_mse: 0.01155 | valid_rmsle: 0.00103 | valid_mae: 0.10393 | valid_rmse: 0.13656 | valid_mse: 0.01865 |  0:01:13s\n",
      "epoch 67 | loss: 0.01504 | train_rmsle: 0.00053 | train_mae: 0.07459 | train_rmse: 0.09624 | train_mse: 0.00926 | valid_rmsle: 0.00088 | valid_mae: 0.09606 | valid_rmse: 0.12567 | valid_mse: 0.01579 |  0:01:14s\n",
      "epoch 68 | loss: 0.01244 | train_rmsle: 0.00048 | train_mae: 0.06998 | train_rmse: 0.09335 | train_mse: 0.00871 | valid_rmsle: 0.00088 | valid_mae: 0.09611 | valid_rmse: 0.12569 | valid_mse: 0.0158  |  0:01:15s\n",
      "epoch 69 | loss: 0.01269 | train_rmsle: 0.00071 | train_mae: 0.08341 | train_rmse: 0.10586 | train_mse: 0.01121 | valid_rmsle: 0.00113 | valid_mae: 0.10886 | valid_rmse: 0.1372  | valid_mse: 0.01882 |  0:01:16s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 61 and best_valid_mse = 0.01542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.017341279710729244 RMSE: 0.13168629279742536 R2: 0.9232368366377838 MAE: 0.10229790689064952\n",
      "=====================================\n",
      "[74/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.2155  | train_rmsle: 0.29421 | train_mae: 1.77156 | train_rmse: 1.83625 | train_mse: 3.37182 | valid_rmsle: 0.2946  | valid_mae: 1.77586 | valid_rmse: 1.83905 | valid_mse: 3.38209 |  0:00:01s\n",
      "epoch 1  | loss: 0.55652 | train_rmsle: 0.18138 | train_mae: 1.45494 | train_rmse: 1.53022 | train_mse: 2.34156 | valid_rmsle: 0.18231 | valid_mae: 1.45983 | valid_rmse: 1.53503 | valid_mse: 2.35631 |  0:00:02s\n",
      "epoch 2  | loss: 0.31222 | train_rmsle: 0.08749 | train_mae: 1.0515  | train_rmse: 1.14064 | train_mse: 1.30106 | valid_rmsle: 0.08791 | valid_mae: 1.05458 | valid_rmse: 1.14469 | valid_mse: 1.31032 |  0:00:03s\n",
      "epoch 3  | loss: 0.26067 | train_rmsle: 0.04778 | train_mae: 0.78799 | train_rmse: 0.88016 | train_mse: 0.77468 | valid_rmsle: 0.04773 | valid_mae: 0.7878  | valid_rmse: 0.88204 | valid_mse: 0.77799 |  0:00:04s\n",
      "epoch 4  | loss: 0.23257 | train_rmsle: 0.03007 | train_mae: 0.62276 | train_rmse: 0.71375 | train_mse: 0.50943 | valid_rmsle: 0.02979 | valid_mae: 0.62207 | valid_rmse: 0.71375 | valid_mse: 0.50944 |  0:00:05s\n",
      "epoch 5  | loss: 0.2242  | train_rmsle: 0.01861 | train_mae: 0.476   | train_rmse: 0.56347 | train_mse: 0.3175  | valid_rmsle: 0.01832 | valid_mae: 0.47826 | valid_rmse: 0.56358 | valid_mse: 0.31762 |  0:00:06s\n",
      "epoch 6  | loss: 0.21821 | train_rmsle: 0.0174  | train_mae: 0.45645 | train_rmse: 0.54421 | train_mse: 0.29617 | valid_rmsle: 0.01702 | valid_mae: 0.4578  | valid_rmse: 0.54256 | valid_mse: 0.29437 |  0:00:07s\n",
      "epoch 7  | loss: 0.22083 | train_rmsle: 0.02095 | train_mae: 0.51079 | train_rmse: 0.59989 | train_mse: 0.35986 | valid_rmsle: 0.0206  | valid_mae: 0.51161 | valid_rmse: 0.59849 | valid_mse: 0.35819 |  0:00:08s\n",
      "epoch 8  | loss: 0.22938 | train_rmsle: 0.01479 | train_mae: 0.40928 | train_rmse: 0.49716 | train_mse: 0.24717 | valid_rmsle: 0.01444 | valid_mae: 0.41082 | valid_rmse: 0.49643 | valid_mse: 0.24645 |  0:00:09s\n",
      "epoch 9  | loss: 0.21044 | train_rmsle: 0.01368 | train_mae: 0.38531 | train_rmse: 0.47398 | train_mse: 0.22465 | valid_rmsle: 0.01349 | valid_mae: 0.39031 | valid_rmse: 0.47643 | valid_mse: 0.22698 |  0:00:10s\n",
      "epoch 10 | loss: 0.20528 | train_rmsle: 0.01454 | train_mae: 0.40642 | train_rmse: 0.49373 | train_mse: 0.24377 | valid_rmsle: 0.01465 | valid_mae: 0.41213 | valid_rmse: 0.50037 | valid_mse: 0.25037 |  0:00:11s\n",
      "epoch 11 | loss: 0.20287 | train_rmsle: 0.01353 | train_mae: 0.39097 | train_rmse: 0.4773  | train_mse: 0.22781 | valid_rmsle: 0.01377 | valid_mae: 0.3968  | valid_rmse: 0.4864  | valid_mse: 0.23659 |  0:00:12s\n",
      "epoch 12 | loss: 0.19711 | train_rmsle: 0.01115 | train_mae: 0.34441 | train_rmse: 0.42614 | train_mse: 0.18159 | valid_rmsle: 0.01103 | valid_mae: 0.34871 | valid_rmse: 0.42961 | valid_mse: 0.18456 |  0:00:13s\n",
      "epoch 13 | loss: 0.18554 | train_rmsle: 0.01057 | train_mae: 0.33728 | train_rmse: 0.41803 | train_mse: 0.17475 | valid_rmsle: 0.01066 | valid_mae: 0.34573 | valid_rmse: 0.42509 | valid_mse: 0.1807  |  0:00:15s\n",
      "epoch 14 | loss: 0.173   | train_rmsle: 0.00828 | train_mae: 0.29115 | train_rmse: 0.36542 | train_mse: 0.13353 | valid_rmsle: 0.00811 | valid_mae: 0.29179 | valid_rmse: 0.3662  | valid_mse: 0.1341  |  0:00:16s\n",
      "epoch 15 | loss: 0.15734 | train_rmsle: 0.00987 | train_mae: 0.34353 | train_rmse: 0.41318 | train_mse: 0.17072 | valid_rmsle: 0.00968 | valid_mae: 0.34125 | valid_rmse: 0.41209 | valid_mse: 0.16982 |  0:00:17s\n",
      "epoch 16 | loss: 0.13573 | train_rmsle: 0.00816 | train_mae: 0.30458 | train_rmse: 0.37464 | train_mse: 0.14036 | valid_rmsle: 0.00826 | valid_mae: 0.30579 | valid_rmse: 0.3778  | valid_mse: 0.14274 |  0:00:18s\n",
      "epoch 17 | loss: 0.11473 | train_rmsle: 0.00729 | train_mae: 0.28538 | train_rmse: 0.35314 | train_mse: 0.12471 | valid_rmsle: 0.00748 | valid_mae: 0.28999 | valid_rmse: 0.35813 | valid_mse: 0.12825 |  0:00:19s\n",
      "epoch 18 | loss: 0.09655 | train_rmsle: 0.00682 | train_mae: 0.2792  | train_rmse: 0.34121 | train_mse: 0.11643 | valid_rmsle: 0.00688 | valid_mae: 0.2814  | valid_rmse: 0.34369 | valid_mse: 0.11812 |  0:00:20s\n",
      "epoch 19 | loss: 0.08762 | train_rmsle: 0.00577 | train_mae: 0.25033 | train_rmse: 0.3119  | train_mse: 0.09728 | valid_rmsle: 0.00606 | valid_mae: 0.25705 | valid_rmse: 0.32098 | valid_mse: 0.10303 |  0:00:21s\n",
      "epoch 20 | loss: 0.08152 | train_rmsle: 0.00585 | train_mae: 0.2565  | train_rmse: 0.31528 | train_mse: 0.0994  | valid_rmsle: 0.00603 | valid_mae: 0.25912 | valid_rmse: 0.32143 | valid_mse: 0.10332 |  0:00:22s\n",
      "epoch 21 | loss: 0.07248 | train_rmsle: 0.00445 | train_mae: 0.21627 | train_rmse: 0.27126 | train_mse: 0.07358 | valid_rmsle: 0.00453 | valid_mae: 0.22005 | valid_rmse: 0.27616 | valid_mse: 0.07626 |  0:00:23s\n",
      "epoch 22 | loss: 0.06752 | train_rmsle: 0.00409 | train_mae: 0.20573 | train_rmse: 0.25913 | train_mse: 0.06715 | valid_rmsle: 0.0041  | valid_mae: 0.20932 | valid_rmse: 0.26278 | valid_mse: 0.06906 |  0:00:24s\n",
      "epoch 23 | loss: 0.06426 | train_rmsle: 0.00501 | train_mae: 0.23523 | train_rmse: 0.29049 | train_mse: 0.08438 | valid_rmsle: 0.00526 | valid_mae: 0.23845 | valid_rmse: 0.29925 | valid_mse: 0.08955 |  0:00:25s\n",
      "epoch 24 | loss: 0.05709 | train_rmsle: 0.00389 | train_mae: 0.20206 | train_rmse: 0.25309 | train_mse: 0.06406 | valid_rmsle: 0.00406 | valid_mae: 0.20365 | valid_rmse: 0.26067 | valid_mse: 0.06795 |  0:00:27s\n",
      "epoch 25 | loss: 0.05457 | train_rmsle: 0.00315 | train_mae: 0.18239 | train_rmse: 0.22979 | train_mse: 0.0528  | valid_rmsle: 0.00327 | valid_mae: 0.18693 | valid_rmse: 0.23708 | valid_mse: 0.05621 |  0:00:28s\n",
      "epoch 26 | loss: 0.05101 | train_rmsle: 0.00247 | train_mae: 0.15861 | train_rmse: 0.20292 | train_mse: 0.04118 | valid_rmsle: 0.00256 | valid_mae: 0.16302 | valid_rmse: 0.20944 | valid_mse: 0.04386 |  0:00:29s\n",
      "epoch 27 | loss: 0.04733 | train_rmsle: 0.00225 | train_mae: 0.15001 | train_rmse: 0.19296 | train_mse: 0.03723 | valid_rmsle: 0.00238 | valid_mae: 0.15716 | valid_rmse: 0.20233 | valid_mse: 0.04094 |  0:00:30s\n",
      "epoch 28 | loss: 0.04517 | train_rmsle: 0.00221 | train_mae: 0.1486  | train_rmse: 0.19173 | train_mse: 0.03676 | valid_rmsle: 0.00246 | valid_mae: 0.16015 | valid_rmse: 0.20534 | valid_mse: 0.04216 |  0:00:31s\n",
      "epoch 29 | loss: 0.04221 | train_rmsle: 0.00208 | train_mae: 0.14403 | train_rmse: 0.18736 | train_mse: 0.0351  | valid_rmsle: 0.00234 | valid_mae: 0.15711 | valid_rmse: 0.20165 | valid_mse: 0.04066 |  0:00:32s\n",
      "epoch 30 | loss: 0.03853 | train_rmsle: 0.00181 | train_mae: 0.13447 | train_rmse: 0.17454 | train_mse: 0.03046 | valid_rmsle: 0.00203 | valid_mae: 0.1463  | valid_rmse: 0.18763 | valid_mse: 0.0352  |  0:00:33s\n",
      "epoch 31 | loss: 0.03707 | train_rmsle: 0.00171 | train_mae: 0.13087 | train_rmse: 0.16802 | train_mse: 0.02823 | valid_rmsle: 0.00193 | valid_mae: 0.1421  | valid_rmse: 0.18173 | valid_mse: 0.03303 |  0:00:34s\n",
      "epoch 32 | loss: 0.03388 | train_rmsle: 0.00168 | train_mae: 0.13094 | train_rmse: 0.16755 | train_mse: 0.02807 | valid_rmsle: 0.00185 | valid_mae: 0.13883 | valid_rmse: 0.1788  | valid_mse: 0.03197 |  0:00:35s\n",
      "epoch 33 | loss: 0.03295 | train_rmsle: 0.00151 | train_mae: 0.11919 | train_rmse: 0.15767 | train_mse: 0.02486 | valid_rmsle: 0.00184 | valid_mae: 0.13772 | valid_rmse: 0.17818 | valid_mse: 0.03175 |  0:00:36s\n",
      "epoch 34 | loss: 0.03077 | train_rmsle: 0.00137 | train_mae: 0.11456 | train_rmse: 0.15088 | train_mse: 0.02277 | valid_rmsle: 0.00173 | valid_mae: 0.13491 | valid_rmse: 0.1734  | valid_mse: 0.03007 |  0:00:38s\n",
      "epoch 35 | loss: 0.02844 | train_rmsle: 0.00123 | train_mae: 0.10965 | train_rmse: 0.14452 | train_mse: 0.02089 | valid_rmsle: 0.00157 | valid_mae: 0.12835 | valid_rmse: 0.16694 | valid_mse: 0.02787 |  0:00:39s\n",
      "epoch 36 | loss: 0.03045 | train_rmsle: 0.00135 | train_mae: 0.11615 | train_rmse: 0.15208 | train_mse: 0.02313 | valid_rmsle: 0.00168 | valid_mae: 0.13412 | valid_rmse: 0.17348 | valid_mse: 0.03009 |  0:00:40s\n",
      "epoch 37 | loss: 0.02624 | train_rmsle: 0.0015  | train_mae: 0.12169 | train_rmse: 0.15771 | train_mse: 0.02487 | valid_rmsle: 0.0018  | valid_mae: 0.13816 | valid_rmse: 0.17644 | valid_mse: 0.03113 |  0:00:41s\n",
      "epoch 38 | loss: 0.02569 | train_rmsle: 0.00179 | train_mae: 0.14248 | train_rmse: 0.17645 | train_mse: 0.03114 | valid_rmsle: 0.00211 | valid_mae: 0.15368 | valid_rmse: 0.1944  | valid_mse: 0.03779 |  0:00:42s\n",
      "epoch 39 | loss: 0.02871 | train_rmsle: 0.00099 | train_mae: 0.09852 | train_rmse: 0.13168 | train_mse: 0.01734 | valid_rmsle: 0.00139 | valid_mae: 0.12166 | valid_rmse: 0.158   | valid_mse: 0.02496 |  0:00:43s\n",
      "epoch 40 | loss: 0.02326 | train_rmsle: 0.00109 | train_mae: 0.10408 | train_rmse: 0.13554 | train_mse: 0.01837 | valid_rmsle: 0.00139 | valid_mae: 0.12291 | valid_rmse: 0.15661 | valid_mse: 0.02453 |  0:00:44s\n",
      "epoch 41 | loss: 0.024   | train_rmsle: 0.00096 | train_mae: 0.09743 | train_rmse: 0.12873 | train_mse: 0.01657 | valid_rmsle: 0.00132 | valid_mae: 0.11889 | valid_rmse: 0.15382 | valid_mse: 0.02366 |  0:00:45s\n",
      "epoch 42 | loss: 0.02262 | train_rmsle: 0.00091 | train_mae: 0.09504 | train_rmse: 0.12522 | train_mse: 0.01568 | valid_rmsle: 0.00129 | valid_mae: 0.11641 | valid_rmse: 0.15133 | valid_mse: 0.0229  |  0:00:46s\n",
      "epoch 43 | loss: 0.02177 | train_rmsle: 0.00085 | train_mae: 0.0913  | train_rmse: 0.12205 | train_mse: 0.0149  | valid_rmsle: 0.00125 | valid_mae: 0.11637 | valid_rmse: 0.14984 | valid_mse: 0.02245 |  0:00:47s\n",
      "epoch 44 | loss: 0.0222  | train_rmsle: 0.00099 | train_mae: 0.10285 | train_rmse: 0.1321  | train_mse: 0.01745 | valid_rmsle: 0.00134 | valid_mae: 0.12085 | valid_rmse: 0.15542 | valid_mse: 0.02416 |  0:00:49s\n",
      "epoch 45 | loss: 0.02112 | train_rmsle: 0.00085 | train_mae: 0.08986 | train_rmse: 0.12032 | train_mse: 0.01448 | valid_rmsle: 0.00131 | valid_mae: 0.1177  | valid_rmse: 0.15104 | valid_mse: 0.02281 |  0:00:50s\n",
      "epoch 46 | loss: 0.02141 | train_rmsle: 0.00075 | train_mae: 0.08578 | train_rmse: 0.11605 | train_mse: 0.01347 | valid_rmsle: 0.00118 | valid_mae: 0.11186 | valid_rmse: 0.14569 | valid_mse: 0.02123 |  0:00:51s\n",
      "epoch 47 | loss: 0.01909 | train_rmsle: 0.00077 | train_mae: 0.08768 | train_rmse: 0.11638 | train_mse: 0.01354 | valid_rmsle: 0.0012  | valid_mae: 0.11392 | valid_rmse: 0.14708 | valid_mse: 0.02163 |  0:00:52s\n",
      "epoch 48 | loss: 0.01994 | train_rmsle: 0.00092 | train_mae: 0.09923 | train_rmse: 0.12853 | train_mse: 0.01652 | valid_rmsle: 0.00138 | valid_mae: 0.12529 | valid_rmse: 0.159   | valid_mse: 0.02528 |  0:00:53s\n",
      "epoch 49 | loss: 0.01904 | train_rmsle: 0.00064 | train_mae: 0.07815 | train_rmse: 0.10573 | train_mse: 0.01118 | valid_rmsle: 0.00107 | valid_mae: 0.10625 | valid_rmse: 0.13886 | valid_mse: 0.01928 |  0:00:54s\n",
      "epoch 50 | loss: 0.01799 | train_rmsle: 0.00064 | train_mae: 0.07809 | train_rmse: 0.1062  | train_mse: 0.01128 | valid_rmsle: 0.00106 | valid_mae: 0.10562 | valid_rmse: 0.1381  | valid_mse: 0.01907 |  0:00:55s\n",
      "epoch 51 | loss: 0.01738 | train_rmsle: 0.00105 | train_mae: 0.1094  | train_rmse: 0.13432 | train_mse: 0.01804 | valid_rmsle: 0.00148 | valid_mae: 0.12837 | valid_rmse: 0.16182 | valid_mse: 0.02619 |  0:00:56s\n",
      "epoch 52 | loss: 0.0242  | train_rmsle: 0.00106 | train_mae: 0.10526 | train_rmse: 0.13275 | train_mse: 0.01762 | valid_rmsle: 0.00159 | valid_mae: 0.12885 | valid_rmse: 0.16556 | valid_mse: 0.02741 |  0:00:57s\n",
      "epoch 53 | loss: 0.02045 | train_rmsle: 0.00085 | train_mae: 0.08273 | train_rmse: 0.11746 | train_mse: 0.0138  | valid_rmsle: 0.00135 | valid_mae: 0.1108  | valid_rmse: 0.1513  | valid_mse: 0.02289 |  0:00:58s\n",
      "epoch 54 | loss: 0.02016 | train_rmsle: 0.00116 | train_mae: 0.11838 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00157 | valid_mae: 0.13486 | valid_rmse: 0.17147 | valid_mse: 0.0294  |  0:00:59s\n",
      "epoch 55 | loss: 0.01841 | train_rmsle: 0.00058 | train_mae: 0.07578 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00099 | valid_mae: 0.1025  | valid_rmse: 0.13446 | valid_mse: 0.01808 |  0:01:01s\n",
      "epoch 56 | loss: 0.0161  | train_rmsle: 0.00065 | train_mae: 0.07923 | train_rmse: 0.10638 | train_mse: 0.01132 | valid_rmsle: 0.00106 | valid_mae: 0.10562 | valid_rmse: 0.13728 | valid_mse: 0.01885 |  0:01:02s\n",
      "epoch 57 | loss: 0.01521 | train_rmsle: 0.00056 | train_mae: 0.07342 | train_rmse: 0.0971  | train_mse: 0.00943 | valid_rmsle: 0.00098 | valid_mae: 0.10094 | valid_rmse: 0.1319  | valid_mse: 0.0174  |  0:01:03s\n",
      "epoch 58 | loss: 0.0149  | train_rmsle: 0.00049 | train_mae: 0.06868 | train_rmse: 0.09191 | train_mse: 0.00845 | valid_rmsle: 0.00092 | valid_mae: 0.09662 | valid_rmse: 0.12803 | valid_mse: 0.01639 |  0:01:04s\n",
      "epoch 59 | loss: 0.01449 | train_rmsle: 0.00049 | train_mae: 0.06928 | train_rmse: 0.09197 | train_mse: 0.00846 | valid_rmsle: 0.0009  | valid_mae: 0.09668 | valid_rmse: 0.12715 | valid_mse: 0.01617 |  0:01:05s\n",
      "epoch 60 | loss: 0.01417 | train_rmsle: 0.0007  | train_mae: 0.08991 | train_rmse: 0.11524 | train_mse: 0.01328 | valid_rmsle: 0.00112 | valid_mae: 0.11363 | valid_rmse: 0.14538 | valid_mse: 0.02114 |  0:01:06s\n",
      "epoch 61 | loss: 0.01627 | train_rmsle: 0.00048 | train_mae: 0.06875 | train_rmse: 0.09059 | train_mse: 0.00821 | valid_rmsle: 0.00087 | valid_mae: 0.09474 | valid_rmse: 0.12417 | valid_mse: 0.01542 |  0:01:07s\n",
      "epoch 62 | loss: 0.01374 | train_rmsle: 0.0005  | train_mae: 0.07178 | train_rmse: 0.09485 | train_mse: 0.009   | valid_rmsle: 0.00088 | valid_mae: 0.09755 | valid_rmse: 0.12629 | valid_mse: 0.01595 |  0:01:08s\n",
      "epoch 63 | loss: 0.01461 | train_rmsle: 0.00063 | train_mae: 0.07918 | train_rmse: 0.10355 | train_mse: 0.01072 | valid_rmsle: 0.00102 | valid_mae: 0.10455 | valid_rmse: 0.13381 | valid_mse: 0.01791 |  0:01:09s\n",
      "epoch 64 | loss: 0.01675 | train_rmsle: 0.0006  | train_mae: 0.07811 | train_rmse: 0.10297 | train_mse: 0.0106  | valid_rmsle: 0.00103 | valid_mae: 0.10458 | valid_rmse: 0.13639 | valid_mse: 0.0186  |  0:01:10s\n",
      "epoch 65 | loss: 0.01735 | train_rmsle: 0.00147 | train_mae: 0.13071 | train_rmse: 0.15792 | train_mse: 0.02494 | valid_rmsle: 0.00185 | valid_mae: 0.14572 | valid_rmse: 0.17968 | valid_mse: 0.03228 |  0:01:12s\n",
      "epoch 66 | loss: 0.02068 | train_rmsle: 0.00063 | train_mae: 0.08248 | train_rmse: 0.10746 | train_mse: 0.01155 | valid_rmsle: 0.00103 | valid_mae: 0.10393 | valid_rmse: 0.13656 | valid_mse: 0.01865 |  0:01:13s\n",
      "epoch 67 | loss: 0.01504 | train_rmsle: 0.00053 | train_mae: 0.07459 | train_rmse: 0.09624 | train_mse: 0.00926 | valid_rmsle: 0.00088 | valid_mae: 0.09606 | valid_rmse: 0.12567 | valid_mse: 0.01579 |  0:01:14s\n",
      "epoch 68 | loss: 0.01244 | train_rmsle: 0.00048 | train_mae: 0.06998 | train_rmse: 0.09335 | train_mse: 0.00871 | valid_rmsle: 0.00088 | valid_mae: 0.09611 | valid_rmse: 0.12569 | valid_mse: 0.0158  |  0:01:15s\n",
      "epoch 69 | loss: 0.01269 | train_rmsle: 0.00071 | train_mae: 0.08341 | train_rmse: 0.10586 | train_mse: 0.01121 | valid_rmsle: 0.00113 | valid_mae: 0.10886 | valid_rmse: 0.1372  | valid_mse: 0.01882 |  0:01:16s\n",
      "epoch 70 | loss: 0.01455 | train_rmsle: 0.00057 | train_mae: 0.07919 | train_rmse: 0.09901 | train_mse: 0.0098  | valid_rmsle: 0.00097 | valid_mae: 0.10228 | valid_rmse: 0.13097 | valid_mse: 0.01715 |  0:01:17s\n",
      "epoch 71 | loss: 0.01377 | train_rmsle: 0.00055 | train_mae: 0.07781 | train_rmse: 0.09783 | train_mse: 0.00957 | valid_rmsle: 0.00096 | valid_mae: 0.10211 | valid_rmse: 0.12959 | valid_mse: 0.01679 |  0:01:18s\n",
      "epoch 72 | loss: 0.01354 | train_rmsle: 0.00037 | train_mae: 0.06129 | train_rmse: 0.08059 | train_mse: 0.00649 | valid_rmsle: 0.00079 | valid_mae: 0.08974 | valid_rmse: 0.11828 | valid_mse: 0.01399 |  0:01:19s\n",
      "epoch 73 | loss: 0.01564 | train_rmsle: 0.00038 | train_mae: 0.06153 | train_rmse: 0.08271 | train_mse: 0.00684 | valid_rmsle: 0.00077 | valid_mae: 0.08881 | valid_rmse: 0.11811 | valid_mse: 0.01395 |  0:01:20s\n",
      "epoch 74 | loss: 0.01201 | train_rmsle: 0.00035 | train_mae: 0.06105 | train_rmse: 0.08029 | train_mse: 0.00645 | valid_rmsle: 0.0008  | valid_mae: 0.09047 | valid_rmse: 0.12007 | valid_mse: 0.01442 |  0:01:21s\n",
      "epoch 75 | loss: 0.01388 | train_rmsle: 0.00053 | train_mae: 0.07732 | train_rmse: 0.09776 | train_mse: 0.00956 | valid_rmsle: 0.00101 | valid_mae: 0.10499 | valid_rmse: 0.13536 | valid_mse: 0.01832 |  0:01:22s\n",
      "epoch 76 | loss: 0.01281 | train_rmsle: 0.00046 | train_mae: 0.07264 | train_rmse: 0.09205 | train_mse: 0.00847 | valid_rmsle: 0.00092 | valid_mae: 0.09978 | valid_rmse: 0.12984 | valid_mse: 0.01686 |  0:01:24s\n",
      "epoch 77 | loss: 0.01224 | train_rmsle: 0.00042 | train_mae: 0.06793 | train_rmse: 0.0856  | train_mse: 0.00733 | valid_rmsle: 0.00085 | valid_mae: 0.09487 | valid_rmse: 0.12295 | valid_mse: 0.01512 |  0:01:25s\n",
      "epoch 78 | loss: 0.01195 | train_rmsle: 0.00053 | train_mae: 0.07083 | train_rmse: 0.09043 | train_mse: 0.00818 | valid_rmsle: 0.00095 | valid_mae: 0.09739 | valid_rmse: 0.12555 | valid_mse: 0.01576 |  0:01:26s\n",
      "epoch 79 | loss: 0.01158 | train_rmsle: 0.00033 | train_mae: 0.05839 | train_rmse: 0.07731 | train_mse: 0.00598 | valid_rmsle: 0.00076 | valid_mae: 0.08874 | valid_rmse: 0.11694 | valid_mse: 0.01367 |  0:01:27s\n",
      "epoch 80 | loss: 0.01426 | train_rmsle: 0.0006  | train_mae: 0.0763  | train_rmse: 0.09623 | train_mse: 0.00926 | valid_rmsle: 0.00099 | valid_mae: 0.09926 | valid_rmse: 0.1275  | valid_mse: 0.01626 |  0:01:28s\n",
      "epoch 81 | loss: 0.01411 | train_rmsle: 0.00066 | train_mae: 0.09176 | train_rmse: 0.11099 | train_mse: 0.01232 | valid_rmsle: 0.00109 | valid_mae: 0.11316 | valid_rmse: 0.14133 | valid_mse: 0.01997 |  0:01:29s\n",
      "epoch 82 | loss: 0.01427 | train_rmsle: 0.00046 | train_mae: 0.07212 | train_rmse: 0.08956 | train_mse: 0.00802 | valid_rmsle: 0.00087 | valid_mae: 0.09667 | valid_rmse: 0.12416 | valid_mse: 0.01542 |  0:01:30s\n",
      "epoch 83 | loss: 0.01166 | train_rmsle: 0.00041 | train_mae: 0.06736 | train_rmse: 0.08621 | train_mse: 0.00743 | valid_rmsle: 0.00081 | valid_mae: 0.09298 | valid_rmse: 0.12119 | valid_mse: 0.01469 |  0:01:31s\n",
      "epoch 84 | loss: 0.01301 | train_rmsle: 0.00047 | train_mae: 0.06957 | train_rmse: 0.09212 | train_mse: 0.00849 | valid_rmsle: 0.00085 | valid_mae: 0.09436 | valid_rmse: 0.12433 | valid_mse: 0.01546 |  0:01:32s\n",
      "epoch 85 | loss: 0.01271 | train_rmsle: 0.00057 | train_mae: 0.07213 | train_rmse: 0.09577 | train_mse: 0.00917 | valid_rmsle: 0.00099 | valid_mae: 0.09776 | valid_rmse: 0.12997 | valid_mse: 0.01689 |  0:01:33s\n",
      "epoch 86 | loss: 0.01208 | train_rmsle: 0.00034 | train_mae: 0.06019 | train_rmse: 0.07949 | train_mse: 0.00632 | valid_rmsle: 0.00078 | valid_mae: 0.08898 | valid_rmse: 0.11838 | valid_mse: 0.01401 |  0:01:34s\n",
      "epoch 87 | loss: 0.01437 | train_rmsle: 0.00141 | train_mae: 0.14317 | train_rmse: 0.16157 | train_mse: 0.0261  | valid_rmsle: 0.00186 | valid_mae: 0.15334 | valid_rmse: 0.1839  | valid_mse: 0.03382 |  0:01:35s\n",
      "epoch 88 | loss: 0.01857 | train_rmsle: 0.00051 | train_mae: 0.07234 | train_rmse: 0.09782 | train_mse: 0.00957 | valid_rmsle: 0.00093 | valid_mae: 0.09855 | valid_rmse: 0.12995 | valid_mse: 0.01689 |  0:01:37s\n",
      "epoch 89 | loss: 0.01461 | train_rmsle: 0.00057 | train_mae: 0.07719 | train_rmse: 0.10024 | train_mse: 0.01005 | valid_rmsle: 0.00096 | valid_mae: 0.09858 | valid_rmse: 0.12863 | valid_mse: 0.01655 |  0:01:38s\n",
      "epoch 90 | loss: 0.01455 | train_rmsle: 0.00141 | train_mae: 0.11548 | train_rmse: 0.14151 | train_mse: 0.02002 | valid_rmsle: 0.00174 | valid_mae: 0.13098 | valid_rmse: 0.16173 | valid_mse: 0.02616 |  0:01:39s\n",
      "epoch 91 | loss: 0.01507 | train_rmsle: 0.00049 | train_mae: 0.07219 | train_rmse: 0.09122 | train_mse: 0.00832 | valid_rmsle: 0.00088 | valid_mae: 0.0948  | valid_rmse: 0.12339 | valid_mse: 0.01523 |  0:01:40s\n",
      "epoch 92 | loss: 0.0141  | train_rmsle: 0.00034 | train_mae: 0.06074 | train_rmse: 0.07933 | train_mse: 0.00629 | valid_rmsle: 0.00075 | valid_mae: 0.08659 | valid_rmse: 0.11512 | valid_mse: 0.01325 |  0:01:41s\n",
      "epoch 93 | loss: 0.01373 | train_rmsle: 0.00058 | train_mae: 0.07543 | train_rmse: 0.0969  | train_mse: 0.00939 | valid_rmsle: 0.00097 | valid_mae: 0.09762 | valid_rmse: 0.1272  | valid_mse: 0.01618 |  0:01:42s\n",
      "epoch 94 | loss: 0.01241 | train_rmsle: 0.00039 | train_mae: 0.06289 | train_rmse: 0.08331 | train_mse: 0.00694 | valid_rmsle: 0.00076 | valid_mae: 0.08898 | valid_rmse: 0.11633 | valid_mse: 0.01353 |  0:01:43s\n",
      "epoch 95 | loss: 0.01062 | train_rmsle: 0.0004  | train_mae: 0.06417 | train_rmse: 0.08354 | train_mse: 0.00698 | valid_rmsle: 0.00074 | valid_mae: 0.08821 | valid_rmse: 0.11468 | valid_mse: 0.01315 |  0:01:44s\n",
      "epoch 96 | loss: 0.01016 | train_rmsle: 0.00037 | train_mae: 0.06394 | train_rmse: 0.0821  | train_mse: 0.00674 | valid_rmsle: 0.00074 | valid_mae: 0.08738 | valid_rmse: 0.11366 | valid_mse: 0.01292 |  0:01:45s\n",
      "epoch 97 | loss: 0.0116  | train_rmsle: 0.00031 | train_mae: 0.05821 | train_rmse: 0.07632 | train_mse: 0.00582 | valid_rmsle: 0.0007  | valid_mae: 0.08495 | valid_rmse: 0.11165 | valid_mse: 0.01247 |  0:01:46s\n",
      "epoch 98 | loss: 0.01182 | train_rmsle: 0.00029 | train_mae: 0.05539 | train_rmse: 0.07232 | train_mse: 0.00523 | valid_rmsle: 0.00069 | valid_mae: 0.0838  | valid_rmse: 0.10975 | valid_mse: 0.01204 |  0:01:47s\n",
      "epoch 99 | loss: 0.01042 | train_rmsle: 0.00026 | train_mae: 0.05285 | train_rmse: 0.0693  | train_mse: 0.0048  | valid_rmsle: 0.00063 | valid_mae: 0.08002 | valid_rmse: 0.10545 | valid_mse: 0.01112 |  0:01:49s\n",
      "epoch 100| loss: 0.01216 | train_rmsle: 0.00058 | train_mae: 0.08634 | train_rmse: 0.10335 | train_mse: 0.01068 | valid_rmsle: 0.001   | valid_mae: 0.10539 | valid_rmse: 0.13394 | valid_mse: 0.01794 |  0:01:50s\n",
      "epoch 101| loss: 0.01027 | train_rmsle: 0.00033 | train_mae: 0.05733 | train_rmse: 0.07399 | train_mse: 0.00547 | valid_rmsle: 0.00076 | valid_mae: 0.08613 | valid_rmse: 0.11393 | valid_mse: 0.01298 |  0:01:51s\n",
      "epoch 102| loss: 0.01319 | train_rmsle: 0.00058 | train_mae: 0.08679 | train_rmse: 0.10343 | train_mse: 0.0107  | valid_rmsle: 0.00096 | valid_mae: 0.10638 | valid_rmse: 0.13197 | valid_mse: 0.01742 |  0:01:52s\n",
      "epoch 103| loss: 0.01284 | train_rmsle: 0.00032 | train_mae: 0.0563  | train_rmse: 0.07222 | train_mse: 0.00522 | valid_rmsle: 0.00074 | valid_mae: 0.08511 | valid_rmse: 0.1118  | valid_mse: 0.0125  |  0:01:53s\n",
      "epoch 104| loss: 0.01066 | train_rmsle: 0.00029 | train_mae: 0.05411 | train_rmse: 0.06944 | train_mse: 0.00482 | valid_rmsle: 0.00069 | valid_mae: 0.08249 | valid_rmse: 0.1085  | valid_mse: 0.01177 |  0:01:54s\n",
      "epoch 105| loss: 0.01216 | train_rmsle: 0.00041 | train_mae: 0.06436 | train_rmse: 0.08017 | train_mse: 0.00643 | valid_rmsle: 0.00078 | valid_mae: 0.08804 | valid_rmse: 0.11414 | valid_mse: 0.01303 |  0:01:55s\n",
      "epoch 106| loss: 0.00974 | train_rmsle: 0.00031 | train_mae: 0.05412 | train_rmse: 0.06979 | train_mse: 0.00487 | valid_rmsle: 0.0007  | valid_mae: 0.08198 | valid_rmse: 0.10768 | valid_mse: 0.01159 |  0:01:56s\n",
      "epoch 107| loss: 0.01202 | train_rmsle: 0.00023 | train_mae: 0.05099 | train_rmse: 0.06587 | train_mse: 0.00434 | valid_rmsle: 0.00062 | valid_mae: 0.08084 | valid_rmse: 0.10497 | valid_mse: 0.01102 |  0:01:57s\n",
      "epoch 108| loss: 0.01103 | train_rmsle: 0.00025 | train_mae: 0.05019 | train_rmse: 0.0649  | train_mse: 0.00421 | valid_rmsle: 0.00061 | valid_mae: 0.07931 | valid_rmse: 0.10352 | valid_mse: 0.01072 |  0:01:58s\n",
      "epoch 109| loss: 0.01116 | train_rmsle: 0.00026 | train_mae: 0.05249 | train_rmse: 0.0677  | train_mse: 0.00458 | valid_rmsle: 0.00064 | valid_mae: 0.08081 | valid_rmse: 0.10584 | valid_mse: 0.0112  |  0:01:59s\n",
      "epoch 110| loss: 0.01144 | train_rmsle: 0.00028 | train_mae: 0.05332 | train_rmse: 0.06914 | train_mse: 0.00478 | valid_rmsle: 0.00066 | valid_mae: 0.08118 | valid_rmse: 0.10625 | valid_mse: 0.01129 |  0:02:00s\n",
      "epoch 111| loss: 0.01135 | train_rmsle: 0.00024 | train_mae: 0.04948 | train_rmse: 0.06543 | train_mse: 0.00428 | valid_rmsle: 0.00062 | valid_mae: 0.0783  | valid_rmse: 0.10375 | valid_mse: 0.01076 |  0:02:02s\n",
      "epoch 112| loss: 0.00978 | train_rmsle: 0.00029 | train_mae: 0.05721 | train_rmse: 0.07448 | train_mse: 0.00555 | valid_rmsle: 0.00067 | valid_mae: 0.08496 | valid_rmse: 0.10996 | valid_mse: 0.01209 |  0:02:03s\n",
      "epoch 113| loss: 0.00944 | train_rmsle: 0.0002  | train_mae: 0.046   | train_rmse: 0.05994 | train_mse: 0.00359 | valid_rmsle: 0.0006  | valid_mae: 0.07757 | valid_rmse: 0.10246 | valid_mse: 0.0105  |  0:02:04s\n",
      "epoch 114| loss: 0.00888 | train_rmsle: 0.0002  | train_mae: 0.04703 | train_rmse: 0.06116 | train_mse: 0.00374 | valid_rmsle: 0.00059 | valid_mae: 0.07632 | valid_rmse: 0.10072 | valid_mse: 0.01014 |  0:02:05s\n",
      "epoch 115| loss: 0.01009 | train_rmsle: 0.00029 | train_mae: 0.05755 | train_rmse: 0.07494 | train_mse: 0.00562 | valid_rmsle: 0.00065 | valid_mae: 0.08419 | valid_rmse: 0.10848 | valid_mse: 0.01177 |  0:02:06s\n",
      "epoch 116| loss: 0.0124  | train_rmsle: 0.00054 | train_mae: 0.08404 | train_rmse: 0.10035 | train_mse: 0.01007 | valid_rmsle: 0.00092 | valid_mae: 0.10514 | valid_rmse: 0.12964 | valid_mse: 0.01681 |  0:02:07s\n",
      "epoch 117| loss: 0.0136  | train_rmsle: 0.00039 | train_mae: 0.06411 | train_rmse: 0.08477 | train_mse: 0.00719 | valid_rmsle: 0.00077 | valid_mae: 0.09007 | valid_rmse: 0.11667 | valid_mse: 0.01361 |  0:02:08s\n",
      "epoch 118| loss: 0.013   | train_rmsle: 0.0004  | train_mae: 0.06493 | train_rmse: 0.08877 | train_mse: 0.00788 | valid_rmsle: 0.00078 | valid_mae: 0.09004 | valid_rmse: 0.1192  | valid_mse: 0.01421 |  0:02:09s\n",
      "epoch 119| loss: 0.01226 | train_rmsle: 0.00046 | train_mae: 0.06989 | train_rmse: 0.08876 | train_mse: 0.00788 | valid_rmsle: 0.00084 | valid_mae: 0.09188 | valid_rmse: 0.1185  | valid_mse: 0.01404 |  0:02:10s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 114 and best_valid_mse = 0.01014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010907166719125323 RMSE: 0.10443738180903102 R2: 0.9517181756683668 MAE: 0.07995015796559761\n",
      "=====================================\n",
      "[75/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.2155  | train_rmsle: 0.29421 | train_mae: 1.77156 | train_rmse: 1.83625 | train_mse: 3.37182 | valid_rmsle: 0.2946  | valid_mae: 1.77586 | valid_rmse: 1.83905 | valid_mse: 3.38209 |  0:00:01s\n",
      "epoch 1  | loss: 0.55652 | train_rmsle: 0.18138 | train_mae: 1.45494 | train_rmse: 1.53022 | train_mse: 2.34156 | valid_rmsle: 0.18231 | valid_mae: 1.45983 | valid_rmse: 1.53503 | valid_mse: 2.35631 |  0:00:02s\n",
      "epoch 2  | loss: 0.31222 | train_rmsle: 0.08749 | train_mae: 1.0515  | train_rmse: 1.14064 | train_mse: 1.30106 | valid_rmsle: 0.08791 | valid_mae: 1.05458 | valid_rmse: 1.14469 | valid_mse: 1.31032 |  0:00:03s\n",
      "epoch 3  | loss: 0.26067 | train_rmsle: 0.04778 | train_mae: 0.78799 | train_rmse: 0.88016 | train_mse: 0.77468 | valid_rmsle: 0.04773 | valid_mae: 0.7878  | valid_rmse: 0.88204 | valid_mse: 0.77799 |  0:00:04s\n",
      "epoch 4  | loss: 0.23257 | train_rmsle: 0.03007 | train_mae: 0.62276 | train_rmse: 0.71375 | train_mse: 0.50943 | valid_rmsle: 0.02979 | valid_mae: 0.62207 | valid_rmse: 0.71375 | valid_mse: 0.50944 |  0:00:05s\n",
      "epoch 5  | loss: 0.2242  | train_rmsle: 0.01861 | train_mae: 0.476   | train_rmse: 0.56347 | train_mse: 0.3175  | valid_rmsle: 0.01832 | valid_mae: 0.47826 | valid_rmse: 0.56358 | valid_mse: 0.31762 |  0:00:06s\n",
      "epoch 6  | loss: 0.21821 | train_rmsle: 0.0174  | train_mae: 0.45645 | train_rmse: 0.54421 | train_mse: 0.29617 | valid_rmsle: 0.01702 | valid_mae: 0.4578  | valid_rmse: 0.54256 | valid_mse: 0.29437 |  0:00:07s\n",
      "epoch 7  | loss: 0.22083 | train_rmsle: 0.02095 | train_mae: 0.51079 | train_rmse: 0.59989 | train_mse: 0.35986 | valid_rmsle: 0.0206  | valid_mae: 0.51161 | valid_rmse: 0.59849 | valid_mse: 0.35819 |  0:00:08s\n",
      "epoch 8  | loss: 0.22938 | train_rmsle: 0.01479 | train_mae: 0.40928 | train_rmse: 0.49716 | train_mse: 0.24717 | valid_rmsle: 0.01444 | valid_mae: 0.41082 | valid_rmse: 0.49643 | valid_mse: 0.24645 |  0:00:09s\n",
      "epoch 9  | loss: 0.21044 | train_rmsle: 0.01368 | train_mae: 0.38531 | train_rmse: 0.47398 | train_mse: 0.22465 | valid_rmsle: 0.01349 | valid_mae: 0.39031 | valid_rmse: 0.47643 | valid_mse: 0.22698 |  0:00:11s\n",
      "epoch 10 | loss: 0.20528 | train_rmsle: 0.01454 | train_mae: 0.40642 | train_rmse: 0.49373 | train_mse: 0.24377 | valid_rmsle: 0.01465 | valid_mae: 0.41213 | valid_rmse: 0.50037 | valid_mse: 0.25037 |  0:00:12s\n",
      "epoch 11 | loss: 0.20287 | train_rmsle: 0.01353 | train_mae: 0.39097 | train_rmse: 0.4773  | train_mse: 0.22781 | valid_rmsle: 0.01377 | valid_mae: 0.3968  | valid_rmse: 0.4864  | valid_mse: 0.23659 |  0:00:13s\n",
      "epoch 12 | loss: 0.19711 | train_rmsle: 0.01115 | train_mae: 0.34441 | train_rmse: 0.42614 | train_mse: 0.18159 | valid_rmsle: 0.01103 | valid_mae: 0.34871 | valid_rmse: 0.42961 | valid_mse: 0.18456 |  0:00:14s\n",
      "epoch 13 | loss: 0.18554 | train_rmsle: 0.01057 | train_mae: 0.33728 | train_rmse: 0.41803 | train_mse: 0.17475 | valid_rmsle: 0.01066 | valid_mae: 0.34573 | valid_rmse: 0.42509 | valid_mse: 0.1807  |  0:00:15s\n",
      "epoch 14 | loss: 0.173   | train_rmsle: 0.00828 | train_mae: 0.29115 | train_rmse: 0.36542 | train_mse: 0.13353 | valid_rmsle: 0.00811 | valid_mae: 0.29179 | valid_rmse: 0.3662  | valid_mse: 0.1341  |  0:00:16s\n",
      "epoch 15 | loss: 0.15734 | train_rmsle: 0.00987 | train_mae: 0.34353 | train_rmse: 0.41318 | train_mse: 0.17072 | valid_rmsle: 0.00968 | valid_mae: 0.34125 | valid_rmse: 0.41209 | valid_mse: 0.16982 |  0:00:17s\n",
      "epoch 16 | loss: 0.13573 | train_rmsle: 0.00816 | train_mae: 0.30458 | train_rmse: 0.37464 | train_mse: 0.14036 | valid_rmsle: 0.00826 | valid_mae: 0.30579 | valid_rmse: 0.3778  | valid_mse: 0.14274 |  0:00:18s\n",
      "epoch 17 | loss: 0.11473 | train_rmsle: 0.00729 | train_mae: 0.28538 | train_rmse: 0.35314 | train_mse: 0.12471 | valid_rmsle: 0.00748 | valid_mae: 0.28999 | valid_rmse: 0.35813 | valid_mse: 0.12825 |  0:00:19s\n",
      "epoch 18 | loss: 0.09655 | train_rmsle: 0.00682 | train_mae: 0.2792  | train_rmse: 0.34121 | train_mse: 0.11643 | valid_rmsle: 0.00688 | valid_mae: 0.2814  | valid_rmse: 0.34369 | valid_mse: 0.11812 |  0:00:20s\n",
      "epoch 19 | loss: 0.08762 | train_rmsle: 0.00577 | train_mae: 0.25033 | train_rmse: 0.3119  | train_mse: 0.09728 | valid_rmsle: 0.00606 | valid_mae: 0.25705 | valid_rmse: 0.32098 | valid_mse: 0.10303 |  0:00:22s\n",
      "epoch 20 | loss: 0.08152 | train_rmsle: 0.00585 | train_mae: 0.2565  | train_rmse: 0.31528 | train_mse: 0.0994  | valid_rmsle: 0.00603 | valid_mae: 0.25912 | valid_rmse: 0.32143 | valid_mse: 0.10332 |  0:00:23s\n",
      "epoch 21 | loss: 0.07248 | train_rmsle: 0.00445 | train_mae: 0.21627 | train_rmse: 0.27126 | train_mse: 0.07358 | valid_rmsle: 0.00453 | valid_mae: 0.22005 | valid_rmse: 0.27616 | valid_mse: 0.07626 |  0:00:24s\n",
      "epoch 22 | loss: 0.06752 | train_rmsle: 0.00409 | train_mae: 0.20573 | train_rmse: 0.25913 | train_mse: 0.06715 | valid_rmsle: 0.0041  | valid_mae: 0.20932 | valid_rmse: 0.26278 | valid_mse: 0.06906 |  0:00:25s\n",
      "epoch 23 | loss: 0.06426 | train_rmsle: 0.00501 | train_mae: 0.23523 | train_rmse: 0.29049 | train_mse: 0.08438 | valid_rmsle: 0.00526 | valid_mae: 0.23845 | valid_rmse: 0.29925 | valid_mse: 0.08955 |  0:00:26s\n",
      "epoch 24 | loss: 0.05709 | train_rmsle: 0.00389 | train_mae: 0.20206 | train_rmse: 0.25309 | train_mse: 0.06406 | valid_rmsle: 0.00406 | valid_mae: 0.20365 | valid_rmse: 0.26067 | valid_mse: 0.06795 |  0:00:27s\n",
      "epoch 25 | loss: 0.05457 | train_rmsle: 0.00315 | train_mae: 0.18239 | train_rmse: 0.22979 | train_mse: 0.0528  | valid_rmsle: 0.00327 | valid_mae: 0.18693 | valid_rmse: 0.23708 | valid_mse: 0.05621 |  0:00:28s\n",
      "epoch 26 | loss: 0.05101 | train_rmsle: 0.00247 | train_mae: 0.15861 | train_rmse: 0.20292 | train_mse: 0.04118 | valid_rmsle: 0.00256 | valid_mae: 0.16302 | valid_rmse: 0.20944 | valid_mse: 0.04386 |  0:00:29s\n",
      "epoch 27 | loss: 0.04733 | train_rmsle: 0.00225 | train_mae: 0.15001 | train_rmse: 0.19296 | train_mse: 0.03723 | valid_rmsle: 0.00238 | valid_mae: 0.15716 | valid_rmse: 0.20233 | valid_mse: 0.04094 |  0:00:30s\n",
      "epoch 28 | loss: 0.04517 | train_rmsle: 0.00221 | train_mae: 0.1486  | train_rmse: 0.19173 | train_mse: 0.03676 | valid_rmsle: 0.00246 | valid_mae: 0.16015 | valid_rmse: 0.20534 | valid_mse: 0.04216 |  0:00:31s\n",
      "epoch 29 | loss: 0.04221 | train_rmsle: 0.00208 | train_mae: 0.14403 | train_rmse: 0.18736 | train_mse: 0.0351  | valid_rmsle: 0.00234 | valid_mae: 0.15711 | valid_rmse: 0.20165 | valid_mse: 0.04066 |  0:00:32s\n",
      "epoch 30 | loss: 0.03853 | train_rmsle: 0.00181 | train_mae: 0.13447 | train_rmse: 0.17454 | train_mse: 0.03046 | valid_rmsle: 0.00203 | valid_mae: 0.1463  | valid_rmse: 0.18763 | valid_mse: 0.0352  |  0:00:34s\n",
      "epoch 31 | loss: 0.03707 | train_rmsle: 0.00171 | train_mae: 0.13087 | train_rmse: 0.16802 | train_mse: 0.02823 | valid_rmsle: 0.00193 | valid_mae: 0.1421  | valid_rmse: 0.18173 | valid_mse: 0.03303 |  0:00:35s\n",
      "epoch 32 | loss: 0.03388 | train_rmsle: 0.00168 | train_mae: 0.13094 | train_rmse: 0.16755 | train_mse: 0.02807 | valid_rmsle: 0.00185 | valid_mae: 0.13883 | valid_rmse: 0.1788  | valid_mse: 0.03197 |  0:00:36s\n",
      "epoch 33 | loss: 0.03295 | train_rmsle: 0.00151 | train_mae: 0.11919 | train_rmse: 0.15767 | train_mse: 0.02486 | valid_rmsle: 0.00184 | valid_mae: 0.13772 | valid_rmse: 0.17818 | valid_mse: 0.03175 |  0:00:37s\n",
      "epoch 34 | loss: 0.03077 | train_rmsle: 0.00137 | train_mae: 0.11456 | train_rmse: 0.15088 | train_mse: 0.02277 | valid_rmsle: 0.00173 | valid_mae: 0.13491 | valid_rmse: 0.1734  | valid_mse: 0.03007 |  0:00:38s\n",
      "epoch 35 | loss: 0.02844 | train_rmsle: 0.00123 | train_mae: 0.10965 | train_rmse: 0.14452 | train_mse: 0.02089 | valid_rmsle: 0.00157 | valid_mae: 0.12835 | valid_rmse: 0.16694 | valid_mse: 0.02787 |  0:00:39s\n",
      "epoch 36 | loss: 0.03045 | train_rmsle: 0.00135 | train_mae: 0.11615 | train_rmse: 0.15208 | train_mse: 0.02313 | valid_rmsle: 0.00168 | valid_mae: 0.13412 | valid_rmse: 0.17348 | valid_mse: 0.03009 |  0:00:40s\n",
      "epoch 37 | loss: 0.02624 | train_rmsle: 0.0015  | train_mae: 0.12169 | train_rmse: 0.15771 | train_mse: 0.02487 | valid_rmsle: 0.0018  | valid_mae: 0.13816 | valid_rmse: 0.17644 | valid_mse: 0.03113 |  0:00:41s\n",
      "epoch 38 | loss: 0.02569 | train_rmsle: 0.00179 | train_mae: 0.14248 | train_rmse: 0.17645 | train_mse: 0.03114 | valid_rmsle: 0.00211 | valid_mae: 0.15368 | valid_rmse: 0.1944  | valid_mse: 0.03779 |  0:00:42s\n",
      "epoch 39 | loss: 0.02871 | train_rmsle: 0.00099 | train_mae: 0.09852 | train_rmse: 0.13168 | train_mse: 0.01734 | valid_rmsle: 0.00139 | valid_mae: 0.12166 | valid_rmse: 0.158   | valid_mse: 0.02496 |  0:00:43s\n",
      "epoch 40 | loss: 0.02326 | train_rmsle: 0.00109 | train_mae: 0.10408 | train_rmse: 0.13554 | train_mse: 0.01837 | valid_rmsle: 0.00139 | valid_mae: 0.12291 | valid_rmse: 0.15661 | valid_mse: 0.02453 |  0:00:45s\n",
      "epoch 41 | loss: 0.024   | train_rmsle: 0.00096 | train_mae: 0.09743 | train_rmse: 0.12873 | train_mse: 0.01657 | valid_rmsle: 0.00132 | valid_mae: 0.11889 | valid_rmse: 0.15382 | valid_mse: 0.02366 |  0:00:46s\n",
      "epoch 42 | loss: 0.02262 | train_rmsle: 0.00091 | train_mae: 0.09504 | train_rmse: 0.12522 | train_mse: 0.01568 | valid_rmsle: 0.00129 | valid_mae: 0.11641 | valid_rmse: 0.15133 | valid_mse: 0.0229  |  0:00:47s\n",
      "epoch 43 | loss: 0.02177 | train_rmsle: 0.00085 | train_mae: 0.0913  | train_rmse: 0.12205 | train_mse: 0.0149  | valid_rmsle: 0.00125 | valid_mae: 0.11637 | valid_rmse: 0.14984 | valid_mse: 0.02245 |  0:00:48s\n",
      "epoch 44 | loss: 0.0222  | train_rmsle: 0.00099 | train_mae: 0.10285 | train_rmse: 0.1321  | train_mse: 0.01745 | valid_rmsle: 0.00134 | valid_mae: 0.12085 | valid_rmse: 0.15542 | valid_mse: 0.02416 |  0:00:49s\n",
      "epoch 45 | loss: 0.02112 | train_rmsle: 0.00085 | train_mae: 0.08986 | train_rmse: 0.12032 | train_mse: 0.01448 | valid_rmsle: 0.00131 | valid_mae: 0.1177  | valid_rmse: 0.15104 | valid_mse: 0.02281 |  0:00:50s\n",
      "epoch 46 | loss: 0.02141 | train_rmsle: 0.00075 | train_mae: 0.08578 | train_rmse: 0.11605 | train_mse: 0.01347 | valid_rmsle: 0.00118 | valid_mae: 0.11186 | valid_rmse: 0.14569 | valid_mse: 0.02123 |  0:00:51s\n",
      "epoch 47 | loss: 0.01909 | train_rmsle: 0.00077 | train_mae: 0.08768 | train_rmse: 0.11638 | train_mse: 0.01354 | valid_rmsle: 0.0012  | valid_mae: 0.11392 | valid_rmse: 0.14708 | valid_mse: 0.02163 |  0:00:52s\n",
      "epoch 48 | loss: 0.01994 | train_rmsle: 0.00092 | train_mae: 0.09923 | train_rmse: 0.12853 | train_mse: 0.01652 | valid_rmsle: 0.00138 | valid_mae: 0.12529 | valid_rmse: 0.159   | valid_mse: 0.02528 |  0:00:53s\n",
      "epoch 49 | loss: 0.01904 | train_rmsle: 0.00064 | train_mae: 0.07815 | train_rmse: 0.10573 | train_mse: 0.01118 | valid_rmsle: 0.00107 | valid_mae: 0.10625 | valid_rmse: 0.13886 | valid_mse: 0.01928 |  0:00:54s\n",
      "epoch 50 | loss: 0.01799 | train_rmsle: 0.00064 | train_mae: 0.07809 | train_rmse: 0.1062  | train_mse: 0.01128 | valid_rmsle: 0.00106 | valid_mae: 0.10562 | valid_rmse: 0.1381  | valid_mse: 0.01907 |  0:00:55s\n",
      "epoch 51 | loss: 0.01738 | train_rmsle: 0.00105 | train_mae: 0.1094  | train_rmse: 0.13432 | train_mse: 0.01804 | valid_rmsle: 0.00148 | valid_mae: 0.12837 | valid_rmse: 0.16182 | valid_mse: 0.02619 |  0:00:57s\n",
      "epoch 52 | loss: 0.0242  | train_rmsle: 0.00106 | train_mae: 0.10526 | train_rmse: 0.13275 | train_mse: 0.01762 | valid_rmsle: 0.00159 | valid_mae: 0.12885 | valid_rmse: 0.16556 | valid_mse: 0.02741 |  0:00:58s\n",
      "epoch 53 | loss: 0.02045 | train_rmsle: 0.00085 | train_mae: 0.08273 | train_rmse: 0.11746 | train_mse: 0.0138  | valid_rmsle: 0.00135 | valid_mae: 0.1108  | valid_rmse: 0.1513  | valid_mse: 0.02289 |  0:00:59s\n",
      "epoch 54 | loss: 0.02016 | train_rmsle: 0.00116 | train_mae: 0.11838 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00157 | valid_mae: 0.13486 | valid_rmse: 0.17147 | valid_mse: 0.0294  |  0:01:00s\n",
      "epoch 55 | loss: 0.01841 | train_rmsle: 0.00058 | train_mae: 0.07578 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00099 | valid_mae: 0.1025  | valid_rmse: 0.13446 | valid_mse: 0.01808 |  0:01:01s\n",
      "epoch 56 | loss: 0.0161  | train_rmsle: 0.00065 | train_mae: 0.07923 | train_rmse: 0.10638 | train_mse: 0.01132 | valid_rmsle: 0.00106 | valid_mae: 0.10562 | valid_rmse: 0.13728 | valid_mse: 0.01885 |  0:01:02s\n",
      "epoch 57 | loss: 0.01521 | train_rmsle: 0.00056 | train_mae: 0.07342 | train_rmse: 0.0971  | train_mse: 0.00943 | valid_rmsle: 0.00098 | valid_mae: 0.10094 | valid_rmse: 0.1319  | valid_mse: 0.0174  |  0:01:03s\n",
      "epoch 58 | loss: 0.0149  | train_rmsle: 0.00049 | train_mae: 0.06868 | train_rmse: 0.09191 | train_mse: 0.00845 | valid_rmsle: 0.00092 | valid_mae: 0.09662 | valid_rmse: 0.12803 | valid_mse: 0.01639 |  0:01:04s\n",
      "epoch 59 | loss: 0.01449 | train_rmsle: 0.00049 | train_mae: 0.06928 | train_rmse: 0.09197 | train_mse: 0.00846 | valid_rmsle: 0.0009  | valid_mae: 0.09668 | valid_rmse: 0.12715 | valid_mse: 0.01617 |  0:01:05s\n",
      "epoch 60 | loss: 0.01417 | train_rmsle: 0.0007  | train_mae: 0.08991 | train_rmse: 0.11524 | train_mse: 0.01328 | valid_rmsle: 0.00112 | valid_mae: 0.11363 | valid_rmse: 0.14538 | valid_mse: 0.02114 |  0:01:06s\n",
      "epoch 61 | loss: 0.01627 | train_rmsle: 0.00048 | train_mae: 0.06875 | train_rmse: 0.09059 | train_mse: 0.00821 | valid_rmsle: 0.00087 | valid_mae: 0.09474 | valid_rmse: 0.12417 | valid_mse: 0.01542 |  0:01:07s\n",
      "epoch 62 | loss: 0.01374 | train_rmsle: 0.0005  | train_mae: 0.07178 | train_rmse: 0.09485 | train_mse: 0.009   | valid_rmsle: 0.00088 | valid_mae: 0.09755 | valid_rmse: 0.12629 | valid_mse: 0.01595 |  0:01:09s\n",
      "epoch 63 | loss: 0.01461 | train_rmsle: 0.00063 | train_mae: 0.07918 | train_rmse: 0.10355 | train_mse: 0.01072 | valid_rmsle: 0.00102 | valid_mae: 0.10455 | valid_rmse: 0.13381 | valid_mse: 0.01791 |  0:01:10s\n",
      "epoch 64 | loss: 0.01675 | train_rmsle: 0.0006  | train_mae: 0.07811 | train_rmse: 0.10297 | train_mse: 0.0106  | valid_rmsle: 0.00103 | valid_mae: 0.10458 | valid_rmse: 0.13639 | valid_mse: 0.0186  |  0:01:11s\n",
      "epoch 65 | loss: 0.01735 | train_rmsle: 0.00147 | train_mae: 0.13071 | train_rmse: 0.15792 | train_mse: 0.02494 | valid_rmsle: 0.00185 | valid_mae: 0.14572 | valid_rmse: 0.17968 | valid_mse: 0.03228 |  0:01:12s\n",
      "epoch 66 | loss: 0.02068 | train_rmsle: 0.00063 | train_mae: 0.08248 | train_rmse: 0.10746 | train_mse: 0.01155 | valid_rmsle: 0.00103 | valid_mae: 0.10393 | valid_rmse: 0.13656 | valid_mse: 0.01865 |  0:01:13s\n",
      "epoch 67 | loss: 0.01504 | train_rmsle: 0.00053 | train_mae: 0.07459 | train_rmse: 0.09624 | train_mse: 0.00926 | valid_rmsle: 0.00088 | valid_mae: 0.09606 | valid_rmse: 0.12567 | valid_mse: 0.01579 |  0:01:14s\n",
      "epoch 68 | loss: 0.01244 | train_rmsle: 0.00048 | train_mae: 0.06998 | train_rmse: 0.09335 | train_mse: 0.00871 | valid_rmsle: 0.00088 | valid_mae: 0.09611 | valid_rmse: 0.12569 | valid_mse: 0.0158  |  0:01:15s\n",
      "epoch 69 | loss: 0.01269 | train_rmsle: 0.00071 | train_mae: 0.08341 | train_rmse: 0.10586 | train_mse: 0.01121 | valid_rmsle: 0.00113 | valid_mae: 0.10886 | valid_rmse: 0.1372  | valid_mse: 0.01882 |  0:01:16s\n",
      "epoch 70 | loss: 0.01455 | train_rmsle: 0.00057 | train_mae: 0.07919 | train_rmse: 0.09901 | train_mse: 0.0098  | valid_rmsle: 0.00097 | valid_mae: 0.10228 | valid_rmse: 0.13097 | valid_mse: 0.01715 |  0:01:17s\n",
      "epoch 71 | loss: 0.01377 | train_rmsle: 0.00055 | train_mae: 0.07781 | train_rmse: 0.09783 | train_mse: 0.00957 | valid_rmsle: 0.00096 | valid_mae: 0.10211 | valid_rmse: 0.12959 | valid_mse: 0.01679 |  0:01:18s\n",
      "epoch 72 | loss: 0.01354 | train_rmsle: 0.00037 | train_mae: 0.06129 | train_rmse: 0.08059 | train_mse: 0.00649 | valid_rmsle: 0.00079 | valid_mae: 0.08974 | valid_rmse: 0.11828 | valid_mse: 0.01399 |  0:01:19s\n",
      "epoch 73 | loss: 0.01564 | train_rmsle: 0.00038 | train_mae: 0.06153 | train_rmse: 0.08271 | train_mse: 0.00684 | valid_rmsle: 0.00077 | valid_mae: 0.08881 | valid_rmse: 0.11811 | valid_mse: 0.01395 |  0:01:21s\n",
      "epoch 74 | loss: 0.01201 | train_rmsle: 0.00035 | train_mae: 0.06105 | train_rmse: 0.08029 | train_mse: 0.00645 | valid_rmsle: 0.0008  | valid_mae: 0.09047 | valid_rmse: 0.12007 | valid_mse: 0.01442 |  0:01:22s\n",
      "epoch 75 | loss: 0.01388 | train_rmsle: 0.00053 | train_mae: 0.07732 | train_rmse: 0.09776 | train_mse: 0.00956 | valid_rmsle: 0.00101 | valid_mae: 0.10499 | valid_rmse: 0.13536 | valid_mse: 0.01832 |  0:01:23s\n",
      "epoch 76 | loss: 0.01281 | train_rmsle: 0.00046 | train_mae: 0.07264 | train_rmse: 0.09205 | train_mse: 0.00847 | valid_rmsle: 0.00092 | valid_mae: 0.09978 | valid_rmse: 0.12984 | valid_mse: 0.01686 |  0:01:24s\n",
      "epoch 77 | loss: 0.01224 | train_rmsle: 0.00042 | train_mae: 0.06793 | train_rmse: 0.0856  | train_mse: 0.00733 | valid_rmsle: 0.00085 | valid_mae: 0.09487 | valid_rmse: 0.12295 | valid_mse: 0.01512 |  0:01:25s\n",
      "epoch 78 | loss: 0.01195 | train_rmsle: 0.00053 | train_mae: 0.07083 | train_rmse: 0.09043 | train_mse: 0.00818 | valid_rmsle: 0.00095 | valid_mae: 0.09739 | valid_rmse: 0.12555 | valid_mse: 0.01576 |  0:01:26s\n",
      "epoch 79 | loss: 0.01158 | train_rmsle: 0.00033 | train_mae: 0.05839 | train_rmse: 0.07731 | train_mse: 0.00598 | valid_rmsle: 0.00076 | valid_mae: 0.08874 | valid_rmse: 0.11694 | valid_mse: 0.01367 |  0:01:27s\n",
      "epoch 80 | loss: 0.01426 | train_rmsle: 0.0006  | train_mae: 0.0763  | train_rmse: 0.09623 | train_mse: 0.00926 | valid_rmsle: 0.00099 | valid_mae: 0.09926 | valid_rmse: 0.1275  | valid_mse: 0.01626 |  0:01:28s\n",
      "epoch 81 | loss: 0.01411 | train_rmsle: 0.00066 | train_mae: 0.09176 | train_rmse: 0.11099 | train_mse: 0.01232 | valid_rmsle: 0.00109 | valid_mae: 0.11316 | valid_rmse: 0.14133 | valid_mse: 0.01997 |  0:01:29s\n",
      "epoch 82 | loss: 0.01427 | train_rmsle: 0.00046 | train_mae: 0.07212 | train_rmse: 0.08956 | train_mse: 0.00802 | valid_rmsle: 0.00087 | valid_mae: 0.09667 | valid_rmse: 0.12416 | valid_mse: 0.01542 |  0:01:30s\n",
      "epoch 83 | loss: 0.01166 | train_rmsle: 0.00041 | train_mae: 0.06736 | train_rmse: 0.08621 | train_mse: 0.00743 | valid_rmsle: 0.00081 | valid_mae: 0.09298 | valid_rmse: 0.12119 | valid_mse: 0.01469 |  0:01:31s\n",
      "epoch 84 | loss: 0.01301 | train_rmsle: 0.00047 | train_mae: 0.06957 | train_rmse: 0.09212 | train_mse: 0.00849 | valid_rmsle: 0.00085 | valid_mae: 0.09436 | valid_rmse: 0.12433 | valid_mse: 0.01546 |  0:01:33s\n",
      "epoch 85 | loss: 0.01271 | train_rmsle: 0.00057 | train_mae: 0.07213 | train_rmse: 0.09577 | train_mse: 0.00917 | valid_rmsle: 0.00099 | valid_mae: 0.09776 | valid_rmse: 0.12997 | valid_mse: 0.01689 |  0:01:34s\n",
      "epoch 86 | loss: 0.01208 | train_rmsle: 0.00034 | train_mae: 0.06019 | train_rmse: 0.07949 | train_mse: 0.00632 | valid_rmsle: 0.00078 | valid_mae: 0.08898 | valid_rmse: 0.11838 | valid_mse: 0.01401 |  0:01:35s\n",
      "epoch 87 | loss: 0.01437 | train_rmsle: 0.00141 | train_mae: 0.14317 | train_rmse: 0.16157 | train_mse: 0.0261  | valid_rmsle: 0.00186 | valid_mae: 0.15334 | valid_rmse: 0.1839  | valid_mse: 0.03382 |  0:01:36s\n",
      "epoch 88 | loss: 0.01857 | train_rmsle: 0.00051 | train_mae: 0.07234 | train_rmse: 0.09782 | train_mse: 0.00957 | valid_rmsle: 0.00093 | valid_mae: 0.09855 | valid_rmse: 0.12995 | valid_mse: 0.01689 |  0:01:37s\n",
      "epoch 89 | loss: 0.01461 | train_rmsle: 0.00057 | train_mae: 0.07719 | train_rmse: 0.10024 | train_mse: 0.01005 | valid_rmsle: 0.00096 | valid_mae: 0.09858 | valid_rmse: 0.12863 | valid_mse: 0.01655 |  0:01:38s\n",
      "epoch 90 | loss: 0.01455 | train_rmsle: 0.00141 | train_mae: 0.11548 | train_rmse: 0.14151 | train_mse: 0.02002 | valid_rmsle: 0.00174 | valid_mae: 0.13098 | valid_rmse: 0.16173 | valid_mse: 0.02616 |  0:01:39s\n",
      "epoch 91 | loss: 0.01507 | train_rmsle: 0.00049 | train_mae: 0.07219 | train_rmse: 0.09122 | train_mse: 0.00832 | valid_rmsle: 0.00088 | valid_mae: 0.0948  | valid_rmse: 0.12339 | valid_mse: 0.01523 |  0:01:40s\n",
      "epoch 92 | loss: 0.0141  | train_rmsle: 0.00034 | train_mae: 0.06074 | train_rmse: 0.07933 | train_mse: 0.00629 | valid_rmsle: 0.00075 | valid_mae: 0.08659 | valid_rmse: 0.11512 | valid_mse: 0.01325 |  0:01:41s\n",
      "epoch 93 | loss: 0.01373 | train_rmsle: 0.00058 | train_mae: 0.07543 | train_rmse: 0.0969  | train_mse: 0.00939 | valid_rmsle: 0.00097 | valid_mae: 0.09762 | valid_rmse: 0.1272  | valid_mse: 0.01618 |  0:01:42s\n",
      "epoch 94 | loss: 0.01241 | train_rmsle: 0.00039 | train_mae: 0.06289 | train_rmse: 0.08331 | train_mse: 0.00694 | valid_rmsle: 0.00076 | valid_mae: 0.08898 | valid_rmse: 0.11633 | valid_mse: 0.01353 |  0:01:43s\n",
      "epoch 95 | loss: 0.01062 | train_rmsle: 0.0004  | train_mae: 0.06417 | train_rmse: 0.08354 | train_mse: 0.00698 | valid_rmsle: 0.00074 | valid_mae: 0.08821 | valid_rmse: 0.11468 | valid_mse: 0.01315 |  0:01:44s\n",
      "epoch 96 | loss: 0.01016 | train_rmsle: 0.00037 | train_mae: 0.06394 | train_rmse: 0.0821  | train_mse: 0.00674 | valid_rmsle: 0.00074 | valid_mae: 0.08738 | valid_rmse: 0.11366 | valid_mse: 0.01292 |  0:01:46s\n",
      "epoch 97 | loss: 0.0116  | train_rmsle: 0.00031 | train_mae: 0.05821 | train_rmse: 0.07632 | train_mse: 0.00582 | valid_rmsle: 0.0007  | valid_mae: 0.08495 | valid_rmse: 0.11165 | valid_mse: 0.01247 |  0:01:47s\n",
      "epoch 98 | loss: 0.01182 | train_rmsle: 0.00029 | train_mae: 0.05539 | train_rmse: 0.07232 | train_mse: 0.00523 | valid_rmsle: 0.00069 | valid_mae: 0.0838  | valid_rmse: 0.10975 | valid_mse: 0.01204 |  0:01:48s\n",
      "epoch 99 | loss: 0.01042 | train_rmsle: 0.00026 | train_mae: 0.05285 | train_rmse: 0.0693  | train_mse: 0.0048  | valid_rmsle: 0.00063 | valid_mae: 0.08002 | valid_rmse: 0.10545 | valid_mse: 0.01112 |  0:01:49s\n",
      "epoch 100| loss: 0.01216 | train_rmsle: 0.00058 | train_mae: 0.08634 | train_rmse: 0.10335 | train_mse: 0.01068 | valid_rmsle: 0.001   | valid_mae: 0.10539 | valid_rmse: 0.13394 | valid_mse: 0.01794 |  0:01:50s\n",
      "epoch 101| loss: 0.01027 | train_rmsle: 0.00033 | train_mae: 0.05733 | train_rmse: 0.07399 | train_mse: 0.00547 | valid_rmsle: 0.00076 | valid_mae: 0.08613 | valid_rmse: 0.11393 | valid_mse: 0.01298 |  0:01:51s\n",
      "epoch 102| loss: 0.01319 | train_rmsle: 0.00058 | train_mae: 0.08679 | train_rmse: 0.10343 | train_mse: 0.0107  | valid_rmsle: 0.00096 | valid_mae: 0.10638 | valid_rmse: 0.13197 | valid_mse: 0.01742 |  0:01:52s\n",
      "epoch 103| loss: 0.01284 | train_rmsle: 0.00032 | train_mae: 0.0563  | train_rmse: 0.07222 | train_mse: 0.00522 | valid_rmsle: 0.00074 | valid_mae: 0.08511 | valid_rmse: 0.1118  | valid_mse: 0.0125  |  0:01:53s\n",
      "epoch 104| loss: 0.01066 | train_rmsle: 0.00029 | train_mae: 0.05411 | train_rmse: 0.06944 | train_mse: 0.00482 | valid_rmsle: 0.00069 | valid_mae: 0.08249 | valid_rmse: 0.1085  | valid_mse: 0.01177 |  0:01:54s\n",
      "epoch 105| loss: 0.01216 | train_rmsle: 0.00041 | train_mae: 0.06436 | train_rmse: 0.08017 | train_mse: 0.00643 | valid_rmsle: 0.00078 | valid_mae: 0.08804 | valid_rmse: 0.11414 | valid_mse: 0.01303 |  0:01:55s\n",
      "epoch 106| loss: 0.00974 | train_rmsle: 0.00031 | train_mae: 0.05412 | train_rmse: 0.06979 | train_mse: 0.00487 | valid_rmsle: 0.0007  | valid_mae: 0.08198 | valid_rmse: 0.10768 | valid_mse: 0.01159 |  0:01:56s\n",
      "epoch 107| loss: 0.01202 | train_rmsle: 0.00023 | train_mae: 0.05099 | train_rmse: 0.06587 | train_mse: 0.00434 | valid_rmsle: 0.00062 | valid_mae: 0.08084 | valid_rmse: 0.10497 | valid_mse: 0.01102 |  0:01:58s\n",
      "epoch 108| loss: 0.01103 | train_rmsle: 0.00025 | train_mae: 0.05019 | train_rmse: 0.0649  | train_mse: 0.00421 | valid_rmsle: 0.00061 | valid_mae: 0.07931 | valid_rmse: 0.10352 | valid_mse: 0.01072 |  0:01:59s\n",
      "epoch 109| loss: 0.01116 | train_rmsle: 0.00026 | train_mae: 0.05249 | train_rmse: 0.0677  | train_mse: 0.00458 | valid_rmsle: 0.00064 | valid_mae: 0.08081 | valid_rmse: 0.10584 | valid_mse: 0.0112  |  0:02:00s\n",
      "epoch 110| loss: 0.01144 | train_rmsle: 0.00028 | train_mae: 0.05332 | train_rmse: 0.06914 | train_mse: 0.00478 | valid_rmsle: 0.00066 | valid_mae: 0.08118 | valid_rmse: 0.10625 | valid_mse: 0.01129 |  0:02:01s\n",
      "epoch 111| loss: 0.01135 | train_rmsle: 0.00024 | train_mae: 0.04948 | train_rmse: 0.06543 | train_mse: 0.00428 | valid_rmsle: 0.00062 | valid_mae: 0.0783  | valid_rmse: 0.10375 | valid_mse: 0.01076 |  0:02:02s\n",
      "epoch 112| loss: 0.00978 | train_rmsle: 0.00029 | train_mae: 0.05721 | train_rmse: 0.07448 | train_mse: 0.00555 | valid_rmsle: 0.00067 | valid_mae: 0.08496 | valid_rmse: 0.10996 | valid_mse: 0.01209 |  0:02:03s\n",
      "epoch 113| loss: 0.00944 | train_rmsle: 0.0002  | train_mae: 0.046   | train_rmse: 0.05994 | train_mse: 0.00359 | valid_rmsle: 0.0006  | valid_mae: 0.07757 | valid_rmse: 0.10246 | valid_mse: 0.0105  |  0:02:04s\n",
      "epoch 114| loss: 0.00888 | train_rmsle: 0.0002  | train_mae: 0.04703 | train_rmse: 0.06116 | train_mse: 0.00374 | valid_rmsle: 0.00059 | valid_mae: 0.07632 | valid_rmse: 0.10072 | valid_mse: 0.01014 |  0:02:05s\n",
      "epoch 115| loss: 0.01009 | train_rmsle: 0.00029 | train_mae: 0.05755 | train_rmse: 0.07494 | train_mse: 0.00562 | valid_rmsle: 0.00065 | valid_mae: 0.08419 | valid_rmse: 0.10848 | valid_mse: 0.01177 |  0:02:06s\n",
      "epoch 116| loss: 0.0124  | train_rmsle: 0.00054 | train_mae: 0.08404 | train_rmse: 0.10035 | train_mse: 0.01007 | valid_rmsle: 0.00092 | valid_mae: 0.10514 | valid_rmse: 0.12964 | valid_mse: 0.01681 |  0:02:07s\n",
      "epoch 117| loss: 0.0136  | train_rmsle: 0.00039 | train_mae: 0.06411 | train_rmse: 0.08477 | train_mse: 0.00719 | valid_rmsle: 0.00077 | valid_mae: 0.09007 | valid_rmse: 0.11667 | valid_mse: 0.01361 |  0:02:08s\n",
      "epoch 118| loss: 0.013   | train_rmsle: 0.0004  | train_mae: 0.06493 | train_rmse: 0.08877 | train_mse: 0.00788 | valid_rmsle: 0.00078 | valid_mae: 0.09004 | valid_rmse: 0.1192  | valid_mse: 0.01421 |  0:02:10s\n",
      "epoch 119| loss: 0.01226 | train_rmsle: 0.00046 | train_mae: 0.06989 | train_rmse: 0.08876 | train_mse: 0.00788 | valid_rmsle: 0.00084 | valid_mae: 0.09188 | valid_rmse: 0.1185  | valid_mse: 0.01404 |  0:02:11s\n",
      "epoch 120| loss: 0.01285 | train_rmsle: 0.00025 | train_mae: 0.05103 | train_rmse: 0.06855 | train_mse: 0.0047  | valid_rmsle: 0.00065 | valid_mae: 0.08076 | valid_rmse: 0.10587 | valid_mse: 0.01121 |  0:02:12s\n",
      "epoch 121| loss: 0.01072 | train_rmsle: 0.00027 | train_mae: 0.05345 | train_rmse: 0.07031 | train_mse: 0.00494 | valid_rmsle: 0.00066 | valid_mae: 0.08197 | valid_rmse: 0.10723 | valid_mse: 0.0115  |  0:02:13s\n",
      "epoch 122| loss: 0.01055 | train_rmsle: 0.00028 | train_mae: 0.05208 | train_rmse: 0.06988 | train_mse: 0.00488 | valid_rmsle: 0.00067 | valid_mae: 0.08184 | valid_rmse: 0.10773 | valid_mse: 0.01161 |  0:02:14s\n",
      "epoch 123| loss: 0.01262 | train_rmsle: 0.00039 | train_mae: 0.06752 | train_rmse: 0.08694 | train_mse: 0.00756 | valid_rmsle: 0.0008  | valid_mae: 0.09418 | valid_rmse: 0.12025 | valid_mse: 0.01446 |  0:02:15s\n",
      "epoch 124| loss: 0.01281 | train_rmsle: 0.00026 | train_mae: 0.0533  | train_rmse: 0.06958 | train_mse: 0.00484 | valid_rmsle: 0.00067 | valid_mae: 0.08454 | valid_rmse: 0.10874 | valid_mse: 0.01182 |  0:02:16s\n",
      "epoch 125| loss: 0.01147 | train_rmsle: 0.0002  | train_mae: 0.04637 | train_rmse: 0.06195 | train_mse: 0.00384 | valid_rmsle: 0.00061 | valid_mae: 0.07912 | valid_rmse: 0.10281 | valid_mse: 0.01057 |  0:02:17s\n",
      "epoch 126| loss: 0.01117 | train_rmsle: 0.00022 | train_mae: 0.04876 | train_rmse: 0.06354 | train_mse: 0.00404 | valid_rmsle: 0.00063 | valid_mae: 0.08104 | valid_rmse: 0.10474 | valid_mse: 0.01097 |  0:02:18s\n",
      "epoch 127| loss: 0.00922 | train_rmsle: 0.00022 | train_mae: 0.04847 | train_rmse: 0.06305 | train_mse: 0.00397 | valid_rmsle: 0.00065 | valid_mae: 0.08071 | valid_rmse: 0.10555 | valid_mse: 0.01114 |  0:02:19s\n",
      "epoch 128| loss: 0.00968 | train_rmsle: 0.00023 | train_mae: 0.04915 | train_rmse: 0.06387 | train_mse: 0.00408 | valid_rmsle: 0.00065 | valid_mae: 0.08074 | valid_rmse: 0.10537 | valid_mse: 0.0111  |  0:02:20s\n",
      "epoch 129| loss: 0.00939 | train_rmsle: 0.00036 | train_mae: 0.05718 | train_rmse: 0.07373 | train_mse: 0.00544 | valid_rmsle: 0.00075 | valid_mae: 0.08484 | valid_rmse: 0.11078 | valid_mse: 0.01227 |  0:02:21s\n",
      "epoch 130| loss: 0.01023 | train_rmsle: 0.00042 | train_mae: 0.06906 | train_rmse: 0.08816 | train_mse: 0.00777 | valid_rmsle: 0.00085 | valid_mae: 0.09522 | valid_rmse: 0.12216 | valid_mse: 0.01492 |  0:02:23s\n",
      "epoch 131| loss: 0.00912 | train_rmsle: 0.00026 | train_mae: 0.0549  | train_rmse: 0.07146 | train_mse: 0.00511 | valid_rmsle: 0.00069 | valid_mae: 0.08444 | valid_rmse: 0.1103  | valid_mse: 0.01217 |  0:02:24s\n",
      "epoch 132| loss: 0.01075 | train_rmsle: 0.00034 | train_mae: 0.05742 | train_rmse: 0.07462 | train_mse: 0.00557 | valid_rmsle: 0.00071 | valid_mae: 0.08574 | valid_rmse: 0.10969 | valid_mse: 0.01203 |  0:02:25s\n",
      "epoch 133| loss: 0.01219 | train_rmsle: 0.00101 | train_mae: 0.12393 | train_rmse: 0.1389  | train_mse: 0.01929 | valid_rmsle: 0.00135 | valid_mae: 0.13413 | valid_rmse: 0.15901 | valid_mse: 0.02529 |  0:02:26s\n",
      "epoch 134| loss: 0.01261 | train_rmsle: 0.00021 | train_mae: 0.04799 | train_rmse: 0.06313 | train_mse: 0.00399 | valid_rmsle: 0.00065 | valid_mae: 0.08042 | valid_rmse: 0.10539 | valid_mse: 0.01111 |  0:02:27s\n",
      "\n",
      "Early stopping occurred at epoch 134 with best_epoch = 114 and best_valid_mse = 0.01014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010907166719125323 RMSE: 0.10443738180903102 R2: 0.9517181756683668 MAE: 0.07995015796559761\n",
      "=====================================\n",
      "[76/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.2155  | train_rmsle: 0.29421 | train_mae: 1.77156 | train_rmse: 1.83625 | train_mse: 3.37182 | valid_rmsle: 0.2946  | valid_mae: 1.77586 | valid_rmse: 1.83905 | valid_mse: 3.38209 |  0:00:01s\n",
      "epoch 1  | loss: 0.55652 | train_rmsle: 0.18138 | train_mae: 1.45494 | train_rmse: 1.53022 | train_mse: 2.34156 | valid_rmsle: 0.18231 | valid_mae: 1.45983 | valid_rmse: 1.53503 | valid_mse: 2.35631 |  0:00:02s\n",
      "epoch 2  | loss: 0.31222 | train_rmsle: 0.08749 | train_mae: 1.0515  | train_rmse: 1.14064 | train_mse: 1.30106 | valid_rmsle: 0.08791 | valid_mae: 1.05458 | valid_rmse: 1.14469 | valid_mse: 1.31032 |  0:00:03s\n",
      "epoch 3  | loss: 0.26067 | train_rmsle: 0.04778 | train_mae: 0.78799 | train_rmse: 0.88016 | train_mse: 0.77468 | valid_rmsle: 0.04773 | valid_mae: 0.7878  | valid_rmse: 0.88204 | valid_mse: 0.77799 |  0:00:04s\n",
      "epoch 4  | loss: 0.23257 | train_rmsle: 0.03007 | train_mae: 0.62276 | train_rmse: 0.71375 | train_mse: 0.50943 | valid_rmsle: 0.02979 | valid_mae: 0.62207 | valid_rmse: 0.71375 | valid_mse: 0.50944 |  0:00:05s\n",
      "epoch 5  | loss: 0.2242  | train_rmsle: 0.01861 | train_mae: 0.476   | train_rmse: 0.56347 | train_mse: 0.3175  | valid_rmsle: 0.01832 | valid_mae: 0.47826 | valid_rmse: 0.56358 | valid_mse: 0.31762 |  0:00:06s\n",
      "epoch 6  | loss: 0.21821 | train_rmsle: 0.0174  | train_mae: 0.45645 | train_rmse: 0.54421 | train_mse: 0.29617 | valid_rmsle: 0.01702 | valid_mae: 0.4578  | valid_rmse: 0.54256 | valid_mse: 0.29437 |  0:00:07s\n",
      "epoch 7  | loss: 0.22083 | train_rmsle: 0.02095 | train_mae: 0.51079 | train_rmse: 0.59989 | train_mse: 0.35986 | valid_rmsle: 0.0206  | valid_mae: 0.51161 | valid_rmse: 0.59849 | valid_mse: 0.35819 |  0:00:08s\n",
      "epoch 8  | loss: 0.22938 | train_rmsle: 0.01479 | train_mae: 0.40928 | train_rmse: 0.49716 | train_mse: 0.24717 | valid_rmsle: 0.01444 | valid_mae: 0.41082 | valid_rmse: 0.49643 | valid_mse: 0.24645 |  0:00:09s\n",
      "epoch 9  | loss: 0.21044 | train_rmsle: 0.01368 | train_mae: 0.38531 | train_rmse: 0.47398 | train_mse: 0.22465 | valid_rmsle: 0.01349 | valid_mae: 0.39031 | valid_rmse: 0.47643 | valid_mse: 0.22698 |  0:00:10s\n",
      "epoch 10 | loss: 0.20528 | train_rmsle: 0.01454 | train_mae: 0.40642 | train_rmse: 0.49373 | train_mse: 0.24377 | valid_rmsle: 0.01465 | valid_mae: 0.41213 | valid_rmse: 0.50037 | valid_mse: 0.25037 |  0:00:12s\n",
      "epoch 11 | loss: 0.20287 | train_rmsle: 0.01353 | train_mae: 0.39097 | train_rmse: 0.4773  | train_mse: 0.22781 | valid_rmsle: 0.01377 | valid_mae: 0.3968  | valid_rmse: 0.4864  | valid_mse: 0.23659 |  0:00:13s\n",
      "epoch 12 | loss: 0.19711 | train_rmsle: 0.01115 | train_mae: 0.34441 | train_rmse: 0.42614 | train_mse: 0.18159 | valid_rmsle: 0.01103 | valid_mae: 0.34871 | valid_rmse: 0.42961 | valid_mse: 0.18456 |  0:00:14s\n",
      "epoch 13 | loss: 0.18554 | train_rmsle: 0.01057 | train_mae: 0.33728 | train_rmse: 0.41803 | train_mse: 0.17475 | valid_rmsle: 0.01066 | valid_mae: 0.34573 | valid_rmse: 0.42509 | valid_mse: 0.1807  |  0:00:15s\n",
      "epoch 14 | loss: 0.173   | train_rmsle: 0.00828 | train_mae: 0.29115 | train_rmse: 0.36542 | train_mse: 0.13353 | valid_rmsle: 0.00811 | valid_mae: 0.29179 | valid_rmse: 0.3662  | valid_mse: 0.1341  |  0:00:16s\n",
      "epoch 15 | loss: 0.15734 | train_rmsle: 0.00987 | train_mae: 0.34353 | train_rmse: 0.41318 | train_mse: 0.17072 | valid_rmsle: 0.00968 | valid_mae: 0.34125 | valid_rmse: 0.41209 | valid_mse: 0.16982 |  0:00:17s\n",
      "epoch 16 | loss: 0.13573 | train_rmsle: 0.00816 | train_mae: 0.30458 | train_rmse: 0.37464 | train_mse: 0.14036 | valid_rmsle: 0.00826 | valid_mae: 0.30579 | valid_rmse: 0.3778  | valid_mse: 0.14274 |  0:00:18s\n",
      "epoch 17 | loss: 0.11473 | train_rmsle: 0.00729 | train_mae: 0.28538 | train_rmse: 0.35314 | train_mse: 0.12471 | valid_rmsle: 0.00748 | valid_mae: 0.28999 | valid_rmse: 0.35813 | valid_mse: 0.12825 |  0:00:19s\n",
      "epoch 18 | loss: 0.09655 | train_rmsle: 0.00682 | train_mae: 0.2792  | train_rmse: 0.34121 | train_mse: 0.11643 | valid_rmsle: 0.00688 | valid_mae: 0.2814  | valid_rmse: 0.34369 | valid_mse: 0.11812 |  0:00:20s\n",
      "epoch 19 | loss: 0.08762 | train_rmsle: 0.00577 | train_mae: 0.25033 | train_rmse: 0.3119  | train_mse: 0.09728 | valid_rmsle: 0.00606 | valid_mae: 0.25705 | valid_rmse: 0.32098 | valid_mse: 0.10303 |  0:00:21s\n",
      "epoch 20 | loss: 0.08152 | train_rmsle: 0.00585 | train_mae: 0.2565  | train_rmse: 0.31528 | train_mse: 0.0994  | valid_rmsle: 0.00603 | valid_mae: 0.25912 | valid_rmse: 0.32143 | valid_mse: 0.10332 |  0:00:22s\n",
      "epoch 21 | loss: 0.07248 | train_rmsle: 0.00445 | train_mae: 0.21627 | train_rmse: 0.27126 | train_mse: 0.07358 | valid_rmsle: 0.00453 | valid_mae: 0.22005 | valid_rmse: 0.27616 | valid_mse: 0.07626 |  0:00:23s\n",
      "epoch 22 | loss: 0.06752 | train_rmsle: 0.00409 | train_mae: 0.20573 | train_rmse: 0.25913 | train_mse: 0.06715 | valid_rmsle: 0.0041  | valid_mae: 0.20932 | valid_rmse: 0.26278 | valid_mse: 0.06906 |  0:00:24s\n",
      "epoch 23 | loss: 0.06426 | train_rmsle: 0.00501 | train_mae: 0.23523 | train_rmse: 0.29049 | train_mse: 0.08438 | valid_rmsle: 0.00526 | valid_mae: 0.23845 | valid_rmse: 0.29925 | valid_mse: 0.08955 |  0:00:26s\n",
      "epoch 24 | loss: 0.05709 | train_rmsle: 0.00389 | train_mae: 0.20206 | train_rmse: 0.25309 | train_mse: 0.06406 | valid_rmsle: 0.00406 | valid_mae: 0.20365 | valid_rmse: 0.26067 | valid_mse: 0.06795 |  0:00:27s\n",
      "epoch 25 | loss: 0.05457 | train_rmsle: 0.00315 | train_mae: 0.18239 | train_rmse: 0.22979 | train_mse: 0.0528  | valid_rmsle: 0.00327 | valid_mae: 0.18693 | valid_rmse: 0.23708 | valid_mse: 0.05621 |  0:00:28s\n",
      "epoch 26 | loss: 0.05101 | train_rmsle: 0.00247 | train_mae: 0.15861 | train_rmse: 0.20292 | train_mse: 0.04118 | valid_rmsle: 0.00256 | valid_mae: 0.16302 | valid_rmse: 0.20944 | valid_mse: 0.04386 |  0:00:29s\n",
      "epoch 27 | loss: 0.04733 | train_rmsle: 0.00225 | train_mae: 0.15001 | train_rmse: 0.19296 | train_mse: 0.03723 | valid_rmsle: 0.00238 | valid_mae: 0.15716 | valid_rmse: 0.20233 | valid_mse: 0.04094 |  0:00:30s\n",
      "epoch 28 | loss: 0.04517 | train_rmsle: 0.00221 | train_mae: 0.1486  | train_rmse: 0.19173 | train_mse: 0.03676 | valid_rmsle: 0.00246 | valid_mae: 0.16015 | valid_rmse: 0.20534 | valid_mse: 0.04216 |  0:00:31s\n",
      "epoch 29 | loss: 0.04221 | train_rmsle: 0.00208 | train_mae: 0.14403 | train_rmse: 0.18736 | train_mse: 0.0351  | valid_rmsle: 0.00234 | valid_mae: 0.15711 | valid_rmse: 0.20165 | valid_mse: 0.04066 |  0:00:32s\n",
      "epoch 30 | loss: 0.03853 | train_rmsle: 0.00181 | train_mae: 0.13447 | train_rmse: 0.17454 | train_mse: 0.03046 | valid_rmsle: 0.00203 | valid_mae: 0.1463  | valid_rmse: 0.18763 | valid_mse: 0.0352  |  0:00:33s\n",
      "epoch 31 | loss: 0.03707 | train_rmsle: 0.00171 | train_mae: 0.13087 | train_rmse: 0.16802 | train_mse: 0.02823 | valid_rmsle: 0.00193 | valid_mae: 0.1421  | valid_rmse: 0.18173 | valid_mse: 0.03303 |  0:00:34s\n",
      "epoch 32 | loss: 0.03388 | train_rmsle: 0.00168 | train_mae: 0.13094 | train_rmse: 0.16755 | train_mse: 0.02807 | valid_rmsle: 0.00185 | valid_mae: 0.13883 | valid_rmse: 0.1788  | valid_mse: 0.03197 |  0:00:35s\n",
      "epoch 33 | loss: 0.03295 | train_rmsle: 0.00151 | train_mae: 0.11919 | train_rmse: 0.15767 | train_mse: 0.02486 | valid_rmsle: 0.00184 | valid_mae: 0.13772 | valid_rmse: 0.17818 | valid_mse: 0.03175 |  0:00:37s\n",
      "epoch 34 | loss: 0.03077 | train_rmsle: 0.00137 | train_mae: 0.11456 | train_rmse: 0.15088 | train_mse: 0.02277 | valid_rmsle: 0.00173 | valid_mae: 0.13491 | valid_rmse: 0.1734  | valid_mse: 0.03007 |  0:00:38s\n",
      "epoch 35 | loss: 0.02844 | train_rmsle: 0.00123 | train_mae: 0.10965 | train_rmse: 0.14452 | train_mse: 0.02089 | valid_rmsle: 0.00157 | valid_mae: 0.12835 | valid_rmse: 0.16694 | valid_mse: 0.02787 |  0:00:39s\n",
      "epoch 36 | loss: 0.03045 | train_rmsle: 0.00135 | train_mae: 0.11615 | train_rmse: 0.15208 | train_mse: 0.02313 | valid_rmsle: 0.00168 | valid_mae: 0.13412 | valid_rmse: 0.17348 | valid_mse: 0.03009 |  0:00:40s\n",
      "epoch 37 | loss: 0.02624 | train_rmsle: 0.0015  | train_mae: 0.12169 | train_rmse: 0.15771 | train_mse: 0.02487 | valid_rmsle: 0.0018  | valid_mae: 0.13816 | valid_rmse: 0.17644 | valid_mse: 0.03113 |  0:00:41s\n",
      "epoch 38 | loss: 0.02569 | train_rmsle: 0.00179 | train_mae: 0.14248 | train_rmse: 0.17645 | train_mse: 0.03114 | valid_rmsle: 0.00211 | valid_mae: 0.15368 | valid_rmse: 0.1944  | valid_mse: 0.03779 |  0:00:42s\n",
      "epoch 39 | loss: 0.02871 | train_rmsle: 0.00099 | train_mae: 0.09852 | train_rmse: 0.13168 | train_mse: 0.01734 | valid_rmsle: 0.00139 | valid_mae: 0.12166 | valid_rmse: 0.158   | valid_mse: 0.02496 |  0:00:43s\n",
      "epoch 40 | loss: 0.02326 | train_rmsle: 0.00109 | train_mae: 0.10408 | train_rmse: 0.13554 | train_mse: 0.01837 | valid_rmsle: 0.00139 | valid_mae: 0.12291 | valid_rmse: 0.15661 | valid_mse: 0.02453 |  0:00:44s\n",
      "epoch 41 | loss: 0.024   | train_rmsle: 0.00096 | train_mae: 0.09743 | train_rmse: 0.12873 | train_mse: 0.01657 | valid_rmsle: 0.00132 | valid_mae: 0.11889 | valid_rmse: 0.15382 | valid_mse: 0.02366 |  0:00:45s\n",
      "epoch 42 | loss: 0.02262 | train_rmsle: 0.00091 | train_mae: 0.09504 | train_rmse: 0.12522 | train_mse: 0.01568 | valid_rmsle: 0.00129 | valid_mae: 0.11641 | valid_rmse: 0.15133 | valid_mse: 0.0229  |  0:00:46s\n",
      "epoch 43 | loss: 0.02177 | train_rmsle: 0.00085 | train_mae: 0.0913  | train_rmse: 0.12205 | train_mse: 0.0149  | valid_rmsle: 0.00125 | valid_mae: 0.11637 | valid_rmse: 0.14984 | valid_mse: 0.02245 |  0:00:47s\n",
      "epoch 44 | loss: 0.0222  | train_rmsle: 0.00099 | train_mae: 0.10285 | train_rmse: 0.1321  | train_mse: 0.01745 | valid_rmsle: 0.00134 | valid_mae: 0.12085 | valid_rmse: 0.15542 | valid_mse: 0.02416 |  0:00:48s\n",
      "epoch 45 | loss: 0.02112 | train_rmsle: 0.00085 | train_mae: 0.08986 | train_rmse: 0.12032 | train_mse: 0.01448 | valid_rmsle: 0.00131 | valid_mae: 0.1177  | valid_rmse: 0.15104 | valid_mse: 0.02281 |  0:00:49s\n",
      "epoch 46 | loss: 0.02141 | train_rmsle: 0.00075 | train_mae: 0.08578 | train_rmse: 0.11605 | train_mse: 0.01347 | valid_rmsle: 0.00118 | valid_mae: 0.11186 | valid_rmse: 0.14569 | valid_mse: 0.02123 |  0:00:50s\n",
      "epoch 47 | loss: 0.01909 | train_rmsle: 0.00077 | train_mae: 0.08768 | train_rmse: 0.11638 | train_mse: 0.01354 | valid_rmsle: 0.0012  | valid_mae: 0.11392 | valid_rmse: 0.14708 | valid_mse: 0.02163 |  0:00:51s\n",
      "epoch 48 | loss: 0.01994 | train_rmsle: 0.00092 | train_mae: 0.09923 | train_rmse: 0.12853 | train_mse: 0.01652 | valid_rmsle: 0.00138 | valid_mae: 0.12529 | valid_rmse: 0.159   | valid_mse: 0.02528 |  0:00:53s\n",
      "epoch 49 | loss: 0.01904 | train_rmsle: 0.00064 | train_mae: 0.07815 | train_rmse: 0.10573 | train_mse: 0.01118 | valid_rmsle: 0.00107 | valid_mae: 0.10625 | valid_rmse: 0.13886 | valid_mse: 0.01928 |  0:00:54s\n",
      "epoch 50 | loss: 0.01799 | train_rmsle: 0.00064 | train_mae: 0.07809 | train_rmse: 0.1062  | train_mse: 0.01128 | valid_rmsle: 0.00106 | valid_mae: 0.10562 | valid_rmse: 0.1381  | valid_mse: 0.01907 |  0:00:55s\n",
      "epoch 51 | loss: 0.01738 | train_rmsle: 0.00105 | train_mae: 0.1094  | train_rmse: 0.13432 | train_mse: 0.01804 | valid_rmsle: 0.00148 | valid_mae: 0.12837 | valid_rmse: 0.16182 | valid_mse: 0.02619 |  0:00:56s\n",
      "epoch 52 | loss: 0.0242  | train_rmsle: 0.00106 | train_mae: 0.10526 | train_rmse: 0.13275 | train_mse: 0.01762 | valid_rmsle: 0.00159 | valid_mae: 0.12885 | valid_rmse: 0.16556 | valid_mse: 0.02741 |  0:00:57s\n",
      "epoch 53 | loss: 0.02045 | train_rmsle: 0.00085 | train_mae: 0.08273 | train_rmse: 0.11746 | train_mse: 0.0138  | valid_rmsle: 0.00135 | valid_mae: 0.1108  | valid_rmse: 0.1513  | valid_mse: 0.02289 |  0:00:58s\n",
      "epoch 54 | loss: 0.02016 | train_rmsle: 0.00116 | train_mae: 0.11838 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00157 | valid_mae: 0.13486 | valid_rmse: 0.17147 | valid_mse: 0.0294  |  0:00:59s\n",
      "epoch 55 | loss: 0.01841 | train_rmsle: 0.00058 | train_mae: 0.07578 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00099 | valid_mae: 0.1025  | valid_rmse: 0.13446 | valid_mse: 0.01808 |  0:01:00s\n",
      "epoch 56 | loss: 0.0161  | train_rmsle: 0.00065 | train_mae: 0.07923 | train_rmse: 0.10638 | train_mse: 0.01132 | valid_rmsle: 0.00106 | valid_mae: 0.10562 | valid_rmse: 0.13728 | valid_mse: 0.01885 |  0:01:01s\n",
      "epoch 57 | loss: 0.01521 | train_rmsle: 0.00056 | train_mae: 0.07342 | train_rmse: 0.0971  | train_mse: 0.00943 | valid_rmsle: 0.00098 | valid_mae: 0.10094 | valid_rmse: 0.1319  | valid_mse: 0.0174  |  0:01:02s\n",
      "epoch 58 | loss: 0.0149  | train_rmsle: 0.00049 | train_mae: 0.06868 | train_rmse: 0.09191 | train_mse: 0.00845 | valid_rmsle: 0.00092 | valid_mae: 0.09662 | valid_rmse: 0.12803 | valid_mse: 0.01639 |  0:01:03s\n",
      "epoch 59 | loss: 0.01449 | train_rmsle: 0.00049 | train_mae: 0.06928 | train_rmse: 0.09197 | train_mse: 0.00846 | valid_rmsle: 0.0009  | valid_mae: 0.09668 | valid_rmse: 0.12715 | valid_mse: 0.01617 |  0:01:04s\n",
      "epoch 60 | loss: 0.01417 | train_rmsle: 0.0007  | train_mae: 0.08991 | train_rmse: 0.11524 | train_mse: 0.01328 | valid_rmsle: 0.00112 | valid_mae: 0.11363 | valid_rmse: 0.14538 | valid_mse: 0.02114 |  0:01:06s\n",
      "epoch 61 | loss: 0.01627 | train_rmsle: 0.00048 | train_mae: 0.06875 | train_rmse: 0.09059 | train_mse: 0.00821 | valid_rmsle: 0.00087 | valid_mae: 0.09474 | valid_rmse: 0.12417 | valid_mse: 0.01542 |  0:01:07s\n",
      "epoch 62 | loss: 0.01374 | train_rmsle: 0.0005  | train_mae: 0.07178 | train_rmse: 0.09485 | train_mse: 0.009   | valid_rmsle: 0.00088 | valid_mae: 0.09755 | valid_rmse: 0.12629 | valid_mse: 0.01595 |  0:01:08s\n",
      "epoch 63 | loss: 0.01461 | train_rmsle: 0.00063 | train_mae: 0.07918 | train_rmse: 0.10355 | train_mse: 0.01072 | valid_rmsle: 0.00102 | valid_mae: 0.10455 | valid_rmse: 0.13381 | valid_mse: 0.01791 |  0:01:09s\n",
      "epoch 64 | loss: 0.01675 | train_rmsle: 0.0006  | train_mae: 0.07811 | train_rmse: 0.10297 | train_mse: 0.0106  | valid_rmsle: 0.00103 | valid_mae: 0.10458 | valid_rmse: 0.13639 | valid_mse: 0.0186  |  0:01:10s\n",
      "epoch 65 | loss: 0.01735 | train_rmsle: 0.00147 | train_mae: 0.13071 | train_rmse: 0.15792 | train_mse: 0.02494 | valid_rmsle: 0.00185 | valid_mae: 0.14572 | valid_rmse: 0.17968 | valid_mse: 0.03228 |  0:01:11s\n",
      "epoch 66 | loss: 0.02068 | train_rmsle: 0.00063 | train_mae: 0.08248 | train_rmse: 0.10746 | train_mse: 0.01155 | valid_rmsle: 0.00103 | valid_mae: 0.10393 | valid_rmse: 0.13656 | valid_mse: 0.01865 |  0:01:12s\n",
      "epoch 67 | loss: 0.01504 | train_rmsle: 0.00053 | train_mae: 0.07459 | train_rmse: 0.09624 | train_mse: 0.00926 | valid_rmsle: 0.00088 | valid_mae: 0.09606 | valid_rmse: 0.12567 | valid_mse: 0.01579 |  0:01:13s\n",
      "epoch 68 | loss: 0.01244 | train_rmsle: 0.00048 | train_mae: 0.06998 | train_rmse: 0.09335 | train_mse: 0.00871 | valid_rmsle: 0.00088 | valid_mae: 0.09611 | valid_rmse: 0.12569 | valid_mse: 0.0158  |  0:01:14s\n",
      "epoch 69 | loss: 0.01269 | train_rmsle: 0.00071 | train_mae: 0.08341 | train_rmse: 0.10586 | train_mse: 0.01121 | valid_rmsle: 0.00113 | valid_mae: 0.10886 | valid_rmse: 0.1372  | valid_mse: 0.01882 |  0:01:15s\n",
      "epoch 70 | loss: 0.01455 | train_rmsle: 0.00057 | train_mae: 0.07919 | train_rmse: 0.09901 | train_mse: 0.0098  | valid_rmsle: 0.00097 | valid_mae: 0.10228 | valid_rmse: 0.13097 | valid_mse: 0.01715 |  0:01:16s\n",
      "epoch 71 | loss: 0.01377 | train_rmsle: 0.00055 | train_mae: 0.07781 | train_rmse: 0.09783 | train_mse: 0.00957 | valid_rmsle: 0.00096 | valid_mae: 0.10211 | valid_rmse: 0.12959 | valid_mse: 0.01679 |  0:01:17s\n",
      "epoch 72 | loss: 0.01354 | train_rmsle: 0.00037 | train_mae: 0.06129 | train_rmse: 0.08059 | train_mse: 0.00649 | valid_rmsle: 0.00079 | valid_mae: 0.08974 | valid_rmse: 0.11828 | valid_mse: 0.01399 |  0:01:19s\n",
      "epoch 73 | loss: 0.01564 | train_rmsle: 0.00038 | train_mae: 0.06153 | train_rmse: 0.08271 | train_mse: 0.00684 | valid_rmsle: 0.00077 | valid_mae: 0.08881 | valid_rmse: 0.11811 | valid_mse: 0.01395 |  0:01:20s\n",
      "epoch 74 | loss: 0.01201 | train_rmsle: 0.00035 | train_mae: 0.06105 | train_rmse: 0.08029 | train_mse: 0.00645 | valid_rmsle: 0.0008  | valid_mae: 0.09047 | valid_rmse: 0.12007 | valid_mse: 0.01442 |  0:01:21s\n",
      "epoch 75 | loss: 0.01388 | train_rmsle: 0.00053 | train_mae: 0.07732 | train_rmse: 0.09776 | train_mse: 0.00956 | valid_rmsle: 0.00101 | valid_mae: 0.10499 | valid_rmse: 0.13536 | valid_mse: 0.01832 |  0:01:22s\n",
      "epoch 76 | loss: 0.01281 | train_rmsle: 0.00046 | train_mae: 0.07264 | train_rmse: 0.09205 | train_mse: 0.00847 | valid_rmsle: 0.00092 | valid_mae: 0.09978 | valid_rmse: 0.12984 | valid_mse: 0.01686 |  0:01:23s\n",
      "epoch 77 | loss: 0.01224 | train_rmsle: 0.00042 | train_mae: 0.06793 | train_rmse: 0.0856  | train_mse: 0.00733 | valid_rmsle: 0.00085 | valid_mae: 0.09487 | valid_rmse: 0.12295 | valid_mse: 0.01512 |  0:01:24s\n",
      "epoch 78 | loss: 0.01195 | train_rmsle: 0.00053 | train_mae: 0.07083 | train_rmse: 0.09043 | train_mse: 0.00818 | valid_rmsle: 0.00095 | valid_mae: 0.09739 | valid_rmse: 0.12555 | valid_mse: 0.01576 |  0:01:25s\n",
      "epoch 79 | loss: 0.01158 | train_rmsle: 0.00033 | train_mae: 0.05839 | train_rmse: 0.07731 | train_mse: 0.00598 | valid_rmsle: 0.00076 | valid_mae: 0.08874 | valid_rmse: 0.11694 | valid_mse: 0.01367 |  0:01:26s\n",
      "epoch 80 | loss: 0.01426 | train_rmsle: 0.0006  | train_mae: 0.0763  | train_rmse: 0.09623 | train_mse: 0.00926 | valid_rmsle: 0.00099 | valid_mae: 0.09926 | valid_rmse: 0.1275  | valid_mse: 0.01626 |  0:01:27s\n",
      "epoch 81 | loss: 0.01411 | train_rmsle: 0.00066 | train_mae: 0.09176 | train_rmse: 0.11099 | train_mse: 0.01232 | valid_rmsle: 0.00109 | valid_mae: 0.11316 | valid_rmse: 0.14133 | valid_mse: 0.01997 |  0:01:28s\n",
      "epoch 82 | loss: 0.01427 | train_rmsle: 0.00046 | train_mae: 0.07212 | train_rmse: 0.08956 | train_mse: 0.00802 | valid_rmsle: 0.00087 | valid_mae: 0.09667 | valid_rmse: 0.12416 | valid_mse: 0.01542 |  0:01:29s\n",
      "epoch 83 | loss: 0.01166 | train_rmsle: 0.00041 | train_mae: 0.06736 | train_rmse: 0.08621 | train_mse: 0.00743 | valid_rmsle: 0.00081 | valid_mae: 0.09298 | valid_rmse: 0.12119 | valid_mse: 0.01469 |  0:01:30s\n",
      "epoch 84 | loss: 0.01301 | train_rmsle: 0.00047 | train_mae: 0.06957 | train_rmse: 0.09212 | train_mse: 0.00849 | valid_rmsle: 0.00085 | valid_mae: 0.09436 | valid_rmse: 0.12433 | valid_mse: 0.01546 |  0:01:32s\n",
      "epoch 85 | loss: 0.01271 | train_rmsle: 0.00057 | train_mae: 0.07213 | train_rmse: 0.09577 | train_mse: 0.00917 | valid_rmsle: 0.00099 | valid_mae: 0.09776 | valid_rmse: 0.12997 | valid_mse: 0.01689 |  0:01:33s\n",
      "epoch 86 | loss: 0.01208 | train_rmsle: 0.00034 | train_mae: 0.06019 | train_rmse: 0.07949 | train_mse: 0.00632 | valid_rmsle: 0.00078 | valid_mae: 0.08898 | valid_rmse: 0.11838 | valid_mse: 0.01401 |  0:01:34s\n",
      "epoch 87 | loss: 0.01437 | train_rmsle: 0.00141 | train_mae: 0.14317 | train_rmse: 0.16157 | train_mse: 0.0261  | valid_rmsle: 0.00186 | valid_mae: 0.15334 | valid_rmse: 0.1839  | valid_mse: 0.03382 |  0:01:35s\n",
      "epoch 88 | loss: 0.01857 | train_rmsle: 0.00051 | train_mae: 0.07234 | train_rmse: 0.09782 | train_mse: 0.00957 | valid_rmsle: 0.00093 | valid_mae: 0.09855 | valid_rmse: 0.12995 | valid_mse: 0.01689 |  0:01:36s\n",
      "epoch 89 | loss: 0.01461 | train_rmsle: 0.00057 | train_mae: 0.07719 | train_rmse: 0.10024 | train_mse: 0.01005 | valid_rmsle: 0.00096 | valid_mae: 0.09858 | valid_rmse: 0.12863 | valid_mse: 0.01655 |  0:01:37s\n",
      "epoch 90 | loss: 0.01455 | train_rmsle: 0.00141 | train_mae: 0.11548 | train_rmse: 0.14151 | train_mse: 0.02002 | valid_rmsle: 0.00174 | valid_mae: 0.13098 | valid_rmse: 0.16173 | valid_mse: 0.02616 |  0:01:38s\n",
      "epoch 91 | loss: 0.01507 | train_rmsle: 0.00049 | train_mae: 0.07219 | train_rmse: 0.09122 | train_mse: 0.00832 | valid_rmsle: 0.00088 | valid_mae: 0.0948  | valid_rmse: 0.12339 | valid_mse: 0.01523 |  0:01:39s\n",
      "epoch 92 | loss: 0.0141  | train_rmsle: 0.00034 | train_mae: 0.06074 | train_rmse: 0.07933 | train_mse: 0.00629 | valid_rmsle: 0.00075 | valid_mae: 0.08659 | valid_rmse: 0.11512 | valid_mse: 0.01325 |  0:01:40s\n",
      "epoch 93 | loss: 0.01373 | train_rmsle: 0.00058 | train_mae: 0.07543 | train_rmse: 0.0969  | train_mse: 0.00939 | valid_rmsle: 0.00097 | valid_mae: 0.09762 | valid_rmse: 0.1272  | valid_mse: 0.01618 |  0:01:41s\n",
      "epoch 94 | loss: 0.01241 | train_rmsle: 0.00039 | train_mae: 0.06289 | train_rmse: 0.08331 | train_mse: 0.00694 | valid_rmsle: 0.00076 | valid_mae: 0.08898 | valid_rmse: 0.11633 | valid_mse: 0.01353 |  0:01:42s\n",
      "epoch 95 | loss: 0.01062 | train_rmsle: 0.0004  | train_mae: 0.06417 | train_rmse: 0.08354 | train_mse: 0.00698 | valid_rmsle: 0.00074 | valid_mae: 0.08821 | valid_rmse: 0.11468 | valid_mse: 0.01315 |  0:01:44s\n",
      "epoch 96 | loss: 0.01016 | train_rmsle: 0.00037 | train_mae: 0.06394 | train_rmse: 0.0821  | train_mse: 0.00674 | valid_rmsle: 0.00074 | valid_mae: 0.08738 | valid_rmse: 0.11366 | valid_mse: 0.01292 |  0:01:45s\n",
      "epoch 97 | loss: 0.0116  | train_rmsle: 0.00031 | train_mae: 0.05821 | train_rmse: 0.07632 | train_mse: 0.00582 | valid_rmsle: 0.0007  | valid_mae: 0.08495 | valid_rmse: 0.11165 | valid_mse: 0.01247 |  0:01:46s\n",
      "epoch 98 | loss: 0.01182 | train_rmsle: 0.00029 | train_mae: 0.05539 | train_rmse: 0.07232 | train_mse: 0.00523 | valid_rmsle: 0.00069 | valid_mae: 0.0838  | valid_rmse: 0.10975 | valid_mse: 0.01204 |  0:01:47s\n",
      "epoch 99 | loss: 0.01042 | train_rmsle: 0.00026 | train_mae: 0.05285 | train_rmse: 0.0693  | train_mse: 0.0048  | valid_rmsle: 0.00063 | valid_mae: 0.08002 | valid_rmse: 0.10545 | valid_mse: 0.01112 |  0:01:48s\n",
      "epoch 100| loss: 0.01216 | train_rmsle: 0.00058 | train_mae: 0.08634 | train_rmse: 0.10335 | train_mse: 0.01068 | valid_rmsle: 0.001   | valid_mae: 0.10539 | valid_rmse: 0.13394 | valid_mse: 0.01794 |  0:01:49s\n",
      "epoch 101| loss: 0.01027 | train_rmsle: 0.00033 | train_mae: 0.05733 | train_rmse: 0.07399 | train_mse: 0.00547 | valid_rmsle: 0.00076 | valid_mae: 0.08613 | valid_rmse: 0.11393 | valid_mse: 0.01298 |  0:01:50s\n",
      "epoch 102| loss: 0.01319 | train_rmsle: 0.00058 | train_mae: 0.08679 | train_rmse: 0.10343 | train_mse: 0.0107  | valid_rmsle: 0.00096 | valid_mae: 0.10638 | valid_rmse: 0.13197 | valid_mse: 0.01742 |  0:01:51s\n",
      "epoch 103| loss: 0.01284 | train_rmsle: 0.00032 | train_mae: 0.0563  | train_rmse: 0.07222 | train_mse: 0.00522 | valid_rmsle: 0.00074 | valid_mae: 0.08511 | valid_rmse: 0.1118  | valid_mse: 0.0125  |  0:01:52s\n",
      "epoch 104| loss: 0.01066 | train_rmsle: 0.00029 | train_mae: 0.05411 | train_rmse: 0.06944 | train_mse: 0.00482 | valid_rmsle: 0.00069 | valid_mae: 0.08249 | valid_rmse: 0.1085  | valid_mse: 0.01177 |  0:01:53s\n",
      "epoch 105| loss: 0.01216 | train_rmsle: 0.00041 | train_mae: 0.06436 | train_rmse: 0.08017 | train_mse: 0.00643 | valid_rmsle: 0.00078 | valid_mae: 0.08804 | valid_rmse: 0.11414 | valid_mse: 0.01303 |  0:01:54s\n",
      "epoch 106| loss: 0.00974 | train_rmsle: 0.00031 | train_mae: 0.05412 | train_rmse: 0.06979 | train_mse: 0.00487 | valid_rmsle: 0.0007  | valid_mae: 0.08198 | valid_rmse: 0.10768 | valid_mse: 0.01159 |  0:01:56s\n",
      "epoch 107| loss: 0.01202 | train_rmsle: 0.00023 | train_mae: 0.05099 | train_rmse: 0.06587 | train_mse: 0.00434 | valid_rmsle: 0.00062 | valid_mae: 0.08084 | valid_rmse: 0.10497 | valid_mse: 0.01102 |  0:01:57s\n",
      "epoch 108| loss: 0.01103 | train_rmsle: 0.00025 | train_mae: 0.05019 | train_rmse: 0.0649  | train_mse: 0.00421 | valid_rmsle: 0.00061 | valid_mae: 0.07931 | valid_rmse: 0.10352 | valid_mse: 0.01072 |  0:01:58s\n",
      "epoch 109| loss: 0.01116 | train_rmsle: 0.00026 | train_mae: 0.05249 | train_rmse: 0.0677  | train_mse: 0.00458 | valid_rmsle: 0.00064 | valid_mae: 0.08081 | valid_rmse: 0.10584 | valid_mse: 0.0112  |  0:01:59s\n",
      "epoch 110| loss: 0.01144 | train_rmsle: 0.00028 | train_mae: 0.05332 | train_rmse: 0.06914 | train_mse: 0.00478 | valid_rmsle: 0.00066 | valid_mae: 0.08118 | valid_rmse: 0.10625 | valid_mse: 0.01129 |  0:02:00s\n",
      "epoch 111| loss: 0.01135 | train_rmsle: 0.00024 | train_mae: 0.04948 | train_rmse: 0.06543 | train_mse: 0.00428 | valid_rmsle: 0.00062 | valid_mae: 0.0783  | valid_rmse: 0.10375 | valid_mse: 0.01076 |  0:02:01s\n",
      "epoch 112| loss: 0.00978 | train_rmsle: 0.00029 | train_mae: 0.05721 | train_rmse: 0.07448 | train_mse: 0.00555 | valid_rmsle: 0.00067 | valid_mae: 0.08496 | valid_rmse: 0.10996 | valid_mse: 0.01209 |  0:02:02s\n",
      "epoch 113| loss: 0.00944 | train_rmsle: 0.0002  | train_mae: 0.046   | train_rmse: 0.05994 | train_mse: 0.00359 | valid_rmsle: 0.0006  | valid_mae: 0.07757 | valid_rmse: 0.10246 | valid_mse: 0.0105  |  0:02:03s\n",
      "epoch 114| loss: 0.00888 | train_rmsle: 0.0002  | train_mae: 0.04703 | train_rmse: 0.06116 | train_mse: 0.00374 | valid_rmsle: 0.00059 | valid_mae: 0.07632 | valid_rmse: 0.10072 | valid_mse: 0.01014 |  0:02:04s\n",
      "epoch 115| loss: 0.01009 | train_rmsle: 0.00029 | train_mae: 0.05755 | train_rmse: 0.07494 | train_mse: 0.00562 | valid_rmsle: 0.00065 | valid_mae: 0.08419 | valid_rmse: 0.10848 | valid_mse: 0.01177 |  0:02:05s\n",
      "epoch 116| loss: 0.0124  | train_rmsle: 0.00054 | train_mae: 0.08404 | train_rmse: 0.10035 | train_mse: 0.01007 | valid_rmsle: 0.00092 | valid_mae: 0.10514 | valid_rmse: 0.12964 | valid_mse: 0.01681 |  0:02:06s\n",
      "epoch 117| loss: 0.0136  | train_rmsle: 0.00039 | train_mae: 0.06411 | train_rmse: 0.08477 | train_mse: 0.00719 | valid_rmsle: 0.00077 | valid_mae: 0.09007 | valid_rmse: 0.11667 | valid_mse: 0.01361 |  0:02:08s\n",
      "epoch 118| loss: 0.013   | train_rmsle: 0.0004  | train_mae: 0.06493 | train_rmse: 0.08877 | train_mse: 0.00788 | valid_rmsle: 0.00078 | valid_mae: 0.09004 | valid_rmse: 0.1192  | valid_mse: 0.01421 |  0:02:09s\n",
      "epoch 119| loss: 0.01226 | train_rmsle: 0.00046 | train_mae: 0.06989 | train_rmse: 0.08876 | train_mse: 0.00788 | valid_rmsle: 0.00084 | valid_mae: 0.09188 | valid_rmse: 0.1185  | valid_mse: 0.01404 |  0:02:10s\n",
      "epoch 120| loss: 0.01285 | train_rmsle: 0.00025 | train_mae: 0.05103 | train_rmse: 0.06855 | train_mse: 0.0047  | valid_rmsle: 0.00065 | valid_mae: 0.08076 | valid_rmse: 0.10587 | valid_mse: 0.01121 |  0:02:11s\n",
      "epoch 121| loss: 0.01072 | train_rmsle: 0.00027 | train_mae: 0.05345 | train_rmse: 0.07031 | train_mse: 0.00494 | valid_rmsle: 0.00066 | valid_mae: 0.08197 | valid_rmse: 0.10723 | valid_mse: 0.0115  |  0:02:12s\n",
      "epoch 122| loss: 0.01055 | train_rmsle: 0.00028 | train_mae: 0.05208 | train_rmse: 0.06988 | train_mse: 0.00488 | valid_rmsle: 0.00067 | valid_mae: 0.08184 | valid_rmse: 0.10773 | valid_mse: 0.01161 |  0:02:13s\n",
      "epoch 123| loss: 0.01262 | train_rmsle: 0.00039 | train_mae: 0.06752 | train_rmse: 0.08694 | train_mse: 0.00756 | valid_rmsle: 0.0008  | valid_mae: 0.09418 | valid_rmse: 0.12025 | valid_mse: 0.01446 |  0:02:14s\n",
      "epoch 124| loss: 0.01281 | train_rmsle: 0.00026 | train_mae: 0.0533  | train_rmse: 0.06958 | train_mse: 0.00484 | valid_rmsle: 0.00067 | valid_mae: 0.08454 | valid_rmse: 0.10874 | valid_mse: 0.01182 |  0:02:15s\n",
      "epoch 125| loss: 0.01147 | train_rmsle: 0.0002  | train_mae: 0.04637 | train_rmse: 0.06195 | train_mse: 0.00384 | valid_rmsle: 0.00061 | valid_mae: 0.07912 | valid_rmse: 0.10281 | valid_mse: 0.01057 |  0:02:16s\n",
      "epoch 126| loss: 0.01117 | train_rmsle: 0.00022 | train_mae: 0.04876 | train_rmse: 0.06354 | train_mse: 0.00404 | valid_rmsle: 0.00063 | valid_mae: 0.08104 | valid_rmse: 0.10474 | valid_mse: 0.01097 |  0:02:17s\n",
      "epoch 127| loss: 0.00922 | train_rmsle: 0.00022 | train_mae: 0.04847 | train_rmse: 0.06305 | train_mse: 0.00397 | valid_rmsle: 0.00065 | valid_mae: 0.08071 | valid_rmse: 0.10555 | valid_mse: 0.01114 |  0:02:18s\n",
      "epoch 128| loss: 0.00968 | train_rmsle: 0.00023 | train_mae: 0.04915 | train_rmse: 0.06387 | train_mse: 0.00408 | valid_rmsle: 0.00065 | valid_mae: 0.08074 | valid_rmse: 0.10537 | valid_mse: 0.0111  |  0:02:19s\n",
      "epoch 129| loss: 0.00939 | train_rmsle: 0.00036 | train_mae: 0.05718 | train_rmse: 0.07373 | train_mse: 0.00544 | valid_rmsle: 0.00075 | valid_mae: 0.08484 | valid_rmse: 0.11078 | valid_mse: 0.01227 |  0:02:21s\n",
      "epoch 130| loss: 0.01023 | train_rmsle: 0.00042 | train_mae: 0.06906 | train_rmse: 0.08816 | train_mse: 0.00777 | valid_rmsle: 0.00085 | valid_mae: 0.09522 | valid_rmse: 0.12216 | valid_mse: 0.01492 |  0:02:22s\n",
      "epoch 131| loss: 0.00912 | train_rmsle: 0.00026 | train_mae: 0.0549  | train_rmse: 0.07146 | train_mse: 0.00511 | valid_rmsle: 0.00069 | valid_mae: 0.08444 | valid_rmse: 0.1103  | valid_mse: 0.01217 |  0:02:23s\n",
      "epoch 132| loss: 0.01075 | train_rmsle: 0.00034 | train_mae: 0.05742 | train_rmse: 0.07462 | train_mse: 0.00557 | valid_rmsle: 0.00071 | valid_mae: 0.08574 | valid_rmse: 0.10969 | valid_mse: 0.01203 |  0:02:24s\n",
      "epoch 133| loss: 0.01219 | train_rmsle: 0.00101 | train_mae: 0.12393 | train_rmse: 0.1389  | train_mse: 0.01929 | valid_rmsle: 0.00135 | valid_mae: 0.13413 | valid_rmse: 0.15901 | valid_mse: 0.02529 |  0:02:25s\n",
      "epoch 134| loss: 0.01261 | train_rmsle: 0.00021 | train_mae: 0.04799 | train_rmse: 0.06313 | train_mse: 0.00399 | valid_rmsle: 0.00065 | valid_mae: 0.08042 | valid_rmse: 0.10539 | valid_mse: 0.01111 |  0:02:26s\n",
      "\n",
      "Early stopping occurred at epoch 134 with best_epoch = 114 and best_valid_mse = 0.01014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010907166719125323 RMSE: 0.10443738180903102 R2: 0.9517181756683668 MAE: 0.07995015796559761\n",
      "=====================================\n",
      "[77/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 7.65764 | train_rmsle: 0.18577 | train_mae: 1.46954 | train_rmse: 1.54441 | train_mse: 2.38519 | valid_rmsle: 0.18658 | valid_mae: 1.47413 | valid_rmse: 1.54865 | valid_mse: 2.39831 |  0:00:01s\n",
      "epoch 1  | loss: 1.11933 | train_rmsle: 0.07433 | train_mae: 0.97433 | train_rmse: 1.06538 | train_mse: 1.13502 | valid_rmsle: 0.07458 | valid_mae: 0.9764  | valid_rmse: 1.06878 | valid_mse: 1.14229 |  0:00:02s\n",
      "epoch 2  | loss: 0.49055 | train_rmsle: 0.05013 | train_mae: 0.80516 | train_rmse: 0.89925 | train_mse: 0.80866 | valid_rmsle: 0.05023 | valid_mae: 0.80579 | valid_rmse: 0.90228 | valid_mse: 0.81411 |  0:00:03s\n",
      "epoch 3  | loss: 0.35894 | train_rmsle: 0.0426  | train_mae: 0.74298 | train_rmse: 0.83671 | train_mse: 0.70009 | valid_rmsle: 0.04256 | valid_mae: 0.7421  | valid_rmse: 0.83878 | valid_mse: 0.70354 |  0:00:04s\n",
      "epoch 4  | loss: 0.28264 | train_rmsle: 0.03243 | train_mae: 0.64853 | train_rmse: 0.7391  | train_mse: 0.54627 | valid_rmsle: 0.03224 | valid_mae: 0.64775 | valid_rmse: 0.73985 | valid_mse: 0.54737 |  0:00:05s\n",
      "epoch 5  | loss: 0.25765 | train_rmsle: 0.02613 | train_mae: 0.5781  | train_rmse: 0.66747 | train_mse: 0.44551 | valid_rmsle: 0.02604 | valid_mae: 0.57947 | valid_rmse: 0.66939 | valid_mse: 0.44809 |  0:00:06s\n",
      "epoch 6  | loss: 0.23853 | train_rmsle: 0.0205  | train_mae: 0.50413 | train_rmse: 0.59204 | train_mse: 0.35052 | valid_rmsle: 0.02018 | valid_mae: 0.50425 | valid_rmse: 0.59109 | valid_mse: 0.34939 |  0:00:07s\n",
      "epoch 7  | loss: 0.22578 | train_rmsle: 0.01783 | train_mae: 0.46024 | train_rmse: 0.5502  | train_mse: 0.30272 | valid_rmsle: 0.0176  | valid_mae: 0.46132 | valid_rmse: 0.55053 | valid_mse: 0.30308 |  0:00:08s\n",
      "epoch 8  | loss: 0.21382 | train_rmsle: 0.01637 | train_mae: 0.43847 | train_rmse: 0.52629 | train_mse: 0.27698 | valid_rmsle: 0.01614 | valid_mae: 0.44113 | valid_rmse: 0.52697 | valid_mse: 0.2777  |  0:00:09s\n",
      "epoch 9  | loss: 0.20513 | train_rmsle: 0.01353 | train_mae: 0.37812 | train_rmse: 0.46953 | train_mse: 0.22046 | valid_rmsle: 0.01322 | valid_mae: 0.38074 | valid_rmse: 0.46924 | valid_mse: 0.22019 |  0:00:10s\n",
      "epoch 10 | loss: 0.19859 | train_rmsle: 0.01424 | train_mae: 0.39245 | train_rmse: 0.48446 | train_mse: 0.2347  | valid_rmsle: 0.01395 | valid_mae: 0.39547 | valid_rmse: 0.48423 | valid_mse: 0.23448 |  0:00:12s\n",
      "epoch 11 | loss: 0.18859 | train_rmsle: 0.01394 | train_mae: 0.39023 | train_rmse: 0.47977 | train_mse: 0.23018 | valid_rmsle: 0.01362 | valid_mae: 0.39406 | valid_rmse: 0.47898 | valid_mse: 0.22942 |  0:00:13s\n",
      "epoch 12 | loss: 0.18835 | train_rmsle: 0.01441 | train_mae: 0.40053 | train_rmse: 0.49008 | train_mse: 0.24018 | valid_rmsle: 0.01431 | valid_mae: 0.40608 | valid_rmse: 0.49263 | valid_mse: 0.24268 |  0:00:14s\n",
      "epoch 13 | loss: 0.18952 | train_rmsle: 0.01391 | train_mae: 0.39076 | train_rmse: 0.48055 | train_mse: 0.23093 | valid_rmsle: 0.0138  | valid_mae: 0.39518 | valid_rmse: 0.48315 | valid_mse: 0.23344 |  0:00:15s\n",
      "epoch 14 | loss: 0.17848 | train_rmsle: 0.01283 | train_mae: 0.36537 | train_rmse: 0.45637 | train_mse: 0.20827 | valid_rmsle: 0.01252 | valid_mae: 0.36786 | valid_rmse: 0.45554 | valid_mse: 0.20752 |  0:00:16s\n",
      "epoch 15 | loss: 0.17265 | train_rmsle: 0.01293 | train_mae: 0.37178 | train_rmse: 0.45971 | train_mse: 0.21133 | valid_rmsle: 0.01269 | valid_mae: 0.37537 | valid_rmse: 0.46023 | valid_mse: 0.21181 |  0:00:17s\n",
      "epoch 16 | loss: 0.1709  | train_rmsle: 0.0128  | train_mae: 0.36781 | train_rmse: 0.45721 | train_mse: 0.20904 | valid_rmsle: 0.01261 | valid_mae: 0.36947 | valid_rmse: 0.4582  | valid_mse: 0.20994 |  0:00:18s\n",
      "epoch 17 | loss: 0.16793 | train_rmsle: 0.01221 | train_mae: 0.35458 | train_rmse: 0.444   | train_mse: 0.19714 | valid_rmsle: 0.01231 | valid_mae: 0.36332 | valid_rmse: 0.4513  | valid_mse: 0.20367 |  0:00:19s\n",
      "epoch 18 | loss: 0.16423 | train_rmsle: 0.01222 | train_mae: 0.35668 | train_rmse: 0.44548 | train_mse: 0.19845 | valid_rmsle: 0.01238 | valid_mae: 0.36658 | valid_rmse: 0.45367 | valid_mse: 0.20582 |  0:00:20s\n",
      "epoch 19 | loss: 0.15921 | train_rmsle: 0.0119  | train_mae: 0.353   | train_rmse: 0.4401  | train_mse: 0.19368 | valid_rmsle: 0.01224 | valid_mae: 0.36586 | valid_rmse: 0.45213 | valid_mse: 0.20443 |  0:00:21s\n",
      "epoch 20 | loss: 0.15368 | train_rmsle: 0.0119  | train_mae: 0.35461 | train_rmse: 0.44133 | train_mse: 0.19478 | valid_rmsle: 0.0127  | valid_mae: 0.37467 | valid_rmse: 0.46165 | valid_mse: 0.21312 |  0:00:23s\n",
      "epoch 21 | loss: 0.14985 | train_rmsle: 0.01115 | train_mae: 0.33822 | train_rmse: 0.42471 | train_mse: 0.18038 | valid_rmsle: 0.01192 | valid_mae: 0.35723 | valid_rmse: 0.4451  | valid_mse: 0.19811 |  0:00:24s\n",
      "epoch 22 | loss: 0.14374 | train_rmsle: 0.01044 | train_mae: 0.32406 | train_rmse: 0.4099  | train_mse: 0.16802 | valid_rmsle: 0.01122 | valid_mae: 0.34368 | valid_rmse: 0.43084 | valid_mse: 0.18562 |  0:00:25s\n",
      "epoch 23 | loss: 0.14257 | train_rmsle: 0.0101  | train_mae: 0.32116 | train_rmse: 0.40487 | train_mse: 0.16392 | valid_rmsle: 0.01088 | valid_mae: 0.34222 | valid_rmse: 0.42638 | valid_mse: 0.1818  |  0:00:26s\n",
      "epoch 24 | loss: 0.13652 | train_rmsle: 0.00936 | train_mae: 0.30942 | train_rmse: 0.3899  | train_mse: 0.15202 | valid_rmsle: 0.01024 | valid_mae: 0.33325 | valid_rmse: 0.41416 | valid_mse: 0.17153 |  0:00:27s\n",
      "epoch 25 | loss: 0.13076 | train_rmsle: 0.00835 | train_mae: 0.28962 | train_rmse: 0.36735 | train_mse: 0.13495 | valid_rmsle: 0.00966 | valid_mae: 0.32132 | valid_rmse: 0.402   | valid_mse: 0.16161 |  0:00:28s\n",
      "epoch 26 | loss: 0.12387 | train_rmsle: 0.00747 | train_mae: 0.26944 | train_rmse: 0.34608 | train_mse: 0.11977 | valid_rmsle: 0.00863 | valid_mae: 0.30048 | valid_rmse: 0.37949 | valid_mse: 0.14401 |  0:00:29s\n",
      "epoch 27 | loss: 0.11404 | train_rmsle: 0.00723 | train_mae: 0.26311 | train_rmse: 0.33858 | train_mse: 0.11464 | valid_rmsle: 0.00858 | valid_mae: 0.30253 | valid_rmse: 0.37837 | valid_mse: 0.14316 |  0:00:30s\n",
      "epoch 28 | loss: 0.10162 | train_rmsle: 0.00689 | train_mae: 0.26142 | train_rmse: 0.33446 | train_mse: 0.11186 | valid_rmsle: 0.00758 | valid_mae: 0.28351 | valid_rmse: 0.35824 | valid_mse: 0.12834 |  0:00:31s\n",
      "epoch 29 | loss: 0.08675 | train_rmsle: 0.00537 | train_mae: 0.2282  | train_rmse: 0.29448 | train_mse: 0.08672 | valid_rmsle: 0.00661 | valid_mae: 0.25907 | valid_rmse: 0.33366 | valid_mse: 0.11133 |  0:00:32s\n",
      "epoch 30 | loss: 0.07725 | train_rmsle: 0.00459 | train_mae: 0.20829 | train_rmse: 0.26882 | train_mse: 0.07227 | valid_rmsle: 0.00566 | valid_mae: 0.23662 | valid_rmse: 0.30574 | valid_mse: 0.09347 |  0:00:34s\n",
      "epoch 31 | loss: 0.06906 | train_rmsle: 0.00434 | train_mae: 0.20569 | train_rmse: 0.26304 | train_mse: 0.06919 | valid_rmsle: 0.00566 | valid_mae: 0.24085 | valid_rmse: 0.30768 | valid_mse: 0.09467 |  0:00:35s\n",
      "epoch 32 | loss: 0.06483 | train_rmsle: 0.0038  | train_mae: 0.1915  | train_rmse: 0.24577 | train_mse: 0.0604  | valid_rmsle: 0.005   | valid_mae: 0.22898 | valid_rmse: 0.28909 | valid_mse: 0.08358 |  0:00:36s\n",
      "epoch 33 | loss: 0.06201 | train_rmsle: 0.00365 | train_mae: 0.18882 | train_rmse: 0.24085 | train_mse: 0.05801 | valid_rmsle: 0.00515 | valid_mae: 0.23111 | valid_rmse: 0.29382 | valid_mse: 0.08633 |  0:00:37s\n",
      "epoch 34 | loss: 0.05834 | train_rmsle: 0.00319 | train_mae: 0.17259 | train_rmse: 0.22476 | train_mse: 0.05052 | valid_rmsle: 0.00477 | valid_mae: 0.22306 | valid_rmse: 0.28312 | valid_mse: 0.08016 |  0:00:38s\n",
      "epoch 35 | loss: 0.05477 | train_rmsle: 0.00311 | train_mae: 0.17133 | train_rmse: 0.22326 | train_mse: 0.04985 | valid_rmsle: 0.0046  | valid_mae: 0.21424 | valid_rmse: 0.27874 | valid_mse: 0.07769 |  0:00:39s\n",
      "epoch 36 | loss: 0.05495 | train_rmsle: 0.00292 | train_mae: 0.16641 | train_rmse: 0.21623 | train_mse: 0.04675 | valid_rmsle: 0.00439 | valid_mae: 0.21184 | valid_rmse: 0.27157 | valid_mse: 0.07375 |  0:00:40s\n",
      "epoch 37 | loss: 0.05089 | train_rmsle: 0.00299 | train_mae: 0.17119 | train_rmse: 0.22001 | train_mse: 0.0484  | valid_rmsle: 0.00449 | valid_mae: 0.21424 | valid_rmse: 0.2753  | valid_mse: 0.07579 |  0:00:41s\n",
      "epoch 38 | loss: 0.05112 | train_rmsle: 0.0028  | train_mae: 0.16398 | train_rmse: 0.2123  | train_mse: 0.04507 | valid_rmsle: 0.0044  | valid_mae: 0.21133 | valid_rmse: 0.27239 | valid_mse: 0.0742  |  0:00:42s\n",
      "epoch 39 | loss: 0.04999 | train_rmsle: 0.00267 | train_mae: 0.161   | train_rmse: 0.20754 | train_mse: 0.04307 | valid_rmsle: 0.00448 | valid_mae: 0.21476 | valid_rmse: 0.2742  | valid_mse: 0.07519 |  0:00:43s\n",
      "epoch 40 | loss: 0.04783 | train_rmsle: 0.00247 | train_mae: 0.15326 | train_rmse: 0.19998 | train_mse: 0.03999 | valid_rmsle: 0.00449 | valid_mae: 0.21286 | valid_rmse: 0.27486 | valid_mse: 0.07555 |  0:00:44s\n",
      "epoch 41 | loss: 0.04853 | train_rmsle: 0.00247 | train_mae: 0.15124 | train_rmse: 0.19926 | train_mse: 0.03971 | valid_rmsle: 0.00456 | valid_mae: 0.21459 | valid_rmse: 0.27703 | valid_mse: 0.07675 |  0:00:46s\n",
      "epoch 42 | loss: 0.04655 | train_rmsle: 0.00243 | train_mae: 0.15397 | train_rmse: 0.20004 | train_mse: 0.04001 | valid_rmsle: 0.00467 | valid_mae: 0.22283 | valid_rmse: 0.28226 | valid_mse: 0.07967 |  0:00:47s\n",
      "epoch 43 | loss: 0.04311 | train_rmsle: 0.00225 | train_mae: 0.14567 | train_rmse: 0.19018 | train_mse: 0.03617 | valid_rmsle: 0.00433 | valid_mae: 0.21015 | valid_rmse: 0.27021 | valid_mse: 0.07302 |  0:00:48s\n",
      "epoch 44 | loss: 0.04331 | train_rmsle: 0.00231 | train_mae: 0.15169 | train_rmse: 0.19585 | train_mse: 0.03836 | valid_rmsle: 0.00449 | valid_mae: 0.21917 | valid_rmse: 0.27749 | valid_mse: 0.077   |  0:00:49s\n",
      "epoch 45 | loss: 0.04072 | train_rmsle: 0.00194 | train_mae: 0.13184 | train_rmse: 0.17595 | train_mse: 0.03096 | valid_rmsle: 0.00427 | valid_mae: 0.20597 | valid_rmse: 0.26862 | valid_mse: 0.07215 |  0:00:50s\n",
      "epoch 46 | loss: 0.03894 | train_rmsle: 0.00186 | train_mae: 0.12839 | train_rmse: 0.1724  | train_mse: 0.02972 | valid_rmsle: 0.00426 | valid_mae: 0.20579 | valid_rmse: 0.26775 | valid_mse: 0.07169 |  0:00:51s\n",
      "epoch 47 | loss: 0.04072 | train_rmsle: 0.00187 | train_mae: 0.13223 | train_rmse: 0.17541 | train_mse: 0.03077 | valid_rmsle: 0.00432 | valid_mae: 0.21007 | valid_rmse: 0.27205 | valid_mse: 0.07401 |  0:00:52s\n",
      "epoch 48 | loss: 0.04112 | train_rmsle: 0.00185 | train_mae: 0.1305  | train_rmse: 0.17389 | train_mse: 0.03024 | valid_rmsle: 0.00426 | valid_mae: 0.20844 | valid_rmse: 0.26995 | valid_mse: 0.07287 |  0:00:53s\n",
      "epoch 49 | loss: 0.04001 | train_rmsle: 0.00188 | train_mae: 0.13284 | train_rmse: 0.17631 | train_mse: 0.03108 | valid_rmsle: 0.00419 | valid_mae: 0.20644 | valid_rmse: 0.26748 | valid_mse: 0.07155 |  0:00:54s\n",
      "epoch 50 | loss: 0.03815 | train_rmsle: 0.00191 | train_mae: 0.13579 | train_rmse: 0.17862 | train_mse: 0.0319  | valid_rmsle: 0.0042  | valid_mae: 0.2106  | valid_rmse: 0.26894 | valid_mse: 0.07233 |  0:00:55s\n",
      "epoch 51 | loss: 0.03647 | train_rmsle: 0.00184 | train_mae: 0.13325 | train_rmse: 0.17584 | train_mse: 0.03092 | valid_rmsle: 0.00421 | valid_mae: 0.20892 | valid_rmse: 0.26852 | valid_mse: 0.0721  |  0:00:56s\n",
      "epoch 52 | loss: 0.03789 | train_rmsle: 0.00161 | train_mae: 0.12144 | train_rmse: 0.16248 | train_mse: 0.0264  | valid_rmsle: 0.00413 | valid_mae: 0.20335 | valid_rmse: 0.26539 | valid_mse: 0.07043 |  0:00:57s\n",
      "epoch 53 | loss: 0.03625 | train_rmsle: 0.00179 | train_mae: 0.1288  | train_rmse: 0.171   | train_mse: 0.02924 | valid_rmsle: 0.00433 | valid_mae: 0.20914 | valid_rmse: 0.27231 | valid_mse: 0.07415 |  0:00:58s\n",
      "epoch 54 | loss: 0.03719 | train_rmsle: 0.00189 | train_mae: 0.13711 | train_rmse: 0.17932 | train_mse: 0.03215 | valid_rmsle: 0.00422 | valid_mae: 0.21128 | valid_rmse: 0.27065 | valid_mse: 0.07325 |  0:00:59s\n",
      "epoch 55 | loss: 0.03607 | train_rmsle: 0.00159 | train_mae: 0.12198 | train_rmse: 0.16273 | train_mse: 0.02648 | valid_rmsle: 0.0039  | valid_mae: 0.20098 | valid_rmse: 0.25932 | valid_mse: 0.06725 |  0:01:00s\n",
      "epoch 56 | loss: 0.03311 | train_rmsle: 0.00167 | train_mae: 0.12745 | train_rmse: 0.16856 | train_mse: 0.02841 | valid_rmsle: 0.00387 | valid_mae: 0.20236 | valid_rmse: 0.259   | valid_mse: 0.06708 |  0:01:01s\n",
      "epoch 57 | loss: 0.03415 | train_rmsle: 0.00153 | train_mae: 0.12054 | train_rmse: 0.1603  | train_mse: 0.0257  | valid_rmsle: 0.00376 | valid_mae: 0.19819 | valid_rmse: 0.25507 | valid_mse: 0.06506 |  0:01:03s\n",
      "epoch 58 | loss: 0.03331 | train_rmsle: 0.00154 | train_mae: 0.12218 | train_rmse: 0.16114 | train_mse: 0.02596 | valid_rmsle: 0.00375 | valid_mae: 0.19981 | valid_rmse: 0.25522 | valid_mse: 0.06514 |  0:01:04s\n",
      "epoch 59 | loss: 0.03088 | train_rmsle: 0.00141 | train_mae: 0.11481 | train_rmse: 0.15343 | train_mse: 0.02354 | valid_rmsle: 0.0036  | valid_mae: 0.19513 | valid_rmse: 0.24933 | valid_mse: 0.06216 |  0:01:05s\n",
      "epoch 60 | loss: 0.03111 | train_rmsle: 0.00148 | train_mae: 0.11955 | train_rmse: 0.15819 | train_mse: 0.02502 | valid_rmsle: 0.00365 | valid_mae: 0.19633 | valid_rmse: 0.25195 | valid_mse: 0.06348 |  0:01:06s\n",
      "epoch 61 | loss: 0.03085 | train_rmsle: 0.0015  | train_mae: 0.11874 | train_rmse: 0.15611 | train_mse: 0.02437 | valid_rmsle: 0.00374 | valid_mae: 0.19809 | valid_rmse: 0.25293 | valid_mse: 0.06397 |  0:01:07s\n",
      "epoch 62 | loss: 0.03128 | train_rmsle: 0.00133 | train_mae: 0.11033 | train_rmse: 0.149   | train_mse: 0.0222  | valid_rmsle: 0.00353 | valid_mae: 0.19039 | valid_rmse: 0.24772 | valid_mse: 0.06136 |  0:01:08s\n",
      "epoch 63 | loss: 0.02985 | train_rmsle: 0.00129 | train_mae: 0.10623 | train_rmse: 0.14386 | train_mse: 0.0207  | valid_rmsle: 0.00357 | valid_mae: 0.19053 | valid_rmse: 0.24747 | valid_mse: 0.06124 |  0:01:09s\n",
      "epoch 64 | loss: 0.03022 | train_rmsle: 0.00119 | train_mae: 0.10394 | train_rmse: 0.14116 | train_mse: 0.01993 | valid_rmsle: 0.00336 | valid_mae: 0.18602 | valid_rmse: 0.24087 | valid_mse: 0.05802 |  0:01:10s\n",
      "epoch 65 | loss: 0.02785 | train_rmsle: 0.00115 | train_mae: 0.10198 | train_rmse: 0.13887 | train_mse: 0.01928 | valid_rmsle: 0.00341 | valid_mae: 0.18754 | valid_rmse: 0.24258 | valid_mse: 0.05885 |  0:01:11s\n",
      "epoch 66 | loss: 0.02641 | train_rmsle: 0.00113 | train_mae: 0.09993 | train_rmse: 0.13703 | train_mse: 0.01878 | valid_rmsle: 0.00342 | valid_mae: 0.18574 | valid_rmse: 0.24292 | valid_mse: 0.05901 |  0:01:12s\n",
      "epoch 67 | loss: 0.02671 | train_rmsle: 0.0011  | train_mae: 0.09989 | train_rmse: 0.13652 | train_mse: 0.01864 | valid_rmsle: 0.00348 | valid_mae: 0.18728 | valid_rmse: 0.24471 | valid_mse: 0.05988 |  0:01:13s\n",
      "epoch 68 | loss: 0.02618 | train_rmsle: 0.0011  | train_mae: 0.09962 | train_rmse: 0.1349  | train_mse: 0.0182  | valid_rmsle: 0.00358 | valid_mae: 0.19085 | valid_rmse: 0.24846 | valid_mse: 0.06173 |  0:01:15s\n",
      "epoch 69 | loss: 0.02538 | train_rmsle: 0.00129 | train_mae: 0.11074 | train_rmse: 0.14534 | train_mse: 0.02112 | valid_rmsle: 0.00365 | valid_mae: 0.1937  | valid_rmse: 0.24971 | valid_mse: 0.06236 |  0:01:16s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 64 and best_valid_mse = 0.05802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0542677105884393 RMSE: 0.23295431008770648 R2: 0.7597777555818771 MAE: 0.18186037610294573\n",
      "=====================================\n",
      "[78/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 7.65764 | train_rmsle: 0.18577 | train_mae: 1.46954 | train_rmse: 1.54441 | train_mse: 2.38519 | valid_rmsle: 0.18658 | valid_mae: 1.47413 | valid_rmse: 1.54865 | valid_mse: 2.39831 |  0:00:01s\n",
      "epoch 1  | loss: 1.11933 | train_rmsle: 0.07433 | train_mae: 0.97433 | train_rmse: 1.06538 | train_mse: 1.13502 | valid_rmsle: 0.07458 | valid_mae: 0.9764  | valid_rmse: 1.06878 | valid_mse: 1.14229 |  0:00:02s\n",
      "epoch 2  | loss: 0.49055 | train_rmsle: 0.05013 | train_mae: 0.80516 | train_rmse: 0.89925 | train_mse: 0.80866 | valid_rmsle: 0.05023 | valid_mae: 0.80579 | valid_rmse: 0.90228 | valid_mse: 0.81411 |  0:00:03s\n",
      "epoch 3  | loss: 0.35894 | train_rmsle: 0.0426  | train_mae: 0.74298 | train_rmse: 0.83671 | train_mse: 0.70009 | valid_rmsle: 0.04256 | valid_mae: 0.7421  | valid_rmse: 0.83878 | valid_mse: 0.70354 |  0:00:04s\n",
      "epoch 4  | loss: 0.28264 | train_rmsle: 0.03243 | train_mae: 0.64853 | train_rmse: 0.7391  | train_mse: 0.54627 | valid_rmsle: 0.03224 | valid_mae: 0.64775 | valid_rmse: 0.73985 | valid_mse: 0.54737 |  0:00:05s\n",
      "epoch 5  | loss: 0.25765 | train_rmsle: 0.02613 | train_mae: 0.5781  | train_rmse: 0.66747 | train_mse: 0.44551 | valid_rmsle: 0.02604 | valid_mae: 0.57947 | valid_rmse: 0.66939 | valid_mse: 0.44809 |  0:00:06s\n",
      "epoch 6  | loss: 0.23853 | train_rmsle: 0.0205  | train_mae: 0.50413 | train_rmse: 0.59204 | train_mse: 0.35052 | valid_rmsle: 0.02018 | valid_mae: 0.50425 | valid_rmse: 0.59109 | valid_mse: 0.34939 |  0:00:07s\n",
      "epoch 7  | loss: 0.22578 | train_rmsle: 0.01783 | train_mae: 0.46024 | train_rmse: 0.5502  | train_mse: 0.30272 | valid_rmsle: 0.0176  | valid_mae: 0.46132 | valid_rmse: 0.55053 | valid_mse: 0.30308 |  0:00:08s\n",
      "epoch 8  | loss: 0.21382 | train_rmsle: 0.01637 | train_mae: 0.43847 | train_rmse: 0.52629 | train_mse: 0.27698 | valid_rmsle: 0.01614 | valid_mae: 0.44113 | valid_rmse: 0.52697 | valid_mse: 0.2777  |  0:00:09s\n",
      "epoch 9  | loss: 0.20513 | train_rmsle: 0.01353 | train_mae: 0.37812 | train_rmse: 0.46953 | train_mse: 0.22046 | valid_rmsle: 0.01322 | valid_mae: 0.38074 | valid_rmse: 0.46924 | valid_mse: 0.22019 |  0:00:10s\n",
      "epoch 10 | loss: 0.19859 | train_rmsle: 0.01424 | train_mae: 0.39245 | train_rmse: 0.48446 | train_mse: 0.2347  | valid_rmsle: 0.01395 | valid_mae: 0.39547 | valid_rmse: 0.48423 | valid_mse: 0.23448 |  0:00:12s\n",
      "epoch 11 | loss: 0.18859 | train_rmsle: 0.01394 | train_mae: 0.39023 | train_rmse: 0.47977 | train_mse: 0.23018 | valid_rmsle: 0.01362 | valid_mae: 0.39406 | valid_rmse: 0.47898 | valid_mse: 0.22942 |  0:00:13s\n",
      "epoch 12 | loss: 0.18835 | train_rmsle: 0.01441 | train_mae: 0.40053 | train_rmse: 0.49008 | train_mse: 0.24018 | valid_rmsle: 0.01431 | valid_mae: 0.40608 | valid_rmse: 0.49263 | valid_mse: 0.24268 |  0:00:14s\n",
      "epoch 13 | loss: 0.18952 | train_rmsle: 0.01391 | train_mae: 0.39076 | train_rmse: 0.48055 | train_mse: 0.23093 | valid_rmsle: 0.0138  | valid_mae: 0.39518 | valid_rmse: 0.48315 | valid_mse: 0.23344 |  0:00:15s\n",
      "epoch 14 | loss: 0.17848 | train_rmsle: 0.01283 | train_mae: 0.36537 | train_rmse: 0.45637 | train_mse: 0.20827 | valid_rmsle: 0.01252 | valid_mae: 0.36786 | valid_rmse: 0.45554 | valid_mse: 0.20752 |  0:00:16s\n",
      "epoch 15 | loss: 0.17265 | train_rmsle: 0.01293 | train_mae: 0.37178 | train_rmse: 0.45971 | train_mse: 0.21133 | valid_rmsle: 0.01269 | valid_mae: 0.37537 | valid_rmse: 0.46023 | valid_mse: 0.21181 |  0:00:17s\n",
      "epoch 16 | loss: 0.1709  | train_rmsle: 0.0128  | train_mae: 0.36781 | train_rmse: 0.45721 | train_mse: 0.20904 | valid_rmsle: 0.01261 | valid_mae: 0.36947 | valid_rmse: 0.4582  | valid_mse: 0.20994 |  0:00:18s\n",
      "epoch 17 | loss: 0.16793 | train_rmsle: 0.01221 | train_mae: 0.35458 | train_rmse: 0.444   | train_mse: 0.19714 | valid_rmsle: 0.01231 | valid_mae: 0.36332 | valid_rmse: 0.4513  | valid_mse: 0.20367 |  0:00:19s\n",
      "epoch 18 | loss: 0.16423 | train_rmsle: 0.01222 | train_mae: 0.35668 | train_rmse: 0.44548 | train_mse: 0.19845 | valid_rmsle: 0.01238 | valid_mae: 0.36658 | valid_rmse: 0.45367 | valid_mse: 0.20582 |  0:00:20s\n",
      "epoch 19 | loss: 0.15921 | train_rmsle: 0.0119  | train_mae: 0.353   | train_rmse: 0.4401  | train_mse: 0.19368 | valid_rmsle: 0.01224 | valid_mae: 0.36586 | valid_rmse: 0.45213 | valid_mse: 0.20443 |  0:00:21s\n",
      "epoch 20 | loss: 0.15368 | train_rmsle: 0.0119  | train_mae: 0.35461 | train_rmse: 0.44133 | train_mse: 0.19478 | valid_rmsle: 0.0127  | valid_mae: 0.37467 | valid_rmse: 0.46165 | valid_mse: 0.21312 |  0:00:23s\n",
      "epoch 21 | loss: 0.14985 | train_rmsle: 0.01115 | train_mae: 0.33822 | train_rmse: 0.42471 | train_mse: 0.18038 | valid_rmsle: 0.01192 | valid_mae: 0.35723 | valid_rmse: 0.4451  | valid_mse: 0.19811 |  0:00:24s\n",
      "epoch 22 | loss: 0.14374 | train_rmsle: 0.01044 | train_mae: 0.32406 | train_rmse: 0.4099  | train_mse: 0.16802 | valid_rmsle: 0.01122 | valid_mae: 0.34368 | valid_rmse: 0.43084 | valid_mse: 0.18562 |  0:00:25s\n",
      "epoch 23 | loss: 0.14257 | train_rmsle: 0.0101  | train_mae: 0.32116 | train_rmse: 0.40487 | train_mse: 0.16392 | valid_rmsle: 0.01088 | valid_mae: 0.34222 | valid_rmse: 0.42638 | valid_mse: 0.1818  |  0:00:26s\n",
      "epoch 24 | loss: 0.13652 | train_rmsle: 0.00936 | train_mae: 0.30942 | train_rmse: 0.3899  | train_mse: 0.15202 | valid_rmsle: 0.01024 | valid_mae: 0.33325 | valid_rmse: 0.41416 | valid_mse: 0.17153 |  0:00:27s\n",
      "epoch 25 | loss: 0.13076 | train_rmsle: 0.00835 | train_mae: 0.28962 | train_rmse: 0.36735 | train_mse: 0.13495 | valid_rmsle: 0.00966 | valid_mae: 0.32132 | valid_rmse: 0.402   | valid_mse: 0.16161 |  0:00:28s\n",
      "epoch 26 | loss: 0.12387 | train_rmsle: 0.00747 | train_mae: 0.26944 | train_rmse: 0.34608 | train_mse: 0.11977 | valid_rmsle: 0.00863 | valid_mae: 0.30048 | valid_rmse: 0.37949 | valid_mse: 0.14401 |  0:00:29s\n",
      "epoch 27 | loss: 0.11404 | train_rmsle: 0.00723 | train_mae: 0.26311 | train_rmse: 0.33858 | train_mse: 0.11464 | valid_rmsle: 0.00858 | valid_mae: 0.30253 | valid_rmse: 0.37837 | valid_mse: 0.14316 |  0:00:30s\n",
      "epoch 28 | loss: 0.10162 | train_rmsle: 0.00689 | train_mae: 0.26142 | train_rmse: 0.33446 | train_mse: 0.11186 | valid_rmsle: 0.00758 | valid_mae: 0.28351 | valid_rmse: 0.35824 | valid_mse: 0.12834 |  0:00:31s\n",
      "epoch 29 | loss: 0.08675 | train_rmsle: 0.00537 | train_mae: 0.2282  | train_rmse: 0.29448 | train_mse: 0.08672 | valid_rmsle: 0.00661 | valid_mae: 0.25907 | valid_rmse: 0.33366 | valid_mse: 0.11133 |  0:00:32s\n",
      "epoch 30 | loss: 0.07725 | train_rmsle: 0.00459 | train_mae: 0.20829 | train_rmse: 0.26882 | train_mse: 0.07227 | valid_rmsle: 0.00566 | valid_mae: 0.23662 | valid_rmse: 0.30574 | valid_mse: 0.09347 |  0:00:34s\n",
      "epoch 31 | loss: 0.06906 | train_rmsle: 0.00434 | train_mae: 0.20569 | train_rmse: 0.26304 | train_mse: 0.06919 | valid_rmsle: 0.00566 | valid_mae: 0.24085 | valid_rmse: 0.30768 | valid_mse: 0.09467 |  0:00:35s\n",
      "epoch 32 | loss: 0.06483 | train_rmsle: 0.0038  | train_mae: 0.1915  | train_rmse: 0.24577 | train_mse: 0.0604  | valid_rmsle: 0.005   | valid_mae: 0.22898 | valid_rmse: 0.28909 | valid_mse: 0.08358 |  0:00:36s\n",
      "epoch 33 | loss: 0.06201 | train_rmsle: 0.00365 | train_mae: 0.18882 | train_rmse: 0.24085 | train_mse: 0.05801 | valid_rmsle: 0.00515 | valid_mae: 0.23111 | valid_rmse: 0.29382 | valid_mse: 0.08633 |  0:00:37s\n",
      "epoch 34 | loss: 0.05834 | train_rmsle: 0.00319 | train_mae: 0.17259 | train_rmse: 0.22476 | train_mse: 0.05052 | valid_rmsle: 0.00477 | valid_mae: 0.22306 | valid_rmse: 0.28312 | valid_mse: 0.08016 |  0:00:38s\n",
      "epoch 35 | loss: 0.05477 | train_rmsle: 0.00311 | train_mae: 0.17133 | train_rmse: 0.22326 | train_mse: 0.04985 | valid_rmsle: 0.0046  | valid_mae: 0.21424 | valid_rmse: 0.27874 | valid_mse: 0.07769 |  0:00:39s\n",
      "epoch 36 | loss: 0.05495 | train_rmsle: 0.00292 | train_mae: 0.16641 | train_rmse: 0.21623 | train_mse: 0.04675 | valid_rmsle: 0.00439 | valid_mae: 0.21184 | valid_rmse: 0.27157 | valid_mse: 0.07375 |  0:00:40s\n",
      "epoch 37 | loss: 0.05089 | train_rmsle: 0.00299 | train_mae: 0.17119 | train_rmse: 0.22001 | train_mse: 0.0484  | valid_rmsle: 0.00449 | valid_mae: 0.21424 | valid_rmse: 0.2753  | valid_mse: 0.07579 |  0:00:41s\n",
      "epoch 38 | loss: 0.05112 | train_rmsle: 0.0028  | train_mae: 0.16398 | train_rmse: 0.2123  | train_mse: 0.04507 | valid_rmsle: 0.0044  | valid_mae: 0.21133 | valid_rmse: 0.27239 | valid_mse: 0.0742  |  0:00:42s\n",
      "epoch 39 | loss: 0.04999 | train_rmsle: 0.00267 | train_mae: 0.161   | train_rmse: 0.20754 | train_mse: 0.04307 | valid_rmsle: 0.00448 | valid_mae: 0.21476 | valid_rmse: 0.2742  | valid_mse: 0.07519 |  0:00:43s\n",
      "epoch 40 | loss: 0.04783 | train_rmsle: 0.00247 | train_mae: 0.15326 | train_rmse: 0.19998 | train_mse: 0.03999 | valid_rmsle: 0.00449 | valid_mae: 0.21286 | valid_rmse: 0.27486 | valid_mse: 0.07555 |  0:00:44s\n",
      "epoch 41 | loss: 0.04853 | train_rmsle: 0.00247 | train_mae: 0.15124 | train_rmse: 0.19926 | train_mse: 0.03971 | valid_rmsle: 0.00456 | valid_mae: 0.21459 | valid_rmse: 0.27703 | valid_mse: 0.07675 |  0:00:46s\n",
      "epoch 42 | loss: 0.04655 | train_rmsle: 0.00243 | train_mae: 0.15397 | train_rmse: 0.20004 | train_mse: 0.04001 | valid_rmsle: 0.00467 | valid_mae: 0.22283 | valid_rmse: 0.28226 | valid_mse: 0.07967 |  0:00:47s\n",
      "epoch 43 | loss: 0.04311 | train_rmsle: 0.00225 | train_mae: 0.14567 | train_rmse: 0.19018 | train_mse: 0.03617 | valid_rmsle: 0.00433 | valid_mae: 0.21015 | valid_rmse: 0.27021 | valid_mse: 0.07302 |  0:00:48s\n",
      "epoch 44 | loss: 0.04331 | train_rmsle: 0.00231 | train_mae: 0.15169 | train_rmse: 0.19585 | train_mse: 0.03836 | valid_rmsle: 0.00449 | valid_mae: 0.21917 | valid_rmse: 0.27749 | valid_mse: 0.077   |  0:00:49s\n",
      "epoch 45 | loss: 0.04072 | train_rmsle: 0.00194 | train_mae: 0.13184 | train_rmse: 0.17595 | train_mse: 0.03096 | valid_rmsle: 0.00427 | valid_mae: 0.20597 | valid_rmse: 0.26862 | valid_mse: 0.07215 |  0:00:50s\n",
      "epoch 46 | loss: 0.03894 | train_rmsle: 0.00186 | train_mae: 0.12839 | train_rmse: 0.1724  | train_mse: 0.02972 | valid_rmsle: 0.00426 | valid_mae: 0.20579 | valid_rmse: 0.26775 | valid_mse: 0.07169 |  0:00:51s\n",
      "epoch 47 | loss: 0.04072 | train_rmsle: 0.00187 | train_mae: 0.13223 | train_rmse: 0.17541 | train_mse: 0.03077 | valid_rmsle: 0.00432 | valid_mae: 0.21007 | valid_rmse: 0.27205 | valid_mse: 0.07401 |  0:00:52s\n",
      "epoch 48 | loss: 0.04112 | train_rmsle: 0.00185 | train_mae: 0.1305  | train_rmse: 0.17389 | train_mse: 0.03024 | valid_rmsle: 0.00426 | valid_mae: 0.20844 | valid_rmse: 0.26995 | valid_mse: 0.07287 |  0:00:53s\n",
      "epoch 49 | loss: 0.04001 | train_rmsle: 0.00188 | train_mae: 0.13284 | train_rmse: 0.17631 | train_mse: 0.03108 | valid_rmsle: 0.00419 | valid_mae: 0.20644 | valid_rmse: 0.26748 | valid_mse: 0.07155 |  0:00:54s\n",
      "epoch 50 | loss: 0.03815 | train_rmsle: 0.00191 | train_mae: 0.13579 | train_rmse: 0.17862 | train_mse: 0.0319  | valid_rmsle: 0.0042  | valid_mae: 0.2106  | valid_rmse: 0.26894 | valid_mse: 0.07233 |  0:00:55s\n",
      "epoch 51 | loss: 0.03647 | train_rmsle: 0.00184 | train_mae: 0.13325 | train_rmse: 0.17584 | train_mse: 0.03092 | valid_rmsle: 0.00421 | valid_mae: 0.20892 | valid_rmse: 0.26852 | valid_mse: 0.0721  |  0:00:57s\n",
      "epoch 52 | loss: 0.03789 | train_rmsle: 0.00161 | train_mae: 0.12144 | train_rmse: 0.16248 | train_mse: 0.0264  | valid_rmsle: 0.00413 | valid_mae: 0.20335 | valid_rmse: 0.26539 | valid_mse: 0.07043 |  0:00:58s\n",
      "epoch 53 | loss: 0.03625 | train_rmsle: 0.00179 | train_mae: 0.1288  | train_rmse: 0.171   | train_mse: 0.02924 | valid_rmsle: 0.00433 | valid_mae: 0.20914 | valid_rmse: 0.27231 | valid_mse: 0.07415 |  0:00:59s\n",
      "epoch 54 | loss: 0.03719 | train_rmsle: 0.00189 | train_mae: 0.13711 | train_rmse: 0.17932 | train_mse: 0.03215 | valid_rmsle: 0.00422 | valid_mae: 0.21128 | valid_rmse: 0.27065 | valid_mse: 0.07325 |  0:01:00s\n",
      "epoch 55 | loss: 0.03607 | train_rmsle: 0.00159 | train_mae: 0.12198 | train_rmse: 0.16273 | train_mse: 0.02648 | valid_rmsle: 0.0039  | valid_mae: 0.20098 | valid_rmse: 0.25932 | valid_mse: 0.06725 |  0:01:01s\n",
      "epoch 56 | loss: 0.03311 | train_rmsle: 0.00167 | train_mae: 0.12745 | train_rmse: 0.16856 | train_mse: 0.02841 | valid_rmsle: 0.00387 | valid_mae: 0.20236 | valid_rmse: 0.259   | valid_mse: 0.06708 |  0:01:02s\n",
      "epoch 57 | loss: 0.03415 | train_rmsle: 0.00153 | train_mae: 0.12054 | train_rmse: 0.1603  | train_mse: 0.0257  | valid_rmsle: 0.00376 | valid_mae: 0.19819 | valid_rmse: 0.25507 | valid_mse: 0.06506 |  0:01:03s\n",
      "epoch 58 | loss: 0.03331 | train_rmsle: 0.00154 | train_mae: 0.12218 | train_rmse: 0.16114 | train_mse: 0.02596 | valid_rmsle: 0.00375 | valid_mae: 0.19981 | valid_rmse: 0.25522 | valid_mse: 0.06514 |  0:01:04s\n",
      "epoch 59 | loss: 0.03088 | train_rmsle: 0.00141 | train_mae: 0.11481 | train_rmse: 0.15343 | train_mse: 0.02354 | valid_rmsle: 0.0036  | valid_mae: 0.19513 | valid_rmse: 0.24933 | valid_mse: 0.06216 |  0:01:05s\n",
      "epoch 60 | loss: 0.03111 | train_rmsle: 0.00148 | train_mae: 0.11955 | train_rmse: 0.15819 | train_mse: 0.02502 | valid_rmsle: 0.00365 | valid_mae: 0.19633 | valid_rmse: 0.25195 | valid_mse: 0.06348 |  0:01:06s\n",
      "epoch 61 | loss: 0.03085 | train_rmsle: 0.0015  | train_mae: 0.11874 | train_rmse: 0.15611 | train_mse: 0.02437 | valid_rmsle: 0.00374 | valid_mae: 0.19809 | valid_rmse: 0.25293 | valid_mse: 0.06397 |  0:01:07s\n",
      "epoch 62 | loss: 0.03128 | train_rmsle: 0.00133 | train_mae: 0.11033 | train_rmse: 0.149   | train_mse: 0.0222  | valid_rmsle: 0.00353 | valid_mae: 0.19039 | valid_rmse: 0.24772 | valid_mse: 0.06136 |  0:01:09s\n",
      "epoch 63 | loss: 0.02985 | train_rmsle: 0.00129 | train_mae: 0.10623 | train_rmse: 0.14386 | train_mse: 0.0207  | valid_rmsle: 0.00357 | valid_mae: 0.19053 | valid_rmse: 0.24747 | valid_mse: 0.06124 |  0:01:10s\n",
      "epoch 64 | loss: 0.03022 | train_rmsle: 0.00119 | train_mae: 0.10394 | train_rmse: 0.14116 | train_mse: 0.01993 | valid_rmsle: 0.00336 | valid_mae: 0.18602 | valid_rmse: 0.24087 | valid_mse: 0.05802 |  0:01:11s\n",
      "epoch 65 | loss: 0.02785 | train_rmsle: 0.00115 | train_mae: 0.10198 | train_rmse: 0.13887 | train_mse: 0.01928 | valid_rmsle: 0.00341 | valid_mae: 0.18754 | valid_rmse: 0.24258 | valid_mse: 0.05885 |  0:01:12s\n",
      "epoch 66 | loss: 0.02641 | train_rmsle: 0.00113 | train_mae: 0.09993 | train_rmse: 0.13703 | train_mse: 0.01878 | valid_rmsle: 0.00342 | valid_mae: 0.18574 | valid_rmse: 0.24292 | valid_mse: 0.05901 |  0:01:13s\n",
      "epoch 67 | loss: 0.02671 | train_rmsle: 0.0011  | train_mae: 0.09989 | train_rmse: 0.13652 | train_mse: 0.01864 | valid_rmsle: 0.00348 | valid_mae: 0.18728 | valid_rmse: 0.24471 | valid_mse: 0.05988 |  0:01:14s\n",
      "epoch 68 | loss: 0.02618 | train_rmsle: 0.0011  | train_mae: 0.09962 | train_rmse: 0.1349  | train_mse: 0.0182  | valid_rmsle: 0.00358 | valid_mae: 0.19085 | valid_rmse: 0.24846 | valid_mse: 0.06173 |  0:01:15s\n",
      "epoch 69 | loss: 0.02538 | train_rmsle: 0.00129 | train_mae: 0.11074 | train_rmse: 0.14534 | train_mse: 0.02112 | valid_rmsle: 0.00365 | valid_mae: 0.1937  | valid_rmse: 0.24971 | valid_mse: 0.06236 |  0:01:16s\n",
      "epoch 70 | loss: 0.02697 | train_rmsle: 0.001   | train_mae: 0.09502 | train_rmse: 0.1301  | train_mse: 0.01693 | valid_rmsle: 0.00324 | valid_mae: 0.18159 | valid_rmse: 0.23643 | valid_mse: 0.0559  |  0:01:17s\n",
      "epoch 71 | loss: 0.02508 | train_rmsle: 0.00096 | train_mae: 0.09473 | train_rmse: 0.12917 | train_mse: 0.01669 | valid_rmsle: 0.0033  | valid_mae: 0.18195 | valid_rmse: 0.23769 | valid_mse: 0.0565  |  0:01:18s\n",
      "epoch 72 | loss: 0.02569 | train_rmsle: 0.00108 | train_mae: 0.10184 | train_rmse: 0.13559 | train_mse: 0.01838 | valid_rmsle: 0.00343 | valid_mae: 0.18605 | valid_rmse: 0.24337 | valid_mse: 0.05923 |  0:01:19s\n",
      "epoch 73 | loss: 0.02511 | train_rmsle: 0.00096 | train_mae: 0.09588 | train_rmse: 0.12935 | train_mse: 0.01673 | valid_rmsle: 0.00329 | valid_mae: 0.18181 | valid_rmse: 0.23923 | valid_mse: 0.05723 |  0:01:21s\n",
      "epoch 74 | loss: 0.02212 | train_rmsle: 0.00085 | train_mae: 0.08735 | train_rmse: 0.12068 | train_mse: 0.01456 | valid_rmsle: 0.00316 | valid_mae: 0.17694 | valid_rmse: 0.23358 | valid_mse: 0.05456 |  0:01:22s\n",
      "epoch 75 | loss: 0.02215 | train_rmsle: 0.00081 | train_mae: 0.08651 | train_rmse: 0.11954 | train_mse: 0.01429 | valid_rmsle: 0.00313 | valid_mae: 0.17649 | valid_rmse: 0.23276 | valid_mse: 0.05418 |  0:01:23s\n",
      "epoch 76 | loss: 0.02118 | train_rmsle: 0.00087 | train_mae: 0.09258 | train_rmse: 0.12453 | train_mse: 0.01551 | valid_rmsle: 0.00322 | valid_mae: 0.18199 | valid_rmse: 0.23639 | valid_mse: 0.05588 |  0:01:24s\n",
      "epoch 77 | loss: 0.02209 | train_rmsle: 0.00082 | train_mae: 0.08858 | train_rmse: 0.12102 | train_mse: 0.01465 | valid_rmsle: 0.00322 | valid_mae: 0.18016 | valid_rmse: 0.23579 | valid_mse: 0.0556  |  0:01:25s\n",
      "epoch 78 | loss: 0.02367 | train_rmsle: 0.00129 | train_mae: 0.12062 | train_rmse: 0.14984 | train_mse: 0.02245 | valid_rmsle: 0.00368 | valid_mae: 0.19614 | valid_rmse: 0.25064 | valid_mse: 0.06282 |  0:01:26s\n",
      "epoch 79 | loss: 0.02204 | train_rmsle: 0.00081 | train_mae: 0.0874  | train_rmse: 0.12004 | train_mse: 0.01441 | valid_rmsle: 0.00314 | valid_mae: 0.17691 | valid_rmse: 0.23346 | valid_mse: 0.0545  |  0:01:27s\n",
      "epoch 80 | loss: 0.02187 | train_rmsle: 0.001   | train_mae: 0.09619 | train_rmse: 0.12733 | train_mse: 0.01621 | valid_rmsle: 0.00333 | valid_mae: 0.18208 | valid_rmse: 0.23645 | valid_mse: 0.05591 |  0:01:28s\n",
      "epoch 81 | loss: 0.0228  | train_rmsle: 0.00078 | train_mae: 0.08704 | train_rmse: 0.11857 | train_mse: 0.01406 | valid_rmsle: 0.00308 | valid_mae: 0.17675 | valid_rmse: 0.23169 | valid_mse: 0.05368 |  0:01:29s\n",
      "epoch 82 | loss: 0.02123 | train_rmsle: 0.00088 | train_mae: 0.09508 | train_rmse: 0.1262  | train_mse: 0.01593 | valid_rmsle: 0.00297 | valid_mae: 0.17347 | valid_rmse: 0.22773 | valid_mse: 0.05186 |  0:01:30s\n",
      "epoch 83 | loss: 0.0217  | train_rmsle: 0.00071 | train_mae: 0.08104 | train_rmse: 0.11332 | train_mse: 0.01284 | valid_rmsle: 0.00288 | valid_mae: 0.16883 | valid_rmse: 0.22391 | valid_mse: 0.05014 |  0:01:31s\n",
      "epoch 84 | loss: 0.0223  | train_rmsle: 0.00117 | train_mae: 0.10793 | train_rmse: 0.13761 | train_mse: 0.01894 | valid_rmsle: 0.00336 | valid_mae: 0.18369 | valid_rmse: 0.23803 | valid_mse: 0.05666 |  0:01:33s\n",
      "epoch 85 | loss: 0.021   | train_rmsle: 0.00092 | train_mae: 0.09425 | train_rmse: 0.12377 | train_mse: 0.01532 | valid_rmsle: 0.00309 | valid_mae: 0.17403 | valid_rmse: 0.22962 | valid_mse: 0.05272 |  0:01:34s\n",
      "epoch 86 | loss: 0.01906 | train_rmsle: 0.0007  | train_mae: 0.08067 | train_rmse: 0.11161 | train_mse: 0.01246 | valid_rmsle: 0.00282 | valid_mae: 0.16697 | valid_rmse: 0.22134 | valid_mse: 0.04899 |  0:01:35s\n",
      "epoch 87 | loss: 0.02192 | train_rmsle: 0.00066 | train_mae: 0.07691 | train_rmse: 0.10757 | train_mse: 0.01157 | valid_rmsle: 0.00291 | valid_mae: 0.16899 | valid_rmse: 0.22494 | valid_mse: 0.0506  |  0:01:36s\n",
      "epoch 88 | loss: 0.01983 | train_rmsle: 0.0007  | train_mae: 0.07865 | train_rmse: 0.10984 | train_mse: 0.01207 | valid_rmsle: 0.00287 | valid_mae: 0.16988 | valid_rmse: 0.22357 | valid_mse: 0.04998 |  0:01:37s\n",
      "epoch 89 | loss: 0.02024 | train_rmsle: 0.00061 | train_mae: 0.07424 | train_rmse: 0.1043  | train_mse: 0.01088 | valid_rmsle: 0.00281 | valid_mae: 0.16717 | valid_rmse: 0.22239 | valid_mse: 0.04946 |  0:01:38s\n",
      "epoch 90 | loss: 0.01894 | train_rmsle: 0.00065 | train_mae: 0.07683 | train_rmse: 0.10683 | train_mse: 0.01141 | valid_rmsle: 0.00282 | valid_mae: 0.16715 | valid_rmse: 0.2223  | valid_mse: 0.04942 |  0:01:39s\n",
      "epoch 91 | loss: 0.01938 | train_rmsle: 0.00065 | train_mae: 0.0766  | train_rmse: 0.1058  | train_mse: 0.01119 | valid_rmsle: 0.00295 | valid_mae: 0.16935 | valid_rmse: 0.22782 | valid_mse: 0.0519  |  0:01:40s\n",
      "epoch 92 | loss: 0.01781 | train_rmsle: 0.00059 | train_mae: 0.0716  | train_rmse: 0.10175 | train_mse: 0.01035 | valid_rmsle: 0.00288 | valid_mae: 0.16796 | valid_rmse: 0.22548 | valid_mse: 0.05084 |  0:01:41s\n",
      "epoch 93 | loss: 0.01969 | train_rmsle: 0.00067 | train_mae: 0.08052 | train_rmse: 0.10901 | train_mse: 0.01188 | valid_rmsle: 0.00287 | valid_mae: 0.16815 | valid_rmse: 0.22405 | valid_mse: 0.0502  |  0:01:42s\n",
      "epoch 94 | loss: 0.01815 | train_rmsle: 0.00056 | train_mae: 0.0701  | train_rmse: 0.09915 | train_mse: 0.00983 | valid_rmsle: 0.00273 | valid_mae: 0.16455 | valid_rmse: 0.21884 | valid_mse: 0.04789 |  0:01:43s\n",
      "epoch 95 | loss: 0.01681 | train_rmsle: 0.00075 | train_mae: 0.08937 | train_rmse: 0.11777 | train_mse: 0.01387 | valid_rmsle: 0.00293 | valid_mae: 0.17464 | valid_rmse: 0.22766 | valid_mse: 0.05183 |  0:01:45s\n",
      "epoch 96 | loss: 0.01717 | train_rmsle: 0.00053 | train_mae: 0.0684  | train_rmse: 0.09713 | train_mse: 0.00943 | valid_rmsle: 0.00281 | valid_mae: 0.16633 | valid_rmse: 0.22237 | valid_mse: 0.04945 |  0:01:46s\n",
      "epoch 97 | loss: 0.01683 | train_rmsle: 0.0005  | train_mae: 0.06616 | train_rmse: 0.09383 | train_mse: 0.0088  | valid_rmsle: 0.00283 | valid_mae: 0.16569 | valid_rmse: 0.22219 | valid_mse: 0.04937 |  0:01:47s\n",
      "epoch 98 | loss: 0.01705 | train_rmsle: 0.00053 | train_mae: 0.06823 | train_rmse: 0.09669 | train_mse: 0.00935 | valid_rmsle: 0.00281 | valid_mae: 0.16623 | valid_rmse: 0.22153 | valid_mse: 0.04907 |  0:01:48s\n",
      "epoch 99 | loss: 0.01661 | train_rmsle: 0.00049 | train_mae: 0.06609 | train_rmse: 0.09423 | train_mse: 0.00888 | valid_rmsle: 0.00281 | valid_mae: 0.16542 | valid_rmse: 0.22247 | valid_mse: 0.04949 |  0:01:49s\n",
      "epoch 100| loss: 0.01781 | train_rmsle: 0.00063 | train_mae: 0.07864 | train_rmse: 0.10499 | train_mse: 0.01102 | valid_rmsle: 0.00284 | valid_mae: 0.1679  | valid_rmse: 0.22326 | valid_mse: 0.04985 |  0:01:50s\n",
      "epoch 101| loss: 0.01654 | train_rmsle: 0.00055 | train_mae: 0.06941 | train_rmse: 0.0969  | train_mse: 0.00939 | valid_rmsle: 0.00267 | valid_mae: 0.16348 | valid_rmse: 0.21568 | valid_mse: 0.04652 |  0:01:51s\n",
      "epoch 102| loss: 0.01756 | train_rmsle: 0.00051 | train_mae: 0.06904 | train_rmse: 0.0954  | train_mse: 0.0091  | valid_rmsle: 0.0027  | valid_mae: 0.16366 | valid_rmse: 0.21848 | valid_mse: 0.04773 |  0:01:52s\n",
      "epoch 103| loss: 0.0163  | train_rmsle: 0.00044 | train_mae: 0.06294 | train_rmse: 0.0888  | train_mse: 0.00789 | valid_rmsle: 0.00272 | valid_mae: 0.16421 | valid_rmse: 0.21877 | valid_mse: 0.04786 |  0:01:53s\n",
      "epoch 104| loss: 0.01612 | train_rmsle: 0.0005  | train_mae: 0.06689 | train_rmse: 0.09235 | train_mse: 0.00853 | valid_rmsle: 0.00267 | valid_mae: 0.16041 | valid_rmse: 0.21523 | valid_mse: 0.04633 |  0:01:54s\n",
      "epoch 105| loss: 0.0168  | train_rmsle: 0.00049 | train_mae: 0.06762 | train_rmse: 0.09394 | train_mse: 0.00882 | valid_rmsle: 0.00262 | valid_mae: 0.15948 | valid_rmse: 0.21479 | valid_mse: 0.04614 |  0:01:55s\n",
      "epoch 106| loss: 0.01528 | train_rmsle: 0.00052 | train_mae: 0.07024 | train_rmse: 0.09693 | train_mse: 0.0094  | valid_rmsle: 0.00264 | valid_mae: 0.16017 | valid_rmse: 0.21605 | valid_mse: 0.04668 |  0:01:57s\n",
      "epoch 107| loss: 0.01727 | train_rmsle: 0.00058 | train_mae: 0.07772 | train_rmse: 0.10324 | train_mse: 0.01066 | valid_rmsle: 0.00271 | valid_mae: 0.16591 | valid_rmse: 0.21855 | valid_mse: 0.04776 |  0:01:58s\n",
      "epoch 108| loss: 0.01583 | train_rmsle: 0.00057 | train_mae: 0.07122 | train_rmse: 0.09674 | train_mse: 0.00936 | valid_rmsle: 0.00271 | valid_mae: 0.1612  | valid_rmse: 0.21706 | valid_mse: 0.04712 |  0:01:59s\n",
      "epoch 109| loss: 0.01553 | train_rmsle: 0.00055 | train_mae: 0.07026 | train_rmse: 0.09504 | train_mse: 0.00903 | valid_rmsle: 0.0026  | valid_mae: 0.16143 | valid_rmse: 0.21321 | valid_mse: 0.04546 |  0:02:00s\n",
      "epoch 110| loss: 0.01578 | train_rmsle: 0.00043 | train_mae: 0.06039 | train_rmse: 0.08592 | train_mse: 0.00738 | valid_rmsle: 0.00254 | valid_mae: 0.15887 | valid_rmse: 0.21157 | valid_mse: 0.04476 |  0:02:01s\n",
      "epoch 111| loss: 0.01611 | train_rmsle: 0.00078 | train_mae: 0.0969  | train_rmse: 0.1218  | train_mse: 0.01483 | valid_rmsle: 0.00283 | valid_mae: 0.17001 | valid_rmse: 0.22587 | valid_mse: 0.05102 |  0:02:02s\n",
      "epoch 112| loss: 0.01761 | train_rmsle: 0.00059 | train_mae: 0.07063 | train_rmse: 0.09639 | train_mse: 0.00929 | valid_rmsle: 0.00261 | valid_mae: 0.16153 | valid_rmse: 0.21215 | valid_mse: 0.04501 |  0:02:03s\n",
      "epoch 113| loss: 0.01556 | train_rmsle: 0.00043 | train_mae: 0.06323 | train_rmse: 0.08869 | train_mse: 0.00787 | valid_rmsle: 0.00246 | valid_mae: 0.15771 | valid_rmse: 0.20809 | valid_mse: 0.0433  |  0:02:04s\n",
      "epoch 114| loss: 0.0146  | train_rmsle: 0.00042 | train_mae: 0.06199 | train_rmse: 0.08626 | train_mse: 0.00744 | valid_rmsle: 0.00249 | valid_mae: 0.15697 | valid_rmse: 0.20948 | valid_mse: 0.04388 |  0:02:06s\n",
      "epoch 115| loss: 0.0142  | train_rmsle: 0.00042 | train_mae: 0.06095 | train_rmse: 0.08479 | train_mse: 0.00719 | valid_rmsle: 0.00251 | valid_mae: 0.15757 | valid_rmse: 0.21037 | valid_mse: 0.04425 |  0:02:07s\n",
      "epoch 116| loss: 0.01711 | train_rmsle: 0.00046 | train_mae: 0.06597 | train_rmse: 0.09111 | train_mse: 0.0083  | valid_rmsle: 0.00251 | valid_mae: 0.15838 | valid_rmse: 0.20986 | valid_mse: 0.04404 |  0:02:08s\n",
      "epoch 117| loss: 0.0151  | train_rmsle: 0.00039 | train_mae: 0.0594  | train_rmse: 0.08399 | train_mse: 0.00705 | valid_rmsle: 0.00251 | valid_mae: 0.15655 | valid_rmse: 0.20951 | valid_mse: 0.04389 |  0:02:09s\n",
      "epoch 118| loss: 0.01442 | train_rmsle: 0.00057 | train_mae: 0.07745 | train_rmse: 0.0987  | train_mse: 0.00974 | valid_rmsle: 0.00274 | valid_mae: 0.16765 | valid_rmse: 0.2181  | valid_mse: 0.04757 |  0:02:10s\n",
      "epoch 119| loss: 0.01437 | train_rmsle: 0.00046 | train_mae: 0.0663  | train_rmse: 0.08859 | train_mse: 0.00785 | valid_rmsle: 0.0025  | valid_mae: 0.15747 | valid_rmse: 0.21014 | valid_mse: 0.04416 |  0:02:11s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 113 and best_valid_mse = 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.04085158703270006 RMSE: 0.20211775536231363 R2: 0.8191657650815278 MAE: 0.15029100776430881\n",
      "=====================================\n",
      "[79/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 7.65764 | train_rmsle: 0.18577 | train_mae: 1.46954 | train_rmse: 1.54441 | train_mse: 2.38519 | valid_rmsle: 0.18658 | valid_mae: 1.47413 | valid_rmse: 1.54865 | valid_mse: 2.39831 |  0:00:01s\n",
      "epoch 1  | loss: 1.11933 | train_rmsle: 0.07433 | train_mae: 0.97433 | train_rmse: 1.06538 | train_mse: 1.13502 | valid_rmsle: 0.07458 | valid_mae: 0.9764  | valid_rmse: 1.06878 | valid_mse: 1.14229 |  0:00:02s\n",
      "epoch 2  | loss: 0.49055 | train_rmsle: 0.05013 | train_mae: 0.80516 | train_rmse: 0.89925 | train_mse: 0.80866 | valid_rmsle: 0.05023 | valid_mae: 0.80579 | valid_rmse: 0.90228 | valid_mse: 0.81411 |  0:00:03s\n",
      "epoch 3  | loss: 0.35894 | train_rmsle: 0.0426  | train_mae: 0.74298 | train_rmse: 0.83671 | train_mse: 0.70009 | valid_rmsle: 0.04256 | valid_mae: 0.7421  | valid_rmse: 0.83878 | valid_mse: 0.70354 |  0:00:04s\n",
      "epoch 4  | loss: 0.28264 | train_rmsle: 0.03243 | train_mae: 0.64853 | train_rmse: 0.7391  | train_mse: 0.54627 | valid_rmsle: 0.03224 | valid_mae: 0.64775 | valid_rmse: 0.73985 | valid_mse: 0.54737 |  0:00:05s\n",
      "epoch 5  | loss: 0.25765 | train_rmsle: 0.02613 | train_mae: 0.5781  | train_rmse: 0.66747 | train_mse: 0.44551 | valid_rmsle: 0.02604 | valid_mae: 0.57947 | valid_rmse: 0.66939 | valid_mse: 0.44809 |  0:00:06s\n",
      "epoch 6  | loss: 0.23853 | train_rmsle: 0.0205  | train_mae: 0.50413 | train_rmse: 0.59204 | train_mse: 0.35052 | valid_rmsle: 0.02018 | valid_mae: 0.50425 | valid_rmse: 0.59109 | valid_mse: 0.34939 |  0:00:08s\n",
      "epoch 7  | loss: 0.22578 | train_rmsle: 0.01783 | train_mae: 0.46024 | train_rmse: 0.5502  | train_mse: 0.30272 | valid_rmsle: 0.0176  | valid_mae: 0.46132 | valid_rmse: 0.55053 | valid_mse: 0.30308 |  0:00:09s\n",
      "epoch 8  | loss: 0.21382 | train_rmsle: 0.01637 | train_mae: 0.43847 | train_rmse: 0.52629 | train_mse: 0.27698 | valid_rmsle: 0.01614 | valid_mae: 0.44113 | valid_rmse: 0.52697 | valid_mse: 0.2777  |  0:00:10s\n",
      "epoch 9  | loss: 0.20513 | train_rmsle: 0.01353 | train_mae: 0.37812 | train_rmse: 0.46953 | train_mse: 0.22046 | valid_rmsle: 0.01322 | valid_mae: 0.38074 | valid_rmse: 0.46924 | valid_mse: 0.22019 |  0:00:11s\n",
      "epoch 10 | loss: 0.19859 | train_rmsle: 0.01424 | train_mae: 0.39245 | train_rmse: 0.48446 | train_mse: 0.2347  | valid_rmsle: 0.01395 | valid_mae: 0.39547 | valid_rmse: 0.48423 | valid_mse: 0.23448 |  0:00:12s\n",
      "epoch 11 | loss: 0.18859 | train_rmsle: 0.01394 | train_mae: 0.39023 | train_rmse: 0.47977 | train_mse: 0.23018 | valid_rmsle: 0.01362 | valid_mae: 0.39406 | valid_rmse: 0.47898 | valid_mse: 0.22942 |  0:00:13s\n",
      "epoch 12 | loss: 0.18835 | train_rmsle: 0.01441 | train_mae: 0.40053 | train_rmse: 0.49008 | train_mse: 0.24018 | valid_rmsle: 0.01431 | valid_mae: 0.40608 | valid_rmse: 0.49263 | valid_mse: 0.24268 |  0:00:14s\n",
      "epoch 13 | loss: 0.18952 | train_rmsle: 0.01391 | train_mae: 0.39076 | train_rmse: 0.48055 | train_mse: 0.23093 | valid_rmsle: 0.0138  | valid_mae: 0.39518 | valid_rmse: 0.48315 | valid_mse: 0.23344 |  0:00:16s\n",
      "epoch 14 | loss: 0.17848 | train_rmsle: 0.01283 | train_mae: 0.36537 | train_rmse: 0.45637 | train_mse: 0.20827 | valid_rmsle: 0.01252 | valid_mae: 0.36786 | valid_rmse: 0.45554 | valid_mse: 0.20752 |  0:00:17s\n",
      "epoch 15 | loss: 0.17265 | train_rmsle: 0.01293 | train_mae: 0.37178 | train_rmse: 0.45971 | train_mse: 0.21133 | valid_rmsle: 0.01269 | valid_mae: 0.37537 | valid_rmse: 0.46023 | valid_mse: 0.21181 |  0:00:18s\n",
      "epoch 16 | loss: 0.1709  | train_rmsle: 0.0128  | train_mae: 0.36781 | train_rmse: 0.45721 | train_mse: 0.20904 | valid_rmsle: 0.01261 | valid_mae: 0.36947 | valid_rmse: 0.4582  | valid_mse: 0.20994 |  0:00:19s\n",
      "epoch 17 | loss: 0.16793 | train_rmsle: 0.01221 | train_mae: 0.35458 | train_rmse: 0.444   | train_mse: 0.19714 | valid_rmsle: 0.01231 | valid_mae: 0.36332 | valid_rmse: 0.4513  | valid_mse: 0.20367 |  0:00:20s\n",
      "epoch 18 | loss: 0.16423 | train_rmsle: 0.01222 | train_mae: 0.35668 | train_rmse: 0.44548 | train_mse: 0.19845 | valid_rmsle: 0.01238 | valid_mae: 0.36658 | valid_rmse: 0.45367 | valid_mse: 0.20582 |  0:00:21s\n",
      "epoch 19 | loss: 0.15921 | train_rmsle: 0.0119  | train_mae: 0.353   | train_rmse: 0.4401  | train_mse: 0.19368 | valid_rmsle: 0.01224 | valid_mae: 0.36586 | valid_rmse: 0.45213 | valid_mse: 0.20443 |  0:00:22s\n",
      "epoch 20 | loss: 0.15368 | train_rmsle: 0.0119  | train_mae: 0.35461 | train_rmse: 0.44133 | train_mse: 0.19478 | valid_rmsle: 0.0127  | valid_mae: 0.37467 | valid_rmse: 0.46165 | valid_mse: 0.21312 |  0:00:23s\n",
      "epoch 21 | loss: 0.14985 | train_rmsle: 0.01115 | train_mae: 0.33822 | train_rmse: 0.42471 | train_mse: 0.18038 | valid_rmsle: 0.01192 | valid_mae: 0.35723 | valid_rmse: 0.4451  | valid_mse: 0.19811 |  0:00:25s\n",
      "epoch 22 | loss: 0.14374 | train_rmsle: 0.01044 | train_mae: 0.32406 | train_rmse: 0.4099  | train_mse: 0.16802 | valid_rmsle: 0.01122 | valid_mae: 0.34368 | valid_rmse: 0.43084 | valid_mse: 0.18562 |  0:00:26s\n",
      "epoch 23 | loss: 0.14257 | train_rmsle: 0.0101  | train_mae: 0.32116 | train_rmse: 0.40487 | train_mse: 0.16392 | valid_rmsle: 0.01088 | valid_mae: 0.34222 | valid_rmse: 0.42638 | valid_mse: 0.1818  |  0:00:27s\n",
      "epoch 24 | loss: 0.13652 | train_rmsle: 0.00936 | train_mae: 0.30942 | train_rmse: 0.3899  | train_mse: 0.15202 | valid_rmsle: 0.01024 | valid_mae: 0.33325 | valid_rmse: 0.41416 | valid_mse: 0.17153 |  0:00:28s\n",
      "epoch 25 | loss: 0.13076 | train_rmsle: 0.00835 | train_mae: 0.28962 | train_rmse: 0.36735 | train_mse: 0.13495 | valid_rmsle: 0.00966 | valid_mae: 0.32132 | valid_rmse: 0.402   | valid_mse: 0.16161 |  0:00:29s\n",
      "epoch 26 | loss: 0.12387 | train_rmsle: 0.00747 | train_mae: 0.26944 | train_rmse: 0.34608 | train_mse: 0.11977 | valid_rmsle: 0.00863 | valid_mae: 0.30048 | valid_rmse: 0.37949 | valid_mse: 0.14401 |  0:00:30s\n",
      "epoch 27 | loss: 0.11404 | train_rmsle: 0.00723 | train_mae: 0.26311 | train_rmse: 0.33858 | train_mse: 0.11464 | valid_rmsle: 0.00858 | valid_mae: 0.30253 | valid_rmse: 0.37837 | valid_mse: 0.14316 |  0:00:31s\n",
      "epoch 28 | loss: 0.10162 | train_rmsle: 0.00689 | train_mae: 0.26142 | train_rmse: 0.33446 | train_mse: 0.11186 | valid_rmsle: 0.00758 | valid_mae: 0.28351 | valid_rmse: 0.35824 | valid_mse: 0.12834 |  0:00:33s\n",
      "epoch 29 | loss: 0.08675 | train_rmsle: 0.00537 | train_mae: 0.2282  | train_rmse: 0.29448 | train_mse: 0.08672 | valid_rmsle: 0.00661 | valid_mae: 0.25907 | valid_rmse: 0.33366 | valid_mse: 0.11133 |  0:00:34s\n",
      "epoch 30 | loss: 0.07725 | train_rmsle: 0.00459 | train_mae: 0.20829 | train_rmse: 0.26882 | train_mse: 0.07227 | valid_rmsle: 0.00566 | valid_mae: 0.23662 | valid_rmse: 0.30574 | valid_mse: 0.09347 |  0:00:35s\n",
      "epoch 31 | loss: 0.06906 | train_rmsle: 0.00434 | train_mae: 0.20569 | train_rmse: 0.26304 | train_mse: 0.06919 | valid_rmsle: 0.00566 | valid_mae: 0.24085 | valid_rmse: 0.30768 | valid_mse: 0.09467 |  0:00:36s\n",
      "epoch 32 | loss: 0.06483 | train_rmsle: 0.0038  | train_mae: 0.1915  | train_rmse: 0.24577 | train_mse: 0.0604  | valid_rmsle: 0.005   | valid_mae: 0.22898 | valid_rmse: 0.28909 | valid_mse: 0.08358 |  0:00:37s\n",
      "epoch 33 | loss: 0.06201 | train_rmsle: 0.00365 | train_mae: 0.18882 | train_rmse: 0.24085 | train_mse: 0.05801 | valid_rmsle: 0.00515 | valid_mae: 0.23111 | valid_rmse: 0.29382 | valid_mse: 0.08633 |  0:00:38s\n",
      "epoch 34 | loss: 0.05834 | train_rmsle: 0.00319 | train_mae: 0.17259 | train_rmse: 0.22476 | train_mse: 0.05052 | valid_rmsle: 0.00477 | valid_mae: 0.22306 | valid_rmse: 0.28312 | valid_mse: 0.08016 |  0:00:39s\n",
      "epoch 35 | loss: 0.05477 | train_rmsle: 0.00311 | train_mae: 0.17133 | train_rmse: 0.22326 | train_mse: 0.04985 | valid_rmsle: 0.0046  | valid_mae: 0.21424 | valid_rmse: 0.27874 | valid_mse: 0.07769 |  0:00:41s\n",
      "epoch 36 | loss: 0.05495 | train_rmsle: 0.00292 | train_mae: 0.16641 | train_rmse: 0.21623 | train_mse: 0.04675 | valid_rmsle: 0.00439 | valid_mae: 0.21184 | valid_rmse: 0.27157 | valid_mse: 0.07375 |  0:00:42s\n",
      "epoch 37 | loss: 0.05089 | train_rmsle: 0.00299 | train_mae: 0.17119 | train_rmse: 0.22001 | train_mse: 0.0484  | valid_rmsle: 0.00449 | valid_mae: 0.21424 | valid_rmse: 0.2753  | valid_mse: 0.07579 |  0:00:43s\n",
      "epoch 38 | loss: 0.05112 | train_rmsle: 0.0028  | train_mae: 0.16398 | train_rmse: 0.2123  | train_mse: 0.04507 | valid_rmsle: 0.0044  | valid_mae: 0.21133 | valid_rmse: 0.27239 | valid_mse: 0.0742  |  0:00:44s\n",
      "epoch 39 | loss: 0.04999 | train_rmsle: 0.00267 | train_mae: 0.161   | train_rmse: 0.20754 | train_mse: 0.04307 | valid_rmsle: 0.00448 | valid_mae: 0.21476 | valid_rmse: 0.2742  | valid_mse: 0.07519 |  0:00:45s\n",
      "epoch 40 | loss: 0.04783 | train_rmsle: 0.00247 | train_mae: 0.15326 | train_rmse: 0.19998 | train_mse: 0.03999 | valid_rmsle: 0.00449 | valid_mae: 0.21286 | valid_rmse: 0.27486 | valid_mse: 0.07555 |  0:00:46s\n",
      "epoch 41 | loss: 0.04853 | train_rmsle: 0.00247 | train_mae: 0.15124 | train_rmse: 0.19926 | train_mse: 0.03971 | valid_rmsle: 0.00456 | valid_mae: 0.21459 | valid_rmse: 0.27703 | valid_mse: 0.07675 |  0:00:47s\n",
      "epoch 42 | loss: 0.04655 | train_rmsle: 0.00243 | train_mae: 0.15397 | train_rmse: 0.20004 | train_mse: 0.04001 | valid_rmsle: 0.00467 | valid_mae: 0.22283 | valid_rmse: 0.28226 | valid_mse: 0.07967 |  0:00:49s\n",
      "epoch 43 | loss: 0.04311 | train_rmsle: 0.00225 | train_mae: 0.14567 | train_rmse: 0.19018 | train_mse: 0.03617 | valid_rmsle: 0.00433 | valid_mae: 0.21015 | valid_rmse: 0.27021 | valid_mse: 0.07302 |  0:00:50s\n",
      "epoch 44 | loss: 0.04331 | train_rmsle: 0.00231 | train_mae: 0.15169 | train_rmse: 0.19585 | train_mse: 0.03836 | valid_rmsle: 0.00449 | valid_mae: 0.21917 | valid_rmse: 0.27749 | valid_mse: 0.077   |  0:00:51s\n",
      "epoch 45 | loss: 0.04072 | train_rmsle: 0.00194 | train_mae: 0.13184 | train_rmse: 0.17595 | train_mse: 0.03096 | valid_rmsle: 0.00427 | valid_mae: 0.20597 | valid_rmse: 0.26862 | valid_mse: 0.07215 |  0:00:52s\n",
      "epoch 46 | loss: 0.03894 | train_rmsle: 0.00186 | train_mae: 0.12839 | train_rmse: 0.1724  | train_mse: 0.02972 | valid_rmsle: 0.00426 | valid_mae: 0.20579 | valid_rmse: 0.26775 | valid_mse: 0.07169 |  0:00:53s\n",
      "epoch 47 | loss: 0.04072 | train_rmsle: 0.00187 | train_mae: 0.13223 | train_rmse: 0.17541 | train_mse: 0.03077 | valid_rmsle: 0.00432 | valid_mae: 0.21007 | valid_rmse: 0.27205 | valid_mse: 0.07401 |  0:00:54s\n",
      "epoch 48 | loss: 0.04112 | train_rmsle: 0.00185 | train_mae: 0.1305  | train_rmse: 0.17389 | train_mse: 0.03024 | valid_rmsle: 0.00426 | valid_mae: 0.20844 | valid_rmse: 0.26995 | valid_mse: 0.07287 |  0:00:55s\n",
      "epoch 49 | loss: 0.04001 | train_rmsle: 0.00188 | train_mae: 0.13284 | train_rmse: 0.17631 | train_mse: 0.03108 | valid_rmsle: 0.00419 | valid_mae: 0.20644 | valid_rmse: 0.26748 | valid_mse: 0.07155 |  0:00:57s\n",
      "epoch 50 | loss: 0.03815 | train_rmsle: 0.00191 | train_mae: 0.13579 | train_rmse: 0.17862 | train_mse: 0.0319  | valid_rmsle: 0.0042  | valid_mae: 0.2106  | valid_rmse: 0.26894 | valid_mse: 0.07233 |  0:00:58s\n",
      "epoch 51 | loss: 0.03647 | train_rmsle: 0.00184 | train_mae: 0.13325 | train_rmse: 0.17584 | train_mse: 0.03092 | valid_rmsle: 0.00421 | valid_mae: 0.20892 | valid_rmse: 0.26852 | valid_mse: 0.0721  |  0:00:59s\n",
      "epoch 52 | loss: 0.03789 | train_rmsle: 0.00161 | train_mae: 0.12144 | train_rmse: 0.16248 | train_mse: 0.0264  | valid_rmsle: 0.00413 | valid_mae: 0.20335 | valid_rmse: 0.26539 | valid_mse: 0.07043 |  0:01:00s\n",
      "epoch 53 | loss: 0.03625 | train_rmsle: 0.00179 | train_mae: 0.1288  | train_rmse: 0.171   | train_mse: 0.02924 | valid_rmsle: 0.00433 | valid_mae: 0.20914 | valid_rmse: 0.27231 | valid_mse: 0.07415 |  0:01:01s\n",
      "epoch 54 | loss: 0.03719 | train_rmsle: 0.00189 | train_mae: 0.13711 | train_rmse: 0.17932 | train_mse: 0.03215 | valid_rmsle: 0.00422 | valid_mae: 0.21128 | valid_rmse: 0.27065 | valid_mse: 0.07325 |  0:01:02s\n",
      "epoch 55 | loss: 0.03607 | train_rmsle: 0.00159 | train_mae: 0.12198 | train_rmse: 0.16273 | train_mse: 0.02648 | valid_rmsle: 0.0039  | valid_mae: 0.20098 | valid_rmse: 0.25932 | valid_mse: 0.06725 |  0:01:03s\n",
      "epoch 56 | loss: 0.03311 | train_rmsle: 0.00167 | train_mae: 0.12745 | train_rmse: 0.16856 | train_mse: 0.02841 | valid_rmsle: 0.00387 | valid_mae: 0.20236 | valid_rmse: 0.259   | valid_mse: 0.06708 |  0:01:05s\n",
      "epoch 57 | loss: 0.03415 | train_rmsle: 0.00153 | train_mae: 0.12054 | train_rmse: 0.1603  | train_mse: 0.0257  | valid_rmsle: 0.00376 | valid_mae: 0.19819 | valid_rmse: 0.25507 | valid_mse: 0.06506 |  0:01:06s\n",
      "epoch 58 | loss: 0.03331 | train_rmsle: 0.00154 | train_mae: 0.12218 | train_rmse: 0.16114 | train_mse: 0.02596 | valid_rmsle: 0.00375 | valid_mae: 0.19981 | valid_rmse: 0.25522 | valid_mse: 0.06514 |  0:01:07s\n",
      "epoch 59 | loss: 0.03088 | train_rmsle: 0.00141 | train_mae: 0.11481 | train_rmse: 0.15343 | train_mse: 0.02354 | valid_rmsle: 0.0036  | valid_mae: 0.19513 | valid_rmse: 0.24933 | valid_mse: 0.06216 |  0:01:08s\n",
      "epoch 60 | loss: 0.03111 | train_rmsle: 0.00148 | train_mae: 0.11955 | train_rmse: 0.15819 | train_mse: 0.02502 | valid_rmsle: 0.00365 | valid_mae: 0.19633 | valid_rmse: 0.25195 | valid_mse: 0.06348 |  0:01:09s\n",
      "epoch 61 | loss: 0.03085 | train_rmsle: 0.0015  | train_mae: 0.11874 | train_rmse: 0.15611 | train_mse: 0.02437 | valid_rmsle: 0.00374 | valid_mae: 0.19809 | valid_rmse: 0.25293 | valid_mse: 0.06397 |  0:01:10s\n",
      "epoch 62 | loss: 0.03128 | train_rmsle: 0.00133 | train_mae: 0.11033 | train_rmse: 0.149   | train_mse: 0.0222  | valid_rmsle: 0.00353 | valid_mae: 0.19039 | valid_rmse: 0.24772 | valid_mse: 0.06136 |  0:01:11s\n",
      "epoch 63 | loss: 0.02985 | train_rmsle: 0.00129 | train_mae: 0.10623 | train_rmse: 0.14386 | train_mse: 0.0207  | valid_rmsle: 0.00357 | valid_mae: 0.19053 | valid_rmse: 0.24747 | valid_mse: 0.06124 |  0:01:12s\n",
      "epoch 64 | loss: 0.03022 | train_rmsle: 0.00119 | train_mae: 0.10394 | train_rmse: 0.14116 | train_mse: 0.01993 | valid_rmsle: 0.00336 | valid_mae: 0.18602 | valid_rmse: 0.24087 | valid_mse: 0.05802 |  0:01:14s\n",
      "epoch 65 | loss: 0.02785 | train_rmsle: 0.00115 | train_mae: 0.10198 | train_rmse: 0.13887 | train_mse: 0.01928 | valid_rmsle: 0.00341 | valid_mae: 0.18754 | valid_rmse: 0.24258 | valid_mse: 0.05885 |  0:01:15s\n",
      "epoch 66 | loss: 0.02641 | train_rmsle: 0.00113 | train_mae: 0.09993 | train_rmse: 0.13703 | train_mse: 0.01878 | valid_rmsle: 0.00342 | valid_mae: 0.18574 | valid_rmse: 0.24292 | valid_mse: 0.05901 |  0:01:16s\n",
      "epoch 67 | loss: 0.02671 | train_rmsle: 0.0011  | train_mae: 0.09989 | train_rmse: 0.13652 | train_mse: 0.01864 | valid_rmsle: 0.00348 | valid_mae: 0.18728 | valid_rmse: 0.24471 | valid_mse: 0.05988 |  0:01:17s\n",
      "epoch 68 | loss: 0.02618 | train_rmsle: 0.0011  | train_mae: 0.09962 | train_rmse: 0.1349  | train_mse: 0.0182  | valid_rmsle: 0.00358 | valid_mae: 0.19085 | valid_rmse: 0.24846 | valid_mse: 0.06173 |  0:01:18s\n",
      "epoch 69 | loss: 0.02538 | train_rmsle: 0.00129 | train_mae: 0.11074 | train_rmse: 0.14534 | train_mse: 0.02112 | valid_rmsle: 0.00365 | valid_mae: 0.1937  | valid_rmse: 0.24971 | valid_mse: 0.06236 |  0:01:19s\n",
      "epoch 70 | loss: 0.02697 | train_rmsle: 0.001   | train_mae: 0.09502 | train_rmse: 0.1301  | train_mse: 0.01693 | valid_rmsle: 0.00324 | valid_mae: 0.18159 | valid_rmse: 0.23643 | valid_mse: 0.0559  |  0:01:21s\n",
      "epoch 71 | loss: 0.02508 | train_rmsle: 0.00096 | train_mae: 0.09473 | train_rmse: 0.12917 | train_mse: 0.01669 | valid_rmsle: 0.0033  | valid_mae: 0.18195 | valid_rmse: 0.23769 | valid_mse: 0.0565  |  0:01:22s\n",
      "epoch 72 | loss: 0.02569 | train_rmsle: 0.00108 | train_mae: 0.10184 | train_rmse: 0.13559 | train_mse: 0.01838 | valid_rmsle: 0.00343 | valid_mae: 0.18605 | valid_rmse: 0.24337 | valid_mse: 0.05923 |  0:01:23s\n",
      "epoch 73 | loss: 0.02511 | train_rmsle: 0.00096 | train_mae: 0.09588 | train_rmse: 0.12935 | train_mse: 0.01673 | valid_rmsle: 0.00329 | valid_mae: 0.18181 | valid_rmse: 0.23923 | valid_mse: 0.05723 |  0:01:24s\n",
      "epoch 74 | loss: 0.02212 | train_rmsle: 0.00085 | train_mae: 0.08735 | train_rmse: 0.12068 | train_mse: 0.01456 | valid_rmsle: 0.00316 | valid_mae: 0.17694 | valid_rmse: 0.23358 | valid_mse: 0.05456 |  0:01:25s\n",
      "epoch 75 | loss: 0.02215 | train_rmsle: 0.00081 | train_mae: 0.08651 | train_rmse: 0.11954 | train_mse: 0.01429 | valid_rmsle: 0.00313 | valid_mae: 0.17649 | valid_rmse: 0.23276 | valid_mse: 0.05418 |  0:01:26s\n",
      "epoch 76 | loss: 0.02118 | train_rmsle: 0.00087 | train_mae: 0.09258 | train_rmse: 0.12453 | train_mse: 0.01551 | valid_rmsle: 0.00322 | valid_mae: 0.18199 | valid_rmse: 0.23639 | valid_mse: 0.05588 |  0:01:27s\n",
      "epoch 77 | loss: 0.02209 | train_rmsle: 0.00082 | train_mae: 0.08858 | train_rmse: 0.12102 | train_mse: 0.01465 | valid_rmsle: 0.00322 | valid_mae: 0.18016 | valid_rmse: 0.23579 | valid_mse: 0.0556  |  0:01:28s\n",
      "epoch 78 | loss: 0.02367 | train_rmsle: 0.00129 | train_mae: 0.12062 | train_rmse: 0.14984 | train_mse: 0.02245 | valid_rmsle: 0.00368 | valid_mae: 0.19614 | valid_rmse: 0.25064 | valid_mse: 0.06282 |  0:01:30s\n",
      "epoch 79 | loss: 0.02204 | train_rmsle: 0.00081 | train_mae: 0.0874  | train_rmse: 0.12004 | train_mse: 0.01441 | valid_rmsle: 0.00314 | valid_mae: 0.17691 | valid_rmse: 0.23346 | valid_mse: 0.0545  |  0:01:31s\n",
      "epoch 80 | loss: 0.02187 | train_rmsle: 0.001   | train_mae: 0.09619 | train_rmse: 0.12733 | train_mse: 0.01621 | valid_rmsle: 0.00333 | valid_mae: 0.18208 | valid_rmse: 0.23645 | valid_mse: 0.05591 |  0:01:32s\n",
      "epoch 81 | loss: 0.0228  | train_rmsle: 0.00078 | train_mae: 0.08704 | train_rmse: 0.11857 | train_mse: 0.01406 | valid_rmsle: 0.00308 | valid_mae: 0.17675 | valid_rmse: 0.23169 | valid_mse: 0.05368 |  0:01:33s\n",
      "epoch 82 | loss: 0.02123 | train_rmsle: 0.00088 | train_mae: 0.09508 | train_rmse: 0.1262  | train_mse: 0.01593 | valid_rmsle: 0.00297 | valid_mae: 0.17347 | valid_rmse: 0.22773 | valid_mse: 0.05186 |  0:01:34s\n",
      "epoch 83 | loss: 0.0217  | train_rmsle: 0.00071 | train_mae: 0.08104 | train_rmse: 0.11332 | train_mse: 0.01284 | valid_rmsle: 0.00288 | valid_mae: 0.16883 | valid_rmse: 0.22391 | valid_mse: 0.05014 |  0:01:35s\n",
      "epoch 84 | loss: 0.0223  | train_rmsle: 0.00117 | train_mae: 0.10793 | train_rmse: 0.13761 | train_mse: 0.01894 | valid_rmsle: 0.00336 | valid_mae: 0.18369 | valid_rmse: 0.23803 | valid_mse: 0.05666 |  0:01:36s\n",
      "epoch 85 | loss: 0.021   | train_rmsle: 0.00092 | train_mae: 0.09425 | train_rmse: 0.12377 | train_mse: 0.01532 | valid_rmsle: 0.00309 | valid_mae: 0.17403 | valid_rmse: 0.22962 | valid_mse: 0.05272 |  0:01:38s\n",
      "epoch 86 | loss: 0.01906 | train_rmsle: 0.0007  | train_mae: 0.08067 | train_rmse: 0.11161 | train_mse: 0.01246 | valid_rmsle: 0.00282 | valid_mae: 0.16697 | valid_rmse: 0.22134 | valid_mse: 0.04899 |  0:01:39s\n",
      "epoch 87 | loss: 0.02192 | train_rmsle: 0.00066 | train_mae: 0.07691 | train_rmse: 0.10757 | train_mse: 0.01157 | valid_rmsle: 0.00291 | valid_mae: 0.16899 | valid_rmse: 0.22494 | valid_mse: 0.0506  |  0:01:40s\n",
      "epoch 88 | loss: 0.01983 | train_rmsle: 0.0007  | train_mae: 0.07865 | train_rmse: 0.10984 | train_mse: 0.01207 | valid_rmsle: 0.00287 | valid_mae: 0.16988 | valid_rmse: 0.22357 | valid_mse: 0.04998 |  0:01:41s\n",
      "epoch 89 | loss: 0.02024 | train_rmsle: 0.00061 | train_mae: 0.07424 | train_rmse: 0.1043  | train_mse: 0.01088 | valid_rmsle: 0.00281 | valid_mae: 0.16717 | valid_rmse: 0.22239 | valid_mse: 0.04946 |  0:01:42s\n",
      "epoch 90 | loss: 0.01894 | train_rmsle: 0.00065 | train_mae: 0.07683 | train_rmse: 0.10683 | train_mse: 0.01141 | valid_rmsle: 0.00282 | valid_mae: 0.16715 | valid_rmse: 0.2223  | valid_mse: 0.04942 |  0:01:43s\n",
      "epoch 91 | loss: 0.01938 | train_rmsle: 0.00065 | train_mae: 0.0766  | train_rmse: 0.1058  | train_mse: 0.01119 | valid_rmsle: 0.00295 | valid_mae: 0.16935 | valid_rmse: 0.22782 | valid_mse: 0.0519  |  0:01:45s\n",
      "epoch 92 | loss: 0.01781 | train_rmsle: 0.00059 | train_mae: 0.0716  | train_rmse: 0.10175 | train_mse: 0.01035 | valid_rmsle: 0.00288 | valid_mae: 0.16796 | valid_rmse: 0.22548 | valid_mse: 0.05084 |  0:01:46s\n",
      "epoch 93 | loss: 0.01969 | train_rmsle: 0.00067 | train_mae: 0.08052 | train_rmse: 0.10901 | train_mse: 0.01188 | valid_rmsle: 0.00287 | valid_mae: 0.16815 | valid_rmse: 0.22405 | valid_mse: 0.0502  |  0:01:47s\n",
      "epoch 94 | loss: 0.01815 | train_rmsle: 0.00056 | train_mae: 0.0701  | train_rmse: 0.09915 | train_mse: 0.00983 | valid_rmsle: 0.00273 | valid_mae: 0.16455 | valid_rmse: 0.21884 | valid_mse: 0.04789 |  0:01:48s\n",
      "epoch 95 | loss: 0.01681 | train_rmsle: 0.00075 | train_mae: 0.08937 | train_rmse: 0.11777 | train_mse: 0.01387 | valid_rmsle: 0.00293 | valid_mae: 0.17464 | valid_rmse: 0.22766 | valid_mse: 0.05183 |  0:01:49s\n",
      "epoch 96 | loss: 0.01717 | train_rmsle: 0.00053 | train_mae: 0.0684  | train_rmse: 0.09713 | train_mse: 0.00943 | valid_rmsle: 0.00281 | valid_mae: 0.16633 | valid_rmse: 0.22237 | valid_mse: 0.04945 |  0:01:50s\n",
      "epoch 97 | loss: 0.01683 | train_rmsle: 0.0005  | train_mae: 0.06616 | train_rmse: 0.09383 | train_mse: 0.0088  | valid_rmsle: 0.00283 | valid_mae: 0.16569 | valid_rmse: 0.22219 | valid_mse: 0.04937 |  0:01:51s\n",
      "epoch 98 | loss: 0.01705 | train_rmsle: 0.00053 | train_mae: 0.06823 | train_rmse: 0.09669 | train_mse: 0.00935 | valid_rmsle: 0.00281 | valid_mae: 0.16623 | valid_rmse: 0.22153 | valid_mse: 0.04907 |  0:01:52s\n",
      "epoch 99 | loss: 0.01661 | train_rmsle: 0.00049 | train_mae: 0.06609 | train_rmse: 0.09423 | train_mse: 0.00888 | valid_rmsle: 0.00281 | valid_mae: 0.16542 | valid_rmse: 0.22247 | valid_mse: 0.04949 |  0:01:54s\n",
      "epoch 100| loss: 0.01781 | train_rmsle: 0.00063 | train_mae: 0.07864 | train_rmse: 0.10499 | train_mse: 0.01102 | valid_rmsle: 0.00284 | valid_mae: 0.1679  | valid_rmse: 0.22326 | valid_mse: 0.04985 |  0:01:55s\n",
      "epoch 101| loss: 0.01654 | train_rmsle: 0.00055 | train_mae: 0.06941 | train_rmse: 0.0969  | train_mse: 0.00939 | valid_rmsle: 0.00267 | valid_mae: 0.16348 | valid_rmse: 0.21568 | valid_mse: 0.04652 |  0:01:56s\n",
      "epoch 102| loss: 0.01756 | train_rmsle: 0.00051 | train_mae: 0.06904 | train_rmse: 0.0954  | train_mse: 0.0091  | valid_rmsle: 0.0027  | valid_mae: 0.16366 | valid_rmse: 0.21848 | valid_mse: 0.04773 |  0:01:57s\n",
      "epoch 103| loss: 0.0163  | train_rmsle: 0.00044 | train_mae: 0.06294 | train_rmse: 0.0888  | train_mse: 0.00789 | valid_rmsle: 0.00272 | valid_mae: 0.16421 | valid_rmse: 0.21877 | valid_mse: 0.04786 |  0:01:58s\n",
      "epoch 104| loss: 0.01612 | train_rmsle: 0.0005  | train_mae: 0.06689 | train_rmse: 0.09235 | train_mse: 0.00853 | valid_rmsle: 0.00267 | valid_mae: 0.16041 | valid_rmse: 0.21523 | valid_mse: 0.04633 |  0:01:59s\n",
      "epoch 105| loss: 0.0168  | train_rmsle: 0.00049 | train_mae: 0.06762 | train_rmse: 0.09394 | train_mse: 0.00882 | valid_rmsle: 0.00262 | valid_mae: 0.15948 | valid_rmse: 0.21479 | valid_mse: 0.04614 |  0:02:00s\n",
      "epoch 106| loss: 0.01528 | train_rmsle: 0.00052 | train_mae: 0.07024 | train_rmse: 0.09693 | train_mse: 0.0094  | valid_rmsle: 0.00264 | valid_mae: 0.16017 | valid_rmse: 0.21605 | valid_mse: 0.04668 |  0:02:02s\n",
      "epoch 107| loss: 0.01727 | train_rmsle: 0.00058 | train_mae: 0.07772 | train_rmse: 0.10324 | train_mse: 0.01066 | valid_rmsle: 0.00271 | valid_mae: 0.16591 | valid_rmse: 0.21855 | valid_mse: 0.04776 |  0:02:03s\n",
      "epoch 108| loss: 0.01583 | train_rmsle: 0.00057 | train_mae: 0.07122 | train_rmse: 0.09674 | train_mse: 0.00936 | valid_rmsle: 0.00271 | valid_mae: 0.1612  | valid_rmse: 0.21706 | valid_mse: 0.04712 |  0:02:04s\n",
      "epoch 109| loss: 0.01553 | train_rmsle: 0.00055 | train_mae: 0.07026 | train_rmse: 0.09504 | train_mse: 0.00903 | valid_rmsle: 0.0026  | valid_mae: 0.16143 | valid_rmse: 0.21321 | valid_mse: 0.04546 |  0:02:05s\n",
      "epoch 110| loss: 0.01578 | train_rmsle: 0.00043 | train_mae: 0.06039 | train_rmse: 0.08592 | train_mse: 0.00738 | valid_rmsle: 0.00254 | valid_mae: 0.15887 | valid_rmse: 0.21157 | valid_mse: 0.04476 |  0:02:06s\n",
      "epoch 111| loss: 0.01611 | train_rmsle: 0.00078 | train_mae: 0.0969  | train_rmse: 0.1218  | train_mse: 0.01483 | valid_rmsle: 0.00283 | valid_mae: 0.17001 | valid_rmse: 0.22587 | valid_mse: 0.05102 |  0:02:07s\n",
      "epoch 112| loss: 0.01761 | train_rmsle: 0.00059 | train_mae: 0.07063 | train_rmse: 0.09639 | train_mse: 0.00929 | valid_rmsle: 0.00261 | valid_mae: 0.16153 | valid_rmse: 0.21215 | valid_mse: 0.04501 |  0:02:08s\n",
      "epoch 113| loss: 0.01556 | train_rmsle: 0.00043 | train_mae: 0.06323 | train_rmse: 0.08869 | train_mse: 0.00787 | valid_rmsle: 0.00246 | valid_mae: 0.15771 | valid_rmse: 0.20809 | valid_mse: 0.0433  |  0:02:09s\n",
      "epoch 114| loss: 0.0146  | train_rmsle: 0.00042 | train_mae: 0.06199 | train_rmse: 0.08626 | train_mse: 0.00744 | valid_rmsle: 0.00249 | valid_mae: 0.15697 | valid_rmse: 0.20948 | valid_mse: 0.04388 |  0:02:11s\n",
      "epoch 115| loss: 0.0142  | train_rmsle: 0.00042 | train_mae: 0.06095 | train_rmse: 0.08479 | train_mse: 0.00719 | valid_rmsle: 0.00251 | valid_mae: 0.15757 | valid_rmse: 0.21037 | valid_mse: 0.04425 |  0:02:12s\n",
      "epoch 116| loss: 0.01711 | train_rmsle: 0.00046 | train_mae: 0.06597 | train_rmse: 0.09111 | train_mse: 0.0083  | valid_rmsle: 0.00251 | valid_mae: 0.15838 | valid_rmse: 0.20986 | valid_mse: 0.04404 |  0:02:13s\n",
      "epoch 117| loss: 0.0151  | train_rmsle: 0.00039 | train_mae: 0.0594  | train_rmse: 0.08399 | train_mse: 0.00705 | valid_rmsle: 0.00251 | valid_mae: 0.15655 | valid_rmse: 0.20951 | valid_mse: 0.04389 |  0:02:14s\n",
      "epoch 118| loss: 0.01442 | train_rmsle: 0.00057 | train_mae: 0.07745 | train_rmse: 0.0987  | train_mse: 0.00974 | valid_rmsle: 0.00274 | valid_mae: 0.16765 | valid_rmse: 0.2181  | valid_mse: 0.04757 |  0:02:15s\n",
      "epoch 119| loss: 0.01437 | train_rmsle: 0.00046 | train_mae: 0.0663  | train_rmse: 0.08859 | train_mse: 0.00785 | valid_rmsle: 0.0025  | valid_mae: 0.15747 | valid_rmse: 0.21014 | valid_mse: 0.04416 |  0:02:16s\n",
      "epoch 120| loss: 0.01834 | train_rmsle: 0.00058 | train_mae: 0.07289 | train_rmse: 0.09565 | train_mse: 0.00915 | valid_rmsle: 0.00272 | valid_mae: 0.16543 | valid_rmse: 0.21636 | valid_mse: 0.04681 |  0:02:17s\n",
      "epoch 121| loss: 0.01276 | train_rmsle: 0.00035 | train_mae: 0.0553  | train_rmse: 0.07838 | train_mse: 0.00614 | valid_rmsle: 0.00241 | valid_mae: 0.15324 | valid_rmse: 0.20677 | valid_mse: 0.04275 |  0:02:19s\n",
      "epoch 122| loss: 0.01532 | train_rmsle: 0.00047 | train_mae: 0.06654 | train_rmse: 0.08847 | train_mse: 0.00783 | valid_rmsle: 0.00255 | valid_mae: 0.15622 | valid_rmse: 0.21179 | valid_mse: 0.04486 |  0:02:20s\n",
      "epoch 123| loss: 0.01412 | train_rmsle: 0.00037 | train_mae: 0.05921 | train_rmse: 0.08198 | train_mse: 0.00672 | valid_rmsle: 0.0025  | valid_mae: 0.15643 | valid_rmse: 0.21035 | valid_mse: 0.04425 |  0:02:21s\n",
      "epoch 124| loss: 0.01356 | train_rmsle: 0.00051 | train_mae: 0.07527 | train_rmse: 0.09697 | train_mse: 0.0094  | valid_rmsle: 0.00256 | valid_mae: 0.1622  | valid_rmse: 0.2133  | valid_mse: 0.0455  |  0:02:22s\n",
      "epoch 125| loss: 0.0154  | train_rmsle: 0.00056 | train_mae: 0.0771  | train_rmse: 0.10087 | train_mse: 0.01017 | valid_rmsle: 0.00266 | valid_mae: 0.16534 | valid_rmse: 0.21735 | valid_mse: 0.04724 |  0:02:23s\n",
      "epoch 126| loss: 0.0149  | train_rmsle: 0.00034 | train_mae: 0.05653 | train_rmse: 0.07846 | train_mse: 0.00616 | valid_rmsle: 0.00243 | valid_mae: 0.15509 | valid_rmse: 0.20762 | valid_mse: 0.0431  |  0:02:24s\n",
      "epoch 127| loss: 0.01181 | train_rmsle: 0.00039 | train_mae: 0.05784 | train_rmse: 0.08085 | train_mse: 0.00654 | valid_rmsle: 0.00237 | valid_mae: 0.15321 | valid_rmse: 0.20434 | valid_mse: 0.04176 |  0:02:25s\n",
      "epoch 128| loss: 0.01273 | train_rmsle: 0.00031 | train_mae: 0.05246 | train_rmse: 0.07436 | train_mse: 0.00553 | valid_rmsle: 0.00231 | valid_mae: 0.15162 | valid_rmse: 0.20293 | valid_mse: 0.04118 |  0:02:27s\n",
      "epoch 129| loss: 0.01285 | train_rmsle: 0.00084 | train_mae: 0.09846 | train_rmse: 0.11661 | train_mse: 0.0136  | valid_rmsle: 0.00286 | valid_mae: 0.16896 | valid_rmse: 0.22328 | valid_mse: 0.04985 |  0:02:28s\n",
      "epoch 130| loss: 0.01475 | train_rmsle: 0.00031 | train_mae: 0.05331 | train_rmse: 0.0745  | train_mse: 0.00555 | valid_rmsle: 0.0024  | valid_mae: 0.1544  | valid_rmse: 0.20717 | valid_mse: 0.04292 |  0:02:29s\n",
      "epoch 131| loss: 0.0127  | train_rmsle: 0.00031 | train_mae: 0.05289 | train_rmse: 0.0733  | train_mse: 0.00537 | valid_rmsle: 0.00238 | valid_mae: 0.15331 | valid_rmse: 0.20471 | valid_mse: 0.0419  |  0:02:30s\n",
      "epoch 132| loss: 0.01361 | train_rmsle: 0.00028 | train_mae: 0.05101 | train_rmse: 0.07168 | train_mse: 0.00514 | valid_rmsle: 0.00233 | valid_mae: 0.15244 | valid_rmse: 0.20418 | valid_mse: 0.04169 |  0:02:31s\n",
      "epoch 133| loss: 0.01492 | train_rmsle: 0.00033 | train_mae: 0.05316 | train_rmse: 0.07417 | train_mse: 0.0055  | valid_rmsle: 0.00224 | valid_mae: 0.14843 | valid_rmse: 0.19926 | valid_mse: 0.0397  |  0:02:32s\n",
      "epoch 134| loss: 0.01312 | train_rmsle: 0.00045 | train_mae: 0.07044 | train_rmse: 0.09127 | train_mse: 0.00833 | valid_rmsle: 0.00237 | valid_mae: 0.15359 | valid_rmse: 0.20661 | valid_mse: 0.04269 |  0:02:34s\n",
      "epoch 135| loss: 0.01406 | train_rmsle: 0.00032 | train_mae: 0.05515 | train_rmse: 0.07466 | train_mse: 0.00557 | valid_rmsle: 0.0022  | valid_mae: 0.15072 | valid_rmse: 0.19814 | valid_mse: 0.03926 |  0:02:35s\n",
      "epoch 136| loss: 0.01213 | train_rmsle: 0.00031 | train_mae: 0.05635 | train_rmse: 0.07679 | train_mse: 0.0059  | valid_rmsle: 0.00221 | valid_mae: 0.15122 | valid_rmse: 0.19932 | valid_mse: 0.03973 |  0:02:36s\n",
      "epoch 137| loss: 0.01216 | train_rmsle: 0.00026 | train_mae: 0.04904 | train_rmse: 0.06964 | train_mse: 0.00485 | valid_rmsle: 0.0022  | valid_mae: 0.14777 | valid_rmse: 0.19811 | valid_mse: 0.03925 |  0:02:37s\n",
      "epoch 138| loss: 0.01305 | train_rmsle: 0.00036 | train_mae: 0.05952 | train_rmse: 0.08123 | train_mse: 0.0066  | valid_rmsle: 0.0023  | valid_mae: 0.14887 | valid_rmse: 0.20229 | valid_mse: 0.04092 |  0:02:38s\n",
      "epoch 139| loss: 0.01378 | train_rmsle: 0.00066 | train_mae: 0.0816  | train_rmse: 0.10228 | train_mse: 0.01046 | valid_rmsle: 0.0026  | valid_mae: 0.15772 | valid_rmse: 0.21317 | valid_mse: 0.04544 |  0:02:39s\n",
      "epoch 140| loss: 0.01437 | train_rmsle: 0.00026 | train_mae: 0.04946 | train_rmse: 0.06995 | train_mse: 0.00489 | valid_rmsle: 0.00222 | valid_mae: 0.14774 | valid_rmse: 0.19944 | valid_mse: 0.03977 |  0:02:40s\n",
      "epoch 141| loss: 0.01161 | train_rmsle: 0.00028 | train_mae: 0.05141 | train_rmse: 0.07093 | train_mse: 0.00503 | valid_rmsle: 0.00227 | valid_mae: 0.14692 | valid_rmse: 0.20201 | valid_mse: 0.04081 |  0:02:41s\n",
      "epoch 142| loss: 0.0115  | train_rmsle: 0.00031 | train_mae: 0.05263 | train_rmse: 0.07319 | train_mse: 0.00536 | valid_rmsle: 0.00221 | valid_mae: 0.14551 | valid_rmse: 0.19778 | valid_mse: 0.03912 |  0:02:43s\n",
      "epoch 143| loss: 0.01181 | train_rmsle: 0.00033 | train_mae: 0.05738 | train_rmse: 0.0765  | train_mse: 0.00585 | valid_rmsle: 0.00221 | valid_mae: 0.14935 | valid_rmse: 0.1978  | valid_mse: 0.03913 |  0:02:44s\n",
      "epoch 144| loss: 0.01157 | train_rmsle: 0.00036 | train_mae: 0.05916 | train_rmse: 0.07736 | train_mse: 0.00598 | valid_rmsle: 0.00224 | valid_mae: 0.14711 | valid_rmse: 0.19758 | valid_mse: 0.03904 |  0:02:45s\n",
      "epoch 145| loss: 0.01023 | train_rmsle: 0.0003  | train_mae: 0.05412 | train_rmse: 0.0724  | train_mse: 0.00524 | valid_rmsle: 0.00216 | valid_mae: 0.148   | valid_rmse: 0.19539 | valid_mse: 0.03818 |  0:02:46s\n",
      "epoch 146| loss: 0.01066 | train_rmsle: 0.00062 | train_mae: 0.08204 | train_rmse: 0.09923 | train_mse: 0.00985 | valid_rmsle: 0.00243 | valid_mae: 0.15942 | valid_rmse: 0.2046  | valid_mse: 0.04186 |  0:02:47s\n",
      "epoch 147| loss: 0.01188 | train_rmsle: 0.00037 | train_mae: 0.06285 | train_rmse: 0.08275 | train_mse: 0.00685 | valid_rmsle: 0.00223 | valid_mae: 0.151   | valid_rmse: 0.19972 | valid_mse: 0.03989 |  0:02:48s\n",
      "epoch 148| loss: 0.01352 | train_rmsle: 0.00065 | train_mae: 0.07684 | train_rmse: 0.09843 | train_mse: 0.00969 | valid_rmsle: 0.00244 | valid_mae: 0.15453 | valid_rmse: 0.20366 | valid_mse: 0.04148 |  0:02:49s\n",
      "epoch 149| loss: 0.01229 | train_rmsle: 0.00032 | train_mae: 0.05773 | train_rmse: 0.07821 | train_mse: 0.00612 | valid_rmsle: 0.00215 | valid_mae: 0.14567 | valid_rmse: 0.19636 | valid_mse: 0.03856 |  0:02:50s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 145 and best_valid_mse = 0.03818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.036993032429804146 RMSE: 0.19233572842767446 R2: 0.8362460995357879 MAE: 0.14363219333618701\n",
      "=====================================\n",
      "[80/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 7.65764 | train_rmsle: 0.18577 | train_mae: 1.46954 | train_rmse: 1.54441 | train_mse: 2.38519 | valid_rmsle: 0.18658 | valid_mae: 1.47413 | valid_rmse: 1.54865 | valid_mse: 2.39831 |  0:00:01s\n",
      "epoch 1  | loss: 1.11933 | train_rmsle: 0.07433 | train_mae: 0.97433 | train_rmse: 1.06538 | train_mse: 1.13502 | valid_rmsle: 0.07458 | valid_mae: 0.9764  | valid_rmse: 1.06878 | valid_mse: 1.14229 |  0:00:02s\n",
      "epoch 2  | loss: 0.49055 | train_rmsle: 0.05013 | train_mae: 0.80516 | train_rmse: 0.89925 | train_mse: 0.80866 | valid_rmsle: 0.05023 | valid_mae: 0.80579 | valid_rmse: 0.90228 | valid_mse: 0.81411 |  0:00:03s\n",
      "epoch 3  | loss: 0.35894 | train_rmsle: 0.0426  | train_mae: 0.74298 | train_rmse: 0.83671 | train_mse: 0.70009 | valid_rmsle: 0.04256 | valid_mae: 0.7421  | valid_rmse: 0.83878 | valid_mse: 0.70354 |  0:00:04s\n",
      "epoch 4  | loss: 0.28264 | train_rmsle: 0.03243 | train_mae: 0.64853 | train_rmse: 0.7391  | train_mse: 0.54627 | valid_rmsle: 0.03224 | valid_mae: 0.64775 | valid_rmse: 0.73985 | valid_mse: 0.54737 |  0:00:05s\n",
      "epoch 5  | loss: 0.25765 | train_rmsle: 0.02613 | train_mae: 0.5781  | train_rmse: 0.66747 | train_mse: 0.44551 | valid_rmsle: 0.02604 | valid_mae: 0.57947 | valid_rmse: 0.66939 | valid_mse: 0.44809 |  0:00:07s\n",
      "epoch 6  | loss: 0.23853 | train_rmsle: 0.0205  | train_mae: 0.50413 | train_rmse: 0.59204 | train_mse: 0.35052 | valid_rmsle: 0.02018 | valid_mae: 0.50425 | valid_rmse: 0.59109 | valid_mse: 0.34939 |  0:00:08s\n",
      "epoch 7  | loss: 0.22578 | train_rmsle: 0.01783 | train_mae: 0.46024 | train_rmse: 0.5502  | train_mse: 0.30272 | valid_rmsle: 0.0176  | valid_mae: 0.46132 | valid_rmse: 0.55053 | valid_mse: 0.30308 |  0:00:09s\n",
      "epoch 8  | loss: 0.21382 | train_rmsle: 0.01637 | train_mae: 0.43847 | train_rmse: 0.52629 | train_mse: 0.27698 | valid_rmsle: 0.01614 | valid_mae: 0.44113 | valid_rmse: 0.52697 | valid_mse: 0.2777  |  0:00:10s\n",
      "epoch 9  | loss: 0.20513 | train_rmsle: 0.01353 | train_mae: 0.37812 | train_rmse: 0.46953 | train_mse: 0.22046 | valid_rmsle: 0.01322 | valid_mae: 0.38074 | valid_rmse: 0.46924 | valid_mse: 0.22019 |  0:00:11s\n",
      "epoch 10 | loss: 0.19859 | train_rmsle: 0.01424 | train_mae: 0.39245 | train_rmse: 0.48446 | train_mse: 0.2347  | valid_rmsle: 0.01395 | valid_mae: 0.39547 | valid_rmse: 0.48423 | valid_mse: 0.23448 |  0:00:12s\n",
      "epoch 11 | loss: 0.18859 | train_rmsle: 0.01394 | train_mae: 0.39023 | train_rmse: 0.47977 | train_mse: 0.23018 | valid_rmsle: 0.01362 | valid_mae: 0.39406 | valid_rmse: 0.47898 | valid_mse: 0.22942 |  0:00:13s\n",
      "epoch 12 | loss: 0.18835 | train_rmsle: 0.01441 | train_mae: 0.40053 | train_rmse: 0.49008 | train_mse: 0.24018 | valid_rmsle: 0.01431 | valid_mae: 0.40608 | valid_rmse: 0.49263 | valid_mse: 0.24268 |  0:00:15s\n",
      "epoch 13 | loss: 0.18952 | train_rmsle: 0.01391 | train_mae: 0.39076 | train_rmse: 0.48055 | train_mse: 0.23093 | valid_rmsle: 0.0138  | valid_mae: 0.39518 | valid_rmse: 0.48315 | valid_mse: 0.23344 |  0:00:16s\n",
      "epoch 14 | loss: 0.17848 | train_rmsle: 0.01283 | train_mae: 0.36537 | train_rmse: 0.45637 | train_mse: 0.20827 | valid_rmsle: 0.01252 | valid_mae: 0.36786 | valid_rmse: 0.45554 | valid_mse: 0.20752 |  0:00:17s\n",
      "epoch 15 | loss: 0.17265 | train_rmsle: 0.01293 | train_mae: 0.37178 | train_rmse: 0.45971 | train_mse: 0.21133 | valid_rmsle: 0.01269 | valid_mae: 0.37537 | valid_rmse: 0.46023 | valid_mse: 0.21181 |  0:00:18s\n",
      "epoch 16 | loss: 0.1709  | train_rmsle: 0.0128  | train_mae: 0.36781 | train_rmse: 0.45721 | train_mse: 0.20904 | valid_rmsle: 0.01261 | valid_mae: 0.36947 | valid_rmse: 0.4582  | valid_mse: 0.20994 |  0:00:19s\n",
      "epoch 17 | loss: 0.16793 | train_rmsle: 0.01221 | train_mae: 0.35458 | train_rmse: 0.444   | train_mse: 0.19714 | valid_rmsle: 0.01231 | valid_mae: 0.36332 | valid_rmse: 0.4513  | valid_mse: 0.20367 |  0:00:20s\n",
      "epoch 18 | loss: 0.16423 | train_rmsle: 0.01222 | train_mae: 0.35668 | train_rmse: 0.44548 | train_mse: 0.19845 | valid_rmsle: 0.01238 | valid_mae: 0.36658 | valid_rmse: 0.45367 | valid_mse: 0.20582 |  0:00:21s\n",
      "epoch 19 | loss: 0.15921 | train_rmsle: 0.0119  | train_mae: 0.353   | train_rmse: 0.4401  | train_mse: 0.19368 | valid_rmsle: 0.01224 | valid_mae: 0.36586 | valid_rmse: 0.45213 | valid_mse: 0.20443 |  0:00:23s\n",
      "epoch 20 | loss: 0.15368 | train_rmsle: 0.0119  | train_mae: 0.35461 | train_rmse: 0.44133 | train_mse: 0.19478 | valid_rmsle: 0.0127  | valid_mae: 0.37467 | valid_rmse: 0.46165 | valid_mse: 0.21312 |  0:00:24s\n",
      "epoch 21 | loss: 0.14985 | train_rmsle: 0.01115 | train_mae: 0.33822 | train_rmse: 0.42471 | train_mse: 0.18038 | valid_rmsle: 0.01192 | valid_mae: 0.35723 | valid_rmse: 0.4451  | valid_mse: 0.19811 |  0:00:25s\n",
      "epoch 22 | loss: 0.14374 | train_rmsle: 0.01044 | train_mae: 0.32406 | train_rmse: 0.4099  | train_mse: 0.16802 | valid_rmsle: 0.01122 | valid_mae: 0.34368 | valid_rmse: 0.43084 | valid_mse: 0.18562 |  0:00:26s\n",
      "epoch 23 | loss: 0.14257 | train_rmsle: 0.0101  | train_mae: 0.32116 | train_rmse: 0.40487 | train_mse: 0.16392 | valid_rmsle: 0.01088 | valid_mae: 0.34222 | valid_rmse: 0.42638 | valid_mse: 0.1818  |  0:00:27s\n",
      "epoch 24 | loss: 0.13652 | train_rmsle: 0.00936 | train_mae: 0.30942 | train_rmse: 0.3899  | train_mse: 0.15202 | valid_rmsle: 0.01024 | valid_mae: 0.33325 | valid_rmse: 0.41416 | valid_mse: 0.17153 |  0:00:28s\n",
      "epoch 25 | loss: 0.13076 | train_rmsle: 0.00835 | train_mae: 0.28962 | train_rmse: 0.36735 | train_mse: 0.13495 | valid_rmsle: 0.00966 | valid_mae: 0.32132 | valid_rmse: 0.402   | valid_mse: 0.16161 |  0:00:29s\n",
      "epoch 26 | loss: 0.12387 | train_rmsle: 0.00747 | train_mae: 0.26944 | train_rmse: 0.34608 | train_mse: 0.11977 | valid_rmsle: 0.00863 | valid_mae: 0.30048 | valid_rmse: 0.37949 | valid_mse: 0.14401 |  0:00:30s\n",
      "epoch 27 | loss: 0.11404 | train_rmsle: 0.00723 | train_mae: 0.26311 | train_rmse: 0.33858 | train_mse: 0.11464 | valid_rmsle: 0.00858 | valid_mae: 0.30253 | valid_rmse: 0.37837 | valid_mse: 0.14316 |  0:00:32s\n",
      "epoch 28 | loss: 0.10162 | train_rmsle: 0.00689 | train_mae: 0.26142 | train_rmse: 0.33446 | train_mse: 0.11186 | valid_rmsle: 0.00758 | valid_mae: 0.28351 | valid_rmse: 0.35824 | valid_mse: 0.12834 |  0:00:33s\n",
      "epoch 29 | loss: 0.08675 | train_rmsle: 0.00537 | train_mae: 0.2282  | train_rmse: 0.29448 | train_mse: 0.08672 | valid_rmsle: 0.00661 | valid_mae: 0.25907 | valid_rmse: 0.33366 | valid_mse: 0.11133 |  0:00:34s\n",
      "epoch 30 | loss: 0.07725 | train_rmsle: 0.00459 | train_mae: 0.20829 | train_rmse: 0.26882 | train_mse: 0.07227 | valid_rmsle: 0.00566 | valid_mae: 0.23662 | valid_rmse: 0.30574 | valid_mse: 0.09347 |  0:00:35s\n",
      "epoch 31 | loss: 0.06906 | train_rmsle: 0.00434 | train_mae: 0.20569 | train_rmse: 0.26304 | train_mse: 0.06919 | valid_rmsle: 0.00566 | valid_mae: 0.24085 | valid_rmse: 0.30768 | valid_mse: 0.09467 |  0:00:36s\n",
      "epoch 32 | loss: 0.06483 | train_rmsle: 0.0038  | train_mae: 0.1915  | train_rmse: 0.24577 | train_mse: 0.0604  | valid_rmsle: 0.005   | valid_mae: 0.22898 | valid_rmse: 0.28909 | valid_mse: 0.08358 |  0:00:37s\n",
      "epoch 33 | loss: 0.06201 | train_rmsle: 0.00365 | train_mae: 0.18882 | train_rmse: 0.24085 | train_mse: 0.05801 | valid_rmsle: 0.00515 | valid_mae: 0.23111 | valid_rmse: 0.29382 | valid_mse: 0.08633 |  0:00:38s\n",
      "epoch 34 | loss: 0.05834 | train_rmsle: 0.00319 | train_mae: 0.17259 | train_rmse: 0.22476 | train_mse: 0.05052 | valid_rmsle: 0.00477 | valid_mae: 0.22306 | valid_rmse: 0.28312 | valid_mse: 0.08016 |  0:00:40s\n",
      "epoch 35 | loss: 0.05477 | train_rmsle: 0.00311 | train_mae: 0.17133 | train_rmse: 0.22326 | train_mse: 0.04985 | valid_rmsle: 0.0046  | valid_mae: 0.21424 | valid_rmse: 0.27874 | valid_mse: 0.07769 |  0:00:41s\n",
      "epoch 36 | loss: 0.05495 | train_rmsle: 0.00292 | train_mae: 0.16641 | train_rmse: 0.21623 | train_mse: 0.04675 | valid_rmsle: 0.00439 | valid_mae: 0.21184 | valid_rmse: 0.27157 | valid_mse: 0.07375 |  0:00:42s\n",
      "epoch 37 | loss: 0.05089 | train_rmsle: 0.00299 | train_mae: 0.17119 | train_rmse: 0.22001 | train_mse: 0.0484  | valid_rmsle: 0.00449 | valid_mae: 0.21424 | valid_rmse: 0.2753  | valid_mse: 0.07579 |  0:00:43s\n",
      "epoch 38 | loss: 0.05112 | train_rmsle: 0.0028  | train_mae: 0.16398 | train_rmse: 0.2123  | train_mse: 0.04507 | valid_rmsle: 0.0044  | valid_mae: 0.21133 | valid_rmse: 0.27239 | valid_mse: 0.0742  |  0:00:44s\n",
      "epoch 39 | loss: 0.04999 | train_rmsle: 0.00267 | train_mae: 0.161   | train_rmse: 0.20754 | train_mse: 0.04307 | valid_rmsle: 0.00448 | valid_mae: 0.21476 | valid_rmse: 0.2742  | valid_mse: 0.07519 |  0:00:45s\n",
      "epoch 40 | loss: 0.04783 | train_rmsle: 0.00247 | train_mae: 0.15326 | train_rmse: 0.19998 | train_mse: 0.03999 | valid_rmsle: 0.00449 | valid_mae: 0.21286 | valid_rmse: 0.27486 | valid_mse: 0.07555 |  0:00:46s\n",
      "epoch 41 | loss: 0.04853 | train_rmsle: 0.00247 | train_mae: 0.15124 | train_rmse: 0.19926 | train_mse: 0.03971 | valid_rmsle: 0.00456 | valid_mae: 0.21459 | valid_rmse: 0.27703 | valid_mse: 0.07675 |  0:00:48s\n",
      "epoch 42 | loss: 0.04655 | train_rmsle: 0.00243 | train_mae: 0.15397 | train_rmse: 0.20004 | train_mse: 0.04001 | valid_rmsle: 0.00467 | valid_mae: 0.22283 | valid_rmse: 0.28226 | valid_mse: 0.07967 |  0:00:49s\n",
      "epoch 43 | loss: 0.04311 | train_rmsle: 0.00225 | train_mae: 0.14567 | train_rmse: 0.19018 | train_mse: 0.03617 | valid_rmsle: 0.00433 | valid_mae: 0.21015 | valid_rmse: 0.27021 | valid_mse: 0.07302 |  0:00:50s\n",
      "epoch 44 | loss: 0.04331 | train_rmsle: 0.00231 | train_mae: 0.15169 | train_rmse: 0.19585 | train_mse: 0.03836 | valid_rmsle: 0.00449 | valid_mae: 0.21917 | valid_rmse: 0.27749 | valid_mse: 0.077   |  0:00:51s\n",
      "epoch 45 | loss: 0.04072 | train_rmsle: 0.00194 | train_mae: 0.13184 | train_rmse: 0.17595 | train_mse: 0.03096 | valid_rmsle: 0.00427 | valid_mae: 0.20597 | valid_rmse: 0.26862 | valid_mse: 0.07215 |  0:00:52s\n",
      "epoch 46 | loss: 0.03894 | train_rmsle: 0.00186 | train_mae: 0.12839 | train_rmse: 0.1724  | train_mse: 0.02972 | valid_rmsle: 0.00426 | valid_mae: 0.20579 | valid_rmse: 0.26775 | valid_mse: 0.07169 |  0:00:53s\n",
      "epoch 47 | loss: 0.04072 | train_rmsle: 0.00187 | train_mae: 0.13223 | train_rmse: 0.17541 | train_mse: 0.03077 | valid_rmsle: 0.00432 | valid_mae: 0.21007 | valid_rmse: 0.27205 | valid_mse: 0.07401 |  0:00:55s\n",
      "epoch 48 | loss: 0.04112 | train_rmsle: 0.00185 | train_mae: 0.1305  | train_rmse: 0.17389 | train_mse: 0.03024 | valid_rmsle: 0.00426 | valid_mae: 0.20844 | valid_rmse: 0.26995 | valid_mse: 0.07287 |  0:00:56s\n",
      "epoch 49 | loss: 0.04001 | train_rmsle: 0.00188 | train_mae: 0.13284 | train_rmse: 0.17631 | train_mse: 0.03108 | valid_rmsle: 0.00419 | valid_mae: 0.20644 | valid_rmse: 0.26748 | valid_mse: 0.07155 |  0:00:57s\n",
      "epoch 50 | loss: 0.03815 | train_rmsle: 0.00191 | train_mae: 0.13579 | train_rmse: 0.17862 | train_mse: 0.0319  | valid_rmsle: 0.0042  | valid_mae: 0.2106  | valid_rmse: 0.26894 | valid_mse: 0.07233 |  0:00:58s\n",
      "epoch 51 | loss: 0.03647 | train_rmsle: 0.00184 | train_mae: 0.13325 | train_rmse: 0.17584 | train_mse: 0.03092 | valid_rmsle: 0.00421 | valid_mae: 0.20892 | valid_rmse: 0.26852 | valid_mse: 0.0721  |  0:00:59s\n",
      "epoch 52 | loss: 0.03789 | train_rmsle: 0.00161 | train_mae: 0.12144 | train_rmse: 0.16248 | train_mse: 0.0264  | valid_rmsle: 0.00413 | valid_mae: 0.20335 | valid_rmse: 0.26539 | valid_mse: 0.07043 |  0:01:00s\n",
      "epoch 53 | loss: 0.03625 | train_rmsle: 0.00179 | train_mae: 0.1288  | train_rmse: 0.171   | train_mse: 0.02924 | valid_rmsle: 0.00433 | valid_mae: 0.20914 | valid_rmse: 0.27231 | valid_mse: 0.07415 |  0:01:01s\n",
      "epoch 54 | loss: 0.03719 | train_rmsle: 0.00189 | train_mae: 0.13711 | train_rmse: 0.17932 | train_mse: 0.03215 | valid_rmsle: 0.00422 | valid_mae: 0.21128 | valid_rmse: 0.27065 | valid_mse: 0.07325 |  0:01:02s\n",
      "epoch 55 | loss: 0.03607 | train_rmsle: 0.00159 | train_mae: 0.12198 | train_rmse: 0.16273 | train_mse: 0.02648 | valid_rmsle: 0.0039  | valid_mae: 0.20098 | valid_rmse: 0.25932 | valid_mse: 0.06725 |  0:01:04s\n",
      "epoch 56 | loss: 0.03311 | train_rmsle: 0.00167 | train_mae: 0.12745 | train_rmse: 0.16856 | train_mse: 0.02841 | valid_rmsle: 0.00387 | valid_mae: 0.20236 | valid_rmse: 0.259   | valid_mse: 0.06708 |  0:01:05s\n",
      "epoch 57 | loss: 0.03415 | train_rmsle: 0.00153 | train_mae: 0.12054 | train_rmse: 0.1603  | train_mse: 0.0257  | valid_rmsle: 0.00376 | valid_mae: 0.19819 | valid_rmse: 0.25507 | valid_mse: 0.06506 |  0:01:06s\n",
      "epoch 58 | loss: 0.03331 | train_rmsle: 0.00154 | train_mae: 0.12218 | train_rmse: 0.16114 | train_mse: 0.02596 | valid_rmsle: 0.00375 | valid_mae: 0.19981 | valid_rmse: 0.25522 | valid_mse: 0.06514 |  0:01:07s\n",
      "epoch 59 | loss: 0.03088 | train_rmsle: 0.00141 | train_mae: 0.11481 | train_rmse: 0.15343 | train_mse: 0.02354 | valid_rmsle: 0.0036  | valid_mae: 0.19513 | valid_rmse: 0.24933 | valid_mse: 0.06216 |  0:01:08s\n",
      "epoch 60 | loss: 0.03111 | train_rmsle: 0.00148 | train_mae: 0.11955 | train_rmse: 0.15819 | train_mse: 0.02502 | valid_rmsle: 0.00365 | valid_mae: 0.19633 | valid_rmse: 0.25195 | valid_mse: 0.06348 |  0:01:09s\n",
      "epoch 61 | loss: 0.03085 | train_rmsle: 0.0015  | train_mae: 0.11874 | train_rmse: 0.15611 | train_mse: 0.02437 | valid_rmsle: 0.00374 | valid_mae: 0.19809 | valid_rmse: 0.25293 | valid_mse: 0.06397 |  0:01:10s\n",
      "epoch 62 | loss: 0.03128 | train_rmsle: 0.00133 | train_mae: 0.11033 | train_rmse: 0.149   | train_mse: 0.0222  | valid_rmsle: 0.00353 | valid_mae: 0.19039 | valid_rmse: 0.24772 | valid_mse: 0.06136 |  0:01:12s\n",
      "epoch 63 | loss: 0.02985 | train_rmsle: 0.00129 | train_mae: 0.10623 | train_rmse: 0.14386 | train_mse: 0.0207  | valid_rmsle: 0.00357 | valid_mae: 0.19053 | valid_rmse: 0.24747 | valid_mse: 0.06124 |  0:01:13s\n",
      "epoch 64 | loss: 0.03022 | train_rmsle: 0.00119 | train_mae: 0.10394 | train_rmse: 0.14116 | train_mse: 0.01993 | valid_rmsle: 0.00336 | valid_mae: 0.18602 | valid_rmse: 0.24087 | valid_mse: 0.05802 |  0:01:14s\n",
      "epoch 65 | loss: 0.02785 | train_rmsle: 0.00115 | train_mae: 0.10198 | train_rmse: 0.13887 | train_mse: 0.01928 | valid_rmsle: 0.00341 | valid_mae: 0.18754 | valid_rmse: 0.24258 | valid_mse: 0.05885 |  0:01:15s\n",
      "epoch 66 | loss: 0.02641 | train_rmsle: 0.00113 | train_mae: 0.09993 | train_rmse: 0.13703 | train_mse: 0.01878 | valid_rmsle: 0.00342 | valid_mae: 0.18574 | valid_rmse: 0.24292 | valid_mse: 0.05901 |  0:01:16s\n",
      "epoch 67 | loss: 0.02671 | train_rmsle: 0.0011  | train_mae: 0.09989 | train_rmse: 0.13652 | train_mse: 0.01864 | valid_rmsle: 0.00348 | valid_mae: 0.18728 | valid_rmse: 0.24471 | valid_mse: 0.05988 |  0:01:17s\n",
      "epoch 68 | loss: 0.02618 | train_rmsle: 0.0011  | train_mae: 0.09962 | train_rmse: 0.1349  | train_mse: 0.0182  | valid_rmsle: 0.00358 | valid_mae: 0.19085 | valid_rmse: 0.24846 | valid_mse: 0.06173 |  0:01:18s\n",
      "epoch 69 | loss: 0.02538 | train_rmsle: 0.00129 | train_mae: 0.11074 | train_rmse: 0.14534 | train_mse: 0.02112 | valid_rmsle: 0.00365 | valid_mae: 0.1937  | valid_rmse: 0.24971 | valid_mse: 0.06236 |  0:01:19s\n",
      "epoch 70 | loss: 0.02697 | train_rmsle: 0.001   | train_mae: 0.09502 | train_rmse: 0.1301  | train_mse: 0.01693 | valid_rmsle: 0.00324 | valid_mae: 0.18159 | valid_rmse: 0.23643 | valid_mse: 0.0559  |  0:01:20s\n",
      "epoch 71 | loss: 0.02508 | train_rmsle: 0.00096 | train_mae: 0.09473 | train_rmse: 0.12917 | train_mse: 0.01669 | valid_rmsle: 0.0033  | valid_mae: 0.18195 | valid_rmse: 0.23769 | valid_mse: 0.0565  |  0:01:22s\n",
      "epoch 72 | loss: 0.02569 | train_rmsle: 0.00108 | train_mae: 0.10184 | train_rmse: 0.13559 | train_mse: 0.01838 | valid_rmsle: 0.00343 | valid_mae: 0.18605 | valid_rmse: 0.24337 | valid_mse: 0.05923 |  0:01:23s\n",
      "epoch 73 | loss: 0.02511 | train_rmsle: 0.00096 | train_mae: 0.09588 | train_rmse: 0.12935 | train_mse: 0.01673 | valid_rmsle: 0.00329 | valid_mae: 0.18181 | valid_rmse: 0.23923 | valid_mse: 0.05723 |  0:01:24s\n",
      "epoch 74 | loss: 0.02212 | train_rmsle: 0.00085 | train_mae: 0.08735 | train_rmse: 0.12068 | train_mse: 0.01456 | valid_rmsle: 0.00316 | valid_mae: 0.17694 | valid_rmse: 0.23358 | valid_mse: 0.05456 |  0:01:25s\n",
      "epoch 75 | loss: 0.02215 | train_rmsle: 0.00081 | train_mae: 0.08651 | train_rmse: 0.11954 | train_mse: 0.01429 | valid_rmsle: 0.00313 | valid_mae: 0.17649 | valid_rmse: 0.23276 | valid_mse: 0.05418 |  0:01:26s\n",
      "epoch 76 | loss: 0.02118 | train_rmsle: 0.00087 | train_mae: 0.09258 | train_rmse: 0.12453 | train_mse: 0.01551 | valid_rmsle: 0.00322 | valid_mae: 0.18199 | valid_rmse: 0.23639 | valid_mse: 0.05588 |  0:01:27s\n",
      "epoch 77 | loss: 0.02209 | train_rmsle: 0.00082 | train_mae: 0.08858 | train_rmse: 0.12102 | train_mse: 0.01465 | valid_rmsle: 0.00322 | valid_mae: 0.18016 | valid_rmse: 0.23579 | valid_mse: 0.0556  |  0:01:28s\n",
      "epoch 78 | loss: 0.02367 | train_rmsle: 0.00129 | train_mae: 0.12062 | train_rmse: 0.14984 | train_mse: 0.02245 | valid_rmsle: 0.00368 | valid_mae: 0.19614 | valid_rmse: 0.25064 | valid_mse: 0.06282 |  0:01:29s\n",
      "epoch 79 | loss: 0.02204 | train_rmsle: 0.00081 | train_mae: 0.0874  | train_rmse: 0.12004 | train_mse: 0.01441 | valid_rmsle: 0.00314 | valid_mae: 0.17691 | valid_rmse: 0.23346 | valid_mse: 0.0545  |  0:01:30s\n",
      "epoch 80 | loss: 0.02187 | train_rmsle: 0.001   | train_mae: 0.09619 | train_rmse: 0.12733 | train_mse: 0.01621 | valid_rmsle: 0.00333 | valid_mae: 0.18208 | valid_rmse: 0.23645 | valid_mse: 0.05591 |  0:01:31s\n",
      "epoch 81 | loss: 0.0228  | train_rmsle: 0.00078 | train_mae: 0.08704 | train_rmse: 0.11857 | train_mse: 0.01406 | valid_rmsle: 0.00308 | valid_mae: 0.17675 | valid_rmse: 0.23169 | valid_mse: 0.05368 |  0:01:32s\n",
      "epoch 82 | loss: 0.02123 | train_rmsle: 0.00088 | train_mae: 0.09508 | train_rmse: 0.1262  | train_mse: 0.01593 | valid_rmsle: 0.00297 | valid_mae: 0.17347 | valid_rmse: 0.22773 | valid_mse: 0.05186 |  0:01:34s\n",
      "epoch 83 | loss: 0.0217  | train_rmsle: 0.00071 | train_mae: 0.08104 | train_rmse: 0.11332 | train_mse: 0.01284 | valid_rmsle: 0.00288 | valid_mae: 0.16883 | valid_rmse: 0.22391 | valid_mse: 0.05014 |  0:01:35s\n",
      "epoch 84 | loss: 0.0223  | train_rmsle: 0.00117 | train_mae: 0.10793 | train_rmse: 0.13761 | train_mse: 0.01894 | valid_rmsle: 0.00336 | valid_mae: 0.18369 | valid_rmse: 0.23803 | valid_mse: 0.05666 |  0:01:36s\n",
      "epoch 85 | loss: 0.021   | train_rmsle: 0.00092 | train_mae: 0.09425 | train_rmse: 0.12377 | train_mse: 0.01532 | valid_rmsle: 0.00309 | valid_mae: 0.17403 | valid_rmse: 0.22962 | valid_mse: 0.05272 |  0:01:37s\n",
      "epoch 86 | loss: 0.01906 | train_rmsle: 0.0007  | train_mae: 0.08067 | train_rmse: 0.11161 | train_mse: 0.01246 | valid_rmsle: 0.00282 | valid_mae: 0.16697 | valid_rmse: 0.22134 | valid_mse: 0.04899 |  0:01:38s\n",
      "epoch 87 | loss: 0.02192 | train_rmsle: 0.00066 | train_mae: 0.07691 | train_rmse: 0.10757 | train_mse: 0.01157 | valid_rmsle: 0.00291 | valid_mae: 0.16899 | valid_rmse: 0.22494 | valid_mse: 0.0506  |  0:01:39s\n",
      "epoch 88 | loss: 0.01983 | train_rmsle: 0.0007  | train_mae: 0.07865 | train_rmse: 0.10984 | train_mse: 0.01207 | valid_rmsle: 0.00287 | valid_mae: 0.16988 | valid_rmse: 0.22357 | valid_mse: 0.04998 |  0:01:40s\n",
      "epoch 89 | loss: 0.02024 | train_rmsle: 0.00061 | train_mae: 0.07424 | train_rmse: 0.1043  | train_mse: 0.01088 | valid_rmsle: 0.00281 | valid_mae: 0.16717 | valid_rmse: 0.22239 | valid_mse: 0.04946 |  0:01:41s\n",
      "epoch 90 | loss: 0.01894 | train_rmsle: 0.00065 | train_mae: 0.07683 | train_rmse: 0.10683 | train_mse: 0.01141 | valid_rmsle: 0.00282 | valid_mae: 0.16715 | valid_rmse: 0.2223  | valid_mse: 0.04942 |  0:01:42s\n",
      "epoch 91 | loss: 0.01938 | train_rmsle: 0.00065 | train_mae: 0.0766  | train_rmse: 0.1058  | train_mse: 0.01119 | valid_rmsle: 0.00295 | valid_mae: 0.16935 | valid_rmse: 0.22782 | valid_mse: 0.0519  |  0:01:43s\n",
      "epoch 92 | loss: 0.01781 | train_rmsle: 0.00059 | train_mae: 0.0716  | train_rmse: 0.10175 | train_mse: 0.01035 | valid_rmsle: 0.00288 | valid_mae: 0.16796 | valid_rmse: 0.22548 | valid_mse: 0.05084 |  0:01:44s\n",
      "epoch 93 | loss: 0.01969 | train_rmsle: 0.00067 | train_mae: 0.08052 | train_rmse: 0.10901 | train_mse: 0.01188 | valid_rmsle: 0.00287 | valid_mae: 0.16815 | valid_rmse: 0.22405 | valid_mse: 0.0502  |  0:01:46s\n",
      "epoch 94 | loss: 0.01815 | train_rmsle: 0.00056 | train_mae: 0.0701  | train_rmse: 0.09915 | train_mse: 0.00983 | valid_rmsle: 0.00273 | valid_mae: 0.16455 | valid_rmse: 0.21884 | valid_mse: 0.04789 |  0:01:47s\n",
      "epoch 95 | loss: 0.01681 | train_rmsle: 0.00075 | train_mae: 0.08937 | train_rmse: 0.11777 | train_mse: 0.01387 | valid_rmsle: 0.00293 | valid_mae: 0.17464 | valid_rmse: 0.22766 | valid_mse: 0.05183 |  0:01:48s\n",
      "epoch 96 | loss: 0.01717 | train_rmsle: 0.00053 | train_mae: 0.0684  | train_rmse: 0.09713 | train_mse: 0.00943 | valid_rmsle: 0.00281 | valid_mae: 0.16633 | valid_rmse: 0.22237 | valid_mse: 0.04945 |  0:01:49s\n",
      "epoch 97 | loss: 0.01683 | train_rmsle: 0.0005  | train_mae: 0.06616 | train_rmse: 0.09383 | train_mse: 0.0088  | valid_rmsle: 0.00283 | valid_mae: 0.16569 | valid_rmse: 0.22219 | valid_mse: 0.04937 |  0:01:50s\n",
      "epoch 98 | loss: 0.01705 | train_rmsle: 0.00053 | train_mae: 0.06823 | train_rmse: 0.09669 | train_mse: 0.00935 | valid_rmsle: 0.00281 | valid_mae: 0.16623 | valid_rmse: 0.22153 | valid_mse: 0.04907 |  0:01:51s\n",
      "epoch 99 | loss: 0.01661 | train_rmsle: 0.00049 | train_mae: 0.06609 | train_rmse: 0.09423 | train_mse: 0.00888 | valid_rmsle: 0.00281 | valid_mae: 0.16542 | valid_rmse: 0.22247 | valid_mse: 0.04949 |  0:01:52s\n",
      "epoch 100| loss: 0.01781 | train_rmsle: 0.00063 | train_mae: 0.07864 | train_rmse: 0.10499 | train_mse: 0.01102 | valid_rmsle: 0.00284 | valid_mae: 0.1679  | valid_rmse: 0.22326 | valid_mse: 0.04985 |  0:01:53s\n",
      "epoch 101| loss: 0.01654 | train_rmsle: 0.00055 | train_mae: 0.06941 | train_rmse: 0.0969  | train_mse: 0.00939 | valid_rmsle: 0.00267 | valid_mae: 0.16348 | valid_rmse: 0.21568 | valid_mse: 0.04652 |  0:01:54s\n",
      "epoch 102| loss: 0.01756 | train_rmsle: 0.00051 | train_mae: 0.06904 | train_rmse: 0.0954  | train_mse: 0.0091  | valid_rmsle: 0.0027  | valid_mae: 0.16366 | valid_rmse: 0.21848 | valid_mse: 0.04773 |  0:01:55s\n",
      "epoch 103| loss: 0.0163  | train_rmsle: 0.00044 | train_mae: 0.06294 | train_rmse: 0.0888  | train_mse: 0.00789 | valid_rmsle: 0.00272 | valid_mae: 0.16421 | valid_rmse: 0.21877 | valid_mse: 0.04786 |  0:01:56s\n",
      "epoch 104| loss: 0.01612 | train_rmsle: 0.0005  | train_mae: 0.06689 | train_rmse: 0.09235 | train_mse: 0.00853 | valid_rmsle: 0.00267 | valid_mae: 0.16041 | valid_rmse: 0.21523 | valid_mse: 0.04633 |  0:01:57s\n",
      "epoch 105| loss: 0.0168  | train_rmsle: 0.00049 | train_mae: 0.06762 | train_rmse: 0.09394 | train_mse: 0.00882 | valid_rmsle: 0.00262 | valid_mae: 0.15948 | valid_rmse: 0.21479 | valid_mse: 0.04614 |  0:01:59s\n",
      "epoch 106| loss: 0.01528 | train_rmsle: 0.00052 | train_mae: 0.07024 | train_rmse: 0.09693 | train_mse: 0.0094  | valid_rmsle: 0.00264 | valid_mae: 0.16017 | valid_rmse: 0.21605 | valid_mse: 0.04668 |  0:02:00s\n",
      "epoch 107| loss: 0.01727 | train_rmsle: 0.00058 | train_mae: 0.07772 | train_rmse: 0.10324 | train_mse: 0.01066 | valid_rmsle: 0.00271 | valid_mae: 0.16591 | valid_rmse: 0.21855 | valid_mse: 0.04776 |  0:02:01s\n",
      "epoch 108| loss: 0.01583 | train_rmsle: 0.00057 | train_mae: 0.07122 | train_rmse: 0.09674 | train_mse: 0.00936 | valid_rmsle: 0.00271 | valid_mae: 0.1612  | valid_rmse: 0.21706 | valid_mse: 0.04712 |  0:02:02s\n",
      "epoch 109| loss: 0.01553 | train_rmsle: 0.00055 | train_mae: 0.07026 | train_rmse: 0.09504 | train_mse: 0.00903 | valid_rmsle: 0.0026  | valid_mae: 0.16143 | valid_rmse: 0.21321 | valid_mse: 0.04546 |  0:02:03s\n",
      "epoch 110| loss: 0.01578 | train_rmsle: 0.00043 | train_mae: 0.06039 | train_rmse: 0.08592 | train_mse: 0.00738 | valid_rmsle: 0.00254 | valid_mae: 0.15887 | valid_rmse: 0.21157 | valid_mse: 0.04476 |  0:02:04s\n",
      "epoch 111| loss: 0.01611 | train_rmsle: 0.00078 | train_mae: 0.0969  | train_rmse: 0.1218  | train_mse: 0.01483 | valid_rmsle: 0.00283 | valid_mae: 0.17001 | valid_rmse: 0.22587 | valid_mse: 0.05102 |  0:02:05s\n",
      "epoch 112| loss: 0.01761 | train_rmsle: 0.00059 | train_mae: 0.07063 | train_rmse: 0.09639 | train_mse: 0.00929 | valid_rmsle: 0.00261 | valid_mae: 0.16153 | valid_rmse: 0.21215 | valid_mse: 0.04501 |  0:02:06s\n",
      "epoch 113| loss: 0.01556 | train_rmsle: 0.00043 | train_mae: 0.06323 | train_rmse: 0.08869 | train_mse: 0.00787 | valid_rmsle: 0.00246 | valid_mae: 0.15771 | valid_rmse: 0.20809 | valid_mse: 0.0433  |  0:02:07s\n",
      "epoch 114| loss: 0.0146  | train_rmsle: 0.00042 | train_mae: 0.06199 | train_rmse: 0.08626 | train_mse: 0.00744 | valid_rmsle: 0.00249 | valid_mae: 0.15697 | valid_rmse: 0.20948 | valid_mse: 0.04388 |  0:02:08s\n",
      "epoch 115| loss: 0.0142  | train_rmsle: 0.00042 | train_mae: 0.06095 | train_rmse: 0.08479 | train_mse: 0.00719 | valid_rmsle: 0.00251 | valid_mae: 0.15757 | valid_rmse: 0.21037 | valid_mse: 0.04425 |  0:02:10s\n",
      "epoch 116| loss: 0.01711 | train_rmsle: 0.00046 | train_mae: 0.06597 | train_rmse: 0.09111 | train_mse: 0.0083  | valid_rmsle: 0.00251 | valid_mae: 0.15838 | valid_rmse: 0.20986 | valid_mse: 0.04404 |  0:02:11s\n",
      "epoch 117| loss: 0.0151  | train_rmsle: 0.00039 | train_mae: 0.0594  | train_rmse: 0.08399 | train_mse: 0.00705 | valid_rmsle: 0.00251 | valid_mae: 0.15655 | valid_rmse: 0.20951 | valid_mse: 0.04389 |  0:02:12s\n",
      "epoch 118| loss: 0.01442 | train_rmsle: 0.00057 | train_mae: 0.07745 | train_rmse: 0.0987  | train_mse: 0.00974 | valid_rmsle: 0.00274 | valid_mae: 0.16765 | valid_rmse: 0.2181  | valid_mse: 0.04757 |  0:02:13s\n",
      "epoch 119| loss: 0.01437 | train_rmsle: 0.00046 | train_mae: 0.0663  | train_rmse: 0.08859 | train_mse: 0.00785 | valid_rmsle: 0.0025  | valid_mae: 0.15747 | valid_rmse: 0.21014 | valid_mse: 0.04416 |  0:02:14s\n",
      "epoch 120| loss: 0.01834 | train_rmsle: 0.00058 | train_mae: 0.07289 | train_rmse: 0.09565 | train_mse: 0.00915 | valid_rmsle: 0.00272 | valid_mae: 0.16543 | valid_rmse: 0.21636 | valid_mse: 0.04681 |  0:02:15s\n",
      "epoch 121| loss: 0.01276 | train_rmsle: 0.00035 | train_mae: 0.0553  | train_rmse: 0.07838 | train_mse: 0.00614 | valid_rmsle: 0.00241 | valid_mae: 0.15324 | valid_rmse: 0.20677 | valid_mse: 0.04275 |  0:02:16s\n",
      "epoch 122| loss: 0.01532 | train_rmsle: 0.00047 | train_mae: 0.06654 | train_rmse: 0.08847 | train_mse: 0.00783 | valid_rmsle: 0.00255 | valid_mae: 0.15622 | valid_rmse: 0.21179 | valid_mse: 0.04486 |  0:02:17s\n",
      "epoch 123| loss: 0.01412 | train_rmsle: 0.00037 | train_mae: 0.05921 | train_rmse: 0.08198 | train_mse: 0.00672 | valid_rmsle: 0.0025  | valid_mae: 0.15643 | valid_rmse: 0.21035 | valid_mse: 0.04425 |  0:02:18s\n",
      "epoch 124| loss: 0.01356 | train_rmsle: 0.00051 | train_mae: 0.07527 | train_rmse: 0.09697 | train_mse: 0.0094  | valid_rmsle: 0.00256 | valid_mae: 0.1622  | valid_rmse: 0.2133  | valid_mse: 0.0455  |  0:02:19s\n",
      "epoch 125| loss: 0.0154  | train_rmsle: 0.00056 | train_mae: 0.0771  | train_rmse: 0.10087 | train_mse: 0.01017 | valid_rmsle: 0.00266 | valid_mae: 0.16534 | valid_rmse: 0.21735 | valid_mse: 0.04724 |  0:02:20s\n",
      "epoch 126| loss: 0.0149  | train_rmsle: 0.00034 | train_mae: 0.05653 | train_rmse: 0.07846 | train_mse: 0.00616 | valid_rmsle: 0.00243 | valid_mae: 0.15509 | valid_rmse: 0.20762 | valid_mse: 0.0431  |  0:02:21s\n",
      "epoch 127| loss: 0.01181 | train_rmsle: 0.00039 | train_mae: 0.05784 | train_rmse: 0.08085 | train_mse: 0.00654 | valid_rmsle: 0.00237 | valid_mae: 0.15321 | valid_rmse: 0.20434 | valid_mse: 0.04176 |  0:02:23s\n",
      "epoch 128| loss: 0.01273 | train_rmsle: 0.00031 | train_mae: 0.05246 | train_rmse: 0.07436 | train_mse: 0.00553 | valid_rmsle: 0.00231 | valid_mae: 0.15162 | valid_rmse: 0.20293 | valid_mse: 0.04118 |  0:02:24s\n",
      "epoch 129| loss: 0.01285 | train_rmsle: 0.00084 | train_mae: 0.09846 | train_rmse: 0.11661 | train_mse: 0.0136  | valid_rmsle: 0.00286 | valid_mae: 0.16896 | valid_rmse: 0.22328 | valid_mse: 0.04985 |  0:02:25s\n",
      "epoch 130| loss: 0.01475 | train_rmsle: 0.00031 | train_mae: 0.05331 | train_rmse: 0.0745  | train_mse: 0.00555 | valid_rmsle: 0.0024  | valid_mae: 0.1544  | valid_rmse: 0.20717 | valid_mse: 0.04292 |  0:02:26s\n",
      "epoch 131| loss: 0.0127  | train_rmsle: 0.00031 | train_mae: 0.05289 | train_rmse: 0.0733  | train_mse: 0.00537 | valid_rmsle: 0.00238 | valid_mae: 0.15331 | valid_rmse: 0.20471 | valid_mse: 0.0419  |  0:02:27s\n",
      "epoch 132| loss: 0.01361 | train_rmsle: 0.00028 | train_mae: 0.05101 | train_rmse: 0.07168 | train_mse: 0.00514 | valid_rmsle: 0.00233 | valid_mae: 0.15244 | valid_rmse: 0.20418 | valid_mse: 0.04169 |  0:02:28s\n",
      "epoch 133| loss: 0.01492 | train_rmsle: 0.00033 | train_mae: 0.05316 | train_rmse: 0.07417 | train_mse: 0.0055  | valid_rmsle: 0.00224 | valid_mae: 0.14843 | valid_rmse: 0.19926 | valid_mse: 0.0397  |  0:02:29s\n",
      "epoch 134| loss: 0.01312 | train_rmsle: 0.00045 | train_mae: 0.07044 | train_rmse: 0.09127 | train_mse: 0.00833 | valid_rmsle: 0.00237 | valid_mae: 0.15359 | valid_rmse: 0.20661 | valid_mse: 0.04269 |  0:02:30s\n",
      "epoch 135| loss: 0.01406 | train_rmsle: 0.00032 | train_mae: 0.05515 | train_rmse: 0.07466 | train_mse: 0.00557 | valid_rmsle: 0.0022  | valid_mae: 0.15072 | valid_rmse: 0.19814 | valid_mse: 0.03926 |  0:02:31s\n",
      "epoch 136| loss: 0.01213 | train_rmsle: 0.00031 | train_mae: 0.05635 | train_rmse: 0.07679 | train_mse: 0.0059  | valid_rmsle: 0.00221 | valid_mae: 0.15122 | valid_rmse: 0.19932 | valid_mse: 0.03973 |  0:02:32s\n",
      "epoch 137| loss: 0.01216 | train_rmsle: 0.00026 | train_mae: 0.04904 | train_rmse: 0.06964 | train_mse: 0.00485 | valid_rmsle: 0.0022  | valid_mae: 0.14777 | valid_rmse: 0.19811 | valid_mse: 0.03925 |  0:02:34s\n",
      "epoch 138| loss: 0.01305 | train_rmsle: 0.00036 | train_mae: 0.05952 | train_rmse: 0.08123 | train_mse: 0.0066  | valid_rmsle: 0.0023  | valid_mae: 0.14887 | valid_rmse: 0.20229 | valid_mse: 0.04092 |  0:02:35s\n",
      "epoch 139| loss: 0.01378 | train_rmsle: 0.00066 | train_mae: 0.0816  | train_rmse: 0.10228 | train_mse: 0.01046 | valid_rmsle: 0.0026  | valid_mae: 0.15772 | valid_rmse: 0.21317 | valid_mse: 0.04544 |  0:02:36s\n",
      "epoch 140| loss: 0.01437 | train_rmsle: 0.00026 | train_mae: 0.04946 | train_rmse: 0.06995 | train_mse: 0.00489 | valid_rmsle: 0.00222 | valid_mae: 0.14774 | valid_rmse: 0.19944 | valid_mse: 0.03977 |  0:02:37s\n",
      "epoch 141| loss: 0.01161 | train_rmsle: 0.00028 | train_mae: 0.05141 | train_rmse: 0.07093 | train_mse: 0.00503 | valid_rmsle: 0.00227 | valid_mae: 0.14692 | valid_rmse: 0.20201 | valid_mse: 0.04081 |  0:02:38s\n",
      "epoch 142| loss: 0.0115  | train_rmsle: 0.00031 | train_mae: 0.05263 | train_rmse: 0.07319 | train_mse: 0.00536 | valid_rmsle: 0.00221 | valid_mae: 0.14551 | valid_rmse: 0.19778 | valid_mse: 0.03912 |  0:02:39s\n",
      "epoch 143| loss: 0.01181 | train_rmsle: 0.00033 | train_mae: 0.05738 | train_rmse: 0.0765  | train_mse: 0.00585 | valid_rmsle: 0.00221 | valid_mae: 0.14935 | valid_rmse: 0.1978  | valid_mse: 0.03913 |  0:02:40s\n",
      "epoch 144| loss: 0.01157 | train_rmsle: 0.00036 | train_mae: 0.05916 | train_rmse: 0.07736 | train_mse: 0.00598 | valid_rmsle: 0.00224 | valid_mae: 0.14711 | valid_rmse: 0.19758 | valid_mse: 0.03904 |  0:02:41s\n",
      "epoch 145| loss: 0.01023 | train_rmsle: 0.0003  | train_mae: 0.05412 | train_rmse: 0.0724  | train_mse: 0.00524 | valid_rmsle: 0.00216 | valid_mae: 0.148   | valid_rmse: 0.19539 | valid_mse: 0.03818 |  0:02:42s\n",
      "epoch 146| loss: 0.01066 | train_rmsle: 0.00062 | train_mae: 0.08204 | train_rmse: 0.09923 | train_mse: 0.00985 | valid_rmsle: 0.00243 | valid_mae: 0.15942 | valid_rmse: 0.2046  | valid_mse: 0.04186 |  0:02:43s\n",
      "epoch 147| loss: 0.01188 | train_rmsle: 0.00037 | train_mae: 0.06285 | train_rmse: 0.08275 | train_mse: 0.00685 | valid_rmsle: 0.00223 | valid_mae: 0.151   | valid_rmse: 0.19972 | valid_mse: 0.03989 |  0:02:44s\n",
      "epoch 148| loss: 0.01352 | train_rmsle: 0.00065 | train_mae: 0.07684 | train_rmse: 0.09843 | train_mse: 0.00969 | valid_rmsle: 0.00244 | valid_mae: 0.15453 | valid_rmse: 0.20366 | valid_mse: 0.04148 |  0:02:46s\n",
      "epoch 149| loss: 0.01229 | train_rmsle: 0.00032 | train_mae: 0.05773 | train_rmse: 0.07821 | train_mse: 0.00612 | valid_rmsle: 0.00215 | valid_mae: 0.14567 | valid_rmse: 0.19636 | valid_mse: 0.03856 |  0:02:47s\n",
      "epoch 150| loss: 0.01205 | train_rmsle: 0.00027 | train_mae: 0.05063 | train_rmse: 0.07021 | train_mse: 0.00493 | valid_rmsle: 0.00204 | valid_mae: 0.14228 | valid_rmse: 0.19146 | valid_mse: 0.03666 |  0:02:48s\n",
      "epoch 151| loss: 0.01164 | train_rmsle: 0.00029 | train_mae: 0.05134 | train_rmse: 0.07002 | train_mse: 0.0049  | valid_rmsle: 0.00204 | valid_mae: 0.14029 | valid_rmse: 0.18979 | valid_mse: 0.03602 |  0:02:49s\n",
      "epoch 152| loss: 0.01083 | train_rmsle: 0.00025 | train_mae: 0.0474  | train_rmse: 0.0668  | train_mse: 0.00446 | valid_rmsle: 0.00202 | valid_mae: 0.13951 | valid_rmse: 0.19    | valid_mse: 0.0361  |  0:02:50s\n",
      "epoch 153| loss: 0.01147 | train_rmsle: 0.00061 | train_mae: 0.08369 | train_rmse: 0.10019 | train_mse: 0.01004 | valid_rmsle: 0.00233 | valid_mae: 0.15606 | valid_rmse: 0.20264 | valid_mse: 0.04106 |  0:02:51s\n",
      "epoch 154| loss: 0.01257 | train_rmsle: 0.00029 | train_mae: 0.05238 | train_rmse: 0.07018 | train_mse: 0.00492 | valid_rmsle: 0.00199 | valid_mae: 0.13699 | valid_rmse: 0.18713 | valid_mse: 0.03502 |  0:02:52s\n",
      "epoch 155| loss: 0.01086 | train_rmsle: 0.00067 | train_mae: 0.07996 | train_rmse: 0.09905 | train_mse: 0.00981 | valid_rmsle: 0.00239 | valid_mae: 0.15599 | valid_rmse: 0.20172 | valid_mse: 0.04069 |  0:02:53s\n",
      "epoch 156| loss: 0.01239 | train_rmsle: 0.00024 | train_mae: 0.04727 | train_rmse: 0.06742 | train_mse: 0.00455 | valid_rmsle: 0.00201 | valid_mae: 0.14048 | valid_rmse: 0.18856 | valid_mse: 0.03555 |  0:02:54s\n",
      "epoch 157| loss: 0.01223 | train_rmsle: 0.00033 | train_mae: 0.05156 | train_rmse: 0.07168 | train_mse: 0.00514 | valid_rmsle: 0.00209 | valid_mae: 0.14071 | valid_rmse: 0.19081 | valid_mse: 0.03641 |  0:02:55s\n",
      "epoch 158| loss: 0.01046 | train_rmsle: 0.00037 | train_mae: 0.05985 | train_rmse: 0.07827 | train_mse: 0.00613 | valid_rmsle: 0.00208 | valid_mae: 0.1419  | valid_rmse: 0.19135 | valid_mse: 0.03661 |  0:02:56s\n",
      "epoch 159| loss: 0.01202 | train_rmsle: 0.00025 | train_mae: 0.04789 | train_rmse: 0.0672  | train_mse: 0.00452 | valid_rmsle: 0.00192 | valid_mae: 0.13768 | valid_rmse: 0.18483 | valid_mse: 0.03416 |  0:02:58s\n",
      "epoch 160| loss: 0.01206 | train_rmsle: 0.00061 | train_mae: 0.07387 | train_rmse: 0.09417 | train_mse: 0.00887 | valid_rmsle: 0.00219 | valid_mae: 0.14899 | valid_rmse: 0.19422 | valid_mse: 0.03772 |  0:02:59s\n",
      "epoch 161| loss: 0.01143 | train_rmsle: 0.00021 | train_mae: 0.04287 | train_rmse: 0.06265 | train_mse: 0.00392 | valid_rmsle: 0.00184 | valid_mae: 0.135   | valid_rmse: 0.18137 | valid_mse: 0.03289 |  0:03:00s\n",
      "epoch 162| loss: 0.01106 | train_rmsle: 0.00029 | train_mae: 0.04876 | train_rmse: 0.06735 | train_mse: 0.00454 | valid_rmsle: 0.00195 | valid_mae: 0.13915 | valid_rmse: 0.18501 | valid_mse: 0.03423 |  0:03:01s\n",
      "epoch 163| loss: 0.01243 | train_rmsle: 0.00033 | train_mae: 0.05918 | train_rmse: 0.07793 | train_mse: 0.00607 | valid_rmsle: 0.00199 | valid_mae: 0.1437  | valid_rmse: 0.18923 | valid_mse: 0.03581 |  0:03:02s\n",
      "epoch 164| loss: 0.01048 | train_rmsle: 0.00022 | train_mae: 0.04425 | train_rmse: 0.06329 | train_mse: 0.00401 | valid_rmsle: 0.00192 | valid_mae: 0.13937 | valid_rmse: 0.18512 | valid_mse: 0.03427 |  0:03:03s\n",
      "epoch 165| loss: 0.01146 | train_rmsle: 0.00022 | train_mae: 0.04468 | train_rmse: 0.06263 | train_mse: 0.00392 | valid_rmsle: 0.002   | valid_mae: 0.14072 | valid_rmse: 0.1889  | valid_mse: 0.03568 |  0:03:04s\n",
      "epoch 166| loss: 0.01046 | train_rmsle: 0.0005  | train_mae: 0.07006 | train_rmse: 0.0875  | train_mse: 0.00766 | valid_rmsle: 0.00219 | valid_mae: 0.14979 | valid_rmse: 0.19588 | valid_mse: 0.03837 |  0:03:05s\n",
      "epoch 167| loss: 0.01329 | train_rmsle: 0.00059 | train_mae: 0.08665 | train_rmse: 0.10563 | train_mse: 0.01116 | valid_rmsle: 0.0023  | valid_mae: 0.15589 | valid_rmse: 0.20417 | valid_mse: 0.04169 |  0:03:06s\n",
      "epoch 168| loss: 0.01661 | train_rmsle: 0.00044 | train_mae: 0.069   | train_rmse: 0.08684 | train_mse: 0.00754 | valid_rmsle: 0.00209 | valid_mae: 0.1482  | valid_rmse: 0.1937  | valid_mse: 0.03752 |  0:03:07s\n",
      "epoch 169| loss: 0.01243 | train_rmsle: 0.00027 | train_mae: 0.05161 | train_rmse: 0.07043 | train_mse: 0.00496 | valid_rmsle: 0.00188 | valid_mae: 0.133   | valid_rmse: 0.1823  | valid_mse: 0.03323 |  0:03:08s\n",
      "epoch 170| loss: 0.01023 | train_rmsle: 0.00024 | train_mae: 0.04771 | train_rmse: 0.06566 | train_mse: 0.00431 | valid_rmsle: 0.00192 | valid_mae: 0.13418 | valid_rmse: 0.18472 | valid_mse: 0.03412 |  0:03:09s\n",
      "epoch 171| loss: 0.01053 | train_rmsle: 0.00027 | train_mae: 0.05139 | train_rmse: 0.06795 | train_mse: 0.00462 | valid_rmsle: 0.00195 | valid_mae: 0.13995 | valid_rmse: 0.18714 | valid_mse: 0.03502 |  0:03:11s\n",
      "epoch 172| loss: 0.01052 | train_rmsle: 0.00034 | train_mae: 0.0542  | train_rmse: 0.07352 | train_mse: 0.00541 | valid_rmsle: 0.00204 | valid_mae: 0.14136 | valid_rmse: 0.18981 | valid_mse: 0.03603 |  0:03:12s\n",
      "epoch 173| loss: 0.00948 | train_rmsle: 0.00027 | train_mae: 0.05106 | train_rmse: 0.07106 | train_mse: 0.00505 | valid_rmsle: 0.00192 | valid_mae: 0.13779 | valid_rmse: 0.18696 | valid_mse: 0.03495 |  0:03:13s\n",
      "epoch 174| loss: 0.0105  | train_rmsle: 0.00043 | train_mae: 0.06669 | train_rmse: 0.08451 | train_mse: 0.00714 | valid_rmsle: 0.00213 | valid_mae: 0.14171 | valid_rmse: 0.19413 | valid_mse: 0.03768 |  0:03:14s\n",
      "epoch 175| loss: 0.0112  | train_rmsle: 0.00036 | train_mae: 0.05447 | train_rmse: 0.07301 | train_mse: 0.00533 | valid_rmsle: 0.00195 | valid_mae: 0.13905 | valid_rmse: 0.18481 | valid_mse: 0.03416 |  0:03:15s\n",
      "epoch 176| loss: 0.0124  | train_rmsle: 0.00038 | train_mae: 0.05515 | train_rmse: 0.07394 | train_mse: 0.00547 | valid_rmsle: 0.00195 | valid_mae: 0.13881 | valid_rmse: 0.18374 | valid_mse: 0.03376 |  0:03:16s\n",
      "epoch 177| loss: 0.01094 | train_rmsle: 0.00033 | train_mae: 0.06005 | train_rmse: 0.07897 | train_mse: 0.00624 | valid_rmsle: 0.00189 | valid_mae: 0.13981 | valid_rmse: 0.18445 | valid_mse: 0.03402 |  0:03:17s\n",
      "epoch 178| loss: 0.01033 | train_rmsle: 0.00019 | train_mae: 0.04154 | train_rmse: 0.06022 | train_mse: 0.00363 | valid_rmsle: 0.00181 | valid_mae: 0.13258 | valid_rmse: 0.18026 | valid_mse: 0.03249 |  0:03:18s\n",
      "epoch 179| loss: 0.01065 | train_rmsle: 0.00056 | train_mae: 0.08866 | train_rmse: 0.10296 | train_mse: 0.0106  | valid_rmsle: 0.00224 | valid_mae: 0.14739 | valid_rmse: 0.20029 | valid_mse: 0.04012 |  0:03:19s\n",
      "epoch 180| loss: 0.01294 | train_rmsle: 0.00034 | train_mae: 0.0605  | train_rmse: 0.07756 | train_mse: 0.00602 | valid_rmsle: 0.00201 | valid_mae: 0.14207 | valid_rmse: 0.18942 | valid_mse: 0.03588 |  0:03:20s\n",
      "epoch 181| loss: 0.00992 | train_rmsle: 0.00034 | train_mae: 0.06134 | train_rmse: 0.0772  | train_mse: 0.00596 | valid_rmsle: 0.00199 | valid_mae: 0.14314 | valid_rmse: 0.18828 | valid_mse: 0.03545 |  0:03:21s\n",
      "epoch 182| loss: 0.01035 | train_rmsle: 0.00023 | train_mae: 0.04704 | train_rmse: 0.06483 | train_mse: 0.0042  | valid_rmsle: 0.00184 | valid_mae: 0.13495 | valid_rmse: 0.18192 | valid_mse: 0.03309 |  0:03:23s\n",
      "epoch 183| loss: 0.00966 | train_rmsle: 0.00017 | train_mae: 0.0388  | train_rmse: 0.05652 | train_mse: 0.00319 | valid_rmsle: 0.00172 | valid_mae: 0.12767 | valid_rmse: 0.17523 | valid_mse: 0.0307  |  0:03:24s\n",
      "epoch 184| loss: 0.00909 | train_rmsle: 0.00017 | train_mae: 0.03913 | train_rmse: 0.05622 | train_mse: 0.00316 | valid_rmsle: 0.00171 | valid_mae: 0.12875 | valid_rmse: 0.17491 | valid_mse: 0.03059 |  0:03:25s\n",
      "epoch 185| loss: 0.01065 | train_rmsle: 0.00018 | train_mae: 0.04104 | train_rmse: 0.05805 | train_mse: 0.00337 | valid_rmsle: 0.00178 | valid_mae: 0.12926 | valid_rmse: 0.17764 | valid_mse: 0.03156 |  0:03:26s\n",
      "epoch 186| loss: 0.00955 | train_rmsle: 0.00031 | train_mae: 0.05557 | train_rmse: 0.07243 | train_mse: 0.00525 | valid_rmsle: 0.00183 | valid_mae: 0.13576 | valid_rmse: 0.18036 | valid_mse: 0.03253 |  0:03:27s\n",
      "epoch 187| loss: 0.01034 | train_rmsle: 0.00042 | train_mae: 0.06316 | train_rmse: 0.0794  | train_mse: 0.0063  | valid_rmsle: 0.00191 | valid_mae: 0.14044 | valid_rmse: 0.1832  | valid_mse: 0.03356 |  0:03:28s\n",
      "epoch 188| loss: 0.00996 | train_rmsle: 0.00018 | train_mae: 0.04105 | train_rmse: 0.05789 | train_mse: 0.00335 | valid_rmsle: 0.00165 | valid_mae: 0.12736 | valid_rmse: 0.1725  | valid_mse: 0.02976 |  0:03:29s\n",
      "epoch 189| loss: 0.01174 | train_rmsle: 0.00044 | train_mae: 0.0745  | train_rmse: 0.09241 | train_mse: 0.00854 | valid_rmsle: 0.00193 | valid_mae: 0.14535 | valid_rmse: 0.18806 | valid_mse: 0.03537 |  0:03:30s\n",
      "epoch 190| loss: 0.01134 | train_rmsle: 0.00018 | train_mae: 0.03952 | train_rmse: 0.05723 | train_mse: 0.00327 | valid_rmsle: 0.00169 | valid_mae: 0.12671 | valid_rmse: 0.174   | valid_mse: 0.03028 |  0:03:31s\n",
      "epoch 191| loss: 0.0112  | train_rmsle: 0.00034 | train_mae: 0.05608 | train_rmse: 0.07319 | train_mse: 0.00536 | valid_rmsle: 0.00186 | valid_mae: 0.13236 | valid_rmse: 0.17978 | valid_mse: 0.03232 |  0:03:32s\n",
      "epoch 192| loss: 0.01055 | train_rmsle: 0.00062 | train_mae: 0.07428 | train_rmse: 0.10101 | train_mse: 0.0102  | valid_rmsle: 0.00203 | valid_mae: 0.14129 | valid_rmse: 0.18936 | valid_mse: 0.03586 |  0:03:34s\n",
      "epoch 193| loss: 0.01496 | train_rmsle: 0.00055 | train_mae: 0.07176 | train_rmse: 0.10044 | train_mse: 0.01009 | valid_rmsle: 0.00183 | valid_mae: 0.13601 | valid_rmse: 0.18233 | valid_mse: 0.03325 |  0:03:35s\n",
      "epoch 194| loss: 0.01564 | train_rmsle: 0.00072 | train_mae: 0.09149 | train_rmse: 0.1173  | train_mse: 0.01376 | valid_rmsle: 0.00205 | valid_mae: 0.14926 | valid_rmse: 0.19342 | valid_mse: 0.03741 |  0:03:36s\n",
      "epoch 195| loss: 0.01393 | train_rmsle: 0.00039 | train_mae: 0.05993 | train_rmse: 0.08365 | train_mse: 0.007   | valid_rmsle: 0.00165 | valid_mae: 0.12728 | valid_rmse: 0.17228 | valid_mse: 0.02968 |  0:03:37s\n",
      "epoch 196| loss: 0.0125  | train_rmsle: 0.00049 | train_mae: 0.07031 | train_rmse: 0.09329 | train_mse: 0.0087  | valid_rmsle: 0.00174 | valid_mae: 0.13421 | valid_rmse: 0.17627 | valid_mse: 0.03107 |  0:03:38s\n",
      "epoch 197| loss: 0.01149 | train_rmsle: 0.00033 | train_mae: 0.05566 | train_rmse: 0.07659 | train_mse: 0.00587 | valid_rmsle: 0.00164 | valid_mae: 0.12546 | valid_rmse: 0.17069 | valid_mse: 0.02914 |  0:03:39s\n",
      "epoch 198| loss: 0.01341 | train_rmsle: 0.00048 | train_mae: 0.06674 | train_rmse: 0.08636 | train_mse: 0.00746 | valid_rmsle: 0.00174 | valid_mae: 0.1297  | valid_rmse: 0.17455 | valid_mse: 0.03047 |  0:03:40s\n",
      "epoch 199| loss: 0.01166 | train_rmsle: 0.00034 | train_mae: 0.06075 | train_rmse: 0.08042 | train_mse: 0.00647 | valid_rmsle: 0.00158 | valid_mae: 0.12515 | valid_rmse: 0.16876 | valid_mse: 0.02848 |  0:03:41s\n",
      "epoch 200| loss: 0.0117  | train_rmsle: 0.00035 | train_mae: 0.05483 | train_rmse: 0.07395 | train_mse: 0.00547 | valid_rmsle: 0.00162 | valid_mae: 0.12543 | valid_rmse: 0.16731 | valid_mse: 0.02799 |  0:03:42s\n",
      "epoch 201| loss: 0.01068 | train_rmsle: 0.00022 | train_mae: 0.04552 | train_rmse: 0.06366 | train_mse: 0.00405 | valid_rmsle: 0.00155 | valid_mae: 0.12153 | valid_rmse: 0.16622 | valid_mse: 0.02763 |  0:03:43s\n",
      "epoch 202| loss: 0.0113  | train_rmsle: 0.00027 | train_mae: 0.04928 | train_rmse: 0.06792 | train_mse: 0.00461 | valid_rmsle: 0.00152 | valid_mae: 0.12236 | valid_rmse: 0.16439 | valid_mse: 0.02702 |  0:03:44s\n",
      "epoch 203| loss: 0.0106  | train_rmsle: 0.00022 | train_mae: 0.04488 | train_rmse: 0.06313 | train_mse: 0.00399 | valid_rmsle: 0.00145 | valid_mae: 0.11935 | valid_rmse: 0.16146 | valid_mse: 0.02607 |  0:03:46s\n",
      "epoch 204| loss: 0.01105 | train_rmsle: 0.0003  | train_mae: 0.05723 | train_rmse: 0.07513 | train_mse: 0.00564 | valid_rmsle: 0.00156 | valid_mae: 0.12277 | valid_rmse: 0.16794 | valid_mse: 0.02821 |  0:03:47s\n",
      "epoch 205| loss: 0.01216 | train_rmsle: 0.00026 | train_mae: 0.05039 | train_rmse: 0.06983 | train_mse: 0.00488 | valid_rmsle: 0.0015  | valid_mae: 0.12084 | valid_rmse: 0.16355 | valid_mse: 0.02675 |  0:03:48s\n",
      "epoch 206| loss: 0.0107  | train_rmsle: 0.00026 | train_mae: 0.04945 | train_rmse: 0.06855 | train_mse: 0.0047  | valid_rmsle: 0.00143 | valid_mae: 0.11926 | valid_rmse: 0.15989 | valid_mse: 0.02556 |  0:03:49s\n",
      "epoch 207| loss: 0.01139 | train_rmsle: 0.0004  | train_mae: 0.06351 | train_rmse: 0.08176 | train_mse: 0.00668 | valid_rmsle: 0.00155 | valid_mae: 0.12661 | valid_rmse: 0.16628 | valid_mse: 0.02765 |  0:03:50s\n",
      "epoch 208| loss: 0.01206 | train_rmsle: 0.00033 | train_mae: 0.05596 | train_rmse: 0.07311 | train_mse: 0.00535 | valid_rmsle: 0.00153 | valid_mae: 0.12225 | valid_rmse: 0.16439 | valid_mse: 0.02703 |  0:03:51s\n",
      "epoch 209| loss: 0.00918 | train_rmsle: 0.00025 | train_mae: 0.04715 | train_rmse: 0.06428 | train_mse: 0.00413 | valid_rmsle: 0.00145 | valid_mae: 0.11925 | valid_rmse: 0.16104 | valid_mse: 0.02593 |  0:03:52s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 206 and best_valid_mse = 0.02556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.025584852481464478 RMSE: 0.15995265700032768 R2: 0.8867457163834496 MAE: 0.11777180921829519\n",
      "=====================================\n",
      "[81/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.06696| train_rmsle: 0.18914 | train_mae: 1.48063 | train_rmse: 1.55501 | train_mse: 2.41804 | valid_rmsle: 0.18992 | valid_mae: 1.48508 | valid_rmse: 1.55906 | valid_mse: 2.43066 |  0:00:01s\n",
      "epoch 1  | loss: 2.58066 | train_rmsle: 0.12728 | train_mae: 1.24733 | train_rmse: 1.33011 | train_mse: 1.76919 | valid_rmsle: 0.12804 | valid_mae: 1.25149 | valid_rmse: 1.33497 | valid_mse: 1.78215 |  0:00:02s\n",
      "epoch 2  | loss: 1.04413 | train_rmsle: 0.04195 | train_mae: 0.73801 | train_rmse: 0.83113 | train_mse: 0.69077 | valid_rmsle: 0.042   | valid_mae: 0.73838 | valid_rmse: 0.83401 | valid_mse: 0.69557 |  0:00:03s\n",
      "epoch 3  | loss: 0.67605 | train_rmsle: 0.03039 | train_mae: 0.62575 | train_rmse: 0.71751 | train_mse: 0.51482 | valid_rmsle: 0.03034 | valid_mae: 0.62614 | valid_rmse: 0.71999 | valid_mse: 0.51838 |  0:00:04s\n",
      "epoch 4  | loss: 0.48168 | train_rmsle: 0.02373 | train_mae: 0.54767 | train_rmse: 0.63742 | train_mse: 0.4063  | valid_rmsle: 0.02352 | valid_mae: 0.54914 | valid_rmse: 0.63857 | valid_mse: 0.40778 |  0:00:05s\n",
      "epoch 5  | loss: 0.3782  | train_rmsle: 0.02101 | train_mae: 0.51129 | train_rmse: 0.59978 | train_mse: 0.35974 | valid_rmsle: 0.02074 | valid_mae: 0.51298 | valid_rmse: 0.60017 | valid_mse: 0.36021 |  0:00:06s\n",
      "epoch 6  | loss: 0.33025 | train_rmsle: 0.02203 | train_mae: 0.52547 | train_rmse: 0.61432 | train_mse: 0.37739 | valid_rmsle: 0.0218  | valid_mae: 0.52753 | valid_rmse: 0.61521 | valid_mse: 0.37848 |  0:00:07s\n",
      "epoch 7  | loss: 0.30833 | train_rmsle: 0.02081 | train_mae: 0.50857 | train_rmse: 0.59693 | train_mse: 0.35633 | valid_rmsle: 0.02048 | valid_mae: 0.51005 | valid_rmse: 0.59638 | valid_mse: 0.35567 |  0:00:08s\n",
      "epoch 8  | loss: 0.27466 | train_rmsle: 0.02004 | train_mae: 0.49777 | train_rmse: 0.58566 | train_mse: 0.343   | valid_rmsle: 0.01974 | valid_mae: 0.49959 | valid_rmse: 0.58555 | valid_mse: 0.34287 |  0:00:09s\n",
      "epoch 9  | loss: 0.25593 | train_rmsle: 0.01816 | train_mae: 0.46855 | train_rmse: 0.55572 | train_mse: 0.30882 | valid_rmsle: 0.01783 | valid_mae: 0.47003 | valid_rmse: 0.55534 | valid_mse: 0.3084  |  0:00:10s\n",
      "epoch 10 | loss: 0.23974 | train_rmsle: 0.01739 | train_mae: 0.46476 | train_rmse: 0.54598 | train_mse: 0.29809 | valid_rmsle: 0.01689 | valid_mae: 0.46353 | valid_rmse: 0.54241 | valid_mse: 0.29421 |  0:00:12s\n",
      "epoch 11 | loss: 0.20976 | train_rmsle: 0.01181 | train_mae: 0.36125 | train_rmse: 0.43729 | train_mse: 0.19122 | valid_rmsle: 0.01091 | valid_mae: 0.34593 | valid_rmse: 0.42335 | valid_mse: 0.17922 |  0:00:13s\n",
      "epoch 12 | loss: 0.16309 | train_rmsle: 0.0116  | train_mae: 0.33908 | train_rmse: 0.42552 | train_mse: 0.18107 | valid_rmsle: 0.01088 | valid_mae: 0.32728 | valid_rmse: 0.4141  | valid_mse: 0.17148 |  0:00:14s\n",
      "epoch 13 | loss: 0.13959 | train_rmsle: 0.01068 | train_mae: 0.32664 | train_rmse: 0.41231 | train_mse: 0.17    | valid_rmsle: 0.00991 | valid_mae: 0.31753 | valid_rmse: 0.40091 | valid_mse: 0.16073 |  0:00:15s\n",
      "epoch 14 | loss: 0.12105 | train_rmsle: 0.00867 | train_mae: 0.28963 | train_rmse: 0.36822 | train_mse: 0.13559 | valid_rmsle: 0.00799 | valid_mae: 0.27956 | valid_rmse: 0.35622 | valid_mse: 0.12689 |  0:00:16s\n",
      "epoch 15 | loss: 0.1143  | train_rmsle: 0.00837 | train_mae: 0.28821 | train_rmse: 0.36406 | train_mse: 0.13254 | valid_rmsle: 0.0079  | valid_mae: 0.28043 | valid_rmse: 0.35569 | valid_mse: 0.12652 |  0:00:17s\n",
      "epoch 16 | loss: 0.11111 | train_rmsle: 0.00767 | train_mae: 0.27332 | train_rmse: 0.35038 | train_mse: 0.12277 | valid_rmsle: 0.00729 | valid_mae: 0.27262 | valid_rmse: 0.34662 | valid_mse: 0.12014 |  0:00:18s\n",
      "epoch 17 | loss: 0.10367 | train_rmsle: 0.00718 | train_mae: 0.25978 | train_rmse: 0.33391 | train_mse: 0.1115  | valid_rmsle: 0.00667 | valid_mae: 0.25278 | valid_rmse: 0.32546 | valid_mse: 0.10592 |  0:00:19s\n",
      "epoch 18 | loss: 0.10336 | train_rmsle: 0.00692 | train_mae: 0.25229 | train_rmse: 0.32697 | train_mse: 0.10691 | valid_rmsle: 0.00649 | valid_mae: 0.24465 | valid_rmse: 0.32002 | valid_mse: 0.10241 |  0:00:20s\n",
      "epoch 19 | loss: 0.09742 | train_rmsle: 0.00726 | train_mae: 0.25871 | train_rmse: 0.33479 | train_mse: 0.11208 | valid_rmsle: 0.00682 | valid_mae: 0.25211 | valid_rmse: 0.32737 | valid_mse: 0.10717 |  0:00:21s\n",
      "epoch 20 | loss: 0.09306 | train_rmsle: 0.00675 | train_mae: 0.25018 | train_rmse: 0.32287 | train_mse: 0.10424 | valid_rmsle: 0.00647 | valid_mae: 0.24627 | valid_rmse: 0.31861 | valid_mse: 0.10151 |  0:00:23s\n",
      "epoch 21 | loss: 0.0923  | train_rmsle: 0.00701 | train_mae: 0.25298 | train_rmse: 0.32721 | train_mse: 0.10707 | valid_rmsle: 0.00652 | valid_mae: 0.24846 | valid_rmse: 0.3195  | valid_mse: 0.10208 |  0:00:24s\n",
      "epoch 22 | loss: 0.08963 | train_rmsle: 0.00691 | train_mae: 0.25184 | train_rmse: 0.325   | train_mse: 0.10563 | valid_rmsle: 0.00649 | valid_mae: 0.24738 | valid_rmse: 0.31832 | valid_mse: 0.10133 |  0:00:25s\n",
      "epoch 23 | loss: 0.08909 | train_rmsle: 0.00614 | train_mae: 0.23535 | train_rmse: 0.30608 | train_mse: 0.09369 | valid_rmsle: 0.00596 | valid_mae: 0.2355  | valid_rmse: 0.30517 | valid_mse: 0.09313 |  0:00:26s\n",
      "epoch 24 | loss: 0.08668 | train_rmsle: 0.00627 | train_mae: 0.24178 | train_rmse: 0.31128 | train_mse: 0.09689 | valid_rmsle: 0.00614 | valid_mae: 0.24114 | valid_rmse: 0.31085 | valid_mse: 0.09663 |  0:00:27s\n",
      "epoch 25 | loss: 0.08542 | train_rmsle: 0.00598 | train_mae: 0.22994 | train_rmse: 0.30119 | train_mse: 0.09072 | valid_rmsle: 0.00599 | valid_mae: 0.23274 | valid_rmse: 0.306   | valid_mse: 0.09364 |  0:00:28s\n",
      "epoch 26 | loss: 0.08482 | train_rmsle: 0.00594 | train_mae: 0.23396 | train_rmse: 0.30199 | train_mse: 0.0912  | valid_rmsle: 0.00609 | valid_mae: 0.24018 | valid_rmse: 0.31006 | valid_mse: 0.09614 |  0:00:29s\n",
      "epoch 27 | loss: 0.08289 | train_rmsle: 0.0059  | train_mae: 0.23458 | train_rmse: 0.30152 | train_mse: 0.09091 | valid_rmsle: 0.00619 | valid_mae: 0.24404 | valid_rmse: 0.31294 | valid_mse: 0.09793 |  0:00:30s\n",
      "epoch 28 | loss: 0.08312 | train_rmsle: 0.00568 | train_mae: 0.22892 | train_rmse: 0.29548 | train_mse: 0.08731 | valid_rmsle: 0.00626 | valid_mae: 0.24095 | valid_rmse: 0.31363 | valid_mse: 0.09837 |  0:00:31s\n",
      "epoch 29 | loss: 0.07975 | train_rmsle: 0.00541 | train_mae: 0.21885 | train_rmse: 0.28607 | train_mse: 0.08184 | valid_rmsle: 0.00597 | valid_mae: 0.23315 | valid_rmse: 0.3057  | valid_mse: 0.09345 |  0:00:32s\n",
      "epoch 30 | loss: 0.07889 | train_rmsle: 0.00535 | train_mae: 0.21958 | train_rmse: 0.28551 | train_mse: 0.08152 | valid_rmsle: 0.00613 | valid_mae: 0.23691 | valid_rmse: 0.31049 | valid_mse: 0.09641 |  0:00:33s\n",
      "epoch 31 | loss: 0.07727 | train_rmsle: 0.00508 | train_mae: 0.21258 | train_rmse: 0.27803 | train_mse: 0.0773  | valid_rmsle: 0.00625 | valid_mae: 0.23879 | valid_rmse: 0.31285 | valid_mse: 0.09788 |  0:00:35s\n",
      "epoch 32 | loss: 0.07702 | train_rmsle: 0.00485 | train_mae: 0.2112  | train_rmse: 0.27313 | train_mse: 0.0746  | valid_rmsle: 0.006   | valid_mae: 0.23656 | valid_rmse: 0.30725 | valid_mse: 0.0944  |  0:00:36s\n",
      "epoch 33 | loss: 0.07572 | train_rmsle: 0.00464 | train_mae: 0.20249 | train_rmse: 0.26566 | train_mse: 0.07058 | valid_rmsle: 0.0061  | valid_mae: 0.23439 | valid_rmse: 0.30912 | valid_mse: 0.09556 |  0:00:37s\n",
      "epoch 34 | loss: 0.07655 | train_rmsle: 0.00464 | train_mae: 0.20465 | train_rmse: 0.26679 | train_mse: 0.07117 | valid_rmsle: 0.00595 | valid_mae: 0.23592 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:00:38s\n",
      "epoch 35 | loss: 0.07338 | train_rmsle: 0.00482 | train_mae: 0.20165 | train_rmse: 0.26877 | train_mse: 0.07224 | valid_rmsle: 0.00623 | valid_mae: 0.23774 | valid_rmse: 0.31321 | valid_mse: 0.0981  |  0:00:39s\n",
      "epoch 36 | loss: 0.07458 | train_rmsle: 0.00441 | train_mae: 0.20059 | train_rmse: 0.26083 | train_mse: 0.06803 | valid_rmsle: 0.00604 | valid_mae: 0.24325 | valid_rmse: 0.3114  | valid_mse: 0.09697 |  0:00:40s\n",
      "epoch 37 | loss: 0.06965 | train_rmsle: 0.00431 | train_mae: 0.19505 | train_rmse: 0.25677 | train_mse: 0.06593 | valid_rmsle: 0.00607 | valid_mae: 0.24122 | valid_rmse: 0.3113  | valid_mse: 0.09691 |  0:00:41s\n",
      "epoch 38 | loss: 0.0701  | train_rmsle: 0.00397 | train_mae: 0.18888 | train_rmse: 0.2475  | train_mse: 0.06126 | valid_rmsle: 0.00632 | valid_mae: 0.24482 | valid_rmse: 0.31589 | valid_mse: 0.09978 |  0:00:42s\n",
      "epoch 39 | loss: 0.07061 | train_rmsle: 0.0039  | train_mae: 0.18724 | train_rmse: 0.2455  | train_mse: 0.06027 | valid_rmsle: 0.00631 | valid_mae: 0.24538 | valid_rmse: 0.31727 | valid_mse: 0.10066 |  0:00:43s\n",
      "epoch 40 | loss: 0.06943 | train_rmsle: 0.00386 | train_mae: 0.18551 | train_rmse: 0.24425 | train_mse: 0.05966 | valid_rmsle: 0.00644 | valid_mae: 0.24392 | valid_rmse: 0.31962 | valid_mse: 0.10215 |  0:00:44s\n",
      "epoch 41 | loss: 0.0694  | train_rmsle: 0.00378 | train_mae: 0.18597 | train_rmse: 0.24316 | train_mse: 0.05912 | valid_rmsle: 0.00642 | valid_mae: 0.24736 | valid_rmse: 0.31995 | valid_mse: 0.10237 |  0:00:46s\n",
      "epoch 42 | loss: 0.06883 | train_rmsle: 0.00378 | train_mae: 0.18383 | train_rmse: 0.24184 | train_mse: 0.05849 | valid_rmsle: 0.00622 | valid_mae: 0.2418  | valid_rmse: 0.31548 | valid_mse: 0.09953 |  0:00:47s\n",
      "epoch 43 | loss: 0.06846 | train_rmsle: 0.00381 | train_mae: 0.18317 | train_rmse: 0.24143 | train_mse: 0.05829 | valid_rmsle: 0.00628 | valid_mae: 0.24243 | valid_rmse: 0.31609 | valid_mse: 0.09991 |  0:00:48s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_mse = 0.09313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09649207339249978 RMSE: 0.31063173275198364 R2: 0.5728667712795958 MAE: 0.2384033480735491\n",
      "=====================================\n",
      "[82/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.06696| train_rmsle: 0.18914 | train_mae: 1.48063 | train_rmse: 1.55501 | train_mse: 2.41804 | valid_rmsle: 0.18992 | valid_mae: 1.48508 | valid_rmse: 1.55906 | valid_mse: 2.43066 |  0:00:01s\n",
      "epoch 1  | loss: 2.58066 | train_rmsle: 0.12728 | train_mae: 1.24733 | train_rmse: 1.33011 | train_mse: 1.76919 | valid_rmsle: 0.12804 | valid_mae: 1.25149 | valid_rmse: 1.33497 | valid_mse: 1.78215 |  0:00:02s\n",
      "epoch 2  | loss: 1.04413 | train_rmsle: 0.04195 | train_mae: 0.73801 | train_rmse: 0.83113 | train_mse: 0.69077 | valid_rmsle: 0.042   | valid_mae: 0.73838 | valid_rmse: 0.83401 | valid_mse: 0.69557 |  0:00:03s\n",
      "epoch 3  | loss: 0.67605 | train_rmsle: 0.03039 | train_mae: 0.62575 | train_rmse: 0.71751 | train_mse: 0.51482 | valid_rmsle: 0.03034 | valid_mae: 0.62614 | valid_rmse: 0.71999 | valid_mse: 0.51838 |  0:00:04s\n",
      "epoch 4  | loss: 0.48168 | train_rmsle: 0.02373 | train_mae: 0.54767 | train_rmse: 0.63742 | train_mse: 0.4063  | valid_rmsle: 0.02352 | valid_mae: 0.54914 | valid_rmse: 0.63857 | valid_mse: 0.40778 |  0:00:05s\n",
      "epoch 5  | loss: 0.3782  | train_rmsle: 0.02101 | train_mae: 0.51129 | train_rmse: 0.59978 | train_mse: 0.35974 | valid_rmsle: 0.02074 | valid_mae: 0.51298 | valid_rmse: 0.60017 | valid_mse: 0.36021 |  0:00:06s\n",
      "epoch 6  | loss: 0.33025 | train_rmsle: 0.02203 | train_mae: 0.52547 | train_rmse: 0.61432 | train_mse: 0.37739 | valid_rmsle: 0.0218  | valid_mae: 0.52753 | valid_rmse: 0.61521 | valid_mse: 0.37848 |  0:00:07s\n",
      "epoch 7  | loss: 0.30833 | train_rmsle: 0.02081 | train_mae: 0.50857 | train_rmse: 0.59693 | train_mse: 0.35633 | valid_rmsle: 0.02048 | valid_mae: 0.51005 | valid_rmse: 0.59638 | valid_mse: 0.35567 |  0:00:08s\n",
      "epoch 8  | loss: 0.27466 | train_rmsle: 0.02004 | train_mae: 0.49777 | train_rmse: 0.58566 | train_mse: 0.343   | valid_rmsle: 0.01974 | valid_mae: 0.49959 | valid_rmse: 0.58555 | valid_mse: 0.34287 |  0:00:09s\n",
      "epoch 9  | loss: 0.25593 | train_rmsle: 0.01816 | train_mae: 0.46855 | train_rmse: 0.55572 | train_mse: 0.30882 | valid_rmsle: 0.01783 | valid_mae: 0.47003 | valid_rmse: 0.55534 | valid_mse: 0.3084  |  0:00:10s\n",
      "epoch 10 | loss: 0.23974 | train_rmsle: 0.01739 | train_mae: 0.46476 | train_rmse: 0.54598 | train_mse: 0.29809 | valid_rmsle: 0.01689 | valid_mae: 0.46353 | valid_rmse: 0.54241 | valid_mse: 0.29421 |  0:00:12s\n",
      "epoch 11 | loss: 0.20976 | train_rmsle: 0.01181 | train_mae: 0.36125 | train_rmse: 0.43729 | train_mse: 0.19122 | valid_rmsle: 0.01091 | valid_mae: 0.34593 | valid_rmse: 0.42335 | valid_mse: 0.17922 |  0:00:13s\n",
      "epoch 12 | loss: 0.16309 | train_rmsle: 0.0116  | train_mae: 0.33908 | train_rmse: 0.42552 | train_mse: 0.18107 | valid_rmsle: 0.01088 | valid_mae: 0.32728 | valid_rmse: 0.4141  | valid_mse: 0.17148 |  0:00:14s\n",
      "epoch 13 | loss: 0.13959 | train_rmsle: 0.01068 | train_mae: 0.32664 | train_rmse: 0.41231 | train_mse: 0.17    | valid_rmsle: 0.00991 | valid_mae: 0.31753 | valid_rmse: 0.40091 | valid_mse: 0.16073 |  0:00:15s\n",
      "epoch 14 | loss: 0.12105 | train_rmsle: 0.00867 | train_mae: 0.28963 | train_rmse: 0.36822 | train_mse: 0.13559 | valid_rmsle: 0.00799 | valid_mae: 0.27956 | valid_rmse: 0.35622 | valid_mse: 0.12689 |  0:00:16s\n",
      "epoch 15 | loss: 0.1143  | train_rmsle: 0.00837 | train_mae: 0.28821 | train_rmse: 0.36406 | train_mse: 0.13254 | valid_rmsle: 0.0079  | valid_mae: 0.28043 | valid_rmse: 0.35569 | valid_mse: 0.12652 |  0:00:17s\n",
      "epoch 16 | loss: 0.11111 | train_rmsle: 0.00767 | train_mae: 0.27332 | train_rmse: 0.35038 | train_mse: 0.12277 | valid_rmsle: 0.00729 | valid_mae: 0.27262 | valid_rmse: 0.34662 | valid_mse: 0.12014 |  0:00:18s\n",
      "epoch 17 | loss: 0.10367 | train_rmsle: 0.00718 | train_mae: 0.25978 | train_rmse: 0.33391 | train_mse: 0.1115  | valid_rmsle: 0.00667 | valid_mae: 0.25278 | valid_rmse: 0.32546 | valid_mse: 0.10592 |  0:00:19s\n",
      "epoch 18 | loss: 0.10336 | train_rmsle: 0.00692 | train_mae: 0.25229 | train_rmse: 0.32697 | train_mse: 0.10691 | valid_rmsle: 0.00649 | valid_mae: 0.24465 | valid_rmse: 0.32002 | valid_mse: 0.10241 |  0:00:20s\n",
      "epoch 19 | loss: 0.09742 | train_rmsle: 0.00726 | train_mae: 0.25871 | train_rmse: 0.33479 | train_mse: 0.11208 | valid_rmsle: 0.00682 | valid_mae: 0.25211 | valid_rmse: 0.32737 | valid_mse: 0.10717 |  0:00:21s\n",
      "epoch 20 | loss: 0.09306 | train_rmsle: 0.00675 | train_mae: 0.25018 | train_rmse: 0.32287 | train_mse: 0.10424 | valid_rmsle: 0.00647 | valid_mae: 0.24627 | valid_rmse: 0.31861 | valid_mse: 0.10151 |  0:00:22s\n",
      "epoch 21 | loss: 0.0923  | train_rmsle: 0.00701 | train_mae: 0.25298 | train_rmse: 0.32721 | train_mse: 0.10707 | valid_rmsle: 0.00652 | valid_mae: 0.24846 | valid_rmse: 0.3195  | valid_mse: 0.10208 |  0:00:23s\n",
      "epoch 22 | loss: 0.08963 | train_rmsle: 0.00691 | train_mae: 0.25184 | train_rmse: 0.325   | train_mse: 0.10563 | valid_rmsle: 0.00649 | valid_mae: 0.24738 | valid_rmse: 0.31832 | valid_mse: 0.10133 |  0:00:24s\n",
      "epoch 23 | loss: 0.08909 | train_rmsle: 0.00614 | train_mae: 0.23535 | train_rmse: 0.30608 | train_mse: 0.09369 | valid_rmsle: 0.00596 | valid_mae: 0.2355  | valid_rmse: 0.30517 | valid_mse: 0.09313 |  0:00:25s\n",
      "epoch 24 | loss: 0.08668 | train_rmsle: 0.00627 | train_mae: 0.24178 | train_rmse: 0.31128 | train_mse: 0.09689 | valid_rmsle: 0.00614 | valid_mae: 0.24114 | valid_rmse: 0.31085 | valid_mse: 0.09663 |  0:00:27s\n",
      "epoch 25 | loss: 0.08542 | train_rmsle: 0.00598 | train_mae: 0.22994 | train_rmse: 0.30119 | train_mse: 0.09072 | valid_rmsle: 0.00599 | valid_mae: 0.23274 | valid_rmse: 0.306   | valid_mse: 0.09364 |  0:00:28s\n",
      "epoch 26 | loss: 0.08482 | train_rmsle: 0.00594 | train_mae: 0.23396 | train_rmse: 0.30199 | train_mse: 0.0912  | valid_rmsle: 0.00609 | valid_mae: 0.24018 | valid_rmse: 0.31006 | valid_mse: 0.09614 |  0:00:29s\n",
      "epoch 27 | loss: 0.08289 | train_rmsle: 0.0059  | train_mae: 0.23458 | train_rmse: 0.30152 | train_mse: 0.09091 | valid_rmsle: 0.00619 | valid_mae: 0.24404 | valid_rmse: 0.31294 | valid_mse: 0.09793 |  0:00:30s\n",
      "epoch 28 | loss: 0.08312 | train_rmsle: 0.00568 | train_mae: 0.22892 | train_rmse: 0.29548 | train_mse: 0.08731 | valid_rmsle: 0.00626 | valid_mae: 0.24095 | valid_rmse: 0.31363 | valid_mse: 0.09837 |  0:00:31s\n",
      "epoch 29 | loss: 0.07975 | train_rmsle: 0.00541 | train_mae: 0.21885 | train_rmse: 0.28607 | train_mse: 0.08184 | valid_rmsle: 0.00597 | valid_mae: 0.23315 | valid_rmse: 0.3057  | valid_mse: 0.09345 |  0:00:32s\n",
      "epoch 30 | loss: 0.07889 | train_rmsle: 0.00535 | train_mae: 0.21958 | train_rmse: 0.28551 | train_mse: 0.08152 | valid_rmsle: 0.00613 | valid_mae: 0.23691 | valid_rmse: 0.31049 | valid_mse: 0.09641 |  0:00:33s\n",
      "epoch 31 | loss: 0.07727 | train_rmsle: 0.00508 | train_mae: 0.21258 | train_rmse: 0.27803 | train_mse: 0.0773  | valid_rmsle: 0.00625 | valid_mae: 0.23879 | valid_rmse: 0.31285 | valid_mse: 0.09788 |  0:00:34s\n",
      "epoch 32 | loss: 0.07702 | train_rmsle: 0.00485 | train_mae: 0.2112  | train_rmse: 0.27313 | train_mse: 0.0746  | valid_rmsle: 0.006   | valid_mae: 0.23656 | valid_rmse: 0.30725 | valid_mse: 0.0944  |  0:00:35s\n",
      "epoch 33 | loss: 0.07572 | train_rmsle: 0.00464 | train_mae: 0.20249 | train_rmse: 0.26566 | train_mse: 0.07058 | valid_rmsle: 0.0061  | valid_mae: 0.23439 | valid_rmse: 0.30912 | valid_mse: 0.09556 |  0:00:36s\n",
      "epoch 34 | loss: 0.07655 | train_rmsle: 0.00464 | train_mae: 0.20465 | train_rmse: 0.26679 | train_mse: 0.07117 | valid_rmsle: 0.00595 | valid_mae: 0.23592 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:00:37s\n",
      "epoch 35 | loss: 0.07338 | train_rmsle: 0.00482 | train_mae: 0.20165 | train_rmse: 0.26877 | train_mse: 0.07224 | valid_rmsle: 0.00623 | valid_mae: 0.23774 | valid_rmse: 0.31321 | valid_mse: 0.0981  |  0:00:39s\n",
      "epoch 36 | loss: 0.07458 | train_rmsle: 0.00441 | train_mae: 0.20059 | train_rmse: 0.26083 | train_mse: 0.06803 | valid_rmsle: 0.00604 | valid_mae: 0.24325 | valid_rmse: 0.3114  | valid_mse: 0.09697 |  0:00:40s\n",
      "epoch 37 | loss: 0.06965 | train_rmsle: 0.00431 | train_mae: 0.19505 | train_rmse: 0.25677 | train_mse: 0.06593 | valid_rmsle: 0.00607 | valid_mae: 0.24122 | valid_rmse: 0.3113  | valid_mse: 0.09691 |  0:00:41s\n",
      "epoch 38 | loss: 0.0701  | train_rmsle: 0.00397 | train_mae: 0.18888 | train_rmse: 0.2475  | train_mse: 0.06126 | valid_rmsle: 0.00632 | valid_mae: 0.24482 | valid_rmse: 0.31589 | valid_mse: 0.09978 |  0:00:42s\n",
      "epoch 39 | loss: 0.07061 | train_rmsle: 0.0039  | train_mae: 0.18724 | train_rmse: 0.2455  | train_mse: 0.06027 | valid_rmsle: 0.00631 | valid_mae: 0.24538 | valid_rmse: 0.31727 | valid_mse: 0.10066 |  0:00:43s\n",
      "epoch 40 | loss: 0.06943 | train_rmsle: 0.00386 | train_mae: 0.18551 | train_rmse: 0.24425 | train_mse: 0.05966 | valid_rmsle: 0.00644 | valid_mae: 0.24392 | valid_rmse: 0.31962 | valid_mse: 0.10215 |  0:00:44s\n",
      "epoch 41 | loss: 0.0694  | train_rmsle: 0.00378 | train_mae: 0.18597 | train_rmse: 0.24316 | train_mse: 0.05912 | valid_rmsle: 0.00642 | valid_mae: 0.24736 | valid_rmse: 0.31995 | valid_mse: 0.10237 |  0:00:45s\n",
      "epoch 42 | loss: 0.06883 | train_rmsle: 0.00378 | train_mae: 0.18383 | train_rmse: 0.24184 | train_mse: 0.05849 | valid_rmsle: 0.00622 | valid_mae: 0.2418  | valid_rmse: 0.31548 | valid_mse: 0.09953 |  0:00:46s\n",
      "epoch 43 | loss: 0.06846 | train_rmsle: 0.00381 | train_mae: 0.18317 | train_rmse: 0.24143 | train_mse: 0.05829 | valid_rmsle: 0.00628 | valid_mae: 0.24243 | valid_rmse: 0.31609 | valid_mse: 0.09991 |  0:00:47s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_mse = 0.09313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09649207339249978 RMSE: 0.31063173275198364 R2: 0.5728667712795958 MAE: 0.2384033480735491\n",
      "=====================================\n",
      "[83/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.06696| train_rmsle: 0.18914 | train_mae: 1.48063 | train_rmse: 1.55501 | train_mse: 2.41804 | valid_rmsle: 0.18992 | valid_mae: 1.48508 | valid_rmse: 1.55906 | valid_mse: 2.43066 |  0:00:01s\n",
      "epoch 1  | loss: 2.58066 | train_rmsle: 0.12728 | train_mae: 1.24733 | train_rmse: 1.33011 | train_mse: 1.76919 | valid_rmsle: 0.12804 | valid_mae: 1.25149 | valid_rmse: 1.33497 | valid_mse: 1.78215 |  0:00:02s\n",
      "epoch 2  | loss: 1.04413 | train_rmsle: 0.04195 | train_mae: 0.73801 | train_rmse: 0.83113 | train_mse: 0.69077 | valid_rmsle: 0.042   | valid_mae: 0.73838 | valid_rmse: 0.83401 | valid_mse: 0.69557 |  0:00:03s\n",
      "epoch 3  | loss: 0.67605 | train_rmsle: 0.03039 | train_mae: 0.62575 | train_rmse: 0.71751 | train_mse: 0.51482 | valid_rmsle: 0.03034 | valid_mae: 0.62614 | valid_rmse: 0.71999 | valid_mse: 0.51838 |  0:00:04s\n",
      "epoch 4  | loss: 0.48168 | train_rmsle: 0.02373 | train_mae: 0.54767 | train_rmse: 0.63742 | train_mse: 0.4063  | valid_rmsle: 0.02352 | valid_mae: 0.54914 | valid_rmse: 0.63857 | valid_mse: 0.40778 |  0:00:05s\n",
      "epoch 5  | loss: 0.3782  | train_rmsle: 0.02101 | train_mae: 0.51129 | train_rmse: 0.59978 | train_mse: 0.35974 | valid_rmsle: 0.02074 | valid_mae: 0.51298 | valid_rmse: 0.60017 | valid_mse: 0.36021 |  0:00:06s\n",
      "epoch 6  | loss: 0.33025 | train_rmsle: 0.02203 | train_mae: 0.52547 | train_rmse: 0.61432 | train_mse: 0.37739 | valid_rmsle: 0.0218  | valid_mae: 0.52753 | valid_rmse: 0.61521 | valid_mse: 0.37848 |  0:00:07s\n",
      "epoch 7  | loss: 0.30833 | train_rmsle: 0.02081 | train_mae: 0.50857 | train_rmse: 0.59693 | train_mse: 0.35633 | valid_rmsle: 0.02048 | valid_mae: 0.51005 | valid_rmse: 0.59638 | valid_mse: 0.35567 |  0:00:08s\n",
      "epoch 8  | loss: 0.27466 | train_rmsle: 0.02004 | train_mae: 0.49777 | train_rmse: 0.58566 | train_mse: 0.343   | valid_rmsle: 0.01974 | valid_mae: 0.49959 | valid_rmse: 0.58555 | valid_mse: 0.34287 |  0:00:09s\n",
      "epoch 9  | loss: 0.25593 | train_rmsle: 0.01816 | train_mae: 0.46855 | train_rmse: 0.55572 | train_mse: 0.30882 | valid_rmsle: 0.01783 | valid_mae: 0.47003 | valid_rmse: 0.55534 | valid_mse: 0.3084  |  0:00:11s\n",
      "epoch 10 | loss: 0.23974 | train_rmsle: 0.01739 | train_mae: 0.46476 | train_rmse: 0.54598 | train_mse: 0.29809 | valid_rmsle: 0.01689 | valid_mae: 0.46353 | valid_rmse: 0.54241 | valid_mse: 0.29421 |  0:00:12s\n",
      "epoch 11 | loss: 0.20976 | train_rmsle: 0.01181 | train_mae: 0.36125 | train_rmse: 0.43729 | train_mse: 0.19122 | valid_rmsle: 0.01091 | valid_mae: 0.34593 | valid_rmse: 0.42335 | valid_mse: 0.17922 |  0:00:13s\n",
      "epoch 12 | loss: 0.16309 | train_rmsle: 0.0116  | train_mae: 0.33908 | train_rmse: 0.42552 | train_mse: 0.18107 | valid_rmsle: 0.01088 | valid_mae: 0.32728 | valid_rmse: 0.4141  | valid_mse: 0.17148 |  0:00:14s\n",
      "epoch 13 | loss: 0.13959 | train_rmsle: 0.01068 | train_mae: 0.32664 | train_rmse: 0.41231 | train_mse: 0.17    | valid_rmsle: 0.00991 | valid_mae: 0.31753 | valid_rmse: 0.40091 | valid_mse: 0.16073 |  0:00:15s\n",
      "epoch 14 | loss: 0.12105 | train_rmsle: 0.00867 | train_mae: 0.28963 | train_rmse: 0.36822 | train_mse: 0.13559 | valid_rmsle: 0.00799 | valid_mae: 0.27956 | valid_rmse: 0.35622 | valid_mse: 0.12689 |  0:00:16s\n",
      "epoch 15 | loss: 0.1143  | train_rmsle: 0.00837 | train_mae: 0.28821 | train_rmse: 0.36406 | train_mse: 0.13254 | valid_rmsle: 0.0079  | valid_mae: 0.28043 | valid_rmse: 0.35569 | valid_mse: 0.12652 |  0:00:17s\n",
      "epoch 16 | loss: 0.11111 | train_rmsle: 0.00767 | train_mae: 0.27332 | train_rmse: 0.35038 | train_mse: 0.12277 | valid_rmsle: 0.00729 | valid_mae: 0.27262 | valid_rmse: 0.34662 | valid_mse: 0.12014 |  0:00:18s\n",
      "epoch 17 | loss: 0.10367 | train_rmsle: 0.00718 | train_mae: 0.25978 | train_rmse: 0.33391 | train_mse: 0.1115  | valid_rmsle: 0.00667 | valid_mae: 0.25278 | valid_rmse: 0.32546 | valid_mse: 0.10592 |  0:00:19s\n",
      "epoch 18 | loss: 0.10336 | train_rmsle: 0.00692 | train_mae: 0.25229 | train_rmse: 0.32697 | train_mse: 0.10691 | valid_rmsle: 0.00649 | valid_mae: 0.24465 | valid_rmse: 0.32002 | valid_mse: 0.10241 |  0:00:20s\n",
      "epoch 19 | loss: 0.09742 | train_rmsle: 0.00726 | train_mae: 0.25871 | train_rmse: 0.33479 | train_mse: 0.11208 | valid_rmsle: 0.00682 | valid_mae: 0.25211 | valid_rmse: 0.32737 | valid_mse: 0.10717 |  0:00:22s\n",
      "epoch 20 | loss: 0.09306 | train_rmsle: 0.00675 | train_mae: 0.25018 | train_rmse: 0.32287 | train_mse: 0.10424 | valid_rmsle: 0.00647 | valid_mae: 0.24627 | valid_rmse: 0.31861 | valid_mse: 0.10151 |  0:00:23s\n",
      "epoch 21 | loss: 0.0923  | train_rmsle: 0.00701 | train_mae: 0.25298 | train_rmse: 0.32721 | train_mse: 0.10707 | valid_rmsle: 0.00652 | valid_mae: 0.24846 | valid_rmse: 0.3195  | valid_mse: 0.10208 |  0:00:24s\n",
      "epoch 22 | loss: 0.08963 | train_rmsle: 0.00691 | train_mae: 0.25184 | train_rmse: 0.325   | train_mse: 0.10563 | valid_rmsle: 0.00649 | valid_mae: 0.24738 | valid_rmse: 0.31832 | valid_mse: 0.10133 |  0:00:25s\n",
      "epoch 23 | loss: 0.08909 | train_rmsle: 0.00614 | train_mae: 0.23535 | train_rmse: 0.30608 | train_mse: 0.09369 | valid_rmsle: 0.00596 | valid_mae: 0.2355  | valid_rmse: 0.30517 | valid_mse: 0.09313 |  0:00:26s\n",
      "epoch 24 | loss: 0.08668 | train_rmsle: 0.00627 | train_mae: 0.24178 | train_rmse: 0.31128 | train_mse: 0.09689 | valid_rmsle: 0.00614 | valid_mae: 0.24114 | valid_rmse: 0.31085 | valid_mse: 0.09663 |  0:00:27s\n",
      "epoch 25 | loss: 0.08542 | train_rmsle: 0.00598 | train_mae: 0.22994 | train_rmse: 0.30119 | train_mse: 0.09072 | valid_rmsle: 0.00599 | valid_mae: 0.23274 | valid_rmse: 0.306   | valid_mse: 0.09364 |  0:00:28s\n",
      "epoch 26 | loss: 0.08482 | train_rmsle: 0.00594 | train_mae: 0.23396 | train_rmse: 0.30199 | train_mse: 0.0912  | valid_rmsle: 0.00609 | valid_mae: 0.24018 | valid_rmse: 0.31006 | valid_mse: 0.09614 |  0:00:29s\n",
      "epoch 27 | loss: 0.08289 | train_rmsle: 0.0059  | train_mae: 0.23458 | train_rmse: 0.30152 | train_mse: 0.09091 | valid_rmsle: 0.00619 | valid_mae: 0.24404 | valid_rmse: 0.31294 | valid_mse: 0.09793 |  0:00:31s\n",
      "epoch 28 | loss: 0.08312 | train_rmsle: 0.00568 | train_mae: 0.22892 | train_rmse: 0.29548 | train_mse: 0.08731 | valid_rmsle: 0.00626 | valid_mae: 0.24095 | valid_rmse: 0.31363 | valid_mse: 0.09837 |  0:00:32s\n",
      "epoch 29 | loss: 0.07975 | train_rmsle: 0.00541 | train_mae: 0.21885 | train_rmse: 0.28607 | train_mse: 0.08184 | valid_rmsle: 0.00597 | valid_mae: 0.23315 | valid_rmse: 0.3057  | valid_mse: 0.09345 |  0:00:33s\n",
      "epoch 30 | loss: 0.07889 | train_rmsle: 0.00535 | train_mae: 0.21958 | train_rmse: 0.28551 | train_mse: 0.08152 | valid_rmsle: 0.00613 | valid_mae: 0.23691 | valid_rmse: 0.31049 | valid_mse: 0.09641 |  0:00:34s\n",
      "epoch 31 | loss: 0.07727 | train_rmsle: 0.00508 | train_mae: 0.21258 | train_rmse: 0.27803 | train_mse: 0.0773  | valid_rmsle: 0.00625 | valid_mae: 0.23879 | valid_rmse: 0.31285 | valid_mse: 0.09788 |  0:00:35s\n",
      "epoch 32 | loss: 0.07702 | train_rmsle: 0.00485 | train_mae: 0.2112  | train_rmse: 0.27313 | train_mse: 0.0746  | valid_rmsle: 0.006   | valid_mae: 0.23656 | valid_rmse: 0.30725 | valid_mse: 0.0944  |  0:00:36s\n",
      "epoch 33 | loss: 0.07572 | train_rmsle: 0.00464 | train_mae: 0.20249 | train_rmse: 0.26566 | train_mse: 0.07058 | valid_rmsle: 0.0061  | valid_mae: 0.23439 | valid_rmse: 0.30912 | valid_mse: 0.09556 |  0:00:37s\n",
      "epoch 34 | loss: 0.07655 | train_rmsle: 0.00464 | train_mae: 0.20465 | train_rmse: 0.26679 | train_mse: 0.07117 | valid_rmsle: 0.00595 | valid_mae: 0.23592 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:00:38s\n",
      "epoch 35 | loss: 0.07338 | train_rmsle: 0.00482 | train_mae: 0.20165 | train_rmse: 0.26877 | train_mse: 0.07224 | valid_rmsle: 0.00623 | valid_mae: 0.23774 | valid_rmse: 0.31321 | valid_mse: 0.0981  |  0:00:39s\n",
      "epoch 36 | loss: 0.07458 | train_rmsle: 0.00441 | train_mae: 0.20059 | train_rmse: 0.26083 | train_mse: 0.06803 | valid_rmsle: 0.00604 | valid_mae: 0.24325 | valid_rmse: 0.3114  | valid_mse: 0.09697 |  0:00:40s\n",
      "epoch 37 | loss: 0.06965 | train_rmsle: 0.00431 | train_mae: 0.19505 | train_rmse: 0.25677 | train_mse: 0.06593 | valid_rmsle: 0.00607 | valid_mae: 0.24122 | valid_rmse: 0.3113  | valid_mse: 0.09691 |  0:00:41s\n",
      "epoch 38 | loss: 0.0701  | train_rmsle: 0.00397 | train_mae: 0.18888 | train_rmse: 0.2475  | train_mse: 0.06126 | valid_rmsle: 0.00632 | valid_mae: 0.24482 | valid_rmse: 0.31589 | valid_mse: 0.09978 |  0:00:43s\n",
      "epoch 39 | loss: 0.07061 | train_rmsle: 0.0039  | train_mae: 0.18724 | train_rmse: 0.2455  | train_mse: 0.06027 | valid_rmsle: 0.00631 | valid_mae: 0.24538 | valid_rmse: 0.31727 | valid_mse: 0.10066 |  0:00:44s\n",
      "epoch 40 | loss: 0.06943 | train_rmsle: 0.00386 | train_mae: 0.18551 | train_rmse: 0.24425 | train_mse: 0.05966 | valid_rmsle: 0.00644 | valid_mae: 0.24392 | valid_rmse: 0.31962 | valid_mse: 0.10215 |  0:00:45s\n",
      "epoch 41 | loss: 0.0694  | train_rmsle: 0.00378 | train_mae: 0.18597 | train_rmse: 0.24316 | train_mse: 0.05912 | valid_rmsle: 0.00642 | valid_mae: 0.24736 | valid_rmse: 0.31995 | valid_mse: 0.10237 |  0:00:46s\n",
      "epoch 42 | loss: 0.06883 | train_rmsle: 0.00378 | train_mae: 0.18383 | train_rmse: 0.24184 | train_mse: 0.05849 | valid_rmsle: 0.00622 | valid_mae: 0.2418  | valid_rmse: 0.31548 | valid_mse: 0.09953 |  0:00:47s\n",
      "epoch 43 | loss: 0.06846 | train_rmsle: 0.00381 | train_mae: 0.18317 | train_rmse: 0.24143 | train_mse: 0.05829 | valid_rmsle: 0.00628 | valid_mae: 0.24243 | valid_rmse: 0.31609 | valid_mse: 0.09991 |  0:00:48s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_mse = 0.09313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09649207339249978 RMSE: 0.31063173275198364 R2: 0.5728667712795958 MAE: 0.2384033480735491\n",
      "=====================================\n",
      "[84/108] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.06696| train_rmsle: 0.18914 | train_mae: 1.48063 | train_rmse: 1.55501 | train_mse: 2.41804 | valid_rmsle: 0.18992 | valid_mae: 1.48508 | valid_rmse: 1.55906 | valid_mse: 2.43066 |  0:00:01s\n",
      "epoch 1  | loss: 2.58066 | train_rmsle: 0.12728 | train_mae: 1.24733 | train_rmse: 1.33011 | train_mse: 1.76919 | valid_rmsle: 0.12804 | valid_mae: 1.25149 | valid_rmse: 1.33497 | valid_mse: 1.78215 |  0:00:02s\n",
      "epoch 2  | loss: 1.04413 | train_rmsle: 0.04195 | train_mae: 0.73801 | train_rmse: 0.83113 | train_mse: 0.69077 | valid_rmsle: 0.042   | valid_mae: 0.73838 | valid_rmse: 0.83401 | valid_mse: 0.69557 |  0:00:03s\n",
      "epoch 3  | loss: 0.67605 | train_rmsle: 0.03039 | train_mae: 0.62575 | train_rmse: 0.71751 | train_mse: 0.51482 | valid_rmsle: 0.03034 | valid_mae: 0.62614 | valid_rmse: 0.71999 | valid_mse: 0.51838 |  0:00:04s\n",
      "epoch 4  | loss: 0.48168 | train_rmsle: 0.02373 | train_mae: 0.54767 | train_rmse: 0.63742 | train_mse: 0.4063  | valid_rmsle: 0.02352 | valid_mae: 0.54914 | valid_rmse: 0.63857 | valid_mse: 0.40778 |  0:00:05s\n",
      "epoch 5  | loss: 0.3782  | train_rmsle: 0.02101 | train_mae: 0.51129 | train_rmse: 0.59978 | train_mse: 0.35974 | valid_rmsle: 0.02074 | valid_mae: 0.51298 | valid_rmse: 0.60017 | valid_mse: 0.36021 |  0:00:06s\n",
      "epoch 6  | loss: 0.33025 | train_rmsle: 0.02203 | train_mae: 0.52547 | train_rmse: 0.61432 | train_mse: 0.37739 | valid_rmsle: 0.0218  | valid_mae: 0.52753 | valid_rmse: 0.61521 | valid_mse: 0.37848 |  0:00:07s\n",
      "epoch 7  | loss: 0.30833 | train_rmsle: 0.02081 | train_mae: 0.50857 | train_rmse: 0.59693 | train_mse: 0.35633 | valid_rmsle: 0.02048 | valid_mae: 0.51005 | valid_rmse: 0.59638 | valid_mse: 0.35567 |  0:00:08s\n",
      "epoch 8  | loss: 0.27466 | train_rmsle: 0.02004 | train_mae: 0.49777 | train_rmse: 0.58566 | train_mse: 0.343   | valid_rmsle: 0.01974 | valid_mae: 0.49959 | valid_rmse: 0.58555 | valid_mse: 0.34287 |  0:00:09s\n",
      "epoch 9  | loss: 0.25593 | train_rmsle: 0.01816 | train_mae: 0.46855 | train_rmse: 0.55572 | train_mse: 0.30882 | valid_rmsle: 0.01783 | valid_mae: 0.47003 | valid_rmse: 0.55534 | valid_mse: 0.3084  |  0:00:11s\n",
      "epoch 10 | loss: 0.23974 | train_rmsle: 0.01739 | train_mae: 0.46476 | train_rmse: 0.54598 | train_mse: 0.29809 | valid_rmsle: 0.01689 | valid_mae: 0.46353 | valid_rmse: 0.54241 | valid_mse: 0.29421 |  0:00:12s\n",
      "epoch 11 | loss: 0.20976 | train_rmsle: 0.01181 | train_mae: 0.36125 | train_rmse: 0.43729 | train_mse: 0.19122 | valid_rmsle: 0.01091 | valid_mae: 0.34593 | valid_rmse: 0.42335 | valid_mse: 0.17922 |  0:00:13s\n",
      "epoch 12 | loss: 0.16309 | train_rmsle: 0.0116  | train_mae: 0.33908 | train_rmse: 0.42552 | train_mse: 0.18107 | valid_rmsle: 0.01088 | valid_mae: 0.32728 | valid_rmse: 0.4141  | valid_mse: 0.17148 |  0:00:14s\n",
      "epoch 13 | loss: 0.13959 | train_rmsle: 0.01068 | train_mae: 0.32664 | train_rmse: 0.41231 | train_mse: 0.17    | valid_rmsle: 0.00991 | valid_mae: 0.31753 | valid_rmse: 0.40091 | valid_mse: 0.16073 |  0:00:15s\n",
      "epoch 14 | loss: 0.12105 | train_rmsle: 0.00867 | train_mae: 0.28963 | train_rmse: 0.36822 | train_mse: 0.13559 | valid_rmsle: 0.00799 | valid_mae: 0.27956 | valid_rmse: 0.35622 | valid_mse: 0.12689 |  0:00:16s\n",
      "epoch 15 | loss: 0.1143  | train_rmsle: 0.00837 | train_mae: 0.28821 | train_rmse: 0.36406 | train_mse: 0.13254 | valid_rmsle: 0.0079  | valid_mae: 0.28043 | valid_rmse: 0.35569 | valid_mse: 0.12652 |  0:00:17s\n",
      "epoch 16 | loss: 0.11111 | train_rmsle: 0.00767 | train_mae: 0.27332 | train_rmse: 0.35038 | train_mse: 0.12277 | valid_rmsle: 0.00729 | valid_mae: 0.27262 | valid_rmse: 0.34662 | valid_mse: 0.12014 |  0:00:18s\n",
      "epoch 17 | loss: 0.10367 | train_rmsle: 0.00718 | train_mae: 0.25978 | train_rmse: 0.33391 | train_mse: 0.1115  | valid_rmsle: 0.00667 | valid_mae: 0.25278 | valid_rmse: 0.32546 | valid_mse: 0.10592 |  0:00:19s\n",
      "epoch 18 | loss: 0.10336 | train_rmsle: 0.00692 | train_mae: 0.25229 | train_rmse: 0.32697 | train_mse: 0.10691 | valid_rmsle: 0.00649 | valid_mae: 0.24465 | valid_rmse: 0.32002 | valid_mse: 0.10241 |  0:00:20s\n",
      "epoch 19 | loss: 0.09742 | train_rmsle: 0.00726 | train_mae: 0.25871 | train_rmse: 0.33479 | train_mse: 0.11208 | valid_rmsle: 0.00682 | valid_mae: 0.25211 | valid_rmse: 0.32737 | valid_mse: 0.10717 |  0:00:22s\n",
      "epoch 20 | loss: 0.09306 | train_rmsle: 0.00675 | train_mae: 0.25018 | train_rmse: 0.32287 | train_mse: 0.10424 | valid_rmsle: 0.00647 | valid_mae: 0.24627 | valid_rmse: 0.31861 | valid_mse: 0.10151 |  0:00:23s\n",
      "epoch 21 | loss: 0.0923  | train_rmsle: 0.00701 | train_mae: 0.25298 | train_rmse: 0.32721 | train_mse: 0.10707 | valid_rmsle: 0.00652 | valid_mae: 0.24846 | valid_rmse: 0.3195  | valid_mse: 0.10208 |  0:00:24s\n",
      "epoch 22 | loss: 0.08963 | train_rmsle: 0.00691 | train_mae: 0.25184 | train_rmse: 0.325   | train_mse: 0.10563 | valid_rmsle: 0.00649 | valid_mae: 0.24738 | valid_rmse: 0.31832 | valid_mse: 0.10133 |  0:00:25s\n",
      "epoch 23 | loss: 0.08909 | train_rmsle: 0.00614 | train_mae: 0.23535 | train_rmse: 0.30608 | train_mse: 0.09369 | valid_rmsle: 0.00596 | valid_mae: 0.2355  | valid_rmse: 0.30517 | valid_mse: 0.09313 |  0:00:26s\n",
      "epoch 24 | loss: 0.08668 | train_rmsle: 0.00627 | train_mae: 0.24178 | train_rmse: 0.31128 | train_mse: 0.09689 | valid_rmsle: 0.00614 | valid_mae: 0.24114 | valid_rmse: 0.31085 | valid_mse: 0.09663 |  0:00:27s\n",
      "epoch 25 | loss: 0.08542 | train_rmsle: 0.00598 | train_mae: 0.22994 | train_rmse: 0.30119 | train_mse: 0.09072 | valid_rmsle: 0.00599 | valid_mae: 0.23274 | valid_rmse: 0.306   | valid_mse: 0.09364 |  0:00:28s\n",
      "epoch 26 | loss: 0.08482 | train_rmsle: 0.00594 | train_mae: 0.23396 | train_rmse: 0.30199 | train_mse: 0.0912  | valid_rmsle: 0.00609 | valid_mae: 0.24018 | valid_rmse: 0.31006 | valid_mse: 0.09614 |  0:00:29s\n",
      "epoch 27 | loss: 0.08289 | train_rmsle: 0.0059  | train_mae: 0.23458 | train_rmse: 0.30152 | train_mse: 0.09091 | valid_rmsle: 0.00619 | valid_mae: 0.24404 | valid_rmse: 0.31294 | valid_mse: 0.09793 |  0:00:30s\n",
      "epoch 28 | loss: 0.08312 | train_rmsle: 0.00568 | train_mae: 0.22892 | train_rmse: 0.29548 | train_mse: 0.08731 | valid_rmsle: 0.00626 | valid_mae: 0.24095 | valid_rmse: 0.31363 | valid_mse: 0.09837 |  0:00:31s\n",
      "epoch 29 | loss: 0.07975 | train_rmsle: 0.00541 | train_mae: 0.21885 | train_rmse: 0.28607 | train_mse: 0.08184 | valid_rmsle: 0.00597 | valid_mae: 0.23315 | valid_rmse: 0.3057  | valid_mse: 0.09345 |  0:00:33s\n",
      "epoch 30 | loss: 0.07889 | train_rmsle: 0.00535 | train_mae: 0.21958 | train_rmse: 0.28551 | train_mse: 0.08152 | valid_rmsle: 0.00613 | valid_mae: 0.23691 | valid_rmse: 0.31049 | valid_mse: 0.09641 |  0:00:34s\n",
      "epoch 31 | loss: 0.07727 | train_rmsle: 0.00508 | train_mae: 0.21258 | train_rmse: 0.27803 | train_mse: 0.0773  | valid_rmsle: 0.00625 | valid_mae: 0.23879 | valid_rmse: 0.31285 | valid_mse: 0.09788 |  0:00:35s\n",
      "epoch 32 | loss: 0.07702 | train_rmsle: 0.00485 | train_mae: 0.2112  | train_rmse: 0.27313 | train_mse: 0.0746  | valid_rmsle: 0.006   | valid_mae: 0.23656 | valid_rmse: 0.30725 | valid_mse: 0.0944  |  0:00:36s\n",
      "epoch 33 | loss: 0.07572 | train_rmsle: 0.00464 | train_mae: 0.20249 | train_rmse: 0.26566 | train_mse: 0.07058 | valid_rmsle: 0.0061  | valid_mae: 0.23439 | valid_rmse: 0.30912 | valid_mse: 0.09556 |  0:00:37s\n",
      "epoch 34 | loss: 0.07655 | train_rmsle: 0.00464 | train_mae: 0.20465 | train_rmse: 0.26679 | train_mse: 0.07117 | valid_rmsle: 0.00595 | valid_mae: 0.23592 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:00:38s\n",
      "epoch 35 | loss: 0.07338 | train_rmsle: 0.00482 | train_mae: 0.20165 | train_rmse: 0.26877 | train_mse: 0.07224 | valid_rmsle: 0.00623 | valid_mae: 0.23774 | valid_rmse: 0.31321 | valid_mse: 0.0981  |  0:00:39s\n",
      "epoch 36 | loss: 0.07458 | train_rmsle: 0.00441 | train_mae: 0.20059 | train_rmse: 0.26083 | train_mse: 0.06803 | valid_rmsle: 0.00604 | valid_mae: 0.24325 | valid_rmse: 0.3114  | valid_mse: 0.09697 |  0:00:40s\n",
      "epoch 37 | loss: 0.06965 | train_rmsle: 0.00431 | train_mae: 0.19505 | train_rmse: 0.25677 | train_mse: 0.06593 | valid_rmsle: 0.00607 | valid_mae: 0.24122 | valid_rmse: 0.3113  | valid_mse: 0.09691 |  0:00:41s\n",
      "epoch 38 | loss: 0.0701  | train_rmsle: 0.00397 | train_mae: 0.18888 | train_rmse: 0.2475  | train_mse: 0.06126 | valid_rmsle: 0.00632 | valid_mae: 0.24482 | valid_rmse: 0.31589 | valid_mse: 0.09978 |  0:00:42s\n",
      "epoch 39 | loss: 0.07061 | train_rmsle: 0.0039  | train_mae: 0.18724 | train_rmse: 0.2455  | train_mse: 0.06027 | valid_rmsle: 0.00631 | valid_mae: 0.24538 | valid_rmse: 0.31727 | valid_mse: 0.10066 |  0:00:44s\n",
      "epoch 40 | loss: 0.06943 | train_rmsle: 0.00386 | train_mae: 0.18551 | train_rmse: 0.24425 | train_mse: 0.05966 | valid_rmsle: 0.00644 | valid_mae: 0.24392 | valid_rmse: 0.31962 | valid_mse: 0.10215 |  0:00:45s\n",
      "epoch 41 | loss: 0.0694  | train_rmsle: 0.00378 | train_mae: 0.18597 | train_rmse: 0.24316 | train_mse: 0.05912 | valid_rmsle: 0.00642 | valid_mae: 0.24736 | valid_rmse: 0.31995 | valid_mse: 0.10237 |  0:00:46s\n",
      "epoch 42 | loss: 0.06883 | train_rmsle: 0.00378 | train_mae: 0.18383 | train_rmse: 0.24184 | train_mse: 0.05849 | valid_rmsle: 0.00622 | valid_mae: 0.2418  | valid_rmse: 0.31548 | valid_mse: 0.09953 |  0:00:47s\n",
      "epoch 43 | loss: 0.06846 | train_rmsle: 0.00381 | train_mae: 0.18317 | train_rmse: 0.24143 | train_mse: 0.05829 | valid_rmsle: 0.00628 | valid_mae: 0.24243 | valid_rmse: 0.31609 | valid_mse: 0.09991 |  0:00:48s\n",
      "\n",
      "Early stopping occurred at epoch 43 with best_epoch = 23 and best_valid_mse = 0.09313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09649207339249978 RMSE: 0.31063173275198364 R2: 0.5728667712795958 MAE: 0.2384033480735491\n",
      "=====================================\n",
      "[85/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.49595 | train_rmsle: 0.25339 | train_mae: 1.66944 | train_rmse: 1.73779 | train_mse: 3.01992 | valid_rmsle: 0.25516 | valid_mae: 1.67669 | valid_rmse: 1.74425 | valid_mse: 3.04241 |  0:00:01s\n",
      "epoch 1  | loss: 0.68901 | train_rmsle: 0.12799 | train_mae: 1.25026 | train_rmse: 1.33312 | train_mse: 1.7772  | valid_rmsle: 0.12859 | valid_mae: 1.25369 | valid_rmse: 1.33734 | valid_mse: 1.78847 |  0:00:03s\n",
      "epoch 2  | loss: 0.36487 | train_rmsle: 0.10927 | train_mae: 1.16508 | train_rmse: 1.25029 | train_mse: 1.56324 | valid_rmsle: 0.10985 | valid_mae: 1.1683  | valid_rmse: 1.25477 | valid_mse: 1.57445 |  0:00:04s\n",
      "epoch 3  | loss: 0.31525 | train_rmsle: 0.08541 | train_mae: 1.04073 | train_rmse: 1.1293  | train_mse: 1.27531 | valid_rmsle: 0.08568 | valid_mae: 1.04268 | valid_rmse: 1.13258 | valid_mse: 1.28273 |  0:00:05s\n",
      "epoch 4  | loss: 0.28473 | train_rmsle: 0.03898 | train_mae: 0.71155 | train_rmse: 0.80416 | train_mse: 0.64667 | valid_rmsle: 0.0389  | valid_mae: 0.71111 | valid_rmse: 0.80603 | valid_mse: 0.64968 |  0:00:07s\n",
      "epoch 5  | loss: 0.2469  | train_rmsle: 0.03499 | train_mae: 0.67332 | train_rmse: 0.76575 | train_mse: 0.58637 | valid_rmsle: 0.03505 | valid_mae: 0.67479 | valid_rmse: 0.76904 | valid_mse: 0.59142 |  0:00:08s\n",
      "epoch 6  | loss: 0.24164 | train_rmsle: 0.03    | train_mae: 0.62198 | train_rmse: 0.71304 | train_mse: 0.50843 | valid_rmsle: 0.03004 | valid_mae: 0.62368 | valid_rmse: 0.7165  | valid_mse: 0.51337 |  0:00:10s\n",
      "epoch 7  | loss: 0.23761 | train_rmsle: 0.01821 | train_mae: 0.46887 | train_rmse: 0.55648 | train_mse: 0.30967 | valid_rmsle: 0.0179  | valid_mae: 0.47142 | valid_rmse: 0.55645 | valid_mse: 0.30963 |  0:00:11s\n",
      "epoch 8  | loss: 0.23888 | train_rmsle: 0.01668 | train_mae: 0.4418  | train_rmse: 0.52992 | train_mse: 0.28082 | valid_rmsle: 0.01633 | valid_mae: 0.44542 | valid_rmse: 0.52927 | valid_mse: 0.28013 |  0:00:13s\n",
      "epoch 9  | loss: 0.23455 | train_rmsle: 0.01677 | train_mae: 0.44347 | train_rmse: 0.53146 | train_mse: 0.28245 | valid_rmsle: 0.01637 | valid_mae: 0.44638 | valid_rmse: 0.53008 | valid_mse: 0.28099 |  0:00:14s\n",
      "epoch 10 | loss: 0.22851 | train_rmsle: 0.01561 | train_mae: 0.41861 | train_rmse: 0.50853 | train_mse: 0.2586  | valid_rmsle: 0.01501 | valid_mae: 0.41817 | valid_rmse: 0.50392 | valid_mse: 0.25394 |  0:00:15s\n",
      "epoch 11 | loss: 0.22824 | train_rmsle: 0.01579 | train_mae: 0.42471 | train_rmse: 0.51359 | train_mse: 0.26377 | valid_rmsle: 0.01528 | valid_mae: 0.4254  | valid_rmse: 0.51059 | valid_mse: 0.2607  |  0:00:17s\n",
      "epoch 12 | loss: 0.23593 | train_rmsle: 0.01464 | train_mae: 0.38363 | train_rmse: 0.48311 | train_mse: 0.2334  | valid_rmsle: 0.0141  | valid_mae: 0.38587 | valid_rmse: 0.47947 | valid_mse: 0.22989 |  0:00:18s\n",
      "epoch 13 | loss: 0.23634 | train_rmsle: 0.01486 | train_mae: 0.39598 | train_rmse: 0.49063 | train_mse: 0.24072 | valid_rmsle: 0.01436 | valid_mae: 0.39749 | valid_rmse: 0.48752 | valid_mse: 0.23767 |  0:00:20s\n",
      "epoch 14 | loss: 0.22241 | train_rmsle: 0.01545 | train_mae: 0.41836 | train_rmse: 0.50715 | train_mse: 0.2572  | valid_rmsle: 0.01495 | valid_mae: 0.41881 | valid_rmse: 0.50406 | valid_mse: 0.25407 |  0:00:21s\n",
      "epoch 15 | loss: 0.2231  | train_rmsle: 0.01643 | train_mae: 0.43945 | train_rmse: 0.52718 | train_mse: 0.27792 | valid_rmsle: 0.01598 | valid_mae: 0.44038 | valid_rmse: 0.52493 | valid_mse: 0.27555 |  0:00:23s\n",
      "epoch 16 | loss: 0.22186 | train_rmsle: 0.01838 | train_mae: 0.47141 | train_rmse: 0.56036 | train_mse: 0.314   | valid_rmsle: 0.01811 | valid_mae: 0.47246 | valid_rmse: 0.56081 | valid_mse: 0.3145  |  0:00:24s\n",
      "epoch 17 | loss: 0.22365 | train_rmsle: 0.01521 | train_mae: 0.41414 | train_rmse: 0.50296 | train_mse: 0.25297 | valid_rmsle: 0.01474 | valid_mae: 0.41544 | valid_rmse: 0.50047 | valid_mse: 0.25047 |  0:00:26s\n",
      "epoch 18 | loss: 0.2175  | train_rmsle: 0.01472 | train_mae: 0.40358 | train_rmse: 0.49313 | train_mse: 0.24318 | valid_rmsle: 0.0143  | valid_mae: 0.40589 | valid_rmse: 0.4915  | valid_mse: 0.24158 |  0:00:27s\n",
      "epoch 19 | loss: 0.21615 | train_rmsle: 0.01539 | train_mae: 0.41939 | train_rmse: 0.50794 | train_mse: 0.258   | valid_rmsle: 0.01502 | valid_mae: 0.42126 | valid_rmse: 0.50725 | valid_mse: 0.2573  |  0:00:28s\n",
      "epoch 20 | loss: 0.21417 | train_rmsle: 0.01465 | train_mae: 0.4051  | train_rmse: 0.49441 | train_mse: 0.24444 | valid_rmsle: 0.01442 | valid_mae: 0.40865 | valid_rmse: 0.49609 | valid_mse: 0.2461  |  0:00:30s\n",
      "epoch 21 | loss: 0.21138 | train_rmsle: 0.01409 | train_mae: 0.39397 | train_rmse: 0.48346 | train_mse: 0.23373 | valid_rmsle: 0.01396 | valid_mae: 0.40166 | valid_rmse: 0.48728 | valid_mse: 0.23744 |  0:00:31s\n",
      "epoch 22 | loss: 0.20891 | train_rmsle: 0.01327 | train_mae: 0.37149 | train_rmse: 0.46351 | train_mse: 0.21484 | valid_rmsle: 0.01309 | valid_mae: 0.37872 | valid_rmse: 0.46651 | valid_mse: 0.21763 |  0:00:33s\n",
      "epoch 23 | loss: 0.20709 | train_rmsle: 0.01378 | train_mae: 0.39185 | train_rmse: 0.47861 | train_mse: 0.22906 | valid_rmsle: 0.01373 | valid_mae: 0.402   | valid_rmse: 0.48353 | valid_mse: 0.2338  |  0:00:34s\n",
      "epoch 24 | loss: 0.19133 | train_rmsle: 0.01131 | train_mae: 0.33634 | train_rmse: 0.42473 | train_mse: 0.18039 | valid_rmsle: 0.01128 | valid_mae: 0.34861 | valid_rmse: 0.43143 | valid_mse: 0.18613 |  0:00:36s\n",
      "epoch 25 | loss: 0.17035 | train_rmsle: 0.00923 | train_mae: 0.29644 | train_rmse: 0.37938 | train_mse: 0.14393 | valid_rmsle: 0.00935 | valid_mae: 0.30985 | valid_rmse: 0.38914 | valid_mse: 0.15143 |  0:00:37s\n",
      "epoch 26 | loss: 0.15098 | train_rmsle: 0.01019 | train_mae: 0.34153 | train_rmse: 0.41089 | train_mse: 0.16883 | valid_rmsle: 0.01002 | valid_mae: 0.3425  | valid_rmse: 0.41312 | valid_mse: 0.17067 |  0:00:38s\n",
      "epoch 27 | loss: 0.1364  | train_rmsle: 0.00839 | train_mae: 0.29743 | train_rmse: 0.36656 | train_mse: 0.13437 | valid_rmsle: 0.00802 | valid_mae: 0.29534 | valid_rmse: 0.36423 | valid_mse: 0.13267 |  0:00:40s\n",
      "epoch 28 | loss: 0.11581 | train_rmsle: 0.00734 | train_mae: 0.26933 | train_rmse: 0.33809 | train_mse: 0.11431 | valid_rmsle: 0.00697 | valid_mae: 0.26526 | valid_rmse: 0.33496 | valid_mse: 0.1122  |  0:00:41s\n",
      "epoch 29 | loss: 0.10191 | train_rmsle: 0.00777 | train_mae: 0.28666 | train_rmse: 0.35164 | train_mse: 0.12365 | valid_rmsle: 0.00766 | valid_mae: 0.28891 | valid_rmse: 0.35446 | valid_mse: 0.12565 |  0:00:43s\n",
      "epoch 30 | loss: 0.08792 | train_rmsle: 0.00634 | train_mae: 0.25072 | train_rmse: 0.31476 | train_mse: 0.09907 | valid_rmsle: 0.00637 | valid_mae: 0.25715 | valid_rmse: 0.31995 | valid_mse: 0.10237 |  0:00:44s\n",
      "epoch 31 | loss: 0.07499 | train_rmsle: 0.00426 | train_mae: 0.20903 | train_rmse: 0.26485 | train_mse: 0.07015 | valid_rmsle: 0.00448 | valid_mae: 0.22109 | valid_rmse: 0.2757  | valid_mse: 0.07601 |  0:00:46s\n",
      "epoch 32 | loss: 0.06929 | train_rmsle: 0.00384 | train_mae: 0.19726 | train_rmse: 0.2514  | train_mse: 0.0632  | valid_rmsle: 0.00417 | valid_mae: 0.2115  | valid_rmse: 0.26663 | valid_mse: 0.07109 |  0:00:47s\n",
      "epoch 33 | loss: 0.05978 | train_rmsle: 0.00288 | train_mae: 0.17172 | train_rmse: 0.22061 | train_mse: 0.04867 | valid_rmsle: 0.00314 | valid_mae: 0.183   | valid_rmse: 0.23345 | valid_mse: 0.0545  |  0:00:49s\n",
      "epoch 34 | loss: 0.05236 | train_rmsle: 0.00284 | train_mae: 0.16708 | train_rmse: 0.21417 | train_mse: 0.04587 | valid_rmsle: 0.00312 | valid_mae: 0.17937 | valid_rmse: 0.22878 | valid_mse: 0.05234 |  0:00:50s\n",
      "epoch 35 | loss: 0.061   | train_rmsle: 0.00399 | train_mae: 0.20626 | train_rmse: 0.26128 | train_mse: 0.06827 | valid_rmsle: 0.0043  | valid_mae: 0.21615 | valid_rmse: 0.27365 | valid_mse: 0.07488 |  0:00:52s\n",
      "epoch 36 | loss: 0.05627 | train_rmsle: 0.00262 | train_mae: 0.16359 | train_rmse: 0.20984 | train_mse: 0.04403 | valid_rmsle: 0.0031  | valid_mae: 0.18103 | valid_rmse: 0.23065 | valid_mse: 0.0532  |  0:00:53s\n",
      "epoch 37 | loss: 0.04082 | train_rmsle: 0.0019  | train_mae: 0.13923 | train_rmse: 0.18068 | train_mse: 0.03265 | valid_rmsle: 0.00236 | valid_mae: 0.15801 | valid_rmse: 0.20383 | valid_mse: 0.04155 |  0:00:54s\n",
      "epoch 38 | loss: 0.0382  | train_rmsle: 0.00177 | train_mae: 0.13581 | train_rmse: 0.17651 | train_mse: 0.03116 | valid_rmsle: 0.00222 | valid_mae: 0.15471 | valid_rmse: 0.1994  | valid_mse: 0.03976 |  0:00:56s\n",
      "epoch 39 | loss: 0.03422 | train_rmsle: 0.00167 | train_mae: 0.13195 | train_rmse: 0.17176 | train_mse: 0.0295  | valid_rmsle: 0.00205 | valid_mae: 0.14707 | valid_rmse: 0.19209 | valid_mse: 0.0369  |  0:00:57s\n",
      "epoch 40 | loss: 0.03408 | train_rmsle: 0.0015  | train_mae: 0.12505 | train_rmse: 0.16329 | train_mse: 0.02666 | valid_rmsle: 0.00189 | valid_mae: 0.14033 | valid_rmse: 0.18417 | valid_mse: 0.03392 |  0:00:59s\n",
      "epoch 41 | loss: 0.03153 | train_rmsle: 0.00145 | train_mae: 0.12322 | train_rmse: 0.16167 | train_mse: 0.02614 | valid_rmsle: 0.00178 | valid_mae: 0.13658 | valid_rmse: 0.17979 | valid_mse: 0.03233 |  0:01:00s\n",
      "epoch 42 | loss: 0.02812 | train_rmsle: 0.00141 | train_mae: 0.12499 | train_rmse: 0.16235 | train_mse: 0.02636 | valid_rmsle: 0.00182 | valid_mae: 0.14206 | valid_rmse: 0.18427 | valid_mse: 0.03396 |  0:01:02s\n",
      "epoch 43 | loss: 0.02677 | train_rmsle: 0.00203 | train_mae: 0.15205 | train_rmse: 0.18475 | train_mse: 0.03413 | valid_rmsle: 0.00242 | valid_mae: 0.1663  | valid_rmse: 0.20435 | valid_mse: 0.04176 |  0:01:03s\n",
      "epoch 44 | loss: 0.02811 | train_rmsle: 0.00201 | train_mae: 0.14875 | train_rmse: 0.18222 | train_mse: 0.0332  | valid_rmsle: 0.00241 | valid_mae: 0.1642  | valid_rmse: 0.20189 | valid_mse: 0.04076 |  0:01:05s\n",
      "epoch 45 | loss: 0.03048 | train_rmsle: 0.00132 | train_mae: 0.11846 | train_rmse: 0.15315 | train_mse: 0.02345 | valid_rmsle: 0.00163 | valid_mae: 0.13252 | valid_rmse: 0.17063 | valid_mse: 0.02912 |  0:01:06s\n",
      "epoch 46 | loss: 0.02591 | train_rmsle: 0.00114 | train_mae: 0.11089 | train_rmse: 0.14312 | train_mse: 0.02048 | valid_rmsle: 0.00145 | valid_mae: 0.12595 | valid_rmse: 0.16217 | valid_mse: 0.0263  |  0:01:08s\n",
      "epoch 47 | loss: 0.0253  | train_rmsle: 0.00105 | train_mae: 0.10692 | train_rmse: 0.13949 | train_mse: 0.01946 | valid_rmsle: 0.00137 | valid_mae: 0.1231  | valid_rmse: 0.1593  | valid_mse: 0.02538 |  0:01:09s\n",
      "epoch 48 | loss: 0.02733 | train_rmsle: 0.00118 | train_mae: 0.11651 | train_rmse: 0.14516 | train_mse: 0.02107 | valid_rmsle: 0.00154 | valid_mae: 0.13181 | valid_rmse: 0.1661  | valid_mse: 0.02759 |  0:01:10s\n",
      "epoch 49 | loss: 0.02091 | train_rmsle: 0.00082 | train_mae: 0.09274 | train_rmse: 0.12088 | train_mse: 0.01461 | valid_rmsle: 0.00116 | valid_mae: 0.1105  | valid_rmse: 0.14485 | valid_mse: 0.02098 |  0:01:12s\n",
      "epoch 50 | loss: 0.01956 | train_rmsle: 0.00076 | train_mae: 0.08992 | train_rmse: 0.11766 | train_mse: 0.01384 | valid_rmsle: 0.00109 | valid_mae: 0.10774 | valid_rmse: 0.14174 | valid_mse: 0.02009 |  0:01:13s\n",
      "epoch 51 | loss: 0.02078 | train_rmsle: 0.00148 | train_mae: 0.13282 | train_rmse: 0.15876 | train_mse: 0.0252  | valid_rmsle: 0.00184 | valid_mae: 0.14712 | valid_rmse: 0.17973 | valid_mse: 0.0323  |  0:01:15s\n",
      "epoch 52 | loss: 0.02702 | train_rmsle: 0.00074 | train_mae: 0.08914 | train_rmse: 0.1162  | train_mse: 0.0135  | valid_rmsle: 0.00108 | valid_mae: 0.10768 | valid_rmse: 0.14101 | valid_mse: 0.01988 |  0:01:16s\n",
      "epoch 53 | loss: 0.01946 | train_rmsle: 0.00129 | train_mae: 0.12052 | train_rmse: 0.14991 | train_mse: 0.02247 | valid_rmsle: 0.00161 | valid_mae: 0.13591 | valid_rmse: 0.16915 | valid_mse: 0.02861 |  0:01:18s\n",
      "epoch 54 | loss: 0.02217 | train_rmsle: 0.00074 | train_mae: 0.0907  | train_rmse: 0.11643 | train_mse: 0.01355 | valid_rmsle: 0.00103 | valid_mae: 0.10743 | valid_rmse: 0.13797 | valid_mse: 0.01904 |  0:01:19s\n",
      "epoch 55 | loss: 0.02113 | train_rmsle: 0.00141 | train_mae: 0.11629 | train_rmse: 0.16554 | train_mse: 0.0274  | valid_rmsle: 0.00184 | valid_mae: 0.13444 | valid_rmse: 0.18917 | valid_mse: 0.03579 |  0:01:21s\n",
      "epoch 56 | loss: 0.02286 | train_rmsle: 0.0008  | train_mae: 0.09229 | train_rmse: 0.12083 | train_mse: 0.0146  | valid_rmsle: 0.00112 | valid_mae: 0.10969 | valid_rmse: 0.14371 | valid_mse: 0.02065 |  0:01:22s\n",
      "epoch 57 | loss: 0.01776 | train_rmsle: 0.00086 | train_mae: 0.10025 | train_rmse: 0.12621 | train_mse: 0.01593 | valid_rmsle: 0.00116 | valid_mae: 0.11572 | valid_rmse: 0.14667 | valid_mse: 0.02151 |  0:01:23s\n",
      "epoch 58 | loss: 0.02115 | train_rmsle: 0.00101 | train_mae: 0.11145 | train_rmse: 0.13727 | train_mse: 0.01884 | valid_rmsle: 0.00131 | valid_mae: 0.12408 | valid_rmse: 0.15603 | valid_mse: 0.02434 |  0:01:25s\n",
      "epoch 59 | loss: 0.01605 | train_rmsle: 0.00073 | train_mae: 0.087   | train_rmse: 0.11106 | train_mse: 0.01233 | valid_rmsle: 0.001   | valid_mae: 0.10231 | valid_rmse: 0.1318  | valid_mse: 0.01737 |  0:01:26s\n",
      "epoch 60 | loss: 0.01694 | train_rmsle: 0.00071 | train_mae: 0.08983 | train_rmse: 0.11265 | train_mse: 0.01269 | valid_rmsle: 0.00097 | valid_mae: 0.10448 | valid_rmse: 0.13247 | valid_mse: 0.01755 |  0:01:28s\n",
      "epoch 61 | loss: 0.01508 | train_rmsle: 0.00065 | train_mae: 0.08283 | train_rmse: 0.10643 | train_mse: 0.01133 | valid_rmsle: 0.00091 | valid_mae: 0.09943 | valid_rmse: 0.12717 | valid_mse: 0.01617 |  0:01:29s\n",
      "epoch 62 | loss: 0.01462 | train_rmsle: 0.00075 | train_mae: 0.09555 | train_rmse: 0.11896 | train_mse: 0.01415 | valid_rmsle: 0.00101 | valid_mae: 0.1091  | valid_rmse: 0.13787 | valid_mse: 0.01901 |  0:01:31s\n",
      "epoch 63 | loss: 0.01585 | train_rmsle: 0.0005  | train_mae: 0.07272 | train_rmse: 0.09557 | train_mse: 0.00913 | valid_rmsle: 0.00075 | valid_mae: 0.08977 | valid_rmse: 0.11764 | valid_mse: 0.01384 |  0:01:32s\n",
      "epoch 64 | loss: 0.01496 | train_rmsle: 0.00059 | train_mae: 0.07805 | train_rmse: 0.10137 | train_mse: 0.01028 | valid_rmsle: 0.00083 | valid_mae: 0.09384 | valid_rmse: 0.12253 | valid_mse: 0.01501 |  0:01:34s\n",
      "epoch 65 | loss: 0.01423 | train_rmsle: 0.00068 | train_mae: 0.08671 | train_rmse: 0.11497 | train_mse: 0.01322 | valid_rmsle: 0.00096 | valid_mae: 0.10293 | valid_rmse: 0.13638 | valid_mse: 0.0186  |  0:01:35s\n",
      "epoch 66 | loss: 0.01488 | train_rmsle: 0.00047 | train_mae: 0.0704  | train_rmse: 0.09269 | train_mse: 0.00859 | valid_rmsle: 0.00072 | valid_mae: 0.08729 | valid_rmse: 0.11488 | valid_mse: 0.0132  |  0:01:36s\n",
      "epoch 67 | loss: 0.01572 | train_rmsle: 0.00047 | train_mae: 0.07107 | train_rmse: 0.09249 | train_mse: 0.00855 | valid_rmsle: 0.00071 | valid_mae: 0.08687 | valid_rmse: 0.11366 | valid_mse: 0.01292 |  0:01:38s\n",
      "epoch 68 | loss: 0.01275 | train_rmsle: 0.00043 | train_mae: 0.06761 | train_rmse: 0.08788 | train_mse: 0.00772 | valid_rmsle: 0.00066 | valid_mae: 0.08294 | valid_rmse: 0.1089  | valid_mse: 0.01186 |  0:01:39s\n",
      "epoch 69 | loss: 0.01411 | train_rmsle: 0.00053 | train_mae: 0.0766  | train_rmse: 0.09657 | train_mse: 0.00933 | valid_rmsle: 0.00076 | valid_mae: 0.09059 | valid_rmse: 0.11636 | valid_mse: 0.01354 |  0:01:41s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.01186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.012376599846692234 RMSE: 0.11125016785017555 R2: 0.9452135614125065 MAE: 0.08636304932218111\n",
      "=====================================\n",
      "[86/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.49595 | train_rmsle: 0.25339 | train_mae: 1.66944 | train_rmse: 1.73779 | train_mse: 3.01992 | valid_rmsle: 0.25516 | valid_mae: 1.67669 | valid_rmse: 1.74425 | valid_mse: 3.04241 |  0:00:01s\n",
      "epoch 1  | loss: 0.68901 | train_rmsle: 0.12799 | train_mae: 1.25026 | train_rmse: 1.33312 | train_mse: 1.7772  | valid_rmsle: 0.12859 | valid_mae: 1.25369 | valid_rmse: 1.33734 | valid_mse: 1.78847 |  0:00:03s\n",
      "epoch 2  | loss: 0.36487 | train_rmsle: 0.10927 | train_mae: 1.16508 | train_rmse: 1.25029 | train_mse: 1.56324 | valid_rmsle: 0.10985 | valid_mae: 1.1683  | valid_rmse: 1.25477 | valid_mse: 1.57445 |  0:00:04s\n",
      "epoch 3  | loss: 0.31525 | train_rmsle: 0.08541 | train_mae: 1.04073 | train_rmse: 1.1293  | train_mse: 1.27531 | valid_rmsle: 0.08568 | valid_mae: 1.04268 | valid_rmse: 1.13258 | valid_mse: 1.28273 |  0:00:05s\n",
      "epoch 4  | loss: 0.28473 | train_rmsle: 0.03898 | train_mae: 0.71155 | train_rmse: 0.80416 | train_mse: 0.64667 | valid_rmsle: 0.0389  | valid_mae: 0.71111 | valid_rmse: 0.80603 | valid_mse: 0.64968 |  0:00:07s\n",
      "epoch 5  | loss: 0.2469  | train_rmsle: 0.03499 | train_mae: 0.67332 | train_rmse: 0.76575 | train_mse: 0.58637 | valid_rmsle: 0.03505 | valid_mae: 0.67479 | valid_rmse: 0.76904 | valid_mse: 0.59142 |  0:00:08s\n",
      "epoch 6  | loss: 0.24164 | train_rmsle: 0.03    | train_mae: 0.62198 | train_rmse: 0.71304 | train_mse: 0.50843 | valid_rmsle: 0.03004 | valid_mae: 0.62368 | valid_rmse: 0.7165  | valid_mse: 0.51337 |  0:00:10s\n",
      "epoch 7  | loss: 0.23761 | train_rmsle: 0.01821 | train_mae: 0.46887 | train_rmse: 0.55648 | train_mse: 0.30967 | valid_rmsle: 0.0179  | valid_mae: 0.47142 | valid_rmse: 0.55645 | valid_mse: 0.30963 |  0:00:11s\n",
      "epoch 8  | loss: 0.23888 | train_rmsle: 0.01668 | train_mae: 0.4418  | train_rmse: 0.52992 | train_mse: 0.28082 | valid_rmsle: 0.01633 | valid_mae: 0.44542 | valid_rmse: 0.52927 | valid_mse: 0.28013 |  0:00:13s\n",
      "epoch 9  | loss: 0.23455 | train_rmsle: 0.01677 | train_mae: 0.44347 | train_rmse: 0.53146 | train_mse: 0.28245 | valid_rmsle: 0.01637 | valid_mae: 0.44638 | valid_rmse: 0.53008 | valid_mse: 0.28099 |  0:00:14s\n",
      "epoch 10 | loss: 0.22851 | train_rmsle: 0.01561 | train_mae: 0.41861 | train_rmse: 0.50853 | train_mse: 0.2586  | valid_rmsle: 0.01501 | valid_mae: 0.41817 | valid_rmse: 0.50392 | valid_mse: 0.25394 |  0:00:16s\n",
      "epoch 11 | loss: 0.22824 | train_rmsle: 0.01579 | train_mae: 0.42471 | train_rmse: 0.51359 | train_mse: 0.26377 | valid_rmsle: 0.01528 | valid_mae: 0.4254  | valid_rmse: 0.51059 | valid_mse: 0.2607  |  0:00:17s\n",
      "epoch 12 | loss: 0.23593 | train_rmsle: 0.01464 | train_mae: 0.38363 | train_rmse: 0.48311 | train_mse: 0.2334  | valid_rmsle: 0.0141  | valid_mae: 0.38587 | valid_rmse: 0.47947 | valid_mse: 0.22989 |  0:00:18s\n",
      "epoch 13 | loss: 0.23634 | train_rmsle: 0.01486 | train_mae: 0.39598 | train_rmse: 0.49063 | train_mse: 0.24072 | valid_rmsle: 0.01436 | valid_mae: 0.39749 | valid_rmse: 0.48752 | valid_mse: 0.23767 |  0:00:20s\n",
      "epoch 14 | loss: 0.22241 | train_rmsle: 0.01545 | train_mae: 0.41836 | train_rmse: 0.50715 | train_mse: 0.2572  | valid_rmsle: 0.01495 | valid_mae: 0.41881 | valid_rmse: 0.50406 | valid_mse: 0.25407 |  0:00:21s\n",
      "epoch 15 | loss: 0.2231  | train_rmsle: 0.01643 | train_mae: 0.43945 | train_rmse: 0.52718 | train_mse: 0.27792 | valid_rmsle: 0.01598 | valid_mae: 0.44038 | valid_rmse: 0.52493 | valid_mse: 0.27555 |  0:00:23s\n",
      "epoch 16 | loss: 0.22186 | train_rmsle: 0.01838 | train_mae: 0.47141 | train_rmse: 0.56036 | train_mse: 0.314   | valid_rmsle: 0.01811 | valid_mae: 0.47246 | valid_rmse: 0.56081 | valid_mse: 0.3145  |  0:00:24s\n",
      "epoch 17 | loss: 0.22365 | train_rmsle: 0.01521 | train_mae: 0.41414 | train_rmse: 0.50296 | train_mse: 0.25297 | valid_rmsle: 0.01474 | valid_mae: 0.41544 | valid_rmse: 0.50047 | valid_mse: 0.25047 |  0:00:26s\n",
      "epoch 18 | loss: 0.2175  | train_rmsle: 0.01472 | train_mae: 0.40358 | train_rmse: 0.49313 | train_mse: 0.24318 | valid_rmsle: 0.0143  | valid_mae: 0.40589 | valid_rmse: 0.4915  | valid_mse: 0.24158 |  0:00:27s\n",
      "epoch 19 | loss: 0.21615 | train_rmsle: 0.01539 | train_mae: 0.41939 | train_rmse: 0.50794 | train_mse: 0.258   | valid_rmsle: 0.01502 | valid_mae: 0.42126 | valid_rmse: 0.50725 | valid_mse: 0.2573  |  0:00:29s\n",
      "epoch 20 | loss: 0.21417 | train_rmsle: 0.01465 | train_mae: 0.4051  | train_rmse: 0.49441 | train_mse: 0.24444 | valid_rmsle: 0.01442 | valid_mae: 0.40865 | valid_rmse: 0.49609 | valid_mse: 0.2461  |  0:00:30s\n",
      "epoch 21 | loss: 0.21138 | train_rmsle: 0.01409 | train_mae: 0.39397 | train_rmse: 0.48346 | train_mse: 0.23373 | valid_rmsle: 0.01396 | valid_mae: 0.40166 | valid_rmse: 0.48728 | valid_mse: 0.23744 |  0:00:31s\n",
      "epoch 22 | loss: 0.20891 | train_rmsle: 0.01327 | train_mae: 0.37149 | train_rmse: 0.46351 | train_mse: 0.21484 | valid_rmsle: 0.01309 | valid_mae: 0.37872 | valid_rmse: 0.46651 | valid_mse: 0.21763 |  0:00:33s\n",
      "epoch 23 | loss: 0.20709 | train_rmsle: 0.01378 | train_mae: 0.39185 | train_rmse: 0.47861 | train_mse: 0.22906 | valid_rmsle: 0.01373 | valid_mae: 0.402   | valid_rmse: 0.48353 | valid_mse: 0.2338  |  0:00:34s\n",
      "epoch 24 | loss: 0.19133 | train_rmsle: 0.01131 | train_mae: 0.33634 | train_rmse: 0.42473 | train_mse: 0.18039 | valid_rmsle: 0.01128 | valid_mae: 0.34861 | valid_rmse: 0.43143 | valid_mse: 0.18613 |  0:00:36s\n",
      "epoch 25 | loss: 0.17035 | train_rmsle: 0.00923 | train_mae: 0.29644 | train_rmse: 0.37938 | train_mse: 0.14393 | valid_rmsle: 0.00935 | valid_mae: 0.30985 | valid_rmse: 0.38914 | valid_mse: 0.15143 |  0:00:37s\n",
      "epoch 26 | loss: 0.15098 | train_rmsle: 0.01019 | train_mae: 0.34153 | train_rmse: 0.41089 | train_mse: 0.16883 | valid_rmsle: 0.01002 | valid_mae: 0.3425  | valid_rmse: 0.41312 | valid_mse: 0.17067 |  0:00:39s\n",
      "epoch 27 | loss: 0.1364  | train_rmsle: 0.00839 | train_mae: 0.29743 | train_rmse: 0.36656 | train_mse: 0.13437 | valid_rmsle: 0.00802 | valid_mae: 0.29534 | valid_rmse: 0.36423 | valid_mse: 0.13267 |  0:00:40s\n",
      "epoch 28 | loss: 0.11581 | train_rmsle: 0.00734 | train_mae: 0.26933 | train_rmse: 0.33809 | train_mse: 0.11431 | valid_rmsle: 0.00697 | valid_mae: 0.26526 | valid_rmse: 0.33496 | valid_mse: 0.1122  |  0:00:41s\n",
      "epoch 29 | loss: 0.10191 | train_rmsle: 0.00777 | train_mae: 0.28666 | train_rmse: 0.35164 | train_mse: 0.12365 | valid_rmsle: 0.00766 | valid_mae: 0.28891 | valid_rmse: 0.35446 | valid_mse: 0.12565 |  0:00:43s\n",
      "epoch 30 | loss: 0.08792 | train_rmsle: 0.00634 | train_mae: 0.25072 | train_rmse: 0.31476 | train_mse: 0.09907 | valid_rmsle: 0.00637 | valid_mae: 0.25715 | valid_rmse: 0.31995 | valid_mse: 0.10237 |  0:00:44s\n",
      "epoch 31 | loss: 0.07499 | train_rmsle: 0.00426 | train_mae: 0.20903 | train_rmse: 0.26485 | train_mse: 0.07015 | valid_rmsle: 0.00448 | valid_mae: 0.22109 | valid_rmse: 0.2757  | valid_mse: 0.07601 |  0:00:46s\n",
      "epoch 32 | loss: 0.06929 | train_rmsle: 0.00384 | train_mae: 0.19726 | train_rmse: 0.2514  | train_mse: 0.0632  | valid_rmsle: 0.00417 | valid_mae: 0.2115  | valid_rmse: 0.26663 | valid_mse: 0.07109 |  0:00:47s\n",
      "epoch 33 | loss: 0.05978 | train_rmsle: 0.00288 | train_mae: 0.17172 | train_rmse: 0.22061 | train_mse: 0.04867 | valid_rmsle: 0.00314 | valid_mae: 0.183   | valid_rmse: 0.23345 | valid_mse: 0.0545  |  0:00:49s\n",
      "epoch 34 | loss: 0.05236 | train_rmsle: 0.00284 | train_mae: 0.16708 | train_rmse: 0.21417 | train_mse: 0.04587 | valid_rmsle: 0.00312 | valid_mae: 0.17937 | valid_rmse: 0.22878 | valid_mse: 0.05234 |  0:00:50s\n",
      "epoch 35 | loss: 0.061   | train_rmsle: 0.00399 | train_mae: 0.20626 | train_rmse: 0.26128 | train_mse: 0.06827 | valid_rmsle: 0.0043  | valid_mae: 0.21615 | valid_rmse: 0.27365 | valid_mse: 0.07488 |  0:00:52s\n",
      "epoch 36 | loss: 0.05627 | train_rmsle: 0.00262 | train_mae: 0.16359 | train_rmse: 0.20984 | train_mse: 0.04403 | valid_rmsle: 0.0031  | valid_mae: 0.18103 | valid_rmse: 0.23065 | valid_mse: 0.0532  |  0:00:53s\n",
      "epoch 37 | loss: 0.04082 | train_rmsle: 0.0019  | train_mae: 0.13923 | train_rmse: 0.18068 | train_mse: 0.03265 | valid_rmsle: 0.00236 | valid_mae: 0.15801 | valid_rmse: 0.20383 | valid_mse: 0.04155 |  0:00:55s\n",
      "epoch 38 | loss: 0.0382  | train_rmsle: 0.00177 | train_mae: 0.13581 | train_rmse: 0.17651 | train_mse: 0.03116 | valid_rmsle: 0.00222 | valid_mae: 0.15471 | valid_rmse: 0.1994  | valid_mse: 0.03976 |  0:00:56s\n",
      "epoch 39 | loss: 0.03422 | train_rmsle: 0.00167 | train_mae: 0.13195 | train_rmse: 0.17176 | train_mse: 0.0295  | valid_rmsle: 0.00205 | valid_mae: 0.14707 | valid_rmse: 0.19209 | valid_mse: 0.0369  |  0:00:57s\n",
      "epoch 40 | loss: 0.03408 | train_rmsle: 0.0015  | train_mae: 0.12505 | train_rmse: 0.16329 | train_mse: 0.02666 | valid_rmsle: 0.00189 | valid_mae: 0.14033 | valid_rmse: 0.18417 | valid_mse: 0.03392 |  0:00:59s\n",
      "epoch 41 | loss: 0.03153 | train_rmsle: 0.00145 | train_mae: 0.12322 | train_rmse: 0.16167 | train_mse: 0.02614 | valid_rmsle: 0.00178 | valid_mae: 0.13658 | valid_rmse: 0.17979 | valid_mse: 0.03233 |  0:01:00s\n",
      "epoch 42 | loss: 0.02812 | train_rmsle: 0.00141 | train_mae: 0.12499 | train_rmse: 0.16235 | train_mse: 0.02636 | valid_rmsle: 0.00182 | valid_mae: 0.14206 | valid_rmse: 0.18427 | valid_mse: 0.03396 |  0:01:02s\n",
      "epoch 43 | loss: 0.02677 | train_rmsle: 0.00203 | train_mae: 0.15205 | train_rmse: 0.18475 | train_mse: 0.03413 | valid_rmsle: 0.00242 | valid_mae: 0.1663  | valid_rmse: 0.20435 | valid_mse: 0.04176 |  0:01:03s\n",
      "epoch 44 | loss: 0.02811 | train_rmsle: 0.00201 | train_mae: 0.14875 | train_rmse: 0.18222 | train_mse: 0.0332  | valid_rmsle: 0.00241 | valid_mae: 0.1642  | valid_rmse: 0.20189 | valid_mse: 0.04076 |  0:01:05s\n",
      "epoch 45 | loss: 0.03048 | train_rmsle: 0.00132 | train_mae: 0.11846 | train_rmse: 0.15315 | train_mse: 0.02345 | valid_rmsle: 0.00163 | valid_mae: 0.13252 | valid_rmse: 0.17063 | valid_mse: 0.02912 |  0:01:06s\n",
      "epoch 46 | loss: 0.02591 | train_rmsle: 0.00114 | train_mae: 0.11089 | train_rmse: 0.14312 | train_mse: 0.02048 | valid_rmsle: 0.00145 | valid_mae: 0.12595 | valid_rmse: 0.16217 | valid_mse: 0.0263  |  0:01:08s\n",
      "epoch 47 | loss: 0.0253  | train_rmsle: 0.00105 | train_mae: 0.10692 | train_rmse: 0.13949 | train_mse: 0.01946 | valid_rmsle: 0.00137 | valid_mae: 0.1231  | valid_rmse: 0.1593  | valid_mse: 0.02538 |  0:01:09s\n",
      "epoch 48 | loss: 0.02733 | train_rmsle: 0.00118 | train_mae: 0.11651 | train_rmse: 0.14516 | train_mse: 0.02107 | valid_rmsle: 0.00154 | valid_mae: 0.13181 | valid_rmse: 0.1661  | valid_mse: 0.02759 |  0:01:10s\n",
      "epoch 49 | loss: 0.02091 | train_rmsle: 0.00082 | train_mae: 0.09274 | train_rmse: 0.12088 | train_mse: 0.01461 | valid_rmsle: 0.00116 | valid_mae: 0.1105  | valid_rmse: 0.14485 | valid_mse: 0.02098 |  0:01:12s\n",
      "epoch 50 | loss: 0.01956 | train_rmsle: 0.00076 | train_mae: 0.08992 | train_rmse: 0.11766 | train_mse: 0.01384 | valid_rmsle: 0.00109 | valid_mae: 0.10774 | valid_rmse: 0.14174 | valid_mse: 0.02009 |  0:01:13s\n",
      "epoch 51 | loss: 0.02078 | train_rmsle: 0.00148 | train_mae: 0.13282 | train_rmse: 0.15876 | train_mse: 0.0252  | valid_rmsle: 0.00184 | valid_mae: 0.14712 | valid_rmse: 0.17973 | valid_mse: 0.0323  |  0:01:15s\n",
      "epoch 52 | loss: 0.02702 | train_rmsle: 0.00074 | train_mae: 0.08914 | train_rmse: 0.1162  | train_mse: 0.0135  | valid_rmsle: 0.00108 | valid_mae: 0.10768 | valid_rmse: 0.14101 | valid_mse: 0.01988 |  0:01:16s\n",
      "epoch 53 | loss: 0.01946 | train_rmsle: 0.00129 | train_mae: 0.12052 | train_rmse: 0.14991 | train_mse: 0.02247 | valid_rmsle: 0.00161 | valid_mae: 0.13591 | valid_rmse: 0.16915 | valid_mse: 0.02861 |  0:01:18s\n",
      "epoch 54 | loss: 0.02217 | train_rmsle: 0.00074 | train_mae: 0.0907  | train_rmse: 0.11643 | train_mse: 0.01355 | valid_rmsle: 0.00103 | valid_mae: 0.10743 | valid_rmse: 0.13797 | valid_mse: 0.01904 |  0:01:19s\n",
      "epoch 55 | loss: 0.02113 | train_rmsle: 0.00141 | train_mae: 0.11629 | train_rmse: 0.16554 | train_mse: 0.0274  | valid_rmsle: 0.00184 | valid_mae: 0.13444 | valid_rmse: 0.18917 | valid_mse: 0.03579 |  0:01:21s\n",
      "epoch 56 | loss: 0.02286 | train_rmsle: 0.0008  | train_mae: 0.09229 | train_rmse: 0.12083 | train_mse: 0.0146  | valid_rmsle: 0.00112 | valid_mae: 0.10969 | valid_rmse: 0.14371 | valid_mse: 0.02065 |  0:01:22s\n",
      "epoch 57 | loss: 0.01776 | train_rmsle: 0.00086 | train_mae: 0.10025 | train_rmse: 0.12621 | train_mse: 0.01593 | valid_rmsle: 0.00116 | valid_mae: 0.11572 | valid_rmse: 0.14667 | valid_mse: 0.02151 |  0:01:23s\n",
      "epoch 58 | loss: 0.02115 | train_rmsle: 0.00101 | train_mae: 0.11145 | train_rmse: 0.13727 | train_mse: 0.01884 | valid_rmsle: 0.00131 | valid_mae: 0.12408 | valid_rmse: 0.15603 | valid_mse: 0.02434 |  0:01:25s\n",
      "epoch 59 | loss: 0.01605 | train_rmsle: 0.00073 | train_mae: 0.087   | train_rmse: 0.11106 | train_mse: 0.01233 | valid_rmsle: 0.001   | valid_mae: 0.10231 | valid_rmse: 0.1318  | valid_mse: 0.01737 |  0:01:26s\n",
      "epoch 60 | loss: 0.01694 | train_rmsle: 0.00071 | train_mae: 0.08983 | train_rmse: 0.11265 | train_mse: 0.01269 | valid_rmsle: 0.00097 | valid_mae: 0.10448 | valid_rmse: 0.13247 | valid_mse: 0.01755 |  0:01:28s\n",
      "epoch 61 | loss: 0.01508 | train_rmsle: 0.00065 | train_mae: 0.08283 | train_rmse: 0.10643 | train_mse: 0.01133 | valid_rmsle: 0.00091 | valid_mae: 0.09943 | valid_rmse: 0.12717 | valid_mse: 0.01617 |  0:01:29s\n",
      "epoch 62 | loss: 0.01462 | train_rmsle: 0.00075 | train_mae: 0.09555 | train_rmse: 0.11896 | train_mse: 0.01415 | valid_rmsle: 0.00101 | valid_mae: 0.1091  | valid_rmse: 0.13787 | valid_mse: 0.01901 |  0:01:31s\n",
      "epoch 63 | loss: 0.01585 | train_rmsle: 0.0005  | train_mae: 0.07272 | train_rmse: 0.09557 | train_mse: 0.00913 | valid_rmsle: 0.00075 | valid_mae: 0.08977 | valid_rmse: 0.11764 | valid_mse: 0.01384 |  0:01:32s\n",
      "epoch 64 | loss: 0.01496 | train_rmsle: 0.00059 | train_mae: 0.07805 | train_rmse: 0.10137 | train_mse: 0.01028 | valid_rmsle: 0.00083 | valid_mae: 0.09384 | valid_rmse: 0.12253 | valid_mse: 0.01501 |  0:01:33s\n",
      "epoch 65 | loss: 0.01423 | train_rmsle: 0.00068 | train_mae: 0.08671 | train_rmse: 0.11497 | train_mse: 0.01322 | valid_rmsle: 0.00096 | valid_mae: 0.10293 | valid_rmse: 0.13638 | valid_mse: 0.0186  |  0:01:35s\n",
      "epoch 66 | loss: 0.01488 | train_rmsle: 0.00047 | train_mae: 0.0704  | train_rmse: 0.09269 | train_mse: 0.00859 | valid_rmsle: 0.00072 | valid_mae: 0.08729 | valid_rmse: 0.11488 | valid_mse: 0.0132  |  0:01:36s\n",
      "epoch 67 | loss: 0.01572 | train_rmsle: 0.00047 | train_mae: 0.07107 | train_rmse: 0.09249 | train_mse: 0.00855 | valid_rmsle: 0.00071 | valid_mae: 0.08687 | valid_rmse: 0.11366 | valid_mse: 0.01292 |  0:01:38s\n",
      "epoch 68 | loss: 0.01275 | train_rmsle: 0.00043 | train_mae: 0.06761 | train_rmse: 0.08788 | train_mse: 0.00772 | valid_rmsle: 0.00066 | valid_mae: 0.08294 | valid_rmse: 0.1089  | valid_mse: 0.01186 |  0:01:39s\n",
      "epoch 69 | loss: 0.01411 | train_rmsle: 0.00053 | train_mae: 0.0766  | train_rmse: 0.09657 | train_mse: 0.00933 | valid_rmsle: 0.00076 | valid_mae: 0.09059 | valid_rmse: 0.11636 | valid_mse: 0.01354 |  0:01:41s\n",
      "epoch 70 | loss: 0.01822 | train_rmsle: 0.00054 | train_mae: 0.07774 | train_rmse: 0.10026 | train_mse: 0.01005 | valid_rmsle: 0.00077 | valid_mae: 0.09264 | valid_rmse: 0.11921 | valid_mse: 0.01421 |  0:01:42s\n",
      "epoch 71 | loss: 0.0208  | train_rmsle: 0.00059 | train_mae: 0.07717 | train_rmse: 0.09717 | train_mse: 0.00944 | valid_rmsle: 0.0008  | valid_mae: 0.0925  | valid_rmse: 0.11611 | valid_mse: 0.01348 |  0:01:44s\n",
      "epoch 72 | loss: 0.01359 | train_rmsle: 0.00073 | train_mae: 0.08569 | train_rmse: 0.10718 | train_mse: 0.01149 | valid_rmsle: 0.00095 | valid_mae: 0.09899 | valid_rmse: 0.12501 | valid_mse: 0.01563 |  0:01:45s\n",
      "epoch 73 | loss: 0.01386 | train_rmsle: 0.00168 | train_mae: 0.15132 | train_rmse: 0.16862 | train_mse: 0.02843 | valid_rmsle: 0.00188 | valid_mae: 0.15664 | valid_rmse: 0.1799  | valid_mse: 0.03237 |  0:01:46s\n",
      "epoch 74 | loss: 0.0156  | train_rmsle: 0.00076 | train_mae: 0.099   | train_rmse: 0.11821 | train_mse: 0.01397 | valid_rmsle: 0.00098 | valid_mae: 0.10971 | valid_rmse: 0.13465 | valid_mse: 0.01813 |  0:01:48s\n",
      "epoch 75 | loss: 0.01307 | train_rmsle: 0.0005  | train_mae: 0.07551 | train_rmse: 0.09569 | train_mse: 0.00916 | valid_rmsle: 0.00071 | valid_mae: 0.08946 | valid_rmse: 0.11398 | valid_mse: 0.01299 |  0:01:49s\n",
      "epoch 76 | loss: 0.01365 | train_rmsle: 0.0004  | train_mae: 0.06616 | train_rmse: 0.08418 | train_mse: 0.00709 | valid_rmsle: 0.00061 | valid_mae: 0.08136 | valid_rmse: 0.10459 | valid_mse: 0.01094 |  0:01:51s\n",
      "epoch 77 | loss: 0.0135  | train_rmsle: 0.00072 | train_mae: 0.09489 | train_rmse: 0.11808 | train_mse: 0.01394 | valid_rmsle: 0.00091 | valid_mae: 0.10427 | valid_rmse: 0.13233 | valid_mse: 0.01751 |  0:01:52s\n",
      "epoch 78 | loss: 0.01454 | train_rmsle: 0.00078 | train_mae: 0.08949 | train_rmse: 0.11072 | train_mse: 0.01226 | valid_rmsle: 0.00096 | valid_mae: 0.10021 | valid_rmse: 0.12579 | valid_mse: 0.01582 |  0:01:54s\n",
      "epoch 79 | loss: 0.01363 | train_rmsle: 0.00068 | train_mae: 0.08335 | train_rmse: 0.10342 | train_mse: 0.0107  | valid_rmsle: 0.00087 | valid_mae: 0.09616 | valid_rmse: 0.11932 | valid_mse: 0.01424 |  0:01:55s\n",
      "epoch 80 | loss: 0.01144 | train_rmsle: 0.00052 | train_mae: 0.07278 | train_rmse: 0.09195 | train_mse: 0.00845 | valid_rmsle: 0.00073 | valid_mae: 0.08658 | valid_rmse: 0.11076 | valid_mse: 0.01227 |  0:01:57s\n",
      "epoch 81 | loss: 0.0129  | train_rmsle: 0.00061 | train_mae: 0.06423 | train_rmse: 0.09701 | train_mse: 0.00941 | valid_rmsle: 0.00071 | valid_mae: 0.07987 | valid_rmse: 0.1103  | valid_mse: 0.01217 |  0:01:58s\n",
      "epoch 82 | loss: 0.01125 | train_rmsle: 0.00034 | train_mae: 0.05984 | train_rmse: 0.07795 | train_mse: 0.00608 | valid_rmsle: 0.00054 | valid_mae: 0.07571 | valid_rmse: 0.09957 | valid_mse: 0.00991 |  0:01:59s\n",
      "epoch 83 | loss: 0.01328 | train_rmsle: 0.00044 | train_mae: 0.07131 | train_rmse: 0.09135 | train_mse: 0.00834 | valid_rmsle: 0.00066 | valid_mae: 0.08483 | valid_rmse: 0.11095 | valid_mse: 0.01231 |  0:02:01s\n",
      "epoch 84 | loss: 0.01569 | train_rmsle: 0.00049 | train_mae: 0.06881 | train_rmse: 0.08775 | train_mse: 0.0077  | valid_rmsle: 0.00071 | valid_mae: 0.08389 | valid_rmse: 0.10846 | valid_mse: 0.01176 |  0:02:02s\n",
      "epoch 85 | loss: 0.01246 | train_rmsle: 0.00041 | train_mae: 0.06815 | train_rmse: 0.08677 | train_mse: 0.00753 | valid_rmsle: 0.00062 | valid_mae: 0.08133 | valid_rmse: 0.10676 | valid_mse: 0.0114  |  0:02:04s\n",
      "epoch 86 | loss: 0.01215 | train_rmsle: 0.00039 | train_mae: 0.0644  | train_rmse: 0.08114 | train_mse: 0.00658 | valid_rmsle: 0.0006  | valid_mae: 0.07981 | valid_rmse: 0.1033  | valid_mse: 0.01067 |  0:02:05s\n",
      "epoch 87 | loss: 0.01179 | train_rmsle: 0.00048 | train_mae: 0.0706  | train_rmse: 0.08993 | train_mse: 0.00809 | valid_rmsle: 0.0007  | valid_mae: 0.08543 | valid_rmse: 0.11018 | valid_mse: 0.01214 |  0:02:07s\n",
      "epoch 88 | loss: 0.01125 | train_rmsle: 0.0008  | train_mae: 0.07938 | train_rmse: 0.10302 | train_mse: 0.01061 | valid_rmsle: 0.00098 | valid_mae: 0.09278 | valid_rmse: 0.11987 | valid_mse: 0.01437 |  0:02:08s\n",
      "epoch 89 | loss: 0.01162 | train_rmsle: 0.00047 | train_mae: 0.076   | train_rmse: 0.09321 | train_mse: 0.00869 | valid_rmsle: 0.00069 | valid_mae: 0.08933 | valid_rmse: 0.11306 | valid_mse: 0.01278 |  0:02:10s\n",
      "epoch 90 | loss: 0.01117 | train_rmsle: 0.00095 | train_mae: 0.10611 | train_rmse: 0.12269 | train_mse: 0.01505 | valid_rmsle: 0.00114 | valid_mae: 0.1147  | valid_rmse: 0.1373  | valid_mse: 0.01885 |  0:02:11s\n",
      "epoch 91 | loss: 0.01124 | train_rmsle: 0.00028 | train_mae: 0.05471 | train_rmse: 0.0705  | train_mse: 0.00497 | valid_rmsle: 0.0005  | valid_mae: 0.07263 | valid_rmse: 0.09474 | valid_mse: 0.00898 |  0:02:12s\n",
      "epoch 92 | loss: 0.00977 | train_rmsle: 0.00039 | train_mae: 0.0611  | train_rmse: 0.07793 | train_mse: 0.00607 | valid_rmsle: 0.00058 | valid_mae: 0.07639 | valid_rmse: 0.09825 | valid_mse: 0.00965 |  0:02:14s\n",
      "epoch 93 | loss: 0.00923 | train_rmsle: 0.00038 | train_mae: 0.06696 | train_rmse: 0.08289 | train_mse: 0.00687 | valid_rmsle: 0.0006  | valid_mae: 0.0814  | valid_rmse: 0.10383 | valid_mse: 0.01078 |  0:02:15s\n",
      "epoch 94 | loss: 0.01318 | train_rmsle: 0.00047 | train_mae: 0.07486 | train_rmse: 0.09019 | train_mse: 0.00813 | valid_rmsle: 0.00068 | valid_mae: 0.08765 | valid_rmse: 0.10965 | valid_mse: 0.01202 |  0:02:17s\n",
      "epoch 95 | loss: 0.01061 | train_rmsle: 0.00065 | train_mae: 0.08339 | train_rmse: 0.10048 | train_mse: 0.0101  | valid_rmsle: 0.00084 | valid_mae: 0.0949  | valid_rmse: 0.11718 | valid_mse: 0.01373 |  0:02:18s\n",
      "epoch 96 | loss: 0.01097 | train_rmsle: 0.00125 | train_mae: 0.11016 | train_rmse: 0.13137 | train_mse: 0.01726 | valid_rmsle: 0.00142 | valid_mae: 0.11947 | valid_rmse: 0.14522 | valid_mse: 0.02109 |  0:02:20s\n",
      "epoch 97 | loss: 0.01196 | train_rmsle: 0.00028 | train_mae: 0.0558  | train_rmse: 0.07191 | train_mse: 0.00517 | valid_rmsle: 0.00049 | valid_mae: 0.0718  | valid_rmse: 0.09479 | valid_mse: 0.00898 |  0:02:21s\n",
      "epoch 98 | loss: 0.01243 | train_rmsle: 0.00088 | train_mae: 0.0911  | train_rmse: 0.11259 | train_mse: 0.01268 | valid_rmsle: 0.00108 | valid_mae: 0.10136 | valid_rmse: 0.1282  | valid_mse: 0.01644 |  0:02:22s\n",
      "epoch 99 | loss: 0.01041 | train_rmsle: 0.00027 | train_mae: 0.05391 | train_rmse: 0.06883 | train_mse: 0.00474 | valid_rmsle: 0.00048 | valid_mae: 0.07113 | valid_rmse: 0.09284 | valid_mse: 0.00862 |  0:02:24s\n",
      "epoch 100| loss: 0.01068 | train_rmsle: 0.00062 | train_mae: 0.0879  | train_rmse: 0.10366 | train_mse: 0.01075 | valid_rmsle: 0.00081 | valid_mae: 0.09697 | valid_rmse: 0.11924 | valid_mse: 0.01422 |  0:02:25s\n",
      "epoch 101| loss: 0.00972 | train_rmsle: 0.00032 | train_mae: 0.05466 | train_rmse: 0.07086 | train_mse: 0.00502 | valid_rmsle: 0.00053 | valid_mae: 0.07243 | valid_rmse: 0.09401 | valid_mse: 0.00884 |  0:02:27s\n",
      "epoch 102| loss: 0.01142 | train_rmsle: 0.00049 | train_mae: 0.07886 | train_rmse: 0.09418 | train_mse: 0.00887 | valid_rmsle: 0.00071 | valid_mae: 0.09095 | valid_rmse: 0.11305 | valid_mse: 0.01278 |  0:02:28s\n",
      "epoch 103| loss: 0.01042 | train_rmsle: 0.00031 | train_mae: 0.05823 | train_rmse: 0.07325 | train_mse: 0.00536 | valid_rmsle: 0.00054 | valid_mae: 0.07581 | valid_rmse: 0.09695 | valid_mse: 0.0094  |  0:02:30s\n",
      "epoch 104| loss: 0.01318 | train_rmsle: 0.00028 | train_mae: 0.05582 | train_rmse: 0.07126 | train_mse: 0.00508 | valid_rmsle: 0.00051 | valid_mae: 0.07414 | valid_rmse: 0.09602 | valid_mse: 0.00922 |  0:02:31s\n",
      "epoch 105| loss: 0.0113  | train_rmsle: 0.00064 | train_mae: 0.08095 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00088 | valid_mae: 0.09508 | valid_rmse: 0.12178 | valid_mse: 0.01483 |  0:02:33s\n",
      "epoch 106| loss: 0.01168 | train_rmsle: 0.00065 | train_mae: 0.08761 | train_rmse: 0.10558 | train_mse: 0.01115 | valid_rmsle: 0.00088 | valid_mae: 0.10001 | valid_rmse: 0.1232  | valid_mse: 0.01518 |  0:02:34s\n",
      "epoch 107| loss: 0.01566 | train_rmsle: 0.00034 | train_mae: 0.06168 | train_rmse: 0.07908 | train_mse: 0.00625 | valid_rmsle: 0.00058 | valid_mae: 0.08027 | valid_rmse: 0.1022  | valid_mse: 0.01045 |  0:02:35s\n",
      "epoch 108| loss: 0.01083 | train_rmsle: 0.00027 | train_mae: 0.05344 | train_rmse: 0.06852 | train_mse: 0.0047  | valid_rmsle: 0.00049 | valid_mae: 0.07109 | valid_rmse: 0.09224 | valid_mse: 0.00851 |  0:02:37s\n",
      "epoch 109| loss: 0.01013 | train_rmsle: 0.00028 | train_mae: 0.05607 | train_rmse: 0.07158 | train_mse: 0.00512 | valid_rmsle: 0.0005  | valid_mae: 0.07387 | valid_rmse: 0.09494 | valid_mse: 0.00901 |  0:02:38s\n",
      "epoch 110| loss: 0.0105  | train_rmsle: 0.00034 | train_mae: 0.06476 | train_rmse: 0.08112 | train_mse: 0.00658 | valid_rmsle: 0.00056 | valid_mae: 0.08077 | valid_rmse: 0.10175 | valid_mse: 0.01035 |  0:02:40s\n",
      "epoch 111| loss: 0.00932 | train_rmsle: 0.00066 | train_mae: 0.0791  | train_rmse: 0.09869 | train_mse: 0.00974 | valid_rmsle: 0.00081 | valid_mae: 0.08966 | valid_rmse: 0.11412 | valid_mse: 0.01302 |  0:02:41s\n",
      "epoch 112| loss: 0.01306 | train_rmsle: 0.00039 | train_mae: 0.06871 | train_rmse: 0.08384 | train_mse: 0.00703 | valid_rmsle: 0.0006  | valid_mae: 0.0814  | valid_rmse: 0.10373 | valid_mse: 0.01076 |  0:02:43s\n",
      "epoch 113| loss: 0.01298 | train_rmsle: 0.00033 | train_mae: 0.06043 | train_rmse: 0.07771 | train_mse: 0.00604 | valid_rmsle: 0.00056 | valid_mae: 0.07682 | valid_rmse: 0.10076 | valid_mse: 0.01015 |  0:02:44s\n",
      "epoch 114| loss: 0.01107 | train_rmsle: 0.00041 | train_mae: 0.06063 | train_rmse: 0.07792 | train_mse: 0.00607 | valid_rmsle: 0.00063 | valid_mae: 0.07708 | valid_rmse: 0.10011 | valid_mse: 0.01002 |  0:02:46s\n",
      "epoch 115| loss: 0.00886 | train_rmsle: 0.00024 | train_mae: 0.05183 | train_rmse: 0.06645 | train_mse: 0.00442 | valid_rmsle: 0.00047 | valid_mae: 0.07063 | valid_rmse: 0.09142 | valid_mse: 0.00836 |  0:02:47s\n",
      "epoch 116| loss: 0.01263 | train_rmsle: 0.00036 | train_mae: 0.06072 | train_rmse: 0.07823 | train_mse: 0.00612 | valid_rmsle: 0.00059 | valid_mae: 0.07855 | valid_rmse: 0.10028 | valid_mse: 0.01006 |  0:02:49s\n",
      "epoch 117| loss: 0.01114 | train_rmsle: 0.00056 | train_mae: 0.07372 | train_rmse: 0.09326 | train_mse: 0.0087  | valid_rmsle: 0.00076 | valid_mae: 0.08754 | valid_rmse: 0.11215 | valid_mse: 0.01258 |  0:02:50s\n",
      "epoch 118| loss: 0.01376 | train_rmsle: 0.0005  | train_mae: 0.07708 | train_rmse: 0.09683 | train_mse: 0.00938 | valid_rmsle: 0.00076 | valid_mae: 0.09212 | valid_rmse: 0.11754 | valid_mse: 0.01382 |  0:02:51s\n",
      "epoch 119| loss: 0.01105 | train_rmsle: 0.0003  | train_mae: 0.05847 | train_rmse: 0.07552 | train_mse: 0.0057  | valid_rmsle: 0.00056 | valid_mae: 0.07875 | valid_rmse: 0.10092 | valid_mse: 0.01018 |  0:02:53s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 115 and best_valid_mse = 0.00836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009388781884160823 RMSE: 0.09689572686223487 R2: 0.9584394802708741 MAE: 0.07628762708723359\n",
      "=====================================\n",
      "[87/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.49595 | train_rmsle: 0.25339 | train_mae: 1.66944 | train_rmse: 1.73779 | train_mse: 3.01992 | valid_rmsle: 0.25516 | valid_mae: 1.67669 | valid_rmse: 1.74425 | valid_mse: 3.04241 |  0:00:01s\n",
      "epoch 1  | loss: 0.68901 | train_rmsle: 0.12799 | train_mae: 1.25026 | train_rmse: 1.33312 | train_mse: 1.7772  | valid_rmsle: 0.12859 | valid_mae: 1.25369 | valid_rmse: 1.33734 | valid_mse: 1.78847 |  0:00:03s\n",
      "epoch 2  | loss: 0.36487 | train_rmsle: 0.10927 | train_mae: 1.16508 | train_rmse: 1.25029 | train_mse: 1.56324 | valid_rmsle: 0.10985 | valid_mae: 1.1683  | valid_rmse: 1.25477 | valid_mse: 1.57445 |  0:00:04s\n",
      "epoch 3  | loss: 0.31525 | train_rmsle: 0.08541 | train_mae: 1.04073 | train_rmse: 1.1293  | train_mse: 1.27531 | valid_rmsle: 0.08568 | valid_mae: 1.04268 | valid_rmse: 1.13258 | valid_mse: 1.28273 |  0:00:05s\n",
      "epoch 4  | loss: 0.28473 | train_rmsle: 0.03898 | train_mae: 0.71155 | train_rmse: 0.80416 | train_mse: 0.64667 | valid_rmsle: 0.0389  | valid_mae: 0.71111 | valid_rmse: 0.80603 | valid_mse: 0.64968 |  0:00:07s\n",
      "epoch 5  | loss: 0.2469  | train_rmsle: 0.03499 | train_mae: 0.67332 | train_rmse: 0.76575 | train_mse: 0.58637 | valid_rmsle: 0.03505 | valid_mae: 0.67479 | valid_rmse: 0.76904 | valid_mse: 0.59142 |  0:00:08s\n",
      "epoch 6  | loss: 0.24164 | train_rmsle: 0.03    | train_mae: 0.62198 | train_rmse: 0.71304 | train_mse: 0.50843 | valid_rmsle: 0.03004 | valid_mae: 0.62368 | valid_rmse: 0.7165  | valid_mse: 0.51337 |  0:00:10s\n",
      "epoch 7  | loss: 0.23761 | train_rmsle: 0.01821 | train_mae: 0.46887 | train_rmse: 0.55648 | train_mse: 0.30967 | valid_rmsle: 0.0179  | valid_mae: 0.47142 | valid_rmse: 0.55645 | valid_mse: 0.30963 |  0:00:11s\n",
      "epoch 8  | loss: 0.23888 | train_rmsle: 0.01668 | train_mae: 0.4418  | train_rmse: 0.52992 | train_mse: 0.28082 | valid_rmsle: 0.01633 | valid_mae: 0.44542 | valid_rmse: 0.52927 | valid_mse: 0.28013 |  0:00:13s\n",
      "epoch 9  | loss: 0.23455 | train_rmsle: 0.01677 | train_mae: 0.44347 | train_rmse: 0.53146 | train_mse: 0.28245 | valid_rmsle: 0.01637 | valid_mae: 0.44638 | valid_rmse: 0.53008 | valid_mse: 0.28099 |  0:00:14s\n",
      "epoch 10 | loss: 0.22851 | train_rmsle: 0.01561 | train_mae: 0.41861 | train_rmse: 0.50853 | train_mse: 0.2586  | valid_rmsle: 0.01501 | valid_mae: 0.41817 | valid_rmse: 0.50392 | valid_mse: 0.25394 |  0:00:16s\n",
      "epoch 11 | loss: 0.22824 | train_rmsle: 0.01579 | train_mae: 0.42471 | train_rmse: 0.51359 | train_mse: 0.26377 | valid_rmsle: 0.01528 | valid_mae: 0.4254  | valid_rmse: 0.51059 | valid_mse: 0.2607  |  0:00:17s\n",
      "epoch 12 | loss: 0.23593 | train_rmsle: 0.01464 | train_mae: 0.38363 | train_rmse: 0.48311 | train_mse: 0.2334  | valid_rmsle: 0.0141  | valid_mae: 0.38587 | valid_rmse: 0.47947 | valid_mse: 0.22989 |  0:00:19s\n",
      "epoch 13 | loss: 0.23634 | train_rmsle: 0.01486 | train_mae: 0.39598 | train_rmse: 0.49063 | train_mse: 0.24072 | valid_rmsle: 0.01436 | valid_mae: 0.39749 | valid_rmse: 0.48752 | valid_mse: 0.23767 |  0:00:20s\n",
      "epoch 14 | loss: 0.22241 | train_rmsle: 0.01545 | train_mae: 0.41836 | train_rmse: 0.50715 | train_mse: 0.2572  | valid_rmsle: 0.01495 | valid_mae: 0.41881 | valid_rmse: 0.50406 | valid_mse: 0.25407 |  0:00:21s\n",
      "epoch 15 | loss: 0.2231  | train_rmsle: 0.01643 | train_mae: 0.43945 | train_rmse: 0.52718 | train_mse: 0.27792 | valid_rmsle: 0.01598 | valid_mae: 0.44038 | valid_rmse: 0.52493 | valid_mse: 0.27555 |  0:00:23s\n",
      "epoch 16 | loss: 0.22186 | train_rmsle: 0.01838 | train_mae: 0.47141 | train_rmse: 0.56036 | train_mse: 0.314   | valid_rmsle: 0.01811 | valid_mae: 0.47246 | valid_rmse: 0.56081 | valid_mse: 0.3145  |  0:00:24s\n",
      "epoch 17 | loss: 0.22365 | train_rmsle: 0.01521 | train_mae: 0.41414 | train_rmse: 0.50296 | train_mse: 0.25297 | valid_rmsle: 0.01474 | valid_mae: 0.41544 | valid_rmse: 0.50047 | valid_mse: 0.25047 |  0:00:26s\n",
      "epoch 18 | loss: 0.2175  | train_rmsle: 0.01472 | train_mae: 0.40358 | train_rmse: 0.49313 | train_mse: 0.24318 | valid_rmsle: 0.0143  | valid_mae: 0.40589 | valid_rmse: 0.4915  | valid_mse: 0.24158 |  0:00:27s\n",
      "epoch 19 | loss: 0.21615 | train_rmsle: 0.01539 | train_mae: 0.41939 | train_rmse: 0.50794 | train_mse: 0.258   | valid_rmsle: 0.01502 | valid_mae: 0.42126 | valid_rmse: 0.50725 | valid_mse: 0.2573  |  0:00:29s\n",
      "epoch 20 | loss: 0.21417 | train_rmsle: 0.01465 | train_mae: 0.4051  | train_rmse: 0.49441 | train_mse: 0.24444 | valid_rmsle: 0.01442 | valid_mae: 0.40865 | valid_rmse: 0.49609 | valid_mse: 0.2461  |  0:00:30s\n",
      "epoch 21 | loss: 0.21138 | train_rmsle: 0.01409 | train_mae: 0.39397 | train_rmse: 0.48346 | train_mse: 0.23373 | valid_rmsle: 0.01396 | valid_mae: 0.40166 | valid_rmse: 0.48728 | valid_mse: 0.23744 |  0:00:32s\n",
      "epoch 22 | loss: 0.20891 | train_rmsle: 0.01327 | train_mae: 0.37149 | train_rmse: 0.46351 | train_mse: 0.21484 | valid_rmsle: 0.01309 | valid_mae: 0.37872 | valid_rmse: 0.46651 | valid_mse: 0.21763 |  0:00:33s\n",
      "epoch 23 | loss: 0.20709 | train_rmsle: 0.01378 | train_mae: 0.39185 | train_rmse: 0.47861 | train_mse: 0.22906 | valid_rmsle: 0.01373 | valid_mae: 0.402   | valid_rmse: 0.48353 | valid_mse: 0.2338  |  0:00:35s\n",
      "epoch 24 | loss: 0.19133 | train_rmsle: 0.01131 | train_mae: 0.33634 | train_rmse: 0.42473 | train_mse: 0.18039 | valid_rmsle: 0.01128 | valid_mae: 0.34861 | valid_rmse: 0.43143 | valid_mse: 0.18613 |  0:00:36s\n",
      "epoch 25 | loss: 0.17035 | train_rmsle: 0.00923 | train_mae: 0.29644 | train_rmse: 0.37938 | train_mse: 0.14393 | valid_rmsle: 0.00935 | valid_mae: 0.30985 | valid_rmse: 0.38914 | valid_mse: 0.15143 |  0:00:37s\n",
      "epoch 26 | loss: 0.15098 | train_rmsle: 0.01019 | train_mae: 0.34153 | train_rmse: 0.41089 | train_mse: 0.16883 | valid_rmsle: 0.01002 | valid_mae: 0.3425  | valid_rmse: 0.41312 | valid_mse: 0.17067 |  0:00:39s\n",
      "epoch 27 | loss: 0.1364  | train_rmsle: 0.00839 | train_mae: 0.29743 | train_rmse: 0.36656 | train_mse: 0.13437 | valid_rmsle: 0.00802 | valid_mae: 0.29534 | valid_rmse: 0.36423 | valid_mse: 0.13267 |  0:00:40s\n",
      "epoch 28 | loss: 0.11581 | train_rmsle: 0.00734 | train_mae: 0.26933 | train_rmse: 0.33809 | train_mse: 0.11431 | valid_rmsle: 0.00697 | valid_mae: 0.26526 | valid_rmse: 0.33496 | valid_mse: 0.1122  |  0:00:42s\n",
      "epoch 29 | loss: 0.10191 | train_rmsle: 0.00777 | train_mae: 0.28666 | train_rmse: 0.35164 | train_mse: 0.12365 | valid_rmsle: 0.00766 | valid_mae: 0.28891 | valid_rmse: 0.35446 | valid_mse: 0.12565 |  0:00:43s\n",
      "epoch 30 | loss: 0.08792 | train_rmsle: 0.00634 | train_mae: 0.25072 | train_rmse: 0.31476 | train_mse: 0.09907 | valid_rmsle: 0.00637 | valid_mae: 0.25715 | valid_rmse: 0.31995 | valid_mse: 0.10237 |  0:00:45s\n",
      "epoch 31 | loss: 0.07499 | train_rmsle: 0.00426 | train_mae: 0.20903 | train_rmse: 0.26485 | train_mse: 0.07015 | valid_rmsle: 0.00448 | valid_mae: 0.22109 | valid_rmse: 0.2757  | valid_mse: 0.07601 |  0:00:46s\n",
      "epoch 32 | loss: 0.06929 | train_rmsle: 0.00384 | train_mae: 0.19726 | train_rmse: 0.2514  | train_mse: 0.0632  | valid_rmsle: 0.00417 | valid_mae: 0.2115  | valid_rmse: 0.26663 | valid_mse: 0.07109 |  0:00:48s\n",
      "epoch 33 | loss: 0.05978 | train_rmsle: 0.00288 | train_mae: 0.17172 | train_rmse: 0.22061 | train_mse: 0.04867 | valid_rmsle: 0.00314 | valid_mae: 0.183   | valid_rmse: 0.23345 | valid_mse: 0.0545  |  0:00:49s\n",
      "epoch 34 | loss: 0.05236 | train_rmsle: 0.00284 | train_mae: 0.16708 | train_rmse: 0.21417 | train_mse: 0.04587 | valid_rmsle: 0.00312 | valid_mae: 0.17937 | valid_rmse: 0.22878 | valid_mse: 0.05234 |  0:00:50s\n",
      "epoch 35 | loss: 0.061   | train_rmsle: 0.00399 | train_mae: 0.20626 | train_rmse: 0.26128 | train_mse: 0.06827 | valid_rmsle: 0.0043  | valid_mae: 0.21615 | valid_rmse: 0.27365 | valid_mse: 0.07488 |  0:00:52s\n",
      "epoch 36 | loss: 0.05627 | train_rmsle: 0.00262 | train_mae: 0.16359 | train_rmse: 0.20984 | train_mse: 0.04403 | valid_rmsle: 0.0031  | valid_mae: 0.18103 | valid_rmse: 0.23065 | valid_mse: 0.0532  |  0:00:53s\n",
      "epoch 37 | loss: 0.04082 | train_rmsle: 0.0019  | train_mae: 0.13923 | train_rmse: 0.18068 | train_mse: 0.03265 | valid_rmsle: 0.00236 | valid_mae: 0.15801 | valid_rmse: 0.20383 | valid_mse: 0.04155 |  0:00:55s\n",
      "epoch 38 | loss: 0.0382  | train_rmsle: 0.00177 | train_mae: 0.13581 | train_rmse: 0.17651 | train_mse: 0.03116 | valid_rmsle: 0.00222 | valid_mae: 0.15471 | valid_rmse: 0.1994  | valid_mse: 0.03976 |  0:00:56s\n",
      "epoch 39 | loss: 0.03422 | train_rmsle: 0.00167 | train_mae: 0.13195 | train_rmse: 0.17176 | train_mse: 0.0295  | valid_rmsle: 0.00205 | valid_mae: 0.14707 | valid_rmse: 0.19209 | valid_mse: 0.0369  |  0:00:58s\n",
      "epoch 40 | loss: 0.03408 | train_rmsle: 0.0015  | train_mae: 0.12505 | train_rmse: 0.16329 | train_mse: 0.02666 | valid_rmsle: 0.00189 | valid_mae: 0.14033 | valid_rmse: 0.18417 | valid_mse: 0.03392 |  0:00:59s\n",
      "epoch 41 | loss: 0.03153 | train_rmsle: 0.00145 | train_mae: 0.12322 | train_rmse: 0.16167 | train_mse: 0.02614 | valid_rmsle: 0.00178 | valid_mae: 0.13658 | valid_rmse: 0.17979 | valid_mse: 0.03233 |  0:01:01s\n",
      "epoch 42 | loss: 0.02812 | train_rmsle: 0.00141 | train_mae: 0.12499 | train_rmse: 0.16235 | train_mse: 0.02636 | valid_rmsle: 0.00182 | valid_mae: 0.14206 | valid_rmse: 0.18427 | valid_mse: 0.03396 |  0:01:02s\n",
      "epoch 43 | loss: 0.02677 | train_rmsle: 0.00203 | train_mae: 0.15205 | train_rmse: 0.18475 | train_mse: 0.03413 | valid_rmsle: 0.00242 | valid_mae: 0.1663  | valid_rmse: 0.20435 | valid_mse: 0.04176 |  0:01:04s\n",
      "epoch 44 | loss: 0.02811 | train_rmsle: 0.00201 | train_mae: 0.14875 | train_rmse: 0.18222 | train_mse: 0.0332  | valid_rmsle: 0.00241 | valid_mae: 0.1642  | valid_rmse: 0.20189 | valid_mse: 0.04076 |  0:01:05s\n",
      "epoch 45 | loss: 0.03048 | train_rmsle: 0.00132 | train_mae: 0.11846 | train_rmse: 0.15315 | train_mse: 0.02345 | valid_rmsle: 0.00163 | valid_mae: 0.13252 | valid_rmse: 0.17063 | valid_mse: 0.02912 |  0:01:06s\n",
      "epoch 46 | loss: 0.02591 | train_rmsle: 0.00114 | train_mae: 0.11089 | train_rmse: 0.14312 | train_mse: 0.02048 | valid_rmsle: 0.00145 | valid_mae: 0.12595 | valid_rmse: 0.16217 | valid_mse: 0.0263  |  0:01:08s\n",
      "epoch 47 | loss: 0.0253  | train_rmsle: 0.00105 | train_mae: 0.10692 | train_rmse: 0.13949 | train_mse: 0.01946 | valid_rmsle: 0.00137 | valid_mae: 0.1231  | valid_rmse: 0.1593  | valid_mse: 0.02538 |  0:01:09s\n",
      "epoch 48 | loss: 0.02733 | train_rmsle: 0.00118 | train_mae: 0.11651 | train_rmse: 0.14516 | train_mse: 0.02107 | valid_rmsle: 0.00154 | valid_mae: 0.13181 | valid_rmse: 0.1661  | valid_mse: 0.02759 |  0:01:11s\n",
      "epoch 49 | loss: 0.02091 | train_rmsle: 0.00082 | train_mae: 0.09274 | train_rmse: 0.12088 | train_mse: 0.01461 | valid_rmsle: 0.00116 | valid_mae: 0.1105  | valid_rmse: 0.14485 | valid_mse: 0.02098 |  0:01:12s\n",
      "epoch 50 | loss: 0.01956 | train_rmsle: 0.00076 | train_mae: 0.08992 | train_rmse: 0.11766 | train_mse: 0.01384 | valid_rmsle: 0.00109 | valid_mae: 0.10774 | valid_rmse: 0.14174 | valid_mse: 0.02009 |  0:01:14s\n",
      "epoch 51 | loss: 0.02078 | train_rmsle: 0.00148 | train_mae: 0.13282 | train_rmse: 0.15876 | train_mse: 0.0252  | valid_rmsle: 0.00184 | valid_mae: 0.14712 | valid_rmse: 0.17973 | valid_mse: 0.0323  |  0:01:15s\n",
      "epoch 52 | loss: 0.02702 | train_rmsle: 0.00074 | train_mae: 0.08914 | train_rmse: 0.1162  | train_mse: 0.0135  | valid_rmsle: 0.00108 | valid_mae: 0.10768 | valid_rmse: 0.14101 | valid_mse: 0.01988 |  0:01:17s\n",
      "epoch 53 | loss: 0.01946 | train_rmsle: 0.00129 | train_mae: 0.12052 | train_rmse: 0.14991 | train_mse: 0.02247 | valid_rmsle: 0.00161 | valid_mae: 0.13591 | valid_rmse: 0.16915 | valid_mse: 0.02861 |  0:01:18s\n",
      "epoch 54 | loss: 0.02217 | train_rmsle: 0.00074 | train_mae: 0.0907  | train_rmse: 0.11643 | train_mse: 0.01355 | valid_rmsle: 0.00103 | valid_mae: 0.10743 | valid_rmse: 0.13797 | valid_mse: 0.01904 |  0:01:19s\n",
      "epoch 55 | loss: 0.02113 | train_rmsle: 0.00141 | train_mae: 0.11629 | train_rmse: 0.16554 | train_mse: 0.0274  | valid_rmsle: 0.00184 | valid_mae: 0.13444 | valid_rmse: 0.18917 | valid_mse: 0.03579 |  0:01:21s\n",
      "epoch 56 | loss: 0.02286 | train_rmsle: 0.0008  | train_mae: 0.09229 | train_rmse: 0.12083 | train_mse: 0.0146  | valid_rmsle: 0.00112 | valid_mae: 0.10969 | valid_rmse: 0.14371 | valid_mse: 0.02065 |  0:01:22s\n",
      "epoch 57 | loss: 0.01776 | train_rmsle: 0.00086 | train_mae: 0.10025 | train_rmse: 0.12621 | train_mse: 0.01593 | valid_rmsle: 0.00116 | valid_mae: 0.11572 | valid_rmse: 0.14667 | valid_mse: 0.02151 |  0:01:24s\n",
      "epoch 58 | loss: 0.02115 | train_rmsle: 0.00101 | train_mae: 0.11145 | train_rmse: 0.13727 | train_mse: 0.01884 | valid_rmsle: 0.00131 | valid_mae: 0.12408 | valid_rmse: 0.15603 | valid_mse: 0.02434 |  0:01:25s\n",
      "epoch 59 | loss: 0.01605 | train_rmsle: 0.00073 | train_mae: 0.087   | train_rmse: 0.11106 | train_mse: 0.01233 | valid_rmsle: 0.001   | valid_mae: 0.10231 | valid_rmse: 0.1318  | valid_mse: 0.01737 |  0:01:27s\n",
      "epoch 60 | loss: 0.01694 | train_rmsle: 0.00071 | train_mae: 0.08983 | train_rmse: 0.11265 | train_mse: 0.01269 | valid_rmsle: 0.00097 | valid_mae: 0.10448 | valid_rmse: 0.13247 | valid_mse: 0.01755 |  0:01:28s\n",
      "epoch 61 | loss: 0.01508 | train_rmsle: 0.00065 | train_mae: 0.08283 | train_rmse: 0.10643 | train_mse: 0.01133 | valid_rmsle: 0.00091 | valid_mae: 0.09943 | valid_rmse: 0.12717 | valid_mse: 0.01617 |  0:01:30s\n",
      "epoch 62 | loss: 0.01462 | train_rmsle: 0.00075 | train_mae: 0.09555 | train_rmse: 0.11896 | train_mse: 0.01415 | valid_rmsle: 0.00101 | valid_mae: 0.1091  | valid_rmse: 0.13787 | valid_mse: 0.01901 |  0:01:31s\n",
      "epoch 63 | loss: 0.01585 | train_rmsle: 0.0005  | train_mae: 0.07272 | train_rmse: 0.09557 | train_mse: 0.00913 | valid_rmsle: 0.00075 | valid_mae: 0.08977 | valid_rmse: 0.11764 | valid_mse: 0.01384 |  0:01:32s\n",
      "epoch 64 | loss: 0.01496 | train_rmsle: 0.00059 | train_mae: 0.07805 | train_rmse: 0.10137 | train_mse: 0.01028 | valid_rmsle: 0.00083 | valid_mae: 0.09384 | valid_rmse: 0.12253 | valid_mse: 0.01501 |  0:01:34s\n",
      "epoch 65 | loss: 0.01423 | train_rmsle: 0.00068 | train_mae: 0.08671 | train_rmse: 0.11497 | train_mse: 0.01322 | valid_rmsle: 0.00096 | valid_mae: 0.10293 | valid_rmse: 0.13638 | valid_mse: 0.0186  |  0:01:35s\n",
      "epoch 66 | loss: 0.01488 | train_rmsle: 0.00047 | train_mae: 0.0704  | train_rmse: 0.09269 | train_mse: 0.00859 | valid_rmsle: 0.00072 | valid_mae: 0.08729 | valid_rmse: 0.11488 | valid_mse: 0.0132  |  0:01:37s\n",
      "epoch 67 | loss: 0.01572 | train_rmsle: 0.00047 | train_mae: 0.07107 | train_rmse: 0.09249 | train_mse: 0.00855 | valid_rmsle: 0.00071 | valid_mae: 0.08687 | valid_rmse: 0.11366 | valid_mse: 0.01292 |  0:01:38s\n",
      "epoch 68 | loss: 0.01275 | train_rmsle: 0.00043 | train_mae: 0.06761 | train_rmse: 0.08788 | train_mse: 0.00772 | valid_rmsle: 0.00066 | valid_mae: 0.08294 | valid_rmse: 0.1089  | valid_mse: 0.01186 |  0:01:40s\n",
      "epoch 69 | loss: 0.01411 | train_rmsle: 0.00053 | train_mae: 0.0766  | train_rmse: 0.09657 | train_mse: 0.00933 | valid_rmsle: 0.00076 | valid_mae: 0.09059 | valid_rmse: 0.11636 | valid_mse: 0.01354 |  0:01:41s\n",
      "epoch 70 | loss: 0.01822 | train_rmsle: 0.00054 | train_mae: 0.07774 | train_rmse: 0.10026 | train_mse: 0.01005 | valid_rmsle: 0.00077 | valid_mae: 0.09264 | valid_rmse: 0.11921 | valid_mse: 0.01421 |  0:01:43s\n",
      "epoch 71 | loss: 0.0208  | train_rmsle: 0.00059 | train_mae: 0.07717 | train_rmse: 0.09717 | train_mse: 0.00944 | valid_rmsle: 0.0008  | valid_mae: 0.0925  | valid_rmse: 0.11611 | valid_mse: 0.01348 |  0:01:44s\n",
      "epoch 72 | loss: 0.01359 | train_rmsle: 0.00073 | train_mae: 0.08569 | train_rmse: 0.10718 | train_mse: 0.01149 | valid_rmsle: 0.00095 | valid_mae: 0.09899 | valid_rmse: 0.12501 | valid_mse: 0.01563 |  0:01:45s\n",
      "epoch 73 | loss: 0.01386 | train_rmsle: 0.00168 | train_mae: 0.15132 | train_rmse: 0.16862 | train_mse: 0.02843 | valid_rmsle: 0.00188 | valid_mae: 0.15664 | valid_rmse: 0.1799  | valid_mse: 0.03237 |  0:01:47s\n",
      "epoch 74 | loss: 0.0156  | train_rmsle: 0.00076 | train_mae: 0.099   | train_rmse: 0.11821 | train_mse: 0.01397 | valid_rmsle: 0.00098 | valid_mae: 0.10971 | valid_rmse: 0.13465 | valid_mse: 0.01813 |  0:01:48s\n",
      "epoch 75 | loss: 0.01307 | train_rmsle: 0.0005  | train_mae: 0.07551 | train_rmse: 0.09569 | train_mse: 0.00916 | valid_rmsle: 0.00071 | valid_mae: 0.08946 | valid_rmse: 0.11398 | valid_mse: 0.01299 |  0:01:50s\n",
      "epoch 76 | loss: 0.01365 | train_rmsle: 0.0004  | train_mae: 0.06616 | train_rmse: 0.08418 | train_mse: 0.00709 | valid_rmsle: 0.00061 | valid_mae: 0.08136 | valid_rmse: 0.10459 | valid_mse: 0.01094 |  0:01:51s\n",
      "epoch 77 | loss: 0.0135  | train_rmsle: 0.00072 | train_mae: 0.09489 | train_rmse: 0.11808 | train_mse: 0.01394 | valid_rmsle: 0.00091 | valid_mae: 0.10427 | valid_rmse: 0.13233 | valid_mse: 0.01751 |  0:01:53s\n",
      "epoch 78 | loss: 0.01454 | train_rmsle: 0.00078 | train_mae: 0.08949 | train_rmse: 0.11072 | train_mse: 0.01226 | valid_rmsle: 0.00096 | valid_mae: 0.10021 | valid_rmse: 0.12579 | valid_mse: 0.01582 |  0:01:54s\n",
      "epoch 79 | loss: 0.01363 | train_rmsle: 0.00068 | train_mae: 0.08335 | train_rmse: 0.10342 | train_mse: 0.0107  | valid_rmsle: 0.00087 | valid_mae: 0.09616 | valid_rmse: 0.11932 | valid_mse: 0.01424 |  0:01:56s\n",
      "epoch 80 | loss: 0.01144 | train_rmsle: 0.00052 | train_mae: 0.07278 | train_rmse: 0.09195 | train_mse: 0.00845 | valid_rmsle: 0.00073 | valid_mae: 0.08658 | valid_rmse: 0.11076 | valid_mse: 0.01227 |  0:01:57s\n",
      "epoch 81 | loss: 0.0129  | train_rmsle: 0.00061 | train_mae: 0.06423 | train_rmse: 0.09701 | train_mse: 0.00941 | valid_rmsle: 0.00071 | valid_mae: 0.07987 | valid_rmse: 0.1103  | valid_mse: 0.01217 |  0:01:58s\n",
      "epoch 82 | loss: 0.01125 | train_rmsle: 0.00034 | train_mae: 0.05984 | train_rmse: 0.07795 | train_mse: 0.00608 | valid_rmsle: 0.00054 | valid_mae: 0.07571 | valid_rmse: 0.09957 | valid_mse: 0.00991 |  0:02:00s\n",
      "epoch 83 | loss: 0.01328 | train_rmsle: 0.00044 | train_mae: 0.07131 | train_rmse: 0.09135 | train_mse: 0.00834 | valid_rmsle: 0.00066 | valid_mae: 0.08483 | valid_rmse: 0.11095 | valid_mse: 0.01231 |  0:02:01s\n",
      "epoch 84 | loss: 0.01569 | train_rmsle: 0.00049 | train_mae: 0.06881 | train_rmse: 0.08775 | train_mse: 0.0077  | valid_rmsle: 0.00071 | valid_mae: 0.08389 | valid_rmse: 0.10846 | valid_mse: 0.01176 |  0:02:03s\n",
      "epoch 85 | loss: 0.01246 | train_rmsle: 0.00041 | train_mae: 0.06815 | train_rmse: 0.08677 | train_mse: 0.00753 | valid_rmsle: 0.00062 | valid_mae: 0.08133 | valid_rmse: 0.10676 | valid_mse: 0.0114  |  0:02:04s\n",
      "epoch 86 | loss: 0.01215 | train_rmsle: 0.00039 | train_mae: 0.0644  | train_rmse: 0.08114 | train_mse: 0.00658 | valid_rmsle: 0.0006  | valid_mae: 0.07981 | valid_rmse: 0.1033  | valid_mse: 0.01067 |  0:02:06s\n",
      "epoch 87 | loss: 0.01179 | train_rmsle: 0.00048 | train_mae: 0.0706  | train_rmse: 0.08993 | train_mse: 0.00809 | valid_rmsle: 0.0007  | valid_mae: 0.08543 | valid_rmse: 0.11018 | valid_mse: 0.01214 |  0:02:07s\n",
      "epoch 88 | loss: 0.01125 | train_rmsle: 0.0008  | train_mae: 0.07938 | train_rmse: 0.10302 | train_mse: 0.01061 | valid_rmsle: 0.00098 | valid_mae: 0.09278 | valid_rmse: 0.11987 | valid_mse: 0.01437 |  0:02:08s\n",
      "epoch 89 | loss: 0.01162 | train_rmsle: 0.00047 | train_mae: 0.076   | train_rmse: 0.09321 | train_mse: 0.00869 | valid_rmsle: 0.00069 | valid_mae: 0.08933 | valid_rmse: 0.11306 | valid_mse: 0.01278 |  0:02:10s\n",
      "epoch 90 | loss: 0.01117 | train_rmsle: 0.00095 | train_mae: 0.10611 | train_rmse: 0.12269 | train_mse: 0.01505 | valid_rmsle: 0.00114 | valid_mae: 0.1147  | valid_rmse: 0.1373  | valid_mse: 0.01885 |  0:02:11s\n",
      "epoch 91 | loss: 0.01124 | train_rmsle: 0.00028 | train_mae: 0.05471 | train_rmse: 0.0705  | train_mse: 0.00497 | valid_rmsle: 0.0005  | valid_mae: 0.07263 | valid_rmse: 0.09474 | valid_mse: 0.00898 |  0:02:13s\n",
      "epoch 92 | loss: 0.00977 | train_rmsle: 0.00039 | train_mae: 0.0611  | train_rmse: 0.07793 | train_mse: 0.00607 | valid_rmsle: 0.00058 | valid_mae: 0.07639 | valid_rmse: 0.09825 | valid_mse: 0.00965 |  0:02:14s\n",
      "epoch 93 | loss: 0.00923 | train_rmsle: 0.00038 | train_mae: 0.06696 | train_rmse: 0.08289 | train_mse: 0.00687 | valid_rmsle: 0.0006  | valid_mae: 0.0814  | valid_rmse: 0.10383 | valid_mse: 0.01078 |  0:02:16s\n",
      "epoch 94 | loss: 0.01318 | train_rmsle: 0.00047 | train_mae: 0.07486 | train_rmse: 0.09019 | train_mse: 0.00813 | valid_rmsle: 0.00068 | valid_mae: 0.08765 | valid_rmse: 0.10965 | valid_mse: 0.01202 |  0:02:17s\n",
      "epoch 95 | loss: 0.01061 | train_rmsle: 0.00065 | train_mae: 0.08339 | train_rmse: 0.10048 | train_mse: 0.0101  | valid_rmsle: 0.00084 | valid_mae: 0.0949  | valid_rmse: 0.11718 | valid_mse: 0.01373 |  0:02:19s\n",
      "epoch 96 | loss: 0.01097 | train_rmsle: 0.00125 | train_mae: 0.11016 | train_rmse: 0.13137 | train_mse: 0.01726 | valid_rmsle: 0.00142 | valid_mae: 0.11947 | valid_rmse: 0.14522 | valid_mse: 0.02109 |  0:02:20s\n",
      "epoch 97 | loss: 0.01196 | train_rmsle: 0.00028 | train_mae: 0.0558  | train_rmse: 0.07191 | train_mse: 0.00517 | valid_rmsle: 0.00049 | valid_mae: 0.0718  | valid_rmse: 0.09479 | valid_mse: 0.00898 |  0:02:21s\n",
      "epoch 98 | loss: 0.01243 | train_rmsle: 0.00088 | train_mae: 0.0911  | train_rmse: 0.11259 | train_mse: 0.01268 | valid_rmsle: 0.00108 | valid_mae: 0.10136 | valid_rmse: 0.1282  | valid_mse: 0.01644 |  0:02:23s\n",
      "epoch 99 | loss: 0.01041 | train_rmsle: 0.00027 | train_mae: 0.05391 | train_rmse: 0.06883 | train_mse: 0.00474 | valid_rmsle: 0.00048 | valid_mae: 0.07113 | valid_rmse: 0.09284 | valid_mse: 0.00862 |  0:02:24s\n",
      "epoch 100| loss: 0.01068 | train_rmsle: 0.00062 | train_mae: 0.0879  | train_rmse: 0.10366 | train_mse: 0.01075 | valid_rmsle: 0.00081 | valid_mae: 0.09697 | valid_rmse: 0.11924 | valid_mse: 0.01422 |  0:02:26s\n",
      "epoch 101| loss: 0.00972 | train_rmsle: 0.00032 | train_mae: 0.05466 | train_rmse: 0.07086 | train_mse: 0.00502 | valid_rmsle: 0.00053 | valid_mae: 0.07243 | valid_rmse: 0.09401 | valid_mse: 0.00884 |  0:02:27s\n",
      "epoch 102| loss: 0.01142 | train_rmsle: 0.00049 | train_mae: 0.07886 | train_rmse: 0.09418 | train_mse: 0.00887 | valid_rmsle: 0.00071 | valid_mae: 0.09095 | valid_rmse: 0.11305 | valid_mse: 0.01278 |  0:02:29s\n",
      "epoch 103| loss: 0.01042 | train_rmsle: 0.00031 | train_mae: 0.05823 | train_rmse: 0.07325 | train_mse: 0.00536 | valid_rmsle: 0.00054 | valid_mae: 0.07581 | valid_rmse: 0.09695 | valid_mse: 0.0094  |  0:02:30s\n",
      "epoch 104| loss: 0.01318 | train_rmsle: 0.00028 | train_mae: 0.05582 | train_rmse: 0.07126 | train_mse: 0.00508 | valid_rmsle: 0.00051 | valid_mae: 0.07414 | valid_rmse: 0.09602 | valid_mse: 0.00922 |  0:02:32s\n",
      "epoch 105| loss: 0.0113  | train_rmsle: 0.00064 | train_mae: 0.08095 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00088 | valid_mae: 0.09508 | valid_rmse: 0.12178 | valid_mse: 0.01483 |  0:02:33s\n",
      "epoch 106| loss: 0.01168 | train_rmsle: 0.00065 | train_mae: 0.08761 | train_rmse: 0.10558 | train_mse: 0.01115 | valid_rmsle: 0.00088 | valid_mae: 0.10001 | valid_rmse: 0.1232  | valid_mse: 0.01518 |  0:02:34s\n",
      "epoch 107| loss: 0.01566 | train_rmsle: 0.00034 | train_mae: 0.06168 | train_rmse: 0.07908 | train_mse: 0.00625 | valid_rmsle: 0.00058 | valid_mae: 0.08027 | valid_rmse: 0.1022  | valid_mse: 0.01045 |  0:02:36s\n",
      "epoch 108| loss: 0.01083 | train_rmsle: 0.00027 | train_mae: 0.05344 | train_rmse: 0.06852 | train_mse: 0.0047  | valid_rmsle: 0.00049 | valid_mae: 0.07109 | valid_rmse: 0.09224 | valid_mse: 0.00851 |  0:02:37s\n",
      "epoch 109| loss: 0.01013 | train_rmsle: 0.00028 | train_mae: 0.05607 | train_rmse: 0.07158 | train_mse: 0.00512 | valid_rmsle: 0.0005  | valid_mae: 0.07387 | valid_rmse: 0.09494 | valid_mse: 0.00901 |  0:02:39s\n",
      "epoch 110| loss: 0.0105  | train_rmsle: 0.00034 | train_mae: 0.06476 | train_rmse: 0.08112 | train_mse: 0.00658 | valid_rmsle: 0.00056 | valid_mae: 0.08077 | valid_rmse: 0.10175 | valid_mse: 0.01035 |  0:02:40s\n",
      "epoch 111| loss: 0.00932 | train_rmsle: 0.00066 | train_mae: 0.0791  | train_rmse: 0.09869 | train_mse: 0.00974 | valid_rmsle: 0.00081 | valid_mae: 0.08966 | valid_rmse: 0.11412 | valid_mse: 0.01302 |  0:02:42s\n",
      "epoch 112| loss: 0.01306 | train_rmsle: 0.00039 | train_mae: 0.06871 | train_rmse: 0.08384 | train_mse: 0.00703 | valid_rmsle: 0.0006  | valid_mae: 0.0814  | valid_rmse: 0.10373 | valid_mse: 0.01076 |  0:02:43s\n",
      "epoch 113| loss: 0.01298 | train_rmsle: 0.00033 | train_mae: 0.06043 | train_rmse: 0.07771 | train_mse: 0.00604 | valid_rmsle: 0.00056 | valid_mae: 0.07682 | valid_rmse: 0.10076 | valid_mse: 0.01015 |  0:02:44s\n",
      "epoch 114| loss: 0.01107 | train_rmsle: 0.00041 | train_mae: 0.06063 | train_rmse: 0.07792 | train_mse: 0.00607 | valid_rmsle: 0.00063 | valid_mae: 0.07708 | valid_rmse: 0.10011 | valid_mse: 0.01002 |  0:02:46s\n",
      "epoch 115| loss: 0.00886 | train_rmsle: 0.00024 | train_mae: 0.05183 | train_rmse: 0.06645 | train_mse: 0.00442 | valid_rmsle: 0.00047 | valid_mae: 0.07063 | valid_rmse: 0.09142 | valid_mse: 0.00836 |  0:02:47s\n",
      "epoch 116| loss: 0.01263 | train_rmsle: 0.00036 | train_mae: 0.06072 | train_rmse: 0.07823 | train_mse: 0.00612 | valid_rmsle: 0.00059 | valid_mae: 0.07855 | valid_rmse: 0.10028 | valid_mse: 0.01006 |  0:02:49s\n",
      "epoch 117| loss: 0.01114 | train_rmsle: 0.00056 | train_mae: 0.07372 | train_rmse: 0.09326 | train_mse: 0.0087  | valid_rmsle: 0.00076 | valid_mae: 0.08754 | valid_rmse: 0.11215 | valid_mse: 0.01258 |  0:02:50s\n",
      "epoch 118| loss: 0.01376 | train_rmsle: 0.0005  | train_mae: 0.07708 | train_rmse: 0.09683 | train_mse: 0.00938 | valid_rmsle: 0.00076 | valid_mae: 0.09212 | valid_rmse: 0.11754 | valid_mse: 0.01382 |  0:02:52s\n",
      "epoch 119| loss: 0.01105 | train_rmsle: 0.0003  | train_mae: 0.05847 | train_rmse: 0.07552 | train_mse: 0.0057  | valid_rmsle: 0.00056 | valid_mae: 0.07875 | valid_rmse: 0.10092 | valid_mse: 0.01018 |  0:02:53s\n",
      "epoch 120| loss: 0.01207 | train_rmsle: 0.0004  | train_mae: 0.06175 | train_rmse: 0.07881 | train_mse: 0.00621 | valid_rmsle: 0.00065 | valid_mae: 0.07942 | valid_rmse: 0.10291 | valid_mse: 0.01059 |  0:02:55s\n",
      "epoch 121| loss: 0.0091  | train_rmsle: 0.00028 | train_mae: 0.05488 | train_rmse: 0.07138 | train_mse: 0.00509 | valid_rmsle: 0.00054 | valid_mae: 0.07514 | valid_rmse: 0.09838 | valid_mse: 0.00968 |  0:02:56s\n",
      "epoch 122| loss: 0.00957 | train_rmsle: 0.00073 | train_mae: 0.07781 | train_rmse: 0.10068 | train_mse: 0.01014 | valid_rmsle: 0.00097 | valid_mae: 0.09263 | valid_rmse: 0.12076 | valid_mse: 0.01458 |  0:02:57s\n",
      "epoch 123| loss: 0.01076 | train_rmsle: 0.00042 | train_mae: 0.06804 | train_rmse: 0.08548 | train_mse: 0.00731 | valid_rmsle: 0.00066 | valid_mae: 0.08441 | valid_rmse: 0.10698 | valid_mse: 0.01144 |  0:02:59s\n",
      "epoch 124| loss: 0.00854 | train_rmsle: 0.00022 | train_mae: 0.04793 | train_rmse: 0.06171 | train_mse: 0.00381 | valid_rmsle: 0.00046 | valid_mae: 0.06729 | valid_rmse: 0.08929 | valid_mse: 0.00797 |  0:03:00s\n",
      "epoch 125| loss: 0.00992 | train_rmsle: 0.00032 | train_mae: 0.05663 | train_rmse: 0.07183 | train_mse: 0.00516 | valid_rmsle: 0.00056 | valid_mae: 0.07497 | valid_rmse: 0.09687 | valid_mse: 0.00938 |  0:03:02s\n",
      "epoch 126| loss: 0.00935 | train_rmsle: 0.00043 | train_mae: 0.06361 | train_rmse: 0.08097 | train_mse: 0.00656 | valid_rmsle: 0.00066 | valid_mae: 0.08063 | valid_rmse: 0.10344 | valid_mse: 0.0107  |  0:03:03s\n",
      "epoch 127| loss: 0.00986 | train_rmsle: 0.00025 | train_mae: 0.04913 | train_rmse: 0.06311 | train_mse: 0.00398 | valid_rmsle: 0.00048 | valid_mae: 0.06863 | valid_rmse: 0.09014 | valid_mse: 0.00813 |  0:03:05s\n",
      "epoch 128| loss: 0.00911 | train_rmsle: 0.00025 | train_mae: 0.05133 | train_rmse: 0.06559 | train_mse: 0.0043  | valid_rmsle: 0.0005  | valid_mae: 0.07243 | valid_rmse: 0.09306 | valid_mse: 0.00866 |  0:03:06s\n",
      "epoch 129| loss: 0.00959 | train_rmsle: 0.00042 | train_mae: 0.07361 | train_rmse: 0.08997 | train_mse: 0.00809 | valid_rmsle: 0.00067 | valid_mae: 0.0894  | valid_rmse: 0.11109 | valid_mse: 0.01234 |  0:03:07s\n",
      "epoch 130| loss: 0.01382 | train_rmsle: 0.00037 | train_mae: 0.06446 | train_rmse: 0.08269 | train_mse: 0.00684 | valid_rmsle: 0.00062 | valid_mae: 0.08258 | valid_rmse: 0.10639 | valid_mse: 0.01132 |  0:03:09s\n",
      "epoch 131| loss: 0.0138  | train_rmsle: 0.00029 | train_mae: 0.05524 | train_rmse: 0.07109 | train_mse: 0.00505 | valid_rmsle: 0.00055 | valid_mae: 0.07304 | valid_rmse: 0.09637 | valid_mse: 0.00929 |  0:03:10s\n",
      "epoch 132| loss: 0.00915 | train_rmsle: 0.00025 | train_mae: 0.05133 | train_rmse: 0.06607 | train_mse: 0.00437 | valid_rmsle: 0.00053 | valid_mae: 0.0733  | valid_rmse: 0.09517 | valid_mse: 0.00906 |  0:03:12s\n",
      "epoch 133| loss: 0.01092 | train_rmsle: 0.00025 | train_mae: 0.05365 | train_rmse: 0.06807 | train_mse: 0.00463 | valid_rmsle: 0.00052 | valid_mae: 0.07344 | valid_rmse: 0.09623 | valid_mse: 0.00926 |  0:03:13s\n",
      "epoch 134| loss: 0.0127  | train_rmsle: 0.0006  | train_mae: 0.07967 | train_rmse: 0.09574 | train_mse: 0.00917 | valid_rmsle: 0.00087 | valid_mae: 0.09265 | valid_rmse: 0.11727 | valid_mse: 0.01375 |  0:03:15s\n",
      "epoch 135| loss: 0.012   | train_rmsle: 0.0003  | train_mae: 0.06074 | train_rmse: 0.07505 | train_mse: 0.00563 | valid_rmsle: 0.00058 | valid_mae: 0.07852 | valid_rmse: 0.10105 | valid_mse: 0.01021 |  0:03:16s\n",
      "epoch 136| loss: 0.01094 | train_rmsle: 0.00035 | train_mae: 0.06534 | train_rmse: 0.07907 | train_mse: 0.00625 | valid_rmsle: 0.00061 | valid_mae: 0.08005 | valid_rmse: 0.10287 | valid_mse: 0.01058 |  0:03:18s\n",
      "epoch 137| loss: 0.01386 | train_rmsle: 0.00054 | train_mae: 0.07187 | train_rmse: 0.08923 | train_mse: 0.00796 | valid_rmsle: 0.0008  | valid_mae: 0.08631 | valid_rmse: 0.11071 | valid_mse: 0.01226 |  0:03:19s\n",
      "epoch 138| loss: 0.01159 | train_rmsle: 0.00018 | train_mae: 0.04264 | train_rmse: 0.05492 | train_mse: 0.00302 | valid_rmsle: 0.00044 | valid_mae: 0.06589 | valid_rmse: 0.08615 | valid_mse: 0.00742 |  0:03:20s\n",
      "epoch 139| loss: 0.01054 | train_rmsle: 0.00023 | train_mae: 0.05094 | train_rmse: 0.06473 | train_mse: 0.00419 | valid_rmsle: 0.00049 | valid_mae: 0.07122 | valid_rmse: 0.09288 | valid_mse: 0.00863 |  0:03:22s\n",
      "epoch 140| loss: 0.00989 | train_rmsle: 0.00016 | train_mae: 0.04223 | train_rmse: 0.05387 | train_mse: 0.0029  | valid_rmsle: 0.00043 | valid_mae: 0.06625 | valid_rmse: 0.08622 | valid_mse: 0.00743 |  0:03:23s\n",
      "epoch 141| loss: 0.00971 | train_rmsle: 0.00016 | train_mae: 0.04209 | train_rmse: 0.05392 | train_mse: 0.00291 | valid_rmsle: 0.00044 | valid_mae: 0.0672  | valid_rmse: 0.08711 | valid_mse: 0.00759 |  0:03:25s\n",
      "epoch 142| loss: 0.00818 | train_rmsle: 0.00016 | train_mae: 0.04162 | train_rmse: 0.05369 | train_mse: 0.00288 | valid_rmsle: 0.00043 | valid_mae: 0.06698 | valid_rmse: 0.08666 | valid_mse: 0.00751 |  0:03:26s\n",
      "epoch 143| loss: 0.00876 | train_rmsle: 0.00028 | train_mae: 0.05251 | train_rmse: 0.0661  | train_mse: 0.00437 | valid_rmsle: 0.00055 | valid_mae: 0.07352 | valid_rmse: 0.09512 | valid_mse: 0.00905 |  0:03:28s\n",
      "epoch 144| loss: 0.01    | train_rmsle: 0.00031 | train_mae: 0.06365 | train_rmse: 0.07748 | train_mse: 0.006   | valid_rmsle: 0.0006  | valid_mae: 0.08325 | valid_rmse: 0.10427 | valid_mse: 0.01087 |  0:03:29s\n",
      "epoch 145| loss: 0.01553 | train_rmsle: 0.00324 | train_mae: 0.18351 | train_rmse: 0.22819 | train_mse: 0.05207 | valid_rmsle: 0.0035  | valid_mae: 0.19371 | valid_rmse: 0.24043 | valid_mse: 0.05781 |  0:03:31s\n",
      "epoch 146| loss: 0.01796 | train_rmsle: 0.00128 | train_mae: 0.11569 | train_rmse: 0.15671 | train_mse: 0.02456 | valid_rmsle: 0.0016  | valid_mae: 0.13212 | valid_rmse: 0.1739  | valid_mse: 0.03024 |  0:03:32s\n",
      "epoch 147| loss: 0.01727 | train_rmsle: 0.00063 | train_mae: 0.08193 | train_rmse: 0.10916 | train_mse: 0.01192 | valid_rmsle: 0.00097 | valid_mae: 0.10189 | valid_rmse: 0.13273 | valid_mse: 0.01762 |  0:03:33s\n",
      "epoch 148| loss: 0.01406 | train_rmsle: 0.00091 | train_mae: 0.09238 | train_rmse: 0.11682 | train_mse: 0.01365 | valid_rmsle: 0.00124 | valid_mae: 0.11094 | valid_rmse: 0.14026 | valid_mse: 0.01967 |  0:03:35s\n",
      "epoch 149| loss: 0.01095 | train_rmsle: 0.0011  | train_mae: 0.0997  | train_rmse: 0.12502 | train_mse: 0.01563 | valid_rmsle: 0.00137 | valid_mae: 0.11418 | valid_rmse: 0.14367 | valid_mse: 0.02064 |  0:03:36s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 138 and best_valid_mse = 0.00742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00813222251691739 RMSE: 0.09017883630274562 R2: 0.9640017844139963 MAE: 0.06946582838404507\n",
      "=====================================\n",
      "Successfully saved model at model/512_32_5_0.02_150.pt.zip\n",
      "New best model: 512_32_5_0.02_150 with r2: 0.9640017844139963\n",
      "[88/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.49595 | train_rmsle: 0.25339 | train_mae: 1.66944 | train_rmse: 1.73779 | train_mse: 3.01992 | valid_rmsle: 0.25516 | valid_mae: 1.67669 | valid_rmse: 1.74425 | valid_mse: 3.04241 |  0:00:01s\n",
      "epoch 1  | loss: 0.68901 | train_rmsle: 0.12799 | train_mae: 1.25026 | train_rmse: 1.33312 | train_mse: 1.7772  | valid_rmsle: 0.12859 | valid_mae: 1.25369 | valid_rmse: 1.33734 | valid_mse: 1.78847 |  0:00:03s\n",
      "epoch 2  | loss: 0.36487 | train_rmsle: 0.10927 | train_mae: 1.16508 | train_rmse: 1.25029 | train_mse: 1.56324 | valid_rmsle: 0.10985 | valid_mae: 1.1683  | valid_rmse: 1.25477 | valid_mse: 1.57445 |  0:00:04s\n",
      "epoch 3  | loss: 0.31525 | train_rmsle: 0.08541 | train_mae: 1.04073 | train_rmse: 1.1293  | train_mse: 1.27531 | valid_rmsle: 0.08568 | valid_mae: 1.04268 | valid_rmse: 1.13258 | valid_mse: 1.28273 |  0:00:05s\n",
      "epoch 4  | loss: 0.28473 | train_rmsle: 0.03898 | train_mae: 0.71155 | train_rmse: 0.80416 | train_mse: 0.64667 | valid_rmsle: 0.0389  | valid_mae: 0.71111 | valid_rmse: 0.80603 | valid_mse: 0.64968 |  0:00:07s\n",
      "epoch 5  | loss: 0.2469  | train_rmsle: 0.03499 | train_mae: 0.67332 | train_rmse: 0.76575 | train_mse: 0.58637 | valid_rmsle: 0.03505 | valid_mae: 0.67479 | valid_rmse: 0.76904 | valid_mse: 0.59142 |  0:00:08s\n",
      "epoch 6  | loss: 0.24164 | train_rmsle: 0.03    | train_mae: 0.62198 | train_rmse: 0.71304 | train_mse: 0.50843 | valid_rmsle: 0.03004 | valid_mae: 0.62368 | valid_rmse: 0.7165  | valid_mse: 0.51337 |  0:00:10s\n",
      "epoch 7  | loss: 0.23761 | train_rmsle: 0.01821 | train_mae: 0.46887 | train_rmse: 0.55648 | train_mse: 0.30967 | valid_rmsle: 0.0179  | valid_mae: 0.47142 | valid_rmse: 0.55645 | valid_mse: 0.30963 |  0:00:11s\n",
      "epoch 8  | loss: 0.23888 | train_rmsle: 0.01668 | train_mae: 0.4418  | train_rmse: 0.52992 | train_mse: 0.28082 | valid_rmsle: 0.01633 | valid_mae: 0.44542 | valid_rmse: 0.52927 | valid_mse: 0.28013 |  0:00:13s\n",
      "epoch 9  | loss: 0.23455 | train_rmsle: 0.01677 | train_mae: 0.44347 | train_rmse: 0.53146 | train_mse: 0.28245 | valid_rmsle: 0.01637 | valid_mae: 0.44638 | valid_rmse: 0.53008 | valid_mse: 0.28099 |  0:00:14s\n",
      "epoch 10 | loss: 0.22851 | train_rmsle: 0.01561 | train_mae: 0.41861 | train_rmse: 0.50853 | train_mse: 0.2586  | valid_rmsle: 0.01501 | valid_mae: 0.41817 | valid_rmse: 0.50392 | valid_mse: 0.25394 |  0:00:16s\n",
      "epoch 11 | loss: 0.22824 | train_rmsle: 0.01579 | train_mae: 0.42471 | train_rmse: 0.51359 | train_mse: 0.26377 | valid_rmsle: 0.01528 | valid_mae: 0.4254  | valid_rmse: 0.51059 | valid_mse: 0.2607  |  0:00:17s\n",
      "epoch 12 | loss: 0.23593 | train_rmsle: 0.01464 | train_mae: 0.38363 | train_rmse: 0.48311 | train_mse: 0.2334  | valid_rmsle: 0.0141  | valid_mae: 0.38587 | valid_rmse: 0.47947 | valid_mse: 0.22989 |  0:00:18s\n",
      "epoch 13 | loss: 0.23634 | train_rmsle: 0.01486 | train_mae: 0.39598 | train_rmse: 0.49063 | train_mse: 0.24072 | valid_rmsle: 0.01436 | valid_mae: 0.39749 | valid_rmse: 0.48752 | valid_mse: 0.23767 |  0:00:20s\n",
      "epoch 14 | loss: 0.22241 | train_rmsle: 0.01545 | train_mae: 0.41836 | train_rmse: 0.50715 | train_mse: 0.2572  | valid_rmsle: 0.01495 | valid_mae: 0.41881 | valid_rmse: 0.50406 | valid_mse: 0.25407 |  0:00:21s\n",
      "epoch 15 | loss: 0.2231  | train_rmsle: 0.01643 | train_mae: 0.43945 | train_rmse: 0.52718 | train_mse: 0.27792 | valid_rmsle: 0.01598 | valid_mae: 0.44038 | valid_rmse: 0.52493 | valid_mse: 0.27555 |  0:00:23s\n",
      "epoch 16 | loss: 0.22186 | train_rmsle: 0.01838 | train_mae: 0.47141 | train_rmse: 0.56036 | train_mse: 0.314   | valid_rmsle: 0.01811 | valid_mae: 0.47246 | valid_rmse: 0.56081 | valid_mse: 0.3145  |  0:00:24s\n",
      "epoch 17 | loss: 0.22365 | train_rmsle: 0.01521 | train_mae: 0.41414 | train_rmse: 0.50296 | train_mse: 0.25297 | valid_rmsle: 0.01474 | valid_mae: 0.41544 | valid_rmse: 0.50047 | valid_mse: 0.25047 |  0:00:26s\n",
      "epoch 18 | loss: 0.2175  | train_rmsle: 0.01472 | train_mae: 0.40358 | train_rmse: 0.49313 | train_mse: 0.24318 | valid_rmsle: 0.0143  | valid_mae: 0.40589 | valid_rmse: 0.4915  | valid_mse: 0.24158 |  0:00:27s\n",
      "epoch 19 | loss: 0.21615 | train_rmsle: 0.01539 | train_mae: 0.41939 | train_rmse: 0.50794 | train_mse: 0.258   | valid_rmsle: 0.01502 | valid_mae: 0.42126 | valid_rmse: 0.50725 | valid_mse: 0.2573  |  0:00:29s\n",
      "epoch 20 | loss: 0.21417 | train_rmsle: 0.01465 | train_mae: 0.4051  | train_rmse: 0.49441 | train_mse: 0.24444 | valid_rmsle: 0.01442 | valid_mae: 0.40865 | valid_rmse: 0.49609 | valid_mse: 0.2461  |  0:00:30s\n",
      "epoch 21 | loss: 0.21138 | train_rmsle: 0.01409 | train_mae: 0.39397 | train_rmse: 0.48346 | train_mse: 0.23373 | valid_rmsle: 0.01396 | valid_mae: 0.40166 | valid_rmse: 0.48728 | valid_mse: 0.23744 |  0:00:31s\n",
      "epoch 22 | loss: 0.20891 | train_rmsle: 0.01327 | train_mae: 0.37149 | train_rmse: 0.46351 | train_mse: 0.21484 | valid_rmsle: 0.01309 | valid_mae: 0.37872 | valid_rmse: 0.46651 | valid_mse: 0.21763 |  0:00:33s\n",
      "epoch 23 | loss: 0.20709 | train_rmsle: 0.01378 | train_mae: 0.39185 | train_rmse: 0.47861 | train_mse: 0.22906 | valid_rmsle: 0.01373 | valid_mae: 0.402   | valid_rmse: 0.48353 | valid_mse: 0.2338  |  0:00:34s\n",
      "epoch 24 | loss: 0.19133 | train_rmsle: 0.01131 | train_mae: 0.33634 | train_rmse: 0.42473 | train_mse: 0.18039 | valid_rmsle: 0.01128 | valid_mae: 0.34861 | valid_rmse: 0.43143 | valid_mse: 0.18613 |  0:00:36s\n",
      "epoch 25 | loss: 0.17035 | train_rmsle: 0.00923 | train_mae: 0.29644 | train_rmse: 0.37938 | train_mse: 0.14393 | valid_rmsle: 0.00935 | valid_mae: 0.30985 | valid_rmse: 0.38914 | valid_mse: 0.15143 |  0:00:37s\n",
      "epoch 26 | loss: 0.15098 | train_rmsle: 0.01019 | train_mae: 0.34153 | train_rmse: 0.41089 | train_mse: 0.16883 | valid_rmsle: 0.01002 | valid_mae: 0.3425  | valid_rmse: 0.41312 | valid_mse: 0.17067 |  0:00:39s\n",
      "epoch 27 | loss: 0.1364  | train_rmsle: 0.00839 | train_mae: 0.29743 | train_rmse: 0.36656 | train_mse: 0.13437 | valid_rmsle: 0.00802 | valid_mae: 0.29534 | valid_rmse: 0.36423 | valid_mse: 0.13267 |  0:00:40s\n",
      "epoch 28 | loss: 0.11581 | train_rmsle: 0.00734 | train_mae: 0.26933 | train_rmse: 0.33809 | train_mse: 0.11431 | valid_rmsle: 0.00697 | valid_mae: 0.26526 | valid_rmse: 0.33496 | valid_mse: 0.1122  |  0:00:42s\n",
      "epoch 29 | loss: 0.10191 | train_rmsle: 0.00777 | train_mae: 0.28666 | train_rmse: 0.35164 | train_mse: 0.12365 | valid_rmsle: 0.00766 | valid_mae: 0.28891 | valid_rmse: 0.35446 | valid_mse: 0.12565 |  0:00:43s\n",
      "epoch 30 | loss: 0.08792 | train_rmsle: 0.00634 | train_mae: 0.25072 | train_rmse: 0.31476 | train_mse: 0.09907 | valid_rmsle: 0.00637 | valid_mae: 0.25715 | valid_rmse: 0.31995 | valid_mse: 0.10237 |  0:00:44s\n",
      "epoch 31 | loss: 0.07499 | train_rmsle: 0.00426 | train_mae: 0.20903 | train_rmse: 0.26485 | train_mse: 0.07015 | valid_rmsle: 0.00448 | valid_mae: 0.22109 | valid_rmse: 0.2757  | valid_mse: 0.07601 |  0:00:46s\n",
      "epoch 32 | loss: 0.06929 | train_rmsle: 0.00384 | train_mae: 0.19726 | train_rmse: 0.2514  | train_mse: 0.0632  | valid_rmsle: 0.00417 | valid_mae: 0.2115  | valid_rmse: 0.26663 | valid_mse: 0.07109 |  0:00:47s\n",
      "epoch 33 | loss: 0.05978 | train_rmsle: 0.00288 | train_mae: 0.17172 | train_rmse: 0.22061 | train_mse: 0.04867 | valid_rmsle: 0.00314 | valid_mae: 0.183   | valid_rmse: 0.23345 | valid_mse: 0.0545  |  0:00:49s\n",
      "epoch 34 | loss: 0.05236 | train_rmsle: 0.00284 | train_mae: 0.16708 | train_rmse: 0.21417 | train_mse: 0.04587 | valid_rmsle: 0.00312 | valid_mae: 0.17937 | valid_rmse: 0.22878 | valid_mse: 0.05234 |  0:00:50s\n",
      "epoch 35 | loss: 0.061   | train_rmsle: 0.00399 | train_mae: 0.20626 | train_rmse: 0.26128 | train_mse: 0.06827 | valid_rmsle: 0.0043  | valid_mae: 0.21615 | valid_rmse: 0.27365 | valid_mse: 0.07488 |  0:00:52s\n",
      "epoch 36 | loss: 0.05627 | train_rmsle: 0.00262 | train_mae: 0.16359 | train_rmse: 0.20984 | train_mse: 0.04403 | valid_rmsle: 0.0031  | valid_mae: 0.18103 | valid_rmse: 0.23065 | valid_mse: 0.0532  |  0:00:53s\n",
      "epoch 37 | loss: 0.04082 | train_rmsle: 0.0019  | train_mae: 0.13923 | train_rmse: 0.18068 | train_mse: 0.03265 | valid_rmsle: 0.00236 | valid_mae: 0.15801 | valid_rmse: 0.20383 | valid_mse: 0.04155 |  0:00:54s\n",
      "epoch 38 | loss: 0.0382  | train_rmsle: 0.00177 | train_mae: 0.13581 | train_rmse: 0.17651 | train_mse: 0.03116 | valid_rmsle: 0.00222 | valid_mae: 0.15471 | valid_rmse: 0.1994  | valid_mse: 0.03976 |  0:00:56s\n",
      "epoch 39 | loss: 0.03422 | train_rmsle: 0.00167 | train_mae: 0.13195 | train_rmse: 0.17176 | train_mse: 0.0295  | valid_rmsle: 0.00205 | valid_mae: 0.14707 | valid_rmse: 0.19209 | valid_mse: 0.0369  |  0:00:57s\n",
      "epoch 40 | loss: 0.03408 | train_rmsle: 0.0015  | train_mae: 0.12505 | train_rmse: 0.16329 | train_mse: 0.02666 | valid_rmsle: 0.00189 | valid_mae: 0.14033 | valid_rmse: 0.18417 | valid_mse: 0.03392 |  0:00:59s\n",
      "epoch 41 | loss: 0.03153 | train_rmsle: 0.00145 | train_mae: 0.12322 | train_rmse: 0.16167 | train_mse: 0.02614 | valid_rmsle: 0.00178 | valid_mae: 0.13658 | valid_rmse: 0.17979 | valid_mse: 0.03233 |  0:01:00s\n",
      "epoch 42 | loss: 0.02812 | train_rmsle: 0.00141 | train_mae: 0.12499 | train_rmse: 0.16235 | train_mse: 0.02636 | valid_rmsle: 0.00182 | valid_mae: 0.14206 | valid_rmse: 0.18427 | valid_mse: 0.03396 |  0:01:02s\n",
      "epoch 43 | loss: 0.02677 | train_rmsle: 0.00203 | train_mae: 0.15205 | train_rmse: 0.18475 | train_mse: 0.03413 | valid_rmsle: 0.00242 | valid_mae: 0.1663  | valid_rmse: 0.20435 | valid_mse: 0.04176 |  0:01:03s\n",
      "epoch 44 | loss: 0.02811 | train_rmsle: 0.00201 | train_mae: 0.14875 | train_rmse: 0.18222 | train_mse: 0.0332  | valid_rmsle: 0.00241 | valid_mae: 0.1642  | valid_rmse: 0.20189 | valid_mse: 0.04076 |  0:01:05s\n",
      "epoch 45 | loss: 0.03048 | train_rmsle: 0.00132 | train_mae: 0.11846 | train_rmse: 0.15315 | train_mse: 0.02345 | valid_rmsle: 0.00163 | valid_mae: 0.13252 | valid_rmse: 0.17063 | valid_mse: 0.02912 |  0:01:06s\n",
      "epoch 46 | loss: 0.02591 | train_rmsle: 0.00114 | train_mae: 0.11089 | train_rmse: 0.14312 | train_mse: 0.02048 | valid_rmsle: 0.00145 | valid_mae: 0.12595 | valid_rmse: 0.16217 | valid_mse: 0.0263  |  0:01:08s\n",
      "epoch 47 | loss: 0.0253  | train_rmsle: 0.00105 | train_mae: 0.10692 | train_rmse: 0.13949 | train_mse: 0.01946 | valid_rmsle: 0.00137 | valid_mae: 0.1231  | valid_rmse: 0.1593  | valid_mse: 0.02538 |  0:01:09s\n",
      "epoch 48 | loss: 0.02733 | train_rmsle: 0.00118 | train_mae: 0.11651 | train_rmse: 0.14516 | train_mse: 0.02107 | valid_rmsle: 0.00154 | valid_mae: 0.13181 | valid_rmse: 0.1661  | valid_mse: 0.02759 |  0:01:10s\n",
      "epoch 49 | loss: 0.02091 | train_rmsle: 0.00082 | train_mae: 0.09274 | train_rmse: 0.12088 | train_mse: 0.01461 | valid_rmsle: 0.00116 | valid_mae: 0.1105  | valid_rmse: 0.14485 | valid_mse: 0.02098 |  0:01:12s\n",
      "epoch 50 | loss: 0.01956 | train_rmsle: 0.00076 | train_mae: 0.08992 | train_rmse: 0.11766 | train_mse: 0.01384 | valid_rmsle: 0.00109 | valid_mae: 0.10774 | valid_rmse: 0.14174 | valid_mse: 0.02009 |  0:01:13s\n",
      "epoch 51 | loss: 0.02078 | train_rmsle: 0.00148 | train_mae: 0.13282 | train_rmse: 0.15876 | train_mse: 0.0252  | valid_rmsle: 0.00184 | valid_mae: 0.14712 | valid_rmse: 0.17973 | valid_mse: 0.0323  |  0:01:15s\n",
      "epoch 52 | loss: 0.02702 | train_rmsle: 0.00074 | train_mae: 0.08914 | train_rmse: 0.1162  | train_mse: 0.0135  | valid_rmsle: 0.00108 | valid_mae: 0.10768 | valid_rmse: 0.14101 | valid_mse: 0.01988 |  0:01:16s\n",
      "epoch 53 | loss: 0.01946 | train_rmsle: 0.00129 | train_mae: 0.12052 | train_rmse: 0.14991 | train_mse: 0.02247 | valid_rmsle: 0.00161 | valid_mae: 0.13591 | valid_rmse: 0.16915 | valid_mse: 0.02861 |  0:01:18s\n",
      "epoch 54 | loss: 0.02217 | train_rmsle: 0.00074 | train_mae: 0.0907  | train_rmse: 0.11643 | train_mse: 0.01355 | valid_rmsle: 0.00103 | valid_mae: 0.10743 | valid_rmse: 0.13797 | valid_mse: 0.01904 |  0:01:19s\n",
      "epoch 55 | loss: 0.02113 | train_rmsle: 0.00141 | train_mae: 0.11629 | train_rmse: 0.16554 | train_mse: 0.0274  | valid_rmsle: 0.00184 | valid_mae: 0.13444 | valid_rmse: 0.18917 | valid_mse: 0.03579 |  0:01:21s\n",
      "epoch 56 | loss: 0.02286 | train_rmsle: 0.0008  | train_mae: 0.09229 | train_rmse: 0.12083 | train_mse: 0.0146  | valid_rmsle: 0.00112 | valid_mae: 0.10969 | valid_rmse: 0.14371 | valid_mse: 0.02065 |  0:01:22s\n",
      "epoch 57 | loss: 0.01776 | train_rmsle: 0.00086 | train_mae: 0.10025 | train_rmse: 0.12621 | train_mse: 0.01593 | valid_rmsle: 0.00116 | valid_mae: 0.11572 | valid_rmse: 0.14667 | valid_mse: 0.02151 |  0:01:23s\n",
      "epoch 58 | loss: 0.02115 | train_rmsle: 0.00101 | train_mae: 0.11145 | train_rmse: 0.13727 | train_mse: 0.01884 | valid_rmsle: 0.00131 | valid_mae: 0.12408 | valid_rmse: 0.15603 | valid_mse: 0.02434 |  0:01:25s\n",
      "epoch 59 | loss: 0.01605 | train_rmsle: 0.00073 | train_mae: 0.087   | train_rmse: 0.11106 | train_mse: 0.01233 | valid_rmsle: 0.001   | valid_mae: 0.10231 | valid_rmse: 0.1318  | valid_mse: 0.01737 |  0:01:26s\n",
      "epoch 60 | loss: 0.01694 | train_rmsle: 0.00071 | train_mae: 0.08983 | train_rmse: 0.11265 | train_mse: 0.01269 | valid_rmsle: 0.00097 | valid_mae: 0.10448 | valid_rmse: 0.13247 | valid_mse: 0.01755 |  0:01:28s\n",
      "epoch 61 | loss: 0.01508 | train_rmsle: 0.00065 | train_mae: 0.08283 | train_rmse: 0.10643 | train_mse: 0.01133 | valid_rmsle: 0.00091 | valid_mae: 0.09943 | valid_rmse: 0.12717 | valid_mse: 0.01617 |  0:01:29s\n",
      "epoch 62 | loss: 0.01462 | train_rmsle: 0.00075 | train_mae: 0.09555 | train_rmse: 0.11896 | train_mse: 0.01415 | valid_rmsle: 0.00101 | valid_mae: 0.1091  | valid_rmse: 0.13787 | valid_mse: 0.01901 |  0:01:31s\n",
      "epoch 63 | loss: 0.01585 | train_rmsle: 0.0005  | train_mae: 0.07272 | train_rmse: 0.09557 | train_mse: 0.00913 | valid_rmsle: 0.00075 | valid_mae: 0.08977 | valid_rmse: 0.11764 | valid_mse: 0.01384 |  0:01:32s\n",
      "epoch 64 | loss: 0.01496 | train_rmsle: 0.00059 | train_mae: 0.07805 | train_rmse: 0.10137 | train_mse: 0.01028 | valid_rmsle: 0.00083 | valid_mae: 0.09384 | valid_rmse: 0.12253 | valid_mse: 0.01501 |  0:01:34s\n",
      "epoch 65 | loss: 0.01423 | train_rmsle: 0.00068 | train_mae: 0.08671 | train_rmse: 0.11497 | train_mse: 0.01322 | valid_rmsle: 0.00096 | valid_mae: 0.10293 | valid_rmse: 0.13638 | valid_mse: 0.0186  |  0:01:35s\n",
      "epoch 66 | loss: 0.01488 | train_rmsle: 0.00047 | train_mae: 0.0704  | train_rmse: 0.09269 | train_mse: 0.00859 | valid_rmsle: 0.00072 | valid_mae: 0.08729 | valid_rmse: 0.11488 | valid_mse: 0.0132  |  0:01:36s\n",
      "epoch 67 | loss: 0.01572 | train_rmsle: 0.00047 | train_mae: 0.07107 | train_rmse: 0.09249 | train_mse: 0.00855 | valid_rmsle: 0.00071 | valid_mae: 0.08687 | valid_rmse: 0.11366 | valid_mse: 0.01292 |  0:01:38s\n",
      "epoch 68 | loss: 0.01275 | train_rmsle: 0.00043 | train_mae: 0.06761 | train_rmse: 0.08788 | train_mse: 0.00772 | valid_rmsle: 0.00066 | valid_mae: 0.08294 | valid_rmse: 0.1089  | valid_mse: 0.01186 |  0:01:39s\n",
      "epoch 69 | loss: 0.01411 | train_rmsle: 0.00053 | train_mae: 0.0766  | train_rmse: 0.09657 | train_mse: 0.00933 | valid_rmsle: 0.00076 | valid_mae: 0.09059 | valid_rmse: 0.11636 | valid_mse: 0.01354 |  0:01:41s\n",
      "epoch 70 | loss: 0.01822 | train_rmsle: 0.00054 | train_mae: 0.07774 | train_rmse: 0.10026 | train_mse: 0.01005 | valid_rmsle: 0.00077 | valid_mae: 0.09264 | valid_rmse: 0.11921 | valid_mse: 0.01421 |  0:01:42s\n",
      "epoch 71 | loss: 0.0208  | train_rmsle: 0.00059 | train_mae: 0.07717 | train_rmse: 0.09717 | train_mse: 0.00944 | valid_rmsle: 0.0008  | valid_mae: 0.0925  | valid_rmse: 0.11611 | valid_mse: 0.01348 |  0:01:44s\n",
      "epoch 72 | loss: 0.01359 | train_rmsle: 0.00073 | train_mae: 0.08569 | train_rmse: 0.10718 | train_mse: 0.01149 | valid_rmsle: 0.00095 | valid_mae: 0.09899 | valid_rmse: 0.12501 | valid_mse: 0.01563 |  0:01:45s\n",
      "epoch 73 | loss: 0.01386 | train_rmsle: 0.00168 | train_mae: 0.15132 | train_rmse: 0.16862 | train_mse: 0.02843 | valid_rmsle: 0.00188 | valid_mae: 0.15664 | valid_rmse: 0.1799  | valid_mse: 0.03237 |  0:01:47s\n",
      "epoch 74 | loss: 0.0156  | train_rmsle: 0.00076 | train_mae: 0.099   | train_rmse: 0.11821 | train_mse: 0.01397 | valid_rmsle: 0.00098 | valid_mae: 0.10971 | valid_rmse: 0.13465 | valid_mse: 0.01813 |  0:01:48s\n",
      "epoch 75 | loss: 0.01307 | train_rmsle: 0.0005  | train_mae: 0.07551 | train_rmse: 0.09569 | train_mse: 0.00916 | valid_rmsle: 0.00071 | valid_mae: 0.08946 | valid_rmse: 0.11398 | valid_mse: 0.01299 |  0:01:49s\n",
      "epoch 76 | loss: 0.01365 | train_rmsle: 0.0004  | train_mae: 0.06616 | train_rmse: 0.08418 | train_mse: 0.00709 | valid_rmsle: 0.00061 | valid_mae: 0.08136 | valid_rmse: 0.10459 | valid_mse: 0.01094 |  0:01:51s\n",
      "epoch 77 | loss: 0.0135  | train_rmsle: 0.00072 | train_mae: 0.09489 | train_rmse: 0.11808 | train_mse: 0.01394 | valid_rmsle: 0.00091 | valid_mae: 0.10427 | valid_rmse: 0.13233 | valid_mse: 0.01751 |  0:01:52s\n",
      "epoch 78 | loss: 0.01454 | train_rmsle: 0.00078 | train_mae: 0.08949 | train_rmse: 0.11072 | train_mse: 0.01226 | valid_rmsle: 0.00096 | valid_mae: 0.10021 | valid_rmse: 0.12579 | valid_mse: 0.01582 |  0:01:54s\n",
      "epoch 79 | loss: 0.01363 | train_rmsle: 0.00068 | train_mae: 0.08335 | train_rmse: 0.10342 | train_mse: 0.0107  | valid_rmsle: 0.00087 | valid_mae: 0.09616 | valid_rmse: 0.11932 | valid_mse: 0.01424 |  0:01:55s\n",
      "epoch 80 | loss: 0.01144 | train_rmsle: 0.00052 | train_mae: 0.07278 | train_rmse: 0.09195 | train_mse: 0.00845 | valid_rmsle: 0.00073 | valid_mae: 0.08658 | valid_rmse: 0.11076 | valid_mse: 0.01227 |  0:01:57s\n",
      "epoch 81 | loss: 0.0129  | train_rmsle: 0.00061 | train_mae: 0.06423 | train_rmse: 0.09701 | train_mse: 0.00941 | valid_rmsle: 0.00071 | valid_mae: 0.07987 | valid_rmse: 0.1103  | valid_mse: 0.01217 |  0:01:58s\n",
      "epoch 82 | loss: 0.01125 | train_rmsle: 0.00034 | train_mae: 0.05984 | train_rmse: 0.07795 | train_mse: 0.00608 | valid_rmsle: 0.00054 | valid_mae: 0.07571 | valid_rmse: 0.09957 | valid_mse: 0.00991 |  0:01:59s\n",
      "epoch 83 | loss: 0.01328 | train_rmsle: 0.00044 | train_mae: 0.07131 | train_rmse: 0.09135 | train_mse: 0.00834 | valid_rmsle: 0.00066 | valid_mae: 0.08483 | valid_rmse: 0.11095 | valid_mse: 0.01231 |  0:02:01s\n",
      "epoch 84 | loss: 0.01569 | train_rmsle: 0.00049 | train_mae: 0.06881 | train_rmse: 0.08775 | train_mse: 0.0077  | valid_rmsle: 0.00071 | valid_mae: 0.08389 | valid_rmse: 0.10846 | valid_mse: 0.01176 |  0:02:02s\n",
      "epoch 85 | loss: 0.01246 | train_rmsle: 0.00041 | train_mae: 0.06815 | train_rmse: 0.08677 | train_mse: 0.00753 | valid_rmsle: 0.00062 | valid_mae: 0.08133 | valid_rmse: 0.10676 | valid_mse: 0.0114  |  0:02:04s\n",
      "epoch 86 | loss: 0.01215 | train_rmsle: 0.00039 | train_mae: 0.0644  | train_rmse: 0.08114 | train_mse: 0.00658 | valid_rmsle: 0.0006  | valid_mae: 0.07981 | valid_rmse: 0.1033  | valid_mse: 0.01067 |  0:02:05s\n",
      "epoch 87 | loss: 0.01179 | train_rmsle: 0.00048 | train_mae: 0.0706  | train_rmse: 0.08993 | train_mse: 0.00809 | valid_rmsle: 0.0007  | valid_mae: 0.08543 | valid_rmse: 0.11018 | valid_mse: 0.01214 |  0:02:07s\n",
      "epoch 88 | loss: 0.01125 | train_rmsle: 0.0008  | train_mae: 0.07938 | train_rmse: 0.10302 | train_mse: 0.01061 | valid_rmsle: 0.00098 | valid_mae: 0.09278 | valid_rmse: 0.11987 | valid_mse: 0.01437 |  0:02:08s\n",
      "epoch 89 | loss: 0.01162 | train_rmsle: 0.00047 | train_mae: 0.076   | train_rmse: 0.09321 | train_mse: 0.00869 | valid_rmsle: 0.00069 | valid_mae: 0.08933 | valid_rmse: 0.11306 | valid_mse: 0.01278 |  0:02:10s\n",
      "epoch 90 | loss: 0.01117 | train_rmsle: 0.00095 | train_mae: 0.10611 | train_rmse: 0.12269 | train_mse: 0.01505 | valid_rmsle: 0.00114 | valid_mae: 0.1147  | valid_rmse: 0.1373  | valid_mse: 0.01885 |  0:02:11s\n",
      "epoch 91 | loss: 0.01124 | train_rmsle: 0.00028 | train_mae: 0.05471 | train_rmse: 0.0705  | train_mse: 0.00497 | valid_rmsle: 0.0005  | valid_mae: 0.07263 | valid_rmse: 0.09474 | valid_mse: 0.00898 |  0:02:12s\n",
      "epoch 92 | loss: 0.00977 | train_rmsle: 0.00039 | train_mae: 0.0611  | train_rmse: 0.07793 | train_mse: 0.00607 | valid_rmsle: 0.00058 | valid_mae: 0.07639 | valid_rmse: 0.09825 | valid_mse: 0.00965 |  0:02:14s\n",
      "epoch 93 | loss: 0.00923 | train_rmsle: 0.00038 | train_mae: 0.06696 | train_rmse: 0.08289 | train_mse: 0.00687 | valid_rmsle: 0.0006  | valid_mae: 0.0814  | valid_rmse: 0.10383 | valid_mse: 0.01078 |  0:02:15s\n",
      "epoch 94 | loss: 0.01318 | train_rmsle: 0.00047 | train_mae: 0.07486 | train_rmse: 0.09019 | train_mse: 0.00813 | valid_rmsle: 0.00068 | valid_mae: 0.08765 | valid_rmse: 0.10965 | valid_mse: 0.01202 |  0:02:17s\n",
      "epoch 95 | loss: 0.01061 | train_rmsle: 0.00065 | train_mae: 0.08339 | train_rmse: 0.10048 | train_mse: 0.0101  | valid_rmsle: 0.00084 | valid_mae: 0.0949  | valid_rmse: 0.11718 | valid_mse: 0.01373 |  0:02:18s\n",
      "epoch 96 | loss: 0.01097 | train_rmsle: 0.00125 | train_mae: 0.11016 | train_rmse: 0.13137 | train_mse: 0.01726 | valid_rmsle: 0.00142 | valid_mae: 0.11947 | valid_rmse: 0.14522 | valid_mse: 0.02109 |  0:02:20s\n",
      "epoch 97 | loss: 0.01196 | train_rmsle: 0.00028 | train_mae: 0.0558  | train_rmse: 0.07191 | train_mse: 0.00517 | valid_rmsle: 0.00049 | valid_mae: 0.0718  | valid_rmse: 0.09479 | valid_mse: 0.00898 |  0:02:21s\n",
      "epoch 98 | loss: 0.01243 | train_rmsle: 0.00088 | train_mae: 0.0911  | train_rmse: 0.11259 | train_mse: 0.01268 | valid_rmsle: 0.00108 | valid_mae: 0.10136 | valid_rmse: 0.1282  | valid_mse: 0.01644 |  0:02:23s\n",
      "epoch 99 | loss: 0.01041 | train_rmsle: 0.00027 | train_mae: 0.05391 | train_rmse: 0.06883 | train_mse: 0.00474 | valid_rmsle: 0.00048 | valid_mae: 0.07113 | valid_rmse: 0.09284 | valid_mse: 0.00862 |  0:02:24s\n",
      "epoch 100| loss: 0.01068 | train_rmsle: 0.00062 | train_mae: 0.0879  | train_rmse: 0.10366 | train_mse: 0.01075 | valid_rmsle: 0.00081 | valid_mae: 0.09697 | valid_rmse: 0.11924 | valid_mse: 0.01422 |  0:02:25s\n",
      "epoch 101| loss: 0.00972 | train_rmsle: 0.00032 | train_mae: 0.05466 | train_rmse: 0.07086 | train_mse: 0.00502 | valid_rmsle: 0.00053 | valid_mae: 0.07243 | valid_rmse: 0.09401 | valid_mse: 0.00884 |  0:02:27s\n",
      "epoch 102| loss: 0.01142 | train_rmsle: 0.00049 | train_mae: 0.07886 | train_rmse: 0.09418 | train_mse: 0.00887 | valid_rmsle: 0.00071 | valid_mae: 0.09095 | valid_rmse: 0.11305 | valid_mse: 0.01278 |  0:02:28s\n",
      "epoch 103| loss: 0.01042 | train_rmsle: 0.00031 | train_mae: 0.05823 | train_rmse: 0.07325 | train_mse: 0.00536 | valid_rmsle: 0.00054 | valid_mae: 0.07581 | valid_rmse: 0.09695 | valid_mse: 0.0094  |  0:02:30s\n",
      "epoch 104| loss: 0.01318 | train_rmsle: 0.00028 | train_mae: 0.05582 | train_rmse: 0.07126 | train_mse: 0.00508 | valid_rmsle: 0.00051 | valid_mae: 0.07414 | valid_rmse: 0.09602 | valid_mse: 0.00922 |  0:02:31s\n",
      "epoch 105| loss: 0.0113  | train_rmsle: 0.00064 | train_mae: 0.08095 | train_rmse: 0.10198 | train_mse: 0.0104  | valid_rmsle: 0.00088 | valid_mae: 0.09508 | valid_rmse: 0.12178 | valid_mse: 0.01483 |  0:02:33s\n",
      "epoch 106| loss: 0.01168 | train_rmsle: 0.00065 | train_mae: 0.08761 | train_rmse: 0.10558 | train_mse: 0.01115 | valid_rmsle: 0.00088 | valid_mae: 0.10001 | valid_rmse: 0.1232  | valid_mse: 0.01518 |  0:02:34s\n",
      "epoch 107| loss: 0.01566 | train_rmsle: 0.00034 | train_mae: 0.06168 | train_rmse: 0.07908 | train_mse: 0.00625 | valid_rmsle: 0.00058 | valid_mae: 0.08027 | valid_rmse: 0.1022  | valid_mse: 0.01045 |  0:02:36s\n",
      "epoch 108| loss: 0.01083 | train_rmsle: 0.00027 | train_mae: 0.05344 | train_rmse: 0.06852 | train_mse: 0.0047  | valid_rmsle: 0.00049 | valid_mae: 0.07109 | valid_rmse: 0.09224 | valid_mse: 0.00851 |  0:02:37s\n",
      "epoch 109| loss: 0.01013 | train_rmsle: 0.00028 | train_mae: 0.05607 | train_rmse: 0.07158 | train_mse: 0.00512 | valid_rmsle: 0.0005  | valid_mae: 0.07387 | valid_rmse: 0.09494 | valid_mse: 0.00901 |  0:02:38s\n",
      "epoch 110| loss: 0.0105  | train_rmsle: 0.00034 | train_mae: 0.06476 | train_rmse: 0.08112 | train_mse: 0.00658 | valid_rmsle: 0.00056 | valid_mae: 0.08077 | valid_rmse: 0.10175 | valid_mse: 0.01035 |  0:02:40s\n",
      "epoch 111| loss: 0.00932 | train_rmsle: 0.00066 | train_mae: 0.0791  | train_rmse: 0.09869 | train_mse: 0.00974 | valid_rmsle: 0.00081 | valid_mae: 0.08966 | valid_rmse: 0.11412 | valid_mse: 0.01302 |  0:02:41s\n",
      "epoch 112| loss: 0.01306 | train_rmsle: 0.00039 | train_mae: 0.06871 | train_rmse: 0.08384 | train_mse: 0.00703 | valid_rmsle: 0.0006  | valid_mae: 0.0814  | valid_rmse: 0.10373 | valid_mse: 0.01076 |  0:02:43s\n",
      "epoch 113| loss: 0.01298 | train_rmsle: 0.00033 | train_mae: 0.06043 | train_rmse: 0.07771 | train_mse: 0.00604 | valid_rmsle: 0.00056 | valid_mae: 0.07682 | valid_rmse: 0.10076 | valid_mse: 0.01015 |  0:02:44s\n",
      "epoch 114| loss: 0.01107 | train_rmsle: 0.00041 | train_mae: 0.06063 | train_rmse: 0.07792 | train_mse: 0.00607 | valid_rmsle: 0.00063 | valid_mae: 0.07708 | valid_rmse: 0.10011 | valid_mse: 0.01002 |  0:02:46s\n",
      "epoch 115| loss: 0.00886 | train_rmsle: 0.00024 | train_mae: 0.05183 | train_rmse: 0.06645 | train_mse: 0.00442 | valid_rmsle: 0.00047 | valid_mae: 0.07063 | valid_rmse: 0.09142 | valid_mse: 0.00836 |  0:02:47s\n",
      "epoch 116| loss: 0.01263 | train_rmsle: 0.00036 | train_mae: 0.06072 | train_rmse: 0.07823 | train_mse: 0.00612 | valid_rmsle: 0.00059 | valid_mae: 0.07855 | valid_rmse: 0.10028 | valid_mse: 0.01006 |  0:02:48s\n",
      "epoch 117| loss: 0.01114 | train_rmsle: 0.00056 | train_mae: 0.07372 | train_rmse: 0.09326 | train_mse: 0.0087  | valid_rmsle: 0.00076 | valid_mae: 0.08754 | valid_rmse: 0.11215 | valid_mse: 0.01258 |  0:02:50s\n",
      "epoch 118| loss: 0.01376 | train_rmsle: 0.0005  | train_mae: 0.07708 | train_rmse: 0.09683 | train_mse: 0.00938 | valid_rmsle: 0.00076 | valid_mae: 0.09212 | valid_rmse: 0.11754 | valid_mse: 0.01382 |  0:02:51s\n",
      "epoch 119| loss: 0.01105 | train_rmsle: 0.0003  | train_mae: 0.05847 | train_rmse: 0.07552 | train_mse: 0.0057  | valid_rmsle: 0.00056 | valid_mae: 0.07875 | valid_rmse: 0.10092 | valid_mse: 0.01018 |  0:02:53s\n",
      "epoch 120| loss: 0.01207 | train_rmsle: 0.0004  | train_mae: 0.06175 | train_rmse: 0.07881 | train_mse: 0.00621 | valid_rmsle: 0.00065 | valid_mae: 0.07942 | valid_rmse: 0.10291 | valid_mse: 0.01059 |  0:02:54s\n",
      "epoch 121| loss: 0.0091  | train_rmsle: 0.00028 | train_mae: 0.05488 | train_rmse: 0.07138 | train_mse: 0.00509 | valid_rmsle: 0.00054 | valid_mae: 0.07514 | valid_rmse: 0.09838 | valid_mse: 0.00968 |  0:02:56s\n",
      "epoch 122| loss: 0.00957 | train_rmsle: 0.00073 | train_mae: 0.07781 | train_rmse: 0.10068 | train_mse: 0.01014 | valid_rmsle: 0.00097 | valid_mae: 0.09263 | valid_rmse: 0.12076 | valid_mse: 0.01458 |  0:02:57s\n",
      "epoch 123| loss: 0.01076 | train_rmsle: 0.00042 | train_mae: 0.06804 | train_rmse: 0.08548 | train_mse: 0.00731 | valid_rmsle: 0.00066 | valid_mae: 0.08441 | valid_rmse: 0.10698 | valid_mse: 0.01144 |  0:02:59s\n",
      "epoch 124| loss: 0.00854 | train_rmsle: 0.00022 | train_mae: 0.04793 | train_rmse: 0.06171 | train_mse: 0.00381 | valid_rmsle: 0.00046 | valid_mae: 0.06729 | valid_rmse: 0.08929 | valid_mse: 0.00797 |  0:03:00s\n",
      "epoch 125| loss: 0.00992 | train_rmsle: 0.00032 | train_mae: 0.05663 | train_rmse: 0.07183 | train_mse: 0.00516 | valid_rmsle: 0.00056 | valid_mae: 0.07497 | valid_rmse: 0.09687 | valid_mse: 0.00938 |  0:03:01s\n",
      "epoch 126| loss: 0.00935 | train_rmsle: 0.00043 | train_mae: 0.06361 | train_rmse: 0.08097 | train_mse: 0.00656 | valid_rmsle: 0.00066 | valid_mae: 0.08063 | valid_rmse: 0.10344 | valid_mse: 0.0107  |  0:03:03s\n",
      "epoch 127| loss: 0.00986 | train_rmsle: 0.00025 | train_mae: 0.04913 | train_rmse: 0.06311 | train_mse: 0.00398 | valid_rmsle: 0.00048 | valid_mae: 0.06863 | valid_rmse: 0.09014 | valid_mse: 0.00813 |  0:03:04s\n",
      "epoch 128| loss: 0.00911 | train_rmsle: 0.00025 | train_mae: 0.05133 | train_rmse: 0.06559 | train_mse: 0.0043  | valid_rmsle: 0.0005  | valid_mae: 0.07243 | valid_rmse: 0.09306 | valid_mse: 0.00866 |  0:03:06s\n",
      "epoch 129| loss: 0.00959 | train_rmsle: 0.00042 | train_mae: 0.07361 | train_rmse: 0.08997 | train_mse: 0.00809 | valid_rmsle: 0.00067 | valid_mae: 0.0894  | valid_rmse: 0.11109 | valid_mse: 0.01234 |  0:03:07s\n",
      "epoch 130| loss: 0.01382 | train_rmsle: 0.00037 | train_mae: 0.06446 | train_rmse: 0.08269 | train_mse: 0.00684 | valid_rmsle: 0.00062 | valid_mae: 0.08258 | valid_rmse: 0.10639 | valid_mse: 0.01132 |  0:03:09s\n",
      "epoch 131| loss: 0.0138  | train_rmsle: 0.00029 | train_mae: 0.05524 | train_rmse: 0.07109 | train_mse: 0.00505 | valid_rmsle: 0.00055 | valid_mae: 0.07304 | valid_rmse: 0.09637 | valid_mse: 0.00929 |  0:03:10s\n",
      "epoch 132| loss: 0.00915 | train_rmsle: 0.00025 | train_mae: 0.05133 | train_rmse: 0.06607 | train_mse: 0.00437 | valid_rmsle: 0.00053 | valid_mae: 0.0733  | valid_rmse: 0.09517 | valid_mse: 0.00906 |  0:03:12s\n",
      "epoch 133| loss: 0.01092 | train_rmsle: 0.00025 | train_mae: 0.05365 | train_rmse: 0.06807 | train_mse: 0.00463 | valid_rmsle: 0.00052 | valid_mae: 0.07344 | valid_rmse: 0.09623 | valid_mse: 0.00926 |  0:03:13s\n",
      "epoch 134| loss: 0.0127  | train_rmsle: 0.0006  | train_mae: 0.07967 | train_rmse: 0.09574 | train_mse: 0.00917 | valid_rmsle: 0.00087 | valid_mae: 0.09265 | valid_rmse: 0.11727 | valid_mse: 0.01375 |  0:03:14s\n",
      "epoch 135| loss: 0.012   | train_rmsle: 0.0003  | train_mae: 0.06074 | train_rmse: 0.07505 | train_mse: 0.00563 | valid_rmsle: 0.00058 | valid_mae: 0.07852 | valid_rmse: 0.10105 | valid_mse: 0.01021 |  0:03:16s\n",
      "epoch 136| loss: 0.01094 | train_rmsle: 0.00035 | train_mae: 0.06534 | train_rmse: 0.07907 | train_mse: 0.00625 | valid_rmsle: 0.00061 | valid_mae: 0.08005 | valid_rmse: 0.10287 | valid_mse: 0.01058 |  0:03:17s\n",
      "epoch 137| loss: 0.01386 | train_rmsle: 0.00054 | train_mae: 0.07187 | train_rmse: 0.08923 | train_mse: 0.00796 | valid_rmsle: 0.0008  | valid_mae: 0.08631 | valid_rmse: 0.11071 | valid_mse: 0.01226 |  0:03:19s\n",
      "epoch 138| loss: 0.01159 | train_rmsle: 0.00018 | train_mae: 0.04264 | train_rmse: 0.05492 | train_mse: 0.00302 | valid_rmsle: 0.00044 | valid_mae: 0.06589 | valid_rmse: 0.08615 | valid_mse: 0.00742 |  0:03:20s\n",
      "epoch 139| loss: 0.01054 | train_rmsle: 0.00023 | train_mae: 0.05094 | train_rmse: 0.06473 | train_mse: 0.00419 | valid_rmsle: 0.00049 | valid_mae: 0.07122 | valid_rmse: 0.09288 | valid_mse: 0.00863 |  0:03:22s\n",
      "epoch 140| loss: 0.00989 | train_rmsle: 0.00016 | train_mae: 0.04223 | train_rmse: 0.05387 | train_mse: 0.0029  | valid_rmsle: 0.00043 | valid_mae: 0.06625 | valid_rmse: 0.08622 | valid_mse: 0.00743 |  0:03:23s\n",
      "epoch 141| loss: 0.00971 | train_rmsle: 0.00016 | train_mae: 0.04209 | train_rmse: 0.05392 | train_mse: 0.00291 | valid_rmsle: 0.00044 | valid_mae: 0.0672  | valid_rmse: 0.08711 | valid_mse: 0.00759 |  0:03:24s\n",
      "epoch 142| loss: 0.00818 | train_rmsle: 0.00016 | train_mae: 0.04162 | train_rmse: 0.05369 | train_mse: 0.00288 | valid_rmsle: 0.00043 | valid_mae: 0.06698 | valid_rmse: 0.08666 | valid_mse: 0.00751 |  0:03:26s\n",
      "epoch 143| loss: 0.00876 | train_rmsle: 0.00028 | train_mae: 0.05251 | train_rmse: 0.0661  | train_mse: 0.00437 | valid_rmsle: 0.00055 | valid_mae: 0.07352 | valid_rmse: 0.09512 | valid_mse: 0.00905 |  0:03:27s\n",
      "epoch 144| loss: 0.01    | train_rmsle: 0.00031 | train_mae: 0.06365 | train_rmse: 0.07748 | train_mse: 0.006   | valid_rmsle: 0.0006  | valid_mae: 0.08325 | valid_rmse: 0.10427 | valid_mse: 0.01087 |  0:03:29s\n",
      "epoch 145| loss: 0.01553 | train_rmsle: 0.00324 | train_mae: 0.18351 | train_rmse: 0.22819 | train_mse: 0.05207 | valid_rmsle: 0.0035  | valid_mae: 0.19371 | valid_rmse: 0.24043 | valid_mse: 0.05781 |  0:03:30s\n",
      "epoch 146| loss: 0.01796 | train_rmsle: 0.00128 | train_mae: 0.11569 | train_rmse: 0.15671 | train_mse: 0.02456 | valid_rmsle: 0.0016  | valid_mae: 0.13212 | valid_rmse: 0.1739  | valid_mse: 0.03024 |  0:03:32s\n",
      "epoch 147| loss: 0.01727 | train_rmsle: 0.00063 | train_mae: 0.08193 | train_rmse: 0.10916 | train_mse: 0.01192 | valid_rmsle: 0.00097 | valid_mae: 0.10189 | valid_rmse: 0.13273 | valid_mse: 0.01762 |  0:03:33s\n",
      "epoch 148| loss: 0.01406 | train_rmsle: 0.00091 | train_mae: 0.09238 | train_rmse: 0.11682 | train_mse: 0.01365 | valid_rmsle: 0.00124 | valid_mae: 0.11094 | valid_rmse: 0.14026 | valid_mse: 0.01967 |  0:03:35s\n",
      "epoch 149| loss: 0.01095 | train_rmsle: 0.0011  | train_mae: 0.0997  | train_rmse: 0.12502 | train_mse: 0.01563 | valid_rmsle: 0.00137 | valid_mae: 0.11418 | valid_rmse: 0.14367 | valid_mse: 0.02064 |  0:03:36s\n",
      "epoch 150| loss: 0.01142 | train_rmsle: 0.00079 | train_mae: 0.08915 | train_rmse: 0.10894 | train_mse: 0.01187 | valid_rmsle: 0.00106 | valid_mae: 0.10423 | valid_rmse: 0.12936 | valid_mse: 0.01673 |  0:03:38s\n",
      "epoch 151| loss: 0.01229 | train_rmsle: 0.00058 | train_mae: 0.07075 | train_rmse: 0.0901  | train_mse: 0.00812 | valid_rmsle: 0.00082 | valid_mae: 0.08794 | valid_rmse: 0.11165 | valid_mse: 0.01247 |  0:03:39s\n",
      "epoch 152| loss: 0.01279 | train_rmsle: 0.00052 | train_mae: 0.07252 | train_rmse: 0.08955 | train_mse: 0.00802 | valid_rmsle: 0.00076 | valid_mae: 0.08871 | valid_rmse: 0.111   | valid_mse: 0.01232 |  0:03:40s\n",
      "epoch 153| loss: 0.01055 | train_rmsle: 0.00054 | train_mae: 0.07952 | train_rmse: 0.09588 | train_mse: 0.00919 | valid_rmsle: 0.00079 | valid_mae: 0.09347 | valid_rmse: 0.11596 | valid_mse: 0.01345 |  0:03:42s\n",
      "epoch 154| loss: 0.00974 | train_rmsle: 0.00103 | train_mae: 0.09248 | train_rmse: 0.11671 | train_mse: 0.01362 | valid_rmsle: 0.00127 | valid_mae: 0.10511 | valid_rmse: 0.13437 | valid_mse: 0.01806 |  0:03:43s\n",
      "epoch 155| loss: 0.00977 | train_rmsle: 0.00021 | train_mae: 0.04813 | train_rmse: 0.06259 | train_mse: 0.00392 | valid_rmsle: 0.00047 | valid_mae: 0.07036 | valid_rmse: 0.09099 | valid_mse: 0.00828 |  0:03:45s\n",
      "epoch 156| loss: 0.00982 | train_rmsle: 0.00023 | train_mae: 0.05176 | train_rmse: 0.06604 | train_mse: 0.00436 | valid_rmsle: 0.00051 | valid_mae: 0.07354 | valid_rmse: 0.09469 | valid_mse: 0.00897 |  0:03:46s\n",
      "epoch 157| loss: 0.00819 | train_rmsle: 0.00033 | train_mae: 0.06035 | train_rmse: 0.07844 | train_mse: 0.00615 | valid_rmsle: 0.00059 | valid_mae: 0.08076 | valid_rmse: 0.10254 | valid_mse: 0.01052 |  0:03:48s\n",
      "epoch 158| loss: 0.01069 | train_rmsle: 0.00019 | train_mae: 0.04495 | train_rmse: 0.05813 | train_mse: 0.00338 | valid_rmsle: 0.00044 | valid_mae: 0.06817 | valid_rmse: 0.08741 | valid_mse: 0.00764 |  0:03:49s\n",
      "\n",
      "Early stopping occurred at epoch 158 with best_epoch = 138 and best_valid_mse = 0.00742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00813222251691739 RMSE: 0.09017883630274562 R2: 0.9640017844139963 MAE: 0.06946582838404507\n",
      "=====================================\n",
      "[89/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.15236 | train_rmsle: 0.32881 | train_mae: 1.84919 | train_rmse: 1.9117  | train_mse: 3.6546  | valid_rmsle: 0.33052 | valid_mae: 1.85598 | valid_rmse: 1.91746 | valid_mse: 3.67665 |  0:00:01s\n",
      "epoch 1  | loss: 1.38106 | train_rmsle: 0.07356 | train_mae: 0.96923 | train_rmse: 1.0607  | train_mse: 1.12509 | valid_rmsle: 0.07376 | valid_mae: 0.97111 | valid_rmse: 1.06372 | valid_mse: 1.13151 |  0:00:03s\n",
      "epoch 2  | loss: 0.65213 | train_rmsle: 0.07302 | train_mae: 0.96657 | train_rmse: 1.05733 | train_mse: 1.11795 | valid_rmsle: 0.07337 | valid_mae: 0.96908 | valid_rmse: 1.06144 | valid_mse: 1.12666 |  0:00:04s\n",
      "epoch 3  | loss: 0.42092 | train_rmsle: 0.0608  | train_mae: 0.88572 | train_rmse: 0.97778 | train_mse: 0.95606 | valid_rmsle: 0.06087 | valid_mae: 0.88637 | valid_rmse: 0.98026 | valid_mse: 0.96092 |  0:00:05s\n",
      "epoch 4  | loss: 0.2984  | train_rmsle: 0.0324  | train_mae: 0.66919 | train_rmse: 0.7335  | train_mse: 0.53803 | valid_rmsle: 0.03164 | valid_mae: 0.665   | valid_rmse: 0.72804 | valid_mse: 0.53005 |  0:00:07s\n",
      "epoch 5  | loss: 0.23499 | train_rmsle: 0.03586 | train_mae: 0.68402 | train_rmse: 0.74274 | train_mse: 0.55166 | valid_rmsle: 0.03493 | valid_mae: 0.67707 | valid_rmse: 0.73438 | valid_mse: 0.53931 |  0:00:08s\n",
      "epoch 6  | loss: 0.21774 | train_rmsle: 0.01974 | train_mae: 0.49485 | train_rmse: 0.56122 | train_mse: 0.31497 | valid_rmsle: 0.01875 | valid_mae: 0.48298 | valid_rmse: 0.54828 | valid_mse: 0.30061 |  0:00:10s\n",
      "epoch 7  | loss: 0.20965 | train_rmsle: 0.0247  | train_mae: 0.54993 | train_rmse: 0.61891 | train_mse: 0.38305 | valid_rmsle: 0.02386 | valid_mae: 0.54232 | valid_rmse: 0.61058 | valid_mse: 0.37281 |  0:00:11s\n",
      "epoch 8  | loss: 0.16411 | train_rmsle: 0.01897 | train_mae: 0.47171 | train_rmse: 0.55499 | train_mse: 0.30802 | valid_rmsle: 0.01819 | valid_mae: 0.46072 | valid_rmse: 0.54525 | valid_mse: 0.2973  |  0:00:13s\n",
      "epoch 9  | loss: 0.16638 | train_rmsle: 0.02103 | train_mae: 0.49174 | train_rmse: 0.57336 | train_mse: 0.32874 | valid_rmsle: 0.02037 | valid_mae: 0.48427 | valid_rmse: 0.56604 | valid_mse: 0.3204  |  0:00:14s\n",
      "epoch 10 | loss: 0.15447 | train_rmsle: 0.01084 | train_mae: 0.34123 | train_rmse: 0.4158  | train_mse: 0.17289 | valid_rmsle: 0.01008 | valid_mae: 0.32981 | valid_rmse: 0.40409 | valid_mse: 0.16329 |  0:00:16s\n",
      "epoch 11 | loss: 0.14294 | train_rmsle: 0.00984 | train_mae: 0.32259 | train_rmse: 0.39749 | train_mse: 0.158   | valid_rmsle: 0.00916 | valid_mae: 0.31143 | valid_rmse: 0.38609 | valid_mse: 0.14906 |  0:00:17s\n",
      "epoch 12 | loss: 0.13039 | train_rmsle: 0.01071 | train_mae: 0.3478  | train_rmse: 0.41865 | train_mse: 0.17527 | valid_rmsle: 0.00998 | valid_mae: 0.33711 | valid_rmse: 0.40598 | valid_mse: 0.16482 |  0:00:18s\n",
      "epoch 13 | loss: 0.12534 | train_rmsle: 0.0082  | train_mae: 0.29145 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.0078  | valid_mae: 0.28348 | valid_rmse: 0.35607 | valid_mse: 0.12678 |  0:00:20s\n",
      "epoch 14 | loss: 0.12376 | train_rmsle: 0.00903 | train_mae: 0.30403 | train_rmse: 0.37951 | train_mse: 0.14403 | valid_rmsle: 0.00843 | valid_mae: 0.29386 | valid_rmse: 0.36982 | valid_mse: 0.13677 |  0:00:21s\n",
      "epoch 15 | loss: 0.11926 | train_rmsle: 0.00769 | train_mae: 0.27101 | train_rmse: 0.3473  | train_mse: 0.12062 | valid_rmsle: 0.00702 | valid_mae: 0.26232 | valid_rmse: 0.33588 | valid_mse: 0.11282 |  0:00:23s\n",
      "epoch 16 | loss: 0.11464 | train_rmsle: 0.00875 | train_mae: 0.29994 | train_rmse: 0.37398 | train_mse: 0.13986 | valid_rmsle: 0.00807 | valid_mae: 0.28831 | valid_rmse: 0.3617  | valid_mse: 0.13083 |  0:00:24s\n",
      "epoch 17 | loss: 0.1159  | train_rmsle: 0.0072  | train_mae: 0.25811 | train_rmse: 0.33326 | train_mse: 0.11106 | valid_rmsle: 0.00676 | valid_mae: 0.24924 | valid_rmse: 0.32645 | valid_mse: 0.10657 |  0:00:26s\n",
      "epoch 18 | loss: 0.12165 | train_rmsle: 0.00704 | train_mae: 0.25485 | train_rmse: 0.32881 | train_mse: 0.10811 | valid_rmsle: 0.00651 | valid_mae: 0.24401 | valid_rmse: 0.31967 | valid_mse: 0.10219 |  0:00:27s\n",
      "epoch 19 | loss: 0.1103  | train_rmsle: 0.0072  | train_mae: 0.2669  | train_rmse: 0.33583 | train_mse: 0.11278 | valid_rmsle: 0.00654 | valid_mae: 0.25515 | valid_rmse: 0.3233  | valid_mse: 0.10452 |  0:00:29s\n",
      "epoch 20 | loss: 0.11021 | train_rmsle: 0.00866 | train_mae: 0.30599 | train_rmse: 0.37396 | train_mse: 0.13985 | valid_rmsle: 0.00802 | valid_mae: 0.29862 | valid_rmse: 0.36335 | valid_mse: 0.13202 |  0:00:30s\n",
      "epoch 21 | loss: 0.10973 | train_rmsle: 0.00715 | train_mae: 0.2645  | train_rmse: 0.33453 | train_mse: 0.11191 | valid_rmsle: 0.00651 | valid_mae: 0.25466 | valid_rmse: 0.32317 | valid_mse: 0.10444 |  0:00:32s\n",
      "epoch 22 | loss: 0.11177 | train_rmsle: 0.00764 | train_mae: 0.28065 | train_rmse: 0.34876 | train_mse: 0.12164 | valid_rmsle: 0.0071  | valid_mae: 0.27309 | valid_rmse: 0.34037 | valid_mse: 0.11585 |  0:00:33s\n",
      "epoch 23 | loss: 0.10461 | train_rmsle: 0.00687 | train_mae: 0.24297 | train_rmse: 0.32148 | train_mse: 0.10335 | valid_rmsle: 0.00639 | valid_mae: 0.23623 | valid_rmse: 0.31438 | valid_mse: 0.09883 |  0:00:34s\n",
      "epoch 24 | loss: 0.10727 | train_rmsle: 0.0068  | train_mae: 0.24508 | train_rmse: 0.32054 | train_mse: 0.10274 | valid_rmsle: 0.00617 | valid_mae: 0.23409 | valid_rmse: 0.30857 | valid_mse: 0.09522 |  0:00:36s\n",
      "epoch 25 | loss: 0.10489 | train_rmsle: 0.00686 | train_mae: 0.2424  | train_rmse: 0.32059 | train_mse: 0.10278 | valid_rmsle: 0.00623 | valid_mae: 0.23332 | valid_rmse: 0.30976 | valid_mse: 0.09595 |  0:00:37s\n",
      "epoch 26 | loss: 0.10507 | train_rmsle: 0.00708 | train_mae: 0.26333 | train_rmse: 0.33276 | train_mse: 0.11073 | valid_rmsle: 0.00658 | valid_mae: 0.25433 | valid_rmse: 0.32438 | valid_mse: 0.10522 |  0:00:39s\n",
      "epoch 27 | loss: 0.10032 | train_rmsle: 0.00639 | train_mae: 0.23741 | train_rmse: 0.31007 | train_mse: 0.09614 | valid_rmsle: 0.00588 | valid_mae: 0.22925 | valid_rmse: 0.3012  | valid_mse: 0.09072 |  0:00:40s\n",
      "epoch 28 | loss: 0.1015  | train_rmsle: 0.00693 | train_mae: 0.25716 | train_rmse: 0.32676 | train_mse: 0.10677 | valid_rmsle: 0.00633 | valid_mae: 0.24683 | valid_rmse: 0.31574 | valid_mse: 0.09969 |  0:00:42s\n",
      "epoch 29 | loss: 0.09998 | train_rmsle: 0.00628 | train_mae: 0.23779 | train_rmse: 0.30853 | train_mse: 0.09519 | valid_rmsle: 0.0058  | valid_mae: 0.22866 | valid_rmse: 0.29927 | valid_mse: 0.08956 |  0:00:43s\n",
      "epoch 30 | loss: 0.09951 | train_rmsle: 0.00744 | train_mae: 0.2774  | train_rmse: 0.34416 | train_mse: 0.11845 | valid_rmsle: 0.00691 | valid_mae: 0.26876 | valid_rmse: 0.3342  | valid_mse: 0.11169 |  0:00:45s\n",
      "epoch 31 | loss: 0.09888 | train_rmsle: 0.00626 | train_mae: 0.23603 | train_rmse: 0.30672 | train_mse: 0.09408 | valid_rmsle: 0.00578 | valid_mae: 0.22918 | valid_rmse: 0.29879 | valid_mse: 0.08928 |  0:00:46s\n",
      "epoch 32 | loss: 0.09877 | train_rmsle: 0.0065  | train_mae: 0.24955 | train_rmse: 0.31639 | train_mse: 0.1001  | valid_rmsle: 0.00607 | valid_mae: 0.24385 | valid_rmse: 0.30931 | valid_mse: 0.09567 |  0:00:48s\n",
      "epoch 33 | loss: 0.09722 | train_rmsle: 0.00632 | train_mae: 0.23576 | train_rmse: 0.30921 | train_mse: 0.09561 | valid_rmsle: 0.00605 | valid_mae: 0.23188 | valid_rmse: 0.30652 | valid_mse: 0.09395 |  0:00:49s\n",
      "epoch 34 | loss: 0.09706 | train_rmsle: 0.00613 | train_mae: 0.233   | train_rmse: 0.30396 | train_mse: 0.09239 | valid_rmsle: 0.00587 | valid_mae: 0.23001 | valid_rmse: 0.30122 | valid_mse: 0.09073 |  0:00:50s\n",
      "epoch 35 | loss: 0.09461 | train_rmsle: 0.00628 | train_mae: 0.23273 | train_rmse: 0.30609 | train_mse: 0.09369 | valid_rmsle: 0.00605 | valid_mae: 0.23042 | valid_rmse: 0.30487 | valid_mse: 0.09294 |  0:00:52s\n",
      "epoch 36 | loss: 0.09943 | train_rmsle: 0.00607 | train_mae: 0.23384 | train_rmse: 0.30334 | train_mse: 0.09201 | valid_rmsle: 0.00585 | valid_mae: 0.22991 | valid_rmse: 0.30168 | valid_mse: 0.09101 |  0:00:53s\n",
      "epoch 37 | loss: 0.09274 | train_rmsle: 0.00617 | train_mae: 0.23116 | train_rmse: 0.30336 | train_mse: 0.09203 | valid_rmsle: 0.00611 | valid_mae: 0.23004 | valid_rmse: 0.30595 | valid_mse: 0.09361 |  0:00:55s\n",
      "epoch 38 | loss: 0.09134 | train_rmsle: 0.00611 | train_mae: 0.23174 | train_rmse: 0.30276 | train_mse: 0.09167 | valid_rmsle: 0.00601 | valid_mae: 0.23266 | valid_rmse: 0.30514 | valid_mse: 0.09311 |  0:00:56s\n",
      "epoch 39 | loss: 0.08958 | train_rmsle: 0.00629 | train_mae: 0.23103 | train_rmse: 0.30493 | train_mse: 0.09298 | valid_rmsle: 0.00623 | valid_mae: 0.23495 | valid_rmse: 0.30889 | valid_mse: 0.09541 |  0:00:58s\n",
      "epoch 40 | loss: 0.08899 | train_rmsle: 0.00615 | train_mae: 0.2297  | train_rmse: 0.30324 | train_mse: 0.09196 | valid_rmsle: 0.00616 | valid_mae: 0.23321 | valid_rmse: 0.30814 | valid_mse: 0.09495 |  0:00:59s\n",
      "epoch 41 | loss: 0.08679 | train_rmsle: 0.00571 | train_mae: 0.22425 | train_rmse: 0.29287 | train_mse: 0.08577 | valid_rmsle: 0.0059  | valid_mae: 0.23047 | valid_rmse: 0.30139 | valid_mse: 0.09083 |  0:01:00s\n",
      "epoch 42 | loss: 0.0859  | train_rmsle: 0.00568 | train_mae: 0.23    | train_rmse: 0.29615 | train_mse: 0.0877  | valid_rmsle: 0.00585 | valid_mae: 0.23667 | valid_rmse: 0.30366 | valid_mse: 0.09221 |  0:01:02s\n",
      "epoch 43 | loss: 0.08643 | train_rmsle: 0.00587 | train_mae: 0.228   | train_rmse: 0.29702 | train_mse: 0.08822 | valid_rmsle: 0.00603 | valid_mae: 0.23564 | valid_rmse: 0.30531 | valid_mse: 0.09321 |  0:01:03s\n",
      "epoch 44 | loss: 0.08648 | train_rmsle: 0.00569 | train_mae: 0.22766 | train_rmse: 0.29435 | train_mse: 0.08664 | valid_rmsle: 0.00585 | valid_mae: 0.23529 | valid_rmse: 0.30255 | valid_mse: 0.09154 |  0:01:05s\n",
      "epoch 45 | loss: 0.08725 | train_rmsle: 0.00616 | train_mae: 0.23054 | train_rmse: 0.3044  | train_mse: 0.09266 | valid_rmsle: 0.00653 | valid_mae: 0.24054 | valid_rmse: 0.3185  | valid_mse: 0.10144 |  0:01:06s\n",
      "epoch 46 | loss: 0.0856  | train_rmsle: 0.0053  | train_mae: 0.21751 | train_rmse: 0.28409 | train_mse: 0.08071 | valid_rmsle: 0.00576 | valid_mae: 0.23045 | valid_rmse: 0.30035 | valid_mse: 0.09021 |  0:01:08s\n",
      "epoch 47 | loss: 0.08516 | train_rmsle: 0.0055  | train_mae: 0.21678 | train_rmse: 0.28621 | train_mse: 0.08192 | valid_rmsle: 0.00594 | valid_mae: 0.22988 | valid_rmse: 0.30306 | valid_mse: 0.09185 |  0:01:09s\n",
      "epoch 48 | loss: 0.08496 | train_rmsle: 0.00524 | train_mae: 0.21954 | train_rmse: 0.28333 | train_mse: 0.08027 | valid_rmsle: 0.00586 | valid_mae: 0.23717 | valid_rmse: 0.30361 | valid_mse: 0.09218 |  0:01:11s\n",
      "epoch 49 | loss: 0.08211 | train_rmsle: 0.00572 | train_mae: 0.21677 | train_rmse: 0.28978 | train_mse: 0.08397 | valid_rmsle: 0.00627 | valid_mae: 0.23429 | valid_rmse: 0.30994 | valid_mse: 0.09606 |  0:01:12s\n",
      "epoch 50 | loss: 0.08089 | train_rmsle: 0.0051  | train_mae: 0.21931 | train_rmse: 0.28138 | train_mse: 0.07918 | valid_rmsle: 0.00595 | valid_mae: 0.24128 | valid_rmse: 0.30814 | valid_mse: 0.09495 |  0:01:13s\n",
      "epoch 51 | loss: 0.08061 | train_rmsle: 0.00514 | train_mae: 0.21491 | train_rmse: 0.27967 | train_mse: 0.07822 | valid_rmsle: 0.00596 | valid_mae: 0.23771 | valid_rmse: 0.30634 | valid_mse: 0.09384 |  0:01:15s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_valid_mse = 0.08928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09537912148620106 RMSE: 0.3088351040380628 R2: 0.577793380527738 MAE: 0.2367579958957963\n",
      "=====================================\n",
      "[90/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.15236 | train_rmsle: 0.32881 | train_mae: 1.84919 | train_rmse: 1.9117  | train_mse: 3.6546  | valid_rmsle: 0.33052 | valid_mae: 1.85598 | valid_rmse: 1.91746 | valid_mse: 3.67665 |  0:00:01s\n",
      "epoch 1  | loss: 1.38106 | train_rmsle: 0.07356 | train_mae: 0.96923 | train_rmse: 1.0607  | train_mse: 1.12509 | valid_rmsle: 0.07376 | valid_mae: 0.97111 | valid_rmse: 1.06372 | valid_mse: 1.13151 |  0:00:03s\n",
      "epoch 2  | loss: 0.65213 | train_rmsle: 0.07302 | train_mae: 0.96657 | train_rmse: 1.05733 | train_mse: 1.11795 | valid_rmsle: 0.07337 | valid_mae: 0.96908 | valid_rmse: 1.06144 | valid_mse: 1.12666 |  0:00:04s\n",
      "epoch 3  | loss: 0.42092 | train_rmsle: 0.0608  | train_mae: 0.88572 | train_rmse: 0.97778 | train_mse: 0.95606 | valid_rmsle: 0.06087 | valid_mae: 0.88637 | valid_rmse: 0.98026 | valid_mse: 0.96092 |  0:00:05s\n",
      "epoch 4  | loss: 0.2984  | train_rmsle: 0.0324  | train_mae: 0.66919 | train_rmse: 0.7335  | train_mse: 0.53803 | valid_rmsle: 0.03164 | valid_mae: 0.665   | valid_rmse: 0.72804 | valid_mse: 0.53005 |  0:00:07s\n",
      "epoch 5  | loss: 0.23499 | train_rmsle: 0.03586 | train_mae: 0.68402 | train_rmse: 0.74274 | train_mse: 0.55166 | valid_rmsle: 0.03493 | valid_mae: 0.67707 | valid_rmse: 0.73438 | valid_mse: 0.53931 |  0:00:08s\n",
      "epoch 6  | loss: 0.21774 | train_rmsle: 0.01974 | train_mae: 0.49485 | train_rmse: 0.56122 | train_mse: 0.31497 | valid_rmsle: 0.01875 | valid_mae: 0.48298 | valid_rmse: 0.54828 | valid_mse: 0.30061 |  0:00:10s\n",
      "epoch 7  | loss: 0.20965 | train_rmsle: 0.0247  | train_mae: 0.54993 | train_rmse: 0.61891 | train_mse: 0.38305 | valid_rmsle: 0.02386 | valid_mae: 0.54232 | valid_rmse: 0.61058 | valid_mse: 0.37281 |  0:00:11s\n",
      "epoch 8  | loss: 0.16411 | train_rmsle: 0.01897 | train_mae: 0.47171 | train_rmse: 0.55499 | train_mse: 0.30802 | valid_rmsle: 0.01819 | valid_mae: 0.46072 | valid_rmse: 0.54525 | valid_mse: 0.2973  |  0:00:13s\n",
      "epoch 9  | loss: 0.16638 | train_rmsle: 0.02103 | train_mae: 0.49174 | train_rmse: 0.57336 | train_mse: 0.32874 | valid_rmsle: 0.02037 | valid_mae: 0.48427 | valid_rmse: 0.56604 | valid_mse: 0.3204  |  0:00:14s\n",
      "epoch 10 | loss: 0.15447 | train_rmsle: 0.01084 | train_mae: 0.34123 | train_rmse: 0.4158  | train_mse: 0.17289 | valid_rmsle: 0.01008 | valid_mae: 0.32981 | valid_rmse: 0.40409 | valid_mse: 0.16329 |  0:00:16s\n",
      "epoch 11 | loss: 0.14294 | train_rmsle: 0.00984 | train_mae: 0.32259 | train_rmse: 0.39749 | train_mse: 0.158   | valid_rmsle: 0.00916 | valid_mae: 0.31143 | valid_rmse: 0.38609 | valid_mse: 0.14906 |  0:00:17s\n",
      "epoch 12 | loss: 0.13039 | train_rmsle: 0.01071 | train_mae: 0.3478  | train_rmse: 0.41865 | train_mse: 0.17527 | valid_rmsle: 0.00998 | valid_mae: 0.33711 | valid_rmse: 0.40598 | valid_mse: 0.16482 |  0:00:18s\n",
      "epoch 13 | loss: 0.12534 | train_rmsle: 0.0082  | train_mae: 0.29145 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.0078  | valid_mae: 0.28348 | valid_rmse: 0.35607 | valid_mse: 0.12678 |  0:00:20s\n",
      "epoch 14 | loss: 0.12376 | train_rmsle: 0.00903 | train_mae: 0.30403 | train_rmse: 0.37951 | train_mse: 0.14403 | valid_rmsle: 0.00843 | valid_mae: 0.29386 | valid_rmse: 0.36982 | valid_mse: 0.13677 |  0:00:21s\n",
      "epoch 15 | loss: 0.11926 | train_rmsle: 0.00769 | train_mae: 0.27101 | train_rmse: 0.3473  | train_mse: 0.12062 | valid_rmsle: 0.00702 | valid_mae: 0.26232 | valid_rmse: 0.33588 | valid_mse: 0.11282 |  0:00:23s\n",
      "epoch 16 | loss: 0.11464 | train_rmsle: 0.00875 | train_mae: 0.29994 | train_rmse: 0.37398 | train_mse: 0.13986 | valid_rmsle: 0.00807 | valid_mae: 0.28831 | valid_rmse: 0.3617  | valid_mse: 0.13083 |  0:00:24s\n",
      "epoch 17 | loss: 0.1159  | train_rmsle: 0.0072  | train_mae: 0.25811 | train_rmse: 0.33326 | train_mse: 0.11106 | valid_rmsle: 0.00676 | valid_mae: 0.24924 | valid_rmse: 0.32645 | valid_mse: 0.10657 |  0:00:26s\n",
      "epoch 18 | loss: 0.12165 | train_rmsle: 0.00704 | train_mae: 0.25485 | train_rmse: 0.32881 | train_mse: 0.10811 | valid_rmsle: 0.00651 | valid_mae: 0.24401 | valid_rmse: 0.31967 | valid_mse: 0.10219 |  0:00:27s\n",
      "epoch 19 | loss: 0.1103  | train_rmsle: 0.0072  | train_mae: 0.2669  | train_rmse: 0.33583 | train_mse: 0.11278 | valid_rmsle: 0.00654 | valid_mae: 0.25515 | valid_rmse: 0.3233  | valid_mse: 0.10452 |  0:00:29s\n",
      "epoch 20 | loss: 0.11021 | train_rmsle: 0.00866 | train_mae: 0.30599 | train_rmse: 0.37396 | train_mse: 0.13985 | valid_rmsle: 0.00802 | valid_mae: 0.29862 | valid_rmse: 0.36335 | valid_mse: 0.13202 |  0:00:30s\n",
      "epoch 21 | loss: 0.10973 | train_rmsle: 0.00715 | train_mae: 0.2645  | train_rmse: 0.33453 | train_mse: 0.11191 | valid_rmsle: 0.00651 | valid_mae: 0.25466 | valid_rmse: 0.32317 | valid_mse: 0.10444 |  0:00:32s\n",
      "epoch 22 | loss: 0.11177 | train_rmsle: 0.00764 | train_mae: 0.28065 | train_rmse: 0.34876 | train_mse: 0.12164 | valid_rmsle: 0.0071  | valid_mae: 0.27309 | valid_rmse: 0.34037 | valid_mse: 0.11585 |  0:00:33s\n",
      "epoch 23 | loss: 0.10461 | train_rmsle: 0.00687 | train_mae: 0.24297 | train_rmse: 0.32148 | train_mse: 0.10335 | valid_rmsle: 0.00639 | valid_mae: 0.23623 | valid_rmse: 0.31438 | valid_mse: 0.09883 |  0:00:34s\n",
      "epoch 24 | loss: 0.10727 | train_rmsle: 0.0068  | train_mae: 0.24508 | train_rmse: 0.32054 | train_mse: 0.10274 | valid_rmsle: 0.00617 | valid_mae: 0.23409 | valid_rmse: 0.30857 | valid_mse: 0.09522 |  0:00:36s\n",
      "epoch 25 | loss: 0.10489 | train_rmsle: 0.00686 | train_mae: 0.2424  | train_rmse: 0.32059 | train_mse: 0.10278 | valid_rmsle: 0.00623 | valid_mae: 0.23332 | valid_rmse: 0.30976 | valid_mse: 0.09595 |  0:00:37s\n",
      "epoch 26 | loss: 0.10507 | train_rmsle: 0.00708 | train_mae: 0.26333 | train_rmse: 0.33276 | train_mse: 0.11073 | valid_rmsle: 0.00658 | valid_mae: 0.25433 | valid_rmse: 0.32438 | valid_mse: 0.10522 |  0:00:39s\n",
      "epoch 27 | loss: 0.10032 | train_rmsle: 0.00639 | train_mae: 0.23741 | train_rmse: 0.31007 | train_mse: 0.09614 | valid_rmsle: 0.00588 | valid_mae: 0.22925 | valid_rmse: 0.3012  | valid_mse: 0.09072 |  0:00:40s\n",
      "epoch 28 | loss: 0.1015  | train_rmsle: 0.00693 | train_mae: 0.25716 | train_rmse: 0.32676 | train_mse: 0.10677 | valid_rmsle: 0.00633 | valid_mae: 0.24683 | valid_rmse: 0.31574 | valid_mse: 0.09969 |  0:00:42s\n",
      "epoch 29 | loss: 0.09998 | train_rmsle: 0.00628 | train_mae: 0.23779 | train_rmse: 0.30853 | train_mse: 0.09519 | valid_rmsle: 0.0058  | valid_mae: 0.22866 | valid_rmse: 0.29927 | valid_mse: 0.08956 |  0:00:43s\n",
      "epoch 30 | loss: 0.09951 | train_rmsle: 0.00744 | train_mae: 0.2774  | train_rmse: 0.34416 | train_mse: 0.11845 | valid_rmsle: 0.00691 | valid_mae: 0.26876 | valid_rmse: 0.3342  | valid_mse: 0.11169 |  0:00:45s\n",
      "epoch 31 | loss: 0.09888 | train_rmsle: 0.00626 | train_mae: 0.23603 | train_rmse: 0.30672 | train_mse: 0.09408 | valid_rmsle: 0.00578 | valid_mae: 0.22918 | valid_rmse: 0.29879 | valid_mse: 0.08928 |  0:00:46s\n",
      "epoch 32 | loss: 0.09877 | train_rmsle: 0.0065  | train_mae: 0.24955 | train_rmse: 0.31639 | train_mse: 0.1001  | valid_rmsle: 0.00607 | valid_mae: 0.24385 | valid_rmse: 0.30931 | valid_mse: 0.09567 |  0:00:47s\n",
      "epoch 33 | loss: 0.09722 | train_rmsle: 0.00632 | train_mae: 0.23576 | train_rmse: 0.30921 | train_mse: 0.09561 | valid_rmsle: 0.00605 | valid_mae: 0.23188 | valid_rmse: 0.30652 | valid_mse: 0.09395 |  0:00:49s\n",
      "epoch 34 | loss: 0.09706 | train_rmsle: 0.00613 | train_mae: 0.233   | train_rmse: 0.30396 | train_mse: 0.09239 | valid_rmsle: 0.00587 | valid_mae: 0.23001 | valid_rmse: 0.30122 | valid_mse: 0.09073 |  0:00:50s\n",
      "epoch 35 | loss: 0.09461 | train_rmsle: 0.00628 | train_mae: 0.23273 | train_rmse: 0.30609 | train_mse: 0.09369 | valid_rmsle: 0.00605 | valid_mae: 0.23042 | valid_rmse: 0.30487 | valid_mse: 0.09294 |  0:00:52s\n",
      "epoch 36 | loss: 0.09943 | train_rmsle: 0.00607 | train_mae: 0.23384 | train_rmse: 0.30334 | train_mse: 0.09201 | valid_rmsle: 0.00585 | valid_mae: 0.22991 | valid_rmse: 0.30168 | valid_mse: 0.09101 |  0:00:53s\n",
      "epoch 37 | loss: 0.09274 | train_rmsle: 0.00617 | train_mae: 0.23116 | train_rmse: 0.30336 | train_mse: 0.09203 | valid_rmsle: 0.00611 | valid_mae: 0.23004 | valid_rmse: 0.30595 | valid_mse: 0.09361 |  0:00:55s\n",
      "epoch 38 | loss: 0.09134 | train_rmsle: 0.00611 | train_mae: 0.23174 | train_rmse: 0.30276 | train_mse: 0.09167 | valid_rmsle: 0.00601 | valid_mae: 0.23266 | valid_rmse: 0.30514 | valid_mse: 0.09311 |  0:00:56s\n",
      "epoch 39 | loss: 0.08958 | train_rmsle: 0.00629 | train_mae: 0.23103 | train_rmse: 0.30493 | train_mse: 0.09298 | valid_rmsle: 0.00623 | valid_mae: 0.23495 | valid_rmse: 0.30889 | valid_mse: 0.09541 |  0:00:58s\n",
      "epoch 40 | loss: 0.08899 | train_rmsle: 0.00615 | train_mae: 0.2297  | train_rmse: 0.30324 | train_mse: 0.09196 | valid_rmsle: 0.00616 | valid_mae: 0.23321 | valid_rmse: 0.30814 | valid_mse: 0.09495 |  0:00:59s\n",
      "epoch 41 | loss: 0.08679 | train_rmsle: 0.00571 | train_mae: 0.22425 | train_rmse: 0.29287 | train_mse: 0.08577 | valid_rmsle: 0.0059  | valid_mae: 0.23047 | valid_rmse: 0.30139 | valid_mse: 0.09083 |  0:01:01s\n",
      "epoch 42 | loss: 0.0859  | train_rmsle: 0.00568 | train_mae: 0.23    | train_rmse: 0.29615 | train_mse: 0.0877  | valid_rmsle: 0.00585 | valid_mae: 0.23667 | valid_rmse: 0.30366 | valid_mse: 0.09221 |  0:01:02s\n",
      "epoch 43 | loss: 0.08643 | train_rmsle: 0.00587 | train_mae: 0.228   | train_rmse: 0.29702 | train_mse: 0.08822 | valid_rmsle: 0.00603 | valid_mae: 0.23564 | valid_rmse: 0.30531 | valid_mse: 0.09321 |  0:01:03s\n",
      "epoch 44 | loss: 0.08648 | train_rmsle: 0.00569 | train_mae: 0.22766 | train_rmse: 0.29435 | train_mse: 0.08664 | valid_rmsle: 0.00585 | valid_mae: 0.23529 | valid_rmse: 0.30255 | valid_mse: 0.09154 |  0:01:05s\n",
      "epoch 45 | loss: 0.08725 | train_rmsle: 0.00616 | train_mae: 0.23054 | train_rmse: 0.3044  | train_mse: 0.09266 | valid_rmsle: 0.00653 | valid_mae: 0.24054 | valid_rmse: 0.3185  | valid_mse: 0.10144 |  0:01:06s\n",
      "epoch 46 | loss: 0.0856  | train_rmsle: 0.0053  | train_mae: 0.21751 | train_rmse: 0.28409 | train_mse: 0.08071 | valid_rmsle: 0.00576 | valid_mae: 0.23045 | valid_rmse: 0.30035 | valid_mse: 0.09021 |  0:01:08s\n",
      "epoch 47 | loss: 0.08516 | train_rmsle: 0.0055  | train_mae: 0.21678 | train_rmse: 0.28621 | train_mse: 0.08192 | valid_rmsle: 0.00594 | valid_mae: 0.22988 | valid_rmse: 0.30306 | valid_mse: 0.09185 |  0:01:09s\n",
      "epoch 48 | loss: 0.08496 | train_rmsle: 0.00524 | train_mae: 0.21954 | train_rmse: 0.28333 | train_mse: 0.08027 | valid_rmsle: 0.00586 | valid_mae: 0.23717 | valid_rmse: 0.30361 | valid_mse: 0.09218 |  0:01:11s\n",
      "epoch 49 | loss: 0.08211 | train_rmsle: 0.00572 | train_mae: 0.21677 | train_rmse: 0.28978 | train_mse: 0.08397 | valid_rmsle: 0.00627 | valid_mae: 0.23429 | valid_rmse: 0.30994 | valid_mse: 0.09606 |  0:01:12s\n",
      "epoch 50 | loss: 0.08089 | train_rmsle: 0.0051  | train_mae: 0.21931 | train_rmse: 0.28138 | train_mse: 0.07918 | valid_rmsle: 0.00595 | valid_mae: 0.24128 | valid_rmse: 0.30814 | valid_mse: 0.09495 |  0:01:13s\n",
      "epoch 51 | loss: 0.08061 | train_rmsle: 0.00514 | train_mae: 0.21491 | train_rmse: 0.27967 | train_mse: 0.07822 | valid_rmsle: 0.00596 | valid_mae: 0.23771 | valid_rmse: 0.30634 | valid_mse: 0.09384 |  0:01:15s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_valid_mse = 0.08928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09537912148620106 RMSE: 0.3088351040380628 R2: 0.577793380527738 MAE: 0.2367579958957963\n",
      "=====================================\n",
      "[91/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.15236 | train_rmsle: 0.32881 | train_mae: 1.84919 | train_rmse: 1.9117  | train_mse: 3.6546  | valid_rmsle: 0.33052 | valid_mae: 1.85598 | valid_rmse: 1.91746 | valid_mse: 3.67665 |  0:00:01s\n",
      "epoch 1  | loss: 1.38106 | train_rmsle: 0.07356 | train_mae: 0.96923 | train_rmse: 1.0607  | train_mse: 1.12509 | valid_rmsle: 0.07376 | valid_mae: 0.97111 | valid_rmse: 1.06372 | valid_mse: 1.13151 |  0:00:03s\n",
      "epoch 2  | loss: 0.65213 | train_rmsle: 0.07302 | train_mae: 0.96657 | train_rmse: 1.05733 | train_mse: 1.11795 | valid_rmsle: 0.07337 | valid_mae: 0.96908 | valid_rmse: 1.06144 | valid_mse: 1.12666 |  0:00:04s\n",
      "epoch 3  | loss: 0.42092 | train_rmsle: 0.0608  | train_mae: 0.88572 | train_rmse: 0.97778 | train_mse: 0.95606 | valid_rmsle: 0.06087 | valid_mae: 0.88637 | valid_rmse: 0.98026 | valid_mse: 0.96092 |  0:00:05s\n",
      "epoch 4  | loss: 0.2984  | train_rmsle: 0.0324  | train_mae: 0.66919 | train_rmse: 0.7335  | train_mse: 0.53803 | valid_rmsle: 0.03164 | valid_mae: 0.665   | valid_rmse: 0.72804 | valid_mse: 0.53005 |  0:00:07s\n",
      "epoch 5  | loss: 0.23499 | train_rmsle: 0.03586 | train_mae: 0.68402 | train_rmse: 0.74274 | train_mse: 0.55166 | valid_rmsle: 0.03493 | valid_mae: 0.67707 | valid_rmse: 0.73438 | valid_mse: 0.53931 |  0:00:08s\n",
      "epoch 6  | loss: 0.21774 | train_rmsle: 0.01974 | train_mae: 0.49485 | train_rmse: 0.56122 | train_mse: 0.31497 | valid_rmsle: 0.01875 | valid_mae: 0.48298 | valid_rmse: 0.54828 | valid_mse: 0.30061 |  0:00:10s\n",
      "epoch 7  | loss: 0.20965 | train_rmsle: 0.0247  | train_mae: 0.54993 | train_rmse: 0.61891 | train_mse: 0.38305 | valid_rmsle: 0.02386 | valid_mae: 0.54232 | valid_rmse: 0.61058 | valid_mse: 0.37281 |  0:00:11s\n",
      "epoch 8  | loss: 0.16411 | train_rmsle: 0.01897 | train_mae: 0.47171 | train_rmse: 0.55499 | train_mse: 0.30802 | valid_rmsle: 0.01819 | valid_mae: 0.46072 | valid_rmse: 0.54525 | valid_mse: 0.2973  |  0:00:13s\n",
      "epoch 9  | loss: 0.16638 | train_rmsle: 0.02103 | train_mae: 0.49174 | train_rmse: 0.57336 | train_mse: 0.32874 | valid_rmsle: 0.02037 | valid_mae: 0.48427 | valid_rmse: 0.56604 | valid_mse: 0.3204  |  0:00:14s\n",
      "epoch 10 | loss: 0.15447 | train_rmsle: 0.01084 | train_mae: 0.34123 | train_rmse: 0.4158  | train_mse: 0.17289 | valid_rmsle: 0.01008 | valid_mae: 0.32981 | valid_rmse: 0.40409 | valid_mse: 0.16329 |  0:00:16s\n",
      "epoch 11 | loss: 0.14294 | train_rmsle: 0.00984 | train_mae: 0.32259 | train_rmse: 0.39749 | train_mse: 0.158   | valid_rmsle: 0.00916 | valid_mae: 0.31143 | valid_rmse: 0.38609 | valid_mse: 0.14906 |  0:00:17s\n",
      "epoch 12 | loss: 0.13039 | train_rmsle: 0.01071 | train_mae: 0.3478  | train_rmse: 0.41865 | train_mse: 0.17527 | valid_rmsle: 0.00998 | valid_mae: 0.33711 | valid_rmse: 0.40598 | valid_mse: 0.16482 |  0:00:19s\n",
      "epoch 13 | loss: 0.12534 | train_rmsle: 0.0082  | train_mae: 0.29145 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.0078  | valid_mae: 0.28348 | valid_rmse: 0.35607 | valid_mse: 0.12678 |  0:00:20s\n",
      "epoch 14 | loss: 0.12376 | train_rmsle: 0.00903 | train_mae: 0.30403 | train_rmse: 0.37951 | train_mse: 0.14403 | valid_rmsle: 0.00843 | valid_mae: 0.29386 | valid_rmse: 0.36982 | valid_mse: 0.13677 |  0:00:21s\n",
      "epoch 15 | loss: 0.11926 | train_rmsle: 0.00769 | train_mae: 0.27101 | train_rmse: 0.3473  | train_mse: 0.12062 | valid_rmsle: 0.00702 | valid_mae: 0.26232 | valid_rmse: 0.33588 | valid_mse: 0.11282 |  0:00:23s\n",
      "epoch 16 | loss: 0.11464 | train_rmsle: 0.00875 | train_mae: 0.29994 | train_rmse: 0.37398 | train_mse: 0.13986 | valid_rmsle: 0.00807 | valid_mae: 0.28831 | valid_rmse: 0.3617  | valid_mse: 0.13083 |  0:00:24s\n",
      "epoch 17 | loss: 0.1159  | train_rmsle: 0.0072  | train_mae: 0.25811 | train_rmse: 0.33326 | train_mse: 0.11106 | valid_rmsle: 0.00676 | valid_mae: 0.24924 | valid_rmse: 0.32645 | valid_mse: 0.10657 |  0:00:26s\n",
      "epoch 18 | loss: 0.12165 | train_rmsle: 0.00704 | train_mae: 0.25485 | train_rmse: 0.32881 | train_mse: 0.10811 | valid_rmsle: 0.00651 | valid_mae: 0.24401 | valid_rmse: 0.31967 | valid_mse: 0.10219 |  0:00:27s\n",
      "epoch 19 | loss: 0.1103  | train_rmsle: 0.0072  | train_mae: 0.2669  | train_rmse: 0.33583 | train_mse: 0.11278 | valid_rmsle: 0.00654 | valid_mae: 0.25515 | valid_rmse: 0.3233  | valid_mse: 0.10452 |  0:00:29s\n",
      "epoch 20 | loss: 0.11021 | train_rmsle: 0.00866 | train_mae: 0.30599 | train_rmse: 0.37396 | train_mse: 0.13985 | valid_rmsle: 0.00802 | valid_mae: 0.29862 | valid_rmse: 0.36335 | valid_mse: 0.13202 |  0:00:30s\n",
      "epoch 21 | loss: 0.10973 | train_rmsle: 0.00715 | train_mae: 0.2645  | train_rmse: 0.33453 | train_mse: 0.11191 | valid_rmsle: 0.00651 | valid_mae: 0.25466 | valid_rmse: 0.32317 | valid_mse: 0.10444 |  0:00:32s\n",
      "epoch 22 | loss: 0.11177 | train_rmsle: 0.00764 | train_mae: 0.28065 | train_rmse: 0.34876 | train_mse: 0.12164 | valid_rmsle: 0.0071  | valid_mae: 0.27309 | valid_rmse: 0.34037 | valid_mse: 0.11585 |  0:00:33s\n",
      "epoch 23 | loss: 0.10461 | train_rmsle: 0.00687 | train_mae: 0.24297 | train_rmse: 0.32148 | train_mse: 0.10335 | valid_rmsle: 0.00639 | valid_mae: 0.23623 | valid_rmse: 0.31438 | valid_mse: 0.09883 |  0:00:35s\n",
      "epoch 24 | loss: 0.10727 | train_rmsle: 0.0068  | train_mae: 0.24508 | train_rmse: 0.32054 | train_mse: 0.10274 | valid_rmsle: 0.00617 | valid_mae: 0.23409 | valid_rmse: 0.30857 | valid_mse: 0.09522 |  0:00:36s\n",
      "epoch 25 | loss: 0.10489 | train_rmsle: 0.00686 | train_mae: 0.2424  | train_rmse: 0.32059 | train_mse: 0.10278 | valid_rmsle: 0.00623 | valid_mae: 0.23332 | valid_rmse: 0.30976 | valid_mse: 0.09595 |  0:00:37s\n",
      "epoch 26 | loss: 0.10507 | train_rmsle: 0.00708 | train_mae: 0.26333 | train_rmse: 0.33276 | train_mse: 0.11073 | valid_rmsle: 0.00658 | valid_mae: 0.25433 | valid_rmse: 0.32438 | valid_mse: 0.10522 |  0:00:39s\n",
      "epoch 27 | loss: 0.10032 | train_rmsle: 0.00639 | train_mae: 0.23741 | train_rmse: 0.31007 | train_mse: 0.09614 | valid_rmsle: 0.00588 | valid_mae: 0.22925 | valid_rmse: 0.3012  | valid_mse: 0.09072 |  0:00:40s\n",
      "epoch 28 | loss: 0.1015  | train_rmsle: 0.00693 | train_mae: 0.25716 | train_rmse: 0.32676 | train_mse: 0.10677 | valid_rmsle: 0.00633 | valid_mae: 0.24683 | valid_rmse: 0.31574 | valid_mse: 0.09969 |  0:00:42s\n",
      "epoch 29 | loss: 0.09998 | train_rmsle: 0.00628 | train_mae: 0.23779 | train_rmse: 0.30853 | train_mse: 0.09519 | valid_rmsle: 0.0058  | valid_mae: 0.22866 | valid_rmse: 0.29927 | valid_mse: 0.08956 |  0:00:43s\n",
      "epoch 30 | loss: 0.09951 | train_rmsle: 0.00744 | train_mae: 0.2774  | train_rmse: 0.34416 | train_mse: 0.11845 | valid_rmsle: 0.00691 | valid_mae: 0.26876 | valid_rmse: 0.3342  | valid_mse: 0.11169 |  0:00:45s\n",
      "epoch 31 | loss: 0.09888 | train_rmsle: 0.00626 | train_mae: 0.23603 | train_rmse: 0.30672 | train_mse: 0.09408 | valid_rmsle: 0.00578 | valid_mae: 0.22918 | valid_rmse: 0.29879 | valid_mse: 0.08928 |  0:00:46s\n",
      "epoch 32 | loss: 0.09877 | train_rmsle: 0.0065  | train_mae: 0.24955 | train_rmse: 0.31639 | train_mse: 0.1001  | valid_rmsle: 0.00607 | valid_mae: 0.24385 | valid_rmse: 0.30931 | valid_mse: 0.09567 |  0:00:48s\n",
      "epoch 33 | loss: 0.09722 | train_rmsle: 0.00632 | train_mae: 0.23576 | train_rmse: 0.30921 | train_mse: 0.09561 | valid_rmsle: 0.00605 | valid_mae: 0.23188 | valid_rmse: 0.30652 | valid_mse: 0.09395 |  0:00:49s\n",
      "epoch 34 | loss: 0.09706 | train_rmsle: 0.00613 | train_mae: 0.233   | train_rmse: 0.30396 | train_mse: 0.09239 | valid_rmsle: 0.00587 | valid_mae: 0.23001 | valid_rmse: 0.30122 | valid_mse: 0.09073 |  0:00:51s\n",
      "epoch 35 | loss: 0.09461 | train_rmsle: 0.00628 | train_mae: 0.23273 | train_rmse: 0.30609 | train_mse: 0.09369 | valid_rmsle: 0.00605 | valid_mae: 0.23042 | valid_rmse: 0.30487 | valid_mse: 0.09294 |  0:00:52s\n",
      "epoch 36 | loss: 0.09943 | train_rmsle: 0.00607 | train_mae: 0.23384 | train_rmse: 0.30334 | train_mse: 0.09201 | valid_rmsle: 0.00585 | valid_mae: 0.22991 | valid_rmse: 0.30168 | valid_mse: 0.09101 |  0:00:53s\n",
      "epoch 37 | loss: 0.09274 | train_rmsle: 0.00617 | train_mae: 0.23116 | train_rmse: 0.30336 | train_mse: 0.09203 | valid_rmsle: 0.00611 | valid_mae: 0.23004 | valid_rmse: 0.30595 | valid_mse: 0.09361 |  0:00:55s\n",
      "epoch 38 | loss: 0.09134 | train_rmsle: 0.00611 | train_mae: 0.23174 | train_rmse: 0.30276 | train_mse: 0.09167 | valid_rmsle: 0.00601 | valid_mae: 0.23266 | valid_rmse: 0.30514 | valid_mse: 0.09311 |  0:00:56s\n",
      "epoch 39 | loss: 0.08958 | train_rmsle: 0.00629 | train_mae: 0.23103 | train_rmse: 0.30493 | train_mse: 0.09298 | valid_rmsle: 0.00623 | valid_mae: 0.23495 | valid_rmse: 0.30889 | valid_mse: 0.09541 |  0:00:58s\n",
      "epoch 40 | loss: 0.08899 | train_rmsle: 0.00615 | train_mae: 0.2297  | train_rmse: 0.30324 | train_mse: 0.09196 | valid_rmsle: 0.00616 | valid_mae: 0.23321 | valid_rmse: 0.30814 | valid_mse: 0.09495 |  0:00:59s\n",
      "epoch 41 | loss: 0.08679 | train_rmsle: 0.00571 | train_mae: 0.22425 | train_rmse: 0.29287 | train_mse: 0.08577 | valid_rmsle: 0.0059  | valid_mae: 0.23047 | valid_rmse: 0.30139 | valid_mse: 0.09083 |  0:01:01s\n",
      "epoch 42 | loss: 0.0859  | train_rmsle: 0.00568 | train_mae: 0.23    | train_rmse: 0.29615 | train_mse: 0.0877  | valid_rmsle: 0.00585 | valid_mae: 0.23667 | valid_rmse: 0.30366 | valid_mse: 0.09221 |  0:01:02s\n",
      "epoch 43 | loss: 0.08643 | train_rmsle: 0.00587 | train_mae: 0.228   | train_rmse: 0.29702 | train_mse: 0.08822 | valid_rmsle: 0.00603 | valid_mae: 0.23564 | valid_rmse: 0.30531 | valid_mse: 0.09321 |  0:01:04s\n",
      "epoch 44 | loss: 0.08648 | train_rmsle: 0.00569 | train_mae: 0.22766 | train_rmse: 0.29435 | train_mse: 0.08664 | valid_rmsle: 0.00585 | valid_mae: 0.23529 | valid_rmse: 0.30255 | valid_mse: 0.09154 |  0:01:05s\n",
      "epoch 45 | loss: 0.08725 | train_rmsle: 0.00616 | train_mae: 0.23054 | train_rmse: 0.3044  | train_mse: 0.09266 | valid_rmsle: 0.00653 | valid_mae: 0.24054 | valid_rmse: 0.3185  | valid_mse: 0.10144 |  0:01:06s\n",
      "epoch 46 | loss: 0.0856  | train_rmsle: 0.0053  | train_mae: 0.21751 | train_rmse: 0.28409 | train_mse: 0.08071 | valid_rmsle: 0.00576 | valid_mae: 0.23045 | valid_rmse: 0.30035 | valid_mse: 0.09021 |  0:01:08s\n",
      "epoch 47 | loss: 0.08516 | train_rmsle: 0.0055  | train_mae: 0.21678 | train_rmse: 0.28621 | train_mse: 0.08192 | valid_rmsle: 0.00594 | valid_mae: 0.22988 | valid_rmse: 0.30306 | valid_mse: 0.09185 |  0:01:09s\n",
      "epoch 48 | loss: 0.08496 | train_rmsle: 0.00524 | train_mae: 0.21954 | train_rmse: 0.28333 | train_mse: 0.08027 | valid_rmsle: 0.00586 | valid_mae: 0.23717 | valid_rmse: 0.30361 | valid_mse: 0.09218 |  0:01:11s\n",
      "epoch 49 | loss: 0.08211 | train_rmsle: 0.00572 | train_mae: 0.21677 | train_rmse: 0.28978 | train_mse: 0.08397 | valid_rmsle: 0.00627 | valid_mae: 0.23429 | valid_rmse: 0.30994 | valid_mse: 0.09606 |  0:01:12s\n",
      "epoch 50 | loss: 0.08089 | train_rmsle: 0.0051  | train_mae: 0.21931 | train_rmse: 0.28138 | train_mse: 0.07918 | valid_rmsle: 0.00595 | valid_mae: 0.24128 | valid_rmse: 0.30814 | valid_mse: 0.09495 |  0:01:14s\n",
      "epoch 51 | loss: 0.08061 | train_rmsle: 0.00514 | train_mae: 0.21491 | train_rmse: 0.27967 | train_mse: 0.07822 | valid_rmsle: 0.00596 | valid_mae: 0.23771 | valid_rmse: 0.30634 | valid_mse: 0.09384 |  0:01:15s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_valid_mse = 0.08928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09537912148620106 RMSE: 0.3088351040380628 R2: 0.577793380527738 MAE: 0.2367579958957963\n",
      "=====================================\n",
      "[92/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 8.15236 | train_rmsle: 0.32881 | train_mae: 1.84919 | train_rmse: 1.9117  | train_mse: 3.6546  | valid_rmsle: 0.33052 | valid_mae: 1.85598 | valid_rmse: 1.91746 | valid_mse: 3.67665 |  0:00:01s\n",
      "epoch 1  | loss: 1.38106 | train_rmsle: 0.07356 | train_mae: 0.96923 | train_rmse: 1.0607  | train_mse: 1.12509 | valid_rmsle: 0.07376 | valid_mae: 0.97111 | valid_rmse: 1.06372 | valid_mse: 1.13151 |  0:00:03s\n",
      "epoch 2  | loss: 0.65213 | train_rmsle: 0.07302 | train_mae: 0.96657 | train_rmse: 1.05733 | train_mse: 1.11795 | valid_rmsle: 0.07337 | valid_mae: 0.96908 | valid_rmse: 1.06144 | valid_mse: 1.12666 |  0:00:04s\n",
      "epoch 3  | loss: 0.42092 | train_rmsle: 0.0608  | train_mae: 0.88572 | train_rmse: 0.97778 | train_mse: 0.95606 | valid_rmsle: 0.06087 | valid_mae: 0.88637 | valid_rmse: 0.98026 | valid_mse: 0.96092 |  0:00:05s\n",
      "epoch 4  | loss: 0.2984  | train_rmsle: 0.0324  | train_mae: 0.66919 | train_rmse: 0.7335  | train_mse: 0.53803 | valid_rmsle: 0.03164 | valid_mae: 0.665   | valid_rmse: 0.72804 | valid_mse: 0.53005 |  0:00:07s\n",
      "epoch 5  | loss: 0.23499 | train_rmsle: 0.03586 | train_mae: 0.68402 | train_rmse: 0.74274 | train_mse: 0.55166 | valid_rmsle: 0.03493 | valid_mae: 0.67707 | valid_rmse: 0.73438 | valid_mse: 0.53931 |  0:00:08s\n",
      "epoch 6  | loss: 0.21774 | train_rmsle: 0.01974 | train_mae: 0.49485 | train_rmse: 0.56122 | train_mse: 0.31497 | valid_rmsle: 0.01875 | valid_mae: 0.48298 | valid_rmse: 0.54828 | valid_mse: 0.30061 |  0:00:10s\n",
      "epoch 7  | loss: 0.20965 | train_rmsle: 0.0247  | train_mae: 0.54993 | train_rmse: 0.61891 | train_mse: 0.38305 | valid_rmsle: 0.02386 | valid_mae: 0.54232 | valid_rmse: 0.61058 | valid_mse: 0.37281 |  0:00:11s\n",
      "epoch 8  | loss: 0.16411 | train_rmsle: 0.01897 | train_mae: 0.47171 | train_rmse: 0.55499 | train_mse: 0.30802 | valid_rmsle: 0.01819 | valid_mae: 0.46072 | valid_rmse: 0.54525 | valid_mse: 0.2973  |  0:00:13s\n",
      "epoch 9  | loss: 0.16638 | train_rmsle: 0.02103 | train_mae: 0.49174 | train_rmse: 0.57336 | train_mse: 0.32874 | valid_rmsle: 0.02037 | valid_mae: 0.48427 | valid_rmse: 0.56604 | valid_mse: 0.3204  |  0:00:14s\n",
      "epoch 10 | loss: 0.15447 | train_rmsle: 0.01084 | train_mae: 0.34123 | train_rmse: 0.4158  | train_mse: 0.17289 | valid_rmsle: 0.01008 | valid_mae: 0.32981 | valid_rmse: 0.40409 | valid_mse: 0.16329 |  0:00:16s\n",
      "epoch 11 | loss: 0.14294 | train_rmsle: 0.00984 | train_mae: 0.32259 | train_rmse: 0.39749 | train_mse: 0.158   | valid_rmsle: 0.00916 | valid_mae: 0.31143 | valid_rmse: 0.38609 | valid_mse: 0.14906 |  0:00:17s\n",
      "epoch 12 | loss: 0.13039 | train_rmsle: 0.01071 | train_mae: 0.3478  | train_rmse: 0.41865 | train_mse: 0.17527 | valid_rmsle: 0.00998 | valid_mae: 0.33711 | valid_rmse: 0.40598 | valid_mse: 0.16482 |  0:00:18s\n",
      "epoch 13 | loss: 0.12534 | train_rmsle: 0.0082  | train_mae: 0.29145 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.0078  | valid_mae: 0.28348 | valid_rmse: 0.35607 | valid_mse: 0.12678 |  0:00:20s\n",
      "epoch 14 | loss: 0.12376 | train_rmsle: 0.00903 | train_mae: 0.30403 | train_rmse: 0.37951 | train_mse: 0.14403 | valid_rmsle: 0.00843 | valid_mae: 0.29386 | valid_rmse: 0.36982 | valid_mse: 0.13677 |  0:00:21s\n",
      "epoch 15 | loss: 0.11926 | train_rmsle: 0.00769 | train_mae: 0.27101 | train_rmse: 0.3473  | train_mse: 0.12062 | valid_rmsle: 0.00702 | valid_mae: 0.26232 | valid_rmse: 0.33588 | valid_mse: 0.11282 |  0:00:23s\n",
      "epoch 16 | loss: 0.11464 | train_rmsle: 0.00875 | train_mae: 0.29994 | train_rmse: 0.37398 | train_mse: 0.13986 | valid_rmsle: 0.00807 | valid_mae: 0.28831 | valid_rmse: 0.3617  | valid_mse: 0.13083 |  0:00:24s\n",
      "epoch 17 | loss: 0.1159  | train_rmsle: 0.0072  | train_mae: 0.25811 | train_rmse: 0.33326 | train_mse: 0.11106 | valid_rmsle: 0.00676 | valid_mae: 0.24924 | valid_rmse: 0.32645 | valid_mse: 0.10657 |  0:00:26s\n",
      "epoch 18 | loss: 0.12165 | train_rmsle: 0.00704 | train_mae: 0.25485 | train_rmse: 0.32881 | train_mse: 0.10811 | valid_rmsle: 0.00651 | valid_mae: 0.24401 | valid_rmse: 0.31967 | valid_mse: 0.10219 |  0:00:27s\n",
      "epoch 19 | loss: 0.1103  | train_rmsle: 0.0072  | train_mae: 0.2669  | train_rmse: 0.33583 | train_mse: 0.11278 | valid_rmsle: 0.00654 | valid_mae: 0.25515 | valid_rmse: 0.3233  | valid_mse: 0.10452 |  0:00:29s\n",
      "epoch 20 | loss: 0.11021 | train_rmsle: 0.00866 | train_mae: 0.30599 | train_rmse: 0.37396 | train_mse: 0.13985 | valid_rmsle: 0.00802 | valid_mae: 0.29862 | valid_rmse: 0.36335 | valid_mse: 0.13202 |  0:00:30s\n",
      "epoch 21 | loss: 0.10973 | train_rmsle: 0.00715 | train_mae: 0.2645  | train_rmse: 0.33453 | train_mse: 0.11191 | valid_rmsle: 0.00651 | valid_mae: 0.25466 | valid_rmse: 0.32317 | valid_mse: 0.10444 |  0:00:31s\n",
      "epoch 22 | loss: 0.11177 | train_rmsle: 0.00764 | train_mae: 0.28065 | train_rmse: 0.34876 | train_mse: 0.12164 | valid_rmsle: 0.0071  | valid_mae: 0.27309 | valid_rmse: 0.34037 | valid_mse: 0.11585 |  0:00:33s\n",
      "epoch 23 | loss: 0.10461 | train_rmsle: 0.00687 | train_mae: 0.24297 | train_rmse: 0.32148 | train_mse: 0.10335 | valid_rmsle: 0.00639 | valid_mae: 0.23623 | valid_rmse: 0.31438 | valid_mse: 0.09883 |  0:00:34s\n",
      "epoch 24 | loss: 0.10727 | train_rmsle: 0.0068  | train_mae: 0.24508 | train_rmse: 0.32054 | train_mse: 0.10274 | valid_rmsle: 0.00617 | valid_mae: 0.23409 | valid_rmse: 0.30857 | valid_mse: 0.09522 |  0:00:36s\n",
      "epoch 25 | loss: 0.10489 | train_rmsle: 0.00686 | train_mae: 0.2424  | train_rmse: 0.32059 | train_mse: 0.10278 | valid_rmsle: 0.00623 | valid_mae: 0.23332 | valid_rmse: 0.30976 | valid_mse: 0.09595 |  0:00:37s\n",
      "epoch 26 | loss: 0.10507 | train_rmsle: 0.00708 | train_mae: 0.26333 | train_rmse: 0.33276 | train_mse: 0.11073 | valid_rmsle: 0.00658 | valid_mae: 0.25433 | valid_rmse: 0.32438 | valid_mse: 0.10522 |  0:00:39s\n",
      "epoch 27 | loss: 0.10032 | train_rmsle: 0.00639 | train_mae: 0.23741 | train_rmse: 0.31007 | train_mse: 0.09614 | valid_rmsle: 0.00588 | valid_mae: 0.22925 | valid_rmse: 0.3012  | valid_mse: 0.09072 |  0:00:40s\n",
      "epoch 28 | loss: 0.1015  | train_rmsle: 0.00693 | train_mae: 0.25716 | train_rmse: 0.32676 | train_mse: 0.10677 | valid_rmsle: 0.00633 | valid_mae: 0.24683 | valid_rmse: 0.31574 | valid_mse: 0.09969 |  0:00:42s\n",
      "epoch 29 | loss: 0.09998 | train_rmsle: 0.00628 | train_mae: 0.23779 | train_rmse: 0.30853 | train_mse: 0.09519 | valid_rmsle: 0.0058  | valid_mae: 0.22866 | valid_rmse: 0.29927 | valid_mse: 0.08956 |  0:00:43s\n",
      "epoch 30 | loss: 0.09951 | train_rmsle: 0.00744 | train_mae: 0.2774  | train_rmse: 0.34416 | train_mse: 0.11845 | valid_rmsle: 0.00691 | valid_mae: 0.26876 | valid_rmse: 0.3342  | valid_mse: 0.11169 |  0:00:44s\n",
      "epoch 31 | loss: 0.09888 | train_rmsle: 0.00626 | train_mae: 0.23603 | train_rmse: 0.30672 | train_mse: 0.09408 | valid_rmsle: 0.00578 | valid_mae: 0.22918 | valid_rmse: 0.29879 | valid_mse: 0.08928 |  0:00:46s\n",
      "epoch 32 | loss: 0.09877 | train_rmsle: 0.0065  | train_mae: 0.24955 | train_rmse: 0.31639 | train_mse: 0.1001  | valid_rmsle: 0.00607 | valid_mae: 0.24385 | valid_rmse: 0.30931 | valid_mse: 0.09567 |  0:00:47s\n",
      "epoch 33 | loss: 0.09722 | train_rmsle: 0.00632 | train_mae: 0.23576 | train_rmse: 0.30921 | train_mse: 0.09561 | valid_rmsle: 0.00605 | valid_mae: 0.23188 | valid_rmse: 0.30652 | valid_mse: 0.09395 |  0:00:49s\n",
      "epoch 34 | loss: 0.09706 | train_rmsle: 0.00613 | train_mae: 0.233   | train_rmse: 0.30396 | train_mse: 0.09239 | valid_rmsle: 0.00587 | valid_mae: 0.23001 | valid_rmse: 0.30122 | valid_mse: 0.09073 |  0:00:50s\n",
      "epoch 35 | loss: 0.09461 | train_rmsle: 0.00628 | train_mae: 0.23273 | train_rmse: 0.30609 | train_mse: 0.09369 | valid_rmsle: 0.00605 | valid_mae: 0.23042 | valid_rmse: 0.30487 | valid_mse: 0.09294 |  0:00:52s\n",
      "epoch 36 | loss: 0.09943 | train_rmsle: 0.00607 | train_mae: 0.23384 | train_rmse: 0.30334 | train_mse: 0.09201 | valid_rmsle: 0.00585 | valid_mae: 0.22991 | valid_rmse: 0.30168 | valid_mse: 0.09101 |  0:00:53s\n",
      "epoch 37 | loss: 0.09274 | train_rmsle: 0.00617 | train_mae: 0.23116 | train_rmse: 0.30336 | train_mse: 0.09203 | valid_rmsle: 0.00611 | valid_mae: 0.23004 | valid_rmse: 0.30595 | valid_mse: 0.09361 |  0:00:55s\n",
      "epoch 38 | loss: 0.09134 | train_rmsle: 0.00611 | train_mae: 0.23174 | train_rmse: 0.30276 | train_mse: 0.09167 | valid_rmsle: 0.00601 | valid_mae: 0.23266 | valid_rmse: 0.30514 | valid_mse: 0.09311 |  0:00:56s\n",
      "epoch 39 | loss: 0.08958 | train_rmsle: 0.00629 | train_mae: 0.23103 | train_rmse: 0.30493 | train_mse: 0.09298 | valid_rmsle: 0.00623 | valid_mae: 0.23495 | valid_rmse: 0.30889 | valid_mse: 0.09541 |  0:00:57s\n",
      "epoch 40 | loss: 0.08899 | train_rmsle: 0.00615 | train_mae: 0.2297  | train_rmse: 0.30324 | train_mse: 0.09196 | valid_rmsle: 0.00616 | valid_mae: 0.23321 | valid_rmse: 0.30814 | valid_mse: 0.09495 |  0:00:59s\n",
      "epoch 41 | loss: 0.08679 | train_rmsle: 0.00571 | train_mae: 0.22425 | train_rmse: 0.29287 | train_mse: 0.08577 | valid_rmsle: 0.0059  | valid_mae: 0.23047 | valid_rmse: 0.30139 | valid_mse: 0.09083 |  0:01:00s\n",
      "epoch 42 | loss: 0.0859  | train_rmsle: 0.00568 | train_mae: 0.23    | train_rmse: 0.29615 | train_mse: 0.0877  | valid_rmsle: 0.00585 | valid_mae: 0.23667 | valid_rmse: 0.30366 | valid_mse: 0.09221 |  0:01:02s\n",
      "epoch 43 | loss: 0.08643 | train_rmsle: 0.00587 | train_mae: 0.228   | train_rmse: 0.29702 | train_mse: 0.08822 | valid_rmsle: 0.00603 | valid_mae: 0.23564 | valid_rmse: 0.30531 | valid_mse: 0.09321 |  0:01:03s\n",
      "epoch 44 | loss: 0.08648 | train_rmsle: 0.00569 | train_mae: 0.22766 | train_rmse: 0.29435 | train_mse: 0.08664 | valid_rmsle: 0.00585 | valid_mae: 0.23529 | valid_rmse: 0.30255 | valid_mse: 0.09154 |  0:01:05s\n",
      "epoch 45 | loss: 0.08725 | train_rmsle: 0.00616 | train_mae: 0.23054 | train_rmse: 0.3044  | train_mse: 0.09266 | valid_rmsle: 0.00653 | valid_mae: 0.24054 | valid_rmse: 0.3185  | valid_mse: 0.10144 |  0:01:06s\n",
      "epoch 46 | loss: 0.0856  | train_rmsle: 0.0053  | train_mae: 0.21751 | train_rmse: 0.28409 | train_mse: 0.08071 | valid_rmsle: 0.00576 | valid_mae: 0.23045 | valid_rmse: 0.30035 | valid_mse: 0.09021 |  0:01:07s\n",
      "epoch 47 | loss: 0.08516 | train_rmsle: 0.0055  | train_mae: 0.21678 | train_rmse: 0.28621 | train_mse: 0.08192 | valid_rmsle: 0.00594 | valid_mae: 0.22988 | valid_rmse: 0.30306 | valid_mse: 0.09185 |  0:01:09s\n",
      "epoch 48 | loss: 0.08496 | train_rmsle: 0.00524 | train_mae: 0.21954 | train_rmse: 0.28333 | train_mse: 0.08027 | valid_rmsle: 0.00586 | valid_mae: 0.23717 | valid_rmse: 0.30361 | valid_mse: 0.09218 |  0:01:10s\n",
      "epoch 49 | loss: 0.08211 | train_rmsle: 0.00572 | train_mae: 0.21677 | train_rmse: 0.28978 | train_mse: 0.08397 | valid_rmsle: 0.00627 | valid_mae: 0.23429 | valid_rmse: 0.30994 | valid_mse: 0.09606 |  0:01:12s\n",
      "epoch 50 | loss: 0.08089 | train_rmsle: 0.0051  | train_mae: 0.21931 | train_rmse: 0.28138 | train_mse: 0.07918 | valid_rmsle: 0.00595 | valid_mae: 0.24128 | valid_rmse: 0.30814 | valid_mse: 0.09495 |  0:01:13s\n",
      "epoch 51 | loss: 0.08061 | train_rmsle: 0.00514 | train_mae: 0.21491 | train_rmse: 0.27967 | train_mse: 0.07822 | valid_rmsle: 0.00596 | valid_mae: 0.23771 | valid_rmse: 0.30634 | valid_mse: 0.09384 |  0:01:15s\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_valid_mse = 0.08928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09537912148620106 RMSE: 0.3088351040380628 R2: 0.577793380527738 MAE: 0.2367579958957963\n",
      "=====================================\n",
      "[93/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.7386 | train_rmsle: 0.28231 | train_mae: 1.7428  | train_rmse: 1.80858 | train_mse: 3.27097 | valid_rmsle: 0.28398 | valid_mae: 1.74964 | valid_rmse: 1.81462 | valid_mse: 3.29283 |  0:00:01s\n",
      "epoch 1  | loss: 2.71642 | train_rmsle: 0.20833 | train_mae: 1.54158 | train_rmse: 1.61408 | train_mse: 2.60525 | valid_rmsle: 0.20932 | valid_mae: 1.54687 | valid_rmse: 1.61884 | valid_mse: 2.62064 |  0:00:02s\n",
      "epoch 2  | loss: 1.36361 | train_rmsle: 0.05895 | train_mae: 0.87171 | train_rmse: 0.96484 | train_mse: 0.93092 | valid_rmsle: 0.05916 | valid_mae: 0.87321 | valid_rmse: 0.96839 | valid_mse: 0.93778 |  0:00:04s\n",
      "epoch 3  | loss: 0.84464 | train_rmsle: 0.03162 | train_mae: 0.6381  | train_rmse: 0.73059 | train_mse: 0.53377 | valid_rmsle: 0.03152 | valid_mae: 0.63797 | valid_rmse: 0.7326  | valid_mse: 0.53671 |  0:00:05s\n",
      "epoch 4  | loss: 0.63036 | train_rmsle: 0.03901 | train_mae: 0.71045 | train_rmse: 0.80422 | train_mse: 0.64678 | valid_rmsle: 0.03905 | valid_mae: 0.71058 | valid_rmse: 0.80714 | valid_mse: 0.65147 |  0:00:07s\n",
      "epoch 5  | loss: 0.49678 | train_rmsle: 0.02801 | train_mae: 0.59865 | train_rmse: 0.69029 | train_mse: 0.4765  | valid_rmsle: 0.02785 | valid_mae: 0.59879 | valid_rmse: 0.69164 | valid_mse: 0.47837 |  0:00:08s\n",
      "epoch 6  | loss: 0.40612 | train_rmsle: 0.02428 | train_mae: 0.55357 | train_rmse: 0.64431 | train_mse: 0.41513 | valid_rmsle: 0.02395 | valid_mae: 0.55396 | valid_rmse: 0.64368 | valid_mse: 0.41432 |  0:00:10s\n",
      "epoch 7  | loss: 0.34433 | train_rmsle: 0.02392 | train_mae: 0.55022 | train_rmse: 0.63962 | train_mse: 0.40911 | valid_rmsle: 0.0237  | valid_mae: 0.55198 | valid_rmse: 0.64045 | valid_mse: 0.41017 |  0:00:11s\n",
      "epoch 8  | loss: 0.29488 | train_rmsle: 0.02379 | train_mae: 0.54823 | train_rmse: 0.63793 | train_mse: 0.40696 | valid_rmsle: 0.02349 | valid_mae: 0.54897 | valid_rmse: 0.63764 | valid_mse: 0.40659 |  0:00:13s\n",
      "epoch 9  | loss: 0.28519 | train_rmsle: 0.02077 | train_mae: 0.50773 | train_rmse: 0.59621 | train_mse: 0.35547 | valid_rmsle: 0.02032 | valid_mae: 0.50693 | valid_rmse: 0.59397 | valid_mse: 0.3528  |  0:00:14s\n",
      "epoch 10 | loss: 0.26769 | train_rmsle: 0.01973 | train_mae: 0.49494 | train_rmse: 0.58087 | train_mse: 0.33741 | valid_rmsle: 0.01922 | valid_mae: 0.49329 | valid_rmse: 0.57728 | valid_mse: 0.33325 |  0:00:16s\n",
      "epoch 11 | loss: 0.24829 | train_rmsle: 0.01596 | train_mae: 0.44343 | train_rmse: 0.51991 | train_mse: 0.27031 | valid_rmsle: 0.01513 | valid_mae: 0.43165 | valid_rmse: 0.50958 | valid_mse: 0.25967 |  0:00:17s\n",
      "epoch 12 | loss: 0.22488 | train_rmsle: 0.00981 | train_mae: 0.31663 | train_rmse: 0.39681 | train_mse: 0.15745 | valid_rmsle: 0.00924 | valid_mae: 0.30889 | valid_rmse: 0.38859 | valid_mse: 0.151   |  0:00:18s\n",
      "epoch 13 | loss: 0.19813 | train_rmsle: 0.01029 | train_mae: 0.33068 | train_rmse: 0.40602 | train_mse: 0.16485 | valid_rmsle: 0.0097  | valid_mae: 0.31997 | valid_rmse: 0.397   | valid_mse: 0.15761 |  0:00:20s\n",
      "epoch 14 | loss: 0.16338 | train_rmsle: 0.00859 | train_mae: 0.29302 | train_rmse: 0.36787 | train_mse: 0.13533 | valid_rmsle: 0.00785 | valid_mae: 0.28234 | valid_rmse: 0.35538 | valid_mse: 0.1263  |  0:00:21s\n",
      "epoch 15 | loss: 0.15376 | train_rmsle: 0.00828 | train_mae: 0.29224 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.00763 | valid_mae: 0.27965 | valid_rmse: 0.35196 | valid_mse: 0.12387 |  0:00:23s\n",
      "epoch 16 | loss: 0.14009 | train_rmsle: 0.00924 | train_mae: 0.31211 | train_rmse: 0.38429 | train_mse: 0.14768 | valid_rmsle: 0.00828 | valid_mae: 0.29401 | valid_rmse: 0.36611 | valid_mse: 0.13404 |  0:00:24s\n",
      "epoch 17 | loss: 0.13432 | train_rmsle: 0.01152 | train_mae: 0.3626  | train_rmse: 0.43512 | train_mse: 0.18933 | valid_rmsle: 0.01074 | valid_mae: 0.35197 | valid_rmse: 0.4238  | valid_mse: 0.1796  |  0:00:26s\n",
      "epoch 18 | loss: 0.13119 | train_rmsle: 0.00948 | train_mae: 0.32242 | train_rmse: 0.39158 | train_mse: 0.15333 | valid_rmsle: 0.00875 | valid_mae: 0.31139 | valid_rmse: 0.37993 | valid_mse: 0.14435 |  0:00:27s\n",
      "epoch 19 | loss: 0.12414 | train_rmsle: 0.01057 | train_mae: 0.33008 | train_rmse: 0.40694 | train_mse: 0.1656  | valid_rmsle: 0.00956 | valid_mae: 0.31476 | valid_rmse: 0.39053 | valid_mse: 0.15251 |  0:00:29s\n",
      "epoch 20 | loss: 0.13004 | train_rmsle: 0.00847 | train_mae: 0.29145 | train_rmse: 0.36472 | train_mse: 0.13302 | valid_rmsle: 0.00779 | valid_mae: 0.2801  | valid_rmse: 0.35231 | valid_mse: 0.12412 |  0:00:30s\n",
      "epoch 21 | loss: 0.11992 | train_rmsle: 0.00819 | train_mae: 0.28312 | train_rmse: 0.35775 | train_mse: 0.12798 | valid_rmsle: 0.00741 | valid_mae: 0.26879 | valid_rmse: 0.34281 | valid_mse: 0.11752 |  0:00:32s\n",
      "epoch 22 | loss: 0.12612 | train_rmsle: 0.0083  | train_mae: 0.29184 | train_rmse: 0.36265 | train_mse: 0.13152 | valid_rmsle: 0.00764 | valid_mae: 0.2771  | valid_rmse: 0.35062 | valid_mse: 0.12293 |  0:00:33s\n",
      "epoch 23 | loss: 0.11991 | train_rmsle: 0.00827 | train_mae: 0.29269 | train_rmse: 0.36243 | train_mse: 0.13135 | valid_rmsle: 0.00759 | valid_mae: 0.27967 | valid_rmse: 0.35017 | valid_mse: 0.12262 |  0:00:35s\n",
      "epoch 24 | loss: 0.11256 | train_rmsle: 0.00717 | train_mae: 0.26173 | train_rmse: 0.33355 | train_mse: 0.11125 | valid_rmsle: 0.00643 | valid_mae: 0.24812 | valid_rmse: 0.31904 | valid_mse: 0.10178 |  0:00:36s\n",
      "epoch 25 | loss: 0.11463 | train_rmsle: 0.00782 | train_mae: 0.2778  | train_rmse: 0.35013 | train_mse: 0.12259 | valid_rmsle: 0.0073  | valid_mae: 0.2673  | valid_rmse: 0.34081 | valid_mse: 0.11615 |  0:00:37s\n",
      "epoch 26 | loss: 0.10977 | train_rmsle: 0.00773 | train_mae: 0.27975 | train_rmse: 0.34967 | train_mse: 0.12227 | valid_rmsle: 0.00703 | valid_mae: 0.2656  | valid_rmse: 0.33673 | valid_mse: 0.11339 |  0:00:39s\n",
      "epoch 27 | loss: 0.1065  | train_rmsle: 0.00677 | train_mae: 0.24674 | train_rmse: 0.3217  | train_mse: 0.10349 | valid_rmsle: 0.00632 | valid_mae: 0.23994 | valid_rmse: 0.31434 | valid_mse: 0.09881 |  0:00:40s\n",
      "epoch 28 | loss: 0.10798 | train_rmsle: 0.00728 | train_mae: 0.26136 | train_rmse: 0.33526 | train_mse: 0.1124  | valid_rmsle: 0.00676 | valid_mae: 0.25305 | valid_rmse: 0.32682 | valid_mse: 0.10681 |  0:00:42s\n",
      "epoch 29 | loss: 0.10874 | train_rmsle: 0.00763 | train_mae: 0.27487 | train_rmse: 0.34631 | train_mse: 0.11993 | valid_rmsle: 0.007   | valid_mae: 0.26096 | valid_rmse: 0.33371 | valid_mse: 0.11136 |  0:00:43s\n",
      "epoch 30 | loss: 0.10967 | train_rmsle: 0.00722 | train_mae: 0.26601 | train_rmse: 0.33614 | train_mse: 0.11299 | valid_rmsle: 0.00674 | valid_mae: 0.25578 | valid_rmse: 0.32769 | valid_mse: 0.10738 |  0:00:45s\n",
      "epoch 31 | loss: 0.10385 | train_rmsle: 0.00667 | train_mae: 0.2435  | train_rmse: 0.31794 | train_mse: 0.10108 | valid_rmsle: 0.00625 | valid_mae: 0.23858 | valid_rmse: 0.31222 | valid_mse: 0.09748 |  0:00:46s\n",
      "epoch 32 | loss: 0.10566 | train_rmsle: 0.00683 | train_mae: 0.25457 | train_rmse: 0.32501 | train_mse: 0.10563 | valid_rmsle: 0.00629 | valid_mae: 0.24401 | valid_rmse: 0.3149  | valid_mse: 0.09916 |  0:00:48s\n",
      "epoch 33 | loss: 0.10605 | train_rmsle: 0.00658 | train_mae: 0.24432 | train_rmse: 0.31692 | train_mse: 0.10044 | valid_rmsle: 0.00619 | valid_mae: 0.23931 | valid_rmse: 0.31111 | valid_mse: 0.09679 |  0:00:49s\n",
      "epoch 34 | loss: 0.10545 | train_rmsle: 0.00659 | train_mae: 0.24411 | train_rmse: 0.31683 | train_mse: 0.10038 | valid_rmsle: 0.00642 | valid_mae: 0.24202 | valid_rmse: 0.3156  | valid_mse: 0.0996  |  0:00:50s\n",
      "epoch 35 | loss: 0.1022  | train_rmsle: 0.00689 | train_mae: 0.24384 | train_rmse: 0.32268 | train_mse: 0.10412 | valid_rmsle: 0.00676 | valid_mae: 0.24535 | valid_rmse: 0.32392 | valid_mse: 0.10493 |  0:00:52s\n",
      "epoch 36 | loss: 0.10305 | train_rmsle: 0.00679 | train_mae: 0.25422 | train_rmse: 0.32467 | train_mse: 0.10541 | valid_rmsle: 0.00646 | valid_mae: 0.25034 | valid_rmse: 0.3205  | valid_mse: 0.10272 |  0:00:53s\n",
      "epoch 37 | loss: 0.10115 | train_rmsle: 0.00661 | train_mae: 0.24683 | train_rmse: 0.31873 | train_mse: 0.10159 | valid_rmsle: 0.00633 | valid_mae: 0.24151 | valid_rmse: 0.31525 | valid_mse: 0.09938 |  0:00:55s\n",
      "epoch 38 | loss: 0.0991  | train_rmsle: 0.00673 | train_mae: 0.25226 | train_rmse: 0.32247 | train_mse: 0.10399 | valid_rmsle: 0.00644 | valid_mae: 0.24828 | valid_rmse: 0.31879 | valid_mse: 0.10162 |  0:00:56s\n",
      "epoch 39 | loss: 0.10052 | train_rmsle: 0.00668 | train_mae: 0.25225 | train_rmse: 0.32145 | train_mse: 0.10333 | valid_rmsle: 0.00651 | valid_mae: 0.25005 | valid_rmse: 0.32058 | valid_mse: 0.10277 |  0:00:58s\n",
      "epoch 40 | loss: 0.09948 | train_rmsle: 0.00666 | train_mae: 0.24945 | train_rmse: 0.32009 | train_mse: 0.10246 | valid_rmsle: 0.00653 | valid_mae: 0.24679 | valid_rmse: 0.31983 | valid_mse: 0.10229 |  0:00:59s\n",
      "epoch 41 | loss: 0.1001  | train_rmsle: 0.00644 | train_mae: 0.24046 | train_rmse: 0.3125  | train_mse: 0.09766 | valid_rmsle: 0.00624 | valid_mae: 0.23866 | valid_rmse: 0.31123 | valid_mse: 0.09686 |  0:01:01s\n",
      "epoch 42 | loss: 0.10045 | train_rmsle: 0.00837 | train_mae: 0.29679 | train_rmse: 0.36639 | train_mse: 0.13424 | valid_rmsle: 0.00801 | valid_mae: 0.29074 | valid_rmse: 0.36141 | valid_mse: 0.13061 |  0:01:02s\n",
      "epoch 43 | loss: 0.10067 | train_rmsle: 0.00662 | train_mae: 0.24913 | train_rmse: 0.32006 | train_mse: 0.10244 | valid_rmsle: 0.00656 | valid_mae: 0.24881 | valid_rmse: 0.32224 | valid_mse: 0.10384 |  0:01:03s\n",
      "epoch 44 | loss: 0.09838 | train_rmsle: 0.00745 | train_mae: 0.27355 | train_rmse: 0.34286 | train_mse: 0.11755 | valid_rmsle: 0.00746 | valid_mae: 0.27248 | valid_rmse: 0.34561 | valid_mse: 0.11945 |  0:01:05s\n",
      "epoch 45 | loss: 0.10002 | train_rmsle: 0.00637 | train_mae: 0.23972 | train_rmse: 0.31146 | train_mse: 0.09701 | valid_rmsle: 0.00626 | valid_mae: 0.23886 | valid_rmse: 0.31252 | valid_mse: 0.09767 |  0:01:06s\n",
      "epoch 46 | loss: 0.09835 | train_rmsle: 0.00637 | train_mae: 0.23861 | train_rmse: 0.31151 | train_mse: 0.09704 | valid_rmsle: 0.00622 | valid_mae: 0.23818 | valid_rmse: 0.31189 | valid_mse: 0.09727 |  0:01:08s\n",
      "epoch 47 | loss: 0.09992 | train_rmsle: 0.00638 | train_mae: 0.23901 | train_rmse: 0.31226 | train_mse: 0.09751 | valid_rmsle: 0.00631 | valid_mae: 0.23845 | valid_rmse: 0.3147  | valid_mse: 0.09904 |  0:01:09s\n",
      "epoch 48 | loss: 0.10017 | train_rmsle: 0.00633 | train_mae: 0.23879 | train_rmse: 0.3102  | train_mse: 0.09622 | valid_rmsle: 0.00618 | valid_mae: 0.23673 | valid_rmse: 0.31009 | valid_mse: 0.09615 |  0:01:11s\n",
      "epoch 49 | loss: 0.09939 | train_rmsle: 0.00623 | train_mae: 0.23328 | train_rmse: 0.30593 | train_mse: 0.09359 | valid_rmsle: 0.00635 | valid_mae: 0.23676 | valid_rmse: 0.31349 | valid_mse: 0.09828 |  0:01:12s\n",
      "epoch 50 | loss: 0.09872 | train_rmsle: 0.00658 | train_mae: 0.24756 | train_rmse: 0.31643 | train_mse: 0.10013 | valid_rmsle: 0.00619 | valid_mae: 0.2434  | valid_rmse: 0.31274 | valid_mse: 0.0978  |  0:01:14s\n",
      "epoch 51 | loss: 0.09719 | train_rmsle: 0.0065  | train_mae: 0.25005 | train_rmse: 0.3177  | train_mse: 0.10093 | valid_rmsle: 0.00631 | valid_mae: 0.24656 | valid_rmse: 0.316   | valid_mse: 0.09985 |  0:01:15s\n",
      "epoch 52 | loss: 0.09611 | train_rmsle: 0.00619 | train_mae: 0.23341 | train_rmse: 0.3053  | train_mse: 0.09321 | valid_rmsle: 0.00616 | valid_mae: 0.23491 | valid_rmse: 0.30877 | valid_mse: 0.09534 |  0:01:16s\n",
      "epoch 53 | loss: 0.09789 | train_rmsle: 0.00637 | train_mae: 0.2352  | train_rmse: 0.31063 | train_mse: 0.09649 | valid_rmsle: 0.00639 | valid_mae: 0.24093 | valid_rmse: 0.31398 | valid_mse: 0.09858 |  0:01:18s\n",
      "epoch 54 | loss: 0.09681 | train_rmsle: 0.00617 | train_mae: 0.23255 | train_rmse: 0.30455 | train_mse: 0.09275 | valid_rmsle: 0.00609 | valid_mae: 0.23441 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:01:19s\n",
      "epoch 55 | loss: 0.09573 | train_rmsle: 0.00612 | train_mae: 0.23135 | train_rmse: 0.30347 | train_mse: 0.09209 | valid_rmsle: 0.00611 | valid_mae: 0.23522 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:01:21s\n",
      "epoch 56 | loss: 0.0979  | train_rmsle: 0.00679 | train_mae: 0.26164 | train_rmse: 0.32768 | train_mse: 0.10738 | valid_rmsle: 0.00665 | valid_mae: 0.26113 | valid_rmse: 0.32823 | valid_mse: 0.10774 |  0:01:22s\n",
      "epoch 57 | loss: 0.0953  | train_rmsle: 0.00653 | train_mae: 0.23649 | train_rmse: 0.31342 | train_mse: 0.09823 | valid_rmsle: 0.00642 | valid_mae: 0.24196 | valid_rmse: 0.31589 | valid_mse: 0.09978 |  0:01:24s\n",
      "epoch 58 | loss: 0.09517 | train_rmsle: 0.00609 | train_mae: 0.23553 | train_rmse: 0.30432 | train_mse: 0.09261 | valid_rmsle: 0.00611 | valid_mae: 0.24091 | valid_rmse: 0.31021 | valid_mse: 0.09623 |  0:01:25s\n",
      "epoch 59 | loss: 0.09273 | train_rmsle: 0.00604 | train_mae: 0.2304  | train_rmse: 0.30136 | train_mse: 0.09082 | valid_rmsle: 0.00608 | valid_mae: 0.23416 | valid_rmse: 0.30772 | valid_mse: 0.09469 |  0:01:27s\n",
      "epoch 60 | loss: 0.09298 | train_rmsle: 0.006   | train_mae: 0.23158 | train_rmse: 0.30163 | train_mse: 0.09098 | valid_rmsle: 0.00608 | valid_mae: 0.23445 | valid_rmse: 0.30817 | valid_mse: 0.09497 |  0:01:28s\n",
      "epoch 61 | loss: 0.09806 | train_rmsle: 0.00656 | train_mae: 0.25689 | train_rmse: 0.3216  | train_mse: 0.10343 | valid_rmsle: 0.00651 | valid_mae: 0.25461 | valid_rmse: 0.32458 | valid_mse: 0.10536 |  0:01:29s\n",
      "epoch 62 | loss: 0.10154 | train_rmsle: 0.00594 | train_mae: 0.23179 | train_rmse: 0.30012 | train_mse: 0.09007 | valid_rmsle: 0.00607 | valid_mae: 0.23531 | valid_rmse: 0.3082  | valid_mse: 0.09499 |  0:01:31s\n",
      "epoch 63 | loss: 0.09234 | train_rmsle: 0.0059  | train_mae: 0.22876 | train_rmse: 0.29882 | train_mse: 0.08929 | valid_rmsle: 0.00614 | valid_mae: 0.23654 | valid_rmse: 0.30978 | valid_mse: 0.09596 |  0:01:32s\n",
      "epoch 64 | loss: 0.09125 | train_rmsle: 0.00594 | train_mae: 0.2301  | train_rmse: 0.30029 | train_mse: 0.09017 | valid_rmsle: 0.00633 | valid_mae: 0.23777 | valid_rmse: 0.31285 | valid_mse: 0.09788 |  0:01:34s\n",
      "epoch 65 | loss: 0.09271 | train_rmsle: 0.00586 | train_mae: 0.23078 | train_rmse: 0.29918 | train_mse: 0.08951 | valid_rmsle: 0.00636 | valid_mae: 0.24152 | valid_rmse: 0.31593 | valid_mse: 0.09981 |  0:01:35s\n",
      "epoch 66 | loss: 0.09234 | train_rmsle: 0.00599 | train_mae: 0.22971 | train_rmse: 0.30096 | train_mse: 0.09057 | valid_rmsle: 0.00639 | valid_mae: 0.23797 | valid_rmse: 0.31425 | valid_mse: 0.09875 |  0:01:37s\n",
      "epoch 67 | loss: 0.09561 | train_rmsle: 0.0059  | train_mae: 0.23216 | train_rmse: 0.3002  | train_mse: 0.09012 | valid_rmsle: 0.00616 | valid_mae: 0.23808 | valid_rmse: 0.3104  | valid_mse: 0.09635 |  0:01:38s\n",
      "epoch 68 | loss: 0.09338 | train_rmsle: 0.00583 | train_mae: 0.22844 | train_rmse: 0.29778 | train_mse: 0.08868 | valid_rmsle: 0.00614 | valid_mae: 0.23772 | valid_rmse: 0.30974 | valid_mse: 0.09594 |  0:01:39s\n",
      "epoch 69 | loss: 0.09092 | train_rmsle: 0.00586 | train_mae: 0.2278  | train_rmse: 0.29775 | train_mse: 0.08865 | valid_rmsle: 0.00608 | valid_mae: 0.23431 | valid_rmse: 0.30788 | valid_mse: 0.09479 |  0:01:41s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 54 and best_valid_mse = 0.09389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09379131865818442 RMSE: 0.30625368350141424 R2: 0.584821971837445 MAE: 0.23434699130270956\n",
      "=====================================\n",
      "[94/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.7386 | train_rmsle: 0.28231 | train_mae: 1.7428  | train_rmse: 1.80858 | train_mse: 3.27097 | valid_rmsle: 0.28398 | valid_mae: 1.74964 | valid_rmse: 1.81462 | valid_mse: 3.29283 |  0:00:01s\n",
      "epoch 1  | loss: 2.71642 | train_rmsle: 0.20833 | train_mae: 1.54158 | train_rmse: 1.61408 | train_mse: 2.60525 | valid_rmsle: 0.20932 | valid_mae: 1.54687 | valid_rmse: 1.61884 | valid_mse: 2.62064 |  0:00:02s\n",
      "epoch 2  | loss: 1.36361 | train_rmsle: 0.05895 | train_mae: 0.87171 | train_rmse: 0.96484 | train_mse: 0.93092 | valid_rmsle: 0.05916 | valid_mae: 0.87321 | valid_rmse: 0.96839 | valid_mse: 0.93778 |  0:00:04s\n",
      "epoch 3  | loss: 0.84464 | train_rmsle: 0.03162 | train_mae: 0.6381  | train_rmse: 0.73059 | train_mse: 0.53377 | valid_rmsle: 0.03152 | valid_mae: 0.63797 | valid_rmse: 0.7326  | valid_mse: 0.53671 |  0:00:05s\n",
      "epoch 4  | loss: 0.63036 | train_rmsle: 0.03901 | train_mae: 0.71045 | train_rmse: 0.80422 | train_mse: 0.64678 | valid_rmsle: 0.03905 | valid_mae: 0.71058 | valid_rmse: 0.80714 | valid_mse: 0.65147 |  0:00:07s\n",
      "epoch 5  | loss: 0.49678 | train_rmsle: 0.02801 | train_mae: 0.59865 | train_rmse: 0.69029 | train_mse: 0.4765  | valid_rmsle: 0.02785 | valid_mae: 0.59879 | valid_rmse: 0.69164 | valid_mse: 0.47837 |  0:00:08s\n",
      "epoch 6  | loss: 0.40612 | train_rmsle: 0.02428 | train_mae: 0.55357 | train_rmse: 0.64431 | train_mse: 0.41513 | valid_rmsle: 0.02395 | valid_mae: 0.55396 | valid_rmse: 0.64368 | valid_mse: 0.41432 |  0:00:10s\n",
      "epoch 7  | loss: 0.34433 | train_rmsle: 0.02392 | train_mae: 0.55022 | train_rmse: 0.63962 | train_mse: 0.40911 | valid_rmsle: 0.0237  | valid_mae: 0.55198 | valid_rmse: 0.64045 | valid_mse: 0.41017 |  0:00:11s\n",
      "epoch 8  | loss: 0.29488 | train_rmsle: 0.02379 | train_mae: 0.54823 | train_rmse: 0.63793 | train_mse: 0.40696 | valid_rmsle: 0.02349 | valid_mae: 0.54897 | valid_rmse: 0.63764 | valid_mse: 0.40659 |  0:00:13s\n",
      "epoch 9  | loss: 0.28519 | train_rmsle: 0.02077 | train_mae: 0.50773 | train_rmse: 0.59621 | train_mse: 0.35547 | valid_rmsle: 0.02032 | valid_mae: 0.50693 | valid_rmse: 0.59397 | valid_mse: 0.3528  |  0:00:14s\n",
      "epoch 10 | loss: 0.26769 | train_rmsle: 0.01973 | train_mae: 0.49494 | train_rmse: 0.58087 | train_mse: 0.33741 | valid_rmsle: 0.01922 | valid_mae: 0.49329 | valid_rmse: 0.57728 | valid_mse: 0.33325 |  0:00:16s\n",
      "epoch 11 | loss: 0.24829 | train_rmsle: 0.01596 | train_mae: 0.44343 | train_rmse: 0.51991 | train_mse: 0.27031 | valid_rmsle: 0.01513 | valid_mae: 0.43165 | valid_rmse: 0.50958 | valid_mse: 0.25967 |  0:00:17s\n",
      "epoch 12 | loss: 0.22488 | train_rmsle: 0.00981 | train_mae: 0.31663 | train_rmse: 0.39681 | train_mse: 0.15745 | valid_rmsle: 0.00924 | valid_mae: 0.30889 | valid_rmse: 0.38859 | valid_mse: 0.151   |  0:00:18s\n",
      "epoch 13 | loss: 0.19813 | train_rmsle: 0.01029 | train_mae: 0.33068 | train_rmse: 0.40602 | train_mse: 0.16485 | valid_rmsle: 0.0097  | valid_mae: 0.31997 | valid_rmse: 0.397   | valid_mse: 0.15761 |  0:00:20s\n",
      "epoch 14 | loss: 0.16338 | train_rmsle: 0.00859 | train_mae: 0.29302 | train_rmse: 0.36787 | train_mse: 0.13533 | valid_rmsle: 0.00785 | valid_mae: 0.28234 | valid_rmse: 0.35538 | valid_mse: 0.1263  |  0:00:21s\n",
      "epoch 15 | loss: 0.15376 | train_rmsle: 0.00828 | train_mae: 0.29224 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.00763 | valid_mae: 0.27965 | valid_rmse: 0.35196 | valid_mse: 0.12387 |  0:00:23s\n",
      "epoch 16 | loss: 0.14009 | train_rmsle: 0.00924 | train_mae: 0.31211 | train_rmse: 0.38429 | train_mse: 0.14768 | valid_rmsle: 0.00828 | valid_mae: 0.29401 | valid_rmse: 0.36611 | valid_mse: 0.13404 |  0:00:24s\n",
      "epoch 17 | loss: 0.13432 | train_rmsle: 0.01152 | train_mae: 0.3626  | train_rmse: 0.43512 | train_mse: 0.18933 | valid_rmsle: 0.01074 | valid_mae: 0.35197 | valid_rmse: 0.4238  | valid_mse: 0.1796  |  0:00:26s\n",
      "epoch 18 | loss: 0.13119 | train_rmsle: 0.00948 | train_mae: 0.32242 | train_rmse: 0.39158 | train_mse: 0.15333 | valid_rmsle: 0.00875 | valid_mae: 0.31139 | valid_rmse: 0.37993 | valid_mse: 0.14435 |  0:00:27s\n",
      "epoch 19 | loss: 0.12414 | train_rmsle: 0.01057 | train_mae: 0.33008 | train_rmse: 0.40694 | train_mse: 0.1656  | valid_rmsle: 0.00956 | valid_mae: 0.31476 | valid_rmse: 0.39053 | valid_mse: 0.15251 |  0:00:29s\n",
      "epoch 20 | loss: 0.13004 | train_rmsle: 0.00847 | train_mae: 0.29145 | train_rmse: 0.36472 | train_mse: 0.13302 | valid_rmsle: 0.00779 | valid_mae: 0.2801  | valid_rmse: 0.35231 | valid_mse: 0.12412 |  0:00:30s\n",
      "epoch 21 | loss: 0.11992 | train_rmsle: 0.00819 | train_mae: 0.28312 | train_rmse: 0.35775 | train_mse: 0.12798 | valid_rmsle: 0.00741 | valid_mae: 0.26879 | valid_rmse: 0.34281 | valid_mse: 0.11752 |  0:00:32s\n",
      "epoch 22 | loss: 0.12612 | train_rmsle: 0.0083  | train_mae: 0.29184 | train_rmse: 0.36265 | train_mse: 0.13152 | valid_rmsle: 0.00764 | valid_mae: 0.2771  | valid_rmse: 0.35062 | valid_mse: 0.12293 |  0:00:33s\n",
      "epoch 23 | loss: 0.11991 | train_rmsle: 0.00827 | train_mae: 0.29269 | train_rmse: 0.36243 | train_mse: 0.13135 | valid_rmsle: 0.00759 | valid_mae: 0.27967 | valid_rmse: 0.35017 | valid_mse: 0.12262 |  0:00:34s\n",
      "epoch 24 | loss: 0.11256 | train_rmsle: 0.00717 | train_mae: 0.26173 | train_rmse: 0.33355 | train_mse: 0.11125 | valid_rmsle: 0.00643 | valid_mae: 0.24812 | valid_rmse: 0.31904 | valid_mse: 0.10178 |  0:00:36s\n",
      "epoch 25 | loss: 0.11463 | train_rmsle: 0.00782 | train_mae: 0.2778  | train_rmse: 0.35013 | train_mse: 0.12259 | valid_rmsle: 0.0073  | valid_mae: 0.2673  | valid_rmse: 0.34081 | valid_mse: 0.11615 |  0:00:37s\n",
      "epoch 26 | loss: 0.10977 | train_rmsle: 0.00773 | train_mae: 0.27975 | train_rmse: 0.34967 | train_mse: 0.12227 | valid_rmsle: 0.00703 | valid_mae: 0.2656  | valid_rmse: 0.33673 | valid_mse: 0.11339 |  0:00:39s\n",
      "epoch 27 | loss: 0.1065  | train_rmsle: 0.00677 | train_mae: 0.24674 | train_rmse: 0.3217  | train_mse: 0.10349 | valid_rmsle: 0.00632 | valid_mae: 0.23994 | valid_rmse: 0.31434 | valid_mse: 0.09881 |  0:00:40s\n",
      "epoch 28 | loss: 0.10798 | train_rmsle: 0.00728 | train_mae: 0.26136 | train_rmse: 0.33526 | train_mse: 0.1124  | valid_rmsle: 0.00676 | valid_mae: 0.25305 | valid_rmse: 0.32682 | valid_mse: 0.10681 |  0:00:42s\n",
      "epoch 29 | loss: 0.10874 | train_rmsle: 0.00763 | train_mae: 0.27487 | train_rmse: 0.34631 | train_mse: 0.11993 | valid_rmsle: 0.007   | valid_mae: 0.26096 | valid_rmse: 0.33371 | valid_mse: 0.11136 |  0:00:43s\n",
      "epoch 30 | loss: 0.10967 | train_rmsle: 0.00722 | train_mae: 0.26601 | train_rmse: 0.33614 | train_mse: 0.11299 | valid_rmsle: 0.00674 | valid_mae: 0.25578 | valid_rmse: 0.32769 | valid_mse: 0.10738 |  0:00:45s\n",
      "epoch 31 | loss: 0.10385 | train_rmsle: 0.00667 | train_mae: 0.2435  | train_rmse: 0.31794 | train_mse: 0.10108 | valid_rmsle: 0.00625 | valid_mae: 0.23858 | valid_rmse: 0.31222 | valid_mse: 0.09748 |  0:00:46s\n",
      "epoch 32 | loss: 0.10566 | train_rmsle: 0.00683 | train_mae: 0.25457 | train_rmse: 0.32501 | train_mse: 0.10563 | valid_rmsle: 0.00629 | valid_mae: 0.24401 | valid_rmse: 0.3149  | valid_mse: 0.09916 |  0:00:47s\n",
      "epoch 33 | loss: 0.10605 | train_rmsle: 0.00658 | train_mae: 0.24432 | train_rmse: 0.31692 | train_mse: 0.10044 | valid_rmsle: 0.00619 | valid_mae: 0.23931 | valid_rmse: 0.31111 | valid_mse: 0.09679 |  0:00:49s\n",
      "epoch 34 | loss: 0.10545 | train_rmsle: 0.00659 | train_mae: 0.24411 | train_rmse: 0.31683 | train_mse: 0.10038 | valid_rmsle: 0.00642 | valid_mae: 0.24202 | valid_rmse: 0.3156  | valid_mse: 0.0996  |  0:00:50s\n",
      "epoch 35 | loss: 0.1022  | train_rmsle: 0.00689 | train_mae: 0.24384 | train_rmse: 0.32268 | train_mse: 0.10412 | valid_rmsle: 0.00676 | valid_mae: 0.24535 | valid_rmse: 0.32392 | valid_mse: 0.10493 |  0:00:52s\n",
      "epoch 36 | loss: 0.10305 | train_rmsle: 0.00679 | train_mae: 0.25422 | train_rmse: 0.32467 | train_mse: 0.10541 | valid_rmsle: 0.00646 | valid_mae: 0.25034 | valid_rmse: 0.3205  | valid_mse: 0.10272 |  0:00:53s\n",
      "epoch 37 | loss: 0.10115 | train_rmsle: 0.00661 | train_mae: 0.24683 | train_rmse: 0.31873 | train_mse: 0.10159 | valid_rmsle: 0.00633 | valid_mae: 0.24151 | valid_rmse: 0.31525 | valid_mse: 0.09938 |  0:00:55s\n",
      "epoch 38 | loss: 0.0991  | train_rmsle: 0.00673 | train_mae: 0.25226 | train_rmse: 0.32247 | train_mse: 0.10399 | valid_rmsle: 0.00644 | valid_mae: 0.24828 | valid_rmse: 0.31879 | valid_mse: 0.10162 |  0:00:56s\n",
      "epoch 39 | loss: 0.10052 | train_rmsle: 0.00668 | train_mae: 0.25225 | train_rmse: 0.32145 | train_mse: 0.10333 | valid_rmsle: 0.00651 | valid_mae: 0.25005 | valid_rmse: 0.32058 | valid_mse: 0.10277 |  0:00:58s\n",
      "epoch 40 | loss: 0.09948 | train_rmsle: 0.00666 | train_mae: 0.24945 | train_rmse: 0.32009 | train_mse: 0.10246 | valid_rmsle: 0.00653 | valid_mae: 0.24679 | valid_rmse: 0.31983 | valid_mse: 0.10229 |  0:00:59s\n",
      "epoch 41 | loss: 0.1001  | train_rmsle: 0.00644 | train_mae: 0.24046 | train_rmse: 0.3125  | train_mse: 0.09766 | valid_rmsle: 0.00624 | valid_mae: 0.23866 | valid_rmse: 0.31123 | valid_mse: 0.09686 |  0:01:00s\n",
      "epoch 42 | loss: 0.10045 | train_rmsle: 0.00837 | train_mae: 0.29679 | train_rmse: 0.36639 | train_mse: 0.13424 | valid_rmsle: 0.00801 | valid_mae: 0.29074 | valid_rmse: 0.36141 | valid_mse: 0.13061 |  0:01:02s\n",
      "epoch 43 | loss: 0.10067 | train_rmsle: 0.00662 | train_mae: 0.24913 | train_rmse: 0.32006 | train_mse: 0.10244 | valid_rmsle: 0.00656 | valid_mae: 0.24881 | valid_rmse: 0.32224 | valid_mse: 0.10384 |  0:01:03s\n",
      "epoch 44 | loss: 0.09838 | train_rmsle: 0.00745 | train_mae: 0.27355 | train_rmse: 0.34286 | train_mse: 0.11755 | valid_rmsle: 0.00746 | valid_mae: 0.27248 | valid_rmse: 0.34561 | valid_mse: 0.11945 |  0:01:05s\n",
      "epoch 45 | loss: 0.10002 | train_rmsle: 0.00637 | train_mae: 0.23972 | train_rmse: 0.31146 | train_mse: 0.09701 | valid_rmsle: 0.00626 | valid_mae: 0.23886 | valid_rmse: 0.31252 | valid_mse: 0.09767 |  0:01:06s\n",
      "epoch 46 | loss: 0.09835 | train_rmsle: 0.00637 | train_mae: 0.23861 | train_rmse: 0.31151 | train_mse: 0.09704 | valid_rmsle: 0.00622 | valid_mae: 0.23818 | valid_rmse: 0.31189 | valid_mse: 0.09727 |  0:01:08s\n",
      "epoch 47 | loss: 0.09992 | train_rmsle: 0.00638 | train_mae: 0.23901 | train_rmse: 0.31226 | train_mse: 0.09751 | valid_rmsle: 0.00631 | valid_mae: 0.23845 | valid_rmse: 0.3147  | valid_mse: 0.09904 |  0:01:09s\n",
      "epoch 48 | loss: 0.10017 | train_rmsle: 0.00633 | train_mae: 0.23879 | train_rmse: 0.3102  | train_mse: 0.09622 | valid_rmsle: 0.00618 | valid_mae: 0.23673 | valid_rmse: 0.31009 | valid_mse: 0.09615 |  0:01:11s\n",
      "epoch 49 | loss: 0.09939 | train_rmsle: 0.00623 | train_mae: 0.23328 | train_rmse: 0.30593 | train_mse: 0.09359 | valid_rmsle: 0.00635 | valid_mae: 0.23676 | valid_rmse: 0.31349 | valid_mse: 0.09828 |  0:01:12s\n",
      "epoch 50 | loss: 0.09872 | train_rmsle: 0.00658 | train_mae: 0.24756 | train_rmse: 0.31643 | train_mse: 0.10013 | valid_rmsle: 0.00619 | valid_mae: 0.2434  | valid_rmse: 0.31274 | valid_mse: 0.0978  |  0:01:13s\n",
      "epoch 51 | loss: 0.09719 | train_rmsle: 0.0065  | train_mae: 0.25005 | train_rmse: 0.3177  | train_mse: 0.10093 | valid_rmsle: 0.00631 | valid_mae: 0.24656 | valid_rmse: 0.316   | valid_mse: 0.09985 |  0:01:15s\n",
      "epoch 52 | loss: 0.09611 | train_rmsle: 0.00619 | train_mae: 0.23341 | train_rmse: 0.3053  | train_mse: 0.09321 | valid_rmsle: 0.00616 | valid_mae: 0.23491 | valid_rmse: 0.30877 | valid_mse: 0.09534 |  0:01:16s\n",
      "epoch 53 | loss: 0.09789 | train_rmsle: 0.00637 | train_mae: 0.2352  | train_rmse: 0.31063 | train_mse: 0.09649 | valid_rmsle: 0.00639 | valid_mae: 0.24093 | valid_rmse: 0.31398 | valid_mse: 0.09858 |  0:01:18s\n",
      "epoch 54 | loss: 0.09681 | train_rmsle: 0.00617 | train_mae: 0.23255 | train_rmse: 0.30455 | train_mse: 0.09275 | valid_rmsle: 0.00609 | valid_mae: 0.23441 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:01:19s\n",
      "epoch 55 | loss: 0.09573 | train_rmsle: 0.00612 | train_mae: 0.23135 | train_rmse: 0.30347 | train_mse: 0.09209 | valid_rmsle: 0.00611 | valid_mae: 0.23522 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:01:21s\n",
      "epoch 56 | loss: 0.0979  | train_rmsle: 0.00679 | train_mae: 0.26164 | train_rmse: 0.32768 | train_mse: 0.10738 | valid_rmsle: 0.00665 | valid_mae: 0.26113 | valid_rmse: 0.32823 | valid_mse: 0.10774 |  0:01:22s\n",
      "epoch 57 | loss: 0.0953  | train_rmsle: 0.00653 | train_mae: 0.23649 | train_rmse: 0.31342 | train_mse: 0.09823 | valid_rmsle: 0.00642 | valid_mae: 0.24196 | valid_rmse: 0.31589 | valid_mse: 0.09978 |  0:01:24s\n",
      "epoch 58 | loss: 0.09517 | train_rmsle: 0.00609 | train_mae: 0.23553 | train_rmse: 0.30432 | train_mse: 0.09261 | valid_rmsle: 0.00611 | valid_mae: 0.24091 | valid_rmse: 0.31021 | valid_mse: 0.09623 |  0:01:25s\n",
      "epoch 59 | loss: 0.09273 | train_rmsle: 0.00604 | train_mae: 0.2304  | train_rmse: 0.30136 | train_mse: 0.09082 | valid_rmsle: 0.00608 | valid_mae: 0.23416 | valid_rmse: 0.30772 | valid_mse: 0.09469 |  0:01:27s\n",
      "epoch 60 | loss: 0.09298 | train_rmsle: 0.006   | train_mae: 0.23158 | train_rmse: 0.30163 | train_mse: 0.09098 | valid_rmsle: 0.00608 | valid_mae: 0.23445 | valid_rmse: 0.30817 | valid_mse: 0.09497 |  0:01:28s\n",
      "epoch 61 | loss: 0.09806 | train_rmsle: 0.00656 | train_mae: 0.25689 | train_rmse: 0.3216  | train_mse: 0.10343 | valid_rmsle: 0.00651 | valid_mae: 0.25461 | valid_rmse: 0.32458 | valid_mse: 0.10536 |  0:01:29s\n",
      "epoch 62 | loss: 0.10154 | train_rmsle: 0.00594 | train_mae: 0.23179 | train_rmse: 0.30012 | train_mse: 0.09007 | valid_rmsle: 0.00607 | valid_mae: 0.23531 | valid_rmse: 0.3082  | valid_mse: 0.09499 |  0:01:31s\n",
      "epoch 63 | loss: 0.09234 | train_rmsle: 0.0059  | train_mae: 0.22876 | train_rmse: 0.29882 | train_mse: 0.08929 | valid_rmsle: 0.00614 | valid_mae: 0.23654 | valid_rmse: 0.30978 | valid_mse: 0.09596 |  0:01:32s\n",
      "epoch 64 | loss: 0.09125 | train_rmsle: 0.00594 | train_mae: 0.2301  | train_rmse: 0.30029 | train_mse: 0.09017 | valid_rmsle: 0.00633 | valid_mae: 0.23777 | valid_rmse: 0.31285 | valid_mse: 0.09788 |  0:01:34s\n",
      "epoch 65 | loss: 0.09271 | train_rmsle: 0.00586 | train_mae: 0.23078 | train_rmse: 0.29918 | train_mse: 0.08951 | valid_rmsle: 0.00636 | valid_mae: 0.24152 | valid_rmse: 0.31593 | valid_mse: 0.09981 |  0:01:35s\n",
      "epoch 66 | loss: 0.09234 | train_rmsle: 0.00599 | train_mae: 0.22971 | train_rmse: 0.30096 | train_mse: 0.09057 | valid_rmsle: 0.00639 | valid_mae: 0.23797 | valid_rmse: 0.31425 | valid_mse: 0.09875 |  0:01:37s\n",
      "epoch 67 | loss: 0.09561 | train_rmsle: 0.0059  | train_mae: 0.23216 | train_rmse: 0.3002  | train_mse: 0.09012 | valid_rmsle: 0.00616 | valid_mae: 0.23808 | valid_rmse: 0.3104  | valid_mse: 0.09635 |  0:01:38s\n",
      "epoch 68 | loss: 0.09338 | train_rmsle: 0.00583 | train_mae: 0.22844 | train_rmse: 0.29778 | train_mse: 0.08868 | valid_rmsle: 0.00614 | valid_mae: 0.23772 | valid_rmse: 0.30974 | valid_mse: 0.09594 |  0:01:39s\n",
      "epoch 69 | loss: 0.09092 | train_rmsle: 0.00586 | train_mae: 0.2278  | train_rmse: 0.29775 | train_mse: 0.08865 | valid_rmsle: 0.00608 | valid_mae: 0.23431 | valid_rmse: 0.30788 | valid_mse: 0.09479 |  0:01:41s\n",
      "epoch 70 | loss: 0.0952  | train_rmsle: 0.00601 | train_mae: 0.22901 | train_rmse: 0.30103 | train_mse: 0.09062 | valid_rmsle: 0.00623 | valid_mae: 0.23834 | valid_rmse: 0.31122 | valid_mse: 0.09686 |  0:01:42s\n",
      "epoch 71 | loss: 0.09596 | train_rmsle: 0.00632 | train_mae: 0.25133 | train_rmse: 0.31631 | train_mse: 0.10005 | valid_rmsle: 0.00635 | valid_mae: 0.25517 | valid_rmse: 0.32124 | valid_mse: 0.10319 |  0:01:44s\n",
      "epoch 72 | loss: 0.09306 | train_rmsle: 0.00585 | train_mae: 0.2287  | train_rmse: 0.29872 | train_mse: 0.08924 | valid_rmsle: 0.00603 | valid_mae: 0.23471 | valid_rmse: 0.30757 | valid_mse: 0.0946  |  0:01:45s\n",
      "epoch 73 | loss: 0.09217 | train_rmsle: 0.00628 | train_mae: 0.2468  | train_rmse: 0.31324 | train_mse: 0.09812 | valid_rmsle: 0.00621 | valid_mae: 0.24834 | valid_rmse: 0.31567 | valid_mse: 0.09965 |  0:01:47s\n",
      "epoch 74 | loss: 0.09478 | train_rmsle: 0.00592 | train_mae: 0.22596 | train_rmse: 0.2981  | train_mse: 0.08886 | valid_rmsle: 0.0061  | valid_mae: 0.2348  | valid_rmse: 0.30759 | valid_mse: 0.09461 |  0:01:48s\n",
      "\n",
      "Early stopping occurred at epoch 74 with best_epoch = 54 and best_valid_mse = 0.09389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09379131865818442 RMSE: 0.30625368350141424 R2: 0.584821971837445 MAE: 0.23434699130270956\n",
      "=====================================\n",
      "[95/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.7386 | train_rmsle: 0.28231 | train_mae: 1.7428  | train_rmse: 1.80858 | train_mse: 3.27097 | valid_rmsle: 0.28398 | valid_mae: 1.74964 | valid_rmse: 1.81462 | valid_mse: 3.29283 |  0:00:01s\n",
      "epoch 1  | loss: 2.71642 | train_rmsle: 0.20833 | train_mae: 1.54158 | train_rmse: 1.61408 | train_mse: 2.60525 | valid_rmsle: 0.20932 | valid_mae: 1.54687 | valid_rmse: 1.61884 | valid_mse: 2.62064 |  0:00:03s\n",
      "epoch 2  | loss: 1.36361 | train_rmsle: 0.05895 | train_mae: 0.87171 | train_rmse: 0.96484 | train_mse: 0.93092 | valid_rmsle: 0.05916 | valid_mae: 0.87321 | valid_rmse: 0.96839 | valid_mse: 0.93778 |  0:00:04s\n",
      "epoch 3  | loss: 0.84464 | train_rmsle: 0.03162 | train_mae: 0.6381  | train_rmse: 0.73059 | train_mse: 0.53377 | valid_rmsle: 0.03152 | valid_mae: 0.63797 | valid_rmse: 0.7326  | valid_mse: 0.53671 |  0:00:05s\n",
      "epoch 4  | loss: 0.63036 | train_rmsle: 0.03901 | train_mae: 0.71045 | train_rmse: 0.80422 | train_mse: 0.64678 | valid_rmsle: 0.03905 | valid_mae: 0.71058 | valid_rmse: 0.80714 | valid_mse: 0.65147 |  0:00:07s\n",
      "epoch 5  | loss: 0.49678 | train_rmsle: 0.02801 | train_mae: 0.59865 | train_rmse: 0.69029 | train_mse: 0.4765  | valid_rmsle: 0.02785 | valid_mae: 0.59879 | valid_rmse: 0.69164 | valid_mse: 0.47837 |  0:00:09s\n",
      "epoch 6  | loss: 0.40612 | train_rmsle: 0.02428 | train_mae: 0.55357 | train_rmse: 0.64431 | train_mse: 0.41513 | valid_rmsle: 0.02395 | valid_mae: 0.55396 | valid_rmse: 0.64368 | valid_mse: 0.41432 |  0:00:10s\n",
      "epoch 7  | loss: 0.34433 | train_rmsle: 0.02392 | train_mae: 0.55022 | train_rmse: 0.63962 | train_mse: 0.40911 | valid_rmsle: 0.0237  | valid_mae: 0.55198 | valid_rmse: 0.64045 | valid_mse: 0.41017 |  0:00:12s\n",
      "epoch 8  | loss: 0.29488 | train_rmsle: 0.02379 | train_mae: 0.54823 | train_rmse: 0.63793 | train_mse: 0.40696 | valid_rmsle: 0.02349 | valid_mae: 0.54897 | valid_rmse: 0.63764 | valid_mse: 0.40659 |  0:00:13s\n",
      "epoch 9  | loss: 0.28519 | train_rmsle: 0.02077 | train_mae: 0.50773 | train_rmse: 0.59621 | train_mse: 0.35547 | valid_rmsle: 0.02032 | valid_mae: 0.50693 | valid_rmse: 0.59397 | valid_mse: 0.3528  |  0:00:14s\n",
      "epoch 10 | loss: 0.26769 | train_rmsle: 0.01973 | train_mae: 0.49494 | train_rmse: 0.58087 | train_mse: 0.33741 | valid_rmsle: 0.01922 | valid_mae: 0.49329 | valid_rmse: 0.57728 | valid_mse: 0.33325 |  0:00:16s\n",
      "epoch 11 | loss: 0.24829 | train_rmsle: 0.01596 | train_mae: 0.44343 | train_rmse: 0.51991 | train_mse: 0.27031 | valid_rmsle: 0.01513 | valid_mae: 0.43165 | valid_rmse: 0.50958 | valid_mse: 0.25967 |  0:00:17s\n",
      "epoch 12 | loss: 0.22488 | train_rmsle: 0.00981 | train_mae: 0.31663 | train_rmse: 0.39681 | train_mse: 0.15745 | valid_rmsle: 0.00924 | valid_mae: 0.30889 | valid_rmse: 0.38859 | valid_mse: 0.151   |  0:00:19s\n",
      "epoch 13 | loss: 0.19813 | train_rmsle: 0.01029 | train_mae: 0.33068 | train_rmse: 0.40602 | train_mse: 0.16485 | valid_rmsle: 0.0097  | valid_mae: 0.31997 | valid_rmse: 0.397   | valid_mse: 0.15761 |  0:00:20s\n",
      "epoch 14 | loss: 0.16338 | train_rmsle: 0.00859 | train_mae: 0.29302 | train_rmse: 0.36787 | train_mse: 0.13533 | valid_rmsle: 0.00785 | valid_mae: 0.28234 | valid_rmse: 0.35538 | valid_mse: 0.1263  |  0:00:22s\n",
      "epoch 15 | loss: 0.15376 | train_rmsle: 0.00828 | train_mae: 0.29224 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.00763 | valid_mae: 0.27965 | valid_rmse: 0.35196 | valid_mse: 0.12387 |  0:00:23s\n",
      "epoch 16 | loss: 0.14009 | train_rmsle: 0.00924 | train_mae: 0.31211 | train_rmse: 0.38429 | train_mse: 0.14768 | valid_rmsle: 0.00828 | valid_mae: 0.29401 | valid_rmse: 0.36611 | valid_mse: 0.13404 |  0:00:25s\n",
      "epoch 17 | loss: 0.13432 | train_rmsle: 0.01152 | train_mae: 0.3626  | train_rmse: 0.43512 | train_mse: 0.18933 | valid_rmsle: 0.01074 | valid_mae: 0.35197 | valid_rmse: 0.4238  | valid_mse: 0.1796  |  0:00:26s\n",
      "epoch 18 | loss: 0.13119 | train_rmsle: 0.00948 | train_mae: 0.32242 | train_rmse: 0.39158 | train_mse: 0.15333 | valid_rmsle: 0.00875 | valid_mae: 0.31139 | valid_rmse: 0.37993 | valid_mse: 0.14435 |  0:00:28s\n",
      "epoch 19 | loss: 0.12414 | train_rmsle: 0.01057 | train_mae: 0.33008 | train_rmse: 0.40694 | train_mse: 0.1656  | valid_rmsle: 0.00956 | valid_mae: 0.31476 | valid_rmse: 0.39053 | valid_mse: 0.15251 |  0:00:29s\n",
      "epoch 20 | loss: 0.13004 | train_rmsle: 0.00847 | train_mae: 0.29145 | train_rmse: 0.36472 | train_mse: 0.13302 | valid_rmsle: 0.00779 | valid_mae: 0.2801  | valid_rmse: 0.35231 | valid_mse: 0.12412 |  0:00:30s\n",
      "epoch 21 | loss: 0.11992 | train_rmsle: 0.00819 | train_mae: 0.28312 | train_rmse: 0.35775 | train_mse: 0.12798 | valid_rmsle: 0.00741 | valid_mae: 0.26879 | valid_rmse: 0.34281 | valid_mse: 0.11752 |  0:00:32s\n",
      "epoch 22 | loss: 0.12612 | train_rmsle: 0.0083  | train_mae: 0.29184 | train_rmse: 0.36265 | train_mse: 0.13152 | valid_rmsle: 0.00764 | valid_mae: 0.2771  | valid_rmse: 0.35062 | valid_mse: 0.12293 |  0:00:33s\n",
      "epoch 23 | loss: 0.11991 | train_rmsle: 0.00827 | train_mae: 0.29269 | train_rmse: 0.36243 | train_mse: 0.13135 | valid_rmsle: 0.00759 | valid_mae: 0.27967 | valid_rmse: 0.35017 | valid_mse: 0.12262 |  0:00:35s\n",
      "epoch 24 | loss: 0.11256 | train_rmsle: 0.00717 | train_mae: 0.26173 | train_rmse: 0.33355 | train_mse: 0.11125 | valid_rmsle: 0.00643 | valid_mae: 0.24812 | valid_rmse: 0.31904 | valid_mse: 0.10178 |  0:00:36s\n",
      "epoch 25 | loss: 0.11463 | train_rmsle: 0.00782 | train_mae: 0.2778  | train_rmse: 0.35013 | train_mse: 0.12259 | valid_rmsle: 0.0073  | valid_mae: 0.2673  | valid_rmse: 0.34081 | valid_mse: 0.11615 |  0:00:38s\n",
      "epoch 26 | loss: 0.10977 | train_rmsle: 0.00773 | train_mae: 0.27975 | train_rmse: 0.34967 | train_mse: 0.12227 | valid_rmsle: 0.00703 | valid_mae: 0.2656  | valid_rmse: 0.33673 | valid_mse: 0.11339 |  0:00:39s\n",
      "epoch 27 | loss: 0.1065  | train_rmsle: 0.00677 | train_mae: 0.24674 | train_rmse: 0.3217  | train_mse: 0.10349 | valid_rmsle: 0.00632 | valid_mae: 0.23994 | valid_rmse: 0.31434 | valid_mse: 0.09881 |  0:00:41s\n",
      "epoch 28 | loss: 0.10798 | train_rmsle: 0.00728 | train_mae: 0.26136 | train_rmse: 0.33526 | train_mse: 0.1124  | valid_rmsle: 0.00676 | valid_mae: 0.25305 | valid_rmse: 0.32682 | valid_mse: 0.10681 |  0:00:42s\n",
      "epoch 29 | loss: 0.10874 | train_rmsle: 0.00763 | train_mae: 0.27487 | train_rmse: 0.34631 | train_mse: 0.11993 | valid_rmsle: 0.007   | valid_mae: 0.26096 | valid_rmse: 0.33371 | valid_mse: 0.11136 |  0:00:43s\n",
      "epoch 30 | loss: 0.10967 | train_rmsle: 0.00722 | train_mae: 0.26601 | train_rmse: 0.33614 | train_mse: 0.11299 | valid_rmsle: 0.00674 | valid_mae: 0.25578 | valid_rmse: 0.32769 | valid_mse: 0.10738 |  0:00:45s\n",
      "epoch 31 | loss: 0.10385 | train_rmsle: 0.00667 | train_mae: 0.2435  | train_rmse: 0.31794 | train_mse: 0.10108 | valid_rmsle: 0.00625 | valid_mae: 0.23858 | valid_rmse: 0.31222 | valid_mse: 0.09748 |  0:00:46s\n",
      "epoch 32 | loss: 0.10566 | train_rmsle: 0.00683 | train_mae: 0.25457 | train_rmse: 0.32501 | train_mse: 0.10563 | valid_rmsle: 0.00629 | valid_mae: 0.24401 | valid_rmse: 0.3149  | valid_mse: 0.09916 |  0:00:48s\n",
      "epoch 33 | loss: 0.10605 | train_rmsle: 0.00658 | train_mae: 0.24432 | train_rmse: 0.31692 | train_mse: 0.10044 | valid_rmsle: 0.00619 | valid_mae: 0.23931 | valid_rmse: 0.31111 | valid_mse: 0.09679 |  0:00:49s\n",
      "epoch 34 | loss: 0.10545 | train_rmsle: 0.00659 | train_mae: 0.24411 | train_rmse: 0.31683 | train_mse: 0.10038 | valid_rmsle: 0.00642 | valid_mae: 0.24202 | valid_rmse: 0.3156  | valid_mse: 0.0996  |  0:00:51s\n",
      "epoch 35 | loss: 0.1022  | train_rmsle: 0.00689 | train_mae: 0.24384 | train_rmse: 0.32268 | train_mse: 0.10412 | valid_rmsle: 0.00676 | valid_mae: 0.24535 | valid_rmse: 0.32392 | valid_mse: 0.10493 |  0:00:52s\n",
      "epoch 36 | loss: 0.10305 | train_rmsle: 0.00679 | train_mae: 0.25422 | train_rmse: 0.32467 | train_mse: 0.10541 | valid_rmsle: 0.00646 | valid_mae: 0.25034 | valid_rmse: 0.3205  | valid_mse: 0.10272 |  0:00:54s\n",
      "epoch 37 | loss: 0.10115 | train_rmsle: 0.00661 | train_mae: 0.24683 | train_rmse: 0.31873 | train_mse: 0.10159 | valid_rmsle: 0.00633 | valid_mae: 0.24151 | valid_rmse: 0.31525 | valid_mse: 0.09938 |  0:00:55s\n",
      "epoch 38 | loss: 0.0991  | train_rmsle: 0.00673 | train_mae: 0.25226 | train_rmse: 0.32247 | train_mse: 0.10399 | valid_rmsle: 0.00644 | valid_mae: 0.24828 | valid_rmse: 0.31879 | valid_mse: 0.10162 |  0:00:56s\n",
      "epoch 39 | loss: 0.10052 | train_rmsle: 0.00668 | train_mae: 0.25225 | train_rmse: 0.32145 | train_mse: 0.10333 | valid_rmsle: 0.00651 | valid_mae: 0.25005 | valid_rmse: 0.32058 | valid_mse: 0.10277 |  0:00:58s\n",
      "epoch 40 | loss: 0.09948 | train_rmsle: 0.00666 | train_mae: 0.24945 | train_rmse: 0.32009 | train_mse: 0.10246 | valid_rmsle: 0.00653 | valid_mae: 0.24679 | valid_rmse: 0.31983 | valid_mse: 0.10229 |  0:00:59s\n",
      "epoch 41 | loss: 0.1001  | train_rmsle: 0.00644 | train_mae: 0.24046 | train_rmse: 0.3125  | train_mse: 0.09766 | valid_rmsle: 0.00624 | valid_mae: 0.23866 | valid_rmse: 0.31123 | valid_mse: 0.09686 |  0:01:01s\n",
      "epoch 42 | loss: 0.10045 | train_rmsle: 0.00837 | train_mae: 0.29679 | train_rmse: 0.36639 | train_mse: 0.13424 | valid_rmsle: 0.00801 | valid_mae: 0.29074 | valid_rmse: 0.36141 | valid_mse: 0.13061 |  0:01:02s\n",
      "epoch 43 | loss: 0.10067 | train_rmsle: 0.00662 | train_mae: 0.24913 | train_rmse: 0.32006 | train_mse: 0.10244 | valid_rmsle: 0.00656 | valid_mae: 0.24881 | valid_rmse: 0.32224 | valid_mse: 0.10384 |  0:01:04s\n",
      "epoch 44 | loss: 0.09838 | train_rmsle: 0.00745 | train_mae: 0.27355 | train_rmse: 0.34286 | train_mse: 0.11755 | valid_rmsle: 0.00746 | valid_mae: 0.27248 | valid_rmse: 0.34561 | valid_mse: 0.11945 |  0:01:05s\n",
      "epoch 45 | loss: 0.10002 | train_rmsle: 0.00637 | train_mae: 0.23972 | train_rmse: 0.31146 | train_mse: 0.09701 | valid_rmsle: 0.00626 | valid_mae: 0.23886 | valid_rmse: 0.31252 | valid_mse: 0.09767 |  0:01:07s\n",
      "epoch 46 | loss: 0.09835 | train_rmsle: 0.00637 | train_mae: 0.23861 | train_rmse: 0.31151 | train_mse: 0.09704 | valid_rmsle: 0.00622 | valid_mae: 0.23818 | valid_rmse: 0.31189 | valid_mse: 0.09727 |  0:01:08s\n",
      "epoch 47 | loss: 0.09992 | train_rmsle: 0.00638 | train_mae: 0.23901 | train_rmse: 0.31226 | train_mse: 0.09751 | valid_rmsle: 0.00631 | valid_mae: 0.23845 | valid_rmse: 0.3147  | valid_mse: 0.09904 |  0:01:09s\n",
      "epoch 48 | loss: 0.10017 | train_rmsle: 0.00633 | train_mae: 0.23879 | train_rmse: 0.3102  | train_mse: 0.09622 | valid_rmsle: 0.00618 | valid_mae: 0.23673 | valid_rmse: 0.31009 | valid_mse: 0.09615 |  0:01:11s\n",
      "epoch 49 | loss: 0.09939 | train_rmsle: 0.00623 | train_mae: 0.23328 | train_rmse: 0.30593 | train_mse: 0.09359 | valid_rmsle: 0.00635 | valid_mae: 0.23676 | valid_rmse: 0.31349 | valid_mse: 0.09828 |  0:01:12s\n",
      "epoch 50 | loss: 0.09872 | train_rmsle: 0.00658 | train_mae: 0.24756 | train_rmse: 0.31643 | train_mse: 0.10013 | valid_rmsle: 0.00619 | valid_mae: 0.2434  | valid_rmse: 0.31274 | valid_mse: 0.0978  |  0:01:14s\n",
      "epoch 51 | loss: 0.09719 | train_rmsle: 0.0065  | train_mae: 0.25005 | train_rmse: 0.3177  | train_mse: 0.10093 | valid_rmsle: 0.00631 | valid_mae: 0.24656 | valid_rmse: 0.316   | valid_mse: 0.09985 |  0:01:15s\n",
      "epoch 52 | loss: 0.09611 | train_rmsle: 0.00619 | train_mae: 0.23341 | train_rmse: 0.3053  | train_mse: 0.09321 | valid_rmsle: 0.00616 | valid_mae: 0.23491 | valid_rmse: 0.30877 | valid_mse: 0.09534 |  0:01:17s\n",
      "epoch 53 | loss: 0.09789 | train_rmsle: 0.00637 | train_mae: 0.2352  | train_rmse: 0.31063 | train_mse: 0.09649 | valid_rmsle: 0.00639 | valid_mae: 0.24093 | valid_rmse: 0.31398 | valid_mse: 0.09858 |  0:01:18s\n",
      "epoch 54 | loss: 0.09681 | train_rmsle: 0.00617 | train_mae: 0.23255 | train_rmse: 0.30455 | train_mse: 0.09275 | valid_rmsle: 0.00609 | valid_mae: 0.23441 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:01:20s\n",
      "epoch 55 | loss: 0.09573 | train_rmsle: 0.00612 | train_mae: 0.23135 | train_rmse: 0.30347 | train_mse: 0.09209 | valid_rmsle: 0.00611 | valid_mae: 0.23522 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:01:21s\n",
      "epoch 56 | loss: 0.0979  | train_rmsle: 0.00679 | train_mae: 0.26164 | train_rmse: 0.32768 | train_mse: 0.10738 | valid_rmsle: 0.00665 | valid_mae: 0.26113 | valid_rmse: 0.32823 | valid_mse: 0.10774 |  0:01:22s\n",
      "epoch 57 | loss: 0.0953  | train_rmsle: 0.00653 | train_mae: 0.23649 | train_rmse: 0.31342 | train_mse: 0.09823 | valid_rmsle: 0.00642 | valid_mae: 0.24196 | valid_rmse: 0.31589 | valid_mse: 0.09978 |  0:01:24s\n",
      "epoch 58 | loss: 0.09517 | train_rmsle: 0.00609 | train_mae: 0.23553 | train_rmse: 0.30432 | train_mse: 0.09261 | valid_rmsle: 0.00611 | valid_mae: 0.24091 | valid_rmse: 0.31021 | valid_mse: 0.09623 |  0:01:25s\n",
      "epoch 59 | loss: 0.09273 | train_rmsle: 0.00604 | train_mae: 0.2304  | train_rmse: 0.30136 | train_mse: 0.09082 | valid_rmsle: 0.00608 | valid_mae: 0.23416 | valid_rmse: 0.30772 | valid_mse: 0.09469 |  0:01:27s\n",
      "epoch 60 | loss: 0.09298 | train_rmsle: 0.006   | train_mae: 0.23158 | train_rmse: 0.30163 | train_mse: 0.09098 | valid_rmsle: 0.00608 | valid_mae: 0.23445 | valid_rmse: 0.30817 | valid_mse: 0.09497 |  0:01:28s\n",
      "epoch 61 | loss: 0.09806 | train_rmsle: 0.00656 | train_mae: 0.25689 | train_rmse: 0.3216  | train_mse: 0.10343 | valid_rmsle: 0.00651 | valid_mae: 0.25461 | valid_rmse: 0.32458 | valid_mse: 0.10536 |  0:01:30s\n",
      "epoch 62 | loss: 0.10154 | train_rmsle: 0.00594 | train_mae: 0.23179 | train_rmse: 0.30012 | train_mse: 0.09007 | valid_rmsle: 0.00607 | valid_mae: 0.23531 | valid_rmse: 0.3082  | valid_mse: 0.09499 |  0:01:31s\n",
      "epoch 63 | loss: 0.09234 | train_rmsle: 0.0059  | train_mae: 0.22876 | train_rmse: 0.29882 | train_mse: 0.08929 | valid_rmsle: 0.00614 | valid_mae: 0.23654 | valid_rmse: 0.30978 | valid_mse: 0.09596 |  0:01:32s\n",
      "epoch 64 | loss: 0.09125 | train_rmsle: 0.00594 | train_mae: 0.2301  | train_rmse: 0.30029 | train_mse: 0.09017 | valid_rmsle: 0.00633 | valid_mae: 0.23777 | valid_rmse: 0.31285 | valid_mse: 0.09788 |  0:01:34s\n",
      "epoch 65 | loss: 0.09271 | train_rmsle: 0.00586 | train_mae: 0.23078 | train_rmse: 0.29918 | train_mse: 0.08951 | valid_rmsle: 0.00636 | valid_mae: 0.24152 | valid_rmse: 0.31593 | valid_mse: 0.09981 |  0:01:35s\n",
      "epoch 66 | loss: 0.09234 | train_rmsle: 0.00599 | train_mae: 0.22971 | train_rmse: 0.30096 | train_mse: 0.09057 | valid_rmsle: 0.00639 | valid_mae: 0.23797 | valid_rmse: 0.31425 | valid_mse: 0.09875 |  0:01:37s\n",
      "epoch 67 | loss: 0.09561 | train_rmsle: 0.0059  | train_mae: 0.23216 | train_rmse: 0.3002  | train_mse: 0.09012 | valid_rmsle: 0.00616 | valid_mae: 0.23808 | valid_rmse: 0.3104  | valid_mse: 0.09635 |  0:01:38s\n",
      "epoch 68 | loss: 0.09338 | train_rmsle: 0.00583 | train_mae: 0.22844 | train_rmse: 0.29778 | train_mse: 0.08868 | valid_rmsle: 0.00614 | valid_mae: 0.23772 | valid_rmse: 0.30974 | valid_mse: 0.09594 |  0:01:40s\n",
      "epoch 69 | loss: 0.09092 | train_rmsle: 0.00586 | train_mae: 0.2278  | train_rmse: 0.29775 | train_mse: 0.08865 | valid_rmsle: 0.00608 | valid_mae: 0.23431 | valid_rmse: 0.30788 | valid_mse: 0.09479 |  0:01:41s\n",
      "epoch 70 | loss: 0.0952  | train_rmsle: 0.00601 | train_mae: 0.22901 | train_rmse: 0.30103 | train_mse: 0.09062 | valid_rmsle: 0.00623 | valid_mae: 0.23834 | valid_rmse: 0.31122 | valid_mse: 0.09686 |  0:01:43s\n",
      "epoch 71 | loss: 0.09596 | train_rmsle: 0.00632 | train_mae: 0.25133 | train_rmse: 0.31631 | train_mse: 0.10005 | valid_rmsle: 0.00635 | valid_mae: 0.25517 | valid_rmse: 0.32124 | valid_mse: 0.10319 |  0:01:44s\n",
      "epoch 72 | loss: 0.09306 | train_rmsle: 0.00585 | train_mae: 0.2287  | train_rmse: 0.29872 | train_mse: 0.08924 | valid_rmsle: 0.00603 | valid_mae: 0.23471 | valid_rmse: 0.30757 | valid_mse: 0.0946  |  0:01:45s\n",
      "epoch 73 | loss: 0.09217 | train_rmsle: 0.00628 | train_mae: 0.2468  | train_rmse: 0.31324 | train_mse: 0.09812 | valid_rmsle: 0.00621 | valid_mae: 0.24834 | valid_rmse: 0.31567 | valid_mse: 0.09965 |  0:01:47s\n",
      "epoch 74 | loss: 0.09478 | train_rmsle: 0.00592 | train_mae: 0.22596 | train_rmse: 0.2981  | train_mse: 0.08886 | valid_rmsle: 0.0061  | valid_mae: 0.2348  | valid_rmse: 0.30759 | valid_mse: 0.09461 |  0:01:48s\n",
      "\n",
      "Early stopping occurred at epoch 74 with best_epoch = 54 and best_valid_mse = 0.09389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09379131865818442 RMSE: 0.30625368350141424 R2: 0.584821971837445 MAE: 0.23434699130270956\n",
      "=====================================\n",
      "[96/108] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.7386 | train_rmsle: 0.28231 | train_mae: 1.7428  | train_rmse: 1.80858 | train_mse: 3.27097 | valid_rmsle: 0.28398 | valid_mae: 1.74964 | valid_rmse: 1.81462 | valid_mse: 3.29283 |  0:00:01s\n",
      "epoch 1  | loss: 2.71642 | train_rmsle: 0.20833 | train_mae: 1.54158 | train_rmse: 1.61408 | train_mse: 2.60525 | valid_rmsle: 0.20932 | valid_mae: 1.54687 | valid_rmse: 1.61884 | valid_mse: 2.62064 |  0:00:03s\n",
      "epoch 2  | loss: 1.36361 | train_rmsle: 0.05895 | train_mae: 0.87171 | train_rmse: 0.96484 | train_mse: 0.93092 | valid_rmsle: 0.05916 | valid_mae: 0.87321 | valid_rmse: 0.96839 | valid_mse: 0.93778 |  0:00:04s\n",
      "epoch 3  | loss: 0.84464 | train_rmsle: 0.03162 | train_mae: 0.6381  | train_rmse: 0.73059 | train_mse: 0.53377 | valid_rmsle: 0.03152 | valid_mae: 0.63797 | valid_rmse: 0.7326  | valid_mse: 0.53671 |  0:00:05s\n",
      "epoch 4  | loss: 0.63036 | train_rmsle: 0.03901 | train_mae: 0.71045 | train_rmse: 0.80422 | train_mse: 0.64678 | valid_rmsle: 0.03905 | valid_mae: 0.71058 | valid_rmse: 0.80714 | valid_mse: 0.65147 |  0:00:07s\n",
      "epoch 5  | loss: 0.49678 | train_rmsle: 0.02801 | train_mae: 0.59865 | train_rmse: 0.69029 | train_mse: 0.4765  | valid_rmsle: 0.02785 | valid_mae: 0.59879 | valid_rmse: 0.69164 | valid_mse: 0.47837 |  0:00:08s\n",
      "epoch 6  | loss: 0.40612 | train_rmsle: 0.02428 | train_mae: 0.55357 | train_rmse: 0.64431 | train_mse: 0.41513 | valid_rmsle: 0.02395 | valid_mae: 0.55396 | valid_rmse: 0.64368 | valid_mse: 0.41432 |  0:00:10s\n",
      "epoch 7  | loss: 0.34433 | train_rmsle: 0.02392 | train_mae: 0.55022 | train_rmse: 0.63962 | train_mse: 0.40911 | valid_rmsle: 0.0237  | valid_mae: 0.55198 | valid_rmse: 0.64045 | valid_mse: 0.41017 |  0:00:11s\n",
      "epoch 8  | loss: 0.29488 | train_rmsle: 0.02379 | train_mae: 0.54823 | train_rmse: 0.63793 | train_mse: 0.40696 | valid_rmsle: 0.02349 | valid_mae: 0.54897 | valid_rmse: 0.63764 | valid_mse: 0.40659 |  0:00:13s\n",
      "epoch 9  | loss: 0.28519 | train_rmsle: 0.02077 | train_mae: 0.50773 | train_rmse: 0.59621 | train_mse: 0.35547 | valid_rmsle: 0.02032 | valid_mae: 0.50693 | valid_rmse: 0.59397 | valid_mse: 0.3528  |  0:00:14s\n",
      "epoch 10 | loss: 0.26769 | train_rmsle: 0.01973 | train_mae: 0.49494 | train_rmse: 0.58087 | train_mse: 0.33741 | valid_rmsle: 0.01922 | valid_mae: 0.49329 | valid_rmse: 0.57728 | valid_mse: 0.33325 |  0:00:16s\n",
      "epoch 11 | loss: 0.24829 | train_rmsle: 0.01596 | train_mae: 0.44343 | train_rmse: 0.51991 | train_mse: 0.27031 | valid_rmsle: 0.01513 | valid_mae: 0.43165 | valid_rmse: 0.50958 | valid_mse: 0.25967 |  0:00:17s\n",
      "epoch 12 | loss: 0.22488 | train_rmsle: 0.00981 | train_mae: 0.31663 | train_rmse: 0.39681 | train_mse: 0.15745 | valid_rmsle: 0.00924 | valid_mae: 0.30889 | valid_rmse: 0.38859 | valid_mse: 0.151   |  0:00:18s\n",
      "epoch 13 | loss: 0.19813 | train_rmsle: 0.01029 | train_mae: 0.33068 | train_rmse: 0.40602 | train_mse: 0.16485 | valid_rmsle: 0.0097  | valid_mae: 0.31997 | valid_rmse: 0.397   | valid_mse: 0.15761 |  0:00:20s\n",
      "epoch 14 | loss: 0.16338 | train_rmsle: 0.00859 | train_mae: 0.29302 | train_rmse: 0.36787 | train_mse: 0.13533 | valid_rmsle: 0.00785 | valid_mae: 0.28234 | valid_rmse: 0.35538 | valid_mse: 0.1263  |  0:00:21s\n",
      "epoch 15 | loss: 0.15376 | train_rmsle: 0.00828 | train_mae: 0.29224 | train_rmse: 0.36268 | train_mse: 0.13154 | valid_rmsle: 0.00763 | valid_mae: 0.27965 | valid_rmse: 0.35196 | valid_mse: 0.12387 |  0:00:23s\n",
      "epoch 16 | loss: 0.14009 | train_rmsle: 0.00924 | train_mae: 0.31211 | train_rmse: 0.38429 | train_mse: 0.14768 | valid_rmsle: 0.00828 | valid_mae: 0.29401 | valid_rmse: 0.36611 | valid_mse: 0.13404 |  0:00:24s\n",
      "epoch 17 | loss: 0.13432 | train_rmsle: 0.01152 | train_mae: 0.3626  | train_rmse: 0.43512 | train_mse: 0.18933 | valid_rmsle: 0.01074 | valid_mae: 0.35197 | valid_rmse: 0.4238  | valid_mse: 0.1796  |  0:00:26s\n",
      "epoch 18 | loss: 0.13119 | train_rmsle: 0.00948 | train_mae: 0.32242 | train_rmse: 0.39158 | train_mse: 0.15333 | valid_rmsle: 0.00875 | valid_mae: 0.31139 | valid_rmse: 0.37993 | valid_mse: 0.14435 |  0:00:27s\n",
      "epoch 19 | loss: 0.12414 | train_rmsle: 0.01057 | train_mae: 0.33008 | train_rmse: 0.40694 | train_mse: 0.1656  | valid_rmsle: 0.00956 | valid_mae: 0.31476 | valid_rmse: 0.39053 | valid_mse: 0.15251 |  0:00:29s\n",
      "epoch 20 | loss: 0.13004 | train_rmsle: 0.00847 | train_mae: 0.29145 | train_rmse: 0.36472 | train_mse: 0.13302 | valid_rmsle: 0.00779 | valid_mae: 0.2801  | valid_rmse: 0.35231 | valid_mse: 0.12412 |  0:00:30s\n",
      "epoch 21 | loss: 0.11992 | train_rmsle: 0.00819 | train_mae: 0.28312 | train_rmse: 0.35775 | train_mse: 0.12798 | valid_rmsle: 0.00741 | valid_mae: 0.26879 | valid_rmse: 0.34281 | valid_mse: 0.11752 |  0:00:31s\n",
      "epoch 22 | loss: 0.12612 | train_rmsle: 0.0083  | train_mae: 0.29184 | train_rmse: 0.36265 | train_mse: 0.13152 | valid_rmsle: 0.00764 | valid_mae: 0.2771  | valid_rmse: 0.35062 | valid_mse: 0.12293 |  0:00:33s\n",
      "epoch 23 | loss: 0.11991 | train_rmsle: 0.00827 | train_mae: 0.29269 | train_rmse: 0.36243 | train_mse: 0.13135 | valid_rmsle: 0.00759 | valid_mae: 0.27967 | valid_rmse: 0.35017 | valid_mse: 0.12262 |  0:00:34s\n",
      "epoch 24 | loss: 0.11256 | train_rmsle: 0.00717 | train_mae: 0.26173 | train_rmse: 0.33355 | train_mse: 0.11125 | valid_rmsle: 0.00643 | valid_mae: 0.24812 | valid_rmse: 0.31904 | valid_mse: 0.10178 |  0:00:36s\n",
      "epoch 25 | loss: 0.11463 | train_rmsle: 0.00782 | train_mae: 0.2778  | train_rmse: 0.35013 | train_mse: 0.12259 | valid_rmsle: 0.0073  | valid_mae: 0.2673  | valid_rmse: 0.34081 | valid_mse: 0.11615 |  0:00:37s\n",
      "epoch 26 | loss: 0.10977 | train_rmsle: 0.00773 | train_mae: 0.27975 | train_rmse: 0.34967 | train_mse: 0.12227 | valid_rmsle: 0.00703 | valid_mae: 0.2656  | valid_rmse: 0.33673 | valid_mse: 0.11339 |  0:00:39s\n",
      "epoch 27 | loss: 0.1065  | train_rmsle: 0.00677 | train_mae: 0.24674 | train_rmse: 0.3217  | train_mse: 0.10349 | valid_rmsle: 0.00632 | valid_mae: 0.23994 | valid_rmse: 0.31434 | valid_mse: 0.09881 |  0:00:40s\n",
      "epoch 28 | loss: 0.10798 | train_rmsle: 0.00728 | train_mae: 0.26136 | train_rmse: 0.33526 | train_mse: 0.1124  | valid_rmsle: 0.00676 | valid_mae: 0.25305 | valid_rmse: 0.32682 | valid_mse: 0.10681 |  0:00:42s\n",
      "epoch 29 | loss: 0.10874 | train_rmsle: 0.00763 | train_mae: 0.27487 | train_rmse: 0.34631 | train_mse: 0.11993 | valid_rmsle: 0.007   | valid_mae: 0.26096 | valid_rmse: 0.33371 | valid_mse: 0.11136 |  0:00:43s\n",
      "epoch 30 | loss: 0.10967 | train_rmsle: 0.00722 | train_mae: 0.26601 | train_rmse: 0.33614 | train_mse: 0.11299 | valid_rmsle: 0.00674 | valid_mae: 0.25578 | valid_rmse: 0.32769 | valid_mse: 0.10738 |  0:00:44s\n",
      "epoch 31 | loss: 0.10385 | train_rmsle: 0.00667 | train_mae: 0.2435  | train_rmse: 0.31794 | train_mse: 0.10108 | valid_rmsle: 0.00625 | valid_mae: 0.23858 | valid_rmse: 0.31222 | valid_mse: 0.09748 |  0:00:46s\n",
      "epoch 32 | loss: 0.10566 | train_rmsle: 0.00683 | train_mae: 0.25457 | train_rmse: 0.32501 | train_mse: 0.10563 | valid_rmsle: 0.00629 | valid_mae: 0.24401 | valid_rmse: 0.3149  | valid_mse: 0.09916 |  0:00:47s\n",
      "epoch 33 | loss: 0.10605 | train_rmsle: 0.00658 | train_mae: 0.24432 | train_rmse: 0.31692 | train_mse: 0.10044 | valid_rmsle: 0.00619 | valid_mae: 0.23931 | valid_rmse: 0.31111 | valid_mse: 0.09679 |  0:00:49s\n",
      "epoch 34 | loss: 0.10545 | train_rmsle: 0.00659 | train_mae: 0.24411 | train_rmse: 0.31683 | train_mse: 0.10038 | valid_rmsle: 0.00642 | valid_mae: 0.24202 | valid_rmse: 0.3156  | valid_mse: 0.0996  |  0:00:50s\n",
      "epoch 35 | loss: 0.1022  | train_rmsle: 0.00689 | train_mae: 0.24384 | train_rmse: 0.32268 | train_mse: 0.10412 | valid_rmsle: 0.00676 | valid_mae: 0.24535 | valid_rmse: 0.32392 | valid_mse: 0.10493 |  0:00:52s\n",
      "epoch 36 | loss: 0.10305 | train_rmsle: 0.00679 | train_mae: 0.25422 | train_rmse: 0.32467 | train_mse: 0.10541 | valid_rmsle: 0.00646 | valid_mae: 0.25034 | valid_rmse: 0.3205  | valid_mse: 0.10272 |  0:00:53s\n",
      "epoch 37 | loss: 0.10115 | train_rmsle: 0.00661 | train_mae: 0.24683 | train_rmse: 0.31873 | train_mse: 0.10159 | valid_rmsle: 0.00633 | valid_mae: 0.24151 | valid_rmse: 0.31525 | valid_mse: 0.09938 |  0:00:55s\n",
      "epoch 38 | loss: 0.0991  | train_rmsle: 0.00673 | train_mae: 0.25226 | train_rmse: 0.32247 | train_mse: 0.10399 | valid_rmsle: 0.00644 | valid_mae: 0.24828 | valid_rmse: 0.31879 | valid_mse: 0.10162 |  0:00:56s\n",
      "epoch 39 | loss: 0.10052 | train_rmsle: 0.00668 | train_mae: 0.25225 | train_rmse: 0.32145 | train_mse: 0.10333 | valid_rmsle: 0.00651 | valid_mae: 0.25005 | valid_rmse: 0.32058 | valid_mse: 0.10277 |  0:00:57s\n",
      "epoch 40 | loss: 0.09948 | train_rmsle: 0.00666 | train_mae: 0.24945 | train_rmse: 0.32009 | train_mse: 0.10246 | valid_rmsle: 0.00653 | valid_mae: 0.24679 | valid_rmse: 0.31983 | valid_mse: 0.10229 |  0:00:59s\n",
      "epoch 41 | loss: 0.1001  | train_rmsle: 0.00644 | train_mae: 0.24046 | train_rmse: 0.3125  | train_mse: 0.09766 | valid_rmsle: 0.00624 | valid_mae: 0.23866 | valid_rmse: 0.31123 | valid_mse: 0.09686 |  0:01:00s\n",
      "epoch 42 | loss: 0.10045 | train_rmsle: 0.00837 | train_mae: 0.29679 | train_rmse: 0.36639 | train_mse: 0.13424 | valid_rmsle: 0.00801 | valid_mae: 0.29074 | valid_rmse: 0.36141 | valid_mse: 0.13061 |  0:01:02s\n",
      "epoch 43 | loss: 0.10067 | train_rmsle: 0.00662 | train_mae: 0.24913 | train_rmse: 0.32006 | train_mse: 0.10244 | valid_rmsle: 0.00656 | valid_mae: 0.24881 | valid_rmse: 0.32224 | valid_mse: 0.10384 |  0:01:03s\n",
      "epoch 44 | loss: 0.09838 | train_rmsle: 0.00745 | train_mae: 0.27355 | train_rmse: 0.34286 | train_mse: 0.11755 | valid_rmsle: 0.00746 | valid_mae: 0.27248 | valid_rmse: 0.34561 | valid_mse: 0.11945 |  0:01:05s\n",
      "epoch 45 | loss: 0.10002 | train_rmsle: 0.00637 | train_mae: 0.23972 | train_rmse: 0.31146 | train_mse: 0.09701 | valid_rmsle: 0.00626 | valid_mae: 0.23886 | valid_rmse: 0.31252 | valid_mse: 0.09767 |  0:01:06s\n",
      "epoch 46 | loss: 0.09835 | train_rmsle: 0.00637 | train_mae: 0.23861 | train_rmse: 0.31151 | train_mse: 0.09704 | valid_rmsle: 0.00622 | valid_mae: 0.23818 | valid_rmse: 0.31189 | valid_mse: 0.09727 |  0:01:08s\n",
      "epoch 47 | loss: 0.09992 | train_rmsle: 0.00638 | train_mae: 0.23901 | train_rmse: 0.31226 | train_mse: 0.09751 | valid_rmsle: 0.00631 | valid_mae: 0.23845 | valid_rmse: 0.3147  | valid_mse: 0.09904 |  0:01:09s\n",
      "epoch 48 | loss: 0.10017 | train_rmsle: 0.00633 | train_mae: 0.23879 | train_rmse: 0.3102  | train_mse: 0.09622 | valid_rmsle: 0.00618 | valid_mae: 0.23673 | valid_rmse: 0.31009 | valid_mse: 0.09615 |  0:01:10s\n",
      "epoch 49 | loss: 0.09939 | train_rmsle: 0.00623 | train_mae: 0.23328 | train_rmse: 0.30593 | train_mse: 0.09359 | valid_rmsle: 0.00635 | valid_mae: 0.23676 | valid_rmse: 0.31349 | valid_mse: 0.09828 |  0:01:12s\n",
      "epoch 50 | loss: 0.09872 | train_rmsle: 0.00658 | train_mae: 0.24756 | train_rmse: 0.31643 | train_mse: 0.10013 | valid_rmsle: 0.00619 | valid_mae: 0.2434  | valid_rmse: 0.31274 | valid_mse: 0.0978  |  0:01:13s\n",
      "epoch 51 | loss: 0.09719 | train_rmsle: 0.0065  | train_mae: 0.25005 | train_rmse: 0.3177  | train_mse: 0.10093 | valid_rmsle: 0.00631 | valid_mae: 0.24656 | valid_rmse: 0.316   | valid_mse: 0.09985 |  0:01:15s\n",
      "epoch 52 | loss: 0.09611 | train_rmsle: 0.00619 | train_mae: 0.23341 | train_rmse: 0.3053  | train_mse: 0.09321 | valid_rmsle: 0.00616 | valid_mae: 0.23491 | valid_rmse: 0.30877 | valid_mse: 0.09534 |  0:01:16s\n",
      "epoch 53 | loss: 0.09789 | train_rmsle: 0.00637 | train_mae: 0.2352  | train_rmse: 0.31063 | train_mse: 0.09649 | valid_rmsle: 0.00639 | valid_mae: 0.24093 | valid_rmse: 0.31398 | valid_mse: 0.09858 |  0:01:18s\n",
      "epoch 54 | loss: 0.09681 | train_rmsle: 0.00617 | train_mae: 0.23255 | train_rmse: 0.30455 | train_mse: 0.09275 | valid_rmsle: 0.00609 | valid_mae: 0.23441 | valid_rmse: 0.30642 | valid_mse: 0.09389 |  0:01:19s\n",
      "epoch 55 | loss: 0.09573 | train_rmsle: 0.00612 | train_mae: 0.23135 | train_rmse: 0.30347 | train_mse: 0.09209 | valid_rmsle: 0.00611 | valid_mae: 0.23522 | valid_rmse: 0.30724 | valid_mse: 0.0944  |  0:01:21s\n",
      "epoch 56 | loss: 0.0979  | train_rmsle: 0.00679 | train_mae: 0.26164 | train_rmse: 0.32768 | train_mse: 0.10738 | valid_rmsle: 0.00665 | valid_mae: 0.26113 | valid_rmse: 0.32823 | valid_mse: 0.10774 |  0:01:22s\n",
      "epoch 57 | loss: 0.0953  | train_rmsle: 0.00653 | train_mae: 0.23649 | train_rmse: 0.31342 | train_mse: 0.09823 | valid_rmsle: 0.00642 | valid_mae: 0.24196 | valid_rmse: 0.31589 | valid_mse: 0.09978 |  0:01:24s\n",
      "epoch 58 | loss: 0.09517 | train_rmsle: 0.00609 | train_mae: 0.23553 | train_rmse: 0.30432 | train_mse: 0.09261 | valid_rmsle: 0.00611 | valid_mae: 0.24091 | valid_rmse: 0.31021 | valid_mse: 0.09623 |  0:01:25s\n",
      "epoch 59 | loss: 0.09273 | train_rmsle: 0.00604 | train_mae: 0.2304  | train_rmse: 0.30136 | train_mse: 0.09082 | valid_rmsle: 0.00608 | valid_mae: 0.23416 | valid_rmse: 0.30772 | valid_mse: 0.09469 |  0:01:26s\n",
      "epoch 60 | loss: 0.09298 | train_rmsle: 0.006   | train_mae: 0.23158 | train_rmse: 0.30163 | train_mse: 0.09098 | valid_rmsle: 0.00608 | valid_mae: 0.23445 | valid_rmse: 0.30817 | valid_mse: 0.09497 |  0:01:28s\n",
      "epoch 61 | loss: 0.09806 | train_rmsle: 0.00656 | train_mae: 0.25689 | train_rmse: 0.3216  | train_mse: 0.10343 | valid_rmsle: 0.00651 | valid_mae: 0.25461 | valid_rmse: 0.32458 | valid_mse: 0.10536 |  0:01:29s\n",
      "epoch 62 | loss: 0.10154 | train_rmsle: 0.00594 | train_mae: 0.23179 | train_rmse: 0.30012 | train_mse: 0.09007 | valid_rmsle: 0.00607 | valid_mae: 0.23531 | valid_rmse: 0.3082  | valid_mse: 0.09499 |  0:01:31s\n",
      "epoch 63 | loss: 0.09234 | train_rmsle: 0.0059  | train_mae: 0.22876 | train_rmse: 0.29882 | train_mse: 0.08929 | valid_rmsle: 0.00614 | valid_mae: 0.23654 | valid_rmse: 0.30978 | valid_mse: 0.09596 |  0:01:32s\n",
      "epoch 64 | loss: 0.09125 | train_rmsle: 0.00594 | train_mae: 0.2301  | train_rmse: 0.30029 | train_mse: 0.09017 | valid_rmsle: 0.00633 | valid_mae: 0.23777 | valid_rmse: 0.31285 | valid_mse: 0.09788 |  0:01:34s\n",
      "epoch 65 | loss: 0.09271 | train_rmsle: 0.00586 | train_mae: 0.23078 | train_rmse: 0.29918 | train_mse: 0.08951 | valid_rmsle: 0.00636 | valid_mae: 0.24152 | valid_rmse: 0.31593 | valid_mse: 0.09981 |  0:01:35s\n",
      "epoch 66 | loss: 0.09234 | train_rmsle: 0.00599 | train_mae: 0.22971 | train_rmse: 0.30096 | train_mse: 0.09057 | valid_rmsle: 0.00639 | valid_mae: 0.23797 | valid_rmse: 0.31425 | valid_mse: 0.09875 |  0:01:37s\n",
      "epoch 67 | loss: 0.09561 | train_rmsle: 0.0059  | train_mae: 0.23216 | train_rmse: 0.3002  | train_mse: 0.09012 | valid_rmsle: 0.00616 | valid_mae: 0.23808 | valid_rmse: 0.3104  | valid_mse: 0.09635 |  0:01:38s\n",
      "epoch 68 | loss: 0.09338 | train_rmsle: 0.00583 | train_mae: 0.22844 | train_rmse: 0.29778 | train_mse: 0.08868 | valid_rmsle: 0.00614 | valid_mae: 0.23772 | valid_rmse: 0.30974 | valid_mse: 0.09594 |  0:01:39s\n",
      "epoch 69 | loss: 0.09092 | train_rmsle: 0.00586 | train_mae: 0.2278  | train_rmse: 0.29775 | train_mse: 0.08865 | valid_rmsle: 0.00608 | valid_mae: 0.23431 | valid_rmse: 0.30788 | valid_mse: 0.09479 |  0:01:41s\n",
      "epoch 70 | loss: 0.0952  | train_rmsle: 0.00601 | train_mae: 0.22901 | train_rmse: 0.30103 | train_mse: 0.09062 | valid_rmsle: 0.00623 | valid_mae: 0.23834 | valid_rmse: 0.31122 | valid_mse: 0.09686 |  0:01:42s\n",
      "epoch 71 | loss: 0.09596 | train_rmsle: 0.00632 | train_mae: 0.25133 | train_rmse: 0.31631 | train_mse: 0.10005 | valid_rmsle: 0.00635 | valid_mae: 0.25517 | valid_rmse: 0.32124 | valid_mse: 0.10319 |  0:01:44s\n",
      "epoch 72 | loss: 0.09306 | train_rmsle: 0.00585 | train_mae: 0.2287  | train_rmse: 0.29872 | train_mse: 0.08924 | valid_rmsle: 0.00603 | valid_mae: 0.23471 | valid_rmse: 0.30757 | valid_mse: 0.0946  |  0:01:45s\n",
      "epoch 73 | loss: 0.09217 | train_rmsle: 0.00628 | train_mae: 0.2468  | train_rmse: 0.31324 | train_mse: 0.09812 | valid_rmsle: 0.00621 | valid_mae: 0.24834 | valid_rmse: 0.31567 | valid_mse: 0.09965 |  0:01:47s\n",
      "epoch 74 | loss: 0.09478 | train_rmsle: 0.00592 | train_mae: 0.22596 | train_rmse: 0.2981  | train_mse: 0.08886 | valid_rmsle: 0.0061  | valid_mae: 0.2348  | valid_rmse: 0.30759 | valid_mse: 0.09461 |  0:01:48s\n",
      "\n",
      "Early stopping occurred at epoch 74 with best_epoch = 54 and best_valid_mse = 0.09389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09379131865818442 RMSE: 0.30625368350141424 R2: 0.584821971837445 MAE: 0.23434699130270956\n",
      "=====================================\n",
      "[97/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.55594 | train_rmsle: 0.09477 | train_mae: 1.08757 | train_rmse: 1.17947 | train_mse: 1.39116 | valid_rmsle: 0.09529 | valid_mae: 1.09056 | valid_rmse: 1.18399 | valid_mse: 1.40182 |  0:00:01s\n",
      "epoch 1  | loss: 0.57373 | train_rmsle: 0.07849 | train_mae: 1.00133 | train_rmse: 1.08985 | train_mse: 1.18777 | valid_rmsle: 0.07876 | valid_mae: 1.00408 | valid_rmse: 1.09323 | valid_mse: 1.19514 |  0:00:03s\n",
      "epoch 2  | loss: 0.40217 | train_rmsle: 0.05229 | train_mae: 0.82326 | train_rmse: 0.91588 | train_mse: 0.83883 | valid_rmsle: 0.05239 | valid_mae: 0.82398 | valid_rmse: 0.91877 | valid_mse: 0.84414 |  0:00:05s\n",
      "epoch 3  | loss: 0.42356 | train_rmsle: 0.07212 | train_mae: 0.96028 | train_rmse: 1.05172 | train_mse: 1.10611 | valid_rmsle: 0.07233 | valid_mae: 0.96234 | valid_rmse: 1.05488 | valid_mse: 1.11277 |  0:00:07s\n",
      "epoch 4  | loss: 0.59322 | train_rmsle: 0.01688 | train_mae: 0.44366 | train_rmse: 0.53286 | train_mse: 0.28394 | valid_rmsle: 0.0164  | valid_mae: 0.44431 | valid_rmse: 0.53019 | valid_mse: 0.2811  |  0:00:09s\n",
      "epoch 5  | loss: 0.85333 | train_rmsle: 0.15492 | train_mae: 1.35952 | train_rmse: 1.43822 | train_mse: 2.06848 | valid_rmsle: 0.15587 | valid_mae: 1.36455 | valid_rmse: 1.44344 | valid_mse: 2.08352 |  0:00:10s\n",
      "epoch 6  | loss: 0.76832 | train_rmsle: 0.02088 | train_mae: 0.50611 | train_rmse: 0.59707 | train_mse: 0.35649 | valid_rmsle: 0.02038 | valid_mae: 0.50604 | valid_rmse: 0.5943  | valid_mse: 0.3532  |  0:00:12s\n",
      "epoch 7  | loss: 0.2555  | train_rmsle: 0.02383 | train_mae: 0.54629 | train_rmse: 0.63821 | train_mse: 0.40731 | valid_rmsle: 0.02367 | valid_mae: 0.54425 | valid_rmse: 0.63979 | valid_mse: 0.40934 |  0:00:14s\n",
      "epoch 8  | loss: 0.26065 | train_rmsle: 0.0152  | train_mae: 0.41181 | train_rmse: 0.50165 | train_mse: 0.25166 | valid_rmsle: 0.0146  | valid_mae: 0.41094 | valid_rmse: 0.49681 | valid_mse: 0.24682 |  0:00:16s\n",
      "epoch 9  | loss: 0.25261 | train_rmsle: 0.02005 | train_mae: 0.49388 | train_rmse: 0.58552 | train_mse: 0.34284 | valid_rmsle: 0.01975 | valid_mae: 0.49518 | valid_rmse: 0.58518 | valid_mse: 0.34243 |  0:00:18s\n",
      "epoch 10 | loss: 0.23398 | train_rmsle: 0.01573 | train_mae: 0.42017 | train_rmse: 0.51222 | train_mse: 0.26237 | valid_rmsle: 0.01553 | valid_mae: 0.42696 | valid_rmse: 0.51432 | valid_mse: 0.26453 |  0:00:20s\n",
      "epoch 11 | loss: 0.23575 | train_rmsle: 0.02414 | train_mae: 0.55162 | train_rmse: 0.64235 | train_mse: 0.41262 | valid_rmsle: 0.02393 | valid_mae: 0.55197 | valid_rmse: 0.64328 | valid_mse: 0.41381 |  0:00:21s\n",
      "epoch 12 | loss: 0.23768 | train_rmsle: 0.01525 | train_mae: 0.41526 | train_rmse: 0.50502 | train_mse: 0.25504 | valid_rmsle: 0.01471 | valid_mae: 0.41353 | valid_rmse: 0.50129 | valid_mse: 0.25129 |  0:00:23s\n",
      "epoch 13 | loss: 0.22476 | train_rmsle: 0.01575 | train_mae: 0.42333 | train_rmse: 0.51478 | train_mse: 0.26499 | valid_rmsle: 0.01517 | valid_mae: 0.42311 | valid_rmse: 0.51081 | valid_mse: 0.26093 |  0:00:25s\n",
      "epoch 14 | loss: 0.2229  | train_rmsle: 0.01459 | train_mae: 0.40113 | train_rmse: 0.49174 | train_mse: 0.24181 | valid_rmsle: 0.01396 | valid_mae: 0.40054 | valid_rmse: 0.48669 | valid_mse: 0.23686 |  0:00:27s\n",
      "epoch 15 | loss: 0.2305  | train_rmsle: 0.01856 | train_mae: 0.47321 | train_rmse: 0.5634  | train_mse: 0.31742 | valid_rmsle: 0.0181  | valid_mae: 0.47009 | valid_rmse: 0.56096 | valid_mse: 0.31467 |  0:00:29s\n",
      "epoch 16 | loss: 0.21748 | train_rmsle: 0.01402 | train_mae: 0.36883 | train_rmse: 0.47081 | train_mse: 0.22166 | valid_rmsle: 0.01313 | valid_mae: 0.36592 | valid_rmse: 0.46003 | valid_mse: 0.21163 |  0:00:30s\n",
      "epoch 17 | loss: 0.21772 | train_rmsle: 0.01467 | train_mae: 0.40197 | train_rmse: 0.49256 | train_mse: 0.24262 | valid_rmsle: 0.01396 | valid_mae: 0.40023 | valid_rmse: 0.4852  | valid_mse: 0.23542 |  0:00:32s\n",
      "epoch 18 | loss: 0.21621 | train_rmsle: 0.0129  | train_mae: 0.3683  | train_rmse: 0.45771 | train_mse: 0.2095  | valid_rmsle: 0.01217 | valid_mae: 0.36263 | valid_rmse: 0.44897 | valid_mse: 0.20158 |  0:00:34s\n",
      "epoch 19 | loss: 0.20151 | train_rmsle: 0.01303 | train_mae: 0.37542 | train_rmse: 0.46256 | train_mse: 0.21396 | valid_rmsle: 0.01219 | valid_mae: 0.36973 | valid_rmse: 0.45195 | valid_mse: 0.20425 |  0:00:36s\n",
      "epoch 20 | loss: 0.19248 | train_rmsle: 0.01143 | train_mae: 0.33447 | train_rmse: 0.42664 | train_mse: 0.18202 | valid_rmsle: 0.01086 | valid_mae: 0.33076 | valid_rmse: 0.42014 | valid_mse: 0.17652 |  0:00:38s\n",
      "epoch 21 | loss: 0.18073 | train_rmsle: 0.01055 | train_mae: 0.32258 | train_rmse: 0.41182 | train_mse: 0.1696  | valid_rmsle: 0.0102  | valid_mae: 0.3187  | valid_rmse: 0.40765 | valid_mse: 0.16618 |  0:00:39s\n",
      "epoch 22 | loss: 0.16616 | train_rmsle: 0.00987 | train_mae: 0.31477 | train_rmse: 0.39876 | train_mse: 0.15901 | valid_rmsle: 0.00944 | valid_mae: 0.3077  | valid_rmse: 0.39448 | valid_mse: 0.15562 |  0:00:41s\n",
      "epoch 23 | loss: 0.14507 | train_rmsle: 0.00852 | train_mae: 0.27877 | train_rmse: 0.36435 | train_mse: 0.13275 | valid_rmsle: 0.00836 | valid_mae: 0.27705 | valid_rmse: 0.36477 | valid_mse: 0.13306 |  0:00:43s\n",
      "epoch 24 | loss: 0.13086 | train_rmsle: 0.00777 | train_mae: 0.26229 | train_rmse: 0.34525 | train_mse: 0.1192  | valid_rmsle: 0.00732 | valid_mae: 0.25767 | valid_rmse: 0.34002 | valid_mse: 0.11561 |  0:00:45s\n",
      "epoch 25 | loss: 0.11568 | train_rmsle: 0.00756 | train_mae: 0.263   | train_rmse: 0.34255 | train_mse: 0.11734 | valid_rmsle: 0.00711 | valid_mae: 0.2583  | valid_rmse: 0.33773 | valid_mse: 0.11406 |  0:00:47s\n",
      "epoch 26 | loss: 0.1138  | train_rmsle: 0.00728 | train_mae: 0.26275 | train_rmse: 0.3375  | train_mse: 0.11391 | valid_rmsle: 0.00696 | valid_mae: 0.25866 | valid_rmse: 0.33433 | valid_mse: 0.11178 |  0:00:49s\n",
      "epoch 27 | loss: 0.11018 | train_rmsle: 0.00701 | train_mae: 0.25464 | train_rmse: 0.32939 | train_mse: 0.1085  | valid_rmsle: 0.00684 | valid_mae: 0.25246 | valid_rmse: 0.3306  | valid_mse: 0.1093  |  0:00:50s\n",
      "epoch 28 | loss: 0.10567 | train_rmsle: 0.00766 | train_mae: 0.27625 | train_rmse: 0.34878 | train_mse: 0.12164 | valid_rmsle: 0.00719 | valid_mae: 0.26707 | valid_rmse: 0.3416  | valid_mse: 0.11669 |  0:00:52s\n",
      "epoch 29 | loss: 0.10427 | train_rmsle: 0.00843 | train_mae: 0.2914  | train_rmse: 0.3654  | train_mse: 0.13352 | valid_rmsle: 0.00777 | valid_mae: 0.27928 | valid_rmse: 0.35407 | valid_mse: 0.12537 |  0:00:54s\n",
      "epoch 30 | loss: 0.10162 | train_rmsle: 0.00708 | train_mae: 0.25953 | train_rmse: 0.33236 | train_mse: 0.11047 | valid_rmsle: 0.00653 | valid_mae: 0.25126 | valid_rmse: 0.32288 | valid_mse: 0.10425 |  0:00:56s\n",
      "epoch 31 | loss: 0.10202 | train_rmsle: 0.00675 | train_mae: 0.24211 | train_rmse: 0.3194  | train_mse: 0.10201 | valid_rmsle: 0.00651 | valid_mae: 0.24401 | valid_rmse: 0.31899 | valid_mse: 0.10175 |  0:00:57s\n",
      "epoch 32 | loss: 0.10128 | train_rmsle: 0.00655 | train_mae: 0.24033 | train_rmse: 0.31486 | train_mse: 0.09914 | valid_rmsle: 0.00624 | valid_mae: 0.23689 | valid_rmse: 0.31144 | valid_mse: 0.09699 |  0:00:59s\n",
      "epoch 33 | loss: 0.10178 | train_rmsle: 0.00685 | train_mae: 0.25241 | train_rmse: 0.32514 | train_mse: 0.10572 | valid_rmsle: 0.00656 | valid_mae: 0.24631 | valid_rmse: 0.3218  | valid_mse: 0.10356 |  0:01:01s\n",
      "epoch 34 | loss: 0.10222 | train_rmsle: 0.00666 | train_mae: 0.24036 | train_rmse: 0.31693 | train_mse: 0.10044 | valid_rmsle: 0.00653 | valid_mae: 0.24111 | valid_rmse: 0.31843 | valid_mse: 0.1014  |  0:01:03s\n",
      "epoch 35 | loss: 0.09868 | train_rmsle: 0.00641 | train_mae: 0.24289 | train_rmse: 0.31251 | train_mse: 0.09766 | valid_rmsle: 0.00617 | valid_mae: 0.23955 | valid_rmse: 0.31082 | valid_mse: 0.09661 |  0:01:05s\n",
      "epoch 36 | loss: 0.09625 | train_rmsle: 0.00677 | train_mae: 0.25064 | train_rmse: 0.32299 | train_mse: 0.10432 | valid_rmsle: 0.00647 | valid_mae: 0.24352 | valid_rmse: 0.31916 | valid_mse: 0.10186 |  0:01:07s\n",
      "epoch 37 | loss: 0.10122 | train_rmsle: 0.0064  | train_mae: 0.24533 | train_rmse: 0.31383 | train_mse: 0.09849 | valid_rmsle: 0.00608 | valid_mae: 0.23825 | valid_rmse: 0.3095  | valid_mse: 0.09579 |  0:01:08s\n",
      "epoch 38 | loss: 0.0987  | train_rmsle: 0.00645 | train_mae: 0.24798 | train_rmse: 0.31579 | train_mse: 0.09972 | valid_rmsle: 0.00613 | valid_mae: 0.24117 | valid_rmse: 0.31129 | valid_mse: 0.0969  |  0:01:10s\n",
      "epoch 39 | loss: 0.09571 | train_rmsle: 0.0062  | train_mae: 0.23559 | train_rmse: 0.30679 | train_mse: 0.09412 | valid_rmsle: 0.00601 | valid_mae: 0.23316 | valid_rmse: 0.30636 | valid_mse: 0.09386 |  0:01:12s\n",
      "epoch 40 | loss: 0.09755 | train_rmsle: 0.00616 | train_mae: 0.23294 | train_rmse: 0.30443 | train_mse: 0.09267 | valid_rmsle: 0.00594 | valid_mae: 0.23099 | valid_rmse: 0.30352 | valid_mse: 0.09212 |  0:01:14s\n",
      "epoch 41 | loss: 0.09326 | train_rmsle: 0.00621 | train_mae: 0.23148 | train_rmse: 0.30521 | train_mse: 0.09315 | valid_rmsle: 0.00609 | valid_mae: 0.23317 | valid_rmse: 0.30682 | valid_mse: 0.09414 |  0:01:16s\n",
      "epoch 42 | loss: 0.09334 | train_rmsle: 0.00613 | train_mae: 0.23397 | train_rmse: 0.30491 | train_mse: 0.09297 | valid_rmsle: 0.00601 | valid_mae: 0.23483 | valid_rmse: 0.3065  | valid_mse: 0.09394 |  0:01:17s\n",
      "epoch 43 | loss: 0.09313 | train_rmsle: 0.00602 | train_mae: 0.2323  | train_rmse: 0.3015  | train_mse: 0.0909  | valid_rmsle: 0.00595 | valid_mae: 0.23315 | valid_rmse: 0.30423 | valid_mse: 0.09255 |  0:01:19s\n",
      "epoch 44 | loss: 0.09248 | train_rmsle: 0.0062  | train_mae: 0.22911 | train_rmse: 0.30451 | train_mse: 0.09273 | valid_rmsle: 0.00615 | valid_mae: 0.23296 | valid_rmse: 0.30838 | valid_mse: 0.0951  |  0:01:21s\n",
      "epoch 45 | loss: 0.09286 | train_rmsle: 0.00615 | train_mae: 0.22894 | train_rmse: 0.30335 | train_mse: 0.09202 | valid_rmsle: 0.00623 | valid_mae: 0.23609 | valid_rmse: 0.31088 | valid_mse: 0.09665 |  0:01:23s\n",
      "epoch 46 | loss: 0.09035 | train_rmsle: 0.00615 | train_mae: 0.24218 | train_rmse: 0.30822 | train_mse: 0.095   | valid_rmsle: 0.00611 | valid_mae: 0.24211 | valid_rmse: 0.31134 | valid_mse: 0.09694 |  0:01:25s\n",
      "epoch 47 | loss: 0.09233 | train_rmsle: 0.00655 | train_mae: 0.23468 | train_rmse: 0.31293 | train_mse: 0.09793 | valid_rmsle: 0.0068  | valid_mae: 0.24684 | valid_rmse: 0.32491 | valid_mse: 0.10557 |  0:01:26s\n",
      "epoch 48 | loss: 0.09816 | train_rmsle: 0.00575 | train_mae: 0.22571 | train_rmse: 0.29441 | train_mse: 0.08668 | valid_rmsle: 0.00588 | valid_mae: 0.23002 | valid_rmse: 0.30204 | valid_mse: 0.09123 |  0:01:28s\n",
      "epoch 49 | loss: 0.09051 | train_rmsle: 0.00575 | train_mae: 0.22403 | train_rmse: 0.29406 | train_mse: 0.08647 | valid_rmsle: 0.00598 | valid_mae: 0.23121 | valid_rmse: 0.3053  | valid_mse: 0.09321 |  0:01:30s\n",
      "epoch 50 | loss: 0.09153 | train_rmsle: 0.00653 | train_mae: 0.23259 | train_rmse: 0.31281 | train_mse: 0.09785 | valid_rmsle: 0.00688 | valid_mae: 0.24606 | valid_rmse: 0.32742 | valid_mse: 0.1072  |  0:01:32s\n",
      "epoch 51 | loss: 0.09011 | train_rmsle: 0.00606 | train_mae: 0.24054 | train_rmse: 0.30666 | train_mse: 0.09404 | valid_rmsle: 0.00622 | valid_mae: 0.24371 | valid_rmse: 0.31517 | valid_mse: 0.09933 |  0:01:34s\n",
      "epoch 52 | loss: 0.08797 | train_rmsle: 0.00594 | train_mae: 0.22641 | train_rmse: 0.29926 | train_mse: 0.08956 | valid_rmsle: 0.00625 | valid_mae: 0.23998 | valid_rmse: 0.31368 | valid_mse: 0.0984  |  0:01:35s\n",
      "epoch 53 | loss: 0.08928 | train_rmsle: 0.00562 | train_mae: 0.23071 | train_rmse: 0.29496 | train_mse: 0.087   | valid_rmsle: 0.00577 | valid_mae: 0.23452 | valid_rmse: 0.30294 | valid_mse: 0.09177 |  0:01:37s\n",
      "epoch 54 | loss: 0.08529 | train_rmsle: 0.00587 | train_mae: 0.24057 | train_rmse: 0.30374 | train_mse: 0.09226 | valid_rmsle: 0.00605 | valid_mae: 0.24494 | valid_rmse: 0.31174 | valid_mse: 0.09718 |  0:01:39s\n",
      "epoch 55 | loss: 0.08578 | train_rmsle: 0.00545 | train_mae: 0.22523 | train_rmse: 0.29009 | train_mse: 0.08415 | valid_rmsle: 0.00575 | valid_mae: 0.23573 | valid_rmse: 0.30273 | valid_mse: 0.09165 |  0:01:41s\n",
      "epoch 56 | loss: 0.0856  | train_rmsle: 0.00548 | train_mae: 0.22314 | train_rmse: 0.29026 | train_mse: 0.08425 | valid_rmsle: 0.00565 | valid_mae: 0.23106 | valid_rmse: 0.29974 | valid_mse: 0.08985 |  0:01:43s\n",
      "epoch 57 | loss: 0.08536 | train_rmsle: 0.00533 | train_mae: 0.22359 | train_rmse: 0.28786 | train_mse: 0.08287 | valid_rmsle: 0.00535 | valid_mae: 0.22822 | valid_rmse: 0.29326 | valid_mse: 0.086   |  0:01:44s\n",
      "epoch 58 | loss: 0.08128 | train_rmsle: 0.00528 | train_mae: 0.22559 | train_rmse: 0.28852 | train_mse: 0.08325 | valid_rmsle: 0.0053  | valid_mae: 0.2305  | valid_rmse: 0.29306 | valid_mse: 0.08588 |  0:01:46s\n",
      "epoch 59 | loss: 0.08193 | train_rmsle: 0.005   | train_mae: 0.22126 | train_rmse: 0.28112 | train_mse: 0.07903 | valid_rmsle: 0.00503 | valid_mae: 0.22866 | valid_rmse: 0.28719 | valid_mse: 0.08248 |  0:01:48s\n",
      "epoch 60 | loss: 0.07712 | train_rmsle: 0.00494 | train_mae: 0.22198 | train_rmse: 0.28111 | train_mse: 0.07902 | valid_rmsle: 0.00499 | valid_mae: 0.22777 | valid_rmse: 0.28676 | valid_mse: 0.08223 |  0:01:50s\n",
      "epoch 61 | loss: 0.07324 | train_rmsle: 0.00568 | train_mae: 0.23399 | train_rmse: 0.29963 | train_mse: 0.08978 | valid_rmsle: 0.00593 | valid_mae: 0.244   | valid_rmse: 0.31082 | valid_mse: 0.09661 |  0:01:52s\n",
      "epoch 62 | loss: 0.06731 | train_rmsle: 0.0045  | train_mae: 0.21151 | train_rmse: 0.26854 | train_mse: 0.07212 | valid_rmsle: 0.00476 | valid_mae: 0.22227 | valid_rmse: 0.28018 | valid_mse: 0.0785  |  0:01:53s\n",
      "epoch 63 | loss: 0.0623  | train_rmsle: 0.00383 | train_mae: 0.18701 | train_rmse: 0.24423 | train_mse: 0.05965 | valid_rmsle: 0.00425 | valid_mae: 0.20543 | valid_rmse: 0.26281 | valid_mse: 0.06907 |  0:01:55s\n",
      "epoch 64 | loss: 0.06061 | train_rmsle: 0.0039  | train_mae: 0.19674 | train_rmse: 0.24995 | train_mse: 0.06247 | valid_rmsle: 0.00427 | valid_mae: 0.21179 | valid_rmse: 0.26622 | valid_mse: 0.07087 |  0:01:57s\n",
      "epoch 65 | loss: 0.05886 | train_rmsle: 0.00361 | train_mae: 0.18751 | train_rmse: 0.2393  | train_mse: 0.05726 | valid_rmsle: 0.00408 | valid_mae: 0.20677 | valid_rmse: 0.25942 | valid_mse: 0.0673  |  0:01:59s\n",
      "epoch 66 | loss: 0.0549  | train_rmsle: 0.00331 | train_mae: 0.17846 | train_rmse: 0.22883 | train_mse: 0.05236 | valid_rmsle: 0.00373 | valid_mae: 0.1968  | valid_rmse: 0.24753 | valid_mse: 0.06127 |  0:02:01s\n",
      "epoch 67 | loss: 0.05342 | train_rmsle: 0.00361 | train_mae: 0.19256 | train_rmse: 0.24164 | train_mse: 0.05839 | valid_rmsle: 0.00401 | valid_mae: 0.2079  | valid_rmse: 0.25865 | valid_mse: 0.0669  |  0:02:03s\n",
      "epoch 68 | loss: 0.0506  | train_rmsle: 0.00287 | train_mae: 0.16159 | train_rmse: 0.21105 | train_mse: 0.04454 | valid_rmsle: 0.00339 | valid_mae: 0.18643 | valid_rmse: 0.23584 | valid_mse: 0.05562 |  0:02:04s\n",
      "epoch 69 | loss: 0.05372 | train_rmsle: 0.00293 | train_mae: 0.16808 | train_rmse: 0.21569 | train_mse: 0.04652 | valid_rmsle: 0.00342 | valid_mae: 0.19013 | valid_rmse: 0.23792 | valid_mse: 0.0566  |  0:02:06s\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.05562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05967626745017631 RMSE: 0.24428726419970467 R2: 0.7358361583723887 MAE: 0.1901702966763154\n",
      "=====================================\n",
      "[98/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.55594 | train_rmsle: 0.09477 | train_mae: 1.08757 | train_rmse: 1.17947 | train_mse: 1.39116 | valid_rmsle: 0.09529 | valid_mae: 1.09056 | valid_rmse: 1.18399 | valid_mse: 1.40182 |  0:00:01s\n",
      "epoch 1  | loss: 0.57373 | train_rmsle: 0.07849 | train_mae: 1.00133 | train_rmse: 1.08985 | train_mse: 1.18777 | valid_rmsle: 0.07876 | valid_mae: 1.00408 | valid_rmse: 1.09323 | valid_mse: 1.19514 |  0:00:03s\n",
      "epoch 2  | loss: 0.40217 | train_rmsle: 0.05229 | train_mae: 0.82326 | train_rmse: 0.91588 | train_mse: 0.83883 | valid_rmsle: 0.05239 | valid_mae: 0.82398 | valid_rmse: 0.91877 | valid_mse: 0.84414 |  0:00:05s\n",
      "epoch 3  | loss: 0.42356 | train_rmsle: 0.07212 | train_mae: 0.96028 | train_rmse: 1.05172 | train_mse: 1.10611 | valid_rmsle: 0.07233 | valid_mae: 0.96234 | valid_rmse: 1.05488 | valid_mse: 1.11277 |  0:00:07s\n",
      "epoch 4  | loss: 0.59322 | train_rmsle: 0.01688 | train_mae: 0.44366 | train_rmse: 0.53286 | train_mse: 0.28394 | valid_rmsle: 0.0164  | valid_mae: 0.44431 | valid_rmse: 0.53019 | valid_mse: 0.2811  |  0:00:09s\n",
      "epoch 5  | loss: 0.85333 | train_rmsle: 0.15492 | train_mae: 1.35952 | train_rmse: 1.43822 | train_mse: 2.06848 | valid_rmsle: 0.15587 | valid_mae: 1.36455 | valid_rmse: 1.44344 | valid_mse: 2.08352 |  0:00:10s\n",
      "epoch 6  | loss: 0.76832 | train_rmsle: 0.02088 | train_mae: 0.50611 | train_rmse: 0.59707 | train_mse: 0.35649 | valid_rmsle: 0.02038 | valid_mae: 0.50604 | valid_rmse: 0.5943  | valid_mse: 0.3532  |  0:00:12s\n",
      "epoch 7  | loss: 0.2555  | train_rmsle: 0.02383 | train_mae: 0.54629 | train_rmse: 0.63821 | train_mse: 0.40731 | valid_rmsle: 0.02367 | valid_mae: 0.54425 | valid_rmse: 0.63979 | valid_mse: 0.40934 |  0:00:14s\n",
      "epoch 8  | loss: 0.26065 | train_rmsle: 0.0152  | train_mae: 0.41181 | train_rmse: 0.50165 | train_mse: 0.25166 | valid_rmsle: 0.0146  | valid_mae: 0.41094 | valid_rmse: 0.49681 | valid_mse: 0.24682 |  0:00:16s\n",
      "epoch 9  | loss: 0.25261 | train_rmsle: 0.02005 | train_mae: 0.49388 | train_rmse: 0.58552 | train_mse: 0.34284 | valid_rmsle: 0.01975 | valid_mae: 0.49518 | valid_rmse: 0.58518 | valid_mse: 0.34243 |  0:00:18s\n",
      "epoch 10 | loss: 0.23398 | train_rmsle: 0.01573 | train_mae: 0.42017 | train_rmse: 0.51222 | train_mse: 0.26237 | valid_rmsle: 0.01553 | valid_mae: 0.42696 | valid_rmse: 0.51432 | valid_mse: 0.26453 |  0:00:19s\n",
      "epoch 11 | loss: 0.23575 | train_rmsle: 0.02414 | train_mae: 0.55162 | train_rmse: 0.64235 | train_mse: 0.41262 | valid_rmsle: 0.02393 | valid_mae: 0.55197 | valid_rmse: 0.64328 | valid_mse: 0.41381 |  0:00:21s\n",
      "epoch 12 | loss: 0.23768 | train_rmsle: 0.01525 | train_mae: 0.41526 | train_rmse: 0.50502 | train_mse: 0.25504 | valid_rmsle: 0.01471 | valid_mae: 0.41353 | valid_rmse: 0.50129 | valid_mse: 0.25129 |  0:00:23s\n",
      "epoch 13 | loss: 0.22476 | train_rmsle: 0.01575 | train_mae: 0.42333 | train_rmse: 0.51478 | train_mse: 0.26499 | valid_rmsle: 0.01517 | valid_mae: 0.42311 | valid_rmse: 0.51081 | valid_mse: 0.26093 |  0:00:25s\n",
      "epoch 14 | loss: 0.2229  | train_rmsle: 0.01459 | train_mae: 0.40113 | train_rmse: 0.49174 | train_mse: 0.24181 | valid_rmsle: 0.01396 | valid_mae: 0.40054 | valid_rmse: 0.48669 | valid_mse: 0.23686 |  0:00:27s\n",
      "epoch 15 | loss: 0.2305  | train_rmsle: 0.01856 | train_mae: 0.47321 | train_rmse: 0.5634  | train_mse: 0.31742 | valid_rmsle: 0.0181  | valid_mae: 0.47009 | valid_rmse: 0.56096 | valid_mse: 0.31467 |  0:00:28s\n",
      "epoch 16 | loss: 0.21748 | train_rmsle: 0.01402 | train_mae: 0.36883 | train_rmse: 0.47081 | train_mse: 0.22166 | valid_rmsle: 0.01313 | valid_mae: 0.36592 | valid_rmse: 0.46003 | valid_mse: 0.21163 |  0:00:30s\n",
      "epoch 17 | loss: 0.21772 | train_rmsle: 0.01467 | train_mae: 0.40197 | train_rmse: 0.49256 | train_mse: 0.24262 | valid_rmsle: 0.01396 | valid_mae: 0.40023 | valid_rmse: 0.4852  | valid_mse: 0.23542 |  0:00:32s\n",
      "epoch 18 | loss: 0.21621 | train_rmsle: 0.0129  | train_mae: 0.3683  | train_rmse: 0.45771 | train_mse: 0.2095  | valid_rmsle: 0.01217 | valid_mae: 0.36263 | valid_rmse: 0.44897 | valid_mse: 0.20158 |  0:00:34s\n",
      "epoch 19 | loss: 0.20151 | train_rmsle: 0.01303 | train_mae: 0.37542 | train_rmse: 0.46256 | train_mse: 0.21396 | valid_rmsle: 0.01219 | valid_mae: 0.36973 | valid_rmse: 0.45195 | valid_mse: 0.20425 |  0:00:36s\n",
      "epoch 20 | loss: 0.19248 | train_rmsle: 0.01143 | train_mae: 0.33447 | train_rmse: 0.42664 | train_mse: 0.18202 | valid_rmsle: 0.01086 | valid_mae: 0.33076 | valid_rmse: 0.42014 | valid_mse: 0.17652 |  0:00:38s\n",
      "epoch 21 | loss: 0.18073 | train_rmsle: 0.01055 | train_mae: 0.32258 | train_rmse: 0.41182 | train_mse: 0.1696  | valid_rmsle: 0.0102  | valid_mae: 0.3187  | valid_rmse: 0.40765 | valid_mse: 0.16618 |  0:00:39s\n",
      "epoch 22 | loss: 0.16616 | train_rmsle: 0.00987 | train_mae: 0.31477 | train_rmse: 0.39876 | train_mse: 0.15901 | valid_rmsle: 0.00944 | valid_mae: 0.3077  | valid_rmse: 0.39448 | valid_mse: 0.15562 |  0:00:41s\n",
      "epoch 23 | loss: 0.14507 | train_rmsle: 0.00852 | train_mae: 0.27877 | train_rmse: 0.36435 | train_mse: 0.13275 | valid_rmsle: 0.00836 | valid_mae: 0.27705 | valid_rmse: 0.36477 | valid_mse: 0.13306 |  0:00:43s\n",
      "epoch 24 | loss: 0.13086 | train_rmsle: 0.00777 | train_mae: 0.26229 | train_rmse: 0.34525 | train_mse: 0.1192  | valid_rmsle: 0.00732 | valid_mae: 0.25767 | valid_rmse: 0.34002 | valid_mse: 0.11561 |  0:00:45s\n",
      "epoch 25 | loss: 0.11568 | train_rmsle: 0.00756 | train_mae: 0.263   | train_rmse: 0.34255 | train_mse: 0.11734 | valid_rmsle: 0.00711 | valid_mae: 0.2583  | valid_rmse: 0.33773 | valid_mse: 0.11406 |  0:00:47s\n",
      "epoch 26 | loss: 0.1138  | train_rmsle: 0.00728 | train_mae: 0.26275 | train_rmse: 0.3375  | train_mse: 0.11391 | valid_rmsle: 0.00696 | valid_mae: 0.25866 | valid_rmse: 0.33433 | valid_mse: 0.11178 |  0:00:48s\n",
      "epoch 27 | loss: 0.11018 | train_rmsle: 0.00701 | train_mae: 0.25464 | train_rmse: 0.32939 | train_mse: 0.1085  | valid_rmsle: 0.00684 | valid_mae: 0.25246 | valid_rmse: 0.3306  | valid_mse: 0.1093  |  0:00:50s\n",
      "epoch 28 | loss: 0.10567 | train_rmsle: 0.00766 | train_mae: 0.27625 | train_rmse: 0.34878 | train_mse: 0.12164 | valid_rmsle: 0.00719 | valid_mae: 0.26707 | valid_rmse: 0.3416  | valid_mse: 0.11669 |  0:00:52s\n",
      "epoch 29 | loss: 0.10427 | train_rmsle: 0.00843 | train_mae: 0.2914  | train_rmse: 0.3654  | train_mse: 0.13352 | valid_rmsle: 0.00777 | valid_mae: 0.27928 | valid_rmse: 0.35407 | valid_mse: 0.12537 |  0:00:54s\n",
      "epoch 30 | loss: 0.10162 | train_rmsle: 0.00708 | train_mae: 0.25953 | train_rmse: 0.33236 | train_mse: 0.11047 | valid_rmsle: 0.00653 | valid_mae: 0.25126 | valid_rmse: 0.32288 | valid_mse: 0.10425 |  0:00:56s\n",
      "epoch 31 | loss: 0.10202 | train_rmsle: 0.00675 | train_mae: 0.24211 | train_rmse: 0.3194  | train_mse: 0.10201 | valid_rmsle: 0.00651 | valid_mae: 0.24401 | valid_rmse: 0.31899 | valid_mse: 0.10175 |  0:00:57s\n",
      "epoch 32 | loss: 0.10128 | train_rmsle: 0.00655 | train_mae: 0.24033 | train_rmse: 0.31486 | train_mse: 0.09914 | valid_rmsle: 0.00624 | valid_mae: 0.23689 | valid_rmse: 0.31144 | valid_mse: 0.09699 |  0:00:59s\n",
      "epoch 33 | loss: 0.10178 | train_rmsle: 0.00685 | train_mae: 0.25241 | train_rmse: 0.32514 | train_mse: 0.10572 | valid_rmsle: 0.00656 | valid_mae: 0.24631 | valid_rmse: 0.3218  | valid_mse: 0.10356 |  0:01:01s\n",
      "epoch 34 | loss: 0.10222 | train_rmsle: 0.00666 | train_mae: 0.24036 | train_rmse: 0.31693 | train_mse: 0.10044 | valid_rmsle: 0.00653 | valid_mae: 0.24111 | valid_rmse: 0.31843 | valid_mse: 0.1014  |  0:01:03s\n",
      "epoch 35 | loss: 0.09868 | train_rmsle: 0.00641 | train_mae: 0.24289 | train_rmse: 0.31251 | train_mse: 0.09766 | valid_rmsle: 0.00617 | valid_mae: 0.23955 | valid_rmse: 0.31082 | valid_mse: 0.09661 |  0:01:05s\n",
      "epoch 36 | loss: 0.09625 | train_rmsle: 0.00677 | train_mae: 0.25064 | train_rmse: 0.32299 | train_mse: 0.10432 | valid_rmsle: 0.00647 | valid_mae: 0.24352 | valid_rmse: 0.31916 | valid_mse: 0.10186 |  0:01:07s\n",
      "epoch 37 | loss: 0.10122 | train_rmsle: 0.0064  | train_mae: 0.24533 | train_rmse: 0.31383 | train_mse: 0.09849 | valid_rmsle: 0.00608 | valid_mae: 0.23825 | valid_rmse: 0.3095  | valid_mse: 0.09579 |  0:01:08s\n",
      "epoch 38 | loss: 0.0987  | train_rmsle: 0.00645 | train_mae: 0.24798 | train_rmse: 0.31579 | train_mse: 0.09972 | valid_rmsle: 0.00613 | valid_mae: 0.24117 | valid_rmse: 0.31129 | valid_mse: 0.0969  |  0:01:10s\n",
      "epoch 39 | loss: 0.09571 | train_rmsle: 0.0062  | train_mae: 0.23559 | train_rmse: 0.30679 | train_mse: 0.09412 | valid_rmsle: 0.00601 | valid_mae: 0.23316 | valid_rmse: 0.30636 | valid_mse: 0.09386 |  0:01:12s\n",
      "epoch 40 | loss: 0.09755 | train_rmsle: 0.00616 | train_mae: 0.23294 | train_rmse: 0.30443 | train_mse: 0.09267 | valid_rmsle: 0.00594 | valid_mae: 0.23099 | valid_rmse: 0.30352 | valid_mse: 0.09212 |  0:01:14s\n",
      "epoch 41 | loss: 0.09326 | train_rmsle: 0.00621 | train_mae: 0.23148 | train_rmse: 0.30521 | train_mse: 0.09315 | valid_rmsle: 0.00609 | valid_mae: 0.23317 | valid_rmse: 0.30682 | valid_mse: 0.09414 |  0:01:16s\n",
      "epoch 42 | loss: 0.09334 | train_rmsle: 0.00613 | train_mae: 0.23397 | train_rmse: 0.30491 | train_mse: 0.09297 | valid_rmsle: 0.00601 | valid_mae: 0.23483 | valid_rmse: 0.3065  | valid_mse: 0.09394 |  0:01:17s\n",
      "epoch 43 | loss: 0.09313 | train_rmsle: 0.00602 | train_mae: 0.2323  | train_rmse: 0.3015  | train_mse: 0.0909  | valid_rmsle: 0.00595 | valid_mae: 0.23315 | valid_rmse: 0.30423 | valid_mse: 0.09255 |  0:01:19s\n",
      "epoch 44 | loss: 0.09248 | train_rmsle: 0.0062  | train_mae: 0.22911 | train_rmse: 0.30451 | train_mse: 0.09273 | valid_rmsle: 0.00615 | valid_mae: 0.23296 | valid_rmse: 0.30838 | valid_mse: 0.0951  |  0:01:21s\n",
      "epoch 45 | loss: 0.09286 | train_rmsle: 0.00615 | train_mae: 0.22894 | train_rmse: 0.30335 | train_mse: 0.09202 | valid_rmsle: 0.00623 | valid_mae: 0.23609 | valid_rmse: 0.31088 | valid_mse: 0.09665 |  0:01:23s\n",
      "epoch 46 | loss: 0.09035 | train_rmsle: 0.00615 | train_mae: 0.24218 | train_rmse: 0.30822 | train_mse: 0.095   | valid_rmsle: 0.00611 | valid_mae: 0.24211 | valid_rmse: 0.31134 | valid_mse: 0.09694 |  0:01:25s\n",
      "epoch 47 | loss: 0.09233 | train_rmsle: 0.00655 | train_mae: 0.23468 | train_rmse: 0.31293 | train_mse: 0.09793 | valid_rmsle: 0.0068  | valid_mae: 0.24684 | valid_rmse: 0.32491 | valid_mse: 0.10557 |  0:01:26s\n",
      "epoch 48 | loss: 0.09816 | train_rmsle: 0.00575 | train_mae: 0.22571 | train_rmse: 0.29441 | train_mse: 0.08668 | valid_rmsle: 0.00588 | valid_mae: 0.23002 | valid_rmse: 0.30204 | valid_mse: 0.09123 |  0:01:28s\n",
      "epoch 49 | loss: 0.09051 | train_rmsle: 0.00575 | train_mae: 0.22403 | train_rmse: 0.29406 | train_mse: 0.08647 | valid_rmsle: 0.00598 | valid_mae: 0.23121 | valid_rmse: 0.3053  | valid_mse: 0.09321 |  0:01:30s\n",
      "epoch 50 | loss: 0.09153 | train_rmsle: 0.00653 | train_mae: 0.23259 | train_rmse: 0.31281 | train_mse: 0.09785 | valid_rmsle: 0.00688 | valid_mae: 0.24606 | valid_rmse: 0.32742 | valid_mse: 0.1072  |  0:01:32s\n",
      "epoch 51 | loss: 0.09011 | train_rmsle: 0.00606 | train_mae: 0.24054 | train_rmse: 0.30666 | train_mse: 0.09404 | valid_rmsle: 0.00622 | valid_mae: 0.24371 | valid_rmse: 0.31517 | valid_mse: 0.09933 |  0:01:34s\n",
      "epoch 52 | loss: 0.08797 | train_rmsle: 0.00594 | train_mae: 0.22641 | train_rmse: 0.29926 | train_mse: 0.08956 | valid_rmsle: 0.00625 | valid_mae: 0.23998 | valid_rmse: 0.31368 | valid_mse: 0.0984  |  0:01:36s\n",
      "epoch 53 | loss: 0.08928 | train_rmsle: 0.00562 | train_mae: 0.23071 | train_rmse: 0.29496 | train_mse: 0.087   | valid_rmsle: 0.00577 | valid_mae: 0.23452 | valid_rmse: 0.30294 | valid_mse: 0.09177 |  0:01:37s\n",
      "epoch 54 | loss: 0.08529 | train_rmsle: 0.00587 | train_mae: 0.24057 | train_rmse: 0.30374 | train_mse: 0.09226 | valid_rmsle: 0.00605 | valid_mae: 0.24494 | valid_rmse: 0.31174 | valid_mse: 0.09718 |  0:01:39s\n",
      "epoch 55 | loss: 0.08578 | train_rmsle: 0.00545 | train_mae: 0.22523 | train_rmse: 0.29009 | train_mse: 0.08415 | valid_rmsle: 0.00575 | valid_mae: 0.23573 | valid_rmse: 0.30273 | valid_mse: 0.09165 |  0:01:41s\n",
      "epoch 56 | loss: 0.0856  | train_rmsle: 0.00548 | train_mae: 0.22314 | train_rmse: 0.29026 | train_mse: 0.08425 | valid_rmsle: 0.00565 | valid_mae: 0.23106 | valid_rmse: 0.29974 | valid_mse: 0.08985 |  0:01:43s\n",
      "epoch 57 | loss: 0.08536 | train_rmsle: 0.00533 | train_mae: 0.22359 | train_rmse: 0.28786 | train_mse: 0.08287 | valid_rmsle: 0.00535 | valid_mae: 0.22822 | valid_rmse: 0.29326 | valid_mse: 0.086   |  0:01:45s\n",
      "epoch 58 | loss: 0.08128 | train_rmsle: 0.00528 | train_mae: 0.22559 | train_rmse: 0.28852 | train_mse: 0.08325 | valid_rmsle: 0.0053  | valid_mae: 0.2305  | valid_rmse: 0.29306 | valid_mse: 0.08588 |  0:01:46s\n",
      "epoch 59 | loss: 0.08193 | train_rmsle: 0.005   | train_mae: 0.22126 | train_rmse: 0.28112 | train_mse: 0.07903 | valid_rmsle: 0.00503 | valid_mae: 0.22866 | valid_rmse: 0.28719 | valid_mse: 0.08248 |  0:01:48s\n",
      "epoch 60 | loss: 0.07712 | train_rmsle: 0.00494 | train_mae: 0.22198 | train_rmse: 0.28111 | train_mse: 0.07902 | valid_rmsle: 0.00499 | valid_mae: 0.22777 | valid_rmse: 0.28676 | valid_mse: 0.08223 |  0:01:50s\n",
      "epoch 61 | loss: 0.07324 | train_rmsle: 0.00568 | train_mae: 0.23399 | train_rmse: 0.29963 | train_mse: 0.08978 | valid_rmsle: 0.00593 | valid_mae: 0.244   | valid_rmse: 0.31082 | valid_mse: 0.09661 |  0:01:52s\n",
      "epoch 62 | loss: 0.06731 | train_rmsle: 0.0045  | train_mae: 0.21151 | train_rmse: 0.26854 | train_mse: 0.07212 | valid_rmsle: 0.00476 | valid_mae: 0.22227 | valid_rmse: 0.28018 | valid_mse: 0.0785  |  0:01:54s\n",
      "epoch 63 | loss: 0.0623  | train_rmsle: 0.00383 | train_mae: 0.18701 | train_rmse: 0.24423 | train_mse: 0.05965 | valid_rmsle: 0.00425 | valid_mae: 0.20543 | valid_rmse: 0.26281 | valid_mse: 0.06907 |  0:01:55s\n",
      "epoch 64 | loss: 0.06061 | train_rmsle: 0.0039  | train_mae: 0.19674 | train_rmse: 0.24995 | train_mse: 0.06247 | valid_rmsle: 0.00427 | valid_mae: 0.21179 | valid_rmse: 0.26622 | valid_mse: 0.07087 |  0:01:57s\n",
      "epoch 65 | loss: 0.05886 | train_rmsle: 0.00361 | train_mae: 0.18751 | train_rmse: 0.2393  | train_mse: 0.05726 | valid_rmsle: 0.00408 | valid_mae: 0.20677 | valid_rmse: 0.25942 | valid_mse: 0.0673  |  0:01:59s\n",
      "epoch 66 | loss: 0.0549  | train_rmsle: 0.00331 | train_mae: 0.17846 | train_rmse: 0.22883 | train_mse: 0.05236 | valid_rmsle: 0.00373 | valid_mae: 0.1968  | valid_rmse: 0.24753 | valid_mse: 0.06127 |  0:02:01s\n",
      "epoch 67 | loss: 0.05342 | train_rmsle: 0.00361 | train_mae: 0.19256 | train_rmse: 0.24164 | train_mse: 0.05839 | valid_rmsle: 0.00401 | valid_mae: 0.2079  | valid_rmse: 0.25865 | valid_mse: 0.0669  |  0:02:03s\n",
      "epoch 68 | loss: 0.0506  | train_rmsle: 0.00287 | train_mae: 0.16159 | train_rmse: 0.21105 | train_mse: 0.04454 | valid_rmsle: 0.00339 | valid_mae: 0.18643 | valid_rmse: 0.23584 | valid_mse: 0.05562 |  0:02:04s\n",
      "epoch 69 | loss: 0.05372 | train_rmsle: 0.00293 | train_mae: 0.16808 | train_rmse: 0.21569 | train_mse: 0.04652 | valid_rmsle: 0.00342 | valid_mae: 0.19013 | valid_rmse: 0.23792 | valid_mse: 0.0566  |  0:02:06s\n",
      "epoch 70 | loss: 0.0501  | train_rmsle: 0.00269 | train_mae: 0.15789 | train_rmse: 0.20481 | train_mse: 0.04195 | valid_rmsle: 0.00329 | valid_mae: 0.18479 | valid_rmse: 0.23285 | valid_mse: 0.05422 |  0:02:08s\n",
      "epoch 71 | loss: 0.04745 | train_rmsle: 0.00337 | train_mae: 0.19004 | train_rmse: 0.23506 | train_mse: 0.05525 | valid_rmsle: 0.00388 | valid_mae: 0.20675 | valid_rmse: 0.25563 | valid_mse: 0.06535 |  0:02:10s\n",
      "epoch 72 | loss: 0.04619 | train_rmsle: 0.00234 | train_mae: 0.14405 | train_rmse: 0.19065 | train_mse: 0.03635 | valid_rmsle: 0.00297 | valid_mae: 0.17577 | valid_rmse: 0.22205 | valid_mse: 0.04931 |  0:02:12s\n",
      "epoch 73 | loss: 0.04198 | train_rmsle: 0.00237 | train_mae: 0.14316 | train_rmse: 0.19133 | train_mse: 0.03661 | valid_rmsle: 0.00302 | valid_mae: 0.17487 | valid_rmse: 0.22437 | valid_mse: 0.05034 |  0:02:13s\n",
      "epoch 74 | loss: 0.04007 | train_rmsle: 0.00223 | train_mae: 0.14289 | train_rmse: 0.18715 | train_mse: 0.03503 | valid_rmsle: 0.00283 | valid_mae: 0.17271 | valid_rmse: 0.21807 | valid_mse: 0.04755 |  0:02:15s\n",
      "epoch 75 | loss: 0.03712 | train_rmsle: 0.00234 | train_mae: 0.15118 | train_rmse: 0.19445 | train_mse: 0.03781 | valid_rmsle: 0.00285 | valid_mae: 0.17701 | valid_rmse: 0.22023 | valid_mse: 0.0485  |  0:02:17s\n",
      "epoch 76 | loss: 0.03713 | train_rmsle: 0.00206 | train_mae: 0.13392 | train_rmse: 0.17917 | train_mse: 0.0321  | valid_rmsle: 0.00267 | valid_mae: 0.16708 | valid_rmse: 0.21321 | valid_mse: 0.04546 |  0:02:19s\n",
      "epoch 77 | loss: 0.03492 | train_rmsle: 0.00195 | train_mae: 0.13324 | train_rmse: 0.17516 | train_mse: 0.03068 | valid_rmsle: 0.00253 | valid_mae: 0.16511 | valid_rmse: 0.20706 | valid_mse: 0.04287 |  0:02:21s\n",
      "epoch 78 | loss: 0.03155 | train_rmsle: 0.00175 | train_mae: 0.12319 | train_rmse: 0.16491 | train_mse: 0.02719 | valid_rmsle: 0.0023  | valid_mae: 0.15573 | valid_rmse: 0.197   | valid_mse: 0.03881 |  0:02:23s\n",
      "epoch 79 | loss: 0.03048 | train_rmsle: 0.00179 | train_mae: 0.12802 | train_rmse: 0.16828 | train_mse: 0.02832 | valid_rmsle: 0.00228 | valid_mae: 0.15654 | valid_rmse: 0.19717 | valid_mse: 0.03888 |  0:02:24s\n",
      "epoch 80 | loss: 0.02965 | train_rmsle: 0.00169 | train_mae: 0.12328 | train_rmse: 0.16346 | train_mse: 0.02672 | valid_rmsle: 0.00218 | valid_mae: 0.15237 | valid_rmse: 0.1929  | valid_mse: 0.03721 |  0:02:26s\n",
      "epoch 81 | loss: 0.03215 | train_rmsle: 0.00152 | train_mae: 0.11471 | train_rmse: 0.15364 | train_mse: 0.02361 | valid_rmsle: 0.00204 | valid_mae: 0.14578 | valid_rmse: 0.1861  | valid_mse: 0.03463 |  0:02:28s\n",
      "epoch 82 | loss: 0.02931 | train_rmsle: 0.0027  | train_mae: 0.17719 | train_rmse: 0.21248 | train_mse: 0.04515 | valid_rmsle: 0.00316 | valid_mae: 0.18983 | valid_rmse: 0.23345 | valid_mse: 0.0545  |  0:02:30s\n",
      "epoch 83 | loss: 0.03296 | train_rmsle: 0.00143 | train_mae: 0.11272 | train_rmse: 0.15055 | train_mse: 0.02267 | valid_rmsle: 0.002   | valid_mae: 0.14533 | valid_rmse: 0.18585 | valid_mse: 0.03454 |  0:02:32s\n",
      "epoch 84 | loss: 0.02925 | train_rmsle: 0.00207 | train_mae: 0.14886 | train_rmse: 0.18446 | train_mse: 0.03402 | valid_rmsle: 0.00248 | valid_mae: 0.16594 | valid_rmse: 0.2066  | valid_mse: 0.04268 |  0:02:33s\n",
      "epoch 85 | loss: 0.02714 | train_rmsle: 0.00124 | train_mae: 0.10341 | train_rmse: 0.13935 | train_mse: 0.01942 | valid_rmsle: 0.00172 | valid_mae: 0.13348 | valid_rmse: 0.17177 | valid_mse: 0.02951 |  0:02:35s\n",
      "epoch 86 | loss: 0.02434 | train_rmsle: 0.00154 | train_mae: 0.12536 | train_rmse: 0.16105 | train_mse: 0.02594 | valid_rmsle: 0.00201 | valid_mae: 0.14874 | valid_rmse: 0.18825 | valid_mse: 0.03544 |  0:02:37s\n",
      "epoch 87 | loss: 0.02579 | train_rmsle: 0.00111 | train_mae: 0.09803 | train_rmse: 0.13293 | train_mse: 0.01767 | valid_rmsle: 0.00165 | valid_mae: 0.13057 | valid_rmse: 0.16913 | valid_mse: 0.0286  |  0:02:39s\n",
      "epoch 88 | loss: 0.02431 | train_rmsle: 0.00113 | train_mae: 0.10055 | train_rmse: 0.13497 | train_mse: 0.01822 | valid_rmsle: 0.00166 | valid_mae: 0.13258 | valid_rmse: 0.16999 | valid_mse: 0.0289  |  0:02:41s\n",
      "epoch 89 | loss: 0.0276  | train_rmsle: 0.00128 | train_mae: 0.11252 | train_rmse: 0.14543 | train_mse: 0.02115 | valid_rmsle: 0.00183 | valid_mae: 0.14017 | valid_rmse: 0.17874 | valid_mse: 0.03195 |  0:02:42s\n",
      "epoch 90 | loss: 0.02384 | train_rmsle: 0.00131 | train_mae: 0.11539 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00185 | valid_mae: 0.14274 | valid_rmse: 0.18009 | valid_mse: 0.03243 |  0:02:44s\n",
      "epoch 91 | loss: 0.024   | train_rmsle: 0.00098 | train_mae: 0.09156 | train_rmse: 0.124   | train_mse: 0.01538 | valid_rmsle: 0.00155 | valid_mae: 0.12585 | valid_rmse: 0.16374 | valid_mse: 0.02681 |  0:02:46s\n",
      "epoch 92 | loss: 0.02099 | train_rmsle: 0.00095 | train_mae: 0.09185 | train_rmse: 0.12379 | train_mse: 0.01532 | valid_rmsle: 0.00157 | valid_mae: 0.12755 | valid_rmse: 0.16593 | valid_mse: 0.02753 |  0:02:48s\n",
      "epoch 93 | loss: 0.0197  | train_rmsle: 0.00125 | train_mae: 0.11255 | train_rmse: 0.1428  | train_mse: 0.02039 | valid_rmsle: 0.00177 | valid_mae: 0.13788 | valid_rmse: 0.17449 | valid_mse: 0.03045 |  0:02:50s\n",
      "epoch 94 | loss: 0.02551 | train_rmsle: 0.00131 | train_mae: 0.12019 | train_rmse: 0.15024 | train_mse: 0.02257 | valid_rmsle: 0.00182 | valid_mae: 0.14301 | valid_rmse: 0.17963 | valid_mse: 0.03227 |  0:02:51s\n",
      "epoch 95 | loss: 0.02509 | train_rmsle: 0.00084 | train_mae: 0.08602 | train_rmse: 0.11581 | train_mse: 0.01341 | valid_rmsle: 0.00138 | valid_mae: 0.11858 | valid_rmse: 0.15547 | valid_mse: 0.02417 |  0:02:53s\n",
      "epoch 96 | loss: 0.02149 | train_rmsle: 0.00086 | train_mae: 0.08756 | train_rmse: 0.11811 | train_mse: 0.01395 | valid_rmsle: 0.00142 | valid_mae: 0.12121 | valid_rmse: 0.15879 | valid_mse: 0.02521 |  0:02:55s\n",
      "epoch 97 | loss: 0.02045 | train_rmsle: 0.00082 | train_mae: 0.08624 | train_rmse: 0.11526 | train_mse: 0.01328 | valid_rmsle: 0.00132 | valid_mae: 0.11649 | valid_rmse: 0.15163 | valid_mse: 0.02299 |  0:02:57s\n",
      "epoch 98 | loss: 0.01686 | train_rmsle: 0.0008  | train_mae: 0.08799 | train_rmse: 0.11651 | train_mse: 0.01358 | valid_rmsle: 0.00133 | valid_mae: 0.11855 | valid_rmse: 0.1533  | valid_mse: 0.0235  |  0:02:59s\n",
      "epoch 99 | loss: 0.01855 | train_rmsle: 0.00077 | train_mae: 0.08557 | train_rmse: 0.11254 | train_mse: 0.01267 | valid_rmsle: 0.0013  | valid_mae: 0.11563 | valid_rmse: 0.14997 | valid_mse: 0.02249 |  0:03:00s\n",
      "epoch 100| loss: 0.01848 | train_rmsle: 0.00079 | train_mae: 0.0867  | train_rmse: 0.11372 | train_mse: 0.01293 | valid_rmsle: 0.00136 | valid_mae: 0.11726 | valid_rmse: 0.15324 | valid_mse: 0.02348 |  0:03:02s\n",
      "epoch 101| loss: 0.01793 | train_rmsle: 0.00079 | train_mae: 0.09132 | train_rmse: 0.11785 | train_mse: 0.01389 | valid_rmsle: 0.00137 | valid_mae: 0.12028 | valid_rmse: 0.15551 | valid_mse: 0.02418 |  0:03:04s\n",
      "epoch 102| loss: 0.0171  | train_rmsle: 0.00096 | train_mae: 0.09808 | train_rmse: 0.12408 | train_mse: 0.01539 | valid_rmsle: 0.00151 | valid_mae: 0.12621 | valid_rmse: 0.16147 | valid_mse: 0.02607 |  0:03:06s\n",
      "epoch 103| loss: 0.01573 | train_rmsle: 0.00062 | train_mae: 0.07734 | train_rmse: 0.10214 | train_mse: 0.01043 | valid_rmsle: 0.00121 | valid_mae: 0.11151 | valid_rmse: 0.14521 | valid_mse: 0.02108 |  0:03:08s\n",
      "epoch 104| loss: 0.01685 | train_rmsle: 0.00111 | train_mae: 0.11673 | train_rmse: 0.14173 | train_mse: 0.02009 | valid_rmsle: 0.00166 | valid_mae: 0.13676 | valid_rmse: 0.17239 | valid_mse: 0.02972 |  0:03:09s\n",
      "epoch 105| loss: 0.01941 | train_rmsle: 0.00109 | train_mae: 0.09183 | train_rmse: 0.12217 | train_mse: 0.01493 | valid_rmsle: 0.00174 | valid_mae: 0.1194  | valid_rmse: 0.15997 | valid_mse: 0.02559 |  0:03:11s\n",
      "epoch 106| loss: 0.01412 | train_rmsle: 0.00066 | train_mae: 0.08411 | train_rmse: 0.10862 | train_mse: 0.0118  | valid_rmsle: 0.00115 | valid_mae: 0.11097 | valid_rmse: 0.14284 | valid_mse: 0.0204  |  0:03:13s\n",
      "epoch 107| loss: 0.0151  | train_rmsle: 0.00085 | train_mae: 0.08763 | train_rmse: 0.11364 | train_mse: 0.01291 | valid_rmsle: 0.00147 | valid_mae: 0.11505 | valid_rmse: 0.15303 | valid_mse: 0.02342 |  0:03:15s\n",
      "epoch 108| loss: 0.01987 | train_rmsle: 0.00054 | train_mae: 0.0697  | train_rmse: 0.09423 | train_mse: 0.00888 | valid_rmsle: 0.00106 | valid_mae: 0.10272 | valid_rmse: 0.13593 | valid_mse: 0.01848 |  0:03:17s\n",
      "epoch 109| loss: 0.01696 | train_rmsle: 0.00057 | train_mae: 0.07377 | train_rmse: 0.09673 | train_mse: 0.00936 | valid_rmsle: 0.00113 | valid_mae: 0.10465 | valid_rmse: 0.13788 | valid_mse: 0.01901 |  0:03:18s\n",
      "epoch 110| loss: 0.01558 | train_rmsle: 0.00051 | train_mae: 0.0695  | train_rmse: 0.09223 | train_mse: 0.00851 | valid_rmsle: 0.00102 | valid_mae: 0.1007  | valid_rmse: 0.133   | valid_mse: 0.01769 |  0:03:20s\n",
      "epoch 111| loss: 0.01245 | train_rmsle: 0.00047 | train_mae: 0.06947 | train_rmse: 0.09154 | train_mse: 0.00838 | valid_rmsle: 0.00102 | valid_mae: 0.10268 | valid_rmse: 0.13438 | valid_mse: 0.01806 |  0:03:22s\n",
      "epoch 112| loss: 0.01343 | train_rmsle: 0.00041 | train_mae: 0.06368 | train_rmse: 0.08471 | train_mse: 0.00718 | valid_rmsle: 0.00096 | valid_mae: 0.09865 | valid_rmse: 0.13078 | valid_mse: 0.0171  |  0:03:24s\n",
      "epoch 113| loss: 0.01282 | train_rmsle: 0.00074 | train_mae: 0.07683 | train_rmse: 0.10237 | train_mse: 0.01048 | valid_rmsle: 0.00138 | valid_mae: 0.10944 | valid_rmse: 0.1465  | valid_mse: 0.02146 |  0:03:26s\n",
      "epoch 114| loss: 0.01239 | train_rmsle: 0.00041 | train_mae: 0.06376 | train_rmse: 0.08477 | train_mse: 0.00719 | valid_rmsle: 0.00098 | valid_mae: 0.0994  | valid_rmse: 0.13145 | valid_mse: 0.01728 |  0:03:28s\n",
      "epoch 115| loss: 0.01451 | train_rmsle: 0.00041 | train_mae: 0.06338 | train_rmse: 0.08409 | train_mse: 0.00707 | valid_rmsle: 0.001   | valid_mae: 0.09909 | valid_rmse: 0.13246 | valid_mse: 0.01755 |  0:03:29s\n",
      "epoch 116| loss: 0.01405 | train_rmsle: 0.00043 | train_mae: 0.0655  | train_rmse: 0.08654 | train_mse: 0.00749 | valid_rmsle: 0.00099 | valid_mae: 0.09917 | valid_rmse: 0.13191 | valid_mse: 0.0174  |  0:03:31s\n",
      "epoch 117| loss: 0.01234 | train_rmsle: 0.00048 | train_mae: 0.0702  | train_rmse: 0.09181 | train_mse: 0.00843 | valid_rmsle: 0.00098 | valid_mae: 0.10025 | valid_rmse: 0.13183 | valid_mse: 0.01738 |  0:03:33s\n",
      "epoch 118| loss: 0.01367 | train_rmsle: 0.00053 | train_mae: 0.07436 | train_rmse: 0.09671 | train_mse: 0.00935 | valid_rmsle: 0.00103 | valid_mae: 0.10361 | valid_rmse: 0.13491 | valid_mse: 0.0182  |  0:03:35s\n",
      "epoch 119| loss: 0.0156  | train_rmsle: 0.0006  | train_mae: 0.07295 | train_rmse: 0.09529 | train_mse: 0.00908 | valid_rmsle: 0.00115 | valid_mae: 0.10484 | valid_rmse: 0.137   | valid_mse: 0.01877 |  0:03:37s\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 112 and best_valid_mse = 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.015913919553862673 RMSE: 0.12615038467584105 R2: 0.9295552100638508 MAE: 0.0963740532898696\n",
      "=====================================\n",
      "[99/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.55594 | train_rmsle: 0.09477 | train_mae: 1.08757 | train_rmse: 1.17947 | train_mse: 1.39116 | valid_rmsle: 0.09529 | valid_mae: 1.09056 | valid_rmse: 1.18399 | valid_mse: 1.40182 |  0:00:01s\n",
      "epoch 1  | loss: 0.57373 | train_rmsle: 0.07849 | train_mae: 1.00133 | train_rmse: 1.08985 | train_mse: 1.18777 | valid_rmsle: 0.07876 | valid_mae: 1.00408 | valid_rmse: 1.09323 | valid_mse: 1.19514 |  0:00:03s\n",
      "epoch 2  | loss: 0.40217 | train_rmsle: 0.05229 | train_mae: 0.82326 | train_rmse: 0.91588 | train_mse: 0.83883 | valid_rmsle: 0.05239 | valid_mae: 0.82398 | valid_rmse: 0.91877 | valid_mse: 0.84414 |  0:00:05s\n",
      "epoch 3  | loss: 0.42356 | train_rmsle: 0.07212 | train_mae: 0.96028 | train_rmse: 1.05172 | train_mse: 1.10611 | valid_rmsle: 0.07233 | valid_mae: 0.96234 | valid_rmse: 1.05488 | valid_mse: 1.11277 |  0:00:07s\n",
      "epoch 4  | loss: 0.59322 | train_rmsle: 0.01688 | train_mae: 0.44366 | train_rmse: 0.53286 | train_mse: 0.28394 | valid_rmsle: 0.0164  | valid_mae: 0.44431 | valid_rmse: 0.53019 | valid_mse: 0.2811  |  0:00:09s\n",
      "epoch 5  | loss: 0.85333 | train_rmsle: 0.15492 | train_mae: 1.35952 | train_rmse: 1.43822 | train_mse: 2.06848 | valid_rmsle: 0.15587 | valid_mae: 1.36455 | valid_rmse: 1.44344 | valid_mse: 2.08352 |  0:00:11s\n",
      "epoch 6  | loss: 0.76832 | train_rmsle: 0.02088 | train_mae: 0.50611 | train_rmse: 0.59707 | train_mse: 0.35649 | valid_rmsle: 0.02038 | valid_mae: 0.50604 | valid_rmse: 0.5943  | valid_mse: 0.3532  |  0:00:12s\n",
      "epoch 7  | loss: 0.2555  | train_rmsle: 0.02383 | train_mae: 0.54629 | train_rmse: 0.63821 | train_mse: 0.40731 | valid_rmsle: 0.02367 | valid_mae: 0.54425 | valid_rmse: 0.63979 | valid_mse: 0.40934 |  0:00:14s\n",
      "epoch 8  | loss: 0.26065 | train_rmsle: 0.0152  | train_mae: 0.41181 | train_rmse: 0.50165 | train_mse: 0.25166 | valid_rmsle: 0.0146  | valid_mae: 0.41094 | valid_rmse: 0.49681 | valid_mse: 0.24682 |  0:00:16s\n",
      "epoch 9  | loss: 0.25261 | train_rmsle: 0.02005 | train_mae: 0.49388 | train_rmse: 0.58552 | train_mse: 0.34284 | valid_rmsle: 0.01975 | valid_mae: 0.49518 | valid_rmse: 0.58518 | valid_mse: 0.34243 |  0:00:18s\n",
      "epoch 10 | loss: 0.23398 | train_rmsle: 0.01573 | train_mae: 0.42017 | train_rmse: 0.51222 | train_mse: 0.26237 | valid_rmsle: 0.01553 | valid_mae: 0.42696 | valid_rmse: 0.51432 | valid_mse: 0.26453 |  0:00:19s\n",
      "epoch 11 | loss: 0.23575 | train_rmsle: 0.02414 | train_mae: 0.55162 | train_rmse: 0.64235 | train_mse: 0.41262 | valid_rmsle: 0.02393 | valid_mae: 0.55197 | valid_rmse: 0.64328 | valid_mse: 0.41381 |  0:00:21s\n",
      "epoch 12 | loss: 0.23768 | train_rmsle: 0.01525 | train_mae: 0.41526 | train_rmse: 0.50502 | train_mse: 0.25504 | valid_rmsle: 0.01471 | valid_mae: 0.41353 | valid_rmse: 0.50129 | valid_mse: 0.25129 |  0:00:23s\n",
      "epoch 13 | loss: 0.22476 | train_rmsle: 0.01575 | train_mae: 0.42333 | train_rmse: 0.51478 | train_mse: 0.26499 | valid_rmsle: 0.01517 | valid_mae: 0.42311 | valid_rmse: 0.51081 | valid_mse: 0.26093 |  0:00:25s\n",
      "epoch 14 | loss: 0.2229  | train_rmsle: 0.01459 | train_mae: 0.40113 | train_rmse: 0.49174 | train_mse: 0.24181 | valid_rmsle: 0.01396 | valid_mae: 0.40054 | valid_rmse: 0.48669 | valid_mse: 0.23686 |  0:00:27s\n",
      "epoch 15 | loss: 0.2305  | train_rmsle: 0.01856 | train_mae: 0.47321 | train_rmse: 0.5634  | train_mse: 0.31742 | valid_rmsle: 0.0181  | valid_mae: 0.47009 | valid_rmse: 0.56096 | valid_mse: 0.31467 |  0:00:29s\n",
      "epoch 16 | loss: 0.21748 | train_rmsle: 0.01402 | train_mae: 0.36883 | train_rmse: 0.47081 | train_mse: 0.22166 | valid_rmsle: 0.01313 | valid_mae: 0.36592 | valid_rmse: 0.46003 | valid_mse: 0.21163 |  0:00:30s\n",
      "epoch 17 | loss: 0.21772 | train_rmsle: 0.01467 | train_mae: 0.40197 | train_rmse: 0.49256 | train_mse: 0.24262 | valid_rmsle: 0.01396 | valid_mae: 0.40023 | valid_rmse: 0.4852  | valid_mse: 0.23542 |  0:00:32s\n",
      "epoch 18 | loss: 0.21621 | train_rmsle: 0.0129  | train_mae: 0.3683  | train_rmse: 0.45771 | train_mse: 0.2095  | valid_rmsle: 0.01217 | valid_mae: 0.36263 | valid_rmse: 0.44897 | valid_mse: 0.20158 |  0:00:34s\n",
      "epoch 19 | loss: 0.20151 | train_rmsle: 0.01303 | train_mae: 0.37542 | train_rmse: 0.46256 | train_mse: 0.21396 | valid_rmsle: 0.01219 | valid_mae: 0.36973 | valid_rmse: 0.45195 | valid_mse: 0.20425 |  0:00:36s\n",
      "epoch 20 | loss: 0.19248 | train_rmsle: 0.01143 | train_mae: 0.33447 | train_rmse: 0.42664 | train_mse: 0.18202 | valid_rmsle: 0.01086 | valid_mae: 0.33076 | valid_rmse: 0.42014 | valid_mse: 0.17652 |  0:00:38s\n",
      "epoch 21 | loss: 0.18073 | train_rmsle: 0.01055 | train_mae: 0.32258 | train_rmse: 0.41182 | train_mse: 0.1696  | valid_rmsle: 0.0102  | valid_mae: 0.3187  | valid_rmse: 0.40765 | valid_mse: 0.16618 |  0:00:39s\n",
      "epoch 22 | loss: 0.16616 | train_rmsle: 0.00987 | train_mae: 0.31477 | train_rmse: 0.39876 | train_mse: 0.15901 | valid_rmsle: 0.00944 | valid_mae: 0.3077  | valid_rmse: 0.39448 | valid_mse: 0.15562 |  0:00:41s\n",
      "epoch 23 | loss: 0.14507 | train_rmsle: 0.00852 | train_mae: 0.27877 | train_rmse: 0.36435 | train_mse: 0.13275 | valid_rmsle: 0.00836 | valid_mae: 0.27705 | valid_rmse: 0.36477 | valid_mse: 0.13306 |  0:00:43s\n",
      "epoch 24 | loss: 0.13086 | train_rmsle: 0.00777 | train_mae: 0.26229 | train_rmse: 0.34525 | train_mse: 0.1192  | valid_rmsle: 0.00732 | valid_mae: 0.25767 | valid_rmse: 0.34002 | valid_mse: 0.11561 |  0:00:45s\n",
      "epoch 25 | loss: 0.11568 | train_rmsle: 0.00756 | train_mae: 0.263   | train_rmse: 0.34255 | train_mse: 0.11734 | valid_rmsle: 0.00711 | valid_mae: 0.2583  | valid_rmse: 0.33773 | valid_mse: 0.11406 |  0:00:47s\n",
      "epoch 26 | loss: 0.1138  | train_rmsle: 0.00728 | train_mae: 0.26275 | train_rmse: 0.3375  | train_mse: 0.11391 | valid_rmsle: 0.00696 | valid_mae: 0.25866 | valid_rmse: 0.33433 | valid_mse: 0.11178 |  0:00:48s\n",
      "epoch 27 | loss: 0.11018 | train_rmsle: 0.00701 | train_mae: 0.25464 | train_rmse: 0.32939 | train_mse: 0.1085  | valid_rmsle: 0.00684 | valid_mae: 0.25246 | valid_rmse: 0.3306  | valid_mse: 0.1093  |  0:00:50s\n",
      "epoch 28 | loss: 0.10567 | train_rmsle: 0.00766 | train_mae: 0.27625 | train_rmse: 0.34878 | train_mse: 0.12164 | valid_rmsle: 0.00719 | valid_mae: 0.26707 | valid_rmse: 0.3416  | valid_mse: 0.11669 |  0:00:52s\n",
      "epoch 29 | loss: 0.10427 | train_rmsle: 0.00843 | train_mae: 0.2914  | train_rmse: 0.3654  | train_mse: 0.13352 | valid_rmsle: 0.00777 | valid_mae: 0.27928 | valid_rmse: 0.35407 | valid_mse: 0.12537 |  0:00:54s\n",
      "epoch 30 | loss: 0.10162 | train_rmsle: 0.00708 | train_mae: 0.25953 | train_rmse: 0.33236 | train_mse: 0.11047 | valid_rmsle: 0.00653 | valid_mae: 0.25126 | valid_rmse: 0.32288 | valid_mse: 0.10425 |  0:00:56s\n",
      "epoch 31 | loss: 0.10202 | train_rmsle: 0.00675 | train_mae: 0.24211 | train_rmse: 0.3194  | train_mse: 0.10201 | valid_rmsle: 0.00651 | valid_mae: 0.24401 | valid_rmse: 0.31899 | valid_mse: 0.10175 |  0:00:57s\n",
      "epoch 32 | loss: 0.10128 | train_rmsle: 0.00655 | train_mae: 0.24033 | train_rmse: 0.31486 | train_mse: 0.09914 | valid_rmsle: 0.00624 | valid_mae: 0.23689 | valid_rmse: 0.31144 | valid_mse: 0.09699 |  0:00:59s\n",
      "epoch 33 | loss: 0.10178 | train_rmsle: 0.00685 | train_mae: 0.25241 | train_rmse: 0.32514 | train_mse: 0.10572 | valid_rmsle: 0.00656 | valid_mae: 0.24631 | valid_rmse: 0.3218  | valid_mse: 0.10356 |  0:01:01s\n",
      "epoch 34 | loss: 0.10222 | train_rmsle: 0.00666 | train_mae: 0.24036 | train_rmse: 0.31693 | train_mse: 0.10044 | valid_rmsle: 0.00653 | valid_mae: 0.24111 | valid_rmse: 0.31843 | valid_mse: 0.1014  |  0:01:03s\n",
      "epoch 35 | loss: 0.09868 | train_rmsle: 0.00641 | train_mae: 0.24289 | train_rmse: 0.31251 | train_mse: 0.09766 | valid_rmsle: 0.00617 | valid_mae: 0.23955 | valid_rmse: 0.31082 | valid_mse: 0.09661 |  0:01:05s\n",
      "epoch 36 | loss: 0.09625 | train_rmsle: 0.00677 | train_mae: 0.25064 | train_rmse: 0.32299 | train_mse: 0.10432 | valid_rmsle: 0.00647 | valid_mae: 0.24352 | valid_rmse: 0.31916 | valid_mse: 0.10186 |  0:01:06s\n",
      "epoch 37 | loss: 0.10122 | train_rmsle: 0.0064  | train_mae: 0.24533 | train_rmse: 0.31383 | train_mse: 0.09849 | valid_rmsle: 0.00608 | valid_mae: 0.23825 | valid_rmse: 0.3095  | valid_mse: 0.09579 |  0:01:08s\n",
      "epoch 38 | loss: 0.0987  | train_rmsle: 0.00645 | train_mae: 0.24798 | train_rmse: 0.31579 | train_mse: 0.09972 | valid_rmsle: 0.00613 | valid_mae: 0.24117 | valid_rmse: 0.31129 | valid_mse: 0.0969  |  0:01:10s\n",
      "epoch 39 | loss: 0.09571 | train_rmsle: 0.0062  | train_mae: 0.23559 | train_rmse: 0.30679 | train_mse: 0.09412 | valid_rmsle: 0.00601 | valid_mae: 0.23316 | valid_rmse: 0.30636 | valid_mse: 0.09386 |  0:01:12s\n",
      "epoch 40 | loss: 0.09755 | train_rmsle: 0.00616 | train_mae: 0.23294 | train_rmse: 0.30443 | train_mse: 0.09267 | valid_rmsle: 0.00594 | valid_mae: 0.23099 | valid_rmse: 0.30352 | valid_mse: 0.09212 |  0:01:14s\n",
      "epoch 41 | loss: 0.09326 | train_rmsle: 0.00621 | train_mae: 0.23148 | train_rmse: 0.30521 | train_mse: 0.09315 | valid_rmsle: 0.00609 | valid_mae: 0.23317 | valid_rmse: 0.30682 | valid_mse: 0.09414 |  0:01:15s\n",
      "epoch 42 | loss: 0.09334 | train_rmsle: 0.00613 | train_mae: 0.23397 | train_rmse: 0.30491 | train_mse: 0.09297 | valid_rmsle: 0.00601 | valid_mae: 0.23483 | valid_rmse: 0.3065  | valid_mse: 0.09394 |  0:01:17s\n",
      "epoch 43 | loss: 0.09313 | train_rmsle: 0.00602 | train_mae: 0.2323  | train_rmse: 0.3015  | train_mse: 0.0909  | valid_rmsle: 0.00595 | valid_mae: 0.23315 | valid_rmse: 0.30423 | valid_mse: 0.09255 |  0:01:19s\n",
      "epoch 44 | loss: 0.09248 | train_rmsle: 0.0062  | train_mae: 0.22911 | train_rmse: 0.30451 | train_mse: 0.09273 | valid_rmsle: 0.00615 | valid_mae: 0.23296 | valid_rmse: 0.30838 | valid_mse: 0.0951  |  0:01:21s\n",
      "epoch 45 | loss: 0.09286 | train_rmsle: 0.00615 | train_mae: 0.22894 | train_rmse: 0.30335 | train_mse: 0.09202 | valid_rmsle: 0.00623 | valid_mae: 0.23609 | valid_rmse: 0.31088 | valid_mse: 0.09665 |  0:01:23s\n",
      "epoch 46 | loss: 0.09035 | train_rmsle: 0.00615 | train_mae: 0.24218 | train_rmse: 0.30822 | train_mse: 0.095   | valid_rmsle: 0.00611 | valid_mae: 0.24211 | valid_rmse: 0.31134 | valid_mse: 0.09694 |  0:01:25s\n",
      "epoch 47 | loss: 0.09233 | train_rmsle: 0.00655 | train_mae: 0.23468 | train_rmse: 0.31293 | train_mse: 0.09793 | valid_rmsle: 0.0068  | valid_mae: 0.24684 | valid_rmse: 0.32491 | valid_mse: 0.10557 |  0:01:26s\n",
      "epoch 48 | loss: 0.09816 | train_rmsle: 0.00575 | train_mae: 0.22571 | train_rmse: 0.29441 | train_mse: 0.08668 | valid_rmsle: 0.00588 | valid_mae: 0.23002 | valid_rmse: 0.30204 | valid_mse: 0.09123 |  0:01:28s\n",
      "epoch 49 | loss: 0.09051 | train_rmsle: 0.00575 | train_mae: 0.22403 | train_rmse: 0.29406 | train_mse: 0.08647 | valid_rmsle: 0.00598 | valid_mae: 0.23121 | valid_rmse: 0.3053  | valid_mse: 0.09321 |  0:01:30s\n",
      "epoch 50 | loss: 0.09153 | train_rmsle: 0.00653 | train_mae: 0.23259 | train_rmse: 0.31281 | train_mse: 0.09785 | valid_rmsle: 0.00688 | valid_mae: 0.24606 | valid_rmse: 0.32742 | valid_mse: 0.1072  |  0:01:32s\n",
      "epoch 51 | loss: 0.09011 | train_rmsle: 0.00606 | train_mae: 0.24054 | train_rmse: 0.30666 | train_mse: 0.09404 | valid_rmsle: 0.00622 | valid_mae: 0.24371 | valid_rmse: 0.31517 | valid_mse: 0.09933 |  0:01:34s\n",
      "epoch 52 | loss: 0.08797 | train_rmsle: 0.00594 | train_mae: 0.22641 | train_rmse: 0.29926 | train_mse: 0.08956 | valid_rmsle: 0.00625 | valid_mae: 0.23998 | valid_rmse: 0.31368 | valid_mse: 0.0984  |  0:01:35s\n",
      "epoch 53 | loss: 0.08928 | train_rmsle: 0.00562 | train_mae: 0.23071 | train_rmse: 0.29496 | train_mse: 0.087   | valid_rmsle: 0.00577 | valid_mae: 0.23452 | valid_rmse: 0.30294 | valid_mse: 0.09177 |  0:01:37s\n",
      "epoch 54 | loss: 0.08529 | train_rmsle: 0.00587 | train_mae: 0.24057 | train_rmse: 0.30374 | train_mse: 0.09226 | valid_rmsle: 0.00605 | valid_mae: 0.24494 | valid_rmse: 0.31174 | valid_mse: 0.09718 |  0:01:39s\n",
      "epoch 55 | loss: 0.08578 | train_rmsle: 0.00545 | train_mae: 0.22523 | train_rmse: 0.29009 | train_mse: 0.08415 | valid_rmsle: 0.00575 | valid_mae: 0.23573 | valid_rmse: 0.30273 | valid_mse: 0.09165 |  0:01:41s\n",
      "epoch 56 | loss: 0.0856  | train_rmsle: 0.00548 | train_mae: 0.22314 | train_rmse: 0.29026 | train_mse: 0.08425 | valid_rmsle: 0.00565 | valid_mae: 0.23106 | valid_rmse: 0.29974 | valid_mse: 0.08985 |  0:01:43s\n",
      "epoch 57 | loss: 0.08536 | train_rmsle: 0.00533 | train_mae: 0.22359 | train_rmse: 0.28786 | train_mse: 0.08287 | valid_rmsle: 0.00535 | valid_mae: 0.22822 | valid_rmse: 0.29326 | valid_mse: 0.086   |  0:01:44s\n",
      "epoch 58 | loss: 0.08128 | train_rmsle: 0.00528 | train_mae: 0.22559 | train_rmse: 0.28852 | train_mse: 0.08325 | valid_rmsle: 0.0053  | valid_mae: 0.2305  | valid_rmse: 0.29306 | valid_mse: 0.08588 |  0:01:46s\n",
      "epoch 59 | loss: 0.08193 | train_rmsle: 0.005   | train_mae: 0.22126 | train_rmse: 0.28112 | train_mse: 0.07903 | valid_rmsle: 0.00503 | valid_mae: 0.22866 | valid_rmse: 0.28719 | valid_mse: 0.08248 |  0:01:48s\n",
      "epoch 60 | loss: 0.07712 | train_rmsle: 0.00494 | train_mae: 0.22198 | train_rmse: 0.28111 | train_mse: 0.07902 | valid_rmsle: 0.00499 | valid_mae: 0.22777 | valid_rmse: 0.28676 | valid_mse: 0.08223 |  0:01:50s\n",
      "epoch 61 | loss: 0.07324 | train_rmsle: 0.00568 | train_mae: 0.23399 | train_rmse: 0.29963 | train_mse: 0.08978 | valid_rmsle: 0.00593 | valid_mae: 0.244   | valid_rmse: 0.31082 | valid_mse: 0.09661 |  0:01:52s\n",
      "epoch 62 | loss: 0.06731 | train_rmsle: 0.0045  | train_mae: 0.21151 | train_rmse: 0.26854 | train_mse: 0.07212 | valid_rmsle: 0.00476 | valid_mae: 0.22227 | valid_rmse: 0.28018 | valid_mse: 0.0785  |  0:01:53s\n",
      "epoch 63 | loss: 0.0623  | train_rmsle: 0.00383 | train_mae: 0.18701 | train_rmse: 0.24423 | train_mse: 0.05965 | valid_rmsle: 0.00425 | valid_mae: 0.20543 | valid_rmse: 0.26281 | valid_mse: 0.06907 |  0:01:55s\n",
      "epoch 64 | loss: 0.06061 | train_rmsle: 0.0039  | train_mae: 0.19674 | train_rmse: 0.24995 | train_mse: 0.06247 | valid_rmsle: 0.00427 | valid_mae: 0.21179 | valid_rmse: 0.26622 | valid_mse: 0.07087 |  0:01:57s\n",
      "epoch 65 | loss: 0.05886 | train_rmsle: 0.00361 | train_mae: 0.18751 | train_rmse: 0.2393  | train_mse: 0.05726 | valid_rmsle: 0.00408 | valid_mae: 0.20677 | valid_rmse: 0.25942 | valid_mse: 0.0673  |  0:01:59s\n",
      "epoch 66 | loss: 0.0549  | train_rmsle: 0.00331 | train_mae: 0.17846 | train_rmse: 0.22883 | train_mse: 0.05236 | valid_rmsle: 0.00373 | valid_mae: 0.1968  | valid_rmse: 0.24753 | valid_mse: 0.06127 |  0:02:01s\n",
      "epoch 67 | loss: 0.05342 | train_rmsle: 0.00361 | train_mae: 0.19256 | train_rmse: 0.24164 | train_mse: 0.05839 | valid_rmsle: 0.00401 | valid_mae: 0.2079  | valid_rmse: 0.25865 | valid_mse: 0.0669  |  0:02:02s\n",
      "epoch 68 | loss: 0.0506  | train_rmsle: 0.00287 | train_mae: 0.16159 | train_rmse: 0.21105 | train_mse: 0.04454 | valid_rmsle: 0.00339 | valid_mae: 0.18643 | valid_rmse: 0.23584 | valid_mse: 0.05562 |  0:02:04s\n",
      "epoch 69 | loss: 0.05372 | train_rmsle: 0.00293 | train_mae: 0.16808 | train_rmse: 0.21569 | train_mse: 0.04652 | valid_rmsle: 0.00342 | valid_mae: 0.19013 | valid_rmse: 0.23792 | valid_mse: 0.0566  |  0:02:06s\n",
      "epoch 70 | loss: 0.0501  | train_rmsle: 0.00269 | train_mae: 0.15789 | train_rmse: 0.20481 | train_mse: 0.04195 | valid_rmsle: 0.00329 | valid_mae: 0.18479 | valid_rmse: 0.23285 | valid_mse: 0.05422 |  0:02:08s\n",
      "epoch 71 | loss: 0.04745 | train_rmsle: 0.00337 | train_mae: 0.19004 | train_rmse: 0.23506 | train_mse: 0.05525 | valid_rmsle: 0.00388 | valid_mae: 0.20675 | valid_rmse: 0.25563 | valid_mse: 0.06535 |  0:02:10s\n",
      "epoch 72 | loss: 0.04619 | train_rmsle: 0.00234 | train_mae: 0.14405 | train_rmse: 0.19065 | train_mse: 0.03635 | valid_rmsle: 0.00297 | valid_mae: 0.17577 | valid_rmse: 0.22205 | valid_mse: 0.04931 |  0:02:11s\n",
      "epoch 73 | loss: 0.04198 | train_rmsle: 0.00237 | train_mae: 0.14316 | train_rmse: 0.19133 | train_mse: 0.03661 | valid_rmsle: 0.00302 | valid_mae: 0.17487 | valid_rmse: 0.22437 | valid_mse: 0.05034 |  0:02:13s\n",
      "epoch 74 | loss: 0.04007 | train_rmsle: 0.00223 | train_mae: 0.14289 | train_rmse: 0.18715 | train_mse: 0.03503 | valid_rmsle: 0.00283 | valid_mae: 0.17271 | valid_rmse: 0.21807 | valid_mse: 0.04755 |  0:02:15s\n",
      "epoch 75 | loss: 0.03712 | train_rmsle: 0.00234 | train_mae: 0.15118 | train_rmse: 0.19445 | train_mse: 0.03781 | valid_rmsle: 0.00285 | valid_mae: 0.17701 | valid_rmse: 0.22023 | valid_mse: 0.0485  |  0:02:17s\n",
      "epoch 76 | loss: 0.03713 | train_rmsle: 0.00206 | train_mae: 0.13392 | train_rmse: 0.17917 | train_mse: 0.0321  | valid_rmsle: 0.00267 | valid_mae: 0.16708 | valid_rmse: 0.21321 | valid_mse: 0.04546 |  0:02:19s\n",
      "epoch 77 | loss: 0.03492 | train_rmsle: 0.00195 | train_mae: 0.13324 | train_rmse: 0.17516 | train_mse: 0.03068 | valid_rmsle: 0.00253 | valid_mae: 0.16511 | valid_rmse: 0.20706 | valid_mse: 0.04287 |  0:02:20s\n",
      "epoch 78 | loss: 0.03155 | train_rmsle: 0.00175 | train_mae: 0.12319 | train_rmse: 0.16491 | train_mse: 0.02719 | valid_rmsle: 0.0023  | valid_mae: 0.15573 | valid_rmse: 0.197   | valid_mse: 0.03881 |  0:02:22s\n",
      "epoch 79 | loss: 0.03048 | train_rmsle: 0.00179 | train_mae: 0.12802 | train_rmse: 0.16828 | train_mse: 0.02832 | valid_rmsle: 0.00228 | valid_mae: 0.15654 | valid_rmse: 0.19717 | valid_mse: 0.03888 |  0:02:24s\n",
      "epoch 80 | loss: 0.02965 | train_rmsle: 0.00169 | train_mae: 0.12328 | train_rmse: 0.16346 | train_mse: 0.02672 | valid_rmsle: 0.00218 | valid_mae: 0.15237 | valid_rmse: 0.1929  | valid_mse: 0.03721 |  0:02:26s\n",
      "epoch 81 | loss: 0.03215 | train_rmsle: 0.00152 | train_mae: 0.11471 | train_rmse: 0.15364 | train_mse: 0.02361 | valid_rmsle: 0.00204 | valid_mae: 0.14578 | valid_rmse: 0.1861  | valid_mse: 0.03463 |  0:02:28s\n",
      "epoch 82 | loss: 0.02931 | train_rmsle: 0.0027  | train_mae: 0.17719 | train_rmse: 0.21248 | train_mse: 0.04515 | valid_rmsle: 0.00316 | valid_mae: 0.18983 | valid_rmse: 0.23345 | valid_mse: 0.0545  |  0:02:29s\n",
      "epoch 83 | loss: 0.03296 | train_rmsle: 0.00143 | train_mae: 0.11272 | train_rmse: 0.15055 | train_mse: 0.02267 | valid_rmsle: 0.002   | valid_mae: 0.14533 | valid_rmse: 0.18585 | valid_mse: 0.03454 |  0:02:31s\n",
      "epoch 84 | loss: 0.02925 | train_rmsle: 0.00207 | train_mae: 0.14886 | train_rmse: 0.18446 | train_mse: 0.03402 | valid_rmsle: 0.00248 | valid_mae: 0.16594 | valid_rmse: 0.2066  | valid_mse: 0.04268 |  0:02:33s\n",
      "epoch 85 | loss: 0.02714 | train_rmsle: 0.00124 | train_mae: 0.10341 | train_rmse: 0.13935 | train_mse: 0.01942 | valid_rmsle: 0.00172 | valid_mae: 0.13348 | valid_rmse: 0.17177 | valid_mse: 0.02951 |  0:02:35s\n",
      "epoch 86 | loss: 0.02434 | train_rmsle: 0.00154 | train_mae: 0.12536 | train_rmse: 0.16105 | train_mse: 0.02594 | valid_rmsle: 0.00201 | valid_mae: 0.14874 | valid_rmse: 0.18825 | valid_mse: 0.03544 |  0:02:37s\n",
      "epoch 87 | loss: 0.02579 | train_rmsle: 0.00111 | train_mae: 0.09803 | train_rmse: 0.13293 | train_mse: 0.01767 | valid_rmsle: 0.00165 | valid_mae: 0.13057 | valid_rmse: 0.16913 | valid_mse: 0.0286  |  0:02:39s\n",
      "epoch 88 | loss: 0.02431 | train_rmsle: 0.00113 | train_mae: 0.10055 | train_rmse: 0.13497 | train_mse: 0.01822 | valid_rmsle: 0.00166 | valid_mae: 0.13258 | valid_rmse: 0.16999 | valid_mse: 0.0289  |  0:02:40s\n",
      "epoch 89 | loss: 0.0276  | train_rmsle: 0.00128 | train_mae: 0.11252 | train_rmse: 0.14543 | train_mse: 0.02115 | valid_rmsle: 0.00183 | valid_mae: 0.14017 | valid_rmse: 0.17874 | valid_mse: 0.03195 |  0:02:42s\n",
      "epoch 90 | loss: 0.02384 | train_rmsle: 0.00131 | train_mae: 0.11539 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00185 | valid_mae: 0.14274 | valid_rmse: 0.18009 | valid_mse: 0.03243 |  0:02:44s\n",
      "epoch 91 | loss: 0.024   | train_rmsle: 0.00098 | train_mae: 0.09156 | train_rmse: 0.124   | train_mse: 0.01538 | valid_rmsle: 0.00155 | valid_mae: 0.12585 | valid_rmse: 0.16374 | valid_mse: 0.02681 |  0:02:46s\n",
      "epoch 92 | loss: 0.02099 | train_rmsle: 0.00095 | train_mae: 0.09185 | train_rmse: 0.12379 | train_mse: 0.01532 | valid_rmsle: 0.00157 | valid_mae: 0.12755 | valid_rmse: 0.16593 | valid_mse: 0.02753 |  0:02:48s\n",
      "epoch 93 | loss: 0.0197  | train_rmsle: 0.00125 | train_mae: 0.11255 | train_rmse: 0.1428  | train_mse: 0.02039 | valid_rmsle: 0.00177 | valid_mae: 0.13788 | valid_rmse: 0.17449 | valid_mse: 0.03045 |  0:02:49s\n",
      "epoch 94 | loss: 0.02551 | train_rmsle: 0.00131 | train_mae: 0.12019 | train_rmse: 0.15024 | train_mse: 0.02257 | valid_rmsle: 0.00182 | valid_mae: 0.14301 | valid_rmse: 0.17963 | valid_mse: 0.03227 |  0:02:51s\n",
      "epoch 95 | loss: 0.02509 | train_rmsle: 0.00084 | train_mae: 0.08602 | train_rmse: 0.11581 | train_mse: 0.01341 | valid_rmsle: 0.00138 | valid_mae: 0.11858 | valid_rmse: 0.15547 | valid_mse: 0.02417 |  0:02:53s\n",
      "epoch 96 | loss: 0.02149 | train_rmsle: 0.00086 | train_mae: 0.08756 | train_rmse: 0.11811 | train_mse: 0.01395 | valid_rmsle: 0.00142 | valid_mae: 0.12121 | valid_rmse: 0.15879 | valid_mse: 0.02521 |  0:02:55s\n",
      "epoch 97 | loss: 0.02045 | train_rmsle: 0.00082 | train_mae: 0.08624 | train_rmse: 0.11526 | train_mse: 0.01328 | valid_rmsle: 0.00132 | valid_mae: 0.11649 | valid_rmse: 0.15163 | valid_mse: 0.02299 |  0:02:57s\n",
      "epoch 98 | loss: 0.01686 | train_rmsle: 0.0008  | train_mae: 0.08799 | train_rmse: 0.11651 | train_mse: 0.01358 | valid_rmsle: 0.00133 | valid_mae: 0.11855 | valid_rmse: 0.1533  | valid_mse: 0.0235  |  0:02:58s\n",
      "epoch 99 | loss: 0.01855 | train_rmsle: 0.00077 | train_mae: 0.08557 | train_rmse: 0.11254 | train_mse: 0.01267 | valid_rmsle: 0.0013  | valid_mae: 0.11563 | valid_rmse: 0.14997 | valid_mse: 0.02249 |  0:03:00s\n",
      "epoch 100| loss: 0.01848 | train_rmsle: 0.00079 | train_mae: 0.0867  | train_rmse: 0.11372 | train_mse: 0.01293 | valid_rmsle: 0.00136 | valid_mae: 0.11726 | valid_rmse: 0.15324 | valid_mse: 0.02348 |  0:03:02s\n",
      "epoch 101| loss: 0.01793 | train_rmsle: 0.00079 | train_mae: 0.09132 | train_rmse: 0.11785 | train_mse: 0.01389 | valid_rmsle: 0.00137 | valid_mae: 0.12028 | valid_rmse: 0.15551 | valid_mse: 0.02418 |  0:03:04s\n",
      "epoch 102| loss: 0.0171  | train_rmsle: 0.00096 | train_mae: 0.09808 | train_rmse: 0.12408 | train_mse: 0.01539 | valid_rmsle: 0.00151 | valid_mae: 0.12621 | valid_rmse: 0.16147 | valid_mse: 0.02607 |  0:03:06s\n",
      "epoch 103| loss: 0.01573 | train_rmsle: 0.00062 | train_mae: 0.07734 | train_rmse: 0.10214 | train_mse: 0.01043 | valid_rmsle: 0.00121 | valid_mae: 0.11151 | valid_rmse: 0.14521 | valid_mse: 0.02108 |  0:03:07s\n",
      "epoch 104| loss: 0.01685 | train_rmsle: 0.00111 | train_mae: 0.11673 | train_rmse: 0.14173 | train_mse: 0.02009 | valid_rmsle: 0.00166 | valid_mae: 0.13676 | valid_rmse: 0.17239 | valid_mse: 0.02972 |  0:03:09s\n",
      "epoch 105| loss: 0.01941 | train_rmsle: 0.00109 | train_mae: 0.09183 | train_rmse: 0.12217 | train_mse: 0.01493 | valid_rmsle: 0.00174 | valid_mae: 0.1194  | valid_rmse: 0.15997 | valid_mse: 0.02559 |  0:03:11s\n",
      "epoch 106| loss: 0.01412 | train_rmsle: 0.00066 | train_mae: 0.08411 | train_rmse: 0.10862 | train_mse: 0.0118  | valid_rmsle: 0.00115 | valid_mae: 0.11097 | valid_rmse: 0.14284 | valid_mse: 0.0204  |  0:03:13s\n",
      "epoch 107| loss: 0.0151  | train_rmsle: 0.00085 | train_mae: 0.08763 | train_rmse: 0.11364 | train_mse: 0.01291 | valid_rmsle: 0.00147 | valid_mae: 0.11505 | valid_rmse: 0.15303 | valid_mse: 0.02342 |  0:03:15s\n",
      "epoch 108| loss: 0.01987 | train_rmsle: 0.00054 | train_mae: 0.0697  | train_rmse: 0.09423 | train_mse: 0.00888 | valid_rmsle: 0.00106 | valid_mae: 0.10272 | valid_rmse: 0.13593 | valid_mse: 0.01848 |  0:03:16s\n",
      "epoch 109| loss: 0.01696 | train_rmsle: 0.00057 | train_mae: 0.07377 | train_rmse: 0.09673 | train_mse: 0.00936 | valid_rmsle: 0.00113 | valid_mae: 0.10465 | valid_rmse: 0.13788 | valid_mse: 0.01901 |  0:03:18s\n",
      "epoch 110| loss: 0.01558 | train_rmsle: 0.00051 | train_mae: 0.0695  | train_rmse: 0.09223 | train_mse: 0.00851 | valid_rmsle: 0.00102 | valid_mae: 0.1007  | valid_rmse: 0.133   | valid_mse: 0.01769 |  0:03:20s\n",
      "epoch 111| loss: 0.01245 | train_rmsle: 0.00047 | train_mae: 0.06947 | train_rmse: 0.09154 | train_mse: 0.00838 | valid_rmsle: 0.00102 | valid_mae: 0.10268 | valid_rmse: 0.13438 | valid_mse: 0.01806 |  0:03:22s\n",
      "epoch 112| loss: 0.01343 | train_rmsle: 0.00041 | train_mae: 0.06368 | train_rmse: 0.08471 | train_mse: 0.00718 | valid_rmsle: 0.00096 | valid_mae: 0.09865 | valid_rmse: 0.13078 | valid_mse: 0.0171  |  0:03:24s\n",
      "epoch 113| loss: 0.01282 | train_rmsle: 0.00074 | train_mae: 0.07683 | train_rmse: 0.10237 | train_mse: 0.01048 | valid_rmsle: 0.00138 | valid_mae: 0.10944 | valid_rmse: 0.1465  | valid_mse: 0.02146 |  0:03:25s\n",
      "epoch 114| loss: 0.01239 | train_rmsle: 0.00041 | train_mae: 0.06376 | train_rmse: 0.08477 | train_mse: 0.00719 | valid_rmsle: 0.00098 | valid_mae: 0.0994  | valid_rmse: 0.13145 | valid_mse: 0.01728 |  0:03:27s\n",
      "epoch 115| loss: 0.01451 | train_rmsle: 0.00041 | train_mae: 0.06338 | train_rmse: 0.08409 | train_mse: 0.00707 | valid_rmsle: 0.001   | valid_mae: 0.09909 | valid_rmse: 0.13246 | valid_mse: 0.01755 |  0:03:29s\n",
      "epoch 116| loss: 0.01405 | train_rmsle: 0.00043 | train_mae: 0.0655  | train_rmse: 0.08654 | train_mse: 0.00749 | valid_rmsle: 0.00099 | valid_mae: 0.09917 | valid_rmse: 0.13191 | valid_mse: 0.0174  |  0:03:31s\n",
      "epoch 117| loss: 0.01234 | train_rmsle: 0.00048 | train_mae: 0.0702  | train_rmse: 0.09181 | train_mse: 0.00843 | valid_rmsle: 0.00098 | valid_mae: 0.10025 | valid_rmse: 0.13183 | valid_mse: 0.01738 |  0:03:33s\n",
      "epoch 118| loss: 0.01367 | train_rmsle: 0.00053 | train_mae: 0.07436 | train_rmse: 0.09671 | train_mse: 0.00935 | valid_rmsle: 0.00103 | valid_mae: 0.10361 | valid_rmse: 0.13491 | valid_mse: 0.0182  |  0:03:34s\n",
      "epoch 119| loss: 0.0156  | train_rmsle: 0.0006  | train_mae: 0.07295 | train_rmse: 0.09529 | train_mse: 0.00908 | valid_rmsle: 0.00115 | valid_mae: 0.10484 | valid_rmse: 0.137   | valid_mse: 0.01877 |  0:03:36s\n",
      "epoch 120| loss: 0.01485 | train_rmsle: 0.00044 | train_mae: 0.06592 | train_rmse: 0.0865  | train_mse: 0.00748 | valid_rmsle: 0.00097 | valid_mae: 0.09866 | valid_rmse: 0.12886 | valid_mse: 0.01661 |  0:03:38s\n",
      "epoch 121| loss: 0.012   | train_rmsle: 0.00041 | train_mae: 0.06423 | train_rmse: 0.08471 | train_mse: 0.00718 | valid_rmsle: 0.00091 | valid_mae: 0.09654 | valid_rmse: 0.12703 | valid_mse: 0.01614 |  0:03:40s\n",
      "epoch 122| loss: 0.01215 | train_rmsle: 0.00046 | train_mae: 0.06654 | train_rmse: 0.08739 | train_mse: 0.00764 | valid_rmsle: 0.00102 | valid_mae: 0.09936 | valid_rmse: 0.13076 | valid_mse: 0.0171  |  0:03:42s\n",
      "epoch 123| loss: 0.01226 | train_rmsle: 0.00045 | train_mae: 0.06576 | train_rmse: 0.08604 | train_mse: 0.0074  | valid_rmsle: 0.00095 | valid_mae: 0.09716 | valid_rmse: 0.12809 | valid_mse: 0.01641 |  0:03:44s\n",
      "epoch 124| loss: 0.01343 | train_rmsle: 0.00046 | train_mae: 0.07022 | train_rmse: 0.09025 | train_mse: 0.00815 | valid_rmsle: 0.00099 | valid_mae: 0.101   | valid_rmse: 0.13124 | valid_mse: 0.01722 |  0:03:45s\n",
      "epoch 125| loss: 0.01136 | train_rmsle: 0.00036 | train_mae: 0.0603  | train_rmse: 0.07994 | train_mse: 0.00639 | valid_rmsle: 0.00088 | valid_mae: 0.09466 | valid_rmse: 0.12397 | valid_mse: 0.01537 |  0:03:47s\n",
      "epoch 126| loss: 0.01083 | train_rmsle: 0.00033 | train_mae: 0.05665 | train_rmse: 0.07546 | train_mse: 0.00569 | valid_rmsle: 0.00088 | valid_mae: 0.0923  | valid_rmse: 0.1232  | valid_mse: 0.01518 |  0:03:49s\n",
      "epoch 127| loss: 0.01167 | train_rmsle: 0.00048 | train_mae: 0.07339 | train_rmse: 0.09363 | train_mse: 0.00877 | valid_rmsle: 0.00095 | valid_mae: 0.10198 | valid_rmse: 0.13039 | valid_mse: 0.017   |  0:03:51s\n",
      "epoch 128| loss: 0.01439 | train_rmsle: 0.0004  | train_mae: 0.06374 | train_rmse: 0.08336 | train_mse: 0.00695 | valid_rmsle: 0.00097 | valid_mae: 0.0974  | valid_rmse: 0.12949 | valid_mse: 0.01677 |  0:03:53s\n",
      "epoch 129| loss: 0.01188 | train_rmsle: 0.00047 | train_mae: 0.06528 | train_rmse: 0.0853  | train_mse: 0.00728 | valid_rmsle: 0.00092 | valid_mae: 0.09592 | valid_rmse: 0.12574 | valid_mse: 0.01581 |  0:03:54s\n",
      "epoch 130| loss: 0.01334 | train_rmsle: 0.00039 | train_mae: 0.0648  | train_rmse: 0.08354 | train_mse: 0.00698 | valid_rmsle: 0.00093 | valid_mae: 0.09606 | valid_rmse: 0.12724 | valid_mse: 0.01619 |  0:03:56s\n",
      "epoch 131| loss: 0.01197 | train_rmsle: 0.00031 | train_mae: 0.05591 | train_rmse: 0.07376 | train_mse: 0.00544 | valid_rmsle: 0.00082 | valid_mae: 0.09029 | valid_rmse: 0.12011 | valid_mse: 0.01443 |  0:03:58s\n",
      "epoch 132| loss: 0.01432 | train_rmsle: 0.00068 | train_mae: 0.08403 | train_rmse: 0.10324 | train_mse: 0.01066 | valid_rmsle: 0.00116 | valid_mae: 0.10729 | valid_rmse: 0.1399  | valid_mse: 0.01957 |  0:04:00s\n",
      "epoch 133| loss: 0.01281 | train_rmsle: 0.00063 | train_mae: 0.06831 | train_rmse: 0.09082 | train_mse: 0.00825 | valid_rmsle: 0.0012  | valid_mae: 0.099   | valid_rmse: 0.13301 | valid_mse: 0.01769 |  0:04:02s\n",
      "epoch 134| loss: 0.01039 | train_rmsle: 0.00041 | train_mae: 0.06801 | train_rmse: 0.08638 | train_mse: 0.00746 | valid_rmsle: 0.00085 | valid_mae: 0.09552 | valid_rmse: 0.12248 | valid_mse: 0.015   |  0:04:03s\n",
      "epoch 135| loss: 0.01071 | train_rmsle: 0.00051 | train_mae: 0.07796 | train_rmse: 0.09508 | train_mse: 0.00904 | valid_rmsle: 0.00099 | valid_mae: 0.1039  | valid_rmse: 0.13102 | valid_mse: 0.01717 |  0:04:05s\n",
      "epoch 136| loss: 0.01064 | train_rmsle: 0.00042 | train_mae: 0.06536 | train_rmse: 0.0824  | train_mse: 0.00679 | valid_rmsle: 0.00089 | valid_mae: 0.09322 | valid_rmse: 0.12118 | valid_mse: 0.01468 |  0:04:07s\n",
      "epoch 137| loss: 0.01202 | train_rmsle: 0.0004  | train_mae: 0.0671  | train_rmse: 0.08577 | train_mse: 0.00736 | valid_rmsle: 0.00091 | valid_mae: 0.09858 | valid_rmse: 0.12955 | valid_mse: 0.01678 |  0:04:09s\n",
      "epoch 138| loss: 0.01082 | train_rmsle: 0.00031 | train_mae: 0.05552 | train_rmse: 0.07244 | train_mse: 0.00525 | valid_rmsle: 0.00085 | valid_mae: 0.09085 | valid_rmse: 0.1216  | valid_mse: 0.01479 |  0:04:11s\n",
      "epoch 139| loss: 0.01142 | train_rmsle: 0.00038 | train_mae: 0.06034 | train_rmse: 0.07809 | train_mse: 0.0061  | valid_rmsle: 0.00089 | valid_mae: 0.0938  | valid_rmse: 0.12412 | valid_mse: 0.0154  |  0:04:12s\n",
      "epoch 140| loss: 0.01094 | train_rmsle: 0.0005  | train_mae: 0.07152 | train_rmse: 0.08826 | train_mse: 0.00779 | valid_rmsle: 0.001   | valid_mae: 0.09833 | valid_rmse: 0.12714 | valid_mse: 0.01617 |  0:04:14s\n",
      "epoch 141| loss: 0.01359 | train_rmsle: 0.00034 | train_mae: 0.06222 | train_rmse: 0.07891 | train_mse: 0.00623 | valid_rmsle: 0.00086 | valid_mae: 0.0944  | valid_rmse: 0.12334 | valid_mse: 0.01521 |  0:04:16s\n",
      "epoch 142| loss: 0.01311 | train_rmsle: 0.00102 | train_mae: 0.12095 | train_rmse: 0.13511 | train_mse: 0.01826 | valid_rmsle: 0.0015  | valid_mae: 0.1357  | valid_rmse: 0.1623  | valid_mse: 0.02634 |  0:04:18s\n",
      "epoch 143| loss: 0.01268 | train_rmsle: 0.00042 | train_mae: 0.05789 | train_rmse: 0.07747 | train_mse: 0.006   | valid_rmsle: 0.00099 | valid_mae: 0.09238 | valid_rmse: 0.12391 | valid_mse: 0.01535 |  0:04:20s\n",
      "epoch 144| loss: 0.01077 | train_rmsle: 0.00022 | train_mae: 0.04766 | train_rmse: 0.06303 | train_mse: 0.00397 | valid_rmsle: 0.00074 | valid_mae: 0.08536 | valid_rmse: 0.11396 | valid_mse: 0.01299 |  0:04:21s\n",
      "epoch 145| loss: 0.01497 | train_rmsle: 0.00053 | train_mae: 0.08307 | train_rmse: 0.10038 | train_mse: 0.01008 | valid_rmsle: 0.00111 | valid_mae: 0.11095 | valid_rmse: 0.14212 | valid_mse: 0.0202  |  0:04:23s\n",
      "epoch 146| loss: 0.01486 | train_rmsle: 0.00035 | train_mae: 0.06246 | train_rmse: 0.07898 | train_mse: 0.00624 | valid_rmsle: 0.00089 | valid_mae: 0.09597 | valid_rmse: 0.12651 | valid_mse: 0.01601 |  0:04:25s\n",
      "epoch 147| loss: 0.01255 | train_rmsle: 0.00052 | train_mae: 0.08112 | train_rmse: 0.09818 | train_mse: 0.00964 | valid_rmsle: 0.00098 | valid_mae: 0.10686 | valid_rmse: 0.1342  | valid_mse: 0.01801 |  0:04:27s\n",
      "epoch 148| loss: 0.01117 | train_rmsle: 0.00023 | train_mae: 0.04788 | train_rmse: 0.06311 | train_mse: 0.00398 | valid_rmsle: 0.00071 | valid_mae: 0.08363 | valid_rmse: 0.11116 | valid_mse: 0.01236 |  0:04:29s\n",
      "epoch 149| loss: 0.01001 | train_rmsle: 0.00114 | train_mae: 0.11369 | train_rmse: 0.12918 | train_mse: 0.01669 | valid_rmsle: 0.00164 | valid_mae: 0.12944 | valid_rmse: 0.15902 | valid_mse: 0.02529 |  0:04:30s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 148 and best_valid_mse = 0.01236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.013309108065665773 RMSE: 0.11536510766113718 R2: 0.9410857068398484 MAE: 0.08573269865782535\n",
      "=====================================\n",
      "[100/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 2.55594 | train_rmsle: 0.09477 | train_mae: 1.08757 | train_rmse: 1.17947 | train_mse: 1.39116 | valid_rmsle: 0.09529 | valid_mae: 1.09056 | valid_rmse: 1.18399 | valid_mse: 1.40182 |  0:00:01s\n",
      "epoch 1  | loss: 0.57373 | train_rmsle: 0.07849 | train_mae: 1.00133 | train_rmse: 1.08985 | train_mse: 1.18777 | valid_rmsle: 0.07876 | valid_mae: 1.00408 | valid_rmse: 1.09323 | valid_mse: 1.19514 |  0:00:03s\n",
      "epoch 2  | loss: 0.40217 | train_rmsle: 0.05229 | train_mae: 0.82326 | train_rmse: 0.91588 | train_mse: 0.83883 | valid_rmsle: 0.05239 | valid_mae: 0.82398 | valid_rmse: 0.91877 | valid_mse: 0.84414 |  0:00:05s\n",
      "epoch 3  | loss: 0.42356 | train_rmsle: 0.07212 | train_mae: 0.96028 | train_rmse: 1.05172 | train_mse: 1.10611 | valid_rmsle: 0.07233 | valid_mae: 0.96234 | valid_rmse: 1.05488 | valid_mse: 1.11277 |  0:00:07s\n",
      "epoch 4  | loss: 0.59322 | train_rmsle: 0.01688 | train_mae: 0.44366 | train_rmse: 0.53286 | train_mse: 0.28394 | valid_rmsle: 0.0164  | valid_mae: 0.44431 | valid_rmse: 0.53019 | valid_mse: 0.2811  |  0:00:09s\n",
      "epoch 5  | loss: 0.85333 | train_rmsle: 0.15492 | train_mae: 1.35952 | train_rmse: 1.43822 | train_mse: 2.06848 | valid_rmsle: 0.15587 | valid_mae: 1.36455 | valid_rmse: 1.44344 | valid_mse: 2.08352 |  0:00:10s\n",
      "epoch 6  | loss: 0.76832 | train_rmsle: 0.02088 | train_mae: 0.50611 | train_rmse: 0.59707 | train_mse: 0.35649 | valid_rmsle: 0.02038 | valid_mae: 0.50604 | valid_rmse: 0.5943  | valid_mse: 0.3532  |  0:00:12s\n",
      "epoch 7  | loss: 0.2555  | train_rmsle: 0.02383 | train_mae: 0.54629 | train_rmse: 0.63821 | train_mse: 0.40731 | valid_rmsle: 0.02367 | valid_mae: 0.54425 | valid_rmse: 0.63979 | valid_mse: 0.40934 |  0:00:14s\n",
      "epoch 8  | loss: 0.26065 | train_rmsle: 0.0152  | train_mae: 0.41181 | train_rmse: 0.50165 | train_mse: 0.25166 | valid_rmsle: 0.0146  | valid_mae: 0.41094 | valid_rmse: 0.49681 | valid_mse: 0.24682 |  0:00:16s\n",
      "epoch 9  | loss: 0.25261 | train_rmsle: 0.02005 | train_mae: 0.49388 | train_rmse: 0.58552 | train_mse: 0.34284 | valid_rmsle: 0.01975 | valid_mae: 0.49518 | valid_rmse: 0.58518 | valid_mse: 0.34243 |  0:00:18s\n",
      "epoch 10 | loss: 0.23398 | train_rmsle: 0.01573 | train_mae: 0.42017 | train_rmse: 0.51222 | train_mse: 0.26237 | valid_rmsle: 0.01553 | valid_mae: 0.42696 | valid_rmse: 0.51432 | valid_mse: 0.26453 |  0:00:20s\n",
      "epoch 11 | loss: 0.23575 | train_rmsle: 0.02414 | train_mae: 0.55162 | train_rmse: 0.64235 | train_mse: 0.41262 | valid_rmsle: 0.02393 | valid_mae: 0.55197 | valid_rmse: 0.64328 | valid_mse: 0.41381 |  0:00:21s\n",
      "epoch 12 | loss: 0.23768 | train_rmsle: 0.01525 | train_mae: 0.41526 | train_rmse: 0.50502 | train_mse: 0.25504 | valid_rmsle: 0.01471 | valid_mae: 0.41353 | valid_rmse: 0.50129 | valid_mse: 0.25129 |  0:00:23s\n",
      "epoch 13 | loss: 0.22476 | train_rmsle: 0.01575 | train_mae: 0.42333 | train_rmse: 0.51478 | train_mse: 0.26499 | valid_rmsle: 0.01517 | valid_mae: 0.42311 | valid_rmse: 0.51081 | valid_mse: 0.26093 |  0:00:25s\n",
      "epoch 14 | loss: 0.2229  | train_rmsle: 0.01459 | train_mae: 0.40113 | train_rmse: 0.49174 | train_mse: 0.24181 | valid_rmsle: 0.01396 | valid_mae: 0.40054 | valid_rmse: 0.48669 | valid_mse: 0.23686 |  0:00:27s\n",
      "epoch 15 | loss: 0.2305  | train_rmsle: 0.01856 | train_mae: 0.47321 | train_rmse: 0.5634  | train_mse: 0.31742 | valid_rmsle: 0.0181  | valid_mae: 0.47009 | valid_rmse: 0.56096 | valid_mse: 0.31467 |  0:00:29s\n",
      "epoch 16 | loss: 0.21748 | train_rmsle: 0.01402 | train_mae: 0.36883 | train_rmse: 0.47081 | train_mse: 0.22166 | valid_rmsle: 0.01313 | valid_mae: 0.36592 | valid_rmse: 0.46003 | valid_mse: 0.21163 |  0:00:30s\n",
      "epoch 17 | loss: 0.21772 | train_rmsle: 0.01467 | train_mae: 0.40197 | train_rmse: 0.49256 | train_mse: 0.24262 | valid_rmsle: 0.01396 | valid_mae: 0.40023 | valid_rmse: 0.4852  | valid_mse: 0.23542 |  0:00:32s\n",
      "epoch 18 | loss: 0.21621 | train_rmsle: 0.0129  | train_mae: 0.3683  | train_rmse: 0.45771 | train_mse: 0.2095  | valid_rmsle: 0.01217 | valid_mae: 0.36263 | valid_rmse: 0.44897 | valid_mse: 0.20158 |  0:00:34s\n",
      "epoch 19 | loss: 0.20151 | train_rmsle: 0.01303 | train_mae: 0.37542 | train_rmse: 0.46256 | train_mse: 0.21396 | valid_rmsle: 0.01219 | valid_mae: 0.36973 | valid_rmse: 0.45195 | valid_mse: 0.20425 |  0:00:36s\n",
      "epoch 20 | loss: 0.19248 | train_rmsle: 0.01143 | train_mae: 0.33447 | train_rmse: 0.42664 | train_mse: 0.18202 | valid_rmsle: 0.01086 | valid_mae: 0.33076 | valid_rmse: 0.42014 | valid_mse: 0.17652 |  0:00:38s\n",
      "epoch 21 | loss: 0.18073 | train_rmsle: 0.01055 | train_mae: 0.32258 | train_rmse: 0.41182 | train_mse: 0.1696  | valid_rmsle: 0.0102  | valid_mae: 0.3187  | valid_rmse: 0.40765 | valid_mse: 0.16618 |  0:00:39s\n",
      "epoch 22 | loss: 0.16616 | train_rmsle: 0.00987 | train_mae: 0.31477 | train_rmse: 0.39876 | train_mse: 0.15901 | valid_rmsle: 0.00944 | valid_mae: 0.3077  | valid_rmse: 0.39448 | valid_mse: 0.15562 |  0:00:41s\n",
      "epoch 23 | loss: 0.14507 | train_rmsle: 0.00852 | train_mae: 0.27877 | train_rmse: 0.36435 | train_mse: 0.13275 | valid_rmsle: 0.00836 | valid_mae: 0.27705 | valid_rmse: 0.36477 | valid_mse: 0.13306 |  0:00:43s\n",
      "epoch 24 | loss: 0.13086 | train_rmsle: 0.00777 | train_mae: 0.26229 | train_rmse: 0.34525 | train_mse: 0.1192  | valid_rmsle: 0.00732 | valid_mae: 0.25767 | valid_rmse: 0.34002 | valid_mse: 0.11561 |  0:00:45s\n",
      "epoch 25 | loss: 0.11568 | train_rmsle: 0.00756 | train_mae: 0.263   | train_rmse: 0.34255 | train_mse: 0.11734 | valid_rmsle: 0.00711 | valid_mae: 0.2583  | valid_rmse: 0.33773 | valid_mse: 0.11406 |  0:00:47s\n",
      "epoch 26 | loss: 0.1138  | train_rmsle: 0.00728 | train_mae: 0.26275 | train_rmse: 0.3375  | train_mse: 0.11391 | valid_rmsle: 0.00696 | valid_mae: 0.25866 | valid_rmse: 0.33433 | valid_mse: 0.11178 |  0:00:48s\n",
      "epoch 27 | loss: 0.11018 | train_rmsle: 0.00701 | train_mae: 0.25464 | train_rmse: 0.32939 | train_mse: 0.1085  | valid_rmsle: 0.00684 | valid_mae: 0.25246 | valid_rmse: 0.3306  | valid_mse: 0.1093  |  0:00:50s\n",
      "epoch 28 | loss: 0.10567 | train_rmsle: 0.00766 | train_mae: 0.27625 | train_rmse: 0.34878 | train_mse: 0.12164 | valid_rmsle: 0.00719 | valid_mae: 0.26707 | valid_rmse: 0.3416  | valid_mse: 0.11669 |  0:00:52s\n",
      "epoch 29 | loss: 0.10427 | train_rmsle: 0.00843 | train_mae: 0.2914  | train_rmse: 0.3654  | train_mse: 0.13352 | valid_rmsle: 0.00777 | valid_mae: 0.27928 | valid_rmse: 0.35407 | valid_mse: 0.12537 |  0:00:54s\n",
      "epoch 30 | loss: 0.10162 | train_rmsle: 0.00708 | train_mae: 0.25953 | train_rmse: 0.33236 | train_mse: 0.11047 | valid_rmsle: 0.00653 | valid_mae: 0.25126 | valid_rmse: 0.32288 | valid_mse: 0.10425 |  0:00:56s\n",
      "epoch 31 | loss: 0.10202 | train_rmsle: 0.00675 | train_mae: 0.24211 | train_rmse: 0.3194  | train_mse: 0.10201 | valid_rmsle: 0.00651 | valid_mae: 0.24401 | valid_rmse: 0.31899 | valid_mse: 0.10175 |  0:00:58s\n",
      "epoch 32 | loss: 0.10128 | train_rmsle: 0.00655 | train_mae: 0.24033 | train_rmse: 0.31486 | train_mse: 0.09914 | valid_rmsle: 0.00624 | valid_mae: 0.23689 | valid_rmse: 0.31144 | valid_mse: 0.09699 |  0:00:59s\n",
      "epoch 33 | loss: 0.10178 | train_rmsle: 0.00685 | train_mae: 0.25241 | train_rmse: 0.32514 | train_mse: 0.10572 | valid_rmsle: 0.00656 | valid_mae: 0.24631 | valid_rmse: 0.3218  | valid_mse: 0.10356 |  0:01:01s\n",
      "epoch 34 | loss: 0.10222 | train_rmsle: 0.00666 | train_mae: 0.24036 | train_rmse: 0.31693 | train_mse: 0.10044 | valid_rmsle: 0.00653 | valid_mae: 0.24111 | valid_rmse: 0.31843 | valid_mse: 0.1014  |  0:01:03s\n",
      "epoch 35 | loss: 0.09868 | train_rmsle: 0.00641 | train_mae: 0.24289 | train_rmse: 0.31251 | train_mse: 0.09766 | valid_rmsle: 0.00617 | valid_mae: 0.23955 | valid_rmse: 0.31082 | valid_mse: 0.09661 |  0:01:05s\n",
      "epoch 36 | loss: 0.09625 | train_rmsle: 0.00677 | train_mae: 0.25064 | train_rmse: 0.32299 | train_mse: 0.10432 | valid_rmsle: 0.00647 | valid_mae: 0.24352 | valid_rmse: 0.31916 | valid_mse: 0.10186 |  0:01:07s\n",
      "epoch 37 | loss: 0.10122 | train_rmsle: 0.0064  | train_mae: 0.24533 | train_rmse: 0.31383 | train_mse: 0.09849 | valid_rmsle: 0.00608 | valid_mae: 0.23825 | valid_rmse: 0.3095  | valid_mse: 0.09579 |  0:01:08s\n",
      "epoch 38 | loss: 0.0987  | train_rmsle: 0.00645 | train_mae: 0.24798 | train_rmse: 0.31579 | train_mse: 0.09972 | valid_rmsle: 0.00613 | valid_mae: 0.24117 | valid_rmse: 0.31129 | valid_mse: 0.0969  |  0:01:10s\n",
      "epoch 39 | loss: 0.09571 | train_rmsle: 0.0062  | train_mae: 0.23559 | train_rmse: 0.30679 | train_mse: 0.09412 | valid_rmsle: 0.00601 | valid_mae: 0.23316 | valid_rmse: 0.30636 | valid_mse: 0.09386 |  0:01:12s\n",
      "epoch 40 | loss: 0.09755 | train_rmsle: 0.00616 | train_mae: 0.23294 | train_rmse: 0.30443 | train_mse: 0.09267 | valid_rmsle: 0.00594 | valid_mae: 0.23099 | valid_rmse: 0.30352 | valid_mse: 0.09212 |  0:01:14s\n",
      "epoch 41 | loss: 0.09326 | train_rmsle: 0.00621 | train_mae: 0.23148 | train_rmse: 0.30521 | train_mse: 0.09315 | valid_rmsle: 0.00609 | valid_mae: 0.23317 | valid_rmse: 0.30682 | valid_mse: 0.09414 |  0:01:16s\n",
      "epoch 42 | loss: 0.09334 | train_rmsle: 0.00613 | train_mae: 0.23397 | train_rmse: 0.30491 | train_mse: 0.09297 | valid_rmsle: 0.00601 | valid_mae: 0.23483 | valid_rmse: 0.3065  | valid_mse: 0.09394 |  0:01:18s\n",
      "epoch 43 | loss: 0.09313 | train_rmsle: 0.00602 | train_mae: 0.2323  | train_rmse: 0.3015  | train_mse: 0.0909  | valid_rmsle: 0.00595 | valid_mae: 0.23315 | valid_rmse: 0.30423 | valid_mse: 0.09255 |  0:01:19s\n",
      "epoch 44 | loss: 0.09248 | train_rmsle: 0.0062  | train_mae: 0.22911 | train_rmse: 0.30451 | train_mse: 0.09273 | valid_rmsle: 0.00615 | valid_mae: 0.23296 | valid_rmse: 0.30838 | valid_mse: 0.0951  |  0:01:21s\n",
      "epoch 45 | loss: 0.09286 | train_rmsle: 0.00615 | train_mae: 0.22894 | train_rmse: 0.30335 | train_mse: 0.09202 | valid_rmsle: 0.00623 | valid_mae: 0.23609 | valid_rmse: 0.31088 | valid_mse: 0.09665 |  0:01:23s\n",
      "epoch 46 | loss: 0.09035 | train_rmsle: 0.00615 | train_mae: 0.24218 | train_rmse: 0.30822 | train_mse: 0.095   | valid_rmsle: 0.00611 | valid_mae: 0.24211 | valid_rmse: 0.31134 | valid_mse: 0.09694 |  0:01:25s\n",
      "epoch 47 | loss: 0.09233 | train_rmsle: 0.00655 | train_mae: 0.23468 | train_rmse: 0.31293 | train_mse: 0.09793 | valid_rmsle: 0.0068  | valid_mae: 0.24684 | valid_rmse: 0.32491 | valid_mse: 0.10557 |  0:01:27s\n",
      "epoch 48 | loss: 0.09816 | train_rmsle: 0.00575 | train_mae: 0.22571 | train_rmse: 0.29441 | train_mse: 0.08668 | valid_rmsle: 0.00588 | valid_mae: 0.23002 | valid_rmse: 0.30204 | valid_mse: 0.09123 |  0:01:28s\n",
      "epoch 49 | loss: 0.09051 | train_rmsle: 0.00575 | train_mae: 0.22403 | train_rmse: 0.29406 | train_mse: 0.08647 | valid_rmsle: 0.00598 | valid_mae: 0.23121 | valid_rmse: 0.3053  | valid_mse: 0.09321 |  0:01:30s\n",
      "epoch 50 | loss: 0.09153 | train_rmsle: 0.00653 | train_mae: 0.23259 | train_rmse: 0.31281 | train_mse: 0.09785 | valid_rmsle: 0.00688 | valid_mae: 0.24606 | valid_rmse: 0.32742 | valid_mse: 0.1072  |  0:01:32s\n",
      "epoch 51 | loss: 0.09011 | train_rmsle: 0.00606 | train_mae: 0.24054 | train_rmse: 0.30666 | train_mse: 0.09404 | valid_rmsle: 0.00622 | valid_mae: 0.24371 | valid_rmse: 0.31517 | valid_mse: 0.09933 |  0:01:34s\n",
      "epoch 52 | loss: 0.08797 | train_rmsle: 0.00594 | train_mae: 0.22641 | train_rmse: 0.29926 | train_mse: 0.08956 | valid_rmsle: 0.00625 | valid_mae: 0.23998 | valid_rmse: 0.31368 | valid_mse: 0.0984  |  0:01:36s\n",
      "epoch 53 | loss: 0.08928 | train_rmsle: 0.00562 | train_mae: 0.23071 | train_rmse: 0.29496 | train_mse: 0.087   | valid_rmsle: 0.00577 | valid_mae: 0.23452 | valid_rmse: 0.30294 | valid_mse: 0.09177 |  0:01:37s\n",
      "epoch 54 | loss: 0.08529 | train_rmsle: 0.00587 | train_mae: 0.24057 | train_rmse: 0.30374 | train_mse: 0.09226 | valid_rmsle: 0.00605 | valid_mae: 0.24494 | valid_rmse: 0.31174 | valid_mse: 0.09718 |  0:01:39s\n",
      "epoch 55 | loss: 0.08578 | train_rmsle: 0.00545 | train_mae: 0.22523 | train_rmse: 0.29009 | train_mse: 0.08415 | valid_rmsle: 0.00575 | valid_mae: 0.23573 | valid_rmse: 0.30273 | valid_mse: 0.09165 |  0:01:41s\n",
      "epoch 56 | loss: 0.0856  | train_rmsle: 0.00548 | train_mae: 0.22314 | train_rmse: 0.29026 | train_mse: 0.08425 | valid_rmsle: 0.00565 | valid_mae: 0.23106 | valid_rmse: 0.29974 | valid_mse: 0.08985 |  0:01:43s\n",
      "epoch 57 | loss: 0.08536 | train_rmsle: 0.00533 | train_mae: 0.22359 | train_rmse: 0.28786 | train_mse: 0.08287 | valid_rmsle: 0.00535 | valid_mae: 0.22822 | valid_rmse: 0.29326 | valid_mse: 0.086   |  0:01:45s\n",
      "epoch 58 | loss: 0.08128 | train_rmsle: 0.00528 | train_mae: 0.22559 | train_rmse: 0.28852 | train_mse: 0.08325 | valid_rmsle: 0.0053  | valid_mae: 0.2305  | valid_rmse: 0.29306 | valid_mse: 0.08588 |  0:01:46s\n",
      "epoch 59 | loss: 0.08193 | train_rmsle: 0.005   | train_mae: 0.22126 | train_rmse: 0.28112 | train_mse: 0.07903 | valid_rmsle: 0.00503 | valid_mae: 0.22866 | valid_rmse: 0.28719 | valid_mse: 0.08248 |  0:01:48s\n",
      "epoch 60 | loss: 0.07712 | train_rmsle: 0.00494 | train_mae: 0.22198 | train_rmse: 0.28111 | train_mse: 0.07902 | valid_rmsle: 0.00499 | valid_mae: 0.22777 | valid_rmse: 0.28676 | valid_mse: 0.08223 |  0:01:50s\n",
      "epoch 61 | loss: 0.07324 | train_rmsle: 0.00568 | train_mae: 0.23399 | train_rmse: 0.29963 | train_mse: 0.08978 | valid_rmsle: 0.00593 | valid_mae: 0.244   | valid_rmse: 0.31082 | valid_mse: 0.09661 |  0:01:52s\n",
      "epoch 62 | loss: 0.06731 | train_rmsle: 0.0045  | train_mae: 0.21151 | train_rmse: 0.26854 | train_mse: 0.07212 | valid_rmsle: 0.00476 | valid_mae: 0.22227 | valid_rmse: 0.28018 | valid_mse: 0.0785  |  0:01:54s\n",
      "epoch 63 | loss: 0.0623  | train_rmsle: 0.00383 | train_mae: 0.18701 | train_rmse: 0.24423 | train_mse: 0.05965 | valid_rmsle: 0.00425 | valid_mae: 0.20543 | valid_rmse: 0.26281 | valid_mse: 0.06907 |  0:01:56s\n",
      "epoch 64 | loss: 0.06061 | train_rmsle: 0.0039  | train_mae: 0.19674 | train_rmse: 0.24995 | train_mse: 0.06247 | valid_rmsle: 0.00427 | valid_mae: 0.21179 | valid_rmse: 0.26622 | valid_mse: 0.07087 |  0:01:57s\n",
      "epoch 65 | loss: 0.05886 | train_rmsle: 0.00361 | train_mae: 0.18751 | train_rmse: 0.2393  | train_mse: 0.05726 | valid_rmsle: 0.00408 | valid_mae: 0.20677 | valid_rmse: 0.25942 | valid_mse: 0.0673  |  0:01:59s\n",
      "epoch 66 | loss: 0.0549  | train_rmsle: 0.00331 | train_mae: 0.17846 | train_rmse: 0.22883 | train_mse: 0.05236 | valid_rmsle: 0.00373 | valid_mae: 0.1968  | valid_rmse: 0.24753 | valid_mse: 0.06127 |  0:02:01s\n",
      "epoch 67 | loss: 0.05342 | train_rmsle: 0.00361 | train_mae: 0.19256 | train_rmse: 0.24164 | train_mse: 0.05839 | valid_rmsle: 0.00401 | valid_mae: 0.2079  | valid_rmse: 0.25865 | valid_mse: 0.0669  |  0:02:03s\n",
      "epoch 68 | loss: 0.0506  | train_rmsle: 0.00287 | train_mae: 0.16159 | train_rmse: 0.21105 | train_mse: 0.04454 | valid_rmsle: 0.00339 | valid_mae: 0.18643 | valid_rmse: 0.23584 | valid_mse: 0.05562 |  0:02:04s\n",
      "epoch 69 | loss: 0.05372 | train_rmsle: 0.00293 | train_mae: 0.16808 | train_rmse: 0.21569 | train_mse: 0.04652 | valid_rmsle: 0.00342 | valid_mae: 0.19013 | valid_rmse: 0.23792 | valid_mse: 0.0566  |  0:02:06s\n",
      "epoch 70 | loss: 0.0501  | train_rmsle: 0.00269 | train_mae: 0.15789 | train_rmse: 0.20481 | train_mse: 0.04195 | valid_rmsle: 0.00329 | valid_mae: 0.18479 | valid_rmse: 0.23285 | valid_mse: 0.05422 |  0:02:08s\n",
      "epoch 71 | loss: 0.04745 | train_rmsle: 0.00337 | train_mae: 0.19004 | train_rmse: 0.23506 | train_mse: 0.05525 | valid_rmsle: 0.00388 | valid_mae: 0.20675 | valid_rmse: 0.25563 | valid_mse: 0.06535 |  0:02:10s\n",
      "epoch 72 | loss: 0.04619 | train_rmsle: 0.00234 | train_mae: 0.14405 | train_rmse: 0.19065 | train_mse: 0.03635 | valid_rmsle: 0.00297 | valid_mae: 0.17577 | valid_rmse: 0.22205 | valid_mse: 0.04931 |  0:02:12s\n",
      "epoch 73 | loss: 0.04198 | train_rmsle: 0.00237 | train_mae: 0.14316 | train_rmse: 0.19133 | train_mse: 0.03661 | valid_rmsle: 0.00302 | valid_mae: 0.17487 | valid_rmse: 0.22437 | valid_mse: 0.05034 |  0:02:13s\n",
      "epoch 74 | loss: 0.04007 | train_rmsle: 0.00223 | train_mae: 0.14289 | train_rmse: 0.18715 | train_mse: 0.03503 | valid_rmsle: 0.00283 | valid_mae: 0.17271 | valid_rmse: 0.21807 | valid_mse: 0.04755 |  0:02:15s\n",
      "epoch 75 | loss: 0.03712 | train_rmsle: 0.00234 | train_mae: 0.15118 | train_rmse: 0.19445 | train_mse: 0.03781 | valid_rmsle: 0.00285 | valid_mae: 0.17701 | valid_rmse: 0.22023 | valid_mse: 0.0485  |  0:02:17s\n",
      "epoch 76 | loss: 0.03713 | train_rmsle: 0.00206 | train_mae: 0.13392 | train_rmse: 0.17917 | train_mse: 0.0321  | valid_rmsle: 0.00267 | valid_mae: 0.16708 | valid_rmse: 0.21321 | valid_mse: 0.04546 |  0:02:19s\n",
      "epoch 77 | loss: 0.03492 | train_rmsle: 0.00195 | train_mae: 0.13324 | train_rmse: 0.17516 | train_mse: 0.03068 | valid_rmsle: 0.00253 | valid_mae: 0.16511 | valid_rmse: 0.20706 | valid_mse: 0.04287 |  0:02:21s\n",
      "epoch 78 | loss: 0.03155 | train_rmsle: 0.00175 | train_mae: 0.12319 | train_rmse: 0.16491 | train_mse: 0.02719 | valid_rmsle: 0.0023  | valid_mae: 0.15573 | valid_rmse: 0.197   | valid_mse: 0.03881 |  0:02:22s\n",
      "epoch 79 | loss: 0.03048 | train_rmsle: 0.00179 | train_mae: 0.12802 | train_rmse: 0.16828 | train_mse: 0.02832 | valid_rmsle: 0.00228 | valid_mae: 0.15654 | valid_rmse: 0.19717 | valid_mse: 0.03888 |  0:02:24s\n",
      "epoch 80 | loss: 0.02965 | train_rmsle: 0.00169 | train_mae: 0.12328 | train_rmse: 0.16346 | train_mse: 0.02672 | valid_rmsle: 0.00218 | valid_mae: 0.15237 | valid_rmse: 0.1929  | valid_mse: 0.03721 |  0:02:26s\n",
      "epoch 81 | loss: 0.03215 | train_rmsle: 0.00152 | train_mae: 0.11471 | train_rmse: 0.15364 | train_mse: 0.02361 | valid_rmsle: 0.00204 | valid_mae: 0.14578 | valid_rmse: 0.1861  | valid_mse: 0.03463 |  0:02:28s\n",
      "epoch 82 | loss: 0.02931 | train_rmsle: 0.0027  | train_mae: 0.17719 | train_rmse: 0.21248 | train_mse: 0.04515 | valid_rmsle: 0.00316 | valid_mae: 0.18983 | valid_rmse: 0.23345 | valid_mse: 0.0545  |  0:02:30s\n",
      "epoch 83 | loss: 0.03296 | train_rmsle: 0.00143 | train_mae: 0.11272 | train_rmse: 0.15055 | train_mse: 0.02267 | valid_rmsle: 0.002   | valid_mae: 0.14533 | valid_rmse: 0.18585 | valid_mse: 0.03454 |  0:02:31s\n",
      "epoch 84 | loss: 0.02925 | train_rmsle: 0.00207 | train_mae: 0.14886 | train_rmse: 0.18446 | train_mse: 0.03402 | valid_rmsle: 0.00248 | valid_mae: 0.16594 | valid_rmse: 0.2066  | valid_mse: 0.04268 |  0:02:33s\n",
      "epoch 85 | loss: 0.02714 | train_rmsle: 0.00124 | train_mae: 0.10341 | train_rmse: 0.13935 | train_mse: 0.01942 | valid_rmsle: 0.00172 | valid_mae: 0.13348 | valid_rmse: 0.17177 | valid_mse: 0.02951 |  0:02:35s\n",
      "epoch 86 | loss: 0.02434 | train_rmsle: 0.00154 | train_mae: 0.12536 | train_rmse: 0.16105 | train_mse: 0.02594 | valid_rmsle: 0.00201 | valid_mae: 0.14874 | valid_rmse: 0.18825 | valid_mse: 0.03544 |  0:02:37s\n",
      "epoch 87 | loss: 0.02579 | train_rmsle: 0.00111 | train_mae: 0.09803 | train_rmse: 0.13293 | train_mse: 0.01767 | valid_rmsle: 0.00165 | valid_mae: 0.13057 | valid_rmse: 0.16913 | valid_mse: 0.0286  |  0:02:39s\n",
      "epoch 88 | loss: 0.02431 | train_rmsle: 0.00113 | train_mae: 0.10055 | train_rmse: 0.13497 | train_mse: 0.01822 | valid_rmsle: 0.00166 | valid_mae: 0.13258 | valid_rmse: 0.16999 | valid_mse: 0.0289  |  0:02:40s\n",
      "epoch 89 | loss: 0.0276  | train_rmsle: 0.00128 | train_mae: 0.11252 | train_rmse: 0.14543 | train_mse: 0.02115 | valid_rmsle: 0.00183 | valid_mae: 0.14017 | valid_rmse: 0.17874 | valid_mse: 0.03195 |  0:02:42s\n",
      "epoch 90 | loss: 0.02384 | train_rmsle: 0.00131 | train_mae: 0.11539 | train_rmse: 0.14724 | train_mse: 0.02168 | valid_rmsle: 0.00185 | valid_mae: 0.14274 | valid_rmse: 0.18009 | valid_mse: 0.03243 |  0:02:44s\n",
      "epoch 91 | loss: 0.024   | train_rmsle: 0.00098 | train_mae: 0.09156 | train_rmse: 0.124   | train_mse: 0.01538 | valid_rmsle: 0.00155 | valid_mae: 0.12585 | valid_rmse: 0.16374 | valid_mse: 0.02681 |  0:02:46s\n",
      "epoch 92 | loss: 0.02099 | train_rmsle: 0.00095 | train_mae: 0.09185 | train_rmse: 0.12379 | train_mse: 0.01532 | valid_rmsle: 0.00157 | valid_mae: 0.12755 | valid_rmse: 0.16593 | valid_mse: 0.02753 |  0:02:48s\n",
      "epoch 93 | loss: 0.0197  | train_rmsle: 0.00125 | train_mae: 0.11255 | train_rmse: 0.1428  | train_mse: 0.02039 | valid_rmsle: 0.00177 | valid_mae: 0.13788 | valid_rmse: 0.17449 | valid_mse: 0.03045 |  0:02:49s\n",
      "epoch 94 | loss: 0.02551 | train_rmsle: 0.00131 | train_mae: 0.12019 | train_rmse: 0.15024 | train_mse: 0.02257 | valid_rmsle: 0.00182 | valid_mae: 0.14301 | valid_rmse: 0.17963 | valid_mse: 0.03227 |  0:02:51s\n",
      "epoch 95 | loss: 0.02509 | train_rmsle: 0.00084 | train_mae: 0.08602 | train_rmse: 0.11581 | train_mse: 0.01341 | valid_rmsle: 0.00138 | valid_mae: 0.11858 | valid_rmse: 0.15547 | valid_mse: 0.02417 |  0:02:53s\n",
      "epoch 96 | loss: 0.02149 | train_rmsle: 0.00086 | train_mae: 0.08756 | train_rmse: 0.11811 | train_mse: 0.01395 | valid_rmsle: 0.00142 | valid_mae: 0.12121 | valid_rmse: 0.15879 | valid_mse: 0.02521 |  0:02:55s\n",
      "epoch 97 | loss: 0.02045 | train_rmsle: 0.00082 | train_mae: 0.08624 | train_rmse: 0.11526 | train_mse: 0.01328 | valid_rmsle: 0.00132 | valid_mae: 0.11649 | valid_rmse: 0.15163 | valid_mse: 0.02299 |  0:02:57s\n",
      "epoch 98 | loss: 0.01686 | train_rmsle: 0.0008  | train_mae: 0.08799 | train_rmse: 0.11651 | train_mse: 0.01358 | valid_rmsle: 0.00133 | valid_mae: 0.11855 | valid_rmse: 0.1533  | valid_mse: 0.0235  |  0:02:58s\n",
      "epoch 99 | loss: 0.01855 | train_rmsle: 0.00077 | train_mae: 0.08557 | train_rmse: 0.11254 | train_mse: 0.01267 | valid_rmsle: 0.0013  | valid_mae: 0.11563 | valid_rmse: 0.14997 | valid_mse: 0.02249 |  0:03:00s\n",
      "epoch 100| loss: 0.01848 | train_rmsle: 0.00079 | train_mae: 0.0867  | train_rmse: 0.11372 | train_mse: 0.01293 | valid_rmsle: 0.00136 | valid_mae: 0.11726 | valid_rmse: 0.15324 | valid_mse: 0.02348 |  0:03:02s\n",
      "epoch 101| loss: 0.01793 | train_rmsle: 0.00079 | train_mae: 0.09132 | train_rmse: 0.11785 | train_mse: 0.01389 | valid_rmsle: 0.00137 | valid_mae: 0.12028 | valid_rmse: 0.15551 | valid_mse: 0.02418 |  0:03:04s\n",
      "epoch 102| loss: 0.0171  | train_rmsle: 0.00096 | train_mae: 0.09808 | train_rmse: 0.12408 | train_mse: 0.01539 | valid_rmsle: 0.00151 | valid_mae: 0.12621 | valid_rmse: 0.16147 | valid_mse: 0.02607 |  0:03:06s\n",
      "epoch 103| loss: 0.01573 | train_rmsle: 0.00062 | train_mae: 0.07734 | train_rmse: 0.10214 | train_mse: 0.01043 | valid_rmsle: 0.00121 | valid_mae: 0.11151 | valid_rmse: 0.14521 | valid_mse: 0.02108 |  0:03:07s\n",
      "epoch 104| loss: 0.01685 | train_rmsle: 0.00111 | train_mae: 0.11673 | train_rmse: 0.14173 | train_mse: 0.02009 | valid_rmsle: 0.00166 | valid_mae: 0.13676 | valid_rmse: 0.17239 | valid_mse: 0.02972 |  0:03:09s\n",
      "epoch 105| loss: 0.01941 | train_rmsle: 0.00109 | train_mae: 0.09183 | train_rmse: 0.12217 | train_mse: 0.01493 | valid_rmsle: 0.00174 | valid_mae: 0.1194  | valid_rmse: 0.15997 | valid_mse: 0.02559 |  0:03:11s\n",
      "epoch 106| loss: 0.01412 | train_rmsle: 0.00066 | train_mae: 0.08411 | train_rmse: 0.10862 | train_mse: 0.0118  | valid_rmsle: 0.00115 | valid_mae: 0.11097 | valid_rmse: 0.14284 | valid_mse: 0.0204  |  0:03:13s\n",
      "epoch 107| loss: 0.0151  | train_rmsle: 0.00085 | train_mae: 0.08763 | train_rmse: 0.11364 | train_mse: 0.01291 | valid_rmsle: 0.00147 | valid_mae: 0.11505 | valid_rmse: 0.15303 | valid_mse: 0.02342 |  0:03:15s\n",
      "epoch 108| loss: 0.01987 | train_rmsle: 0.00054 | train_mae: 0.0697  | train_rmse: 0.09423 | train_mse: 0.00888 | valid_rmsle: 0.00106 | valid_mae: 0.10272 | valid_rmse: 0.13593 | valid_mse: 0.01848 |  0:03:16s\n",
      "epoch 109| loss: 0.01696 | train_rmsle: 0.00057 | train_mae: 0.07377 | train_rmse: 0.09673 | train_mse: 0.00936 | valid_rmsle: 0.00113 | valid_mae: 0.10465 | valid_rmse: 0.13788 | valid_mse: 0.01901 |  0:03:18s\n",
      "epoch 110| loss: 0.01558 | train_rmsle: 0.00051 | train_mae: 0.0695  | train_rmse: 0.09223 | train_mse: 0.00851 | valid_rmsle: 0.00102 | valid_mae: 0.1007  | valid_rmse: 0.133   | valid_mse: 0.01769 |  0:03:20s\n",
      "epoch 111| loss: 0.01245 | train_rmsle: 0.00047 | train_mae: 0.06947 | train_rmse: 0.09154 | train_mse: 0.00838 | valid_rmsle: 0.00102 | valid_mae: 0.10268 | valid_rmse: 0.13438 | valid_mse: 0.01806 |  0:03:22s\n",
      "epoch 112| loss: 0.01343 | train_rmsle: 0.00041 | train_mae: 0.06368 | train_rmse: 0.08471 | train_mse: 0.00718 | valid_rmsle: 0.00096 | valid_mae: 0.09865 | valid_rmse: 0.13078 | valid_mse: 0.0171  |  0:03:24s\n",
      "epoch 113| loss: 0.01282 | train_rmsle: 0.00074 | train_mae: 0.07683 | train_rmse: 0.10237 | train_mse: 0.01048 | valid_rmsle: 0.00138 | valid_mae: 0.10944 | valid_rmse: 0.1465  | valid_mse: 0.02146 |  0:03:26s\n",
      "epoch 114| loss: 0.01239 | train_rmsle: 0.00041 | train_mae: 0.06376 | train_rmse: 0.08477 | train_mse: 0.00719 | valid_rmsle: 0.00098 | valid_mae: 0.0994  | valid_rmse: 0.13145 | valid_mse: 0.01728 |  0:03:27s\n",
      "epoch 115| loss: 0.01451 | train_rmsle: 0.00041 | train_mae: 0.06338 | train_rmse: 0.08409 | train_mse: 0.00707 | valid_rmsle: 0.001   | valid_mae: 0.09909 | valid_rmse: 0.13246 | valid_mse: 0.01755 |  0:03:29s\n",
      "epoch 116| loss: 0.01405 | train_rmsle: 0.00043 | train_mae: 0.0655  | train_rmse: 0.08654 | train_mse: 0.00749 | valid_rmsle: 0.00099 | valid_mae: 0.09917 | valid_rmse: 0.13191 | valid_mse: 0.0174  |  0:03:31s\n",
      "epoch 117| loss: 0.01234 | train_rmsle: 0.00048 | train_mae: 0.0702  | train_rmse: 0.09181 | train_mse: 0.00843 | valid_rmsle: 0.00098 | valid_mae: 0.10025 | valid_rmse: 0.13183 | valid_mse: 0.01738 |  0:03:33s\n",
      "epoch 118| loss: 0.01367 | train_rmsle: 0.00053 | train_mae: 0.07436 | train_rmse: 0.09671 | train_mse: 0.00935 | valid_rmsle: 0.00103 | valid_mae: 0.10361 | valid_rmse: 0.13491 | valid_mse: 0.0182  |  0:03:35s\n",
      "epoch 119| loss: 0.0156  | train_rmsle: 0.0006  | train_mae: 0.07295 | train_rmse: 0.09529 | train_mse: 0.00908 | valid_rmsle: 0.00115 | valid_mae: 0.10484 | valid_rmse: 0.137   | valid_mse: 0.01877 |  0:03:36s\n",
      "epoch 120| loss: 0.01485 | train_rmsle: 0.00044 | train_mae: 0.06592 | train_rmse: 0.0865  | train_mse: 0.00748 | valid_rmsle: 0.00097 | valid_mae: 0.09866 | valid_rmse: 0.12886 | valid_mse: 0.01661 |  0:03:38s\n",
      "epoch 121| loss: 0.012   | train_rmsle: 0.00041 | train_mae: 0.06423 | train_rmse: 0.08471 | train_mse: 0.00718 | valid_rmsle: 0.00091 | valid_mae: 0.09654 | valid_rmse: 0.12703 | valid_mse: 0.01614 |  0:03:40s\n",
      "epoch 122| loss: 0.01215 | train_rmsle: 0.00046 | train_mae: 0.06654 | train_rmse: 0.08739 | train_mse: 0.00764 | valid_rmsle: 0.00102 | valid_mae: 0.09936 | valid_rmse: 0.13076 | valid_mse: 0.0171  |  0:03:42s\n",
      "epoch 123| loss: 0.01226 | train_rmsle: 0.00045 | train_mae: 0.06576 | train_rmse: 0.08604 | train_mse: 0.0074  | valid_rmsle: 0.00095 | valid_mae: 0.09716 | valid_rmse: 0.12809 | valid_mse: 0.01641 |  0:03:44s\n",
      "epoch 124| loss: 0.01343 | train_rmsle: 0.00046 | train_mae: 0.07022 | train_rmse: 0.09025 | train_mse: 0.00815 | valid_rmsle: 0.00099 | valid_mae: 0.101   | valid_rmse: 0.13124 | valid_mse: 0.01722 |  0:03:45s\n",
      "epoch 125| loss: 0.01136 | train_rmsle: 0.00036 | train_mae: 0.0603  | train_rmse: 0.07994 | train_mse: 0.00639 | valid_rmsle: 0.00088 | valid_mae: 0.09466 | valid_rmse: 0.12397 | valid_mse: 0.01537 |  0:03:47s\n",
      "epoch 126| loss: 0.01083 | train_rmsle: 0.00033 | train_mae: 0.05665 | train_rmse: 0.07546 | train_mse: 0.00569 | valid_rmsle: 0.00088 | valid_mae: 0.0923  | valid_rmse: 0.1232  | valid_mse: 0.01518 |  0:03:49s\n",
      "epoch 127| loss: 0.01167 | train_rmsle: 0.00048 | train_mae: 0.07339 | train_rmse: 0.09363 | train_mse: 0.00877 | valid_rmsle: 0.00095 | valid_mae: 0.10198 | valid_rmse: 0.13039 | valid_mse: 0.017   |  0:03:51s\n",
      "epoch 128| loss: 0.01439 | train_rmsle: 0.0004  | train_mae: 0.06374 | train_rmse: 0.08336 | train_mse: 0.00695 | valid_rmsle: 0.00097 | valid_mae: 0.0974  | valid_rmse: 0.12949 | valid_mse: 0.01677 |  0:03:53s\n",
      "epoch 129| loss: 0.01188 | train_rmsle: 0.00047 | train_mae: 0.06528 | train_rmse: 0.0853  | train_mse: 0.00728 | valid_rmsle: 0.00092 | valid_mae: 0.09592 | valid_rmse: 0.12574 | valid_mse: 0.01581 |  0:03:54s\n",
      "epoch 130| loss: 0.01334 | train_rmsle: 0.00039 | train_mae: 0.0648  | train_rmse: 0.08354 | train_mse: 0.00698 | valid_rmsle: 0.00093 | valid_mae: 0.09606 | valid_rmse: 0.12724 | valid_mse: 0.01619 |  0:03:56s\n",
      "epoch 131| loss: 0.01197 | train_rmsle: 0.00031 | train_mae: 0.05591 | train_rmse: 0.07376 | train_mse: 0.00544 | valid_rmsle: 0.00082 | valid_mae: 0.09029 | valid_rmse: 0.12011 | valid_mse: 0.01443 |  0:03:58s\n",
      "epoch 132| loss: 0.01432 | train_rmsle: 0.00068 | train_mae: 0.08403 | train_rmse: 0.10324 | train_mse: 0.01066 | valid_rmsle: 0.00116 | valid_mae: 0.10729 | valid_rmse: 0.1399  | valid_mse: 0.01957 |  0:04:00s\n",
      "epoch 133| loss: 0.01281 | train_rmsle: 0.00063 | train_mae: 0.06831 | train_rmse: 0.09082 | train_mse: 0.00825 | valid_rmsle: 0.0012  | valid_mae: 0.099   | valid_rmse: 0.13301 | valid_mse: 0.01769 |  0:04:02s\n",
      "epoch 134| loss: 0.01039 | train_rmsle: 0.00041 | train_mae: 0.06801 | train_rmse: 0.08638 | train_mse: 0.00746 | valid_rmsle: 0.00085 | valid_mae: 0.09552 | valid_rmse: 0.12248 | valid_mse: 0.015   |  0:04:03s\n",
      "epoch 135| loss: 0.01071 | train_rmsle: 0.00051 | train_mae: 0.07796 | train_rmse: 0.09508 | train_mse: 0.00904 | valid_rmsle: 0.00099 | valid_mae: 0.1039  | valid_rmse: 0.13102 | valid_mse: 0.01717 |  0:04:05s\n",
      "epoch 136| loss: 0.01064 | train_rmsle: 0.00042 | train_mae: 0.06536 | train_rmse: 0.0824  | train_mse: 0.00679 | valid_rmsle: 0.00089 | valid_mae: 0.09322 | valid_rmse: 0.12118 | valid_mse: 0.01468 |  0:04:07s\n",
      "epoch 137| loss: 0.01202 | train_rmsle: 0.0004  | train_mae: 0.0671  | train_rmse: 0.08577 | train_mse: 0.00736 | valid_rmsle: 0.00091 | valid_mae: 0.09858 | valid_rmse: 0.12955 | valid_mse: 0.01678 |  0:04:09s\n",
      "epoch 138| loss: 0.01082 | train_rmsle: 0.00031 | train_mae: 0.05552 | train_rmse: 0.07244 | train_mse: 0.00525 | valid_rmsle: 0.00085 | valid_mae: 0.09085 | valid_rmse: 0.1216  | valid_mse: 0.01479 |  0:04:11s\n",
      "epoch 139| loss: 0.01142 | train_rmsle: 0.00038 | train_mae: 0.06034 | train_rmse: 0.07809 | train_mse: 0.0061  | valid_rmsle: 0.00089 | valid_mae: 0.0938  | valid_rmse: 0.12412 | valid_mse: 0.0154  |  0:04:12s\n",
      "epoch 140| loss: 0.01094 | train_rmsle: 0.0005  | train_mae: 0.07152 | train_rmse: 0.08826 | train_mse: 0.00779 | valid_rmsle: 0.001   | valid_mae: 0.09833 | valid_rmse: 0.12714 | valid_mse: 0.01617 |  0:04:14s\n",
      "epoch 141| loss: 0.01359 | train_rmsle: 0.00034 | train_mae: 0.06222 | train_rmse: 0.07891 | train_mse: 0.00623 | valid_rmsle: 0.00086 | valid_mae: 0.0944  | valid_rmse: 0.12334 | valid_mse: 0.01521 |  0:04:16s\n",
      "epoch 142| loss: 0.01311 | train_rmsle: 0.00102 | train_mae: 0.12095 | train_rmse: 0.13511 | train_mse: 0.01826 | valid_rmsle: 0.0015  | valid_mae: 0.1357  | valid_rmse: 0.1623  | valid_mse: 0.02634 |  0:04:18s\n",
      "epoch 143| loss: 0.01268 | train_rmsle: 0.00042 | train_mae: 0.05789 | train_rmse: 0.07747 | train_mse: 0.006   | valid_rmsle: 0.00099 | valid_mae: 0.09238 | valid_rmse: 0.12391 | valid_mse: 0.01535 |  0:04:20s\n",
      "epoch 144| loss: 0.01077 | train_rmsle: 0.00022 | train_mae: 0.04766 | train_rmse: 0.06303 | train_mse: 0.00397 | valid_rmsle: 0.00074 | valid_mae: 0.08536 | valid_rmse: 0.11396 | valid_mse: 0.01299 |  0:04:21s\n",
      "epoch 145| loss: 0.01497 | train_rmsle: 0.00053 | train_mae: 0.08307 | train_rmse: 0.10038 | train_mse: 0.01008 | valid_rmsle: 0.00111 | valid_mae: 0.11095 | valid_rmse: 0.14212 | valid_mse: 0.0202  |  0:04:23s\n",
      "epoch 146| loss: 0.01486 | train_rmsle: 0.00035 | train_mae: 0.06246 | train_rmse: 0.07898 | train_mse: 0.00624 | valid_rmsle: 0.00089 | valid_mae: 0.09597 | valid_rmse: 0.12651 | valid_mse: 0.01601 |  0:04:25s\n",
      "epoch 147| loss: 0.01255 | train_rmsle: 0.00052 | train_mae: 0.08112 | train_rmse: 0.09818 | train_mse: 0.00964 | valid_rmsle: 0.00098 | valid_mae: 0.10686 | valid_rmse: 0.1342  | valid_mse: 0.01801 |  0:04:27s\n",
      "epoch 148| loss: 0.01117 | train_rmsle: 0.00023 | train_mae: 0.04788 | train_rmse: 0.06311 | train_mse: 0.00398 | valid_rmsle: 0.00071 | valid_mae: 0.08363 | valid_rmse: 0.11116 | valid_mse: 0.01236 |  0:04:29s\n",
      "epoch 149| loss: 0.01001 | train_rmsle: 0.00114 | train_mae: 0.11369 | train_rmse: 0.12918 | train_mse: 0.01669 | valid_rmsle: 0.00164 | valid_mae: 0.12944 | valid_rmse: 0.15902 | valid_mse: 0.02529 |  0:04:30s\n",
      "epoch 150| loss: 0.01138 | train_rmsle: 0.00037 | train_mae: 0.06608 | train_rmse: 0.08161 | train_mse: 0.00666 | valid_rmsle: 0.00084 | valid_mae: 0.09624 | valid_rmse: 0.12274 | valid_mse: 0.01507 |  0:04:32s\n",
      "epoch 151| loss: 0.01034 | train_rmsle: 0.00029 | train_mae: 0.05603 | train_rmse: 0.07226 | train_mse: 0.00522 | valid_rmsle: 0.00085 | valid_mae: 0.09244 | valid_rmse: 0.12229 | valid_mse: 0.01495 |  0:04:34s\n",
      "epoch 152| loss: 0.01089 | train_rmsle: 0.00029 | train_mae: 0.05118 | train_rmse: 0.06689 | train_mse: 0.00447 | valid_rmsle: 0.00079 | valid_mae: 0.08808 | valid_rmse: 0.1168  | valid_mse: 0.01364 |  0:04:36s\n",
      "epoch 153| loss: 0.01019 | train_rmsle: 0.00033 | train_mae: 0.06227 | train_rmse: 0.0785  | train_mse: 0.00616 | valid_rmsle: 0.00083 | valid_mae: 0.09467 | valid_rmse: 0.12206 | valid_mse: 0.0149  |  0:04:38s\n",
      "epoch 154| loss: 0.00946 | train_rmsle: 0.00084 | train_mae: 0.10046 | train_rmse: 0.11436 | train_mse: 0.01308 | valid_rmsle: 0.00136 | valid_mae: 0.11959 | valid_rmse: 0.14749 | valid_mse: 0.02175 |  0:04:39s\n",
      "epoch 155| loss: 0.00985 | train_rmsle: 0.00023 | train_mae: 0.04884 | train_rmse: 0.06346 | train_mse: 0.00403 | valid_rmsle: 0.00073 | valid_mae: 0.08649 | valid_rmse: 0.11359 | valid_mse: 0.0129  |  0:04:41s\n",
      "epoch 156| loss: 0.00911 | train_rmsle: 0.00029 | train_mae: 0.05767 | train_rmse: 0.07272 | train_mse: 0.00529 | valid_rmsle: 0.0008  | valid_mae: 0.09248 | valid_rmse: 0.11883 | valid_mse: 0.01412 |  0:04:43s\n",
      "epoch 157| loss: 0.01005 | train_rmsle: 0.00046 | train_mae: 0.06475 | train_rmse: 0.08135 | train_mse: 0.00662 | valid_rmsle: 0.00103 | valid_mae: 0.09732 | valid_rmse: 0.12707 | valid_mse: 0.01615 |  0:04:45s\n",
      "epoch 158| loss: 0.00838 | train_rmsle: 0.00077 | train_mae: 0.07768 | train_rmse: 0.10142 | train_mse: 0.01029 | valid_rmsle: 0.00127 | valid_mae: 0.10562 | valid_rmse: 0.1371  | valid_mse: 0.0188  |  0:04:47s\n",
      "epoch 159| loss: 0.01241 | train_rmsle: 0.00042 | train_mae: 0.06845 | train_rmse: 0.08702 | train_mse: 0.00757 | valid_rmsle: 0.00098 | valid_mae: 0.10116 | valid_rmse: 0.13101 | valid_mse: 0.01716 |  0:04:48s\n",
      "epoch 160| loss: 0.01162 | train_rmsle: 0.0002  | train_mae: 0.04492 | train_rmse: 0.0599  | train_mse: 0.00359 | valid_rmsle: 0.00073 | valid_mae: 0.08413 | valid_rmse: 0.11343 | valid_mse: 0.01287 |  0:04:50s\n",
      "epoch 161| loss: 0.0082  | train_rmsle: 0.00017 | train_mae: 0.04025 | train_rmse: 0.05369 | train_mse: 0.00288 | valid_rmsle: 0.00069 | valid_mae: 0.08238 | valid_rmse: 0.1103  | valid_mse: 0.01217 |  0:04:52s\n",
      "epoch 162| loss: 0.00763 | train_rmsle: 0.00016 | train_mae: 0.04047 | train_rmse: 0.05389 | train_mse: 0.0029  | valid_rmsle: 0.0007  | valid_mae: 0.08262 | valid_rmse: 0.11107 | valid_mse: 0.01234 |  0:04:54s\n",
      "epoch 163| loss: 0.00884 | train_rmsle: 0.00015 | train_mae: 0.03987 | train_rmse: 0.05301 | train_mse: 0.00281 | valid_rmsle: 0.00071 | valid_mae: 0.08323 | valid_rmse: 0.11148 | valid_mse: 0.01243 |  0:04:56s\n",
      "epoch 164| loss: 0.01161 | train_rmsle: 0.00074 | train_mae: 0.08998 | train_rmse: 0.10415 | train_mse: 0.01085 | valid_rmsle: 0.00131 | valid_mae: 0.1146  | valid_rmse: 0.14307 | valid_mse: 0.02047 |  0:04:57s\n",
      "epoch 165| loss: 0.0126  | train_rmsle: 0.00032 | train_mae: 0.06155 | train_rmse: 0.07496 | train_mse: 0.00562 | valid_rmsle: 0.00084 | valid_mae: 0.09507 | valid_rmse: 0.12174 | valid_mse: 0.01482 |  0:04:59s\n",
      "epoch 166| loss: 0.00959 | train_rmsle: 0.00022 | train_mae: 0.05065 | train_rmse: 0.06405 | train_mse: 0.0041  | valid_rmsle: 0.00077 | valid_mae: 0.08991 | valid_rmse: 0.11697 | valid_mse: 0.01368 |  0:05:01s\n",
      "epoch 167| loss: 0.00972 | train_rmsle: 0.0007  | train_mae: 0.09224 | train_rmse: 0.10444 | train_mse: 0.01091 | valid_rmsle: 0.00124 | valid_mae: 0.11496 | valid_rmse: 0.14271 | valid_mse: 0.02037 |  0:05:03s\n",
      "epoch 168| loss: 0.009   | train_rmsle: 0.0004  | train_mae: 0.0727  | train_rmse: 0.08529 | train_mse: 0.00727 | valid_rmsle: 0.00095 | valid_mae: 0.1033  | valid_rmse: 0.12954 | valid_mse: 0.01678 |  0:05:05s\n",
      "epoch 169| loss: 0.01007 | train_rmsle: 0.00029 | train_mae: 0.05454 | train_rmse: 0.0678  | train_mse: 0.0046  | valid_rmsle: 0.00084 | valid_mae: 0.09139 | valid_rmse: 0.11852 | valid_mse: 0.01405 |  0:05:06s\n",
      "epoch 170| loss: 0.01096 | train_rmsle: 0.00045 | train_mae: 0.0661  | train_rmse: 0.08552 | train_mse: 0.00731 | valid_rmsle: 0.00098 | valid_mae: 0.09862 | valid_rmse: 0.12793 | valid_mse: 0.01637 |  0:05:08s\n",
      "epoch 171| loss: 0.01211 | train_rmsle: 0.00033 | train_mae: 0.05838 | train_rmse: 0.07755 | train_mse: 0.00601 | valid_rmsle: 0.00091 | valid_mae: 0.09518 | valid_rmse: 0.12615 | valid_mse: 0.01591 |  0:05:10s\n",
      "epoch 172| loss: 0.01102 | train_rmsle: 0.00029 | train_mae: 0.05579 | train_rmse: 0.07343 | train_mse: 0.00539 | valid_rmsle: 0.00082 | valid_mae: 0.08976 | valid_rmse: 0.11888 | valid_mse: 0.01413 |  0:05:12s\n",
      "epoch 173| loss: 0.00946 | train_rmsle: 0.00029 | train_mae: 0.05612 | train_rmse: 0.07337 | train_mse: 0.00538 | valid_rmsle: 0.0008  | valid_mae: 0.08965 | valid_rmse: 0.11754 | valid_mse: 0.01381 |  0:05:14s\n",
      "epoch 174| loss: 0.01026 | train_rmsle: 0.00023 | train_mae: 0.04689 | train_rmse: 0.06174 | train_mse: 0.00381 | valid_rmsle: 0.00072 | valid_mae: 0.08283 | valid_rmse: 0.11077 | valid_mse: 0.01227 |  0:05:15s\n",
      "epoch 175| loss: 0.00899 | train_rmsle: 0.0002  | train_mae: 0.04446 | train_rmse: 0.05918 | train_mse: 0.0035  | valid_rmsle: 0.00069 | valid_mae: 0.0816  | valid_rmse: 0.10897 | valid_mse: 0.01187 |  0:05:17s\n",
      "epoch 176| loss: 0.00921 | train_rmsle: 0.0002  | train_mae: 0.04724 | train_rmse: 0.06101 | train_mse: 0.00372 | valid_rmsle: 0.00069 | valid_mae: 0.08421 | valid_rmse: 0.1102  | valid_mse: 0.01214 |  0:05:19s\n",
      "epoch 177| loss: 0.00995 | train_rmsle: 0.00073 | train_mae: 0.09615 | train_rmse: 0.10915 | train_mse: 0.01191 | valid_rmsle: 0.00121 | valid_mae: 0.11353 | valid_rmse: 0.14044 | valid_mse: 0.01972 |  0:05:21s\n",
      "epoch 178| loss: 0.01416 | train_rmsle: 0.00052 | train_mae: 0.08029 | train_rmse: 0.09487 | train_mse: 0.009   | valid_rmsle: 0.00101 | valid_mae: 0.10461 | valid_rmse: 0.13147 | valid_mse: 0.01729 |  0:05:23s\n",
      "epoch 179| loss: 0.00864 | train_rmsle: 0.00022 | train_mae: 0.04545 | train_rmse: 0.05919 | train_mse: 0.0035  | valid_rmsle: 0.00074 | valid_mae: 0.08473 | valid_rmse: 0.11156 | valid_mse: 0.01245 |  0:05:24s\n",
      "epoch 180| loss: 0.00811 | train_rmsle: 0.0002  | train_mae: 0.04712 | train_rmse: 0.06072 | train_mse: 0.00369 | valid_rmsle: 0.00072 | valid_mae: 0.0859  | valid_rmse: 0.11159 | valid_mse: 0.01245 |  0:05:26s\n",
      "epoch 181| loss: 0.00755 | train_rmsle: 0.00021 | train_mae: 0.04906 | train_rmse: 0.06152 | train_mse: 0.00379 | valid_rmsle: 0.00071 | valid_mae: 0.0857  | valid_rmse: 0.11068 | valid_mse: 0.01225 |  0:05:28s\n",
      "epoch 182| loss: 0.00746 | train_rmsle: 0.00073 | train_mae: 0.06181 | train_rmse: 0.08795 | train_mse: 0.00773 | valid_rmsle: 0.00127 | valid_mae: 0.09619 | valid_rmse: 0.12937 | valid_mse: 0.01674 |  0:05:30s\n",
      "epoch 183| loss: 0.00877 | train_rmsle: 0.00023 | train_mae: 0.04758 | train_rmse: 0.06131 | train_mse: 0.00376 | valid_rmsle: 0.00076 | valid_mae: 0.08564 | valid_rmse: 0.11471 | valid_mse: 0.01316 |  0:05:32s\n",
      "epoch 184| loss: 0.00802 | train_rmsle: 0.00043 | train_mae: 0.07232 | train_rmse: 0.085   | train_mse: 0.00723 | valid_rmsle: 0.00092 | valid_mae: 0.09736 | valid_rmse: 0.12553 | valid_mse: 0.01576 |  0:05:33s\n",
      "epoch 185| loss: 0.01027 | train_rmsle: 0.00025 | train_mae: 0.05247 | train_rmse: 0.06552 | train_mse: 0.00429 | valid_rmsle: 0.00081 | valid_mae: 0.08939 | valid_rmse: 0.11866 | valid_mse: 0.01408 |  0:05:35s\n",
      "epoch 186| loss: 0.01163 | train_rmsle: 0.00052 | train_mae: 0.06009 | train_rmse: 0.08181 | train_mse: 0.00669 | valid_rmsle: 0.00096 | valid_mae: 0.09019 | valid_rmse: 0.12183 | valid_mse: 0.01484 |  0:05:37s\n",
      "epoch 187| loss: 0.00859 | train_rmsle: 0.00031 | train_mae: 0.06286 | train_rmse: 0.07628 | train_mse: 0.00582 | valid_rmsle: 0.0009  | valid_mae: 0.09696 | valid_rmse: 0.12534 | valid_mse: 0.01571 |  0:05:39s\n",
      "epoch 188| loss: 0.00922 | train_rmsle: 0.00058 | train_mae: 0.08669 | train_rmse: 0.09737 | train_mse: 0.00948 | valid_rmsle: 0.0011  | valid_mae: 0.10824 | valid_rmse: 0.13754 | valid_mse: 0.01892 |  0:05:41s\n",
      "epoch 189| loss: 0.01114 | train_rmsle: 0.00032 | train_mae: 0.05802 | train_rmse: 0.07065 | train_mse: 0.00499 | valid_rmsle: 0.00085 | valid_mae: 0.09111 | valid_rmse: 0.12039 | valid_mse: 0.01449 |  0:05:42s\n",
      "epoch 190| loss: 0.00845 | train_rmsle: 0.00014 | train_mae: 0.03813 | train_rmse: 0.0501  | train_mse: 0.00251 | valid_rmsle: 0.0007  | valid_mae: 0.08208 | valid_rmse: 0.11006 | valid_mse: 0.01211 |  0:05:44s\n",
      "epoch 191| loss: 0.00817 | train_rmsle: 0.00016 | train_mae: 0.03888 | train_rmse: 0.05123 | train_mse: 0.00262 | valid_rmsle: 0.00065 | valid_mae: 0.08055 | valid_rmse: 0.106   | valid_mse: 0.01124 |  0:05:46s\n",
      "epoch 192| loss: 0.00791 | train_rmsle: 0.00014 | train_mae: 0.03816 | train_rmse: 0.04969 | train_mse: 0.00247 | valid_rmsle: 0.00066 | valid_mae: 0.08    | valid_rmse: 0.10617 | valid_mse: 0.01127 |  0:05:48s\n",
      "epoch 193| loss: 0.00897 | train_rmsle: 0.00014 | train_mae: 0.03957 | train_rmse: 0.05205 | train_mse: 0.00271 | valid_rmsle: 0.00066 | valid_mae: 0.0812  | valid_rmse: 0.10709 | valid_mse: 0.01147 |  0:05:50s\n",
      "epoch 194| loss: 0.00889 | train_rmsle: 0.0002  | train_mae: 0.04592 | train_rmse: 0.05755 | train_mse: 0.00331 | valid_rmsle: 0.00072 | valid_mae: 0.08339 | valid_rmse: 0.11024 | valid_mse: 0.01215 |  0:05:51s\n",
      "epoch 195| loss: 0.00821 | train_rmsle: 0.0003  | train_mae: 0.04795 | train_rmse: 0.06401 | train_mse: 0.0041  | valid_rmsle: 0.00076 | valid_mae: 0.08402 | valid_rmse: 0.11089 | valid_mse: 0.0123  |  0:05:53s\n",
      "epoch 196| loss: 0.00774 | train_rmsle: 0.00024 | train_mae: 0.05132 | train_rmse: 0.06341 | train_mse: 0.00402 | valid_rmsle: 0.00076 | valid_mae: 0.08719 | valid_rmse: 0.11446 | valid_mse: 0.0131  |  0:05:55s\n",
      "epoch 197| loss: 0.00734 | train_rmsle: 0.00025 | train_mae: 0.05296 | train_rmse: 0.0664  | train_mse: 0.00441 | valid_rmsle: 0.00071 | valid_mae: 0.08637 | valid_rmse: 0.11135 | valid_mse: 0.0124  |  0:05:57s\n",
      "epoch 198| loss: 0.00884 | train_rmsle: 0.00024 | train_mae: 0.05444 | train_rmse: 0.06529 | train_mse: 0.00426 | valid_rmsle: 0.00076 | valid_mae: 0.08867 | valid_rmse: 0.11384 | valid_mse: 0.01296 |  0:05:59s\n",
      "epoch 199| loss: 0.00927 | train_rmsle: 0.00034 | train_mae: 0.05191 | train_rmse: 0.06658 | train_mse: 0.00443 | valid_rmsle: 0.00089 | valid_mae: 0.08945 | valid_rmse: 0.11656 | valid_mse: 0.01359 |  0:06:01s\n",
      "epoch 200| loss: 0.00811 | train_rmsle: 0.00041 | train_mae: 0.07514 | train_rmse: 0.0895  | train_mse: 0.00801 | valid_rmsle: 0.001   | valid_mae: 0.10518 | valid_rmse: 0.13502 | valid_mse: 0.01823 |  0:06:02s\n",
      "epoch 201| loss: 0.00869 | train_rmsle: 0.00015 | train_mae: 0.041   | train_rmse: 0.0523  | train_mse: 0.00273 | valid_rmsle: 0.00069 | valid_mae: 0.08331 | valid_rmse: 0.10891 | valid_mse: 0.01186 |  0:06:04s\n",
      "epoch 202| loss: 0.00892 | train_rmsle: 0.00013 | train_mae: 0.03528 | train_rmse: 0.04666 | train_mse: 0.00218 | valid_rmsle: 0.00068 | valid_mae: 0.08073 | valid_rmse: 0.10611 | valid_mse: 0.01126 |  0:06:06s\n",
      "epoch 203| loss: 0.00768 | train_rmsle: 0.00042 | train_mae: 0.05377 | train_rmse: 0.07432 | train_mse: 0.00552 | valid_rmsle: 0.00096 | valid_mae: 0.09041 | valid_rmse: 0.12097 | valid_mse: 0.01463 |  0:06:08s\n",
      "epoch 204| loss: 0.00754 | train_rmsle: 0.00022 | train_mae: 0.0437  | train_rmse: 0.06089 | train_mse: 0.00371 | valid_rmsle: 0.00071 | valid_mae: 0.08322 | valid_rmse: 0.11072 | valid_mse: 0.01226 |  0:06:10s\n",
      "epoch 205| loss: 0.0094  | train_rmsle: 0.00014 | train_mae: 0.03888 | train_rmse: 0.05083 | train_mse: 0.00258 | valid_rmsle: 0.00067 | valid_mae: 0.08282 | valid_rmse: 0.10811 | valid_mse: 0.01169 |  0:06:11s\n",
      "epoch 206| loss: 0.00844 | train_rmsle: 0.00014 | train_mae: 0.03448 | train_rmse: 0.04613 | train_mse: 0.00213 | valid_rmsle: 0.00067 | valid_mae: 0.08034 | valid_rmse: 0.10735 | valid_mse: 0.01152 |  0:06:13s\n",
      "epoch 207| loss: 0.00843 | train_rmsle: 0.00018 | train_mae: 0.04528 | train_rmse: 0.05595 | train_mse: 0.00313 | valid_rmsle: 0.00069 | valid_mae: 0.08437 | valid_rmse: 0.10913 | valid_mse: 0.01191 |  0:06:15s\n",
      "epoch 208| loss: 0.00737 | train_rmsle: 0.00019 | train_mae: 0.04479 | train_rmse: 0.05769 | train_mse: 0.00333 | valid_rmsle: 0.00069 | valid_mae: 0.08488 | valid_rmse: 0.10958 | valid_mse: 0.01201 |  0:06:17s\n",
      "epoch 209| loss: 0.00714 | train_rmsle: 0.00013 | train_mae: 0.03584 | train_rmse: 0.04664 | train_mse: 0.00218 | valid_rmsle: 0.00069 | valid_mae: 0.08161 | valid_rmse: 0.10806 | valid_mse: 0.01168 |  0:06:19s\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 191 and best_valid_mse = 0.01124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011987057728233346 RMSE: 0.10948542244624782 R2: 0.94693791427311 MAE: 0.0841061363180608\n",
      "=====================================\n",
      "[101/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.59788 | train_rmsle: 0.0426  | train_mae: 0.74247 | train_rmse: 0.83645 | train_mse: 0.69966 | valid_rmsle: 0.04266 | valid_mae: 0.74303 | valid_rmse: 0.83943 | valid_mse: 0.70464 |  0:00:01s\n",
      "epoch 1  | loss: 1.01992 | train_rmsle: 0.08126 | train_mae: 1.01622 | train_rmse: 1.10614 | train_mse: 1.22355 | valid_rmsle: 0.08165 | valid_mae: 1.01885 | valid_rmse: 1.1102  | valid_mse: 1.23254 |  0:00:03s\n",
      "epoch 2  | loss: 0.56434 | train_rmsle: 0.03636 | train_mae: 0.68627 | train_rmse: 0.77932 | train_mse: 0.60734 | valid_rmsle: 0.03635 | valid_mae: 0.68598 | valid_rmse: 0.78186 | valid_mse: 0.61131 |  0:00:05s\n",
      "epoch 3  | loss: 0.40491 | train_rmsle: 0.04834 | train_mae: 0.79165 | train_rmse: 0.88502 | train_mse: 0.78326 | valid_rmsle: 0.04844 | valid_mae: 0.79232 | valid_rmse: 0.88811 | valid_mse: 0.78873 |  0:00:07s\n",
      "epoch 4  | loss: 0.34524 | train_rmsle: 0.04335 | train_mae: 0.75081 | train_rmse: 0.8433  | train_mse: 0.71116 | valid_rmsle: 0.04333 | valid_mae: 0.7508  | valid_rmse: 0.8455  | valid_mse: 0.71487 |  0:00:09s\n",
      "epoch 5  | loss: 0.30944 | train_rmsle: 0.02637 | train_mae: 0.58022 | train_rmse: 0.67086 | train_mse: 0.45006 | valid_rmsle: 0.02605 | valid_mae: 0.57941 | valid_rmse: 0.67047 | valid_mse: 0.44954 |  0:00:10s\n",
      "epoch 6  | loss: 0.32406 | train_rmsle: 0.02556 | train_mae: 0.57006 | train_rmse: 0.66087 | train_mse: 0.43675 | valid_rmsle: 0.02538 | valid_mae: 0.57068 | valid_rmse: 0.66216 | valid_mse: 0.43845 |  0:00:12s\n",
      "epoch 7  | loss: 0.37558 | train_rmsle: 0.02315 | train_mae: 0.53861 | train_rmse: 0.62884 | train_mse: 0.39544 | valid_rmsle: 0.02269 | valid_mae: 0.53869 | valid_rmse: 0.62647 | valid_mse: 0.39246 |  0:00:14s\n",
      "epoch 8  | loss: 0.2763  | train_rmsle: 0.0271  | train_mae: 0.58862 | train_rmse: 0.67931 | train_mse: 0.46146 | valid_rmsle: 0.02689 | valid_mae: 0.58874 | valid_rmse: 0.68012 | valid_mse: 0.46257 |  0:00:16s\n",
      "epoch 9  | loss: 0.28064 | train_rmsle: 0.02207 | train_mae: 0.52496 | train_rmse: 0.6147  | train_mse: 0.37786 | valid_rmsle: 0.02168 | valid_mae: 0.52498 | valid_rmse: 0.61341 | valid_mse: 0.37627 |  0:00:18s\n",
      "epoch 10 | loss: 0.27159 | train_rmsle: 0.02276 | train_mae: 0.53433 | train_rmse: 0.62424 | train_mse: 0.38968 | valid_rmsle: 0.02261 | valid_mae: 0.53682 | valid_rmse: 0.62601 | valid_mse: 0.39189 |  0:00:20s\n",
      "epoch 11 | loss: 0.25284 | train_rmsle: 0.02078 | train_mae: 0.50579 | train_rmse: 0.59611 | train_mse: 0.35535 | valid_rmsle: 0.02051 | valid_mae: 0.50865 | valid_rmse: 0.5966  | valid_mse: 0.35594 |  0:00:21s\n",
      "epoch 12 | loss: 0.28223 | train_rmsle: 0.01974 | train_mae: 0.49207 | train_rmse: 0.58085 | train_mse: 0.33739 | valid_rmsle: 0.01973 | valid_mae: 0.49713 | valid_rmse: 0.58538 | valid_mse: 0.34267 |  0:00:23s\n",
      "epoch 13 | loss: 0.25131 | train_rmsle: 0.01449 | train_mae: 0.38968 | train_rmse: 0.48433 | train_mse: 0.23457 | valid_rmsle: 0.01399 | valid_mae: 0.39318 | valid_rmse: 0.48193 | valid_mse: 0.23226 |  0:00:25s\n",
      "epoch 14 | loss: 0.39455 | train_rmsle: 0.01482 | train_mae: 0.37932 | train_rmse: 0.48459 | train_mse: 0.23482 | valid_rmsle: 0.01412 | valid_mae: 0.38142 | valid_rmse: 0.47814 | valid_mse: 0.22862 |  0:00:27s\n",
      "epoch 15 | loss: 0.39942 | train_rmsle: 0.02439 | train_mae: 0.55399 | train_rmse: 0.6452  | train_mse: 0.41628 | valid_rmsle: 0.02426 | valid_mae: 0.55518 | valid_rmse: 0.64691 | valid_mse: 0.4185  |  0:00:29s\n",
      "epoch 16 | loss: 0.2619  | train_rmsle: 0.01533 | train_mae: 0.41421 | train_rmse: 0.50444 | train_mse: 0.25446 | valid_rmsle: 0.01494 | valid_mae: 0.41771 | valid_rmse: 0.50345 | valid_mse: 0.25346 |  0:00:30s\n",
      "epoch 17 | loss: 0.2523  | train_rmsle: 0.01558 | train_mae: 0.41989 | train_rmse: 0.50966 | train_mse: 0.25976 | valid_rmsle: 0.01513 | valid_mae: 0.42101 | valid_rmse: 0.5075  | valid_mse: 0.25756 |  0:00:32s\n",
      "epoch 18 | loss: 0.23002 | train_rmsle: 0.01606 | train_mae: 0.43058 | train_rmse: 0.51938 | train_mse: 0.26975 | valid_rmsle: 0.0158  | valid_mae: 0.43542 | valid_rmse: 0.52047 | valid_mse: 0.27089 |  0:00:34s\n",
      "epoch 19 | loss: 0.22574 | train_rmsle: 0.01623 | train_mae: 0.43335 | train_rmse: 0.52245 | train_mse: 0.27295 | valid_rmsle: 0.01581 | valid_mae: 0.43381 | valid_rmse: 0.52086 | valid_mse: 0.27129 |  0:00:36s\n",
      "epoch 20 | loss: 0.22544 | train_rmsle: 0.01403 | train_mae: 0.37623 | train_rmse: 0.47396 | train_mse: 0.22464 | valid_rmsle: 0.01327 | valid_mae: 0.37172 | valid_rmse: 0.46602 | valid_mse: 0.21717 |  0:00:38s\n",
      "epoch 21 | loss: 0.22813 | train_rmsle: 0.01573 | train_mae: 0.42427 | train_rmse: 0.513   | train_mse: 0.26317 | valid_rmsle: 0.01523 | valid_mae: 0.42429 | valid_rmse: 0.51    | valid_mse: 0.2601  |  0:00:39s\n",
      "epoch 22 | loss: 0.22998 | train_rmsle: 0.01417 | train_mae: 0.37542 | train_rmse: 0.47547 | train_mse: 0.22607 | valid_rmsle: 0.0136  | valid_mae: 0.379   | valid_rmse: 0.47121 | valid_mse: 0.22204 |  0:00:41s\n",
      "epoch 23 | loss: 0.24719 | train_rmsle: 0.01571 | train_mae: 0.42356 | train_rmse: 0.51291 | train_mse: 0.26308 | valid_rmsle: 0.01546 | valid_mae: 0.42541 | valid_rmse: 0.51385 | valid_mse: 0.26404 |  0:00:43s\n",
      "epoch 24 | loss: 0.22429 | train_rmsle: 0.01574 | train_mae: 0.42383 | train_rmse: 0.51287 | train_mse: 0.26304 | valid_rmsle: 0.01563 | valid_mae: 0.42944 | valid_rmse: 0.51642 | valid_mse: 0.26669 |  0:00:45s\n",
      "epoch 25 | loss: 0.21946 | train_rmsle: 0.01417 | train_mae: 0.38347 | train_rmse: 0.47872 | train_mse: 0.22918 | valid_rmsle: 0.01351 | valid_mae: 0.38077 | valid_rmse: 0.47263 | valid_mse: 0.22338 |  0:00:47s\n",
      "epoch 26 | loss: 0.21709 | train_rmsle: 0.01484 | train_mae: 0.40475 | train_rmse: 0.49498 | train_mse: 0.24501 | valid_rmsle: 0.01442 | valid_mae: 0.40431 | valid_rmse: 0.49356 | valid_mse: 0.2436  |  0:00:49s\n",
      "epoch 27 | loss: 0.21917 | train_rmsle: 0.01472 | train_mae: 0.40278 | train_rmse: 0.49287 | train_mse: 0.24292 | valid_rmsle: 0.01469 | valid_mae: 0.40977 | valid_rmse: 0.49772 | valid_mse: 0.24772 |  0:00:50s\n",
      "epoch 28 | loss: 0.21733 | train_rmsle: 0.0142  | train_mae: 0.38749 | train_rmse: 0.48033 | train_mse: 0.23071 | valid_rmsle: 0.01377 | valid_mae: 0.38494 | valid_rmse: 0.47748 | valid_mse: 0.22799 |  0:00:52s\n",
      "epoch 29 | loss: 0.21664 | train_rmsle: 0.01394 | train_mae: 0.37778 | train_rmse: 0.47398 | train_mse: 0.22466 | valid_rmsle: 0.01376 | valid_mae: 0.38063 | valid_rmse: 0.47674 | valid_mse: 0.22728 |  0:00:54s\n",
      "epoch 30 | loss: 0.21714 | train_rmsle: 0.01445 | train_mae: 0.39796 | train_rmse: 0.4881  | train_mse: 0.23824 | valid_rmsle: 0.01444 | valid_mae: 0.40351 | valid_rmse: 0.49312 | valid_mse: 0.24317 |  0:00:56s\n",
      "epoch 31 | loss: 0.21871 | train_rmsle: 0.01395 | train_mae: 0.37027 | train_rmse: 0.47091 | train_mse: 0.22176 | valid_rmsle: 0.01357 | valid_mae: 0.37383 | valid_rmse: 0.47    | valid_mse: 0.2209  |  0:00:58s\n",
      "epoch 32 | loss: 0.21529 | train_rmsle: 0.01382 | train_mae: 0.37173 | train_rmse: 0.47    | train_mse: 0.2209  | valid_rmsle: 0.01335 | valid_mae: 0.3739  | valid_rmse: 0.46707 | valid_mse: 0.21815 |  0:00:59s\n",
      "epoch 33 | loss: 0.22464 | train_rmsle: 0.01404 | train_mae: 0.37082 | train_rmse: 0.47214 | train_mse: 0.22292 | valid_rmsle: 0.0137  | valid_mae: 0.37591 | valid_rmse: 0.47185 | valid_mse: 0.22265 |  0:01:01s\n",
      "epoch 34 | loss: 0.22643 | train_rmsle: 0.01365 | train_mae: 0.37304 | train_rmse: 0.46842 | train_mse: 0.21942 | valid_rmsle: 0.0135  | valid_mae: 0.38001 | valid_rmse: 0.47153 | valid_mse: 0.22234 |  0:01:03s\n",
      "epoch 35 | loss: 0.21213 | train_rmsle: 0.01355 | train_mae: 0.37129 | train_rmse: 0.46642 | train_mse: 0.21754 | valid_rmsle: 0.01356 | valid_mae: 0.38184 | valid_rmse: 0.47216 | valid_mse: 0.22294 |  0:01:05s\n",
      "epoch 36 | loss: 0.21639 | train_rmsle: 0.01384 | train_mae: 0.38371 | train_rmse: 0.475   | train_mse: 0.22562 | valid_rmsle: 0.01377 | valid_mae: 0.39131 | valid_rmse: 0.47955 | valid_mse: 0.22996 |  0:01:07s\n",
      "epoch 37 | loss: 0.2141  | train_rmsle: 0.01373 | train_mae: 0.37528 | train_rmse: 0.47052 | train_mse: 0.22138 | valid_rmsle: 0.0135  | valid_mae: 0.3783  | valid_rmse: 0.47225 | valid_mse: 0.22302 |  0:01:08s\n",
      "epoch 38 | loss: 0.21242 | train_rmsle: 0.01361 | train_mae: 0.36992 | train_rmse: 0.46644 | train_mse: 0.21757 | valid_rmsle: 0.01349 | valid_mae: 0.37636 | valid_rmse: 0.46967 | valid_mse: 0.22059 |  0:01:10s\n",
      "epoch 39 | loss: 0.21543 | train_rmsle: 0.01376 | train_mae: 0.36967 | train_rmse: 0.46846 | train_mse: 0.21946 | valid_rmsle: 0.01375 | valid_mae: 0.37777 | valid_rmse: 0.4735  | valid_mse: 0.2242  |  0:01:12s\n",
      "epoch 40 | loss: 0.21699 | train_rmsle: 0.0136  | train_mae: 0.3693  | train_rmse: 0.46606 | train_mse: 0.21721 | valid_rmsle: 0.01361 | valid_mae: 0.37812 | valid_rmse: 0.47193 | valid_mse: 0.22272 |  0:01:14s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21832310813868422 RMSE: 0.46725058388265733 R2: 0.03356772421890386 MAE: 0.3709519909239511\n",
      "=====================================\n",
      "[102/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.59788 | train_rmsle: 0.0426  | train_mae: 0.74247 | train_rmse: 0.83645 | train_mse: 0.69966 | valid_rmsle: 0.04266 | valid_mae: 0.74303 | valid_rmse: 0.83943 | valid_mse: 0.70464 |  0:00:01s\n",
      "epoch 1  | loss: 1.01992 | train_rmsle: 0.08126 | train_mae: 1.01622 | train_rmse: 1.10614 | train_mse: 1.22355 | valid_rmsle: 0.08165 | valid_mae: 1.01885 | valid_rmse: 1.1102  | valid_mse: 1.23254 |  0:00:03s\n",
      "epoch 2  | loss: 0.56434 | train_rmsle: 0.03636 | train_mae: 0.68627 | train_rmse: 0.77932 | train_mse: 0.60734 | valid_rmsle: 0.03635 | valid_mae: 0.68598 | valid_rmse: 0.78186 | valid_mse: 0.61131 |  0:00:05s\n",
      "epoch 3  | loss: 0.40491 | train_rmsle: 0.04834 | train_mae: 0.79165 | train_rmse: 0.88502 | train_mse: 0.78326 | valid_rmsle: 0.04844 | valid_mae: 0.79232 | valid_rmse: 0.88811 | valid_mse: 0.78873 |  0:00:07s\n",
      "epoch 4  | loss: 0.34524 | train_rmsle: 0.04335 | train_mae: 0.75081 | train_rmse: 0.8433  | train_mse: 0.71116 | valid_rmsle: 0.04333 | valid_mae: 0.7508  | valid_rmse: 0.8455  | valid_mse: 0.71487 |  0:00:09s\n",
      "epoch 5  | loss: 0.30944 | train_rmsle: 0.02637 | train_mae: 0.58022 | train_rmse: 0.67086 | train_mse: 0.45006 | valid_rmsle: 0.02605 | valid_mae: 0.57941 | valid_rmse: 0.67047 | valid_mse: 0.44954 |  0:00:10s\n",
      "epoch 6  | loss: 0.32406 | train_rmsle: 0.02556 | train_mae: 0.57006 | train_rmse: 0.66087 | train_mse: 0.43675 | valid_rmsle: 0.02538 | valid_mae: 0.57068 | valid_rmse: 0.66216 | valid_mse: 0.43845 |  0:00:12s\n",
      "epoch 7  | loss: 0.37558 | train_rmsle: 0.02315 | train_mae: 0.53861 | train_rmse: 0.62884 | train_mse: 0.39544 | valid_rmsle: 0.02269 | valid_mae: 0.53869 | valid_rmse: 0.62647 | valid_mse: 0.39246 |  0:00:14s\n",
      "epoch 8  | loss: 0.2763  | train_rmsle: 0.0271  | train_mae: 0.58862 | train_rmse: 0.67931 | train_mse: 0.46146 | valid_rmsle: 0.02689 | valid_mae: 0.58874 | valid_rmse: 0.68012 | valid_mse: 0.46257 |  0:00:16s\n",
      "epoch 9  | loss: 0.28064 | train_rmsle: 0.02207 | train_mae: 0.52496 | train_rmse: 0.6147  | train_mse: 0.37786 | valid_rmsle: 0.02168 | valid_mae: 0.52498 | valid_rmse: 0.61341 | valid_mse: 0.37627 |  0:00:18s\n",
      "epoch 10 | loss: 0.27159 | train_rmsle: 0.02276 | train_mae: 0.53433 | train_rmse: 0.62424 | train_mse: 0.38968 | valid_rmsle: 0.02261 | valid_mae: 0.53682 | valid_rmse: 0.62601 | valid_mse: 0.39189 |  0:00:20s\n",
      "epoch 11 | loss: 0.25284 | train_rmsle: 0.02078 | train_mae: 0.50579 | train_rmse: 0.59611 | train_mse: 0.35535 | valid_rmsle: 0.02051 | valid_mae: 0.50865 | valid_rmse: 0.5966  | valid_mse: 0.35594 |  0:00:21s\n",
      "epoch 12 | loss: 0.28223 | train_rmsle: 0.01974 | train_mae: 0.49207 | train_rmse: 0.58085 | train_mse: 0.33739 | valid_rmsle: 0.01973 | valid_mae: 0.49713 | valid_rmse: 0.58538 | valid_mse: 0.34267 |  0:00:23s\n",
      "epoch 13 | loss: 0.25131 | train_rmsle: 0.01449 | train_mae: 0.38968 | train_rmse: 0.48433 | train_mse: 0.23457 | valid_rmsle: 0.01399 | valid_mae: 0.39318 | valid_rmse: 0.48193 | valid_mse: 0.23226 |  0:00:25s\n",
      "epoch 14 | loss: 0.39455 | train_rmsle: 0.01482 | train_mae: 0.37932 | train_rmse: 0.48459 | train_mse: 0.23482 | valid_rmsle: 0.01412 | valid_mae: 0.38142 | valid_rmse: 0.47814 | valid_mse: 0.22862 |  0:00:27s\n",
      "epoch 15 | loss: 0.39942 | train_rmsle: 0.02439 | train_mae: 0.55399 | train_rmse: 0.6452  | train_mse: 0.41628 | valid_rmsle: 0.02426 | valid_mae: 0.55518 | valid_rmse: 0.64691 | valid_mse: 0.4185  |  0:00:29s\n",
      "epoch 16 | loss: 0.2619  | train_rmsle: 0.01533 | train_mae: 0.41421 | train_rmse: 0.50444 | train_mse: 0.25446 | valid_rmsle: 0.01494 | valid_mae: 0.41771 | valid_rmse: 0.50345 | valid_mse: 0.25346 |  0:00:30s\n",
      "epoch 17 | loss: 0.2523  | train_rmsle: 0.01558 | train_mae: 0.41989 | train_rmse: 0.50966 | train_mse: 0.25976 | valid_rmsle: 0.01513 | valid_mae: 0.42101 | valid_rmse: 0.5075  | valid_mse: 0.25756 |  0:00:32s\n",
      "epoch 18 | loss: 0.23002 | train_rmsle: 0.01606 | train_mae: 0.43058 | train_rmse: 0.51938 | train_mse: 0.26975 | valid_rmsle: 0.0158  | valid_mae: 0.43542 | valid_rmse: 0.52047 | valid_mse: 0.27089 |  0:00:34s\n",
      "epoch 19 | loss: 0.22574 | train_rmsle: 0.01623 | train_mae: 0.43335 | train_rmse: 0.52245 | train_mse: 0.27295 | valid_rmsle: 0.01581 | valid_mae: 0.43381 | valid_rmse: 0.52086 | valid_mse: 0.27129 |  0:00:36s\n",
      "epoch 20 | loss: 0.22544 | train_rmsle: 0.01403 | train_mae: 0.37623 | train_rmse: 0.47396 | train_mse: 0.22464 | valid_rmsle: 0.01327 | valid_mae: 0.37172 | valid_rmse: 0.46602 | valid_mse: 0.21717 |  0:00:38s\n",
      "epoch 21 | loss: 0.22813 | train_rmsle: 0.01573 | train_mae: 0.42427 | train_rmse: 0.513   | train_mse: 0.26317 | valid_rmsle: 0.01523 | valid_mae: 0.42429 | valid_rmse: 0.51    | valid_mse: 0.2601  |  0:00:39s\n",
      "epoch 22 | loss: 0.22998 | train_rmsle: 0.01417 | train_mae: 0.37542 | train_rmse: 0.47547 | train_mse: 0.22607 | valid_rmsle: 0.0136  | valid_mae: 0.379   | valid_rmse: 0.47121 | valid_mse: 0.22204 |  0:00:41s\n",
      "epoch 23 | loss: 0.24719 | train_rmsle: 0.01571 | train_mae: 0.42356 | train_rmse: 0.51291 | train_mse: 0.26308 | valid_rmsle: 0.01546 | valid_mae: 0.42541 | valid_rmse: 0.51385 | valid_mse: 0.26404 |  0:00:43s\n",
      "epoch 24 | loss: 0.22429 | train_rmsle: 0.01574 | train_mae: 0.42383 | train_rmse: 0.51287 | train_mse: 0.26304 | valid_rmsle: 0.01563 | valid_mae: 0.42944 | valid_rmse: 0.51642 | valid_mse: 0.26669 |  0:00:45s\n",
      "epoch 25 | loss: 0.21946 | train_rmsle: 0.01417 | train_mae: 0.38347 | train_rmse: 0.47872 | train_mse: 0.22918 | valid_rmsle: 0.01351 | valid_mae: 0.38077 | valid_rmse: 0.47263 | valid_mse: 0.22338 |  0:00:47s\n",
      "epoch 26 | loss: 0.21709 | train_rmsle: 0.01484 | train_mae: 0.40475 | train_rmse: 0.49498 | train_mse: 0.24501 | valid_rmsle: 0.01442 | valid_mae: 0.40431 | valid_rmse: 0.49356 | valid_mse: 0.2436  |  0:00:48s\n",
      "epoch 27 | loss: 0.21917 | train_rmsle: 0.01472 | train_mae: 0.40278 | train_rmse: 0.49287 | train_mse: 0.24292 | valid_rmsle: 0.01469 | valid_mae: 0.40977 | valid_rmse: 0.49772 | valid_mse: 0.24772 |  0:00:50s\n",
      "epoch 28 | loss: 0.21733 | train_rmsle: 0.0142  | train_mae: 0.38749 | train_rmse: 0.48033 | train_mse: 0.23071 | valid_rmsle: 0.01377 | valid_mae: 0.38494 | valid_rmse: 0.47748 | valid_mse: 0.22799 |  0:00:52s\n",
      "epoch 29 | loss: 0.21664 | train_rmsle: 0.01394 | train_mae: 0.37778 | train_rmse: 0.47398 | train_mse: 0.22466 | valid_rmsle: 0.01376 | valid_mae: 0.38063 | valid_rmse: 0.47674 | valid_mse: 0.22728 |  0:00:54s\n",
      "epoch 30 | loss: 0.21714 | train_rmsle: 0.01445 | train_mae: 0.39796 | train_rmse: 0.4881  | train_mse: 0.23824 | valid_rmsle: 0.01444 | valid_mae: 0.40351 | valid_rmse: 0.49312 | valid_mse: 0.24317 |  0:00:56s\n",
      "epoch 31 | loss: 0.21871 | train_rmsle: 0.01395 | train_mae: 0.37027 | train_rmse: 0.47091 | train_mse: 0.22176 | valid_rmsle: 0.01357 | valid_mae: 0.37383 | valid_rmse: 0.47    | valid_mse: 0.2209  |  0:00:57s\n",
      "epoch 32 | loss: 0.21529 | train_rmsle: 0.01382 | train_mae: 0.37173 | train_rmse: 0.47    | train_mse: 0.2209  | valid_rmsle: 0.01335 | valid_mae: 0.3739  | valid_rmse: 0.46707 | valid_mse: 0.21815 |  0:00:59s\n",
      "epoch 33 | loss: 0.22464 | train_rmsle: 0.01404 | train_mae: 0.37082 | train_rmse: 0.47214 | train_mse: 0.22292 | valid_rmsle: 0.0137  | valid_mae: 0.37591 | valid_rmse: 0.47185 | valid_mse: 0.22265 |  0:01:01s\n",
      "epoch 34 | loss: 0.22643 | train_rmsle: 0.01365 | train_mae: 0.37304 | train_rmse: 0.46842 | train_mse: 0.21942 | valid_rmsle: 0.0135  | valid_mae: 0.38001 | valid_rmse: 0.47153 | valid_mse: 0.22234 |  0:01:03s\n",
      "epoch 35 | loss: 0.21213 | train_rmsle: 0.01355 | train_mae: 0.37129 | train_rmse: 0.46642 | train_mse: 0.21754 | valid_rmsle: 0.01356 | valid_mae: 0.38184 | valid_rmse: 0.47216 | valid_mse: 0.22294 |  0:01:05s\n",
      "epoch 36 | loss: 0.21639 | train_rmsle: 0.01384 | train_mae: 0.38371 | train_rmse: 0.475   | train_mse: 0.22562 | valid_rmsle: 0.01377 | valid_mae: 0.39131 | valid_rmse: 0.47955 | valid_mse: 0.22996 |  0:01:06s\n",
      "epoch 37 | loss: 0.2141  | train_rmsle: 0.01373 | train_mae: 0.37528 | train_rmse: 0.47052 | train_mse: 0.22138 | valid_rmsle: 0.0135  | valid_mae: 0.3783  | valid_rmse: 0.47225 | valid_mse: 0.22302 |  0:01:08s\n",
      "epoch 38 | loss: 0.21242 | train_rmsle: 0.01361 | train_mae: 0.36992 | train_rmse: 0.46644 | train_mse: 0.21757 | valid_rmsle: 0.01349 | valid_mae: 0.37636 | valid_rmse: 0.46967 | valid_mse: 0.22059 |  0:01:10s\n",
      "epoch 39 | loss: 0.21543 | train_rmsle: 0.01376 | train_mae: 0.36967 | train_rmse: 0.46846 | train_mse: 0.21946 | valid_rmsle: 0.01375 | valid_mae: 0.37777 | valid_rmse: 0.4735  | valid_mse: 0.2242  |  0:01:12s\n",
      "epoch 40 | loss: 0.21699 | train_rmsle: 0.0136  | train_mae: 0.3693  | train_rmse: 0.46606 | train_mse: 0.21721 | valid_rmsle: 0.01361 | valid_mae: 0.37812 | valid_rmse: 0.47193 | valid_mse: 0.22272 |  0:01:14s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21832310813868422 RMSE: 0.46725058388265733 R2: 0.03356772421890386 MAE: 0.3709519909239511\n",
      "=====================================\n",
      "[103/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.59788 | train_rmsle: 0.0426  | train_mae: 0.74247 | train_rmse: 0.83645 | train_mse: 0.69966 | valid_rmsle: 0.04266 | valid_mae: 0.74303 | valid_rmse: 0.83943 | valid_mse: 0.70464 |  0:00:01s\n",
      "epoch 1  | loss: 1.01992 | train_rmsle: 0.08126 | train_mae: 1.01622 | train_rmse: 1.10614 | train_mse: 1.22355 | valid_rmsle: 0.08165 | valid_mae: 1.01885 | valid_rmse: 1.1102  | valid_mse: 1.23254 |  0:00:03s\n",
      "epoch 2  | loss: 0.56434 | train_rmsle: 0.03636 | train_mae: 0.68627 | train_rmse: 0.77932 | train_mse: 0.60734 | valid_rmsle: 0.03635 | valid_mae: 0.68598 | valid_rmse: 0.78186 | valid_mse: 0.61131 |  0:00:05s\n",
      "epoch 3  | loss: 0.40491 | train_rmsle: 0.04834 | train_mae: 0.79165 | train_rmse: 0.88502 | train_mse: 0.78326 | valid_rmsle: 0.04844 | valid_mae: 0.79232 | valid_rmse: 0.88811 | valid_mse: 0.78873 |  0:00:07s\n",
      "epoch 4  | loss: 0.34524 | train_rmsle: 0.04335 | train_mae: 0.75081 | train_rmse: 0.8433  | train_mse: 0.71116 | valid_rmsle: 0.04333 | valid_mae: 0.7508  | valid_rmse: 0.8455  | valid_mse: 0.71487 |  0:00:09s\n",
      "epoch 5  | loss: 0.30944 | train_rmsle: 0.02637 | train_mae: 0.58022 | train_rmse: 0.67086 | train_mse: 0.45006 | valid_rmsle: 0.02605 | valid_mae: 0.57941 | valid_rmse: 0.67047 | valid_mse: 0.44954 |  0:00:11s\n",
      "epoch 6  | loss: 0.32406 | train_rmsle: 0.02556 | train_mae: 0.57006 | train_rmse: 0.66087 | train_mse: 0.43675 | valid_rmsle: 0.02538 | valid_mae: 0.57068 | valid_rmse: 0.66216 | valid_mse: 0.43845 |  0:00:12s\n",
      "epoch 7  | loss: 0.37558 | train_rmsle: 0.02315 | train_mae: 0.53861 | train_rmse: 0.62884 | train_mse: 0.39544 | valid_rmsle: 0.02269 | valid_mae: 0.53869 | valid_rmse: 0.62647 | valid_mse: 0.39246 |  0:00:14s\n",
      "epoch 8  | loss: 0.2763  | train_rmsle: 0.0271  | train_mae: 0.58862 | train_rmse: 0.67931 | train_mse: 0.46146 | valid_rmsle: 0.02689 | valid_mae: 0.58874 | valid_rmse: 0.68012 | valid_mse: 0.46257 |  0:00:16s\n",
      "epoch 9  | loss: 0.28064 | train_rmsle: 0.02207 | train_mae: 0.52496 | train_rmse: 0.6147  | train_mse: 0.37786 | valid_rmsle: 0.02168 | valid_mae: 0.52498 | valid_rmse: 0.61341 | valid_mse: 0.37627 |  0:00:18s\n",
      "epoch 10 | loss: 0.27159 | train_rmsle: 0.02276 | train_mae: 0.53433 | train_rmse: 0.62424 | train_mse: 0.38968 | valid_rmsle: 0.02261 | valid_mae: 0.53682 | valid_rmse: 0.62601 | valid_mse: 0.39189 |  0:00:20s\n",
      "epoch 11 | loss: 0.25284 | train_rmsle: 0.02078 | train_mae: 0.50579 | train_rmse: 0.59611 | train_mse: 0.35535 | valid_rmsle: 0.02051 | valid_mae: 0.50865 | valid_rmse: 0.5966  | valid_mse: 0.35594 |  0:00:21s\n",
      "epoch 12 | loss: 0.28223 | train_rmsle: 0.01974 | train_mae: 0.49207 | train_rmse: 0.58085 | train_mse: 0.33739 | valid_rmsle: 0.01973 | valid_mae: 0.49713 | valid_rmse: 0.58538 | valid_mse: 0.34267 |  0:00:23s\n",
      "epoch 13 | loss: 0.25131 | train_rmsle: 0.01449 | train_mae: 0.38968 | train_rmse: 0.48433 | train_mse: 0.23457 | valid_rmsle: 0.01399 | valid_mae: 0.39318 | valid_rmse: 0.48193 | valid_mse: 0.23226 |  0:00:25s\n",
      "epoch 14 | loss: 0.39455 | train_rmsle: 0.01482 | train_mae: 0.37932 | train_rmse: 0.48459 | train_mse: 0.23482 | valid_rmsle: 0.01412 | valid_mae: 0.38142 | valid_rmse: 0.47814 | valid_mse: 0.22862 |  0:00:27s\n",
      "epoch 15 | loss: 0.39942 | train_rmsle: 0.02439 | train_mae: 0.55399 | train_rmse: 0.6452  | train_mse: 0.41628 | valid_rmsle: 0.02426 | valid_mae: 0.55518 | valid_rmse: 0.64691 | valid_mse: 0.4185  |  0:00:29s\n",
      "epoch 16 | loss: 0.2619  | train_rmsle: 0.01533 | train_mae: 0.41421 | train_rmse: 0.50444 | train_mse: 0.25446 | valid_rmsle: 0.01494 | valid_mae: 0.41771 | valid_rmse: 0.50345 | valid_mse: 0.25346 |  0:00:30s\n",
      "epoch 17 | loss: 0.2523  | train_rmsle: 0.01558 | train_mae: 0.41989 | train_rmse: 0.50966 | train_mse: 0.25976 | valid_rmsle: 0.01513 | valid_mae: 0.42101 | valid_rmse: 0.5075  | valid_mse: 0.25756 |  0:00:32s\n",
      "epoch 18 | loss: 0.23002 | train_rmsle: 0.01606 | train_mae: 0.43058 | train_rmse: 0.51938 | train_mse: 0.26975 | valid_rmsle: 0.0158  | valid_mae: 0.43542 | valid_rmse: 0.52047 | valid_mse: 0.27089 |  0:00:34s\n",
      "epoch 19 | loss: 0.22574 | train_rmsle: 0.01623 | train_mae: 0.43335 | train_rmse: 0.52245 | train_mse: 0.27295 | valid_rmsle: 0.01581 | valid_mae: 0.43381 | valid_rmse: 0.52086 | valid_mse: 0.27129 |  0:00:36s\n",
      "epoch 20 | loss: 0.22544 | train_rmsle: 0.01403 | train_mae: 0.37623 | train_rmse: 0.47396 | train_mse: 0.22464 | valid_rmsle: 0.01327 | valid_mae: 0.37172 | valid_rmse: 0.46602 | valid_mse: 0.21717 |  0:00:38s\n",
      "epoch 21 | loss: 0.22813 | train_rmsle: 0.01573 | train_mae: 0.42427 | train_rmse: 0.513   | train_mse: 0.26317 | valid_rmsle: 0.01523 | valid_mae: 0.42429 | valid_rmse: 0.51    | valid_mse: 0.2601  |  0:00:39s\n",
      "epoch 22 | loss: 0.22998 | train_rmsle: 0.01417 | train_mae: 0.37542 | train_rmse: 0.47547 | train_mse: 0.22607 | valid_rmsle: 0.0136  | valid_mae: 0.379   | valid_rmse: 0.47121 | valid_mse: 0.22204 |  0:00:41s\n",
      "epoch 23 | loss: 0.24719 | train_rmsle: 0.01571 | train_mae: 0.42356 | train_rmse: 0.51291 | train_mse: 0.26308 | valid_rmsle: 0.01546 | valid_mae: 0.42541 | valid_rmse: 0.51385 | valid_mse: 0.26404 |  0:00:43s\n",
      "epoch 24 | loss: 0.22429 | train_rmsle: 0.01574 | train_mae: 0.42383 | train_rmse: 0.51287 | train_mse: 0.26304 | valid_rmsle: 0.01563 | valid_mae: 0.42944 | valid_rmse: 0.51642 | valid_mse: 0.26669 |  0:00:45s\n",
      "epoch 25 | loss: 0.21946 | train_rmsle: 0.01417 | train_mae: 0.38347 | train_rmse: 0.47872 | train_mse: 0.22918 | valid_rmsle: 0.01351 | valid_mae: 0.38077 | valid_rmse: 0.47263 | valid_mse: 0.22338 |  0:00:47s\n",
      "epoch 26 | loss: 0.21709 | train_rmsle: 0.01484 | train_mae: 0.40475 | train_rmse: 0.49498 | train_mse: 0.24501 | valid_rmsle: 0.01442 | valid_mae: 0.40431 | valid_rmse: 0.49356 | valid_mse: 0.2436  |  0:00:49s\n",
      "epoch 27 | loss: 0.21917 | train_rmsle: 0.01472 | train_mae: 0.40278 | train_rmse: 0.49287 | train_mse: 0.24292 | valid_rmsle: 0.01469 | valid_mae: 0.40977 | valid_rmse: 0.49772 | valid_mse: 0.24772 |  0:00:50s\n",
      "epoch 28 | loss: 0.21733 | train_rmsle: 0.0142  | train_mae: 0.38749 | train_rmse: 0.48033 | train_mse: 0.23071 | valid_rmsle: 0.01377 | valid_mae: 0.38494 | valid_rmse: 0.47748 | valid_mse: 0.22799 |  0:00:52s\n",
      "epoch 29 | loss: 0.21664 | train_rmsle: 0.01394 | train_mae: 0.37778 | train_rmse: 0.47398 | train_mse: 0.22466 | valid_rmsle: 0.01376 | valid_mae: 0.38063 | valid_rmse: 0.47674 | valid_mse: 0.22728 |  0:00:54s\n",
      "epoch 30 | loss: 0.21714 | train_rmsle: 0.01445 | train_mae: 0.39796 | train_rmse: 0.4881  | train_mse: 0.23824 | valid_rmsle: 0.01444 | valid_mae: 0.40351 | valid_rmse: 0.49312 | valid_mse: 0.24317 |  0:00:56s\n",
      "epoch 31 | loss: 0.21871 | train_rmsle: 0.01395 | train_mae: 0.37027 | train_rmse: 0.47091 | train_mse: 0.22176 | valid_rmsle: 0.01357 | valid_mae: 0.37383 | valid_rmse: 0.47    | valid_mse: 0.2209  |  0:00:58s\n",
      "epoch 32 | loss: 0.21529 | train_rmsle: 0.01382 | train_mae: 0.37173 | train_rmse: 0.47    | train_mse: 0.2209  | valid_rmsle: 0.01335 | valid_mae: 0.3739  | valid_rmse: 0.46707 | valid_mse: 0.21815 |  0:00:59s\n",
      "epoch 33 | loss: 0.22464 | train_rmsle: 0.01404 | train_mae: 0.37082 | train_rmse: 0.47214 | train_mse: 0.22292 | valid_rmsle: 0.0137  | valid_mae: 0.37591 | valid_rmse: 0.47185 | valid_mse: 0.22265 |  0:01:01s\n",
      "epoch 34 | loss: 0.22643 | train_rmsle: 0.01365 | train_mae: 0.37304 | train_rmse: 0.46842 | train_mse: 0.21942 | valid_rmsle: 0.0135  | valid_mae: 0.38001 | valid_rmse: 0.47153 | valid_mse: 0.22234 |  0:01:03s\n",
      "epoch 35 | loss: 0.21213 | train_rmsle: 0.01355 | train_mae: 0.37129 | train_rmse: 0.46642 | train_mse: 0.21754 | valid_rmsle: 0.01356 | valid_mae: 0.38184 | valid_rmse: 0.47216 | valid_mse: 0.22294 |  0:01:05s\n",
      "epoch 36 | loss: 0.21639 | train_rmsle: 0.01384 | train_mae: 0.38371 | train_rmse: 0.475   | train_mse: 0.22562 | valid_rmsle: 0.01377 | valid_mae: 0.39131 | valid_rmse: 0.47955 | valid_mse: 0.22996 |  0:01:07s\n",
      "epoch 37 | loss: 0.2141  | train_rmsle: 0.01373 | train_mae: 0.37528 | train_rmse: 0.47052 | train_mse: 0.22138 | valid_rmsle: 0.0135  | valid_mae: 0.3783  | valid_rmse: 0.47225 | valid_mse: 0.22302 |  0:01:08s\n",
      "epoch 38 | loss: 0.21242 | train_rmsle: 0.01361 | train_mae: 0.36992 | train_rmse: 0.46644 | train_mse: 0.21757 | valid_rmsle: 0.01349 | valid_mae: 0.37636 | valid_rmse: 0.46967 | valid_mse: 0.22059 |  0:01:10s\n",
      "epoch 39 | loss: 0.21543 | train_rmsle: 0.01376 | train_mae: 0.36967 | train_rmse: 0.46846 | train_mse: 0.21946 | valid_rmsle: 0.01375 | valid_mae: 0.37777 | valid_rmse: 0.4735  | valid_mse: 0.2242  |  0:01:12s\n",
      "epoch 40 | loss: 0.21699 | train_rmsle: 0.0136  | train_mae: 0.3693  | train_rmse: 0.46606 | train_mse: 0.21721 | valid_rmsle: 0.01361 | valid_mae: 0.37812 | valid_rmse: 0.47193 | valid_mse: 0.22272 |  0:01:14s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21832310813868422 RMSE: 0.46725058388265733 R2: 0.03356772421890386 MAE: 0.3709519909239511\n",
      "=====================================\n",
      "[104/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 3.59788 | train_rmsle: 0.0426  | train_mae: 0.74247 | train_rmse: 0.83645 | train_mse: 0.69966 | valid_rmsle: 0.04266 | valid_mae: 0.74303 | valid_rmse: 0.83943 | valid_mse: 0.70464 |  0:00:01s\n",
      "epoch 1  | loss: 1.01992 | train_rmsle: 0.08126 | train_mae: 1.01622 | train_rmse: 1.10614 | train_mse: 1.22355 | valid_rmsle: 0.08165 | valid_mae: 1.01885 | valid_rmse: 1.1102  | valid_mse: 1.23254 |  0:00:03s\n",
      "epoch 2  | loss: 0.56434 | train_rmsle: 0.03636 | train_mae: 0.68627 | train_rmse: 0.77932 | train_mse: 0.60734 | valid_rmsle: 0.03635 | valid_mae: 0.68598 | valid_rmse: 0.78186 | valid_mse: 0.61131 |  0:00:05s\n",
      "epoch 3  | loss: 0.40491 | train_rmsle: 0.04834 | train_mae: 0.79165 | train_rmse: 0.88502 | train_mse: 0.78326 | valid_rmsle: 0.04844 | valid_mae: 0.79232 | valid_rmse: 0.88811 | valid_mse: 0.78873 |  0:00:07s\n",
      "epoch 4  | loss: 0.34524 | train_rmsle: 0.04335 | train_mae: 0.75081 | train_rmse: 0.8433  | train_mse: 0.71116 | valid_rmsle: 0.04333 | valid_mae: 0.7508  | valid_rmse: 0.8455  | valid_mse: 0.71487 |  0:00:09s\n",
      "epoch 5  | loss: 0.30944 | train_rmsle: 0.02637 | train_mae: 0.58022 | train_rmse: 0.67086 | train_mse: 0.45006 | valid_rmsle: 0.02605 | valid_mae: 0.57941 | valid_rmse: 0.67047 | valid_mse: 0.44954 |  0:00:11s\n",
      "epoch 6  | loss: 0.32406 | train_rmsle: 0.02556 | train_mae: 0.57006 | train_rmse: 0.66087 | train_mse: 0.43675 | valid_rmsle: 0.02538 | valid_mae: 0.57068 | valid_rmse: 0.66216 | valid_mse: 0.43845 |  0:00:12s\n",
      "epoch 7  | loss: 0.37558 | train_rmsle: 0.02315 | train_mae: 0.53861 | train_rmse: 0.62884 | train_mse: 0.39544 | valid_rmsle: 0.02269 | valid_mae: 0.53869 | valid_rmse: 0.62647 | valid_mse: 0.39246 |  0:00:14s\n",
      "epoch 8  | loss: 0.2763  | train_rmsle: 0.0271  | train_mae: 0.58862 | train_rmse: 0.67931 | train_mse: 0.46146 | valid_rmsle: 0.02689 | valid_mae: 0.58874 | valid_rmse: 0.68012 | valid_mse: 0.46257 |  0:00:16s\n",
      "epoch 9  | loss: 0.28064 | train_rmsle: 0.02207 | train_mae: 0.52496 | train_rmse: 0.6147  | train_mse: 0.37786 | valid_rmsle: 0.02168 | valid_mae: 0.52498 | valid_rmse: 0.61341 | valid_mse: 0.37627 |  0:00:18s\n",
      "epoch 10 | loss: 0.27159 | train_rmsle: 0.02276 | train_mae: 0.53433 | train_rmse: 0.62424 | train_mse: 0.38968 | valid_rmsle: 0.02261 | valid_mae: 0.53682 | valid_rmse: 0.62601 | valid_mse: 0.39189 |  0:00:20s\n",
      "epoch 11 | loss: 0.25284 | train_rmsle: 0.02078 | train_mae: 0.50579 | train_rmse: 0.59611 | train_mse: 0.35535 | valid_rmsle: 0.02051 | valid_mae: 0.50865 | valid_rmse: 0.5966  | valid_mse: 0.35594 |  0:00:21s\n",
      "epoch 12 | loss: 0.28223 | train_rmsle: 0.01974 | train_mae: 0.49207 | train_rmse: 0.58085 | train_mse: 0.33739 | valid_rmsle: 0.01973 | valid_mae: 0.49713 | valid_rmse: 0.58538 | valid_mse: 0.34267 |  0:00:23s\n",
      "epoch 13 | loss: 0.25131 | train_rmsle: 0.01449 | train_mae: 0.38968 | train_rmse: 0.48433 | train_mse: 0.23457 | valid_rmsle: 0.01399 | valid_mae: 0.39318 | valid_rmse: 0.48193 | valid_mse: 0.23226 |  0:00:25s\n",
      "epoch 14 | loss: 0.39455 | train_rmsle: 0.01482 | train_mae: 0.37932 | train_rmse: 0.48459 | train_mse: 0.23482 | valid_rmsle: 0.01412 | valid_mae: 0.38142 | valid_rmse: 0.47814 | valid_mse: 0.22862 |  0:00:27s\n",
      "epoch 15 | loss: 0.39942 | train_rmsle: 0.02439 | train_mae: 0.55399 | train_rmse: 0.6452  | train_mse: 0.41628 | valid_rmsle: 0.02426 | valid_mae: 0.55518 | valid_rmse: 0.64691 | valid_mse: 0.4185  |  0:00:29s\n",
      "epoch 16 | loss: 0.2619  | train_rmsle: 0.01533 | train_mae: 0.41421 | train_rmse: 0.50444 | train_mse: 0.25446 | valid_rmsle: 0.01494 | valid_mae: 0.41771 | valid_rmse: 0.50345 | valid_mse: 0.25346 |  0:00:30s\n",
      "epoch 17 | loss: 0.2523  | train_rmsle: 0.01558 | train_mae: 0.41989 | train_rmse: 0.50966 | train_mse: 0.25976 | valid_rmsle: 0.01513 | valid_mae: 0.42101 | valid_rmse: 0.5075  | valid_mse: 0.25756 |  0:00:32s\n",
      "epoch 18 | loss: 0.23002 | train_rmsle: 0.01606 | train_mae: 0.43058 | train_rmse: 0.51938 | train_mse: 0.26975 | valid_rmsle: 0.0158  | valid_mae: 0.43542 | valid_rmse: 0.52047 | valid_mse: 0.27089 |  0:00:34s\n",
      "epoch 19 | loss: 0.22574 | train_rmsle: 0.01623 | train_mae: 0.43335 | train_rmse: 0.52245 | train_mse: 0.27295 | valid_rmsle: 0.01581 | valid_mae: 0.43381 | valid_rmse: 0.52086 | valid_mse: 0.27129 |  0:00:36s\n",
      "epoch 20 | loss: 0.22544 | train_rmsle: 0.01403 | train_mae: 0.37623 | train_rmse: 0.47396 | train_mse: 0.22464 | valid_rmsle: 0.01327 | valid_mae: 0.37172 | valid_rmse: 0.46602 | valid_mse: 0.21717 |  0:00:38s\n",
      "epoch 21 | loss: 0.22813 | train_rmsle: 0.01573 | train_mae: 0.42427 | train_rmse: 0.513   | train_mse: 0.26317 | valid_rmsle: 0.01523 | valid_mae: 0.42429 | valid_rmse: 0.51    | valid_mse: 0.2601  |  0:00:39s\n",
      "epoch 22 | loss: 0.22998 | train_rmsle: 0.01417 | train_mae: 0.37542 | train_rmse: 0.47547 | train_mse: 0.22607 | valid_rmsle: 0.0136  | valid_mae: 0.379   | valid_rmse: 0.47121 | valid_mse: 0.22204 |  0:00:41s\n",
      "epoch 23 | loss: 0.24719 | train_rmsle: 0.01571 | train_mae: 0.42356 | train_rmse: 0.51291 | train_mse: 0.26308 | valid_rmsle: 0.01546 | valid_mae: 0.42541 | valid_rmse: 0.51385 | valid_mse: 0.26404 |  0:00:43s\n",
      "epoch 24 | loss: 0.22429 | train_rmsle: 0.01574 | train_mae: 0.42383 | train_rmse: 0.51287 | train_mse: 0.26304 | valid_rmsle: 0.01563 | valid_mae: 0.42944 | valid_rmse: 0.51642 | valid_mse: 0.26669 |  0:00:45s\n",
      "epoch 25 | loss: 0.21946 | train_rmsle: 0.01417 | train_mae: 0.38347 | train_rmse: 0.47872 | train_mse: 0.22918 | valid_rmsle: 0.01351 | valid_mae: 0.38077 | valid_rmse: 0.47263 | valid_mse: 0.22338 |  0:00:47s\n",
      "epoch 26 | loss: 0.21709 | train_rmsle: 0.01484 | train_mae: 0.40475 | train_rmse: 0.49498 | train_mse: 0.24501 | valid_rmsle: 0.01442 | valid_mae: 0.40431 | valid_rmse: 0.49356 | valid_mse: 0.2436  |  0:00:48s\n",
      "epoch 27 | loss: 0.21917 | train_rmsle: 0.01472 | train_mae: 0.40278 | train_rmse: 0.49287 | train_mse: 0.24292 | valid_rmsle: 0.01469 | valid_mae: 0.40977 | valid_rmse: 0.49772 | valid_mse: 0.24772 |  0:00:50s\n",
      "epoch 28 | loss: 0.21733 | train_rmsle: 0.0142  | train_mae: 0.38749 | train_rmse: 0.48033 | train_mse: 0.23071 | valid_rmsle: 0.01377 | valid_mae: 0.38494 | valid_rmse: 0.47748 | valid_mse: 0.22799 |  0:00:52s\n",
      "epoch 29 | loss: 0.21664 | train_rmsle: 0.01394 | train_mae: 0.37778 | train_rmse: 0.47398 | train_mse: 0.22466 | valid_rmsle: 0.01376 | valid_mae: 0.38063 | valid_rmse: 0.47674 | valid_mse: 0.22728 |  0:00:54s\n",
      "epoch 30 | loss: 0.21714 | train_rmsle: 0.01445 | train_mae: 0.39796 | train_rmse: 0.4881  | train_mse: 0.23824 | valid_rmsle: 0.01444 | valid_mae: 0.40351 | valid_rmse: 0.49312 | valid_mse: 0.24317 |  0:00:56s\n",
      "epoch 31 | loss: 0.21871 | train_rmsle: 0.01395 | train_mae: 0.37027 | train_rmse: 0.47091 | train_mse: 0.22176 | valid_rmsle: 0.01357 | valid_mae: 0.37383 | valid_rmse: 0.47    | valid_mse: 0.2209  |  0:00:57s\n",
      "epoch 32 | loss: 0.21529 | train_rmsle: 0.01382 | train_mae: 0.37173 | train_rmse: 0.47    | train_mse: 0.2209  | valid_rmsle: 0.01335 | valid_mae: 0.3739  | valid_rmse: 0.46707 | valid_mse: 0.21815 |  0:00:59s\n",
      "epoch 33 | loss: 0.22464 | train_rmsle: 0.01404 | train_mae: 0.37082 | train_rmse: 0.47214 | train_mse: 0.22292 | valid_rmsle: 0.0137  | valid_mae: 0.37591 | valid_rmse: 0.47185 | valid_mse: 0.22265 |  0:01:01s\n",
      "epoch 34 | loss: 0.22643 | train_rmsle: 0.01365 | train_mae: 0.37304 | train_rmse: 0.46842 | train_mse: 0.21942 | valid_rmsle: 0.0135  | valid_mae: 0.38001 | valid_rmse: 0.47153 | valid_mse: 0.22234 |  0:01:03s\n",
      "epoch 35 | loss: 0.21213 | train_rmsle: 0.01355 | train_mae: 0.37129 | train_rmse: 0.46642 | train_mse: 0.21754 | valid_rmsle: 0.01356 | valid_mae: 0.38184 | valid_rmse: 0.47216 | valid_mse: 0.22294 |  0:01:05s\n",
      "epoch 36 | loss: 0.21639 | train_rmsle: 0.01384 | train_mae: 0.38371 | train_rmse: 0.475   | train_mse: 0.22562 | valid_rmsle: 0.01377 | valid_mae: 0.39131 | valid_rmse: 0.47955 | valid_mse: 0.22996 |  0:01:06s\n",
      "epoch 37 | loss: 0.2141  | train_rmsle: 0.01373 | train_mae: 0.37528 | train_rmse: 0.47052 | train_mse: 0.22138 | valid_rmsle: 0.0135  | valid_mae: 0.3783  | valid_rmse: 0.47225 | valid_mse: 0.22302 |  0:01:08s\n",
      "epoch 38 | loss: 0.21242 | train_rmsle: 0.01361 | train_mae: 0.36992 | train_rmse: 0.46644 | train_mse: 0.21757 | valid_rmsle: 0.01349 | valid_mae: 0.37636 | valid_rmse: 0.46967 | valid_mse: 0.22059 |  0:01:10s\n",
      "epoch 39 | loss: 0.21543 | train_rmsle: 0.01376 | train_mae: 0.36967 | train_rmse: 0.46846 | train_mse: 0.21946 | valid_rmsle: 0.01375 | valid_mae: 0.37777 | valid_rmse: 0.4735  | valid_mse: 0.2242  |  0:01:12s\n",
      "epoch 40 | loss: 0.21699 | train_rmsle: 0.0136  | train_mae: 0.3693  | train_rmse: 0.46606 | train_mse: 0.21721 | valid_rmsle: 0.01361 | valid_mae: 0.37812 | valid_rmse: 0.47193 | valid_mse: 0.22272 |  0:01:14s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21832310813868422 RMSE: 0.46725058388265733 R2: 0.03356772421890386 MAE: 0.3709519909239511\n",
      "=====================================\n",
      "[105/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.005 max_epochs: 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.22243 | train_rmsle: 0.16573 | train_mae: 1.39283 | train_rmse: 1.4777  | train_mse: 2.1836  | valid_rmsle: 0.16703 | valid_mae: 1.39825 | valid_rmse: 1.48408 | valid_mse: 2.20248 |  0:00:02s\n",
      "epoch 1  | loss: 2.25295 | train_rmsle: 0.04925 | train_mae: 0.79874 | train_rmse: 0.8922  | train_mse: 0.79602 | valid_rmsle: 0.04941 | valid_mae: 0.79997 | valid_rmse: 0.89576 | valid_mse: 0.80238 |  0:00:03s\n",
      "epoch 2  | loss: 1.32941 | train_rmsle: 0.03035 | train_mae: 0.62491 | train_rmse: 0.71698 | train_mse: 0.51407 | valid_rmsle: 0.03034 | valid_mae: 0.62593 | valid_rmse: 0.71997 | valid_mse: 0.51835 |  0:00:05s\n",
      "epoch 3  | loss: 0.83871 | train_rmsle: 0.03217 | train_mae: 0.64443 | train_rmse: 0.7367  | train_mse: 0.54272 | valid_rmsle: 0.03213 | valid_mae: 0.64444 | valid_rmse: 0.73922 | valid_mse: 0.54644 |  0:00:07s\n",
      "epoch 4  | loss: 0.59306 | train_rmsle: 0.02993 | train_mae: 0.62041 | train_rmse: 0.71227 | train_mse: 0.50732 | valid_rmsle: 0.02984 | valid_mae: 0.62083 | valid_rmse: 0.71437 | valid_mse: 0.51033 |  0:00:09s\n",
      "epoch 5  | loss: 0.46346 | train_rmsle: 0.02439 | train_mae: 0.55567 | train_rmse: 0.64597 | train_mse: 0.41728 | valid_rmsle: 0.02425 | valid_mae: 0.55757 | valid_rmse: 0.6478  | valid_mse: 0.41965 |  0:00:11s\n",
      "epoch 6  | loss: 0.36522 | train_rmsle: 0.02349 | train_mae: 0.54451 | train_rmse: 0.6342  | train_mse: 0.40221 | valid_rmsle: 0.02341 | valid_mae: 0.54682 | valid_rmse: 0.63694 | valid_mse: 0.40569 |  0:00:12s\n",
      "epoch 7  | loss: 0.31624 | train_rmsle: 0.01775 | train_mae: 0.46013 | train_rmse: 0.54817 | train_mse: 0.30049 | valid_rmsle: 0.01742 | valid_mae: 0.46241 | valid_rmse: 0.54793 | valid_mse: 0.30022 |  0:00:14s\n",
      "epoch 8  | loss: 0.29118 | train_rmsle: 0.01709 | train_mae: 0.4493  | train_rmse: 0.53746 | train_mse: 0.28887 | valid_rmsle: 0.0168  | valid_mae: 0.45149 | valid_rmse: 0.53789 | valid_mse: 0.28932 |  0:00:16s\n",
      "epoch 9  | loss: 0.29033 | train_rmsle: 0.02427 | train_mae: 0.55439 | train_rmse: 0.64467 | train_mse: 0.4156  | valid_rmsle: 0.02422 | valid_mae: 0.55684 | valid_rmse: 0.64769 | valid_mse: 0.4195  |  0:00:18s\n",
      "epoch 10 | loss: 0.26364 | train_rmsle: 0.0164  | train_mae: 0.43444 | train_rmse: 0.52532 | train_mse: 0.27596 | valid_rmsle: 0.01603 | valid_mae: 0.43537 | valid_rmse: 0.52446 | valid_mse: 0.27505 |  0:00:20s\n",
      "epoch 11 | loss: 0.25184 | train_rmsle: 0.0151  | train_mae: 0.40756 | train_rmse: 0.50056 | train_mse: 0.25056 | valid_rmsle: 0.01488 | valid_mae: 0.4115  | valid_rmse: 0.50245 | valid_mse: 0.25246 |  0:00:21s\n",
      "epoch 12 | loss: 0.26221 | train_rmsle: 0.0144  | train_mae: 0.3831  | train_rmse: 0.4817  | train_mse: 0.23204 | valid_rmsle: 0.01377 | valid_mae: 0.38573 | valid_rmse: 0.4765  | valid_mse: 0.22705 |  0:00:23s\n",
      "epoch 13 | loss: 0.25227 | train_rmsle: 0.0149  | train_mae: 0.4056  | train_rmse: 0.49715 | train_mse: 0.24716 | valid_rmsle: 0.01457 | valid_mae: 0.40762 | valid_rmse: 0.49681 | valid_mse: 0.24682 |  0:00:25s\n",
      "epoch 14 | loss: 0.24424 | train_rmsle: 0.01899 | train_mae: 0.47822 | train_rmse: 0.56951 | train_mse: 0.32435 | valid_rmsle: 0.01885 | valid_mae: 0.47702 | valid_rmse: 0.5717  | valid_mse: 0.32684 |  0:00:27s\n",
      "epoch 15 | loss: 0.24264 | train_rmsle: 0.01441 | train_mae: 0.39234 | train_rmse: 0.4854  | train_mse: 0.23562 | valid_rmsle: 0.01407 | valid_mae: 0.39594 | valid_rmse: 0.48518 | valid_mse: 0.2354  |  0:00:29s\n",
      "epoch 16 | loss: 0.23569 | train_rmsle: 0.01685 | train_mae: 0.44332 | train_rmse: 0.53393 | train_mse: 0.28508 | valid_rmsle: 0.0167  | valid_mae: 0.44539 | valid_rmse: 0.53608 | valid_mse: 0.28738 |  0:00:30s\n",
      "epoch 17 | loss: 0.23707 | train_rmsle: 0.01449 | train_mae: 0.3965  | train_rmse: 0.48847 | train_mse: 0.2386  | valid_rmsle: 0.01391 | valid_mae: 0.39341 | valid_rmse: 0.48312 | valid_mse: 0.23341 |  0:00:32s\n",
      "epoch 18 | loss: 0.23199 | train_rmsle: 0.0147  | train_mae: 0.40141 | train_rmse: 0.49289 | train_mse: 0.24294 | valid_rmsle: 0.01423 | valid_mae: 0.39941 | valid_rmse: 0.48971 | valid_mse: 0.23982 |  0:00:34s\n",
      "epoch 19 | loss: 0.2344  | train_rmsle: 0.01495 | train_mae: 0.40799 | train_rmse: 0.49875 | train_mse: 0.24876 | valid_rmsle: 0.01445 | valid_mae: 0.4067  | valid_rmse: 0.49525 | valid_mse: 0.24527 |  0:00:36s\n",
      "epoch 20 | loss: 0.23231 | train_rmsle: 0.01403 | train_mae: 0.37269 | train_rmse: 0.47226 | train_mse: 0.22303 | valid_rmsle: 0.01325 | valid_mae: 0.36869 | valid_rmse: 0.46352 | valid_mse: 0.21486 |  0:00:38s\n",
      "epoch 21 | loss: 0.24071 | train_rmsle: 0.01442 | train_mae: 0.39382 | train_rmse: 0.487   | train_mse: 0.23717 | valid_rmsle: 0.01383 | valid_mae: 0.39401 | valid_rmse: 0.48165 | valid_mse: 0.23199 |  0:00:39s\n",
      "epoch 22 | loss: 0.227   | train_rmsle: 0.01412 | train_mae: 0.38433 | train_rmse: 0.47906 | train_mse: 0.2295  | valid_rmsle: 0.01368 | valid_mae: 0.38917 | valid_rmse: 0.47746 | valid_mse: 0.22797 |  0:00:41s\n",
      "epoch 23 | loss: 0.24498 | train_rmsle: 0.01473 | train_mae: 0.40294 | train_rmse: 0.49401 | train_mse: 0.24404 | valid_rmsle: 0.01396 | valid_mae: 0.39726 | valid_rmse: 0.48543 | valid_mse: 0.23564 |  0:00:43s\n",
      "epoch 24 | loss: 0.28982 | train_rmsle: 0.01572 | train_mae: 0.42338 | train_rmse: 0.51367 | train_mse: 0.26386 | valid_rmsle: 0.01538 | valid_mae: 0.42377 | valid_rmse: 0.5128  | valid_mse: 0.26296 |  0:00:45s\n",
      "epoch 25 | loss: 0.22289 | train_rmsle: 0.01389 | train_mae: 0.38011 | train_rmse: 0.47425 | train_mse: 0.22491 | valid_rmsle: 0.01342 | valid_mae: 0.38261 | valid_rmse: 0.47168 | valid_mse: 0.22248 |  0:00:47s\n",
      "epoch 26 | loss: 0.22227 | train_rmsle: 0.01402 | train_mae: 0.38211 | train_rmse: 0.47706 | train_mse: 0.22759 | valid_rmsle: 0.0133  | valid_mae: 0.37965 | valid_rmse: 0.46947 | valid_mse: 0.2204  |  0:00:48s\n",
      "epoch 27 | loss: 0.22174 | train_rmsle: 0.01387 | train_mae: 0.37341 | train_rmse: 0.47121 | train_mse: 0.22204 | valid_rmsle: 0.01346 | valid_mae: 0.37562 | valid_rmse: 0.46929 | valid_mse: 0.22024 |  0:00:50s\n",
      "epoch 28 | loss: 0.22467 | train_rmsle: 0.01436 | train_mae: 0.37394 | train_rmse: 0.47824 | train_mse: 0.22872 | valid_rmsle: 0.01409 | valid_mae: 0.37892 | valid_rmse: 0.48019 | valid_mse: 0.23058 |  0:00:52s\n",
      "epoch 29 | loss: 0.24433 | train_rmsle: 0.0144  | train_mae: 0.37249 | train_rmse: 0.47759 | train_mse: 0.22809 | valid_rmsle: 0.01418 | valid_mae: 0.38034 | valid_rmse: 0.47966 | valid_mse: 0.23007 |  0:00:54s\n",
      "epoch 30 | loss: 0.24896 | train_rmsle: 0.01462 | train_mae: 0.40011 | train_rmse: 0.4921  | train_mse: 0.24216 | valid_rmsle: 0.01448 | valid_mae: 0.40658 | valid_rmse: 0.4946  | valid_mse: 0.24463 |  0:00:55s\n",
      "epoch 31 | loss: 0.23056 | train_rmsle: 0.01397 | train_mae: 0.38211 | train_rmse: 0.47658 | train_mse: 0.22713 | valid_rmsle: 0.01362 | valid_mae: 0.38531 | valid_rmse: 0.47618 | valid_mse: 0.22675 |  0:00:57s\n",
      "epoch 32 | loss: 0.22447 | train_rmsle: 0.01393 | train_mae: 0.37155 | train_rmse: 0.47131 | train_mse: 0.22213 | valid_rmsle: 0.01396 | valid_mae: 0.38306 | valid_rmse: 0.47822 | valid_mse: 0.22869 |  0:00:59s\n",
      "epoch 33 | loss: 0.21815 | train_rmsle: 0.01388 | train_mae: 0.38056 | train_rmse: 0.47511 | train_mse: 0.22573 | valid_rmsle: 0.0138  | valid_mae: 0.38752 | valid_rmse: 0.47897 | valid_mse: 0.22941 |  0:01:01s\n",
      "epoch 34 | loss: 0.21618 | train_rmsle: 0.01404 | train_mae: 0.38274 | train_rmse: 0.47793 | train_mse: 0.22841 | valid_rmsle: 0.01378 | valid_mae: 0.3876  | valid_rmse: 0.47772 | valid_mse: 0.22821 |  0:01:03s\n",
      "epoch 35 | loss: 0.21556 | train_rmsle: 0.01392 | train_mae: 0.38258 | train_rmse: 0.47613 | train_mse: 0.2267  | valid_rmsle: 0.01392 | valid_mae: 0.39405 | valid_rmse: 0.48227 | valid_mse: 0.23259 |  0:01:04s\n",
      "epoch 36 | loss: 0.21886 | train_rmsle: 0.01391 | train_mae: 0.36714 | train_rmse: 0.46983 | train_mse: 0.22074 | valid_rmsle: 0.014   | valid_mae: 0.37926 | valid_rmse: 0.47771 | valid_mse: 0.2282  |  0:01:06s\n",
      "epoch 37 | loss: 0.22168 | train_rmsle: 0.01367 | train_mae: 0.37079 | train_rmse: 0.46857 | train_mse: 0.21956 | valid_rmsle: 0.01418 | valid_mae: 0.38919 | valid_rmse: 0.48363 | valid_mse: 0.2339  |  0:01:08s\n",
      "epoch 38 | loss: 0.23037 | train_rmsle: 0.01375 | train_mae: 0.37073 | train_rmse: 0.4694  | train_mse: 0.22034 | valid_rmsle: 0.01374 | valid_mae: 0.38171 | valid_rmse: 0.47571 | valid_mse: 0.2263  |  0:01:10s\n",
      "epoch 39 | loss: 0.22822 | train_rmsle: 0.01366 | train_mae: 0.36694 | train_rmse: 0.46655 | train_mse: 0.21766 | valid_rmsle: 0.01355 | valid_mae: 0.37608 | valid_rmse: 0.47081 | valid_mse: 0.22166 |  0:01:12s\n",
      "epoch 40 | loss: 0.21409 | train_rmsle: 0.0138  | train_mae: 0.36894 | train_rmse: 0.46938 | train_mse: 0.22031 | valid_rmsle: 0.01377 | valid_mae: 0.3791  | valid_rmse: 0.4751  | valid_mse: 0.22572 |  0:01:13s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2203773859618822 RMSE: 0.4694436983940483 R2: 0.024474227847009367 MAE: 0.37100764777734585\n",
      "=====================================\n",
      "[106/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.005 max_epochs: 120\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.22243 | train_rmsle: 0.16573 | train_mae: 1.39283 | train_rmse: 1.4777  | train_mse: 2.1836  | valid_rmsle: 0.16703 | valid_mae: 1.39825 | valid_rmse: 1.48408 | valid_mse: 2.20248 |  0:00:01s\n",
      "epoch 1  | loss: 2.25295 | train_rmsle: 0.04925 | train_mae: 0.79874 | train_rmse: 0.8922  | train_mse: 0.79602 | valid_rmsle: 0.04941 | valid_mae: 0.79997 | valid_rmse: 0.89576 | valid_mse: 0.80238 |  0:00:03s\n",
      "epoch 2  | loss: 1.32941 | train_rmsle: 0.03035 | train_mae: 0.62491 | train_rmse: 0.71698 | train_mse: 0.51407 | valid_rmsle: 0.03034 | valid_mae: 0.62593 | valid_rmse: 0.71997 | valid_mse: 0.51835 |  0:00:05s\n",
      "epoch 3  | loss: 0.83871 | train_rmsle: 0.03217 | train_mae: 0.64443 | train_rmse: 0.7367  | train_mse: 0.54272 | valid_rmsle: 0.03213 | valid_mae: 0.64444 | valid_rmse: 0.73922 | valid_mse: 0.54644 |  0:00:07s\n",
      "epoch 4  | loss: 0.59306 | train_rmsle: 0.02993 | train_mae: 0.62041 | train_rmse: 0.71227 | train_mse: 0.50732 | valid_rmsle: 0.02984 | valid_mae: 0.62083 | valid_rmse: 0.71437 | valid_mse: 0.51033 |  0:00:09s\n",
      "epoch 5  | loss: 0.46346 | train_rmsle: 0.02439 | train_mae: 0.55567 | train_rmse: 0.64597 | train_mse: 0.41728 | valid_rmsle: 0.02425 | valid_mae: 0.55757 | valid_rmse: 0.6478  | valid_mse: 0.41965 |  0:00:10s\n",
      "epoch 6  | loss: 0.36522 | train_rmsle: 0.02349 | train_mae: 0.54451 | train_rmse: 0.6342  | train_mse: 0.40221 | valid_rmsle: 0.02341 | valid_mae: 0.54682 | valid_rmse: 0.63694 | valid_mse: 0.40569 |  0:00:12s\n",
      "epoch 7  | loss: 0.31624 | train_rmsle: 0.01775 | train_mae: 0.46013 | train_rmse: 0.54817 | train_mse: 0.30049 | valid_rmsle: 0.01742 | valid_mae: 0.46241 | valid_rmse: 0.54793 | valid_mse: 0.30022 |  0:00:14s\n",
      "epoch 8  | loss: 0.29118 | train_rmsle: 0.01709 | train_mae: 0.4493  | train_rmse: 0.53746 | train_mse: 0.28887 | valid_rmsle: 0.0168  | valid_mae: 0.45149 | valid_rmse: 0.53789 | valid_mse: 0.28932 |  0:00:16s\n",
      "epoch 9  | loss: 0.29033 | train_rmsle: 0.02427 | train_mae: 0.55439 | train_rmse: 0.64467 | train_mse: 0.4156  | valid_rmsle: 0.02422 | valid_mae: 0.55684 | valid_rmse: 0.64769 | valid_mse: 0.4195  |  0:00:18s\n",
      "epoch 10 | loss: 0.26364 | train_rmsle: 0.0164  | train_mae: 0.43444 | train_rmse: 0.52532 | train_mse: 0.27596 | valid_rmsle: 0.01603 | valid_mae: 0.43537 | valid_rmse: 0.52446 | valid_mse: 0.27505 |  0:00:19s\n",
      "epoch 11 | loss: 0.25184 | train_rmsle: 0.0151  | train_mae: 0.40756 | train_rmse: 0.50056 | train_mse: 0.25056 | valid_rmsle: 0.01488 | valid_mae: 0.4115  | valid_rmse: 0.50245 | valid_mse: 0.25246 |  0:00:21s\n",
      "epoch 12 | loss: 0.26221 | train_rmsle: 0.0144  | train_mae: 0.3831  | train_rmse: 0.4817  | train_mse: 0.23204 | valid_rmsle: 0.01377 | valid_mae: 0.38573 | valid_rmse: 0.4765  | valid_mse: 0.22705 |  0:00:23s\n",
      "epoch 13 | loss: 0.25227 | train_rmsle: 0.0149  | train_mae: 0.4056  | train_rmse: 0.49715 | train_mse: 0.24716 | valid_rmsle: 0.01457 | valid_mae: 0.40762 | valid_rmse: 0.49681 | valid_mse: 0.24682 |  0:00:25s\n",
      "epoch 14 | loss: 0.24424 | train_rmsle: 0.01899 | train_mae: 0.47822 | train_rmse: 0.56951 | train_mse: 0.32435 | valid_rmsle: 0.01885 | valid_mae: 0.47702 | valid_rmse: 0.5717  | valid_mse: 0.32684 |  0:00:27s\n",
      "epoch 15 | loss: 0.24264 | train_rmsle: 0.01441 | train_mae: 0.39234 | train_rmse: 0.4854  | train_mse: 0.23562 | valid_rmsle: 0.01407 | valid_mae: 0.39594 | valid_rmse: 0.48518 | valid_mse: 0.2354  |  0:00:28s\n",
      "epoch 16 | loss: 0.23569 | train_rmsle: 0.01685 | train_mae: 0.44332 | train_rmse: 0.53393 | train_mse: 0.28508 | valid_rmsle: 0.0167  | valid_mae: 0.44539 | valid_rmse: 0.53608 | valid_mse: 0.28738 |  0:00:30s\n",
      "epoch 17 | loss: 0.23707 | train_rmsle: 0.01449 | train_mae: 0.3965  | train_rmse: 0.48847 | train_mse: 0.2386  | valid_rmsle: 0.01391 | valid_mae: 0.39341 | valid_rmse: 0.48312 | valid_mse: 0.23341 |  0:00:32s\n",
      "epoch 18 | loss: 0.23199 | train_rmsle: 0.0147  | train_mae: 0.40141 | train_rmse: 0.49289 | train_mse: 0.24294 | valid_rmsle: 0.01423 | valid_mae: 0.39941 | valid_rmse: 0.48971 | valid_mse: 0.23982 |  0:00:34s\n",
      "epoch 19 | loss: 0.2344  | train_rmsle: 0.01495 | train_mae: 0.40799 | train_rmse: 0.49875 | train_mse: 0.24876 | valid_rmsle: 0.01445 | valid_mae: 0.4067  | valid_rmse: 0.49525 | valid_mse: 0.24527 |  0:00:36s\n",
      "epoch 20 | loss: 0.23231 | train_rmsle: 0.01403 | train_mae: 0.37269 | train_rmse: 0.47226 | train_mse: 0.22303 | valid_rmsle: 0.01325 | valid_mae: 0.36869 | valid_rmse: 0.46352 | valid_mse: 0.21486 |  0:00:37s\n",
      "epoch 21 | loss: 0.24071 | train_rmsle: 0.01442 | train_mae: 0.39382 | train_rmse: 0.487   | train_mse: 0.23717 | valid_rmsle: 0.01383 | valid_mae: 0.39401 | valid_rmse: 0.48165 | valid_mse: 0.23199 |  0:00:39s\n",
      "epoch 22 | loss: 0.227   | train_rmsle: 0.01412 | train_mae: 0.38433 | train_rmse: 0.47906 | train_mse: 0.2295  | valid_rmsle: 0.01368 | valid_mae: 0.38917 | valid_rmse: 0.47746 | valid_mse: 0.22797 |  0:00:41s\n",
      "epoch 23 | loss: 0.24498 | train_rmsle: 0.01473 | train_mae: 0.40294 | train_rmse: 0.49401 | train_mse: 0.24404 | valid_rmsle: 0.01396 | valid_mae: 0.39726 | valid_rmse: 0.48543 | valid_mse: 0.23564 |  0:00:43s\n",
      "epoch 24 | loss: 0.28982 | train_rmsle: 0.01572 | train_mae: 0.42338 | train_rmse: 0.51367 | train_mse: 0.26386 | valid_rmsle: 0.01538 | valid_mae: 0.42377 | valid_rmse: 0.5128  | valid_mse: 0.26296 |  0:00:45s\n",
      "epoch 25 | loss: 0.22289 | train_rmsle: 0.01389 | train_mae: 0.38011 | train_rmse: 0.47425 | train_mse: 0.22491 | valid_rmsle: 0.01342 | valid_mae: 0.38261 | valid_rmse: 0.47168 | valid_mse: 0.22248 |  0:00:46s\n",
      "epoch 26 | loss: 0.22227 | train_rmsle: 0.01402 | train_mae: 0.38211 | train_rmse: 0.47706 | train_mse: 0.22759 | valid_rmsle: 0.0133  | valid_mae: 0.37965 | valid_rmse: 0.46947 | valid_mse: 0.2204  |  0:00:48s\n",
      "epoch 27 | loss: 0.22174 | train_rmsle: 0.01387 | train_mae: 0.37341 | train_rmse: 0.47121 | train_mse: 0.22204 | valid_rmsle: 0.01346 | valid_mae: 0.37562 | valid_rmse: 0.46929 | valid_mse: 0.22024 |  0:00:50s\n",
      "epoch 28 | loss: 0.22467 | train_rmsle: 0.01436 | train_mae: 0.37394 | train_rmse: 0.47824 | train_mse: 0.22872 | valid_rmsle: 0.01409 | valid_mae: 0.37892 | valid_rmse: 0.48019 | valid_mse: 0.23058 |  0:00:52s\n",
      "epoch 29 | loss: 0.24433 | train_rmsle: 0.0144  | train_mae: 0.37249 | train_rmse: 0.47759 | train_mse: 0.22809 | valid_rmsle: 0.01418 | valid_mae: 0.38034 | valid_rmse: 0.47966 | valid_mse: 0.23007 |  0:00:54s\n",
      "epoch 30 | loss: 0.24896 | train_rmsle: 0.01462 | train_mae: 0.40011 | train_rmse: 0.4921  | train_mse: 0.24216 | valid_rmsle: 0.01448 | valid_mae: 0.40658 | valid_rmse: 0.4946  | valid_mse: 0.24463 |  0:00:55s\n",
      "epoch 31 | loss: 0.23056 | train_rmsle: 0.01397 | train_mae: 0.38211 | train_rmse: 0.47658 | train_mse: 0.22713 | valid_rmsle: 0.01362 | valid_mae: 0.38531 | valid_rmse: 0.47618 | valid_mse: 0.22675 |  0:00:57s\n",
      "epoch 32 | loss: 0.22447 | train_rmsle: 0.01393 | train_mae: 0.37155 | train_rmse: 0.47131 | train_mse: 0.22213 | valid_rmsle: 0.01396 | valid_mae: 0.38306 | valid_rmse: 0.47822 | valid_mse: 0.22869 |  0:00:59s\n",
      "epoch 33 | loss: 0.21815 | train_rmsle: 0.01388 | train_mae: 0.38056 | train_rmse: 0.47511 | train_mse: 0.22573 | valid_rmsle: 0.0138  | valid_mae: 0.38752 | valid_rmse: 0.47897 | valid_mse: 0.22941 |  0:01:01s\n",
      "epoch 34 | loss: 0.21618 | train_rmsle: 0.01404 | train_mae: 0.38274 | train_rmse: 0.47793 | train_mse: 0.22841 | valid_rmsle: 0.01378 | valid_mae: 0.3876  | valid_rmse: 0.47772 | valid_mse: 0.22821 |  0:01:03s\n",
      "epoch 35 | loss: 0.21556 | train_rmsle: 0.01392 | train_mae: 0.38258 | train_rmse: 0.47613 | train_mse: 0.2267  | valid_rmsle: 0.01392 | valid_mae: 0.39405 | valid_rmse: 0.48227 | valid_mse: 0.23259 |  0:01:04s\n",
      "epoch 36 | loss: 0.21886 | train_rmsle: 0.01391 | train_mae: 0.36714 | train_rmse: 0.46983 | train_mse: 0.22074 | valid_rmsle: 0.014   | valid_mae: 0.37926 | valid_rmse: 0.47771 | valid_mse: 0.2282  |  0:01:06s\n",
      "epoch 37 | loss: 0.22168 | train_rmsle: 0.01367 | train_mae: 0.37079 | train_rmse: 0.46857 | train_mse: 0.21956 | valid_rmsle: 0.01418 | valid_mae: 0.38919 | valid_rmse: 0.48363 | valid_mse: 0.2339  |  0:01:08s\n",
      "epoch 38 | loss: 0.23037 | train_rmsle: 0.01375 | train_mae: 0.37073 | train_rmse: 0.4694  | train_mse: 0.22034 | valid_rmsle: 0.01374 | valid_mae: 0.38171 | valid_rmse: 0.47571 | valid_mse: 0.2263  |  0:01:10s\n",
      "epoch 39 | loss: 0.22822 | train_rmsle: 0.01366 | train_mae: 0.36694 | train_rmse: 0.46655 | train_mse: 0.21766 | valid_rmsle: 0.01355 | valid_mae: 0.37608 | valid_rmse: 0.47081 | valid_mse: 0.22166 |  0:01:12s\n",
      "epoch 40 | loss: 0.21409 | train_rmsle: 0.0138  | train_mae: 0.36894 | train_rmse: 0.46938 | train_mse: 0.22031 | valid_rmsle: 0.01377 | valid_mae: 0.3791  | valid_rmse: 0.4751  | valid_mse: 0.22572 |  0:01:13s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2203773859618822 RMSE: 0.4694436983940483 R2: 0.024474227847009367 MAE: 0.37100764777734585\n",
      "=====================================\n",
      "[107/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.005 max_epochs: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.22243 | train_rmsle: 0.16573 | train_mae: 1.39283 | train_rmse: 1.4777  | train_mse: 2.1836  | valid_rmsle: 0.16703 | valid_mae: 1.39825 | valid_rmse: 1.48408 | valid_mse: 2.20248 |  0:00:01s\n",
      "epoch 1  | loss: 2.25295 | train_rmsle: 0.04925 | train_mae: 0.79874 | train_rmse: 0.8922  | train_mse: 0.79602 | valid_rmsle: 0.04941 | valid_mae: 0.79997 | valid_rmse: 0.89576 | valid_mse: 0.80238 |  0:00:03s\n",
      "epoch 2  | loss: 1.32941 | train_rmsle: 0.03035 | train_mae: 0.62491 | train_rmse: 0.71698 | train_mse: 0.51407 | valid_rmsle: 0.03034 | valid_mae: 0.62593 | valid_rmse: 0.71997 | valid_mse: 0.51835 |  0:00:05s\n",
      "epoch 3  | loss: 0.83871 | train_rmsle: 0.03217 | train_mae: 0.64443 | train_rmse: 0.7367  | train_mse: 0.54272 | valid_rmsle: 0.03213 | valid_mae: 0.64444 | valid_rmse: 0.73922 | valid_mse: 0.54644 |  0:00:07s\n",
      "epoch 4  | loss: 0.59306 | train_rmsle: 0.02993 | train_mae: 0.62041 | train_rmse: 0.71227 | train_mse: 0.50732 | valid_rmsle: 0.02984 | valid_mae: 0.62083 | valid_rmse: 0.71437 | valid_mse: 0.51033 |  0:00:09s\n",
      "epoch 5  | loss: 0.46346 | train_rmsle: 0.02439 | train_mae: 0.55567 | train_rmse: 0.64597 | train_mse: 0.41728 | valid_rmsle: 0.02425 | valid_mae: 0.55757 | valid_rmse: 0.6478  | valid_mse: 0.41965 |  0:00:10s\n",
      "epoch 6  | loss: 0.36522 | train_rmsle: 0.02349 | train_mae: 0.54451 | train_rmse: 0.6342  | train_mse: 0.40221 | valid_rmsle: 0.02341 | valid_mae: 0.54682 | valid_rmse: 0.63694 | valid_mse: 0.40569 |  0:00:12s\n",
      "epoch 7  | loss: 0.31624 | train_rmsle: 0.01775 | train_mae: 0.46013 | train_rmse: 0.54817 | train_mse: 0.30049 | valid_rmsle: 0.01742 | valid_mae: 0.46241 | valid_rmse: 0.54793 | valid_mse: 0.30022 |  0:00:14s\n",
      "epoch 8  | loss: 0.29118 | train_rmsle: 0.01709 | train_mae: 0.4493  | train_rmse: 0.53746 | train_mse: 0.28887 | valid_rmsle: 0.0168  | valid_mae: 0.45149 | valid_rmse: 0.53789 | valid_mse: 0.28932 |  0:00:16s\n",
      "epoch 9  | loss: 0.29033 | train_rmsle: 0.02427 | train_mae: 0.55439 | train_rmse: 0.64467 | train_mse: 0.4156  | valid_rmsle: 0.02422 | valid_mae: 0.55684 | valid_rmse: 0.64769 | valid_mse: 0.4195  |  0:00:18s\n",
      "epoch 10 | loss: 0.26364 | train_rmsle: 0.0164  | train_mae: 0.43444 | train_rmse: 0.52532 | train_mse: 0.27596 | valid_rmsle: 0.01603 | valid_mae: 0.43537 | valid_rmse: 0.52446 | valid_mse: 0.27505 |  0:00:19s\n",
      "epoch 11 | loss: 0.25184 | train_rmsle: 0.0151  | train_mae: 0.40756 | train_rmse: 0.50056 | train_mse: 0.25056 | valid_rmsle: 0.01488 | valid_mae: 0.4115  | valid_rmse: 0.50245 | valid_mse: 0.25246 |  0:00:21s\n",
      "epoch 12 | loss: 0.26221 | train_rmsle: 0.0144  | train_mae: 0.3831  | train_rmse: 0.4817  | train_mse: 0.23204 | valid_rmsle: 0.01377 | valid_mae: 0.38573 | valid_rmse: 0.4765  | valid_mse: 0.22705 |  0:00:23s\n",
      "epoch 13 | loss: 0.25227 | train_rmsle: 0.0149  | train_mae: 0.4056  | train_rmse: 0.49715 | train_mse: 0.24716 | valid_rmsle: 0.01457 | valid_mae: 0.40762 | valid_rmse: 0.49681 | valid_mse: 0.24682 |  0:00:25s\n",
      "epoch 14 | loss: 0.24424 | train_rmsle: 0.01899 | train_mae: 0.47822 | train_rmse: 0.56951 | train_mse: 0.32435 | valid_rmsle: 0.01885 | valid_mae: 0.47702 | valid_rmse: 0.5717  | valid_mse: 0.32684 |  0:00:27s\n",
      "epoch 15 | loss: 0.24264 | train_rmsle: 0.01441 | train_mae: 0.39234 | train_rmse: 0.4854  | train_mse: 0.23562 | valid_rmsle: 0.01407 | valid_mae: 0.39594 | valid_rmse: 0.48518 | valid_mse: 0.2354  |  0:00:28s\n",
      "epoch 16 | loss: 0.23569 | train_rmsle: 0.01685 | train_mae: 0.44332 | train_rmse: 0.53393 | train_mse: 0.28508 | valid_rmsle: 0.0167  | valid_mae: 0.44539 | valid_rmse: 0.53608 | valid_mse: 0.28738 |  0:00:30s\n",
      "epoch 17 | loss: 0.23707 | train_rmsle: 0.01449 | train_mae: 0.3965  | train_rmse: 0.48847 | train_mse: 0.2386  | valid_rmsle: 0.01391 | valid_mae: 0.39341 | valid_rmse: 0.48312 | valid_mse: 0.23341 |  0:00:32s\n",
      "epoch 18 | loss: 0.23199 | train_rmsle: 0.0147  | train_mae: 0.40141 | train_rmse: 0.49289 | train_mse: 0.24294 | valid_rmsle: 0.01423 | valid_mae: 0.39941 | valid_rmse: 0.48971 | valid_mse: 0.23982 |  0:00:34s\n",
      "epoch 19 | loss: 0.2344  | train_rmsle: 0.01495 | train_mae: 0.40799 | train_rmse: 0.49875 | train_mse: 0.24876 | valid_rmsle: 0.01445 | valid_mae: 0.4067  | valid_rmse: 0.49525 | valid_mse: 0.24527 |  0:00:36s\n",
      "epoch 20 | loss: 0.23231 | train_rmsle: 0.01403 | train_mae: 0.37269 | train_rmse: 0.47226 | train_mse: 0.22303 | valid_rmsle: 0.01325 | valid_mae: 0.36869 | valid_rmse: 0.46352 | valid_mse: 0.21486 |  0:00:38s\n",
      "epoch 21 | loss: 0.24071 | train_rmsle: 0.01442 | train_mae: 0.39382 | train_rmse: 0.487   | train_mse: 0.23717 | valid_rmsle: 0.01383 | valid_mae: 0.39401 | valid_rmse: 0.48165 | valid_mse: 0.23199 |  0:00:39s\n",
      "epoch 22 | loss: 0.227   | train_rmsle: 0.01412 | train_mae: 0.38433 | train_rmse: 0.47906 | train_mse: 0.2295  | valid_rmsle: 0.01368 | valid_mae: 0.38917 | valid_rmse: 0.47746 | valid_mse: 0.22797 |  0:00:41s\n",
      "epoch 23 | loss: 0.24498 | train_rmsle: 0.01473 | train_mae: 0.40294 | train_rmse: 0.49401 | train_mse: 0.24404 | valid_rmsle: 0.01396 | valid_mae: 0.39726 | valid_rmse: 0.48543 | valid_mse: 0.23564 |  0:00:43s\n",
      "epoch 24 | loss: 0.28982 | train_rmsle: 0.01572 | train_mae: 0.42338 | train_rmse: 0.51367 | train_mse: 0.26386 | valid_rmsle: 0.01538 | valid_mae: 0.42377 | valid_rmse: 0.5128  | valid_mse: 0.26296 |  0:00:45s\n",
      "epoch 25 | loss: 0.22289 | train_rmsle: 0.01389 | train_mae: 0.38011 | train_rmse: 0.47425 | train_mse: 0.22491 | valid_rmsle: 0.01342 | valid_mae: 0.38261 | valid_rmse: 0.47168 | valid_mse: 0.22248 |  0:00:47s\n",
      "epoch 26 | loss: 0.22227 | train_rmsle: 0.01402 | train_mae: 0.38211 | train_rmse: 0.47706 | train_mse: 0.22759 | valid_rmsle: 0.0133  | valid_mae: 0.37965 | valid_rmse: 0.46947 | valid_mse: 0.2204  |  0:00:48s\n",
      "epoch 27 | loss: 0.22174 | train_rmsle: 0.01387 | train_mae: 0.37341 | train_rmse: 0.47121 | train_mse: 0.22204 | valid_rmsle: 0.01346 | valid_mae: 0.37562 | valid_rmse: 0.46929 | valid_mse: 0.22024 |  0:00:50s\n",
      "epoch 28 | loss: 0.22467 | train_rmsle: 0.01436 | train_mae: 0.37394 | train_rmse: 0.47824 | train_mse: 0.22872 | valid_rmsle: 0.01409 | valid_mae: 0.37892 | valid_rmse: 0.48019 | valid_mse: 0.23058 |  0:00:52s\n",
      "epoch 29 | loss: 0.24433 | train_rmsle: 0.0144  | train_mae: 0.37249 | train_rmse: 0.47759 | train_mse: 0.22809 | valid_rmsle: 0.01418 | valid_mae: 0.38034 | valid_rmse: 0.47966 | valid_mse: 0.23007 |  0:00:54s\n",
      "epoch 30 | loss: 0.24896 | train_rmsle: 0.01462 | train_mae: 0.40011 | train_rmse: 0.4921  | train_mse: 0.24216 | valid_rmsle: 0.01448 | valid_mae: 0.40658 | valid_rmse: 0.4946  | valid_mse: 0.24463 |  0:00:56s\n",
      "epoch 31 | loss: 0.23056 | train_rmsle: 0.01397 | train_mae: 0.38211 | train_rmse: 0.47658 | train_mse: 0.22713 | valid_rmsle: 0.01362 | valid_mae: 0.38531 | valid_rmse: 0.47618 | valid_mse: 0.22675 |  0:00:57s\n",
      "epoch 32 | loss: 0.22447 | train_rmsle: 0.01393 | train_mae: 0.37155 | train_rmse: 0.47131 | train_mse: 0.22213 | valid_rmsle: 0.01396 | valid_mae: 0.38306 | valid_rmse: 0.47822 | valid_mse: 0.22869 |  0:00:59s\n",
      "epoch 33 | loss: 0.21815 | train_rmsle: 0.01388 | train_mae: 0.38056 | train_rmse: 0.47511 | train_mse: 0.22573 | valid_rmsle: 0.0138  | valid_mae: 0.38752 | valid_rmse: 0.47897 | valid_mse: 0.22941 |  0:01:01s\n",
      "epoch 34 | loss: 0.21618 | train_rmsle: 0.01404 | train_mae: 0.38274 | train_rmse: 0.47793 | train_mse: 0.22841 | valid_rmsle: 0.01378 | valid_mae: 0.3876  | valid_rmse: 0.47772 | valid_mse: 0.22821 |  0:01:03s\n",
      "epoch 35 | loss: 0.21556 | train_rmsle: 0.01392 | train_mae: 0.38258 | train_rmse: 0.47613 | train_mse: 0.2267  | valid_rmsle: 0.01392 | valid_mae: 0.39405 | valid_rmse: 0.48227 | valid_mse: 0.23259 |  0:01:04s\n",
      "epoch 36 | loss: 0.21886 | train_rmsle: 0.01391 | train_mae: 0.36714 | train_rmse: 0.46983 | train_mse: 0.22074 | valid_rmsle: 0.014   | valid_mae: 0.37926 | valid_rmse: 0.47771 | valid_mse: 0.2282  |  0:01:06s\n",
      "epoch 37 | loss: 0.22168 | train_rmsle: 0.01367 | train_mae: 0.37079 | train_rmse: 0.46857 | train_mse: 0.21956 | valid_rmsle: 0.01418 | valid_mae: 0.38919 | valid_rmse: 0.48363 | valid_mse: 0.2339  |  0:01:08s\n",
      "epoch 38 | loss: 0.23037 | train_rmsle: 0.01375 | train_mae: 0.37073 | train_rmse: 0.4694  | train_mse: 0.22034 | valid_rmsle: 0.01374 | valid_mae: 0.38171 | valid_rmse: 0.47571 | valid_mse: 0.2263  |  0:01:10s\n",
      "epoch 39 | loss: 0.22822 | train_rmsle: 0.01366 | train_mae: 0.36694 | train_rmse: 0.46655 | train_mse: 0.21766 | valid_rmsle: 0.01355 | valid_mae: 0.37608 | valid_rmse: 0.47081 | valid_mse: 0.22166 |  0:01:12s\n",
      "epoch 40 | loss: 0.21409 | train_rmsle: 0.0138  | train_mae: 0.36894 | train_rmse: 0.46938 | train_mse: 0.22031 | valid_rmsle: 0.01377 | valid_mae: 0.3791  | valid_rmse: 0.4751  | valid_mse: 0.22572 |  0:01:13s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2203773859618822 RMSE: 0.4694436983940483 R2: 0.024474227847009367 MAE: 0.37100764777734585\n",
      "=====================================\n",
      "[108/108] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.005 max_epochs: 210\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 5.22243 | train_rmsle: 0.16573 | train_mae: 1.39283 | train_rmse: 1.4777  | train_mse: 2.1836  | valid_rmsle: 0.16703 | valid_mae: 1.39825 | valid_rmse: 1.48408 | valid_mse: 2.20248 |  0:00:01s\n",
      "epoch 1  | loss: 2.25295 | train_rmsle: 0.04925 | train_mae: 0.79874 | train_rmse: 0.8922  | train_mse: 0.79602 | valid_rmsle: 0.04941 | valid_mae: 0.79997 | valid_rmse: 0.89576 | valid_mse: 0.80238 |  0:00:03s\n",
      "epoch 2  | loss: 1.32941 | train_rmsle: 0.03035 | train_mae: 0.62491 | train_rmse: 0.71698 | train_mse: 0.51407 | valid_rmsle: 0.03034 | valid_mae: 0.62593 | valid_rmse: 0.71997 | valid_mse: 0.51835 |  0:00:05s\n",
      "epoch 3  | loss: 0.83871 | train_rmsle: 0.03217 | train_mae: 0.64443 | train_rmse: 0.7367  | train_mse: 0.54272 | valid_rmsle: 0.03213 | valid_mae: 0.64444 | valid_rmse: 0.73922 | valid_mse: 0.54644 |  0:00:07s\n",
      "epoch 4  | loss: 0.59306 | train_rmsle: 0.02993 | train_mae: 0.62041 | train_rmse: 0.71227 | train_mse: 0.50732 | valid_rmsle: 0.02984 | valid_mae: 0.62083 | valid_rmse: 0.71437 | valid_mse: 0.51033 |  0:00:09s\n",
      "epoch 5  | loss: 0.46346 | train_rmsle: 0.02439 | train_mae: 0.55567 | train_rmse: 0.64597 | train_mse: 0.41728 | valid_rmsle: 0.02425 | valid_mae: 0.55757 | valid_rmse: 0.6478  | valid_mse: 0.41965 |  0:00:10s\n",
      "epoch 6  | loss: 0.36522 | train_rmsle: 0.02349 | train_mae: 0.54451 | train_rmse: 0.6342  | train_mse: 0.40221 | valid_rmsle: 0.02341 | valid_mae: 0.54682 | valid_rmse: 0.63694 | valid_mse: 0.40569 |  0:00:12s\n",
      "epoch 7  | loss: 0.31624 | train_rmsle: 0.01775 | train_mae: 0.46013 | train_rmse: 0.54817 | train_mse: 0.30049 | valid_rmsle: 0.01742 | valid_mae: 0.46241 | valid_rmse: 0.54793 | valid_mse: 0.30022 |  0:00:14s\n",
      "epoch 8  | loss: 0.29118 | train_rmsle: 0.01709 | train_mae: 0.4493  | train_rmse: 0.53746 | train_mse: 0.28887 | valid_rmsle: 0.0168  | valid_mae: 0.45149 | valid_rmse: 0.53789 | valid_mse: 0.28932 |  0:00:16s\n",
      "epoch 9  | loss: 0.29033 | train_rmsle: 0.02427 | train_mae: 0.55439 | train_rmse: 0.64467 | train_mse: 0.4156  | valid_rmsle: 0.02422 | valid_mae: 0.55684 | valid_rmse: 0.64769 | valid_mse: 0.4195  |  0:00:18s\n",
      "epoch 10 | loss: 0.26364 | train_rmsle: 0.0164  | train_mae: 0.43444 | train_rmse: 0.52532 | train_mse: 0.27596 | valid_rmsle: 0.01603 | valid_mae: 0.43537 | valid_rmse: 0.52446 | valid_mse: 0.27505 |  0:00:19s\n",
      "epoch 11 | loss: 0.25184 | train_rmsle: 0.0151  | train_mae: 0.40756 | train_rmse: 0.50056 | train_mse: 0.25056 | valid_rmsle: 0.01488 | valid_mae: 0.4115  | valid_rmse: 0.50245 | valid_mse: 0.25246 |  0:00:21s\n",
      "epoch 12 | loss: 0.26221 | train_rmsle: 0.0144  | train_mae: 0.3831  | train_rmse: 0.4817  | train_mse: 0.23204 | valid_rmsle: 0.01377 | valid_mae: 0.38573 | valid_rmse: 0.4765  | valid_mse: 0.22705 |  0:00:23s\n",
      "epoch 13 | loss: 0.25227 | train_rmsle: 0.0149  | train_mae: 0.4056  | train_rmse: 0.49715 | train_mse: 0.24716 | valid_rmsle: 0.01457 | valid_mae: 0.40762 | valid_rmse: 0.49681 | valid_mse: 0.24682 |  0:00:25s\n",
      "epoch 14 | loss: 0.24424 | train_rmsle: 0.01899 | train_mae: 0.47822 | train_rmse: 0.56951 | train_mse: 0.32435 | valid_rmsle: 0.01885 | valid_mae: 0.47702 | valid_rmse: 0.5717  | valid_mse: 0.32684 |  0:00:27s\n",
      "epoch 15 | loss: 0.24264 | train_rmsle: 0.01441 | train_mae: 0.39234 | train_rmse: 0.4854  | train_mse: 0.23562 | valid_rmsle: 0.01407 | valid_mae: 0.39594 | valid_rmse: 0.48518 | valid_mse: 0.2354  |  0:00:28s\n",
      "epoch 16 | loss: 0.23569 | train_rmsle: 0.01685 | train_mae: 0.44332 | train_rmse: 0.53393 | train_mse: 0.28508 | valid_rmsle: 0.0167  | valid_mae: 0.44539 | valid_rmse: 0.53608 | valid_mse: 0.28738 |  0:00:30s\n",
      "epoch 17 | loss: 0.23707 | train_rmsle: 0.01449 | train_mae: 0.3965  | train_rmse: 0.48847 | train_mse: 0.2386  | valid_rmsle: 0.01391 | valid_mae: 0.39341 | valid_rmse: 0.48312 | valid_mse: 0.23341 |  0:00:32s\n",
      "epoch 18 | loss: 0.23199 | train_rmsle: 0.0147  | train_mae: 0.40141 | train_rmse: 0.49289 | train_mse: 0.24294 | valid_rmsle: 0.01423 | valid_mae: 0.39941 | valid_rmse: 0.48971 | valid_mse: 0.23982 |  0:00:34s\n",
      "epoch 19 | loss: 0.2344  | train_rmsle: 0.01495 | train_mae: 0.40799 | train_rmse: 0.49875 | train_mse: 0.24876 | valid_rmsle: 0.01445 | valid_mae: 0.4067  | valid_rmse: 0.49525 | valid_mse: 0.24527 |  0:00:36s\n",
      "epoch 20 | loss: 0.23231 | train_rmsle: 0.01403 | train_mae: 0.37269 | train_rmse: 0.47226 | train_mse: 0.22303 | valid_rmsle: 0.01325 | valid_mae: 0.36869 | valid_rmse: 0.46352 | valid_mse: 0.21486 |  0:00:37s\n",
      "epoch 21 | loss: 0.24071 | train_rmsle: 0.01442 | train_mae: 0.39382 | train_rmse: 0.487   | train_mse: 0.23717 | valid_rmsle: 0.01383 | valid_mae: 0.39401 | valid_rmse: 0.48165 | valid_mse: 0.23199 |  0:00:39s\n",
      "epoch 22 | loss: 0.227   | train_rmsle: 0.01412 | train_mae: 0.38433 | train_rmse: 0.47906 | train_mse: 0.2295  | valid_rmsle: 0.01368 | valid_mae: 0.38917 | valid_rmse: 0.47746 | valid_mse: 0.22797 |  0:00:41s\n",
      "epoch 23 | loss: 0.24498 | train_rmsle: 0.01473 | train_mae: 0.40294 | train_rmse: 0.49401 | train_mse: 0.24404 | valid_rmsle: 0.01396 | valid_mae: 0.39726 | valid_rmse: 0.48543 | valid_mse: 0.23564 |  0:00:43s\n",
      "epoch 24 | loss: 0.28982 | train_rmsle: 0.01572 | train_mae: 0.42338 | train_rmse: 0.51367 | train_mse: 0.26386 | valid_rmsle: 0.01538 | valid_mae: 0.42377 | valid_rmse: 0.5128  | valid_mse: 0.26296 |  0:00:45s\n",
      "epoch 25 | loss: 0.22289 | train_rmsle: 0.01389 | train_mae: 0.38011 | train_rmse: 0.47425 | train_mse: 0.22491 | valid_rmsle: 0.01342 | valid_mae: 0.38261 | valid_rmse: 0.47168 | valid_mse: 0.22248 |  0:00:46s\n",
      "epoch 26 | loss: 0.22227 | train_rmsle: 0.01402 | train_mae: 0.38211 | train_rmse: 0.47706 | train_mse: 0.22759 | valid_rmsle: 0.0133  | valid_mae: 0.37965 | valid_rmse: 0.46947 | valid_mse: 0.2204  |  0:00:48s\n",
      "epoch 27 | loss: 0.22174 | train_rmsle: 0.01387 | train_mae: 0.37341 | train_rmse: 0.47121 | train_mse: 0.22204 | valid_rmsle: 0.01346 | valid_mae: 0.37562 | valid_rmse: 0.46929 | valid_mse: 0.22024 |  0:00:50s\n",
      "epoch 28 | loss: 0.22467 | train_rmsle: 0.01436 | train_mae: 0.37394 | train_rmse: 0.47824 | train_mse: 0.22872 | valid_rmsle: 0.01409 | valid_mae: 0.37892 | valid_rmse: 0.48019 | valid_mse: 0.23058 |  0:00:52s\n",
      "epoch 29 | loss: 0.24433 | train_rmsle: 0.0144  | train_mae: 0.37249 | train_rmse: 0.47759 | train_mse: 0.22809 | valid_rmsle: 0.01418 | valid_mae: 0.38034 | valid_rmse: 0.47966 | valid_mse: 0.23007 |  0:00:54s\n",
      "epoch 30 | loss: 0.24896 | train_rmsle: 0.01462 | train_mae: 0.40011 | train_rmse: 0.4921  | train_mse: 0.24216 | valid_rmsle: 0.01448 | valid_mae: 0.40658 | valid_rmse: 0.4946  | valid_mse: 0.24463 |  0:00:56s\n",
      "epoch 31 | loss: 0.23056 | train_rmsle: 0.01397 | train_mae: 0.38211 | train_rmse: 0.47658 | train_mse: 0.22713 | valid_rmsle: 0.01362 | valid_mae: 0.38531 | valid_rmse: 0.47618 | valid_mse: 0.22675 |  0:00:57s\n",
      "epoch 32 | loss: 0.22447 | train_rmsle: 0.01393 | train_mae: 0.37155 | train_rmse: 0.47131 | train_mse: 0.22213 | valid_rmsle: 0.01396 | valid_mae: 0.38306 | valid_rmse: 0.47822 | valid_mse: 0.22869 |  0:00:59s\n",
      "epoch 33 | loss: 0.21815 | train_rmsle: 0.01388 | train_mae: 0.38056 | train_rmse: 0.47511 | train_mse: 0.22573 | valid_rmsle: 0.0138  | valid_mae: 0.38752 | valid_rmse: 0.47897 | valid_mse: 0.22941 |  0:01:01s\n",
      "epoch 34 | loss: 0.21618 | train_rmsle: 0.01404 | train_mae: 0.38274 | train_rmse: 0.47793 | train_mse: 0.22841 | valid_rmsle: 0.01378 | valid_mae: 0.3876  | valid_rmse: 0.47772 | valid_mse: 0.22821 |  0:01:03s\n",
      "epoch 35 | loss: 0.21556 | train_rmsle: 0.01392 | train_mae: 0.38258 | train_rmse: 0.47613 | train_mse: 0.2267  | valid_rmsle: 0.01392 | valid_mae: 0.39405 | valid_rmse: 0.48227 | valid_mse: 0.23259 |  0:01:04s\n",
      "epoch 36 | loss: 0.21886 | train_rmsle: 0.01391 | train_mae: 0.36714 | train_rmse: 0.46983 | train_mse: 0.22074 | valid_rmsle: 0.014   | valid_mae: 0.37926 | valid_rmse: 0.47771 | valid_mse: 0.2282  |  0:01:06s\n",
      "epoch 37 | loss: 0.22168 | train_rmsle: 0.01367 | train_mae: 0.37079 | train_rmse: 0.46857 | train_mse: 0.21956 | valid_rmsle: 0.01418 | valid_mae: 0.38919 | valid_rmse: 0.48363 | valid_mse: 0.2339  |  0:01:08s\n",
      "epoch 38 | loss: 0.23037 | train_rmsle: 0.01375 | train_mae: 0.37073 | train_rmse: 0.4694  | train_mse: 0.22034 | valid_rmsle: 0.01374 | valid_mae: 0.38171 | valid_rmse: 0.47571 | valid_mse: 0.2263  |  0:01:10s\n",
      "epoch 39 | loss: 0.22822 | train_rmsle: 0.01366 | train_mae: 0.36694 | train_rmse: 0.46655 | train_mse: 0.21766 | valid_rmsle: 0.01355 | valid_mae: 0.37608 | valid_rmse: 0.47081 | valid_mse: 0.22166 |  0:01:12s\n",
      "epoch 40 | loss: 0.21409 | train_rmsle: 0.0138  | train_mae: 0.36894 | train_rmse: 0.46938 | train_mse: 0.22031 | valid_rmsle: 0.01377 | valid_mae: 0.3791  | valid_rmse: 0.4751  | valid_mse: 0.22572 |  0:01:13s\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2203773859618822 RMSE: 0.4694436983940483 R2: 0.024474227847009367 MAE: 0.37100764777734585\n",
      "=====================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model SCORE: 0.9640017844139963\n",
      "MSE: 0.00813222261181444 RMSE: 0.09017883682890593 R2: 0.9640017839939237 MAE: 0.06946583074375974\n",
      "=====================================\n",
      "(0.9640017839939237, TabNetRegressor(n_d=32, n_a=32, n_steps=5, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=42, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=1129, output_dim=1, device_name='auto', n_shared_decoder=1, n_indep_decoder=1))\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "batchsize = [512]\n",
    "width = [8,16,32]\n",
    "steps = [3,5,7]\n",
    "learning_rate = [2e-2,1e-2,5e-3]\n",
    "max_epochs = [70,120,150,210]\n",
    "\n",
    "best_model_params = None \n",
    "best_r2 = 0\n",
    "\n",
    "total_iterations = len(batchsize) * len(width) * len(steps) * len(learning_rate) * len(max_epochs)\n",
    "current_iteration = 0\n",
    "\n",
    "for batchsize,width,steps,learning_rate,max_epochs in itertools.product(batchsize,width,steps,learning_rate,max_epochs):\n",
    "    current_iteration += 1\n",
    "    print(f\"[{current_iteration}/{total_iterations}] START => batchsize: {batchsize} width: {width} steps: {steps} learning_rate: {learning_rate} max_epochs: {max_epochs}\")\n",
    "    model = TabNet(ratings, genome_scores,width_values = width, steps = steps, learning_rate = learning_rate)\n",
    "    model.train(max_epochs = max_epochs,batchsize = batchsize)\n",
    "    r2score, instance = model.test()\n",
    "    if r2score > best_r2:\n",
    "        best_r2 = r2score\n",
    "        best_model_params = f'{batchsize}_{width}_{steps}_{learning_rate}_{max_epochs}'\n",
    "        model.save(\"model\",best_model_params)\n",
    "        print(f\"New best model: {best_model_params} with r2: {best_r2}\")\n",
    "\n",
    "model = TabNet(ratings,genome_scores)\n",
    "print(f'Best model SCORE: {best_r2}')\n",
    "model.load(f\"model/{best_model_params}.pt.zip\")\n",
    "print(model.test())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20a32af23fa2dfa3c5d159e60107838eb3f09fc5f820c64a56f9f0f73009b4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
