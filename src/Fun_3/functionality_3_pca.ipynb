{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "from sklearn.decomposition import PCA\n",
    "import warnings\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "SEED = 1038893\n",
    "\n",
    "fix_random(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "root = \"../../data/ml-25m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Acquisition\n",
    "def get_data_from_csv(file: str, nrows=None):\n",
    "    if nrows:\n",
    "        df = pd.read_csv(f\"{root}/{file}\", nrows=nrows)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{root}/{file}\")\n",
    "    print(f\"Loaded ml-25m data: {root}/{file}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_from_csv(nrows=None):\n",
    "    path = \"ratings.csv\"\n",
    "\n",
    "    data = get_data_from_csv(path, nrows)\n",
    "    # data = get_data_from_csv(path)\n",
    "\n",
    "    data.drop(\"timestamp\", axis=1, inplace=True)\n",
    "    # todo: drop user id\n",
    "    #data.drop(\"userId\", axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ml-25m data: ../../data/ml-25m/ratings.csv\n",
      "          userId  movieId  rating\n",
      "0              1      296     5.0\n",
      "1              1      306     3.5\n",
      "2              1      307     5.0\n",
      "3              1      665     5.0\n",
      "4              1      899     3.5\n",
      "...          ...      ...     ...\n",
      "25000090  162541    50872     4.5\n",
      "25000091  162541    55768     2.5\n",
      "25000092  162541    56176     2.0\n",
      "25000093  162541    58559     4.0\n",
      "25000094  162541    63876     5.0\n",
      "\n",
      "[25000095 rows x 3 columns]\n",
      "Loaded ml-25m data: ../../data/ml-25m/genome-scores.csv\n",
      "          movieId  tagId  relevance\n",
      "0               1      1    0.02875\n",
      "1               1      2    0.02375\n",
      "2               1      3    0.06250\n",
      "3               1      4    0.07575\n",
      "4               1      5    0.14075\n",
      "...           ...    ...        ...\n",
      "15584443   206499   1124    0.11000\n",
      "15584444   206499   1125    0.04850\n",
      "15584445   206499   1126    0.01325\n",
      "15584446   206499   1127    0.14025\n",
      "15584447   206499   1128    0.03350\n",
      "\n",
      "[15584448 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_tag_relevances_from_csv(nrows=None):\n",
    "    path = \"genome-scores.csv\"\n",
    "\n",
    "    return get_data_from_csv(path, nrows)\n",
    "genome_scores_path = \"genome-scores.csv\"\n",
    "ratings_path = \"ratings.csv\"\n",
    "ratings = get_ratings_from_csv()\n",
    "print(ratings)\n",
    "genome_scores = get_tag_relevances_from_csv()\n",
    "print(genome_scores)\n",
    "# films = get_data_from_csv(f\"{root}/{ratings}\")[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "           \n",
    "\n",
    "class TabNet:\n",
    "    def __init__(self, ratings, relevance, seed=42,width_values = 8, steps = 3, learning_rate = 2e-2):\n",
    "        self.aug = RegressionSMOTE(p=0.2)\n",
    "        #! df['rating'] = df['rating'].astype('float16')\n",
    "\n",
    "        # Reduce genome-score size\n",
    "\n",
    "\n",
    "        self.train_loss_history = []\n",
    "        self.val_loss_history = []\n",
    "\n",
    "        # Pivot the relevance DataFrame to create a matrix of tag relevance scores for each movie\n",
    "        relevance_matrix = relevance.pivot_table(index='movieId', columns='tagId', values='relevance', fill_value=0)\n",
    "        # Merge the ratings and relevance data\n",
    "        mean_ratings = ratings.groupby('movieId', as_index=False)['rating'].mean()\n",
    "        X = mean_ratings.merge(relevance_matrix, on='movieId')\n",
    "        #X = addColumnOperation(ratings,X)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        ratings = None  \n",
    "        train = X\n",
    "        # mescolare le righe del DataFrame\n",
    "        X = X.sample(frac=1,random_state = seed).reset_index(drop=True)\n",
    "        \n",
    "        if \"Set\" not in train.columns:\n",
    "            train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "\n",
    "        features = [ col for col in train.columns if col not in [\"rating\", \"Set\"]]\n",
    "        target = \"rating\"\n",
    "        \n",
    "        train_indices = train[train.Set==\"train\"].index\n",
    "        valid_indices = train[train.Set==\"valid\"].index\n",
    "        test_indices = train[train.Set==\"test\"].index\n",
    "\n",
    "        self.X_train = train[features].values[train_indices]\n",
    "        self.y_train = train[target].values[train_indices].reshape(-1, 1)\n",
    "\n",
    "        self.X_valid = train[features].values[valid_indices]\n",
    "        self.y_valid = train[target].values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "        self.X_test = train[features].values[test_indices]\n",
    "        self.y_test = train[target].values[test_indices].reshape(-1, 1)\n",
    "\n",
    "        pca = PCA()\n",
    "        pca.fit(self.X_train)\n",
    "        self.X_train = pca.transform(self.X_train)\n",
    "        self.X_test = pca.transform(self.X_test)\n",
    "        self.X_valid = pca.transform(self.X_valid)\n",
    "        \n",
    "        if torch.cuda.is_available():\n",
    "            self.model = TabNetRegressor(n_d = width_values, \n",
    "                                         n_a = width_values , \n",
    "                                         n_steps = steps, \n",
    "                                         optimizer_params = \n",
    "                                         dict(lr=learning_rate), \n",
    "                                         seed=seed,  \n",
    "                                         verbose=0, \n",
    "                                         device_name=\"cuda\")  \n",
    "        else:\n",
    "            self.model = TabNetRegressor(n_d = width_values, n_a = width_values , n_steps = steps, optimizer_params = dict(lr=learning_rate), seed=seed, verbose=0)  \n",
    "\n",
    "\n",
    "\n",
    "    def train(self,max_epochs = 150,batchsize = 1024):\n",
    "        self.model.fit(\n",
    "            X_train=self.X_train, y_train=self.y_train,\n",
    "            eval_set=[(self.X_train,self.y_train), (self.X_valid, self.y_valid)],\n",
    "            eval_name=['train', 'valid'],\n",
    "            eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "            max_epochs=max_epochs,\n",
    "            patience=20,\n",
    "            batch_size=batchsize, virtual_batch_size=1024,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            augmentations=self.aug, #aug,\n",
    "        ) \n",
    "\n",
    "        return self.model.history\n",
    "\n",
    "    def test(self):\n",
    "        # Predict the labels of the test set: y_pred\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "        # Compute the mean squared error\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        rmse = mean_squared_error(self.y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(self.y_test, y_pred)\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "\n",
    "        print(f\"MSE: {mse} RMSE: {rmse} R2: {r2} MAE: {mae}\")\n",
    "        print(\"=====================================\")\n",
    "        return r2,self.model\n",
    "    \n",
    "    def load(self,model):\n",
    "        self.model =TabNetRegressor()\n",
    "        self.model.load_model(model)\n",
    "    \n",
    "    def save(self,root,name):\n",
    "        self.model.save_model(f\"{root}/{name}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TabNet(ratings, genome_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/216] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.05191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05210912650785237 RMSE: 0.2282742353132573 R2: 0.7693329755640941 MAE: 0.17691617550273947\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_70.pt.zip\n",
      "New best model: 512_8_3_0.02_70 with r2: 0.7693329755640941\n",
      "[2/216] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 118 and best_valid_mse = 0.02282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.02384098172684262 RMSE: 0.15440525161678478 R2: 0.8944651602683669 MAE: 0.11771430175260135\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_120.pt.zip\n",
      "New best model: 512_8_3_0.02_120 with r2: 0.8944651602683669\n",
      "[3/216] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 142 and best_valid_mse = 0.01425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.015865488916844934 RMSE: 0.12595828244639148 R2: 0.9297695938327043 MAE: 0.09470088260495114\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_150.pt.zip\n",
      "New best model: 512_8_3_0.02_150 with r2: 0.9297695938327043\n",
      "[4/216] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 199 and best_valid_mse = 0.0112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.012942815630610546 RMSE: 0.11376649608127407 R2: 0.9427071423105589 MAE: 0.08609831465050595\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_210.pt.zip\n",
      "New best model: 512_8_3_0.02_210 with r2: 0.9427071423105589\n",
      "[5/216] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 65 and best_valid_mse = 0.07394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07854032854505065 RMSE: 0.28025047465624503 R2: 0.6523322285785147 MAE: 0.22052411475059883\n",
      "=====================================\n",
      "[6/216] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 117 and best_valid_mse = 0.03801\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03875474164334836 RMSE: 0.196862240268032 R2: 0.828447691666711 MAE: 0.15017869878228784\n",
      "=====================================\n",
      "[7/216] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 147 and best_valid_mse = 0.02183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.022916702590764233 RMSE: 0.15138263635821722 R2: 0.8985565878618665 MAE: 0.10926680744976741\n",
      "=====================================\n",
      "[8/216] START => batchsize: 512 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 205 and best_valid_mse = 0.01412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01380257811330343 RMSE: 0.1174843739111863 R2: 0.938901305082132 MAE: 0.08338525869056392\n",
      "=====================================\n",
      "[9/216] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.09252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09989644712509797 RMSE: 0.31606399213624126 R2: 0.5577969205338182 MAE: 0.24058353504254723\n",
      "=====================================\n",
      "[10/216] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.09252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09989644712509797 RMSE: 0.31606399213624126 R2: 0.5577969205338182 MAE: 0.24058353504254723\n",
      "=====================================\n",
      "[11/216] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.09252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09989644712509797 RMSE: 0.31606399213624126 R2: 0.5577969205338182 MAE: 0.24058353504254723\n",
      "=====================================\n",
      "[12/216] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.09252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09989644712509797 RMSE: 0.31606399213624126 R2: 0.5577969205338182 MAE: 0.24058353504254723\n",
      "=====================================\n",
      "[13/216] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.16164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1664952632366941 RMSE: 0.40803831099137505 R2: 0.26298962336868503 MAE: 0.32375105058541354\n",
      "=====================================\n",
      "[14/216] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 117 and best_valid_mse = 0.02375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.023125964946856405 RMSE: 0.15207223595007868 R2: 0.8976302640441193 MAE: 0.11689933836019716\n",
      "=====================================\n",
      "[15/216] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 145 and best_valid_mse = 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.016600589654245802 RMSE: 0.12884327554919506 R2: 0.9265155861161991 MAE: 0.0986151309788559\n",
      "=====================================\n",
      "[16/216] START => batchsize: 512 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 203 and best_valid_mse = 0.00851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009798249498806961 RMSE: 0.09898610760509255 R2: 0.9566269249163133 MAE: 0.07300380915554663\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_5_0.01_210.pt.zip\n",
      "New best model: 512_8_5_0.01_210 with r2: 0.9566269249163133\n",
      "[17/216] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_valid_mse = 0.02832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.035824932902846975 RMSE: 0.189274755059535 R2: 0.8414168260511824 MAE: 0.14122447899747048\n",
      "=====================================\n",
      "[18/216] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 107 and best_valid_mse = 0.00834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009675581572380524 RMSE: 0.09836453411865745 R2: 0.9571699285603725 MAE: 0.07256054381110555\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_7_0.02_120.pt.zip\n",
      "New best model: 512_8_7_0.02_120 with r2: 0.9571699285603725\n",
      "[19/216] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 127 with best_epoch = 107 and best_valid_mse = 0.00834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009675581572380524 RMSE: 0.09836453411865745 R2: 0.9571699285603725 MAE: 0.07256054381110555\n",
      "=====================================\n",
      "[20/216] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 127 with best_epoch = 107 and best_valid_mse = 0.00834\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009675581572380524 RMSE: 0.09836453411865745 R2: 0.9571699285603725 MAE: 0.07256054381110555\n",
      "=====================================\n",
      "[21/216] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.20794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.20691839603897613 RMSE: 0.45488283770546467 R2: 0.08405199023690002 MAE: 0.3573555169726746\n",
      "=====================================\n",
      "[22/216] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 118 and best_valid_mse = 0.03771\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.039037339211154036 RMSE: 0.1975786911869649 R2: 0.8271967411241272 MAE: 0.15303754941900286\n",
      "=====================================\n",
      "[23/216] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 148 and best_valid_mse = 0.01633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.017808923451232778 RMSE: 0.1334500784984137 R2: 0.9211667579903943 MAE: 0.10183888326349934\n",
      "=====================================\n",
      "[24/216] START => batchsize: 512 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 209 and best_valid_mse = 0.00751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008448922782351981 RMSE: 0.0919180220759345 R2: 0.9625998743694123 MAE: 0.06885722591817509\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_7_0.01_210.pt.zip\n",
      "New best model: 512_8_7_0.01_210 with r2: 0.9625998743694123\n",
      "[25/216] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 66 and best_valid_mse = 0.00971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010701015286653378 RMSE: 0.1034457117847491 R2: 0.9526307286259439 MAE: 0.07624393800015498\n",
      "=====================================\n",
      "[26/216] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 109 and best_valid_mse = 0.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008290198305983244 RMSE: 0.0910505261159058 R2: 0.9633024864668077 MAE: 0.06962713662719916\n",
      "=====================================\n",
      "Successfully saved model at model/512_16_3_0.02_120.pt.zip\n",
      "New best model: 512_16_3_0.02_120 with r2: 0.9633024864668077\n",
      "[27/216] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 129 with best_epoch = 109 and best_valid_mse = 0.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008290198305983244 RMSE: 0.0910505261159058 R2: 0.9633024864668077 MAE: 0.06962713662719916\n",
      "=====================================\n",
      "[28/216] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 129 with best_epoch = 109 and best_valid_mse = 0.00823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.008290198305983244 RMSE: 0.0910505261159058 R2: 0.9633024864668077 MAE: 0.06962713662719916\n",
      "=====================================\n",
      "[29/216] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_valid_mse = 0.09093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10023314423349099 RMSE: 0.3165961848056464 R2: 0.5563064921706122 MAE: 0.242297519581371\n",
      "=====================================\n",
      "[30/216] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_valid_mse = 0.09093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10023314423349099 RMSE: 0.3165961848056464 R2: 0.5563064921706122 MAE: 0.242297519581371\n",
      "=====================================\n",
      "[31/216] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_valid_mse = 0.09093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10023314423349099 RMSE: 0.3165961848056464 R2: 0.5563064921706122 MAE: 0.242297519581371\n",
      "=====================================\n",
      "[32/216] START => batchsize: 512 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 48 with best_epoch = 28 and best_valid_mse = 0.09093\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10023314423349099 RMSE: 0.3165961848056464 R2: 0.5563064921706122 MAE: 0.242297519581371\n",
      "=====================================\n",
      "[33/216] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 66 and best_valid_mse = 0.02854\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.028448336167221415 RMSE: 0.16866634568645109 R2: 0.8740701774600562 MAE: 0.1313403816019833\n",
      "=====================================\n",
      "[34/216] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 113 and best_valid_mse = 0.01027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011874775249514729 RMSE: 0.10897144235768713 R2: 0.9474349455418727 MAE: 0.08537998864179489\n",
      "=====================================\n",
      "[35/216] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 133 with best_epoch = 113 and best_valid_mse = 0.01027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011874775249514729 RMSE: 0.10897144235768713 R2: 0.9474349455418727 MAE: 0.08537998864179489\n",
      "=====================================\n",
      "[36/216] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 133 with best_epoch = 113 and best_valid_mse = 0.01027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011874775249514729 RMSE: 0.10897144235768713 R2: 0.9474349455418727 MAE: 0.08537998864179489\n",
      "=====================================\n",
      "[37/216] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.06196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06275836458603642 RMSE: 0.25051619625492566 R2: 0.7221929019412114 MAE: 0.1948923778658883\n",
      "=====================================\n",
      "[38/216] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 119 and best_valid_mse = 0.01732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.018691792940581004 RMSE: 0.13671793203739224 R2: 0.917258634947063 MAE: 0.10235999678271215\n",
      "=====================================\n",
      "[39/216] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 146 and best_valid_mse = 0.01226\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.013513631990254989 RMSE: 0.11624814833043574 R2: 0.9401803582325591 MAE: 0.08634444351863413\n",
      "=====================================\n",
      "[40/216] START => batchsize: 512 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 197 and best_valid_mse = 0.0096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010340481997878953 RMSE: 0.10168816055902945 R2: 0.9542266705751753 MAE: 0.07635853459846426\n",
      "=====================================\n",
      "[41/216] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 63 and best_valid_mse = 0.02853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.030015762877159555 RMSE: 0.17325057828809565 R2: 0.8671317833737859 MAE: 0.1355415289258456\n",
      "=====================================\n",
      "[42/216] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 115 and best_valid_mse = 0.01031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0107312294857083 RMSE: 0.1035916477603687 R2: 0.9524969820088199 MAE: 0.08327417851273673\n",
      "=====================================\n",
      "[43/216] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 135 with best_epoch = 115 and best_valid_mse = 0.01031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0107312294857083 RMSE: 0.1035916477603687 R2: 0.9524969820088199 MAE: 0.08327417851273673\n",
      "=====================================\n",
      "[44/216] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 135 with best_epoch = 115 and best_valid_mse = 0.01031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0107312294857083 RMSE: 0.1035916477603687 R2: 0.9524969820088199 MAE: 0.08327417851273673\n",
      "=====================================\n",
      "[45/216] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.20966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1995461369318657 RMSE: 0.4467058729543028 R2: 0.11668614063570615 MAE: 0.34963977839925064\n",
      "=====================================\n",
      "[46/216] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 118 and best_valid_mse = 0.03609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.04063724315144155 RMSE: 0.20158681294033484 R2: 0.8201145828531804 MAE: 0.15241730387870076\n",
      "=====================================\n",
      "[47/216] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 149 and best_valid_mse = 0.01852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.02505011712241674 RMSE: 0.15827228791679465 R2: 0.8891127837744875 MAE: 0.10555471970798974\n",
      "=====================================\n",
      "[48/216] START => batchsize: 512 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 208 and best_valid_mse = 0.01058\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010654781508760477 RMSE: 0.1032220010887237 R2: 0.9528353877459423 MAE: 0.08117098887953542\n",
      "=====================================\n",
      "[49/216] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 61 and best_valid_mse = 0.01542\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.017341279710729244 RMSE: 0.13168629279742536 R2: 0.9232368366377838 MAE: 0.10229790689064952\n",
      "=====================================\n",
      "[50/216] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 114 and best_valid_mse = 0.01014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010907166719125323 RMSE: 0.10443738180903102 R2: 0.9517181756683668 MAE: 0.07995015796559761\n",
      "=====================================\n",
      "[51/216] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 134 with best_epoch = 114 and best_valid_mse = 0.01014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010907166719125323 RMSE: 0.10443738180903102 R2: 0.9517181756683668 MAE: 0.07995015796559761\n",
      "=====================================\n",
      "[52/216] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 134 with best_epoch = 114 and best_valid_mse = 0.01014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010907166719125323 RMSE: 0.10443738180903102 R2: 0.9517181756683668 MAE: 0.07995015796559761\n",
      "=====================================\n",
      "[53/216] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 64 and best_valid_mse = 0.05802\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0542677105884393 RMSE: 0.23295431008770648 R2: 0.7597777555818771 MAE: 0.18186037610294573\n",
      "=====================================\n",
      "[54/216] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 113 and best_valid_mse = 0.0433\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.04085158703270006 RMSE: 0.20211775536231363 R2: 0.8191657650815278 MAE: 0.15029100776430881\n",
      "=====================================\n",
      "[55/216] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 145 and best_valid_mse = 0.03818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.036993032429804146 RMSE: 0.19233572842767446 R2: 0.8362460995357879 MAE: 0.14363219333618701\n",
      "=====================================\n",
      "[56/216] START => batchsize: 512 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 206 and best_valid_mse = 0.02556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.025584852481464478 RMSE: 0.15995265700032768 R2: 0.8867457163834496 MAE: 0.11777180921829519\n",
      "=====================================\n",
      "[57/216] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.01186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.012376599846692234 RMSE: 0.11125016785017555 R2: 0.9452135614125065 MAE: 0.08636304932218111\n",
      "=====================================\n",
      "[58/216] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 115 and best_valid_mse = 0.00836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009388781884160823 RMSE: 0.09689572686223487 R2: 0.9584394802708741 MAE: 0.07628762708723359\n",
      "=====================================\n",
      "[59/216] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 138 and best_valid_mse = 0.00742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00813222251691739 RMSE: 0.09017883630274562 R2: 0.9640017844139963 MAE: 0.06946582838404507\n",
      "=====================================\n",
      "Successfully saved model at model/512_32_5_0.02_150.pt.zip\n",
      "New best model: 512_32_5_0.02_150 with r2: 0.9640017844139963\n",
      "[60/216] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 158 with best_epoch = 138 and best_valid_mse = 0.00742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00813222251691739 RMSE: 0.09017883630274562 R2: 0.9640017844139963 MAE: 0.06946582838404507\n",
      "=====================================\n",
      "[61/216] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_valid_mse = 0.08928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09537912148620106 RMSE: 0.3088351040380628 R2: 0.577793380527738 MAE: 0.2367579958957963\n",
      "=====================================\n",
      "[62/216] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_valid_mse = 0.08928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09537912148620106 RMSE: 0.3088351040380628 R2: 0.577793380527738 MAE: 0.2367579958957963\n",
      "=====================================\n",
      "[63/216] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_valid_mse = 0.08928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09537912148620106 RMSE: 0.3088351040380628 R2: 0.577793380527738 MAE: 0.2367579958957963\n",
      "=====================================\n",
      "[64/216] START => batchsize: 512 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 51 with best_epoch = 31 and best_valid_mse = 0.08928\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09537912148620106 RMSE: 0.3088351040380628 R2: 0.577793380527738 MAE: 0.2367579958957963\n",
      "=====================================\n",
      "[65/216] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.05562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05967626745017631 RMSE: 0.24428726419970467 R2: 0.7358361583723887 MAE: 0.1901702966763154\n",
      "=====================================\n",
      "[66/216] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 112 and best_valid_mse = 0.0171\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.015913919553862673 RMSE: 0.12615038467584105 R2: 0.9295552100638508 MAE: 0.0963740532898696\n",
      "=====================================\n",
      "[67/216] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 148 and best_valid_mse = 0.01236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.013309108065665773 RMSE: 0.11536510766113718 R2: 0.9410857068398484 MAE: 0.08573269865782535\n",
      "=====================================\n",
      "[68/216] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 191 and best_valid_mse = 0.01124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011987057728233346 RMSE: 0.10948542244624782 R2: 0.94693791427311 MAE: 0.0841061363180608\n",
      "=====================================\n",
      "[69/216] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21832310813868422 RMSE: 0.46725058388265733 R2: 0.03356772421890386 MAE: 0.3709519909239511\n",
      "=====================================\n",
      "[70/216] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21832310813868422 RMSE: 0.46725058388265733 R2: 0.03356772421890386 MAE: 0.3709519909239511\n",
      "=====================================\n",
      "[71/216] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21832310813868422 RMSE: 0.46725058388265733 R2: 0.03356772421890386 MAE: 0.3709519909239511\n",
      "=====================================\n",
      "[72/216] START => batchsize: 512 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 40 with best_epoch = 20 and best_valid_mse = 0.21717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21832310813868422 RMSE: 0.46725058388265733 R2: 0.03356772421890386 MAE: 0.3709519909239511\n",
      "=====================================\n",
      "[73/216] START => batchsize: 1024 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.02182\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0223099429577666 RMSE: 0.1493651330055532 R2: 0.9012424789613901 MAE: 0.11360842881739389\n",
      "=====================================\n",
      "[74/216] START => batchsize: 1024 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 118 and best_valid_mse = 0.01245\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.013047163107545525 RMSE: 0.11422417917212417 R2: 0.9422452362371888 MAE: 0.08623806978359895\n",
      "=====================================\n",
      "[75/216] START => batchsize: 1024 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 146 and best_valid_mse = 0.00992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011027691573742912 RMSE: 0.10501281623565245 R2: 0.95118465857744 MAE: 0.07859185592705302\n",
      "=====================================\n",
      "[76/216] START => batchsize: 1024 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 186 with best_epoch = 166 and best_valid_mse = 0.00956\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.010727828047601732 RMSE: 0.10357522892855092 R2: 0.9525120388646804 MAE: 0.07771554456613648\n",
      "=====================================\n",
      "[77/216] START => batchsize: 1024 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.20309\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2116870343182908 RMSE: 0.4600945927940154 R2: 0.06294306601927924 MAE: 0.35313234159104245\n",
      "=====================================\n",
      "[78/216] START => batchsize: 1024 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 119 and best_valid_mse = 0.08497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09420226672966218 RMSE: 0.30692387774440455 R2: 0.5830028630709382 MAE: 0.24087050972204446\n",
      "=====================================\n",
      "[79/216] START => batchsize: 1024 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 148 and best_valid_mse = 0.04322\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.04405883930417188 RMSE: 0.2099019754651487 R2: 0.8049684950895961 MAE: 0.16103101661908847\n",
      "=====================================\n",
      "[80/216] START => batchsize: 1024 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 204 and best_valid_mse = 0.02477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0244965918055686 RMSE: 0.15651387096857775 R2: 0.8915630270685881 MAE: 0.11851684554194429\n",
      "=====================================\n",
      "[81/216] START => batchsize: 1024 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.0546\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05586730613673228 RMSE: 0.23636265808441967 R2: 0.7526969624434608 MAE: 0.18431591717241166\n",
      "=====================================\n",
      "[82/216] START => batchsize: 1024 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 117 and best_valid_mse = 0.0224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.022342384644401758 RMSE: 0.14947369214815615 R2: 0.9010988721150407 MAE: 0.11742127489201577\n",
      "=====================================\n",
      "[83/216] START => batchsize: 1024 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 149 and best_valid_mse = 0.01869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.017163214546964553 RMSE: 0.13100845219666002 R2: 0.924025062505955 MAE: 0.09933409126140182\n",
      "=====================================\n",
      "[84/216] START => batchsize: 1024 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 204 and best_valid_mse = 0.01451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.014552108148692018 RMSE: 0.12063211905911302 R2: 0.9355834244233117 MAE: 0.09037869831769096\n",
      "=====================================\n",
      "[85/216] START => batchsize: 1024 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 58 and best_valid_mse = 0.20868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2051060166765688 RMSE: 0.45288631760803816 R2: 0.09207469533084456 MAE: 0.3565722669672212\n",
      "=====================================\n",
      "[86/216] START => batchsize: 1024 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 119 and best_valid_mse = 0.09959\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09455673701757104 RMSE: 0.3075007918974698 R2: 0.5814337596903518 MAE: 0.23588740784971968\n",
      "=====================================\n",
      "[87/216] START => batchsize: 1024 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 147 and best_valid_mse = 0.0443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.04332936610809983 RMSE: 0.2081570707617203 R2: 0.8081975918490348 MAE: 0.1608315482631943\n",
      "=====================================\n",
      "[88/216] START => batchsize: 1024 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 207 and best_valid_mse = 0.0179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.018045831587405657 RMSE: 0.13433477430436863 R2: 0.9201180569566623 MAE: 0.10245954228154454\n",
      "=====================================\n",
      "[89/216] START => batchsize: 1024 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 60 and best_valid_mse = 0.09371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09943816136335906 RMSE: 0.3153381698484328 R2: 0.5598255750150198 MAE: 0.24222364091522414\n",
      "=====================================\n",
      "[90/216] START => batchsize: 1024 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 60 and best_valid_mse = 0.09371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09943816136335906 RMSE: 0.3153381698484328 R2: 0.5598255750150198 MAE: 0.24222364091522414\n",
      "=====================================\n",
      "[91/216] START => batchsize: 1024 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 60 and best_valid_mse = 0.09371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09943816136335906 RMSE: 0.3153381698484328 R2: 0.5598255750150198 MAE: 0.24222364091522414\n",
      "=====================================\n",
      "[92/216] START => batchsize: 1024 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 80 with best_epoch = 60 and best_valid_mse = 0.09371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09943816136335906 RMSE: 0.3153381698484328 R2: 0.5598255750150198 MAE: 0.24222364091522414\n",
      "=====================================\n",
      "[93/216] START => batchsize: 1024 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_valid_mse = 0.21987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21999014544754952 RMSE: 0.4690310708764927 R2: 0.026188392392996973 MAE: 0.37225616861648375\n",
      "=====================================\n",
      "[94/216] START => batchsize: 1024 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 101 with best_epoch = 81 and best_valid_mse = 0.21457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21635198989058654 RMSE: 0.46513652822648377 R2: 0.04229310519475826 MAE: 0.3655234318508805\n",
      "=====================================\n",
      "[95/216] START => batchsize: 1024 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 101 with best_epoch = 81 and best_valid_mse = 0.21457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21635198989058654 RMSE: 0.46513652822648377 R2: 0.04229310519475826 MAE: 0.3655234318508805\n",
      "=====================================\n",
      "[96/216] START => batchsize: 1024 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 101 with best_epoch = 81 and best_valid_mse = 0.21457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21635198989058654 RMSE: 0.46513652822648377 R2: 0.04229310519475826 MAE: 0.3655234318508805\n",
      "=====================================\n",
      "[97/216] START => batchsize: 1024 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 44 and best_valid_mse = 0.06364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06513492156367334 RMSE: 0.25521544146793573 R2: 0.7116727999327602 MAE: 0.1950470111726402\n",
      "=====================================\n",
      "[98/216] START => batchsize: 1024 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 44 and best_valid_mse = 0.06364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06513492156367334 RMSE: 0.25521544146793573 R2: 0.7116727999327602 MAE: 0.1950470111726402\n",
      "=====================================\n",
      "[99/216] START => batchsize: 1024 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 44 and best_valid_mse = 0.06364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06513492156367334 RMSE: 0.25521544146793573 R2: 0.7116727999327602 MAE: 0.1950470111726402\n",
      "=====================================\n",
      "[100/216] START => batchsize: 1024 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 64 with best_epoch = 44 and best_valid_mse = 0.06364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06513492156367334 RMSE: 0.25521544146793573 R2: 0.7116727999327602 MAE: 0.1950470111726402\n",
      "=====================================\n",
      "[101/216] START => batchsize: 1024 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_valid_mse = 0.06929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07097050575558761 RMSE: 0.26640290117712234 R2: 0.6858409172741393 MAE: 0.20505016686156224\n",
      "=====================================\n",
      "[102/216] START => batchsize: 1024 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_valid_mse = 0.06929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07097050575558761 RMSE: 0.26640290117712234 R2: 0.6858409172741393 MAE: 0.20505016686156224\n",
      "=====================================\n",
      "[103/216] START => batchsize: 1024 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_valid_mse = 0.06929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07097050575558761 RMSE: 0.26640290117712234 R2: 0.6858409172741393 MAE: 0.20505016686156224\n",
      "=====================================\n",
      "[104/216] START => batchsize: 1024 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 67 with best_epoch = 47 and best_valid_mse = 0.06929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07097050575558761 RMSE: 0.26640290117712234 R2: 0.6858409172741393 MAE: 0.20505016686156224\n",
      "=====================================\n",
      "[105/216] START => batchsize: 1024 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.09355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10056096503979305 RMSE: 0.3171134892113438 R2: 0.554855355776559 MAE: 0.24645879149828695\n",
      "=====================================\n",
      "[106/216] START => batchsize: 1024 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 108 and best_valid_mse = 0.03027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.033154034408658946 RMSE: 0.1820824934161957 R2: 0.8532398645381518 MAE: 0.1376549352231359\n",
      "=====================================\n",
      "[107/216] START => batchsize: 1024 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 145 and best_valid_mse = 0.01344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.016909383412407945 RMSE: 0.13003608503953026 R2: 0.9251486751327861 MAE: 0.09784689790585568\n",
      "=====================================\n",
      "[108/216] START => batchsize: 1024 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 191 with best_epoch = 171 and best_valid_mse = 0.00955\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.01251983467961119 RMSE: 0.11189206709866072 R2: 0.9445795159982159 MAE: 0.07983509117616981\n",
      "=====================================\n",
      "[109/216] START => batchsize: 1024 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 52 and best_valid_mse = 0.19857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19305220583447702 RMSE: 0.43937706566737983 R2: 0.1454322713715711 MAE: 0.34583947377914226\n",
      "=====================================\n",
      "[110/216] START => batchsize: 1024 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 52 and best_valid_mse = 0.19857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19305220583447702 RMSE: 0.43937706566737983 R2: 0.1454322713715711 MAE: 0.34583947377914226\n",
      "=====================================\n",
      "[111/216] START => batchsize: 1024 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 52 and best_valid_mse = 0.19857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19305220583447702 RMSE: 0.43937706566737983 R2: 0.1454322713715711 MAE: 0.34583947377914226\n",
      "=====================================\n",
      "[112/216] START => batchsize: 1024 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 72 with best_epoch = 52 and best_valid_mse = 0.19857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19305220583447702 RMSE: 0.43937706566737983 R2: 0.1454322713715711 MAE: 0.34583947377914226\n",
      "=====================================\n",
      "[113/216] START => batchsize: 1024 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_valid_mse = 0.21549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2130818458530154 RMSE: 0.4616078918877096 R2: 0.056768772801846 MAE: 0.3683945009397784\n",
      "=====================================\n",
      "[114/216] START => batchsize: 1024 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_valid_mse = 0.21549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2130818458530154 RMSE: 0.4616078918877096 R2: 0.056768772801846 MAE: 0.3683945009397784\n",
      "=====================================\n",
      "[115/216] START => batchsize: 1024 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_valid_mse = 0.21549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2130818458530154 RMSE: 0.4616078918877096 R2: 0.056768772801846 MAE: 0.3683945009397784\n",
      "=====================================\n",
      "[116/216] START => batchsize: 1024 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 56 with best_epoch = 36 and best_valid_mse = 0.21549\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2130818458530154 RMSE: 0.4616078918877096 R2: 0.056768772801846 MAE: 0.3683945009397784\n",
      "=====================================\n",
      "[117/216] START => batchsize: 1024 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_valid_mse = 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19910860797789304 RMSE: 0.4462158759814503 R2: 0.11862291272691028 MAE: 0.35405435755946785\n",
      "=====================================\n",
      "[118/216] START => batchsize: 1024 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_valid_mse = 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19910860797789304 RMSE: 0.4462158759814503 R2: 0.11862291272691028 MAE: 0.35405435755946785\n",
      "=====================================\n",
      "[119/216] START => batchsize: 1024 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_valid_mse = 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19910860797789304 RMSE: 0.4462158759814503 R2: 0.11862291272691028 MAE: 0.35405435755946785\n",
      "=====================================\n",
      "[120/216] START => batchsize: 1024 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 58 with best_epoch = 38 and best_valid_mse = 0.2076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.19910860797789304 RMSE: 0.4462158759814503 R2: 0.11862291272691028 MAE: 0.35405435755946785\n",
      "=====================================\n",
      "[121/216] START => batchsize: 1024 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.05456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05795078541004205 RMSE: 0.24072969366084038 R2: 0.7434742025037826 MAE: 0.1864603368037887\n",
      "=====================================\n",
      "[122/216] START => batchsize: 1024 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 117 and best_valid_mse = 0.04211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.041000275982327715 RMSE: 0.20248524880180213 R2: 0.8185075763941403 MAE: 0.1535770791227396\n",
      "=====================================\n",
      "[123/216] START => batchsize: 1024 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 148 and best_valid_mse = 0.03364\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03267085377808386 RMSE: 0.18075080574670715 R2: 0.8553787190112357 MAE: 0.1367449778596377\n",
      "=====================================\n",
      "[124/216] START => batchsize: 1024 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 205 and best_valid_mse = 0.02377\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.022660305728199586 RMSE: 0.15053340402780901 R2: 0.8996915579779666 MAE: 0.11144205717457357\n",
      "=====================================\n",
      "[125/216] START => batchsize: 1024 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_valid_mse = 0.09188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09829224839348219 RMSE: 0.3135159459955461 R2: 0.5648980901911125 MAE: 0.2474533630849622\n",
      "=====================================\n",
      "[126/216] START => batchsize: 1024 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_valid_mse = 0.09188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09829224839348219 RMSE: 0.3135159459955461 R2: 0.5648980901911125 MAE: 0.2474533630849622\n",
      "=====================================\n",
      "[127/216] START => batchsize: 1024 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_valid_mse = 0.09188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09829224839348219 RMSE: 0.3135159459955461 R2: 0.5648980901911125 MAE: 0.2474533630849622\n",
      "=====================================\n",
      "[128/216] START => batchsize: 1024 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 53 with best_epoch = 33 and best_valid_mse = 0.09188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09829224839348219 RMSE: 0.3135159459955461 R2: 0.5648980901911125 MAE: 0.2474533630849622\n",
      "=====================================\n",
      "[129/216] START => batchsize: 1024 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.05223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05492890730580945 RMSE: 0.2343691688465218 R2: 0.7568508924854561 MAE: 0.1835195594734675\n",
      "=====================================\n",
      "[130/216] START => batchsize: 1024 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 108 and best_valid_mse = 0.02577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.026838129108973874 RMSE: 0.16382346934726377 R2: 0.8811979436642294 MAE: 0.12797166475049254\n",
      "=====================================\n",
      "[131/216] START => batchsize: 1024 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 138 and best_valid_mse = 0.02068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.02301403181138096 RMSE: 0.15170376333954594 R2: 0.8981257489049529 MAE: 0.11670475467763851\n",
      "=====================================\n",
      "[132/216] START => batchsize: 1024 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 198 and best_valid_mse = 0.01136\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.011706581708777853 RMSE: 0.10819695794604325 R2: 0.9481794735386194 MAE: 0.08359632042550173\n",
      "=====================================\n",
      "[133/216] START => batchsize: 1024 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.09164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1008283349156107 RMSE: 0.3175347774899794 R2: 0.5536718123588935 MAE: 0.24316882245069432\n",
      "=====================================\n",
      "[134/216] START => batchsize: 1024 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 117 and best_valid_mse = 0.08107\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08173135912645753 RMSE: 0.28588696914420136 R2: 0.638206765757982 MAE: 0.21927760079904793\n",
      "=====================================\n",
      "[135/216] START => batchsize: 1024 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 143 and best_valid_mse = 0.05848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.05654959337325365 RMSE: 0.2378015840427764 R2: 0.7496767397453263 MAE: 0.1854592555175018\n",
      "=====================================\n",
      "[136/216] START => batchsize: 1024 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 208 and best_valid_mse = 0.03562\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03404182472063284 RMSE: 0.18450426748623686 R2: 0.849309958909141 MAE: 0.1438565880228417\n",
      "=====================================\n",
      "[137/216] START => batchsize: 1024 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 37 and best_valid_mse = 0.21873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21633456463094458 RMSE: 0.4651177965106738 R2: 0.04237024010491697 MAE: 0.3686191564631634\n",
      "=====================================\n",
      "[138/216] START => batchsize: 1024 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 37 and best_valid_mse = 0.21873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21633456463094458 RMSE: 0.4651177965106738 R2: 0.04237024010491697 MAE: 0.3686191564631634\n",
      "=====================================\n",
      "[139/216] START => batchsize: 1024 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 37 and best_valid_mse = 0.21873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21633456463094458 RMSE: 0.4651177965106738 R2: 0.04237024010491697 MAE: 0.3686191564631634\n",
      "=====================================\n",
      "[140/216] START => batchsize: 1024 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 57 with best_epoch = 37 and best_valid_mse = 0.21873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21633456463094458 RMSE: 0.4651177965106738 R2: 0.04237024010491697 MAE: 0.3686191564631634\n",
      "=====================================\n",
      "[141/216] START => batchsize: 1024 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.08457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08809126160003783 RMSE: 0.2968017210193328 R2: 0.6100539280959985 MAE: 0.2324527282496423\n",
      "=====================================\n",
      "[142/216] START => batchsize: 1024 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 117 with best_epoch = 97 and best_valid_mse = 0.08122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08863412268892212 RMSE: 0.29771483451269626 R2: 0.6076508912299687 MAE: 0.23148534223350775\n",
      "=====================================\n",
      "[143/216] START => batchsize: 1024 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 117 with best_epoch = 97 and best_valid_mse = 0.08122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08863412268892212 RMSE: 0.29771483451269626 R2: 0.6076508912299687 MAE: 0.23148534223350775\n",
      "=====================================\n",
      "[144/216] START => batchsize: 1024 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 117 with best_epoch = 97 and best_valid_mse = 0.08122\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08863412268892212 RMSE: 0.29771483451269626 R2: 0.6076508912299687 MAE: 0.23148534223350775\n",
      "=====================================\n",
      "[145/216] START => batchsize: 2048 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_valid_mse = 0.07371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07574071168914304 RMSE: 0.27521030447485617 R2: 0.6647250536552409 MAE: 0.21546237226515705\n",
      "=====================================\n",
      "[146/216] START => batchsize: 2048 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 100 and best_valid_mse = 0.06765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06384388922697723 RMSE: 0.2526734834266889 R2: 0.717387702628574 MAE: 0.20171277992274564\n",
      "=====================================\n",
      "[147/216] START => batchsize: 2048 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 120 with best_epoch = 100 and best_valid_mse = 0.06765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06384388922697723 RMSE: 0.2526734834266889 R2: 0.717387702628574 MAE: 0.20171277992274564\n",
      "=====================================\n",
      "[148/216] START => batchsize: 2048 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 120 with best_epoch = 100 and best_valid_mse = 0.06765\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06384388922697723 RMSE: 0.2526734834266889 R2: 0.717387702628574 MAE: 0.20171277992274564\n",
      "=====================================\n",
      "[149/216] START => batchsize: 2048 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 66 and best_valid_mse = 0.09305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10054826074493957 RMSE: 0.3170934574300447 R2: 0.5549115927946744 MAE: 0.24578383654712055\n",
      "=====================================\n",
      "[150/216] START => batchsize: 2048 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 106 with best_epoch = 86 and best_valid_mse = 0.08418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08953401648266697 RMSE: 0.2992223529127912 R2: 0.6036674081508544 MAE: 0.22946271820236305\n",
      "=====================================\n",
      "[151/216] START => batchsize: 2048 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 106 with best_epoch = 86 and best_valid_mse = 0.08418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08953401648266697 RMSE: 0.2992223529127912 R2: 0.6036674081508544 MAE: 0.22946271820236305\n",
      "=====================================\n",
      "[152/216] START => batchsize: 2048 width: 8 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 106 with best_epoch = 86 and best_valid_mse = 0.08418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08953401648266697 RMSE: 0.2992223529127912 R2: 0.6036674081508544 MAE: 0.22946271820236305\n",
      "=====================================\n",
      "[153/216] START => batchsize: 2048 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.23524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.231687324410267 RMSE: 0.481339095036199 R2: -0.025590511734626897 MAE: 0.3897567506002308\n",
      "=====================================\n",
      "[154/216] START => batchsize: 2048 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.23524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.231687324410267 RMSE: 0.481339095036199 R2: -0.025590511734626897 MAE: 0.3897567506002308\n",
      "=====================================\n",
      "[155/216] START => batchsize: 2048 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.23524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.231687324410267 RMSE: 0.481339095036199 R2: -0.025590511734626897 MAE: 0.3897567506002308\n",
      "=====================================\n",
      "[156/216] START => batchsize: 2048 width: 8 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 42 with best_epoch = 22 and best_valid_mse = 0.23524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.231687324410267 RMSE: 0.481339095036199 R2: -0.025590511734626897 MAE: 0.3897567506002308\n",
      "=====================================\n",
      "[157/216] START => batchsize: 2048 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_valid_mse = 0.08652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0898182981548868 RMSE: 0.29969701058717085 R2: 0.602409002726946 MAE: 0.231762959163073\n",
      "=====================================\n",
      "[158/216] START => batchsize: 2048 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 118 and best_valid_mse = 0.07936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08637442505646241 RMSE: 0.29389526205174255 R2: 0.6176537019453969 MAE: 0.22726516915460002\n",
      "=====================================\n",
      "[159/216] START => batchsize: 2048 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 148 with best_epoch = 128 and best_valid_mse = 0.07898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0869818244228764 RMSE: 0.29492681197693166 R2: 0.6149649789925403 MAE: 0.2275313124683257\n",
      "=====================================\n",
      "[160/216] START => batchsize: 2048 width: 8 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 148 with best_epoch = 128 and best_valid_mse = 0.07898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0869818244228764 RMSE: 0.29492681197693166 R2: 0.6149649789925403 MAE: 0.2275313124683257\n",
      "=====================================\n",
      "[161/216] START => batchsize: 2048 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 48 and best_valid_mse = 0.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.23338593337623972 RMSE: 0.4831003346886025 R2: -0.033109599121402544 MAE: 0.39384001462098117\n",
      "=====================================\n",
      "[162/216] START => batchsize: 2048 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 48 and best_valid_mse = 0.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.23338593337623972 RMSE: 0.4831003346886025 R2: -0.033109599121402544 MAE: 0.39384001462098117\n",
      "=====================================\n",
      "[163/216] START => batchsize: 2048 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 48 and best_valid_mse = 0.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.23338593337623972 RMSE: 0.4831003346886025 R2: -0.033109599121402544 MAE: 0.39384001462098117\n",
      "=====================================\n",
      "[164/216] START => batchsize: 2048 width: 8 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 68 with best_epoch = 48 and best_valid_mse = 0.2366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.23338593337623972 RMSE: 0.4831003346886025 R2: -0.033109599121402544 MAE: 0.39384001462098117\n",
      "=====================================\n",
      "[165/216] START => batchsize: 2048 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 55 and best_valid_mse = 0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2031877745244056 RMSE: 0.45076354613522773 R2: 0.10056601420413902 MAE: 0.35614677128844446\n",
      "=====================================\n",
      "[166/216] START => batchsize: 2048 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 55 and best_valid_mse = 0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2031877745244056 RMSE: 0.45076354613522773 R2: 0.10056601420413902 MAE: 0.35614677128844446\n",
      "=====================================\n",
      "[167/216] START => batchsize: 2048 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 55 and best_valid_mse = 0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2031877745244056 RMSE: 0.45076354613522773 R2: 0.10056601420413902 MAE: 0.35614677128844446\n",
      "=====================================\n",
      "[168/216] START => batchsize: 2048 width: 8 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 75 with best_epoch = 55 and best_valid_mse = 0.2092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.2031877745244056 RMSE: 0.45076354613522773 R2: 0.10056601420413902 MAE: 0.35614677128844446\n",
      "=====================================\n",
      "[169/216] START => batchsize: 2048 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.06557\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06881397737484789 RMSE: 0.2623241837399821 R2: 0.695387037465232 MAE: 0.2104951692394544\n",
      "=====================================\n",
      "[170/216] START => batchsize: 2048 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 111 and best_valid_mse = 0.03512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03693695766041576 RMSE: 0.19218989999585245 R2: 0.8364943209332201 MAE: 0.14908561619414742\n",
      "=====================================\n",
      "[171/216] START => batchsize: 2048 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 131 with best_epoch = 111 and best_valid_mse = 0.03512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03693695766041576 RMSE: 0.19218989999585245 R2: 0.8364943209332201 MAE: 0.14908561619414742\n",
      "=====================================\n",
      "[172/216] START => batchsize: 2048 width: 16 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 131 with best_epoch = 111 and best_valid_mse = 0.03512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03693695766041576 RMSE: 0.19218989999585245 R2: 0.8364943209332201 MAE: 0.14908561619414742\n",
      "=====================================\n",
      "[173/216] START => batchsize: 2048 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_valid_mse = 0.07092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07587794281269586 RMSE: 0.2754595121114823 R2: 0.6641175843489735 MAE: 0.21561367778185483\n",
      "=====================================\n",
      "[174/216] START => batchsize: 2048 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 67 and best_valid_mse = 0.07092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07587794281269586 RMSE: 0.2754595121114823 R2: 0.6641175843489735 MAE: 0.21561367778185483\n",
      "=====================================\n",
      "[175/216] START => batchsize: 2048 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 67 and best_valid_mse = 0.07092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07587794281269586 RMSE: 0.2754595121114823 R2: 0.6641175843489735 MAE: 0.21561367778185483\n",
      "=====================================\n",
      "[176/216] START => batchsize: 2048 width: 16 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 67 and best_valid_mse = 0.07092\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07587794281269586 RMSE: 0.2754595121114823 R2: 0.6641175843489735 MAE: 0.21561367778185483\n",
      "=====================================\n",
      "[177/216] START => batchsize: 2048 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.09119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0991296873954041 RMSE: 0.31484867380283516 R2: 0.5611910704104067 MAE: 0.24146287228757185\n",
      "=====================================\n",
      "[178/216] START => batchsize: 2048 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 101 and best_valid_mse = 0.08869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09342533947774878 RMSE: 0.305655589639301 R2: 0.5864420206506575 MAE: 0.23636685424678097\n",
      "=====================================\n",
      "[179/216] START => batchsize: 2048 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 121 with best_epoch = 101 and best_valid_mse = 0.08869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09342533947774878 RMSE: 0.305655589639301 R2: 0.5864420206506575 MAE: 0.23636685424678097\n",
      "=====================================\n",
      "[180/216] START => batchsize: 2048 width: 16 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 121 with best_epoch = 101 and best_valid_mse = 0.08869\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.09342533947774878 RMSE: 0.305655589639301 R2: 0.5864420206506575 MAE: 0.23636685424678097\n",
      "=====================================\n",
      "[181/216] START => batchsize: 2048 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 66 and best_valid_mse = 0.20638\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21533110704071748 RMSE: 0.46403782932075427 R2: 0.04681216020600398 MAE: 0.3758453835474802\n",
      "=====================================\n",
      "[182/216] START => batchsize: 2048 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 110 with best_epoch = 90 and best_valid_mse = 0.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21094482100280906 RMSE: 0.4592872968010427 R2: 0.06622855837833996 MAE: 0.3693659890429263\n",
      "=====================================\n",
      "[183/216] START => batchsize: 2048 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 110 with best_epoch = 90 and best_valid_mse = 0.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21094482100280906 RMSE: 0.4592872968010427 R2: 0.06622855837833996 MAE: 0.3693659890429263\n",
      "=====================================\n",
      "[184/216] START => batchsize: 2048 width: 16 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 110 with best_epoch = 90 and best_valid_mse = 0.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21094482100280906 RMSE: 0.4592872968010427 R2: 0.06622855837833996 MAE: 0.3693659890429263\n",
      "=====================================\n",
      "[185/216] START => batchsize: 2048 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_valid_mse = 0.22032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.217875822667372 RMSE: 0.4667717029419971 R2: 0.03554768465300273 MAE: 0.3693001979630597\n",
      "=====================================\n",
      "[186/216] START => batchsize: 2048 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 119 and best_valid_mse = 0.17444\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.17899816596825602 RMSE: 0.423081748564336 R2: 0.20764409057672106 MAE: 0.32628773884234946\n",
      "=====================================\n",
      "[187/216] START => batchsize: 2048 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 147 and best_valid_mse = 0.12063\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.13019975803410438 RMSE: 0.3608320357647092 R2: 0.42365583956821584 MAE: 0.2761971706821606\n",
      "=====================================\n",
      "[188/216] START => batchsize: 2048 width: 16 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 208 and best_valid_mse = 0.0361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03862213468590033 RMSE: 0.19652515026301426 R2: 0.8290346915714095 MAE: 0.14893396333095088\n",
      "=====================================\n",
      "[189/216] START => batchsize: 2048 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 66 and best_valid_mse = 0.09271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10026558037933796 RMSE: 0.31664740703081395 R2: 0.5561629098511973 MAE: 0.2418576936878301\n",
      "=====================================\n",
      "[190/216] START => batchsize: 2048 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 66 and best_valid_mse = 0.09271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10026558037933796 RMSE: 0.31664740703081395 R2: 0.5561629098511973 MAE: 0.2418576936878301\n",
      "=====================================\n",
      "[191/216] START => batchsize: 2048 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 66 and best_valid_mse = 0.09271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10026558037933796 RMSE: 0.31664740703081395 R2: 0.5561629098511973 MAE: 0.2418576936878301\n",
      "=====================================\n",
      "[192/216] START => batchsize: 2048 width: 16 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 86 with best_epoch = 66 and best_valid_mse = 0.09271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10026558037933796 RMSE: 0.31664740703081395 R2: 0.5561629098511973 MAE: 0.2418576936878301\n",
      "=====================================\n",
      "[193/216] START => batchsize: 2048 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 69 and best_valid_mse = 0.07584\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.07443221615107833 RMSE: 0.2728226826183599 R2: 0.6705172592146177 MAE: 0.2160389081503966\n",
      "=====================================\n",
      "[194/216] START => batchsize: 2048 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 107 with best_epoch = 87 and best_valid_mse = 0.04579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0475433436337528 RMSE: 0.2180443616188064 R2: 0.7895439370667833 MAE: 0.16603607106814605\n",
      "=====================================\n",
      "[195/216] START => batchsize: 2048 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 107 with best_epoch = 87 and best_valid_mse = 0.04579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0475433436337528 RMSE: 0.2180443616188064 R2: 0.7895439370667833 MAE: 0.16603607106814605\n",
      "=====================================\n",
      "[196/216] START => batchsize: 2048 width: 32 steps: 3 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 107 with best_epoch = 87 and best_valid_mse = 0.04579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.0475433436337528 RMSE: 0.2180443616188064 R2: 0.7895439370667833 MAE: 0.16603607106814605\n",
      "=====================================\n",
      "[197/216] START => batchsize: 2048 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_valid_mse = 0.09651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1044230066782952 RMSE: 0.3231454884077684 R2: 0.5377595855592896 MAE: 0.24659182464002602\n",
      "=====================================\n",
      "[198/216] START => batchsize: 2048 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_valid_mse = 0.09651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1044230066782952 RMSE: 0.3231454884077684 R2: 0.5377595855592896 MAE: 0.24659182464002602\n",
      "=====================================\n",
      "[199/216] START => batchsize: 2048 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_valid_mse = 0.09651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1044230066782952 RMSE: 0.3231454884077684 R2: 0.5377595855592896 MAE: 0.24659182464002602\n",
      "=====================================\n",
      "[200/216] START => batchsize: 2048 width: 32 steps: 3 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 66 with best_epoch = 46 and best_valid_mse = 0.09651\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.1044230066782952 RMSE: 0.3231454884077684 R2: 0.5377595855592896 MAE: 0.24659182464002602\n",
      "=====================================\n",
      "[201/216] START => batchsize: 2048 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 53 and best_valid_mse = 0.21072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.21023787045753065 RMSE: 0.4585170339884121 R2: 0.06935795604111095 MAE: 0.3701571806110759\n",
      "=====================================\n",
      "[202/216] START => batchsize: 2048 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 120\n",
      "Stop training because you reached max_epochs = 120 with best_epoch = 119 and best_valid_mse = 0.08065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.08542160748811524 RMSE: 0.2922697512369613 R2: 0.6218714581821624 MAE: 0.2271224979926703\n",
      "=====================================\n",
      "[203/216] START => batchsize: 2048 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 150\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 145 and best_valid_mse = 0.05893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.06197964993073201 RMSE: 0.24895712468361297 R2: 0.725639971667023 MAE: 0.1920733173697583\n",
      "=====================================\n",
      "[204/216] START => batchsize: 2048 width: 32 steps: 5 learning_rate: 0.02 max_epochs: 210\n",
      "Stop training because you reached max_epochs = 210 with best_epoch = 209 and best_valid_mse = 0.03085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.03535688468623562 RMSE: 0.18803426466002313 R2: 0.8434886951584492 MAE: 0.14027243281507726\n",
      "=====================================\n",
      "[205/216] START => batchsize: 2048 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 68 and best_valid_mse = 0.09383\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10256132925409968 RMSE: 0.3202519777520502 R2: 0.5460005141773114 MAE: 0.244187859559695\n",
      "=====================================\n",
      "[206/216] START => batchsize: 2048 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 70 and best_valid_mse = 0.09206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10101242192272371 RMSE: 0.31782451435143216 R2: 0.5528569301105475 MAE: 0.24263813088249003\n",
      "=====================================\n",
      "[207/216] START => batchsize: 2048 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 70 and best_valid_mse = 0.09206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10101242192272371 RMSE: 0.31782451435143216 R2: 0.5528569301105475 MAE: 0.24263813088249003\n",
      "=====================================\n",
      "[208/216] START => batchsize: 2048 width: 32 steps: 5 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 90 with best_epoch = 70 and best_valid_mse = 0.09206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10101242192272371 RMSE: 0.31782451435143216 R2: 0.5528569301105475 MAE: 0.24263813088249003\n",
      "=====================================\n",
      "[209/216] START => batchsize: 2048 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 70\n",
      "Stop training because you reached max_epochs = 70 with best_epoch = 67 and best_valid_mse = 0.09323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10078814925124545 RMSE: 0.31747149360414306 R2: 0.5538496988107557 MAE: 0.24307415510558153\n",
      "=====================================\n",
      "[210/216] START => batchsize: 2048 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 67 and best_valid_mse = 0.09323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10078814925124545 RMSE: 0.31747149360414306 R2: 0.5538496988107557 MAE: 0.24307415510558153\n",
      "=====================================\n",
      "[211/216] START => batchsize: 2048 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 67 and best_valid_mse = 0.09323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10078814925124545 RMSE: 0.31747149360414306 R2: 0.5538496988107557 MAE: 0.24307415510558153\n",
      "=====================================\n",
      "[212/216] START => batchsize: 2048 width: 32 steps: 7 learning_rate: 0.02 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 87 with best_epoch = 67 and best_valid_mse = 0.09323\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10078814925124545 RMSE: 0.31747149360414306 R2: 0.5538496988107557 MAE: 0.24307415510558153\n",
      "=====================================\n",
      "[213/216] START => batchsize: 2048 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 70\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 35 and best_valid_mse = 0.09848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10582459411181531 RMSE: 0.32530692293865393 R2: 0.5315552980487682 MAE: 0.25048873451973236\n",
      "=====================================\n",
      "[214/216] START => batchsize: 2048 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 120\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 35 and best_valid_mse = 0.09848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10582459411181531 RMSE: 0.32530692293865393 R2: 0.5315552980487682 MAE: 0.25048873451973236\n",
      "=====================================\n",
      "[215/216] START => batchsize: 2048 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 150\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 35 and best_valid_mse = 0.09848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10582459411181531 RMSE: 0.32530692293865393 R2: 0.5315552980487682 MAE: 0.25048873451973236\n",
      "=====================================\n",
      "[216/216] START => batchsize: 2048 width: 32 steps: 7 learning_rate: 0.01 max_epochs: 210\n",
      "\n",
      "Early stopping occurred at epoch 55 with best_epoch = 35 and best_valid_mse = 0.09848\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10582459411181531 RMSE: 0.32530692293865393 R2: 0.5315552980487682 MAE: 0.25048873451973236\n",
      "=====================================\n",
      "Best model SCORE: 0.9640017844139963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Daniele\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cuda\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.00813222261181444 RMSE: 0.09017883682890593 R2: 0.9640017839939237 MAE: 0.06946583074375974\n",
      "=====================================\n",
      "(0.9640017839939237, TabNetRegressor(n_d=32, n_a=32, n_steps=5, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=42, clip_value=1, verbose=0, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=1129, output_dim=1, device_name='auto', n_shared_decoder=1, n_indep_decoder=1))\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "history = None\n",
    "\n",
    "batchsize = [512,1024,2048]\n",
    "width = [8,16,32]\n",
    "steps = [3,5,7]\n",
    "learning_rate = [2e-2,1e-2]\n",
    "max_epochs = [70,120,150,210]\n",
    "\n",
    "best_model_params = None \n",
    "best_r2 = 0\n",
    "\n",
    "total_iterations = len(batchsize) * len(width) * len(steps) * len(learning_rate) * len(max_epochs)\n",
    "current_iteration = 0\n",
    "\n",
    "for batchsize,width,steps,learning_rate,max_epochs in itertools.product(batchsize,width,steps,learning_rate,max_epochs):\n",
    "    current_iteration += 1\n",
    "    print(f\"[{current_iteration}/{total_iterations}] START => batchsize: {batchsize} width: {width} steps: {steps} learning_rate: {learning_rate} max_epochs: {max_epochs}\")\n",
    "    log_name = f'TabNet_{batchsize}_{width}_{steps}_{learning_rate}_{max_epochs}'\n",
    "\n",
    "\n",
    "    writer = SummaryWriter('run/'+log_name)\n",
    "    model = TabNet(ratings, genome_scores,width_values = width, steps = steps, learning_rate = learning_rate)\n",
    "    history = model.train(max_epochs = max_epochs,batchsize = batchsize)\n",
    "    r2score, instance = model.test()\n",
    "    writer.add_hparams({'batchsize': batchsize, 'hidden_size1': width, 'hidden_size2': steps, 'lr': learning_rate, 'num_epochs': max_epochs}, {'metrics/r2': r2score})\n",
    "    \n",
    "    if r2score > best_r2:\n",
    "        best_r2 = r2score\n",
    "        best_model_params = f'{batchsize}_{width}_{steps}_{learning_rate}_{max_epochs}'\n",
    "        model.save(\"model\",best_model_params)\n",
    "        print(f\"New best model: {best_model_params} with r2: {best_r2}\")\n",
    "\n",
    "    writer.flush()\n",
    "writer.close()\n",
    "model = TabNet(ratings,genome_scores)\n",
    "print(f'Best model SCORE: {best_r2}')\n",
    "model.load(f\"model/{best_model_params}.pt.zip\")\n",
    "print(model.test())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0sAAAHUCAYAAADr67PJAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjYuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8o6BhiAAAACXBIWXMAAA9hAAAPYQGoP6dpAAC3E0lEQVR4nOzdd3gc1fn28e/MdvVmy3LvBTeMTTcd/Au9JwRCDemQAiRASCgJJRACL+k0E5KQhA6BEAi9g8Hg3nuTbPW62jbz/rFFEi5aSSutyv25Li6k3dnZI40k77PnOfcxbNu2ERERERERkTbMdA9ARERERESkN1KxJCIiIiIisgcqlkRERERERPZAxZKIiIiIiMgeqFgSERERERHZAxVLIiIiIiIie6BiSUREREREZA9ULImIiIiIiOyBiiUREREREZE9ULEkIiJ9yoUXXsiFF16Y7mGIiMgAoGJJRERERERkD1QsiYiIiIiI7IGKJRER6Xfef/99zj//fGbPns3BBx/M1VdfTWlpaeJ+y7K49957OfbYY5k2bRrHHnssv/nNbwiFQoljXnzxRU477TRmzJjBIYccwjXXXMPOnTvT8eWIiEiaqFgSEZF+5bnnnuOyyy6jpKSEe+65h+uvv57PP/+cr3zlK1RWVgLw4IMP8s9//pPvfe97zJ8/n69+9as8/PDD/OlPfwJg4cKF/OQnP2HevHk8+OCDXH/99Xz00UdcffXV6fzSRESkhznTPQAREZFUsSyLu+++m7lz5/Kb3/wmcfsBBxzASSedxMMPP8xPfvITFixYwLRp0zj77LMBOOigg/D5fGRnZwPRYsnr9fLNb34Tt9sNQF5eHkuXLsW2bQzD6PkvTkREepxmlkREpN/YuHEj5eXlnHLKKW1uHzlyJLNmzWLBggUAHHzwwYlWvYceeoh169bxta99jdNPPx2AAw88EL/fzymnnMJvfvMbPv30U+bOncsVV1yhQklEZABRsSQiIv1GTU0NAEVFRbvdV1RURH19PQCXX345N954I83Nzdx9992cfPLJnHLKKXz00UcAzJo1iwceeIARI0bwyCOPcMEFF3DkkUfyt7/9rce+FhERST8VSyIi0m/k5eUBUFFRsdt95eXl5OfnA2CaJhdccAHPPPMM77//PnfccQfBYJArr7ySYDAIwBFHHMHDDz/MJ598wp///GcmTpzIrbfeypIlS3rs6xERkfRSsSQiIv3GmDFjGDRoEC+++GKb27du3cqiRYs44IADADjvvPO49dZbASgsLOSss87iggsuoK6ujoaGBu68807OPvtsbNvG5/NxzDHHcO211wKwY8eOnv2iREQkbRTwICIifU5ZWRl/+ctfdrt94sSJXHXVVVx//fVcffXVnHbaaVRXV/P73/+e3NxcLr30UiC6Jmn+/PkUFRUxa9Ysdu7cySOPPMJBBx1EQUEBhxxyCI888gjXXXcdp512GqFQiIceeoi8vDwOOeSQHv5qRUQkXQzbtu10D0JERCRZF154YSKo4YvOOeccbrvtNl555RXuv/9+1qxZQ1ZWFkcccQRXXXUVJSUlAITDYf70pz/x73//m7KyMrKzszn22GO5+uqrE616L774IvPnz2fjxo0YhsHs2bO55pprmDRpUo99rSIikl4qlkRERERERPZAa5ZERERERET2QMWSiIiIiIjIHvSKYikYDHLKKafw8ccf7/WYFStWcO655zJz5kzOPvtsli1b1oMjFBERERGRgSbtxVIgEOCqq65i7dq1ez2mqamJb37zm8yZM4dnnnmGWbNm8a1vfYumpqYeHKmIiIiIiAwkaS2W1q1bx5e//GW2bNmyz+NeeuklPB4PP/nJTxg3bhw33HADmZmZvPzyyz00UhERERERGWjSWiwtWLCAgw8+mMcff3yfxy1evJjZs2djGAYAhmFwwAEHsGjRoh4YpYiIiIiIDERp3ZT2/PPPT+q48vJyxo8f3+a2wsLCfbbuiYiIiIiIdEXa1ywlw+/343a729zmdrsJBoNpGpGIiIiIiPR3aZ1ZSpbH49mtMAoGg3i93g6fq6qqnnRvw2sYUFCQnfRYfB/fQ8biB/FPu4imw65P2Tg8S/5K1kd3EBh7Ig3H37PPY/+xcDv3v7+ZEyYX8bN5E9vcl/PMubgqllE374+ERh+TsvH1Vx29/tK/6PoPbLr+A5uu/8Cm69+7xK9He/pEsVRcXExFRUWb2yoqKhg8eHCHz2VZpP0HNLb0Kumx2JEwBOoh2IhlpXAcjTshUI/l8LV73sIMNw2BMBsrmnY71nJ4IVCP0VCW0vH1Vx29/tK/6PoPbLr+A5uu/8Cm69+7xK9He/pEG97MmTP5/PPPsWM/WbZt89lnnzFz5sw0j6yHmI7o/+3UViJmczUAlje/3WNLcjwA7Kht3u0+O6MIAMNfmcLRiYiIiIikV68tlsrLy2lujr4w/9KXvkRdXR233XYb69at47bbbsPv93PiiSemeZQ9xIgVS1Y4taf1VwFgJ1UsRVseKxqDhCJtizbLWwCAqWJJRERERPqRXlsszZ07l5deegmArKws7r//fhYuXMhZZ53F4sWLeeCBB8jIyEjzKHuGbca6Je1ISs/bkZmlggwXHqeJZcPO+kCb+yxfdGZJxZKIiIiI9Ce9Zs3S6tWr9/n5jBkzePbZZ3tySL1HbGbJsLqpWPIVtD8Ew6Akx8OmKj+ldc0Mz/Ml7rMyVCyJiIjIwGBZFpFIx7t9DAOam5sJhYJas9QDTNPENB2JfVo7q9cUS7IPiTVLqS2WjObk2/AAhuR4Y8VS25klO9aGZ/gr9vQwERERkX4hEPBTXV0OdK7aqaoysZSG1WPcbi85OQU4na5On0PFUl+QWLOUvjY8gKGxdUulXwh50MySiIiI9HeWZVFdXY7b7SUrK7dTMxYOh0Ekomml7mbbNpFImIaGGioryxg8eHinZ5hULPUBdmxmyUjlzFLIjxGJzhDFZ4baE0/EK637QrHkLQRixZJtJ5/FKCIiItJHRFvvbLKycnG7PZ06h9NpEg5rZqlneHA4HFRV7SQcDuFyuTt1ll4b8CCtGLGaNoVpeGa8Bc90Ybsyk3pMPBFvR90XAx6ixZJhhTCC9Skbo4iIiEhv09U1MNJzDKPrpY6Kpb7AjF2mFO6z1KYFL8lf+pLcaLFU9oWZJVw+rFjBZWrdkoiIiIj0EyqW+gC7G2aWjFixlGy4A8DQWBvervoAYattv60dn13SuiURERER6SdULPUF3bBmKd6Gl2y4A0BBphu3wyBiRwum1uKteAp5EBEREek91q5dzdKlizv12HPOOZWXXnohxSPqW1Qs9QG2JxdomQ1Khc7MLJmGwZB4It4XQx4SxZLa8ERERER6i5/+9Mds3bqlU4998MG/ctxxJ6R4RH2LiqU+IJI1FABH/faUnbOjseFxe03ESxRLVSkYnYiIiIikgt2FHXDz8/PxeLwpHE3fo+jwPsDKHg7EWudCTeDK6PI5W2aWkosNjytJ7LX0hY1pfdG9lrQxrYiIiAwUtm3T3IEocKdlE450LbDL6zSTTuS74opvUlZWyu2338L8+Q8AcMghh/Hqqy9z4YWX8pWvXMCf//w7Xn/9Vaqrqxg0aDAXXngpp59+FhBtw7vssm9y0kmncsUV3+TAAw9m8eLPWbTocwYPLuZHP/oxBx98aJe+nt5OxVIfYHtysNzZmMF6HA07iOSP7/I54zNAHZ9ZiseH721mSWuWREREpP+zbZvL/7WYJTvqevR5Zw7N4cHzZiZVMN1++6+55JLzOe+8r1FSUsL1119DMBjk4Yf/jtPp4m9/e4QPPniPW2+9i/z8fF5++T/ce+9dHHHEURQUFO52vr/+dT5XX30dV199HX/+8++5885beeqpFzDN/tus1n+/sn7GirXimSlqxTMDnWzDy4224X0xPlzFkoiIiAw0vX3HpZycXEzTJCsri8zMLAAuuOBihg8fwZAhQxg/fiLXXXcj06ZNZ9iw4Vx44aWEw+G9rnE69NC5nHTSqQwbNpyLL/46u3btpKqqf7/208xSHxHJHoazajWO+m2EUnA+o7kGANvXsTa8oe1sTKuABxERERkIDMPgwfNmdqwNz2H2aBvengwZUpL4+Mgjj+aTTz7id7+7ly1bNrFmzSoAIpE9JzCPGDEy8XFmZnSPzXA4dVvb9EYqlvqIxLqlhh0pOV9X2/B21geIWDYOM/rL2rJmSQEPIiIiMjAYhoHP5Uj6eKfTJBxO73yUx+NJfPzAA3/khRee46STTuVLXzqZq6++jnPOOXWvj3U6dy8duhIg0ReoWOojUp2I15nocICiLDdO0yBs2ZQ3BBJR4m3a8GwLDHV4ioiIiKTbvmahnn/+aa6++nqOPfZ4ADZu3NBTw+oz9Iq2j7CyhwFgNqSgWIoEMUMN0fN2sFiK7rUUjw9vacWzYu18hh3BCNR2fYwiIiIi0mVer5fNmzdRX797EEVOTi7vv/8O27dvY/HiRfzylzcCEAwGe3qYvZaKpT4ikhUtllIxsxTfY8k2zMSGtx1RsqeNaR0eLHdO9PwKeRARERHpFc4881yeeeYJfvWrW3e77/rrb2TdujVceOFXuP32mzn22OOZMmUqa9euTsNIeye14fURLWuWSsGKgJl8f+wXJVrwPLmdapeLb0y7o/aLiXgFmME6TH9FSuLNRURERKRrzjrrXM4669w93jdjxv48+ui/2tz2ta9dkvj4qadeSHz8+98/0Oa4kpKhvPfep6kbaC+lmaU+wsocjG04MKwQpr+8S+eKzyx1tAUvLj6zVFa3t41pNbMkIiIiIn2fiqW+wnRiZQ6JftjFVjyjOZpYZ3s7FhseNzRXG9OKiIiISP+nYqkPicRa8bq6bilVM0uleyuWmrTXkoiIiIj0fSqW+hArOxof3vWZpRqg47HhcfE1S2V1AaxW2fpWrA3PbNbMkoiIiIj0fSqW+hArnojXxfjwrs4sFWV5cMT2WqpoaImWtOPx4U0qlkRERESk71Ox1IdE4nst1e/o0nnM2JqlzhZLTtOgODu+11JLK55mlkRERESkP1Gx1IfEN6Z11G/r0nkS0eGdLJagVXz4noolzSyJiIiISD+gYqkPiW9Ma6aqDc/XuTQ82HN8ePx8mlkSERERkf5AxVIfkgh4CNRiBBs6fR7DH48O7/zM0tBYsdR6Y1orsc9SVXTjXBERERGRPkzFUh9iu7OxPLkAmA2dX7eUmFnydKENL3f3NUvx4svATrT6iYiIiEjf8tJLL3DOOacC8NlnnzJ37py9Hvvww/dzxRXfTOq8oVCIf//72cTnV1zxTR5++P6uDbabqVjqYxKJeJ1dt2RFMAK10Q9T0IZX2qoND4cLy5MHaGNaERERkf5g+vSZPP/8yyk512uvvcJf/zo/8fntt/+ar371wpScu7uoWOpjupqIZwRqMYjujWTHCpvOaFmz1Nx2r6WMWMiDXxvTioiIiPR1LpeLwsKilJzLbvWaESAnJ5eMjIyUnLu7ONM9AOmYxLqlToY8JFrw3NngcHV6HIOzPTgMCEZsqhqDFGVF2/IsbyGwDjO2LkpERESk37JtCPs7cLwJYatrz+n0gWEkdehNN12Py+XmZz+7JXHbzTffgNfr5aSTTuVPf/oda9aswjAM9t//AK677kaKitoWRp999inf//63ee+9TwHYuHEDd911G2vWrGLq1OmMHj2mzfEvvPAc//zn39ixYzuZmZkce+w8fvjDa1i8+HNuvz06jrlz5/Dkk//mtttuZtas2Xz9698Cou1/jz32KKWlpYwZM5Yrr/wR++9/AADnnHMq559/ES+//B/WrVvDyJGjue66nzN58pTOfR+TpGKpj4kk2vA6VyylIjYconstDcryUFYfYEddIFEs2RmF0efRzJKIiIj0Z7ZN3jNn4ir7tEefNlRyIDVnPpNUwXTccf/HHXf8gnA4jNPpJBgM8sEH7/Hzn9/CT37yQ77ylQv4+c9/QUVFObff/gv+/vdH+OEPf7zX8wWDQX7ykx8yY8b+XHfdz1m48BPuu+9upk+fCcDnny/k//2/X3Pjjb9k4sTJrFq1gl/+8kbmzDmQww47gu9//2r+9a+/8+CDj5KX1/a16EsvvcC9997FVVddy9Sp0/jPf17gxz/+Af/4x9MMGjQYgPnz7+cnP/kZo0eP4a67buO++37Nn/40f7dxppLa8PoYK3s4AGYni6WubkjbWkluSyteXHRmSW14IiIiMgAkOcOTLoccchi2bfHZZ9GCbsGCj/B4PEyevB8XX3w5l1xyOUOHDmPGjP05+uhj2bhxwz7P9+mnC6itreWaa65n1KjRnHXWuRx55DGJ+32+DK677uccddSxlJQM5ZhjjmfChEls3LgBl8tFVlYWpmlSWFiEw+Foc+6nnvoX55xzHieeeAojR47mO9+5krFjx/P0008kjjnxxFM58sijGTlyFOeddwErV65I4XdrzzSz1MfE1yw5OtmGl6qZJYChOR4+54vx4fFiSW14IiIi0o8ZRnSGpwNteE6nSbgH2/DcbjdHHHE0b7/9BgcddAhvv/0GRx99HIMGDebEE0/h8ccfY+3aNWzatJF169YkZoj2ZtOmDQwfPgKfz5e4bcqU/fjgg/cAmDx5Ch6Ph4cfvp+NG9ezfv06tm3bykEHHdLuWDdt2sSll36jzW3Tpk1n8+aNic+HDx+R+DgjI5NwOJzU96ErNLPUx1hZ8TVLpZ3ayyixZikVM0t7SMRTwIOIiIgMGIYBroye/a+Ds1nHHTePd999m2AwyHvvvcNxx51AefkuLr74K3z22adMmjSF73//Ks4772tJnrFtSIPT2bIG/uOPP+TrX7+QysoKDjnkMG699a52C7A4t9u9222RiEUk0lJculydX2/fWZpZ6mOsjMHYphPDCmM27kwEPiSrpVjqfGx4XEux1HqvpfiaJc0siYiIiKTbnDkHYVkRHn/8MbxeLzNnzuKZZ54gOzuXu+76f4njnnrq8XbPNWbMOLZu3UJDQwNZWVkArF27OnH/Cy88y8knn8bVV18LQDgcZvv2bcyefSAAxj4KvZEjR7F8+TKOOOLoxG3Lly9l5sxZHflyU04zS32N6Wg1u9TxVjwjtmYpFW14e9qY1srQmiURERGR3sLpdHLUUcfy178+wjHHHIdhGOTk5LJzZxmffrqA7du38fe//4W3336DYDC4z3MdeODBFBcP4Ve/+gWbNm3kpZde4PXXX03cn5OTy7Jli1m/fh0bNqzn9ttvobKyInFer9dLfX0dW7du2a2F7itfuYCnn36cl1/+D1u2bOZPf/od69ev5dRTz0j596QjVCz1QZFYsdSZRLzuasOL5+Yr4EFERESkdznuuHn4/U0cd9z/AXDssSfwf/93Ij/72bVcfvlFfPbZp1xxxQ/ZvHnjPgsmp9PJXXf9P+rr67nssq/x7LNPcdZZ5ybuv+yyb5GfX8C3vnUJP/rR93C73ZxxxjmJ2afZsw9k2LARXHzxeaxbt+YLYzyBb37zezz00J+55JKv8vnnC7nnnt8zatTo1H9DOsCwv7g7VD9XUVFPur9iw4CiouxOjyX7tR/gXf00DYdej/+A73XosbnPno17x8fUzfsTgQmndvzJWwlFLA7/f+9hAy9/+xAKM90Y/kqK5kd7U8u/vbFLezn1V129/tK36foPbLr+A5uuf98WCgWprCylsLAEl2v39TXJSEnAgyRtX9cs/vvYHs0s9UGRWHx4p2aW/KmbWXI5TEpyoq14m6ubALA9edhG9McqHlMuIiIiItIXqVjqgxJrltLchgcwtigTgHXlTbEncCTWQxn+ypQ8h4iIiIhIOqhY6oM6vdeSbWMEYvss+VJTLI2PFUvrKxoTt1m+eHy4iiURERER6btULPVBVla0WDLrd3TocUawHsOKJo+kamYpXiyta1MsRWPJFfIgIiIiIn2ZiqU+KD6zZAbrMAJ1ST/OiLXg2U5vdPfnFBg3qGVmKZGIp5klERER6acGWDZan5aKa6ViqS9yZSRmhjqy11Kq1ysBjM734TQNGoMRyuoDANi++Ma0KpZERESkfzDN6MvmSCTczpHSWwSD0demDoez0+fo/CMlrSJZwzCbq3HU7yBSOCWpx8TT6SxvQcrG4XSYjC7IYF1FI+vKGynJ8WL54nstqVgSERGR/sE0HbhcXhoaanA4HBhGx+ccLMsgEtHMVHezbZtgMEBDQzU+X1ai0O0MFUt9lJU9DCqWdWhmKdGGl8KZJYBxRbFiqaKRI8YVqg1PRERE+h3DMMjNLaCysoyqqp2dOodpmliW9lnqKT5fFjk5XZskULHURyUS8eq3Jf2Y7mjDA5gwKItXVpWzrjwa8qCABxEREemPnE4XgwcPJxwOdfixhgH5+ZlUVzdqU+Ie4HA4uzSjFKdiqY9qScTrzMxS6trwYPdEPDs2s6Q1SyIiItLfGIaBy+XuxOPA6/XicoVULPUhCnjoo1r2Wko+PrxlZikvpWMZV5QBwOZqP6GIpTY8EREREekXVCz1UVbWUKCzM0upbcMrzvaQ5XEQsWw2VTW1tOEF6yESSOlziYiIiIj0FBVLfVQkezgAZmMZRJLrm22ZWUptG55hGG1a8WxPLrYZ7fDU7JKIiIiI9FUqlvooO6MI23Rj2BZmY3KJLKY/Hh2e2pklgHHxYqm8CQwzUZCpWBIRERGRvkrFUl9lmFhZJQA4kowPNwLd04YHLSEP6xMhD9qYVkRERET6NhVLfVg85MFMMj480YbnS20bHuyeiNcS8qD4cBERERHpm1Qs9WFWbN2Soz6JRLyQHyPcDHTPzFK8DW9nfYC65lCrvZaqUv5cIiIiIiI9QcVSHxaJJ+Il0YYXn1WyTSe2KyvlY8n2OhmS7QFgfUWTZpZEREREpM9TsdSHWdnJb0ybiA335Ed3ResG4we1SsTTmiURERER6eNULPVhkUQbXjIzS7EkvG5YrxQ3rlXIgxUrlpSGJyIiIiJ9lYqlPiwxs9SwHWx7n8e27LGU123jSYQ8lDe2tOE1qQ1PRERERPomFUt9WCQWHW6GGjECtfs8NtGG1w3hDnGJ+PDKRiLxfZaaFfAgIiIiIn2TiqW+zOlraXdr2HciXqINz9t9bXijCnw4TIOGQIRyKzv6vJpZEhEREZE+SsVSH9eybmnfey31xMySy2EyusAHwJpGb/R5w00Q8nfbc4qIiIiIdBcVS32cFY8PbyfkoWXNUvcVS9DSirey2sA23dHnVsiDiIiIiPRBKpb6uEgs5MHRzl5LLcVS97XhQatEvMomrIx4Ip5a8URERESk70lrsRQIBPjpT3/KnDlzmDt3LvPnz9/rsa+++ionnngis2bN4qtf/SrLly/vwZH2XlZWfK+lfa9Z6ok2PIAJrfZasryKDxcRERGRviutxdJdd93FsmXLePTRR7npppv4/e9/z8svv7zbcWvXruXqq6/mW9/6Fs8//zxTpkzhW9/6Fn6/1sIkZpbaWbPU0214m6r8RLQxrYiIiIj0YWkrlpqamnjyySe54YYbmDp1KieccAKXX345jz322G7Hvv/++4wfP54zzjiDkSNHctVVV1FeXs66devSMPLepc1eS/uQmFnqxk1pAYqzPWR5HEQsm3ozNzo2FUsiIiIi0gelrVhatWoV4XCYWbNmJW6bPXs2ixcvxrKsNsfm5eWxbt06Fi5ciGVZPPPMM2RlZTFy5MieHnavE4m34TXugkhwLwcFMYP1QPfPLBmGwbjC6OxSuZUTHZvWLImIiIhIH+RM1xOXl5eTn5+P2+1O3FZUVEQgEKCmpoaCgpYZkJNOOok33niD888/H4fDgWma3H///eTm5nb4eQ0jJcPvkvgYUjKWjEJshwcjEsDRVIaVs3sBaQRqALAxwJPT7d+D8YMyWbyjju2hLPYjOrPUG77vvUVKr7/0Obr+A5uu/8Cm6z+w6fr3Lsleh7QVS36/v02hBCQ+DwbbzpBUV1dTXl7OjTfeyMyZM/nnP//J9ddfz7PPPkthYWGHnrewMLtrA0+hlI0lbwRUrqPAqIKiqbvfb0XXMxm+PIoG56XmOfdh/9EFPL24lK2h6AyTN1KLt6j3fN97i970syg9T9d/YNP1H9h0/Qc2Xf++JW3Fksfj2a0oin/u9Xrb3H733XczceJELrjgAgB++ctfcuKJJ/L000/zzW9+s0PPW1lZj213YeApYBjRX5RUjSUnowR35Trqt68jkL3/bvc7S7eSB4Q9+dRU1Hf9CdsxxBf9sVpWEy1+Q7U7qe2B5+0rUn39pW/R9R/YdP0HNl3/gU3Xv3eJX4/2pK1YKi4uprq6mnA4jNMZHUZ5eTler5ecnJw2xy5fvpwLL7ww8blpmkyePJkdO/Ydl70ntk2v+QFN1VgirTam3dP5DH9LbHhPfO1jCzMA2NDkA0+0Da+3fM97k970syg9T9d/YNP1H9h0/Qc2Xf++JW0BD1OmTMHpdLJo0aLEbQsXLmT69OmYZtthDR48mPXr17e5bePGjQwfPrwnhtrrtey1tOf48J6KDY/L8boYnOWmglYBD/qrICIiIiJ9TNqKJZ/PxxlnnMHNN9/MkiVLeO2115g/fz4XXXQREJ1lam5uBuDLX/4yTzzxBM899xybN2/m7rvvZseOHZx55pnpGn6vEsmOFo2OvWxM27IhbffGhrc2YVAWlXa0WDIiAYxQY489t4iIiIhIKqStDQ/g+uuv5+abb+biiy8mKyuLK6+8knnz5gEwd+5c7rjjDs466yxOOukkGhsbuf/++ykrK2PKlCk8+uijHQ536K/a22upp2eWAMYVZfL+Ri9Bw4PbDmD4K7HdWT32/CIiIiIiXZXWYsnn83HnnXdy55137nbf6tWr23x+7rnncu655/bU0PqU+JolR/32aLvbF7IQ01EsjR8UXbdUY+Qy2N6F6a/Ayh3VY88vIiIiItJVaWvDk9SxsqPFkhH2J1ruWmtpw+vBYqkoGhu+KxKdTTL9VT323CIiIiIiqaBiqT9weIhkDI5+uIdWPLM5Wqj05MzS6IIMHKbBLqtVyIOIiIiISB+iYqmfsFrFh39ROmaWXA6TUfm+lpAHf2WPPbeIiIiISCqoWOon4iEPjj0USy1rlnouDQ+irXiVifhwFUsiIiIi0reoWOon4vHhu80sWRGM5prohz04swQwflBmYmZJbXgiIiIi0teoWOon4m14X1yzZATrMIhuCGt783p0TOOKMqlKFEsKeBARERGRvkXFUj8Rie+19IWZpUQLnisLHO4eHVPrNjyjSTNLIiIiItK3qFjqJ1o2pt3R5nYjNqNj+3p2vRJASY6HRme09c9SsSQiIiIifYyKpX4ivmbJ0bQLws2J29OxIW2cYRhk5xcD4GyujG6YKyIiIiLSR6hY6idsTx620weA2VCauL0lNjwvHcNi0KDYWio7jBGsS8sYREREREQ6Q8VSf2EYiXVLjlateC0b0vZ8Gx7AyMEFNNje6FgUHy4iIiIifYiKpX7Eyto95CGdbXgA4wdlaGNaEREREemTVCz1I4mZpfptidta2vDSVCy1SsQL1u1KyxhERERERDpDxVI/0pKI13pmKb1teDleFw2OPACqKnbs+2ARERERkV5ExVI/EsmKzyy1FCXpnlkCCHsLAaivKkvbGEREREREOkrFUj9iZUeT59rOLNVE70tjseTMLAIgUFeetjGIiIiIiHSUiqV+JLHXUv32xJ5GRiLgIT1teAC+vOheS2hjWhERERHpQ1Qs9SNW5hBsDIxIIJo8Z9uJNUvpbMPLLSgBwBmowtbGtCIiIiLSR6hY6k8cbqzMwdEPG7ZjhBowrDCQ3ja8gqJosZRn17KzPpC2cYiIiIiIdISKpX7GirXimfXbWsIdHB5w+dI2JjNrEABFRh3rK5rSNg4RERERkY5QsdTPtE7EM/2x2HBf+tYrAdix58+nnnXl9Wkdi4iIiIhIslQs9TOtE/ESM0ue9LXgAVi+aHS407Ao3aX4cBERERHpG1Qs9TMtM0vbMRNJeOktlnC4CTqzAaiuULEkIiIiIn2DiqV+pmXN0vZEEl662/CiY4jOLvlrdxKOWGkejYiIiIhI+1Qs9TOR7NjMUus2vHTPLAFmZjTkIc+uZXO1P82jERERERFpn4qlfsbKiq1Z8ldiNkRb3tLehkdLyEOhUce68sY0j0ZEREREpH0qlvoZ25OL5coEwFmxLHpbLyiWLF8RAIXUsa5CxZKIiIiI9H4qlvobw0isW3JWrQF6x8ySlREtlgoMFUsiIiIi0jeoWOqHIrFWPMMKAb1jZsn2trThrVexJCIiIiJ9gIqlfsiKhTwkPvf2gjS82MxSkVFHaV2AhkA4zSMSEREREdk3FUv9kJX1xWIp/TNLljcaHT7YrAfQ7JKIiIiI9HoqlvqhyBdmlnpDG56VES2Wiow6QMWSiIiIiPR+Kpb6odZteLbpxHZnp3E0UfE0vCy7HhOLtYoPFxEREZFeTsVSPxRp1YZne/LBMNI4mtg4YrNbJjb51GtmSURERER6PRVL/ZCVWYxtRC9tb1ivBIDpTIyl0KhjbUUjEctO86BERERERPZOxVJ/5HBhZQ4BelGxBFi+6Lql4e5GGgIRlu6oS/OIRERERET2TsVSPxVft2T7el+xdOjgCABvr69M53BERERERPZJxVI/Fd+YtjfNLNmxkIdZBdE9lt5eV4FtqxVPRERERHonFUv9VLhoPwAiuWPTPJIW8Zml8Rl+XA6DrTXNbKxqSvOoRERERET2zJnuAUj38M+8nPDg/QmVzEn3UBLixZInWM2BI/P4YGM1b6+rZGxhZppHJiIiIiKyO80s9VcOD6Hhh4PDk+6RJMSLJdNfwVHjoh+/vU7rlkRERESkd1KxJD0mvjGt6a/kyFixtLysnvKGQDqHJSIiIiKyRyqWpMfYsZklw19JUZaHaSXZALyjVDwRERER6YVULEmPad2GB6gVT0RERER6NRVL0mMSbXiBWoiEOGp89PNPttTQEAinc2giIiIiIrtRsSQ9xvbmYRvRHzmzuYrRBT5G5vsIWzYfbqpO8+hERERERNpSsSQ9xzCxvQXRD/2VGIbRqhWvIp0jExERERHZjYol6VEt65ai65SOGh/9/P2NVYQiVtrGJSIiIiLyRSqWpEd9MeRhWkkOBRkuGgIRPttam86hiYiIiIi0oWJJelTrvZYAHKbBEfFWPEWIi4iIiEgvomJJepTta1mzFNd63ZJt22kZl4iIiIjIF6lYkh7VMrPUEuhw4Mg8fC6TXQ1BVu1qSNfQRERERETaULEkPaqlWKpK3OZ1OThkdHTG6S1tUCsiIiIivYSKJelRVqwNr/XMEsDRsVS8d1QsiYiIiEgvoWJJelR8Zqn1miWAw8cU4DBgXUUj22r86RiaiIiIiEgbKpakR9kZ0WLJ0VCK2VCauD3X52LW8FwA3lEqnoiIiIj0AiqWpEdFckYRLpiEEQmQ859LMIItgQ5Hjo8WUm+rFU9EREREegEVS9KzTAe1Jz+C5SvCVbGc7P99F6ww0BIhvmh7LTVNoXSOUkRERERExZL0PCtnJLUnP4Lt9OLZ/AZZ7/wcbJuhuV4mDMrEsuG9jZpdEhEREZH0UrEkaREunkXdCb/DxsC3/G/4Ft0PtKTiqRVPRERERNJNxZKkTXDsiTTOvQmArA9uxb3uRY4aF1239OGmappDkXQOT0REREQGOBVLklb+GV+nafqlAOS89gP2i6xkSLaHQNji48016R2ciIiIiAxoKpYkvQyDxrk3Exh9AkYkQN5/v85ZI6P7LL2zvqKdB4uIiIiIdB8VS5J+poO6eX8gNGgGZnMV3yu7gTzqeXd9FRHLTvfoRERERGSAUrEkvYMrg9qT/0IkeziZjZt52HMvTf5Glu6oS/fIRERERGSASmuxFAgE+OlPf8qcOXOYO3cu8+fP3+uxq1ev5qtf/SozZszg1FNP5aOPPurBkUpPsDMHU3vyo1juHGYbq/i1637eXlue7mGJiIiIyACV1mLprrvuYtmyZTz66KPcdNNN/P73v+fll1/e7bj6+nouu+wyxo8fzwsvvMAJJ5zAFVdcQWWl4qX7m0jhJOpOfBDLcHKa40Mmrv4ttq1WPBERERHpeWkrlpqamnjyySe54YYbmDp1KieccAKXX345jz322G7HPvvss2RkZHDzzTczatQovv/97zNq1CiWLVuWhpFLdwsNP5zKI38FwEWRZ2hY8Jf0DkhEREREBqS0FUurVq0iHA4za9asxG2zZ89m8eLFWJbV5tgFCxZw3HHH4XA4Erc9/fTTHHXUUT02Xulh087j6awLABj96c24tryV3vGIiIiIyIDjTNcTl5eXk5+fj9vtTtxWVFREIBCgpqaGgoKCxO1bt25lxowZ/PznP+eNN95g2LBhXHvttcyePbvDz2sYKRl+l8TH0BvG0ptV7v8Dnn57M2c73iPn5W9Rd8YThItnpntYXabrP7Dp+g9suv4Dm67/wKbr37skex3SViz5/f42hRKQ+DwYDLa5vampiQceeICLLrqIBx98kP/85z98/etf57///S8lJSUdet7CwuyuDTyFetNYeqMzDh7F3Ne/SQlVHMYK8p46FWZ8BY76CRSMTffwukzXf2DT9R/YdP0HNl3/gU3Xv29JW7Hk8Xh2K4rin3u93ja3OxwOpkyZwve//30A9ttvP95//32ef/55vv3tb3foeSsr60l3XoBhRH9ResNYejMTmDQkn2+X/pDnBz3GmKq3YfE/sZc+SWDyl2k68AdY2cPSPcwO0/Uf2HT9BzZd/4FN139g0/XvXeLXoz1pK5aKi4uprq4mHA7jdEaHUV5ejtfrJScnp82xgwYNYuzYtjMJo0ePprS0tMPPa9v0mh/Q3jSW3uqo8UX8vrSe693X8adzfkzmgrtxb3kL74p/4Fn1FM1Tv0rT7CuxMoeke6gdpus/sOn6D2y6/gObrv/Apuvft6Qt4GHKlCk4nU4WLVqUuG3hwoVMnz4d02w7rP3335/Vq1e3uW3Dhg0MG9b3ZhWkY44aVwjAp1tqqMmbRu2pf6f6rGcJDjsMwwriW/ooBX87nMz3foHRVJHm0YqIiIhIf5K2Ysnn83HGGWdw8803s2TJEl577TXmz5/PRRddBERnmZqbmwE477zzWL16Nb/73e/YvHkz9913H1u3buX0009P1/Clh4wuzGBUvo+wZfPBxioAwiUHUnvGE9Sc/jihkgMxIgEyFj9A4d8OI/PDOzCaq9M8ahERERHpD9K6Ke3111/P1KlTufjii7nlllu48sormTdvHgBz587lpZdeAmDYsGE89NBDvPnmm5xyyim8+eabPPDAAxQXF6dz+NJDjhofnV16e13bTYhDww+n5sxnqDnlb4QGz8QIN5Hx2R8o+OuhZHx8N0agLh3DFREREZF+wrDtgdU1WVGR/kV1hgFFRdm9Yix9wZIddXz9n4vI8jh49TuH4nTsoca3bdybXiXz47txVq4AwPLkUnvSI4SHHtTDI943Xf+BTdd/YNP1H9h0/Qc2Xf/eJX492pPWmSWRZEwdkk2+z0VDIMLn22v3fJBhEBwzj+qvvEzt//2ZcP4EzEAtmZ/+vx4dq4iIiIj0HyqWpNdzmAZzx0Y3KX53fdW+DzZMguNPoe6khwFwbf9Q7XgiIiIi0ikqlqRPOCKWivf2+kqS6RyN5I0lnDcWwwrh3vJ2dw9PRERERPohFUvSJxw8Kh+3w2BHbTMbKpuSekxw9AkAuDf9rzuHJiIiIiL9lIol6RMy3A7mjMwD4N31lfs+OCY4Jpqs6N78Bljh7hqaiIiIiPRTKpakzzgy1or3TnvrlmJCQ2ZjefMxA7W4Sj/pzqGJiIiISD+kYkn6jLljo8XSstI6qpqC7T/AdBIcdRwA7o2vdufQRERERKQfUrEkfUZxtofJg7Owgfc2JDe7FBgTXbfk2fgK2tRARERERDpCxZL0KUeMi0eIJ7duKTTiKGzTjaNuM47qdd05NBERERHpZ1QsSZ8SX7f00aZqAmGr3eNtdxah4YcBSsUTERERkY5RsSR9yqTBWQzOctMctvh0a01SjwmMjrfiad2SiIiIiCRPxZL0KYZhJDaoTTpCPFYsOcsWYjRVdNvYRERERKR/UbEkfc4RY1uKJTuJ0AYreyihomkY2NE9l0REREREkqBiSfqcOSPz8DpNdjUEWb2rIanHBOOpeFq3JCIiIiJJUrEkfY7HaXLI6HwA3km2FW/MPADcW96GcHO3jU1ERERE+g8VS9IntaxbSm6/pXDRNCKZQzDCftzb3u/OoYmIiIhIP6FiSfqkuWMLMIBVuxrYWR9o/wGG0TK7tEmpeCIiIiLSPhVL0icVZLiZVpIDwHsbkmvFi0eIuze9Cnb7ezSJiIiIyMCmYkn6rCPHFQDJr1sKDT8My5WJo3EnzvKl3Tk0EREREekHOl0srV+/nvr6egDeffddbrnlFp588smUDUykPfF1S59uqaEpGGn/AQ4PoRFHAuDWBrUiIiI9y4pgNpSmexQiHdKpYunxxx/ntNNOY+XKlaxYsYLvfOc7bN26lfvuu4/77rsv1WMU2aOxhRkMy/USjNh8vLk6qccEtG5JREQkLbLevZHCRw/EuWNBuocikrROFUsPPfQQd955JwcddBBPP/00U6ZM4aGHHuLee+/V7JL0GMMwWqXiJRkhPupYbMPEVbEcs357dw5PREREWnFtew8AZ8XyNI9EJHmdKpZ27tzJ7NmzAXjzzTc5/vjjARgyZAiNjY2pG51IO+Lrlt7bUEXEsts93vYVEh4yB9DskoiISI+JBHDUbgLAbE5u2w+R3qBTxdLYsWN54YUXeOqpp9ixYwfHH388oVCI+fPnM3ny5FSPUWSvZg3LJcvjoNofYnlZfVKPiafiebRuSUREpEc4qtdj2NH1xaZfxZL0HZ0qlq699loefvhhfvazn3H++eczbtw47rjjDl599VVuuOGGVI9RZK+cDpPDRncsFS++35Jr+wcYweQKLBEREek8Z9WaxMeGZpakD+lUsXTooYfy4Ycf8vHHH3PjjTcC8N3vfpc333yTadOmpXSAIu2Jr1tKtliK5I8jnDcWwwrh2vJ2dw5NREREAEerYsn0J/fvtUhv0Ono8Pfee49wOAzAU089xU9/+lP+8Ic/EAwGUzY4kWQcNiYfhwEbK5vYVuNP6jHBRCve/7pzaCIiIgI4q1YnPtaaJelLOlUs/eEPf+AHP/gB27ZtY8GCBdx4442UlJTw6quvcscdd6R6jCL7lON1sf/wXKAjrXjRYsm9+Q2wwt02NhEREWk7s2T4k9vuQ6Q36FSx9MQTT/C73/2OmTNn8vzzz3PggQdyyy238Ktf/YqXXnop1WMUadeR8QjxDcm9WxUaMgfLk4cZqMFV9ml3Dk1ERGRgCzfjqNuc+NRsrgK7/QRbkd6gU8VSbW0tY8eOxbZt3nrrLY455hgAsrKyiEQiKR2gSDKOGBstlj7fVkt9cxIzRaaT4OjjAHArFU9ERKTbOGo2YNgWlisTAMMKKWBJ+oxOFUuTJ0/m4Ycf5ve//z1VVVWccMIJ7Ny5k3vuuYf9998/xUMUad+IfB9jCjKIWDYfbkpudikeIe7e+Ire4RIREekm8fVKkaKp2M4MAAyFPEgf0ali6eabb+bTTz/l0Ucf5aqrrmLYsGE89NBDbN++nZtuuinVYxRJyhHjOhYhHhp5NLbpxlm7CUfN+u4cmoiIyIAVX68ULpiI5Yt2gijkQfoKZ2ceNHnyZJ5//vk2t/34xz/G7XanZFAinXHkuEL++sk2PthYTThi4XTs+70A251FaPihuLe8jXvj//Dnj++hkYqIiAwczlbFkrN8KY76rZjNCnmQvqFTxRLAihUrePjhh9mwYQORSIQxY8ZwwQUXcNBBB6VyfCJJm1aSQ57PRY0/xKLtdcwZmdfuYwKj5+He8jaeTa/iP+C73T9IERGRAcYRb8MrmITtzQfUhid9R6fa8F599VW+/OUvY9s2Z511FmeddRaGYXDZZZfx2muvpXqMIklxmAaHj4224r27IckI8di6JWfZQv3hFhERSbWwH0dtNAmvTRueX2140jd0ambpvvvu45prruGSSy5pc/tf/vIXfve733H88cenYmwiHXbk2AL+s3wn76yv5IdHjcUwjH0eb2UPJVQ0FVfFctyb3yAw+dweGqmIiEj/56xej4GN5c3H9hVheaNvaprNeoNS+oZOzSxt3bo1ERfe2jHHHMPGjRu7PCiRzjp4dD4uh8G2mmY2VjUl9Zj47JJn4/+6c2giIiIDTrwFL1wwEQwjMbOkjWmlr+hUsTRu3Djeeeed3W5/++23GTZsWJcHJdJZmW4nc0bkAfDu+uSm+INj5gHg3vI2hJu7a2giIiIDTjzcIVIwCSCxZklpeNJXdKoN78orr+TKK69k8eLFzJw5E4BFixbxyiuvcNddd6V0gCIddcS4Qj7cVM076yu5+KAR7R4fHjSdSGYxjsaduLd/QHDUsT0wShERkf4vERuePwEAyxdrw9M6YekjOjWzdMwxx/Dggw8SCAT45z//yTPPPINt2/zjH//gpJNOSvUYRTrkiFjIw9IddVQ3Bdt/gGEQHB2bXdr4ancOTUREZEBpmVmaCIDljbXhaWZJ+ohOR4cfeuihHHrooW1uCwQCbN26lREj2n83X6S7DMnxMnFQJmvKG3lvQxWnThvS7mOCY07At/xvuDe9Cvbt0E4whIiIiLQj5Mes2wJAON6Gl5hZUrEkfUOnZpb2ZsGCBcybNy+VpxTplKPHFwHw+Oc7sGy73eODww7DdmbgaCzDWbGsu4cnIiLS7zlr1sWS8AqwM6L/LifS8IJ1EAmlc3giSUlpsSTSW5yzfwmZbgerdzXw8spd7T/A6SU44ggAXFvf6+bRiYiI9H9tkvBibE8uthF9+Wk0KxFPej8VS9Iv5We4E+EOf3pvE4Gw1e5jQsWzAHCWL+3WsYmIiAwEX0zCA8B0YHvyoh9qryXpA1QsSb/11QOGMTjLTVl9gMc/297u8eFB0wFwli/p7qGJiIj0e4kkvFYzS0BiryWtW5K+IOmAh08++aTdY1avXt2lwYikktfl4DtzR3PLy2t4ZMEWTps+hDyfa6/HJ4ql2k0YgTpsT05PDVVERKTf+WISXlx83ZLa8KQvSLpYuvDCC5M6zlCKmPQiJ04p5h8Lt7O2vJGHP9rC1ceM2+uxtq+ASNYwHA3bcVYsIzTssB4cqYiISD8SasLxhSS8ONsX25hWey1JH5B0sbRq1aruHIdIt3CYBj84cixXPL2Upxbt4CuzhjI8z7fX48ODp0eLpV1LVSyJiIh0krN6LQCWrygRFx4X32vJ1F5L0gdozZL0ewePzueQ0fmELZs/vLtxn8eGB80AtG5JRESkK/a2XgnASuy1pJkl6f1ULMmA8P0jx2AAr62pYOmOur0eFx40DQBnufZaEhER6SxnLDY8UjBht/vsWMCD1ixJX6BiSQaECYOyOHlqMQC/fWcD9l42qg3FZpYcNRswgg09Nj4REZH+pGVmadJu91ne+JolteFJ76diSQaMbx8+Go/TZNH2Ot5et+epfzujiEhWCQY2zgrNLomIiHTG3pLwoCUNT2140heoWJIBozjbw/mzhwHwu3c3Eo7seaPaxLqlXdqcVkREpMOCjTjqtwF7nllqacPTzJL0fiqWZEC56MAR5PtcbKn28+zSsj0e07JuScWSiIhIR7Uk4Q3CjrXctdYys1QFe2mLF+ktVCzJgJLlcXL5oaMAePCDzTQEwrsd05KIp2JJRESko/aVhAdgxWeWrCBGqLHHxiXSGSqWZMA5a8YQRub7qPaH+NsnW3e7PzRoOgCO6nUQ1B9xERGRjogn4e2tWMLlw3Z6AbXiSe+nYkkGHKfD5IojxgDw2MLt7KoPtLnfzhxMJLM4GvJQuSIdQxQREemzHIlwh93XK8Up5EH6ChVLMiAdPb6QmUNzCIQt/vz+pt3uD8dml1y7tDmtiIhIRzjbacODllY8xYdLb6diSQYkwzD4wVFjAXhx+U7WlrfdUyleLGndkoiISPKMYAOOhu3AnmPD4+zYzJLa8KS3U7EkA9b0oTkcP7EIG/jtOxvb3KeQBxERkY5LtOBlFGN78/Z6nOVrlYgn0oupWJIB7XtHjMFpGny0qZqPN1Unbg8Pjoc8rIWQP13DExER6VNaNqOdsM/jEmuW2plZenNtBQ9/tBlbEeOSJiqWZEAbnufj7JklANz3zgas2B9jK6MYyzcIw7YU8iAiIpKk9mLD4+zYzJKxj4AH27a57X9r+PP7m1lbrnRaSQ8VSzLgXX7IKDLdDtaWN/LfFbuiNxoGodjsklMhDyIiIklxVkdjw/e1XgnA8sYCHpqr93pMZWOQ2ubofojbaptTNEKRjlGxJANeXoaLSw8eCcAf39tIcygCtA55WJa2sYmIiPQlLTNLe48NB7B8+cC+o8M3VbW0we9QsSRpomJJBPjKrKEUZ3vY1RDkmueX0xAIt8SHl2tmSUREpD1GoA5HQynQ/sySHYsO31ca3qaqpsTHpSqWJE3SWiwFAgF++tOfMmfOHObOncv8+fPbfcy2bduYNWsWH3/8cQ+MUAYKr8vBTV+aiNdp8vHmGr75+GLKMqLvijmq1kBYIQ8iIiL74qheC0Aksxjbk7vPY1s2pU2uWNpRp2JJ0iOtxdJdd93FsmXLePTRR7npppv4/e9/z8svv7zPx9x88800NTXt8xiRzjhwZD73f2UmBRku1pY3ctHzOwl5CjDsCM6KlekenoiISK/WkoS37xY8aFUsBWrACu/xmDbFkmaWJE3SViw1NTXx5JNPcsMNNzB16lROOOEELr/8ch577LG9Pubf//43jY1KQ5Hus9+QbOafvz+j8n3sbAjyUXN0LZOzQuuWRERE9iXZJDwA25uHjQGA0Vyzx2Nar1kqrWtWfLikRdqKpVWrVhEOh5k1a1bittmzZ7N48WIsy9rt+Orqan7961/zi1/8oieHKQPQsFwfD391f/YflsPiyCgASteo7VNERGRfWmaW2i+WMJ2JVr09hTw0BSPsrA8kPveHLGr9e56BEulOznQ9cXl5Ofn5+bjd7sRtRUVFBAIBampqKCgoaHP8r371K84880wmTNj3JmftMYwuPTwl4mPoDWORPcvLcPGHc2fw/NMzofx5QtsX8cjHW7j04BEYXbxwuv4Dm67/wKbrP7D19+vvqIrHhk9K6mu0fIWYgRrMQBXWF47fUh1twcv3uXA6DMobgpTWN5Of6Ur1sHtMf7/+fU2y1yFtxZLf729TKAGJz4PBYJvbP/jgAxYuXMiLL77Y5ectLMzu8jlSpTeNRfbs2189B377CyYa2zjrvTVUBy1+efpUnI6uT8rq+g9suv4Dm67/wNYvr7+/BhrLAMibMAu8SXyN2YOgZj15Lj8UtT2+cmsdABOKs7Fsm/KGIPWWQVFR3//e9cvr34+lrVjyeDy7FUXxz71eb+K25uZmbrzxRm666aY2t3dWZWU96W55NYzoL0pvGIu0w86nwJuPq7maScY2/rnAzZbyBu44dQoZbkenTqnrP7Dp+g9suv4DW3++/s7Sz8kDIplDqG4woaG+3cdkO3PxAA27ttM8uO3xSzdHU/KG5bhpDkWXZ6zeVs3BQ7NSPPKe05+vf18Uvx7tSVuxVFxcTHV1NeFwGKczOozy8nK8Xi85OTmJ45YsWcLWrVv5/ve/3+bx3/jGNzjjjDM6vIbJtuk1P6C9aSyyNwbhQdNxb32Hm/Zv5vylJu9vrOJbjy/mnjOnUZTpbv8Ue9Gd19+5YwHZ7/yUxgN/RHDcyd3zJNIl+v0f2HT9B7b+eP0dlS0teMl+bZYvuuTC8Fft9piNldE2vNEFGdT6Q0A0Ea8/fN/64/Xvz9IW8DBlyhScTieLFi1K3LZw4UKmT5+OabYMa8aMGfzvf//jueeeS/wHcOutt/KDH/ygh0ctA1F8c9r9jA386dwZ5PlcrNzZwNf/8TmbKntfjL3RuIvcl7+Fs3IVviWPpHs4Ij3Otm3+t2oXW6q1P5pIT+lIEl6c7Y0XS7sHPMRjw0cVZFCSE+0sKq0L7HacSHdLW7Hk8/k444wzuPnmm1myZAmvvfYa8+fP56KLLgKis0zNzc14vV5GjRrV5j+IzkwVFhama/gygIRixZKzfBnTh+Yw/6v7MyLPy466AF//1yI+31ab5hG2YkXIefV7mP5yAFy7FkEklN4xifSwd9ZXcsN/VnHzf1eneygiA0aHkvBiLF/0ddwXN6YNWzZba6Jvdowu8DE0N1osaa8lSYe0bkp7/fXXM3XqVC6++GJuueUWrrzySubNmwfA3Llzeemll9I5PBEAwoNnAOCsXAWRICPyo9Hi00uyqWsOc8VTS1i5s/3e7J6Q8ck9uLd/iO3MwHJnY4SbtUeUDDhvrYu+S71iZz3NoUiaRyMyMHRmZimxMW1zdZvbS2ubCUVsPE6TIdnelmJJey1JGqS1WPL5fNx55518/vnnvPvuu1xyySWJ+1avXs1ZZ521x8etXr2agw8+uIdGKQOdlT0Cy5OLYQVxxmJR8zPc/PHcGRw6Op9gxOZn/1lFUzC9L8pcm98k89P7AKg/5i5CQ6O/I66yhekclkiPsmybDzZG36WOWDardzWkeUQi/Z/RXIOjaSfQsZkl25sfffwX2vA2xlrwRub7cJgGxdkeDCAQtqj2q1tCelZaiyWRPsEwEuuWnLuWJG72uhz88qTJDM5ys6Xaz91vrEvXCDHrd5DzWjQExT/tIgITzyA0ZA4ArtJP0jYukZ62cmcDVU0tL6aWl/WOWV+R/iw+qxTJGortTj4WO9GG19y2DW9zVUu4A4DLYTIoKxqopFY86WkqlkSSEG61bqm1XJ+LX548GdOAF5bv5H+rdvX84CIhcv73HczmakKDptNw+I0AhEuixZKz7FPF7siA8cGG6Iuu+F6DK1QsiXQ7Z3XH1ytBSxqe6a9s8+/UpkSx5EvcNkzrliRNVCyJJKGlWFqy230HDM/j0oNHAnD7q2vZXtuzCVyZH/0KV9lCLHcOdf/3Z3BG/0EJDZ6JbTpxNO7ErN/Wo2MSSZf3Yi14J0waBMCyUhVLIt2tZb3SpA49zvJGZ5aMSADCLf92bqqKhztkJG4ryVUinqSHiiWRJCQS8SpX7TFd7vJDRzFjaA6NwQg//89qwlbPzOS4N7xCxqL7Aag/7jdYuaNa7nT6CBdNA8BV9mmPjEcknSobg4mZpMsPjf4ubK9tpqZJaxxEupOzE+EOALgysB0eoCURz7btVjNLrYqlRHy4ZpakZ6lYEkmClTsay52DEQkk3kFrzWka/PKkyWR5HCwtrePBDzd3+5jM2s1kv/4jAJpmfoPg2BN3OyZUciAArlIVS5J6RuMu3BteBttK91AAEsEOkwZnMaYwI9HCs7yXpFWK9FeOTsSGA2AYWLGQB7M5GvJQ7Q9R1xzGIBrwEDc0VixtVxue9DAVSyLJMAzCg2KzNOVL93jI0Fwv1x8/AYBHPtrCwq013TeeSICcV76DGawjVHwAjYdev8fDQkNmA7F1SyIplv3uz8j97+W4N72W7qEALcXS4WOj6yCmDokuNF9eWpe2MYn0d0ZzNY6m6HrdSP6EDj8+HvJgxGaW4rNKJblevC5H4rh4fHipiiXpYSqWRJLUsm5pz8USwLzJgzltWjE2cONLq6jppojTrPd+gat8CZY3P7pOyeHe43GJkIfKlRhBRShLajkqVgCx9tQ0C0csPtwU3atl7phosbTfkBxAiXgi3SmxGW3WMGx3Vocfbyf2WorOLG2q3D3cAaAkN9quV1Yf0F5L0qNULIkkaV8hD61dc+x4Rub72NUQ5Lb/rUn5H3XP2ufxLXsUgPrj78PKHrrXY63MIUSyR2DYFs6dn6V0HDLAWWEcseAQs25LmgcDi3fU0RiMkOdzsV9sRmlaSXxmqV4vrkS6SWc2o22tJREv+mbHnsIdAIqzPJhGdK+lSq1DlB6kYkkkSeHBMwBwVqwAK7zX43wuB7edPBmnafDWukqeWVKasjE4qteT9eZPAGicfSXBUce2+5hQSXy/JbXiSeqYDaUYsd8DR93WNI8G3otFhh82Jh+HGQ0OnzAoE5fDoLY5rHUOIt0kvll7h9crxVixmSWjuW0b3qgvFEtOh0lxdnR2SfHh0pNULIkkKZI7GsuVFQ15qF67z2MnF2dzxRFjALj3rQ2sr2js+gBCfnJe+RZmqJHg0ENoOujq5B4W35xW65YkhRy1LSEmjvr0F0vvx9crxVrwILqR5aTB0bag5YoQF+kWnY0Nj7Nb77VEy4a0Y75QLEGrRDwVS9KDVCyJJMswCQ+aCoBz197XLcV9dfYwDhmdTyBs8bP/rCIQ7lpiWNa7P8NZuQrLV0T9vD+A6UzqcfFEPGfZZ2BFujQGkThH3abEx2b99n3Otna3HbXNbKxswmHAIaPz29wXD3lYpnVLIt3C2dkkvJh4wIPZXEVzKJLYR+mLa5agZa+lHYoPlx6kYkmkA8KDoq14rnbWLQGYhsHNX5pEQYaLdRWN/PbtDZ1+Xs/KJ/CtfBwbg7p5f8DKLE76sZGCSViuLMxQA45Yu4RIVzlarVMy7AhmQ+raTTsq3oI3Y2gOOV5Xm/umtlq3JCKpZfirMP0VAIQ7kYQHrdrw/NVsrvZjA7leJ3k+127HDs1RG570PBVLIh3QEvKwLKnjCzPd3PSlaGvCE4t28M76yg4/p6NqDdnv/BSApoOuJjT88I6dwHQQHnIAoFY8SZ3WbXjQtnjqae9vjP5eHT62cLf7psYS8Vbvqicc6R37QYn0F4n1StkjwJ3ZqXMk2vCaKxMteKMLMjAMY7djE/HhmlmSHqRiSaQDWkIelifd0nbYmALOnz0MgF+8vJryhkDyTxgJkPO/KzDCzQRHHEnTnO93eMzQst+Sq/STTj1e5IvMWLFkm9F3f9MV8tAcirBway3Qdr1S3Ig8LzleJ8GIzdpUrB0UkYT4+t3OJuFBy8yS6a9KhDt8MQkvLrFmqa4D/46KdJGKJZEOiOSOwXZmYIT9OKrXJf24780dw6TBWdQ2h7nxpdVErORijDM/ugtn5QosbwH1x90LRud+ZePrllxlCzv1eJE2bBtHXbRYCsVmLc00hTx8urWGQNiiONvDuKLdX2AZhpGIElcrnkhqdTUJD1qn4VWzqSK6H+CoPaxXgrYzS5a2A5AeomJJpCNMB+FB0wBwVrQf8hDndprcevJkvE6TT7bU8Oe317f7GNfWd8lYdD8A9cfe3aF1Sl8ULp6FbZg46rZgNu7s9HlEAIxADWYwWniEhkXbQtPVhhdfrzR3bMEe23agJeRBm9OKpFZXk/AAbG80lMXApqqqHNj7zNKgLA8OA0IRm4qGYKefU6QjVCyJdFAovm4piUS81kYXZPDjY8cDcPf/VvOvz7bv9VijuZrs138IgH/q1wiOmde5wcbY7mwiBZMBcGrdknSRo3YTAJHM4kT7TTra8Gzb5v0Nu0eGf9E0hTyIdIuWJLzOhTsA4HBheXIBaKrdBcCYwj0XS07ToDhH65akZ6lYEumgeMiDq7xjxRLAqdOK+cqsodg23P3Gev70/ibsL7YS2DbZb/4YR+NOwnnjaDj8xlQMu6UVT5vTShfFwx2snFFYOSMAMNNQLK2vbKKsPoDbYXDgyLy9Hhdvw9tU1URDIH0R5yL9ieGvTOyN1NkkvLh4K15WpBaXw0isTdqTRCKeiiXpISqWRDqoTSJeB/ctMgyDa44dx1UnRN+Nn//RFm5/dS3hVmuYvCv/hWfDy9imi/p5vwfXnt9h6yiFPEiqxFvuIrmjoilYgKNpJ4T9PTqOD2KzSrNH5OF1OfZ6XEGGm6E5Hmxg5U7NLomkQmK9Us7ILv87FU/EKzDqGZnvw2HuuaUWWm9Mq5AH6RkqlkQ6KJI/Htvpwwg34ajd2OHHG4bB94+bwPUnjMc04LmlZVz/wgoCYQtHzQay3r0JgMaDf5wozFIhsTltxbIef1Er/Us8CS+SMwrbm4/likYGO+r33lraHd7b2LJeqT1TS6IR4svUiieSEi3rlTof7hAXn1kqMOoYs5f1SnGJjWm115L0EBVLIh1lOggXTQXAuav9zWn35uyZQ7nj1P1wOQzeWlfJD5/6nIxXrsQINxEcdij+/b+VqhEDYGUPJ5JRjGGFce1anNJzy8DiqNsERGeWMIxEK15PhjzUNYdYsj0WGZ5MsRRrxVuhkAeRlGhZr5SCYik2s5RPPaPaKZaGxYslteFJD1GxJNIJiUS8Tqxbau3YCUX87uzpZLodHLXzEbwVi4m4c6g/7j4w995W1CmGQbhkDgBOrVuSLki04eWMjP4/O/r/nly39NGmaiI2jCnIYFjunmOGW4sXS8tK63dfJygiHeaojLbhdSUJL872trTh7S0JL65EAQ/Sw1QsiXRCaFBsc9ryzs8sxc0ekcc/jw3xPefzANxofYNN4fwun3dPQkOixZJLiXjSWeFmzIYyACK5o6P/T8PM0gexFrxkZpUAJhdn4TCgojHILkUOi3SNbSfWLIVjSatdYfkKgWix1G4bXizgoawukPSehSJdoWJJpBPCg+MhD8vBtrp0LiNQy9RPr8XE5j+OY3isYTaX/3NRtyxED8Vmllyln4LeXZdOcNRtxcDGcmUl3g1OtOH10Ma0lm3zwcZqYN+R4a15XQ7GFUXXVmm/JZGuMZt2YQZqsA2TSP64Lp+vwYxGhxdQz8i9bEgbNyjLg9M0CFs25Q0KeZDup2JJpBMi+ROwHR7MUENiz5nOynr7BhwN24nkjGLCefcxaXAW1f4Q3358CR9vrk7NgGPCRVOj4w7U4Khpf2NckS+Kzx5ZOSMhtglsvB2vp9rwVpTVU+0Pkel2sP+wnKQfNzWx31Jddw1NZECIhztEckeDc+8x38kqDUVnk4qdDfj2kWwJ4DANhsRml0rrVCxJ91OxJNIZppNw0X5A10IePKufwbv2OWzDQd0JvyU/r4A/f3kGc0bm0RSK8MNnlvHq6vJUjRocbkLF+wPab0k6J7Ehbe6oxG093Yb3Xiwy/JDR+Tgdyf8zNm1ItLDSzJJI1yRiw1OwXglgc3O0WCoykvvd1Lol6UkqlkQ6KZxYt9S5kAezbitZ79wAQNOBPyQc2wcpy+PkvjOncdzEIsKWzQ0vruSJz3ekZtBAOLZuyVmm/Zak48y6WGx462IpHvAQqMUIdP+sTWK9UpIteHH7xWaWVpY1aK2DSBc4KlcBqYkNB1jfFC1+cuzkiqWhsWJpu+LDpQeoWBLppJbNaTtRLEXCZL/6fcxgPaEhc2iafWWbu91Ok9tOnsLZM0uwgV+/sY4HPtiUkhSv+H5LmlmSznC02mMpwZ2Z2Celu1vxKhoCrNzZAMChHSyWxhRkkOFy0BSKsLGqqTuGJzIgtMSGdz3cAWBVvRsAj+1Pah/AobnxjWlVLEn3U7Ek0kmhwfGZpWUdD3l4715cpZ9gubKoO+G3YDp3O8RhGlx73Hi+eWj0RemDH27hz+93vWAKxWawnDXrMfxVXTqXDDyJ2PBWM0vQqhWvvntb8eLBDlOKsyjKdHfosQ7TYMqQLABWaHNakc6xbRzxJLzC1LThraiCoB1dq2T621+rW5IbX7OkYkm63+6v0EQkKYmQh2AdRfdPwPIVYvmKsH0FWL6ixOdWRhF2/GNfEY6GbfDWHQA0HHVrdKH8XhiGwTcOG0Wmx8G9b21g/sdbidjwvbmjMWKL6zvK9uYTzh+Ps3odrrKFBMec0KnzyABkW632WPpisTQS167FOLp5Zum9WAve3CQjw79o6pBsFm6tZXlZPadNH5LKoYkMCGb9dsxQI7bpIpI7psvnC4QtdtQFqPZkU0wNZnMlVvbQfT4m3oa3QwEP0gNULIl0lsNF86Sz8K34J0YkgKNhB46G5NcWBSacTmDi2Ukde/7s4RiGwT1vrufRBVuxbZsrjhjT6YIpNGROrFj6VMWSJM1sLMOIBLANB1b2sDb3WT0Q8hCKWCyIJUQePrawU+eYWhINeViWikS8SBCzcRdWzvCun0ukj0iEO+SNBYery+fbWu3HBmrIpZiapDoe4gEPO+uaCVs2TrNz/xaKJEPFkkgXNBzzaxrm3oLpr0z8Z/grMP0VmE2V0f/7KzH8rT62QlAwloajb09ELyfjqwcMw2HAr99Yz18/2UbEgh8c1bmCKTxkDqz8F06tW5IOSMSGZw/frXU0EfLQjTNLi7bX0hiMUJDhYkpxVqfOMXVINORhfUUjzaEI3nZiivclc8HdZHz2R2pOfYzQyKM6fR6RviTRgpeiJLxNsfWDza5cCIPZ3H6xVJTlxuUwCEWiey3FiyeR7qBiSaSrXBlYrozEO+v7ZNuYoToKhxRjVzdDB5cffXnWMAzD4K7X1/HYwm3Y2PzwqLEdLpgSIQ+7FkEkCI6Orf2Qgcms3T0JL64lPrz7iqV4ZPihYwowOzmrOjjLTVGmm4rGIKt3NTBzWG6nx+Pe/Fb0/5teU7EkA0ZiZilF65XiYSthbwE0gOmvbPcxpmFQkuNlS7WfHbXNKpakWyngQaQnGQa2J7dLrQvn7j+U644fD8A/Fm7nnrc2dDj0IZI3FsubjxEJRAMqRJKwxyS8mEQbXv1WSEFq4568HyuW5nYwBa81wzCYFosQX9aVkAcrjKN6HQCuTm4fINIXxTekTdXM0uZYsWRmRFtrjebkNmMvyVHIg/QMFUsifdDZM4dy/QkTAPjXZ9u5+431HSuYDINQbL8lV9nC7hii9EOO+B5LewgliWQPw8bACPsx/BUpf+5tNX42V/txmAaHjM7v0rn2i7XidWVzWkftJgwrCICzYhlY4S6NSaRPsCKtYsNTs8fSpqpoVLgnexCQ3MwStKxb2qH4cOlmKpZE+qizZpTws3kTMIAnFu3grtfXdahgikeIu7Q5rSTJsY82PBwerKxoulx3hDzEZ5X2H5ZDlqdrHeTxdUvLuxDyEN+UE8AIN+OoXtulMYn0BWbdlmjIi8OzxxnmjrJsO7FmKTNvcPQ5klizBC17LSkRT7qbiiWRPuz06SX87P8mYgBPLS7lztfXYSVZMIVj65acpZ92W9uU9C+JmaXc0Xu8Px7y0B3rluKR4Yd3oQUvbr8h2RhEX2RVNQU7dQ5nq2IJwLlrSZfHJdLbORPhDhPB7Hw4StzO+gCBsIXTNMgpKAZIev+/eHy4NqaV7qZiSaSPO23aEG78UrRgenpxKb96bW1SBVNo8Axs04WjaRdmfffujSN9nxGow4ytJdjb3mBWN4U8+EMRPttaA8DhndxfqbUsj5PRBRkArOhkK178RaPlygTAVa5iSfq/RLhDylrworNKI/J9GBlFAJhJFksluWrDk56hYkmkHzhl6hBuPnESpgHPLinj9leTKJicPsKDpgHgKlUrnuxbIjbcV4jt3nNsdzwRz6xPbRvegs01BCM2Q3M8jIkVOV21XxdDHuLxyYHxpwCaWZKBIdXhDvH1SqMLMrC80bWISbfhxQIedjUECEeslIxHZE9ULIn0EyftV8wtJ07GNOD5pWXc+sqadgsmhTxIsszaTcCek/Di4sEPqZ5Z+iDegje2sNMbMX/RtK6EPIT9OGLfj8DkLwPgrFgBkVBKxibSW8XbTyOpKpYqozNLowt82L7orLHRXA12+8VPYaYbj9PEsmFng9YtSfdRsSTSj3xpymB+edJkHAa8sHwnlzz2Oa+vKSdi7bloCpXEiiXNLEk7WtYr7b1Y6o42vGDY4r0N0XSsVLTgxU2NzSytKKvvcPS+s3o9hm1hefIIlRyI5c7BiAQS77qL9EuREI6aDUDqN6SNzizFiiU7ghGobfexhmEwJDsWH16rYkm6j4olkX5m3uTB3HryFDxOk5U7G7juhZV8+S+f8sySUgLhtu/WhWMzS47KVRjBLuw5I/2eozbaWren2PC4eMCD2bAdrEiXn3NzVROX/XMRuxqCZLodzB7e+Q1kv2h8USZuh0Fdc5itNR1b8+Coir67Hi6cDIZJePAMAFzli1M2PpHexlG7EcMKYbkysbKHpeScrYslHG4sd/RNDDPZvZa0bkl6gIolkX7o+EmD+Pc3DuKyQ0aS43WypdrPHa+u5fSHFvCXj7dQ3xzdE8bKLCaSMxIDG2fZZ2ketfRm7SXhQfTnyTZdGFYYs6G0S8/30oqdXPT3z1m9q4E8n4s7T90Pr6vr6VtxLofJpMHxVryORYg7K2OL3Auj766HB02P3r5Lm9NK/5X4uS+YBCloh61rDlHVFG1dHVXgA8COzy4ludfSsER8uIol6T4qlkT6qYIMN985fDQvfONgfnT0WIqzPVQ2BvnDe5s49cGP+e3bGyhvCLRat/RpmkcsvVlij6V97a1iOojE3nF2dDLkwR+KcMvLq7npv6tpCkWYPSKXxy48gIO7uBHtnsRb8ZZ3MOTBkYhPngxAaPBMAJxKxJN+LDGjmuLNaAdnucl0R/dOs2LrlpJOxIvHh6tYkm7UtZ39RKTXy3A7OH/2cL68/1BeWVXOXz/ZyobKJv726Tb++dl2bh82gi8DrlIVS7IXkVC0tQ6w9rFmCWKx4rWbMOu2Qgc7ddaWN/DTF1eyqcqPacDlh4ziskNG4jBTE+rwRVM7GfIQf4c9vm4j3oYXDXkIgMOTwlGK9A7O2Jq8SOHklJyvTQteTHzdktmc3MxSSU58zZKKJek+mlkSGSCcDpOTpxbzz4tnc88ZU9l/WA5hy2b+thIAIts/Zen25PrEZWAx67dh2Ba204uVMXifx0ay4yEPyc8s2bbN04t3cMljn7Opys+gLDd/PHcG3zhsVLcVSgDTYjNLq3c1EEoyetgI1uOIFY7xvWas7BFYnjwMK5QopET6G0frDWlTYPMeiiXbVwh0YGPaWBvedhVL0o1ULIkMMKZhcMS4Qh48b38eOm8mxWNmUGf78Nl+7n78BW59ZQ3+UNcX50v/kVivlDOq3bUKkQ4m4tU3h7n+xZX86rV1BCM2h48p4LELD2D2iLwujTkZw3K95HqdhCI2a8obk3qMI75uI3MItjcveqNhtMwuab8l6Y/CzYm4/FTFhm+Mx4YXtp5Ziu+1lNwbd/FiqbwhmPQbHiIdpWJJZACbOSyXu8+cgV0yG4A55hqeX1bGhX/7jNU7G9I8up5l1m7Gs+op3Jtex1GxAqO5BjoYKd1fxWeJ9rleKcaK77VU336xtKy0jq/9bSGvr6nAaRr88Kix3HPmVPIz3F0bcJIMw2C/IR1bt+SMrduIhzvEhQfFiiWtW5J+yNEqLr+92eVkba6Ob0jrS9zWsmYpuTa8fJ8Lj9PEBnbWKz48zrX5TVxb3k73MPoNrVkSEZwjDoKy9/j26HL+u9PN5mo/l/7zc644YgxfPWBYyjYC7W0MfyWedS/gXfPsHjfmtZ0ZRLJKsLKGEskaipVVgpUd/zj6n+3OSsPIe1Yi3CF377HhcfGZJXMfbXiWbfPYp9v4w3ubiFg2Q3O93H7KlMQaop40rSSbDzdVs6KsDhja7vGOyrbhDnEhzSxJP+ZMhDukJgkvGLbYXhMvllq14XljbXjNybXhGYbB0BwvG6ua2F7bzPA8X/sP6uccNRvIffEiMJ1UXvoZtjf14TgDjYolESFUciAAxXWL+cdFs7n1lTW8vb6Se9/awILNNdz4pYkU9NC7/d0u1IRnw8t41jyLe+s7GHa05dA2TMLFsyAcwNGwA7O5CiPchLNmPdSs3+vpwrljqDvp4cT6lf4o0X6TxMxSfB8mR+NOCDeD09vm/qqmIDf/dzUfboq22Rw/cRA3zJtAlic9/xxNHZIDwLKkZ5bahjvEheOJeFWr9vh1i/RlLeEOqWnB21brJ2JDpttBUWbLvy0dnVkCKMn1sLGqSSEPMb4l8zGwwQrhKv2U4JgT0j2kPk/FkogQLp6FbZg46rdREKng16fvx1OLS7nv7Q28v7GKrz66kFtOnMQhowvSPdTOiYRwb30Hz5pn8Wx8BSPsT9wVGjSDwMQzCUw4DSuzuOUxYT+OhlLMhlLMhh3RAqp+R8vHjWWYgVqctRvJeeU7VJ/7Ijj757ua8TVL7SXhQXSfFNuZgRFuwlG/nUj+uMR9y0rruPbfK9jVEMTjNLnqmHGcOX1IWmcu9xsSnRncXO2nvjlMtnff/yzGi6Uvvmi0soZi+Qox/ZU4K1dGC2+RfsKxlzcJOmtTZUu4Q+vffysW8JDsmiWAoYoPTzACtXhXPpH43FX6sYqlFFCxJCLY7izChVNwVSzHvelVmqddxLn7D2XW8FxueHElGyqbuPLpZXxtznC+O3c0LkcfWO5o2zjLFuJd8yyedS9gtmrriOSMonnimQQmntnmxXwbTh+RvLFE8sbu9SnMhh3kP3EyzqrVZH1wKw1H3pbqryL9bBtHbfJrljAMIjkjcFatxqzbkvj+Pr+0lDtfX0coYjMq38evTt2P8YMyu3PkScnPcDMs18v22mZW7Kzn4FF7b1kxmiow/ZXYGITzJ3zhToPwoOm4t7yFs3ypiiXpV1o2pE3tHkut1ysBiZaxZNPwoCXkYUed1ix5Vz6OEW7CNkwM28K1Y0G6h9Qv9IFXPCLSE4Kjjwcg652f4V32dwDGF2Xy6AWzOGdmNF78759u4+v/XMSWav9ez5N2to1nzXMU/H0u+c+cgW/Zo5jNVVi+IpqmX0r12f+m6mvv0XTwNXsvlJJkZQ2l7vh7AfAtfRT3hldS8RX0Koa/IvqPLwaRnOFJPSbSKuQhGLa449W13Pq/tYQiNkePL+QvF8zqFYVS3NQkQx7is0pWzkhwZex2f2Jz2l2LUzxCkTQKNiYCW1I2sxSLDR9V0Pb3KLHPUqghumdZEuIb0+4Y6G14VgTfkkcA8M/6LhALnAn14n+v+wgVSyICQNOcH+Kf/BUM2yL77evI+OgusG28LgfXHj+Bu0/fj1yvk5U7G/ja3xby4vIy7F6WFueoWEHuc+eQ8+oVOOo2Y7kyaZ50NjWn/p3KSz6l8chfEh5yQEoWKMeFRh5N0/7fAiD7jasxG0pTdu7eIB7uYGUNTXqz1XjIQ6BiI99+YgnPLCnFAL5z+GjuPG2/tK1P2pupJcltTuusjC1y38umnPFEPJdCHqQfcVbH1itlDMb2paYVO14sjflCsWR7crENBwBmkrNLJblqwwNwb3oVR/1WLE8ejXN+QCRzCIYVxrXzs3QPrc9TsSQiUQ4XDcfeTeOBPwIgc+FvyX7jKoiEADhqfBH/uGg2c0bk4g9Z3PLyGn7+0ioaAuF0jhoAo7marHduIP+JL+He8TG200vjwT+m8tLPqT/+PkIjjwaz+16gNx5yLaFB0zEDNWS/9n2w+s8+VYk9lpJYrxQXjw9ftHwpS0vryPI4uPfMaVx2yEjMXpisGJ9ZWlZat883ABLrNvZWLMUS8RxVa/RurvQbqW7Bs207USyN/kKxhGFgx2aXjCTXLQ3LadlrKRgeuHst+ZY8DEDz1PPB5SM09GAAXKVqxesqFUsi0sIwaDroauqPuQvbcOBd9SS5/7kYIxh9x31wtoffnzOD784djcOAV1aVc96jC/nbJ1upagr2/HitCN7lj1Hw2JH4lj6KYVs0jzuFqvPfpmnOD/bYKtUtHG7q5/0B25mBe/uHZHz2x5553h6QiA3PaT82HKIvhN6rjLbYDbZ2MrYwg0cvOIDDx/becJBJg7NwmAZVTaF97tWSCHfYSyuSlTkEyzcIw47grFzRLWMV6WmOWBJeqlrwdjUE8YcsHKbB8LzdUyM7moiX63Pic0VfzpYN0L2WHBUrcG//ENtw4J92CQChkoMAtG4pBXpXL4SI9ArN+52PlVFMzivfxr31HXKfPYe6Ux7FyhyCwzS49OCRzBmRx89eWsWO2mZ++85G/vjeJo4eX8gZ00s4cFRet88gOMsWkvXOz3HFNgENF0yi4YhfEBp+eLc+795E8sZSf+St5LxxFRkL7iY4/DDCQ2anZSyp1DKzNLrdYwNhi1+/vo7VyyN8yQNjnRU8cv4sMtyObh5l13hdDiYUZbJqVwMvr9zFhMFZNDSHqQ9E/2sIhKlvDnH7zpW4gGs/tFj+7ic0BMJkuB1cd/yEaDCEYRAaPAPP5tdx7lrSL66/yN4SIDsrPqs0PNeLcw9hQYliqQN7LZXkeNlQ2cSOWj8j8/tnKum+xGeVAuNOwsqO7hcXGhorlsoWghXu1u6K/k7fORHZo+Do46g58ylyX7wYV8Vy8p46ndpT/06kIJoCNn1oDv+6eDb/W7WLZ5eUsbysntfWVPDamgqG5no5Y/oQTp1aTFFWcutckmU0lZP14R14V0XjUS13Nk0HXY1/2sXgcKX0uToqMPlcmre+jXft8+T87wqqv/IKticnrWPqKkdsc1mrnSS8nfUBrv33CpaX1ZPFIACyrHqaacKm5zeb7aipJdms2tXAH97btMf7h1KBz9tE0HbwWnkOIaJtdlVNIX78/HL+eO4MppXkEI4VS67yJQzsFRTSX3RXbPiYwj3P/Cfa8Dqw19LQ3FixNAAT8Qx/Jd41zwHgn/H1xO2RgklYntzoFhflywgX75+eAfYDKpZEZK/Cg2dSffbz5L7wNZy1G8l75gzqTpqf6IX2uRycPr2E06eXsGZXA88tLeO/K3eyo7aZP763ifvf38QR4wo5Y0YJh4zKx2F2YbYpEsK39C9kfHIPZqwt0D/5KzQeeh12xqBUfLldZxg0HHUHrrLPcNRvJevt66k/4fcpDZToaWa8DS937214n2+r5boXVlDVFCLH6+TWkw/Eej0fs7kas24rkaL9emq4nXbK1GI+3lyNbUO2x0mW10m2x0m2x0GWx8n+zdthPTRmjeZXJ84k2+Mk0+3gd+9s5KPN1fzwmWU8eN7+TEok4inkQfo+o7kGR2MZkMrY8D0n4cUl9lrqSHx4fK+lAZiI51v+d4xIgNDgmW1nsw2TUMmBeDa9hqt0gYqlLlCxJCL7ZOWOoubs58l96VJcZQvJ/ff51B1/H8Hxp7Q5buLgLH5y3Hi+f+QYXltTznNLyli8o4631lXy1rpKhmR7OG36EE6bNoTi7I7NNrm2vkvWuzclUplCg2fScMQvemWbk+3JoW7e78l75iy8a58nOOIoAlO+3KNjaAiE+dun26hpCuF1mWS4HGS4Hfha/9/lwOeO/z96jM/lwDAMDKL1nRlqwtG0C4BQ9kiw7TYbSNq2zZOLSrnnrfVELJsJgzK567T9GJ7nI5IzErO5Gkfdlj5RLE0ryeHZrx+01/t9n70M68E3dBpHjitM3H7nafvxvaeWsKy0niueWsJfTp9ILuCoXgvBRnD3noh0kY6Kr1eKZA3FdqdmhnhT9Z73WIqzYnstdWRj2ngi3oCLD48E8S79KwD+GZft9sZcqOSgaLG042P8+38zHSPsF1QsiUi7bF8BNaf9i5xXr8Cz8RVyXvkOjY1l+GdevtuxXpeDU6YO4ZSpQ1hf0cjzS8v4z4qdlNUHeOCDzTz04WYOHV3AyVOLOWJsAV7X3tezuLZ/QMaCe3Dv+AiI7sHReOh1NE85D4zem08THjKbpoOuIfPjO8l+52eES+bsc3PblD53xOIn/17BJ1tqunyuScYWXvFAjZ3JQX9c2ua+eEFlxcLj5k0axM/+byK+2PWMZI/AtWsxjrqtXR5Hb9CSCNa2FSnDHU36++a/FrOxqolvv7STNzKKcTbtxFmxnPDQvRdgIr2dM8XhDgCb9xIbHhefWepQG15O9A24gRYf7ln/HxxNO4lkDCYw/tTd7m9JxPsEbLtPdzmkk4olEUmOy0fdlx4g670b8S19lKz3bsas30Hj4T/ba+EyriiTq44Zx/eOGMObayt4dkkpn22r5f2NVby/sYpMt4PjJw3i5P2KmTksJxoKYdvRIumTe3Dv+BgA23Thn/o1mg66Gtub14NfdOc1HfBdXNvexb39A7Jf+S415zyf9D5FnWXbNr96bR2fbKnB5zI5f/ZwgmELfyiCPxShKWThD0Zoin8ebPl/8x4id0ca0VmlzXbx7s9F9N9ep2nwvSPGcMHsYW1mnazYXktmbM1TX7evdRt5Phe/O2c6l8c2bP4kaxSHshNX+RIVS9KnOauie4ulKtyhIRCmvCGanLq3Nrz4mqVkAx4gumYJGHBrlnyLY3Hh0y4Ch3u3+8ODpmM7vZjNVTiq1yXWHEvHqFgSkeSZDhqOuJVI1jCyPrydjMUP4KjbjH/m5YSGzNlrwILHafKlKYP50pTBbK5q4qUVO3lpxS7K6gM8v7SM55eWMTTbzXdHbuX0usfILv8UANt007zfV2k64HuJhJ99qWsOsWpnA6t2NrClxs8Bw3OZN3kwzq6sleos00H98feR//g8XBXLyPzwThrn3titT/m3T7bx/LIyTANuO3kKR7RqF2tPxLIJhC2s2D5Dtg05S5fDAhg7bgqvHn0oNnaiSLJjB2W4nXtMu4tHjTvq+8HMkhXGWb0OgPBeXjQWZ3v43TnT+ca/FvOBfySHuhZg7Fzck6MUSblUhzvEZ5WKMt173Zy6o9HhACWxNUuVjUGaQ5F9diz0F86yhbh2LcI23finfm3PBznchIpn4d7+Ia7Sj1UsdZKKJRHpGMPAf8B3sbJKyH79KjwbX8Gz8RUsdzah4XMJjjya4KhjsLL2XNyMKsjgO3PH8K3DR/P5tlpeWl5G09o3+XbgSeasj7Z8BHGxuuQMso78EVlFew4WqPVHC6OVO+tZvauBlTsb2P6FfvXnl5bx0IebueyQkXxpSnGPF01WVgn1x/6G3JcuI2PxAwRHHEF49DHd8lxvrCnnd+9uBOBHR4/rUKEE4DCN3YqezKZt0fvyx5CX0bGkwUhsZqk/tOE5ajdjRALYTl9iw909GV2QwW/PnsZjjy8EoHbjp5iW3bVgE5E0irfh7W1vsY7aVBVbr7SXJDwAyxtrw+vAmqUcbzRwpTEYoawusM/z9xe+JfMBCEw8AzujaK/HhUoOihZLOxbQvLeiSvZJxZKIdEpg4plEckbiW/oo7q1vY/or8Wz4L54N/wWi70QGRx1DcOQxhEoO3K1FwAQOsRdxXOO9uMzoi8sgLh4LH8ufw6eyc2MBzs2bmTu2npP2K8bnMlkZmzVatbN+r+0WQ3O9TCnOojjbw3+W72RrTTO3vLyGhz7cwmUHj+Sk/QbvcW+P7hIcMw//9IvxLX2UnNd/RPVXX4UUR2kvL63jxv9G3wH+8v5DOe+AYSk5b8seS/uODd+TeFHhqNvS53vlHbFWpHDBxHbXyk0pzubcE78E//sVQ0LbuO6VRVzzpf3btCiK9AVGUwWmvxIbg3B+amYkNsZmlkbvYy8k2xcPeKhK+m9HfK+ldRWN7Khr7vfFktmwA8/6/wDQ1CoufE9a1i1pc9rOSmuxFAgEuOWWW/jf//6H1+vlsssu47LLLtvjsW+99Rb33nsvW7ZsYfjw4fzwhz/kuOOO6+ERi0hr4SGzqR8yG2wL564luLe8hXvLmzh3fo6zajXOqtVkfP5nLFdmbNbpGIIjj8ZZvYaMT+7FtfNzAGyHB/+0C/HP+g6H2HnUrirnpRU7WVPemEjT25PheV4mD85mSnEWk4qzmDw4i1xfywzItw4bzVOLdvD3T7exvbaZX/5vDQ9/vIVLDxrByVOLcfVQ0dRw2M9w7fgYZ+Uqsl/7IVzyXMrOXVrXzFXPLScQtjh8TAE/OmZcys6diA3fx2zK3kSyh2FjYIT9GP7Kfb7z2dvFwx3CBZOTOn7mhPE0vjOEzOYyNq9cwB+z8vjeEWO6c4giKRffjNbKGQmurm/0GrbsRPDM6L2sV4JokA+AYYUxgnXYntykzj80N1osDYSQB9/Sv2JYYYJDDyYyaOo+jw0Vz8Y2HDjqt2HW70iqpV3aSmuxdNddd7Fs2TIeffRRduzYwbXXXsvQoUP50pe+1Oa4VatWccUVV/CTn/yEo446ivfee48f/OAHPPXUU0yenNw/XiLSjQyTcPH+hIv3p+nAH2I0V+Pe+g7uzW/i3vIWpr8i0a7Xmu304p96EU2zvo2dORiAIuCCOcO5YM5w1pY38NKKXbyxphyHaTC5OFoYTS7OYvLgbLK9+/4TluF2cNFBIzh31lCeXlzK3z7Zyo7aZm57dS3zP97CJQeP5NSeKJqcPurm/ZH8J07EveVt+OgPMPGSLp+2IRDmh88so6opxIRBmdx2yuTUtRpaERz10Ta8SO7ojj/e4cHKLMbRWIajbgvhvlwsxV40dmSRu3Po/rDhZaaZG3h4wVbyfC4umDO8m0YoknqJ9UqFqXmd9cAHm1hRVk+Gy8GR4/fRJuz0YrkyMUONGP6qpIulklgi3o7afh7yEPbjXfEY0HYT2r1yZxIeNA3XrsW4Sj8mkH1mNw+w/0lbsdTU1MSTTz7Jgw8+yNSpU5k6dSpr167lscce261YevHFFznkkEO46KKLABg1ahRvvPEG//3vf1UsifRCtjefwITTCUw4PTrrVLE8Vji9ibNsITjc+KddHC2S9rGh7IRBWfzgqCx+cFTXYrd9LgdfmzOcc2aW8MySUv76yTZK6wLc8epa5n+0hUsOGsFp04bgdnZf0RQpmEjD3FvIfvs6eO0WHIPmEs4b3+nzhSMW17+wkg2VTRRlurn3zGlkulP3J91sKMWwQtimGytzSKfOYeWMjBZL9VsJDzkgZWPraZ1Z5B4eNBPPhpc5u3gXD++A//f2BnJ9Tk6d1rnvpUhPa5lR7fp6pfc3VvHIx9H1izfMm5AIZNgb21sAoUbM5ioskpuVHTpA9lryrnkWs7maSPYIgmP+L6nHhEoOihZLOxYQmKhiqaPStlHJqlWrCIfDzJo1K3Hb7NmzWbx4MZbVNsL2zDPP5JprrtntHPX19d0+ThHpIsMkPGg6TXO+T81Zz1J5+XIqLltK4+E/32eh1B28Lgfnzx7Oc18/kKuOGUdRppud9QHufH0dZz68gCc+30EosnuEdqo0T72A4KhjwQqR+e7N0X78TrBtm1+/sZ6PNlfjdZrcc+bUDm/0257EeqWc4WB2LlkqkogP78MhD+FmHDXR4IyOzCyFBk8HYGJkHRfMjs4o3frKGt7eS0upSG+TmFEtmNil85TVNXPTS9F1f+fuP5R5kwe3+5iWRLzk48PjBVi/bsOz7URcuH/6JUn/bQ7FtjDQuqXOSdvMUnl5Ofn5+bjdLYu+i4qKCAQC1NTUUFBQkLh93Li2Pfhr167lww8/5Lzzzuvw8/aGNbbxMfSGsUjPG/DX35NNur90n9vB+bOHcfbMEp5bUsqjC7ayqyHIr99Yx+Ofb+fqY8Zx+NiC9k/UUYZB45E3437s3ej6rs2vExpzfIdP89jC7TyzpBQDuPWUyew3JLWBEQCOuk0AWLmjOv2zGt9ryVm3pc/+vDtq1mPYESxPLnZmcdJfR2TwDACctRv50bmF1DaHeHH5Tq5/YQXDB2czPnf3PVGk/+szf/9tG0c8Ca9wUqfHG4pY/PTFldQ2h9mvOIsfHT02qXPZvpa9lpJ97mF5LcVSb/3+dvX6u7Z/gLNqNbYrg8DU85I+T3y/N2fVaszm6kSIxkCX7PcvbcWS3+9vUygBic+DweBeH1dVVcWVV17JAQcc0KmAh8LC1L+o6KzeNBbpebr+vcP3huTy9WMm8OSnW7nv9XVsqfbzg2eWcdzkwfz8lP0YXZSZ2icsmgmHfAc++C25H/4CZp0EzuRnhV5ZXsZ9b28A4IaTp3DOId0UHBAsBcBdPIGiok7+rA6NviPtbS7F29lzpNv26AybWTyVokE5HXhgNuSNhJotFIU28P/On0vz3z/jtZU7ufzRT3n2e4cxfnAf/Z5Il/X6v/+12yFYB6aT/PH7g7Nzxf0vX1zB0tJ6crxO7r/4QIbuI9ihjbwhsBmyzQayk/zb4cqMFktVTSEycnxkpLAtOdU6ff1ffRQAY//zKRzWkTWQ2VA0ESrWUNi4DEac1LnnH6DS9pPk8Xh2K4rin3u9e+5lraio4NJLL8W2bX77299imh3vIqysrO9s50vKGEb0F6U3jEV6nq5/73TihEKOGJnLwx9u4R+fbef1Vbt4Z205X5sznEsPHrnHjVc7wzCg8MgfYy36J2bVBhrf+H/4D/huUo9dWVbPD/61GNuGc2aWcPrkIioquqcdOXvnOjxAg3sozZ18Dqc5iDwgUrmR6m4aZ3fL2LyIDMCfM57GDn4N2YXT8dRsoXHtR/izZ3HzvPFU1PlZtL2Orz/yCY9+bdZeN+aU/qmv/P13bf6MXCCcO4aamgDQ8dCEN9ZU8PB70RbWm740CZ8VSfrvVaaRjQ9oqiylqQO/d1keBw2BCMs2VDA21W90pUBXrr9Zu4n81f/FAKonXkikg3+PsgbPwVuxhqbVb9FUdETHnryfil+P9qTtr3RxcTHV1dWEw2GczugwysvL8Xq95OTs/u7dzp07EwEPf/3rX9u06XWEbXd6mUDK9aaxSM/T9e99Mt1Ovn/UWE6bNoTfvBldE/TIx1t5cflOvn/kWP5v8qDU7JfjzaHx0OvJfv0qfJ/ch3/iOYk0wL0pq2vmR88upzlscejofK4+djxgdNvPUOvY8M4+RyQ7Gjlu1m/HjkQ6vfYpnRytFrl39PsQGjwDz/r/4Ni1BNsGj9PBXaftxyX/WMTmaj8/+88qfnPGVMze2jMk3aa3//3vys89wLYaP7e8HD3H1+YM58hxhR06T8TbsmapI48ryfGytryRHbUBxhT2vmIprjPX37v4EQxsgiOPJpw3Djr4+ODQg/Cu+AeuHQt69c9eb5S2gIcpU6bgdDpZtGhR4raFCxcyffr03WaMmpqauPzyyzFNk7///e8UFxf38GhFZCAZXZjBb8+ext2nT2VYrpfyhiA/f2kV33x8Mat3NaTkOQKTzyE0eH/MUCNZH/1qn8c2BsNc9dxyKhqDjC/K5PZTpqQuInxPbBtHoljq+Ia0cVbmEGzThWGFMBt3pmp0PaozseFx4UHRdUuuXUsStxVkuvnzhbNxOwze21DFQx9uTs1ARVKoK+EOgbDFdS+spDEYYebQHL43d3SHzxFfs2Q0Jx/wADAsnojXz0IejGA93pWPA9A08/JOnSNUEt2c1lm+FEJNKRvbQJC2Ysnn83HGGWdw8803s2TJEl577TXmz5+fmD0qLy+nuTn6w37//fezZcsW7rzzzsR95eXlSsMTkW5jGAZHjS/k8Uvm8J3DR+N1mizaXsdFf/+MX722lhp/qItPYNJwxC8A8K56Amdsg97WIpbNwq01XPPcctaWN1KY6ebeM6d2e+uWEajBDNZFx9CJDWkTTAdWVnQDREf9llQMrUcZwfrEXlOdiU8OD4om4jnqNmM0VydunzE8j5+eMAGABz/cwtvrKlIwWpHUadljqeM/9/e+tZ7VuxrI87m47ZQpODuxj53l7XgaHrQk4vW3+HDvyicwQw2E88cTGnFUp85hZQ8nklWCYYUTG8JLctJWLAFcf/31TJ06lYsvvphbbrmFK6+8knnz5gEwd+5cXnrpJQBeeeUVmpubOffcc5k7d27iv9tuuy2dwxeRAcDjNLnskJE8eekcTpg0CMuGpxeXcvb8T3ji8x2Erc73M4SHHEDzpHMAyHr3RrCtRIF01+vrOPmBj/n2E0v4dGstHqfJPWdMZUg7+5OkQmJWKaMYXL4unStebPXF+PBEGlhGMba34+lRtjcvMTPnLF/W5r5Tpg3hK7OiheRN/13Npkq90yu9hG3hjP/sF3RsL8uXV+7i6cXRpM5fnjSp01saWL7oprWmv2NR+yW5/TA+3LbwLn0EAP+MyzofpWcYhEpiEeI7Pk7V6AaEtK4s9fl83HnnnYkZo9ZWr16d+Pjll1/uyWGJiOxmSI6X20+ZwtkzS7j7jfWsq2jk12+s44nPtzNnZB4TB2cxaXAW4woz8LqSX5vTeOj1uDf8F9fOz3n92T/x612zqWxsCb/J9jg5enwhX541lMnFPZOgFd9jycrtfAteXHyvJUddz80sGU3l5PzvCgLjTqR5+iWdPk9LC17nNz8PDZ6Jo24zzl2LCY1ou6j6h0eNZc2uBj7fXsc1zy/nLxco8EHSz6zbihH2Y5tuIh34G7CxsonbX40WWZcdMpJDRnd++wXbG2/Dq27nyLaG9sOZJffmN3DWbsLy5CbeXOus0NCD8a59XvstdZD+KouIdMDsEXn87cIDeGZxKfd/sInN1X42V/sT9zsMGFWQkSieJg7KZOLgLPJ8rjbniVg2i7bX8trqekaGz+BKHuPYHX/il4HfkO3J5ujxhRw3aRAHjczD1Yk2lq5w1EYLm468UNqb+MySowdnljI+/zPu7e/j2rmQwITTOzUrBG0XuXdWeNB0WPdvXOVL8H/hPqfD5I5T9+Oiv3/G5mo/N/13Nb8+fT8FPkhaJWaV8seDmdzLRH8ownUvrMAfspgzMo9vHNq1vx2JTWmDdRAJgiO56PKhudGZrNK6jqf39UrBRjI+uReA5inngSvJ6PW9SMwslS2ESAgcrnYeIaBiSUSkw5ymwZdnDeX/Jg/iw03VrNnVwJryBlbvaqTGH2JDZRMbKpt4eeWuxGOKsz1MGpzFpMGZBDF4cUlpYgbJzTxO97zGSGMnz+73Plnzbu7xAqk1M7YhbVfCHeLiG9P2VBueEajDu/yx6MfhZrzLH8M/+4pOncvZhXUbceH45rStQh5aK8x0c9fpU/nmvxbxzvpKHv5wC984rOvfd5HO6uh6Jdu2ufO1tWyobKIw082tJ03G0cUAGtuTi22YGLaF2VyNlZlcsFd8zVKNP0RTMJKyLR/SwQjWk/viRbh2LcZyZeGf8fUunzNSMBHLk4sZqMVZsYxw8awUjLT/U7EkItJJuT4XX5oymC9NicZ+27ZNeUOQNeUNrNnVyOpYEbWtppmd9QF21gd4Z31LD362x8lR4ws5ftIgMq3b4OXLmbDp71TVX4qV102bzSbB0So2vKsi2bE2vB4KePCu+AdmqAHb4cGIBPAtfQT//t9M+p3p1pyV8USwLs4sAY76bRj+KsjYvTVp6pBsrj1+Ar98ZQ0PfLiZiYOzOGp8YaefE9vGte19rKwSIvnjOn8eGZCclauA5GdU/72sjP+s2IVpwG0nT6Yws3Mb2LZhmNjefAx/ZTQRL8liKcvjJMfrpK45zI66Zsb3wr2WkmE015D7wtdw7VqE5cml9tS/Y2UPTcGJTUIlB+HZ9CquHQtULCVJxZKISIoYhsHgbA+Dsz3MHdvyYrchEGZdeUvxlJnh5pDhuRzYqsXOsv+P4IijcG99m6z3f0HdyY+k68tIrC9KZRue2VAGkQA4OrfgO7knC+Jb/BAADXNvJuOTe3E07sSz7kUCk87q0KkMfyWmvxyAcCfik+NsTw7hvLE4azbgLF9CeNTRezzutGlDWLWzgScX7eCm/67iLxfMYnRB51puvCv/RfabP8Y2HPhnfJ2mg67Cdmd1+mtIt1p/iLBlp+ZFuLSrJdyh/WJpza4Gfv3GegC+ffhoZo/IS9k4LG8hpr8S019FpAOPG5rjpa65gdLavlksGf4qcv99Pq6KZVjefGpP+0fiTZdUSBRLpQvwz/pWys7bn6U1DU9EZCDI8jjZf3guXzlgGDd+aRJ3nDWDw8cWtG21Mwwa5t6MbTqj/5BteSs9g40EMBtKox/mju7y6WxfIbbTh4GNo357l8+3L551L+BoLMPyDaJ5ypdpnn4xQLSA6uAujPF31yM5o7q8TmBP+y3tyY+OHsv+w3JoDEb48fPLaQiEO/xcZs1Gst69CQDDjpCx+AHy/3E07nUv9u5dUPdiRVk9Zzy8gNMfWsCHmzoWIy2dYIVxVK8D2m/DawiEuf7FlQTCFoePKeDig0akdii+6FrDDseH5/bdkAejqZy8586NFkq+ImrOeCKlhRJAaGhs3VLpArCtlJ67v1KxJCLSS0QKJuCPpbdlvXdzdAFuD3PUbcXAxnJlJhKpusQweiY+3LbJ+Px+IBav6/Dgn3ohtsODq3xJh9OfEus2utCCF9eybmnxPo9zOUx+dep+DM5ys6nKzy0vr8bqSIFjhcl57QcY4SaCQw+h9uRHieSMwtFYRu4r3yb3xQsxazZ25UvpUWvLG7jy6aU0BCIEwhZXP7ect9d1LEpaOsZRuxnDCmI7fVjZw/d6nG3b/Oq1tWyp9lOc7eHmEyelPJikJRGvg/HhOdHZ6762Ma3ZUEres+fgrFpNJKOYmjOfIlI4JeXPEx40HdvpxWyuThTGzaEIy0vrqO3q/oH9lIolEZFepOnAH2H5CnFWr8O37NEef/74eiUrZ1Tn9/P4gpb48O4rllzb3sdZuQLb6cM/7WsA2L4CmiedDYBv8YMdOl98vVJXwh3iEsVS+b5nliAa+HDnafvhchi8ta6S+R8lv9YrY+HvcO38DMudTf1x/4/g6OOo+uprNM75Ibbpxr3lLQr+dTwZC+6BcBdfSFphXDs+wrviH9H2yhTbVNnEFU8tpa45zLSSbI6ZUEQoYnPtCyt4bXV5yp9PohxV8fVKE8HY+0vEl1bs4pVV5TgMuP2UKbulfaZCy15LHZtZiseH96VEPLN+e7RQqllPJGtotFDKH989T+Zw01QUXav0zlv/4dJ/fM4xv/+AS/6xiK/97TPK+liR2RNULImI9CK2J5fGg38CQMaCezA6uCljV5mxPZZSsV4pridCHjIW/RkA/5Tz2kSF+2deDoB7wyuYtZuSPl9ij6VUzCwVTcPGwNFQitHU/gv9aSU5XHtc9IXSAx9s5t317f8MOMs+I+OT/wdAw5G3YeXEZgWcPpoOvobqr75GcPgRGJEAmZ/cQ/6/jse19Z0OfR1GsB73uhfJfvX7FM7fn7xnzyH7zZ+Q+eEdHTpPe7bV+PnuU0uoagoxcVAm9501jdtPmcL/TR5ExLK54T8reWnFzpQ+p0Ql3iTYx2a0W6v93PV6dEbim4eNZsbQnG4ZixWbWTKbO1gsxTem7SNteGbdFvKePQdH3WYiOSOpOfPplAb8RCybteUNPLVoBze+tIrTH1rAQ9tKALC3fcSy0nrClo3DNCirD/C9p5a22etPVCyJiPQ6zVPOI1Q0DTNYR+ZHu2/a3Z0SSXgpLJasbm7Dc1Suwr3lLWzDTBRHcZGCiQRHHo2BjW/J/OROaNsdjk/e5+ncWYl3ifcWIf5Fp08v4eyZJdjAz19axeaqpr0fHGwk+7XvY9gRmiecTmDimbsdEskbS+1p/6Bu3h+JZBTjrN1E3r/PJ/uV72A2lu311GbdNrxLHiH33+dT+PAMcl/5Nt41z2AGarDc0RfJvqV/xUzRerSyuma+++QSyhuCjCnM4A/nzCDH68JpGtxy4mROm1aMZcPN/13Nc0tKU/Kc0sKRCHfYc6hJKGLxs5dW0RSKcMDw3JSvU2rNju21ZHRyzdK6ikauf2ElTy3awYbKRuxesGYvELb4fEt1or3WUbOBvGfPxlG/lXDuGGrOeCqx3UJXrNnVwIMfbObKp5Zy3B8+4Py/fsadr6/jvyt3saO2mU+s6N+1ozzruOXESTz79QN57usHMiTbw5ZqP1c8tVQtea0oDU9EpLcxHTQc8Qvynz0L74p/0jztwpQv8t0bR3xmKQV7LMW1tOF1z8xSxqIHAAiOPRFrD0Ve08xv4N7yFt6Vj9N00DXYnn2/E242lGIG67FNJ5G81ERvhwdNx1m9NlYsnZHUY64+ZhzryhtZvKOOS/+xiGkl2UwZks1+xVlMLs5mcJYbwzDIev8XOGs3EckqoeHI2/bePmkYBCacRnDUMWR8fDe+pY/gXfcC7s1v0nTwNdH1coaJc9cS3JtexbPxVZyVK9p+HXljCY4+geCYeYSGzCb33+fj3v4BGZ/cQ8Oxv+nS96i8IcB3n1xCaV2Akfk+/njuDPIyWtq7HKbBDfMm4nKYPL24lNteXUswYvPlWSmIVBag/b3F7v9gMyvK6snxOrnlxEld3k9pXzo7szQyz8ewXC/ba5t5bU05r62JzuYWZLiYNTyXA4bnccCIXMYWZvToBtBNwQjfeXIJK8rqOXZCEbcdYlDwnwtwNO0inD+B2tP/lfR+Uvvy3JJSfvXaWiKtasMMl4NpJdnMHJbDjKE5TC+aif3XuygI7+SUEWGsbB8Afzx3Bt94fDHrKhr5wTPL+MO508l0q1TQd0BEpBcKDz2I5gmn4137PFnv3kjNmc+kbA3RvjhqUxcbHhcPeOiONUtmYxmeNc8C0LT/nmNwQyOOJFwwCWfVarwr/tluXK4ztm4jkjeuU/sz7Ul48AxY80zSM0sQC3w4bT++8a9FbKtp5sNN1Xy4qTpxf0GGiwtyl3F1dXQT3q2H3UWmN6/d89rubBqPuIXmyV8m++3rce38jKz3bsa7/O8YgXocTS0tbrZhEhpyIMExJxAcfcJu+zY1HnIt7qdPx7vqSfz7f5tIwYSkv77WqpuCfO/JpWytaWZojoc/nDOdoj1EhZuGwbXHjcfjNPnHwu38+o11BMIRLjyw+2Y4BoxIAEfNhuiHe5hZ+mRLNX9dEP0dvmHeRIbE1gZ1Fys2s2R2sBXZ7TR54pI5LCur47OttSzcVsvSHXVUNYV4fU0Fr6+pACDPFy2eZg/PZfaIPMYWdV/xFIpY/OTfy1lRVg9A6bqFZGy7A4ddR7hwCjWn/RM7o6hLz2HbNn/+YHNineMho/M5clwhM4bmML4oc7fCNjxoGq5di3Ht+DixtcKIfB+/P2c63358McvL6rnq2eXcd9Y0vK7UbO5b3hDgs621HDOhCLez7zS3qVgSEemlGg+7Ac/G/+Eq/QTP2ucJTDyje5/QtrplZineVmI2V0GwEdyp2/vEt+QRDCtEqOQgwkMO2PNBhoF/5tfJfvMn+JbMxz/z62Du/Z8/R2XqkvDiQoNnAsm34cUVZbp5/OI5rClvYOXOBlaW1bNyZwMbKxsxmyq4OHIvGPBA+GRu/7eDosyPmFycxX7/v707D4+yuts4/n1mn0z2BWQzCAhCgBBAcEMRUXCrKNpaa9UKYl8Xqq1tLbQFq4hKXV63+ipSsVp3QRCriAuKRVCWsGMS9j2B7JnM+rx/TBiNDBAgCyH357pyZeaZZyZnciYw95xzfqd1Ap3T4+iQ4qZDsjvmm51QRhYlI2fiWvNvPAsnY6upjBW2ewicPBjfKRfiP3lIdDpULMGT+uE7ZRjOjR/hWTyFsuHPH9HzAyirDnD72yvZuK+KVvEOnv1p70O+ETcMg7vO64TLZmHaoq08+cVG/KEwo86ov9dsS2Qt2YBhhgg7Egl72tS6raQqwIT/rMcErux9EkNOPbY39nVh1hR4MI5wZAkigalv+2T6tk9mNOAPhlmzq5wl20pYurWU3B1llHgDfJZXxGd5kfCU5LLx837tuHngyRj1GJrCpsnE/6xn0eYS3HYLU84KM+jrB0gyK1lndMY3eDptjzEoBUJhHpj7HR+s2QPAqDNO5tazMg/5PAJtBkbC0s7Ftfah65Lu4cmRvbjtrRUs3VbKH2ev4e9XZNXe6uIImabJB2v28PfP8qnwhZgwvCuXZZ101I/X2BSWRESOU+H4tlT1uwPPoinEf/5HjEAl1T2ua7ARJkvlboyQD9OwEo6vv6lNpiOBsDMZi68Ea/mW+iuH66/EtfoV4OCjSvtVd70Sz8KHsFZsx7HhQ/xdLjvoudHiDvWwXmm/YHoWpmGJjNqU7QTqvkmsw2ahZ5tEerb5fvpgtT+Ie9aNpO8uY7vjFN713IRlX4CiSj8LNuxjwYbabzBbxTvokOLm5JrwdHKKmw4pbtonuSHrenydLsZZ8AGhxA4E2p15RJsHVw78PY6Nc3EWfIBt93KCrfvU+b4VviBj31lFXmElqXF2nr2mN+2S3Ie9n2EY/M85p+CwWXjuq80899VmfMEw/3N2x3p9o9uS7C/uEErrVuvfGNM0uX/udxRW+OmY6ubuwfUzNfVwotPwvMWRPcKOoV8dNgt92ifRp30So86IhIs1u8pZuq2UpVtLWb69lNLqIM99tZntJdWMu6grtnqYYmiaJo99VsDc9YXYLAYvnBvknG9vA6OSlUZXfuH9PZZ3N/PoiPijLpRR4Qvy+1lr+HZLCVYD/nThqVzRq81h7xdoOwByn8e+48BtFXqclMDjV/bkzndW8t+Nxfzlg3U8cGn3o/qd7K30M/njPObXFKrpcVJCrU3bmwOFJRGR41hVnzHYt36JY8fXJHz+R5wbPqB88BTCCfW/TmP/mqJwQnuw1m8p4FDiyVgKS7CWba23sORe+zoWXynBpFPwn3LhoU+2ufH2/CWeb/+XuNwXDhmW6nOPpSh7HKGUUyNBbOdySDvnmB4u+bvXSNg9H9PiwH3V8/wrrTveQIjv9kRGoNbtLmfTPi9bS7yUVQfZU+FnT4WfJVtLaz2OQWRfmsgI1Bl0CnroYqmmS7qVBFfd3iKE0k7D120krvVv4/n6YUqveK1O9/MGQtw9YxWrd5WT5LLxzDW9yUw9sg2AR52RidNm5X/nb+Cfi7biC4a567xOCkxHIfq6T6k9Be+d3J18UbAXu9XggUu7466nKVmHsz8sGWE/RqAC05FQb49tt1rIbpdEdrskfjUQgqEw763axSOf5DN79W6KvQEmX9b9mKef/XPRVt5YtgOAR891c9aSX4GvjEDbgTjOf4F2729i7e4KbntrBX+75LQjHrHbVVbNXTNWUVBURZzdykM/6c6ZHeu2P16gTWRzWlvxdxjVxbWqiALktE9iyhU9+N3M1XzyXRFu+3f8ZVjXI5qqOG99IQ/Ny6O0OojNYjDmrEx+eXqHegmijUlhSUTkeGZzU3rFG7hXvIjn64dxbJlPyusXUHn2BKq7/6xeR5ksDVAJb79wYgcoXFF/RR7CQdy5UwHw9rn1kHvC7OfteSNxS/+BfdcSbLuWxp62Fw5hq6kIVq9hici6Jdu+9bBj2TGFJWtxAfFf3QdA5Zl/ioZPt90afQP4QyXeAFuLI8FpS7GXrcU130u8VPpD7CjzsaPMx6LNJbXu1yreQZcMD13SPdHvHVPjYk7HqRzwO5x57+HY9iX2bV8RaH/2IZ9DdSDE72auZvn2MuKdVp6+uhdd0o9ueub1/dvjsFqY8mk+/16yHV8wzB8u6NKoi/dPBNHX/Q9GVAuKKnlifmQd0x2DTqFbq7qPiB4zuxvT5sYIejG8++o1LP2YzWphZHZbMuKdjHt/LQs27OO2t1bw2JU9j3oPqXdX7OQfX20CYPw5aVy69lYs1cXQNofSy14m1e7huZ8mMX5O5OfdO2sNdw3uxHX9Dr4Z8A+t31PB3TNWUVjhJ93j4Ikre9Ktdd37x3SnEkw5FVtxHvYdi/F3GnbAOWd2TGXSpd350+w1vL96N3F2K/cM6XzYDyNKvAGmfJLP3Jo90U7N8DBxeDe6Nubrpx4pLImIHO8sVrx9xuDPvICET+7GvnspCZ/dg6NgDhXnP0I4/vBTLuri+/VKJ9fL4/3Q/op49VU+3FnwH6zlWwm7Uqk+bWSd7mN6WuHrGilG4M6dSvlJzx5wjrVsc2Qqos0VLXleXwIZvXGteysSlo62uGEoECkTHqzG3/6cyPqrw0h220l22+n1o2k+pmmyryoSpLaUeNm8z8uGvZXkF1ayq9wXHY3678bvi0pYLQaZKe5ogOqU5uGkBCcZCa1xZ/2CuJUv4Vk4mZKrZx80yAdCYe6dvZZvtpQQZ7fy5FW9OK31sb0R/mlOW5w2g0lz83gndyeBUJhxF3Zt0GptJxrb3prCJjUfEviCYf48Zx2+YJgzO6Zwbd92jd6msCsVa8V2LN69MStd1rdzO6fxzNW9+O3M1azcWc7o15bz1NW9aHOExSw+zSvi4Xl5ANwyoDU3bftjpGJlQnusP38DfHFgQpzDypQrsvj7p/m8k7uTxz/fwM4yH3ed1+mQr92Fm/Zx76y1VAVCdEqL43+v6nlUBTcCbQZEwtLO2GEJ4PxT0/nr8G5M/M963ly+A4/Tym3nHHwfqC8K9vLgx3nsrfRjNeDGgScz+oyTj2nNU1NTWBIRaSZCKZ0puWoG7uXP41n8d5xbPsP+2gVUDLoPX7erj3mUyVqzaWt9FnfYr14r4pkm7v2b0Pa6EWyHX+OyX1X2LbjWvYWzYA6V5dsJJ9R+A2itecMYTOkKlvqdbhRs1TtyYceyyBoMjry/4r59AvueXMLOJMoveKxOI2oHYxgGaR4HaR4HfdrXHo2q8AUpKKokvygSnvJrLlf4QmzYW8WGvVXRT433a20ZyGeO14nbs5w333yBba0uICPeQat4J+k131M9du778Du+2rgPp83CY1dmHRDijtYVvdpgt1q478P1zFq1mw17qzi3cxoDMlM4rVV88wtOwWocWz7HWTAHwiGqu/+MQIdzG2bNYsCLpWbUd/+I6lNfbCC/KLKWbMLwbk0yUhd2p0XCUnXx4U+uJ9ntkph6bR/ufGclm4u9jHptOU9e1YsuGXUb+fx2Swl/nrOWsAlX9WrF7yofx77rW8LOJMou/xcpCa3BVx4932aJVHhsm+jiqS838vrS7ewqq+b+S06LOQ1w1spdPPjxd4RM6N8hiUd+klXnKbM/Fmg7APeaV7HvWHTI8y7p0RpvIMRD8/L556KtxNmt3DSw9odJFb4gj35WwPurI9U0T0mNY8LF3cg6qeFGBBuLwpKISHNiseLt+z/4Ow6NjDLtWU7iJ3fjy3+fivMfJuw5+gpD+6fINcg0vITI1BJr+bFPw7PvXIR9Ty6m1Ym3541HdN9Qeg/87c7Gsf0r3CumUXn2X2rd3hDFHfYLpvfANKwYlYV4vvgzvo4XEWh3Rp2LKdh2fkvckqcAqDjvoXotwvFj8U7bAVP6TNNkd7mPgqKqaHjatLeKPRU+iqsC7A4n8WJwOHfaZnLhnhcZvq0rYWKHObvV4O9X9KBfh+TDN8Y0IVgN9sOH4kt6tMZps/DnOetYtbOcVTvLeXbBJhJdNvp3SGZAZjIDM1Nol+Q6Ptc1hfw4tn6JM38Wjo1zsfi/f1Ptyp9FMKUr3t43U91tZJ1+H3X9ma68GRiYhN1pmHHpfFmwN7rWZsLwbqTFKOPeGEx3ZB3N0VTEOxanpMXx4s/7MPadlWzYW8Utbyzn0RFZ9G2ffMj7rd9dwT3vrSYQMjn/1HT+5nkH1/L3MS12yoY/f9DS+oZhcMOADpyU6GTih+v5PH8v//PWCh4bkUVKXOR3b5omz/93M1NrSoNf3L0VfxnW9ZhGbAJtBgJgK1oFgSqwH3zN4MjstlT5Qzz5xUaeWbCJOIeVn+ZEPmxatKmY++d+x+5yHwbwi/7t+fXZHXE2o/Lgh6KwJCLSDIVST6Vk5Ezcy57Ds/gxnJs/+X6UqevIo/r02Rpds9Sxnlv7/ciSpWzrMVe2ci+LlKeuPu2ao9qbxNvnFhzbv8K15jUqT/9trVLmDVE2PMrmJtDuTBzbFuBeOR33yumYtjj8HQbhzxyCP3PIQadUGv4KEueNxTDDVHcbie/Uy+u/fYdhGAYnJbo4KdHF2Z1qLyIPhsIUVfrZt68Tvo8+pWtwO1M6r2aufQiFFX4KKyLT+nzBMHF2K/dfehpn1GEhuqVsG0lzbsS2bz1hZzKhhHaE49sRTmhLKL4d4YR2NcfaEo5rBRYrF3TNoHvrBBZs2Mc3W4r5ZksJZdVBPs0r4tOaMtFtE52cnpnCwMwUTu+QXGvz27owTZPqYBh/MEyiy3ZswSscxL79vzjzZuHc8B8svu+LcITi2+DrfDmYQVxr38RW/B0J8+/F8/Vkqntch7fXTQeMjtbtZ4awb1+IM29mrZ8ZzOhJUYWPv30UWb90Xb92nHVK3QoGNISwK1I17Uj3WqoPrROcvHBtdnRt3Z1vr+T+S7sftAjD1mIvY99dSaU/RL8OSTzW8Rviv/wHAOVDphBof/Zhx5IvOq0VGfFO7nlvNat2lnPza8t54sqetE1yMenjPObUjNrcPLADv66Hyo/hxPaE4ttirdiBfddSAh0OvZbyl6d3oNIf4sWvtzDl0wIshkF+USXv5O4EoH2yiwnDuh0wUt3cGaZpmoc/7cRRVFROUz9jw4D09ITjoi3S+NT/LVtD9L917/rIKFNhZA8fX8eLKB/8EKanVd3b5S8n/YVIoYCiW9ZhOup5IW6wmoz/6xJ5/JtXHHLvnkOxFheQ+u/zMDEovu7zAzZJrRMzTMq/B2Mr2UD5oL9R3fvm6E0p/z4fW3EeJZf9i0Dm+UfVxkMxQl7SixdRvfJ97Js+q7UBLEAwrQe+jhfgz7yAYOuc6FTA+E9+h3vdG4QS2lP8s7mYzvqZutYQ3EufJX7hg4Ti27Hv+i+iI2emaVLhC2G3GnWqMmYp307yzGvqXBTEtNgIe9oQSmhLOL4dwdSuBFvnUJ3emzX7TBZvKWbR5hJW7igjGP7+j88AurWKp//JybjtFir9IbyBEFX+0EEvV/lD7H8Ej8PKyTVl2TNT48j8wfcfP8/o3/+eEmw7FuPMn42zYE6tMBB2Z+DrcinVXX5CsE3/6FRLw1+Oa+0buFf8M7q+0DSs+DsNp6r3KIJtTj/0hxBmGNuupbjyZuLMn4PF+/00ylBca3ynXk5l79Hc/tE+Fm8poWuGh39el9Okm4d6FkwkLncqVX1vo/LMcQ32cyylm4nLfYFARi98p11Ta3prdSDEXz5Yx+f5ezGAP1zQhav71B7VLarwMfr1XLaXVtM1w8PLZ+2j9dxRGGaYygH3UHX6XUDd//3ftLeK38xYxY7SapJcNjqlxbFsexlWA/449FSu7F0/61QBEubegStvJpWn303VgN8d9nzTNHn88w28tnR7reM/7dOWO849pdGqJdaH/f1xOBpZEhFp5kJp3Si5ehZxS/9B3DeP4dw0F/tri/B1HUEosSOhpI6EkjIjRRYOsr7HUlpTNtydVv9BCcDmIhTXGmvVbqxlWwgeZVhyL4+MKvlPuejoghKAYcHbexQJX4wnLvdFqnveGAklIR/Wkkjlr4aYhgdEfv/dL6ciYzBm2MRWtBrH5k9wbPoE2+5l2PauwbZ3DZ4lTxF2peA/eTChhA64172BiUH50P89roMSgLfXr3CveBFrxXbcq16JFqEwDKPOayt+GJRCiZmUXjYdwkGs5duxVOyo+b4dS/mOyJqWip0Y4SDW8q1Yy2uvizMNC+mpXTmzdV+CvXIoP68PiyszWLy1lMWbS8gvqmTdngrW7ak4qudb6Q9FNgze/cP7m3iopkt8gG6JQTp5Apwc56ety4c1vImEvNk4q78PK15bEmuTB7Ms/nxW27OoKIOKr4NU+lZQ6Q9hsxi0T3bRIeUCOvS5mBzfN3Td8m88O/+Ls2AOzoI5BDJ64e09KjLquH9qpxl5jTnzZuLMm4214vs3uGFXCr7Ol+I79SeR6VgWK//6ZiuLt5TgtFmYdGn3Jg1KAOb+8uHehpmGZ/griFvyJO7lUzHCftxAYPWrlJ83mVBGFgAuu5WHLu/BI5/k8+6KnTz8ST5Flf7opq8VviBj313F9tJq2ie7+L/BBq3/c3tkFPi0n1LV/zdH3K6OaXFM+3kffjtzNWt2lbNsexluu4XJl/fg7Hoe6Qu0HYgrb2bM/ZZiMQyDuwd3oioQ4r2VuzgpwclfhnVlQGbK4e/cTGlkqQloZKFlU/+3bA3d/9a9a0n45LfYC1fGvD3kOSkansKJNSEqqSPWvetI/PS3BFr3peTqWfXfMCD5nRHYd31L2UX/OKppZEZVEWkvD8QI+Si+8l2CbQccfWMCVaRNPx2Lr5TSi1/E32kY1qI1pL5xEWFHIntHr26QhfSH6n/DuxfHls9wbP4Mx5bPa03HAqjqezuVZ/6p3tvUEFyrXiFh/r2E3Wnsu/6rIwrglvIdNUFpM6HETEqufOvw67PCISxVu78PT2VbsRWuwr57Wa2AED3dHk+wdR8CrXPYl9ybhb6OLCqMBLk4u5U4u4VEW4Bko4pEw0uiUUk8VXjClbjNCtyhSpyhCqz+MnyVxQQqizG9JVgDZbiCZcSZldgIH7LJpWYcH4VO5/3wGfw3nEXwKD6/7m3fxq9dHzM0OB+H6QfA50yj7LRf4LJbcefPwlZSUOt5+zsNw3fqFfjbD6q1n9ra3eXc/O/lBMMm4y6s39GLo+Va/QoJn9+Lr+NFlF06rf4e2AzjWvsmnq8fjo6wBdqcjrVoDZZAJaZhwdvrV1QNvCdastw0TaYu3MLzCyOjeiN6ncTdgztz14xVLNtWSprHwfTLM+g+96dYq3bjbz+I0stervU7PtJ//72BEJM/ziOvsJIJw7sec9XIWKx715P6+gWYNjdFo9fUeY890zRZtbOczuke4hzNZzTphzSyJCLSAoXSulMychbOgvex7V2PpXQT1rLNWEs3YfGXY63chbVyF+z4Ovb9G6Bs+PeP3QH7rm+xHGWRB/fKlzBCPgKt+kSmHB0LexzVWb8gbumzuHNfwN9p2A+KO5zWMBXHDsN0p+HrdnWksmE4iH3XEhybP8G+ZT7h+HZU1mGKzPGiuvvPcC9/DlvpJty5U6PTkA7ngKA0og5BCcBijaxbim9LkP61b6rcjW33Muy7l9Z8z8USqMCxbQGObQvwAB2AkQntwbBi+MswfGUYZqhObT5UDAwbNny2RCqMeEpND0UhN9vDKSy0ns4qVz8cTjfxTivnO2x4HFY8DhvxTiseZ+R6vCNyuToQZltJZG+syPdqdpVVsyLQntsCvyKFkfzc+hm/tH1MG99eMnKfjLah2rTzpdGPT63n8K21P8YON849Vpy2NThtVpw2C06bheXbSwmGTYacms6IXkdfKKY+7d+Y1lKPBR5sOxYTv2BC9AOlYNIpVJ4zAX/mBVgqd+H56n5c+bOIW/Eizvz3qTznr/i6/ATDMLjlrEzSPHYe/iSfmSt3MT9/L8XeAB6HlWcuz+S0L67HWrWbYGo3yob/3zFv7u22W/nbJafVx9M+qFDqqYSdyVh8JdgKV8befy4GwzDqrZLl8U5hSUTkRGO14+t6Jb4fHjNNjOpirD8IT9bS779HP109zGaix+KYyocHvLhXTQegKufX9RJmvL1uwr38eRw7vsZWuApbQxZ3OFIWG4G2Awm0HQgNuFajwVjtVA38PYlzb8e9/P/w9roR03XoaTqWihhBKeHYK/6FPa3xdxqOv9PwmgNBrPu+i4SnXcuw716Grfg7rOXbDrivaVgxnYmYjkTCjoSaywmYzqTIdUcCpiuZsDMJs+YrHP2eDDZX9LWaBCQbcEZ6AufVw8iyPxhmR1k122o2G95Wchr3FF9P532fMdT3MT7TzpzQGcwL96WC/VXOwkDlQR+zVbyDcReeetxUCjTdkQIPRj0UeLCUb8fz30m48iMj52FHAlX978Lb+1dgjVScC8e3oXzYs1T3uJb4+eOxlW4kce7t+Ne8RsW5kwildOaq7LakxjkYP2ctxd4ADqvBYz/pSt9vx2Lbt55QXGtKL3v5uJ8uG2VYCLQZEJm+vXNxncNSS6KwJCLSEhhGZMd2d2rs/wz9lVj8ZfW2wW0s4YTIxrRHE5Zc69/GUl1MKPHk79/0Hmt74tvi63wprrz3cOe+gOErAyDYUOuVWhhfl8sJLH0We9Fq4pY8fUCZ9h+yVOwgecb+oHQyJSPerJegFPuH2Qil9yCU3gOyrgfA8JVh27v2B+EogbAzKbLG7DgJDj/msFnomBpHx9Qfl3vOIRi6iwp/iFuCYW4IhvEFw/iCoUgFv1AYX2D/sTDVNbcFwybnd0knyX1soyH1qV5GlgJVxC19hrhlz0U2nMagusd1VA78/UGraQY6nEvxz+cRt+w54r59Ese2BaS8PpSqnP+hqt+dDD41nWev6c1Li7dyTXYbzs1/EMe2LzFtcZRd9tLRVShsQoG2kbDkzH8fX+dLCddsIi4RCksiIgIOD2FH3TZdPFqhmv+ALXWsbhYVDkULO1RljwZL/f3X5c2+BVfeezjzZkXXJoSOh5GlE4FhoWrgH0iacyPulS/hzR4Vc0qdpWInSTN/+oOg9Fajv9k0nYmRUbwThM1qIdnd/Pe4CdcUgrH4SiEcPLK/fdPE+d0MPAsfjEw9BvztzqTinPsiQflwrE6q+v+G6lNHEP/lX3Bu/hTPkidxfTeDinPvJ7vjUB6/Mom4b56IFGAxLJQN+wfBjF5H81SblP/k8zG/fgj7nuWkvnJ2pMJi9i0ET+p/3H5Y0JgUlkREpFFEp+GVbwczXKs876E4Nn2MrXQjYWcS1af9rF7bFGzdh0CbAdh3Lo5ufHlcTMM7Qfgzh0R/v3HfPEHF+Y/Uuj0SlK7BVrqJUEIHSq54s9l9Ki8Nx3QmY2JgYOLOnRopFGJYMA1r5N8Pw4Cay5FjBhgWjFAQd+4L2HcvBSCU0IGKs/+Mv9MlR/zmP5yUSdml03Fs/JD4LydgLd9K0pyb8J0yjEDbgXgW/x2AinMn4e94Qb3/DhpDKK0bpT/5N3FLnsGxdT7Ogg9wFnxAoFU23j5j8HW65JjXXzVnCksiItIowvFtMA0rRthP+nOdMW0usLowbfu/3LD/cs1xbC5sO78BwNvzhlobyNaXquzRJO2MlM0NxbU66j2gJAbDoOKMe0mZcRWutW/gzfk1oeROwPcjStGgNOItwontm7jBclyxWAnHZWCt2kP8fx844rubtjgq+4/Fmz06sn7saBkG/k4Xs6/9uXi+fQJ37gs4N36Ec+NHQGQdZXXPXx794x8HAu3OorTdWVj3rsOdOxXXdzOw78nFPvd2QvFt8Pb6FdU9rsN0JTd1UxudSoc3AZWObtnU/y1bS+//xA9GRd9gHAnT4mDfDQsJe1rXf6PCIVJfHYS1bEuk3O8Vr9X/z6jRUvs/8f0bcW7+hOouP6F82LNYKneRNOMabKUba4LSmy1inURL7f9j4SiYgytvVmQ0+gdfhhkC0wQz9INj+28PEUzvSdXpdzXIvxnWveuJ/2Icjh2LIq/pi56u00h5c+p/o6oI9+p/4V45HYu3CIiEz+ru1+DtPSr6oUdzVtfS4QpLTaA5/bFI/VP/t2wtvv9rqvIZwWqMUDUEqzGC3sj1YDWEqqOXf3g90GYAgQ6DGqxZrjWvk/DZPVSc9We8Ob9usJ/TUvt//x5WAKWXTsfz1X3YSjYQSmhfM6J04gclaLn9f0IyTSylmwgndazz1L5m2f/Bapx57xGX+wK2vesAMDHwd7wQb/YoQokdMII+CPkxQtUYoZrLQV/N5cj3yDk+TLuH6tOuAfuPC5M0PoWlgzgeXqDN8o9F6o36v2VT/x+/LBU7I59C13Et1dFoyf2fMPcOXHkzo9dbWlCClt3/0sz73zSxb1sQmYK4+dNjeqiyoU9E9pNrYtqUVkRE5Ag0ZNl0gcqB9+AseB8jHCQU367FBSWRZs0wCHQYRKDDIKzF+bhzX8SZ9x5GOIBpdWJanWBzfn/Z6sC0OcHqrHV72J2OP7N5FcJQWBIREZEGF07qSOWZ43Fs/pTy8x9WUBJppkIpXagYPJmKwZObuimNQmFJREREGoW3zy14+9zS1M0QEamz5r9jmYiIiIiISANQWBIREREREYlBYUlERERERCQGhSUREREREZEYFJZERERERERiUFgSERERERGJQWFJREREREQkBoUlERERERGRGBSWREREREREYlBYEhERERERiUFhSUREREREJAaFJRERERERkRgUlkRERERERGJQWBIREREREYlBYUlERERERCQGhSUREREREZEYFJZERERERERiUFgSERERERGJQWFJREREREQkBoUlERERERGRGBSWREREREREYlBYEhERERERiUFhSUREREREJAaFJRERERERkRgUlkRERERERGJQWBIREREREYlBYUlERERERCQGhSUREREREZEYFJZERERERERiUFgSERERERGJQWFJREREREQkhiYNSz6fj3HjxtG/f3/OOeccpk2bdtBz16xZwzXXXEN2djYjR45k1apVjdhSERERERFpaZo0LD3yyCOsWrWK6dOnM2HCBJ5++mk+/PDDA86rqqpizJgx9O/fn3fffZecnBxuvfVWqqqqmqDVIiIiIiLSEjRZWKqqquKtt95i/PjxZGVlceGFFzJ69GheffXVA8794IMPcDqd/OEPf6Bz586MHz8ej8cTM1iJiIiIiIjUhyYLS+vWrSMYDJKTkxM91q9fP3JzcwmHw7XOzc3NpV+/fhiGAYBhGPTt25fly5c3ZpNFRERERKQFsTXVDy4sLCQlJQWHwxE9lp6ejs/no6SkhNTU1FrndunSpdb909LSyMvLO+Kfa7GAaR59u+tDTeY7LtoijU/937Kp/1s29X/Lpv5v2dT/x5f9/XE4TRaWvF5vraAERK/7/f46nfvj8+oiNTXhiO/TUI6ntkjjU/+3bOr/lk3937Kp/1s29X/z0mTT8JxO5wFhZ/91l8tVp3N/fJ6IiIiIiEh9abKw1Lp1a4qLiwkGg9FjhYWFuFwuEhMTDzi3qKio1rGioiJatWrVKG0VEREREZGWp8nCUvfu3bHZbLWKNCxZsoRevXphsdRuVnZ2NsuWLcOsmeBpmiZLly4lOzu7MZssIiIiIiItSJOFJbfbzYgRI5g4cSIrVqxg3rx5TJs2jRtuuAGIjDJVV1cDMHz4cMrKypg0aRL5+flMmjQJr9fLxRdf3FTNFxERERGRE5xhmk1Xj8Pr9TJx4kTmzp1LfHw8o0aN4qabbgKgW7duTJ48mauuugqAFStWMGHCBAoKCujWrRv33XcfPXr0aKqmi4iIiIjICa5Jw5KIiIiIiMjxqsmm4YmIiIiIiBzPFJZERERERERiUFgSERERERGJQWGpkfl8PsaNG0f//v0555xzmDZtWlM3SRqB3+/nsssuY9GiRdFjW7du5aabbqJPnz5ccsklLFiwoAlbKA1h9+7djB07lgEDBjBo0CAmT56Mz+cD1P8twebNmxk1ahQ5OTkMHjyYqVOnRm9T/7csY8aM4d57741eX7NmDddccw3Z2dmMHDmSVatWNWHrpCF8/PHHdOvWrdbX2LFjAfV/c6Ow1MgeeeQRVq1axfTp05kwYQJPP/00H374YVM3SxqQz+fjt7/9LXl5edFjpmly++23k56ezjvvvMMVV1zBHXfcwY4dO5qwpVKfTNNk7NixeL1eXn31VR5//HE+++wznnjiCfV/CxAOhxkzZgwpKSnMmDGD++67j3/84x/Mnj1b/d/CzJkzh/nz50evV1VVMWbMGPr378+7775LTk4Ot956K1VVVU3YSqlv+fn5nH/++SxYsCD69cADD6j/myFbUzegJamqquKtt97ihRdeICsri6ysLPLy8nj11VcZPnx4UzdPGkB+fj6/+93v+HHRya+//pqtW7fy+uuvExcXR+fOnVm4cCHvvPMOd955ZxO1VurThg0bWL58OV999RXp6ekAjB07locffphzzz1X/X+CKyoqonv37kycOJH4+Hg6duzImWeeyZIlS0hPT1f/txAlJSU88sgj9OrVK3rsgw8+wOl08oc//AHDMBg/fjxffPEFH374YXS7FGn+CgoK6Nq1KxkZGbWOv/322+r/ZkYjS41o3bp1BINBcnJyosf69etHbm4u4XC4CVsmDWXx4sUMHDiQN954o9bx3NxcevToQVxcXPRYv379WL58eSO3UBpKRkYGU6dOjQal/SoqKtT/LUCrVq144okniI+PxzRNlixZwjfffMOAAQPU/y3Iww8/zBVXXEGXLl2ix3Jzc+nXrx+GYQBgGAZ9+/ZV/59gCgoK6Nix4wHH1f/Nj8JSIyosLCQlJQWHwxE9lp6ejs/no6SkpOkaJg3muuuuY9y4cbjd7lrHCwsLadWqVa1jaWlp7Nq1qzGbJw0oMTGRQYMGRa+Hw2FeeeUVzjjjDPV/CzNkyBCuu+46cnJyGDZsmPq/hVi4cCHffvstt912W63j6v8Tn2mabNy4kQULFjBs2DCGDh3K3//+d/x+v/q/GdI0vEbk9XprBSUget3v9zdFk6SJHOy1oNfBiWvKlCmsWbOGt99+m5deekn934I8+eSTFBUVMXHiRCZPnqy//xbA5/MxYcIE/vrXv+JyuWrdpv4/8e3YsSPaz0888QTbtm3jgQceoLq6Wv3fDCksNSKn03nAH8P+6z/+x1RObE6n84DRRL/fr9fBCWrKlClMnz6dxx9/nK5du6r/W5j961V8Ph/33HMPI0eOxOv11jpH/X9iefrpp+nZs2et0eX9DvZeQP1/4mjXrh2LFi0iKSkJwzDo3r074XCY3//+9wwYMED938woLDWi1q1bU1xcTDAYxGaL/OoLCwtxuVwkJiY2ceukMbVu3Zr8/Pxax4qKig4Ympfm7/777+e1115jypQpDBs2DFD/twRFRUUsX76coUOHRo916dKFQCBARkYGGzZsOOB89f+JY86cORQVFUXXKO9/c/zRRx9x2WWXUVRUVOt89f+JJzk5udb1zp074/P5yMjIUP83M1qz1Ii6d++OzWartYhvyZIl9OrVC4tFXdGSZGdns3r1aqqrq6PHlixZQnZ2dhO2Surb008/zeuvv85jjz3GpZdeGj2u/j/xbdu2jTvuuIPdu3dHj61atYrU1FT69eun/j/B/etf/2L27NnMnDmTmTNnMmTIEIYMGcLMmTPJzs5m2bJl0SqppmmydOlS9f8J5Msvv2TgwIG1RpDXrl1LcnIy/fr1U/83M3qH3ojcbjcjRoxg4sSJrFixgnnz5jFt2jRuuOGGpm6aNLIBAwbQpk0b/vSnP5GXl8fzzz/PihUruPrqq5u6aVJPCgoKePbZZ7nlllvo168fhYWF0S/1/4mvV69eZGVlMW7cOPLz85k/fz5Tpkzh17/+tfq/BWjXrh2ZmZnRL4/Hg8fjITMzk+HDh1NWVsakSZPIz89n0qRJeL1eLr744qZuttSTnJwcnE4nf/7zn9mwYQPz58/nkUceYfTo0er/Zsgwf7wBjDQor9fLxIkTmTt3LvHx8YwaNYqbbrqpqZsljaBbt268/PLLDBw4EIDNmzczfvx4cnNzyczMZNy4cZx11llN3EqpL88//zyPPvpozNvWr1+v/m8Bdu/ezf3338/ChQtxu91cf/313HrrrRiGof5vYe69914AHnroIQBWrFjBhAkTKCgooFu3btx333306NGjKZso9SwvL48HH3yQ5cuX4/F4uPbaa7n99tsxDEP938woLImIiIiIiMSgaXgiIiIiIiIxKCyJiIiIiIjEoLAkIiIiIiISg8KSiIiIiIhIDApLIiIiIiIiMSgsiYiIiIiIxKCwJCIiIiIiEoPCkoiIiIiISAy2pm6AiIhIXQwZMoTt27fHvO3ll19m4MCBDfJz7733XgAeeuihBnl8ERE5fiksiYhIszFu3DguueSSA44nJSU1QWtEROREp7AkIiLNRkJCAhkZGU3dDBERaSG0ZklERE4IQ4YM4aWXXuLyyy+nT58+jBkzhsLCwujtBQUFjBo1ir59+zJo0CCefvppwuFw9Pb33nuP4cOHk52dzbXXXsuaNWuit1VUVHD33XeTnZ3N4MGDmT17dqM+NxERaRoKSyIicsJ46qmnGD16NG+88QZer5c777wTgH379nHdddfRqlUr3nrrLSZMmMArr7zCyy+/DMCXX37J+PHjufHGG5k1axY9e/bk1ltvxe/3A/Dxxx+TlZXF+++/z8UXX8y4ceMoLy9vsucpIiKNwzBN02zqRoiIiBzOkCFDKCwsxGarPYO8bdu2zJkzhyFDhjB06FDGjRsHwNatWxk6dCizZ8/m66+/Ztq0acybNy96/9dee41nnnmGBQsWcMcddxAfHx8t4uD3+3n88ce5+eabefTRR9m0aROvv/46AOXl5fTv358333yT7OzsRvwNiIhIY9OaJRERaTbGjh3LRRddVOvYD8NT3759o5c7dOhAcnIyBQUFFBQUkJWVVevcnJwcCgsLKSsrY+PGjVx77bXR2xwOB3/84x9rPdZ+CQkJAPh8vvp7YiIiclxSWBIRkWYjLS2NzMzMg97+41GnUCiExWLB6XQecO7+9UqhUOiA+/2Y1Wo94JgmZoiInPi0ZklERE4Y69ati17evHkz5eXldOvWjVNOOYXVq1cTCASity9btozU1FSSk5PJzMysdd9QKMSQIUNYsmRJo7ZfRESOLwpLIiLSbJSXl1NYWHjAV1VVFRDZnPaTTz5h3bp1jBs3jrPPPpuOHTty+eWX4/f7+etf/0pBQQHz5s3jqaee4uc//zmGYfDLX/6SWbNmMWPGDDZv3szkyZMxTZOsrKwmfsYiItKUNA1PRESajQcffJAHH3zwgOO/+c1vALjyyit57LHH2LFjB+eddx733XcfAPHx8UydOpVJkyYxYsQIUlNTufHGG7n11lsBOP3005kwYQLPPPMMhYWF9OzZk+eeew6Xy9V4T05ERI47qoYnIiInhCFDhnDHHXdw1VVXNXVTRETkBKFpeCIiIiIiIjEoLImIiIiIiMSgaXgiIiIiIiIxaGRJREREREQkBoUlERERERGRGBSWREREREREYlBYEhERERERiUFhSUREREREJAaFJRERERERkRgUlkRERERERGJQWBIREREREYnh/wFCYe2KbThezAAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.set_style('darkgrid')\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.plot(history['loss'], label='train')\n",
    "plt.plot(history['valid_mse'],label='validation')\n",
    "plt.ylim(0,1)\n",
    "plt.title('Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f8bec9e9efeda165029d081619199fa95bb45532afd075062965979786e87119"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
