{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 1038893\n",
    "\n",
    "fix_random(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "root = \"../../data/ml-25m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Acquisition\n",
    "def get_data_from_csv(file: str, nrows=None):\n",
    "    if nrows:\n",
    "        df = pd.read_csv(f\"{root}/{file}\", nrows=nrows)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{root}/{file}\")\n",
    "    print(f\"Loaded ml-25m data: {root}/{file}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_from_csv(nrows=None):\n",
    "    path = \"ratings.csv\"\n",
    "\n",
    "    data = get_data_from_csv(path, nrows)\n",
    "    # data = get_data_from_csv(path)\n",
    "\n",
    "    data.drop(\"timestamp\", axis=1, inplace=True)\n",
    "    # todo: drop user id\n",
    "    #data.drop(\"userId\", axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ml-25m data: ../../data/ml-25m/ratings.csv\n",
      "          userId  movieId  rating\n",
      "0              1      296     5.0\n",
      "1              1      306     3.5\n",
      "2              1      307     5.0\n",
      "3              1      665     5.0\n",
      "4              1      899     3.5\n",
      "...          ...      ...     ...\n",
      "25000090  162541    50872     4.5\n",
      "25000091  162541    55768     2.5\n",
      "25000092  162541    56176     2.0\n",
      "25000093  162541    58559     4.0\n",
      "25000094  162541    63876     5.0\n",
      "\n",
      "[25000095 rows x 3 columns]\n",
      "Loaded ml-25m data: ../../data/ml-25m/genome-scores.csv\n",
      "          movieId  tagId  relevance\n",
      "0               1      1    0.02875\n",
      "1               1      2    0.02375\n",
      "2               1      3    0.06250\n",
      "3               1      4    0.07575\n",
      "4               1      5    0.14075\n",
      "...           ...    ...        ...\n",
      "15584443   206499   1124    0.11000\n",
      "15584444   206499   1125    0.04850\n",
      "15584445   206499   1126    0.01325\n",
      "15584446   206499   1127    0.14025\n",
      "15584447   206499   1128    0.03350\n",
      "\n",
      "[15584448 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_tag_relevances_from_csv(nrows=None):\n",
    "    path = \"genome-scores.csv\"\n",
    "\n",
    "    return get_data_from_csv(path, nrows)\n",
    "genome_scores_path = \"genome-scores.csv\"\n",
    "ratings_path = \"ratings.csv\"\n",
    "ratings = get_ratings_from_csv()\n",
    "print(ratings)\n",
    "genome_scores = get_tag_relevances_from_csv()\n",
    "print(genome_scores)\n",
    "# films = get_data_from_csv(f\"{root}/{ratings}\")[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA VISUALIZATION\n",
    "\n",
    "            # # Fill in missing values with zeros\n",
    "            # X.fillna(0, inplace=True)\n",
    "\n",
    "# FARE TEST CON AVG, STD_DEV\n",
    "def addColumnOperation(ratings,X):\n",
    "     # Compute the mean rating for each user\n",
    "     count_rating = ratings.groupby('movieId', as_index=False)['rating'].count()\n",
    "     std= ratings.groupby('movieId', as_index=False)['rating'].std()\n",
    "     std.fillna(0, inplace=True)\n",
    "     min_ratings= ratings.groupby('movieId', as_index=False)['rating'].min()\n",
    "     max_ratings= ratings.groupby('movieId', as_index=False)['rating'].max()\n",
    "     median= ratings.groupby('movieId', as_index=False)['rating'].median()\n",
    "     operation = pd.DataFrame({'movieId':count_rating['movieId'],'count_rating': count_rating['rating'], 'std': std['rating'], 'min': min_ratings['rating'], 'max': max_ratings['rating'], 'median': median['rating']}) \n",
    "     X = pd.merge(X, operation, on='movieId')\n",
    "     X.drop(\"movieId\", axis=1, inplace=True)\n",
    "     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "           \n",
    "\n",
    "class Model:\n",
    "    def __init__(self, ratings, relevance, seed=42):\n",
    "        self.aug = RegressionSMOTE(p=0.2)\n",
    "        #! df['rating'] = df['rating'].astype('float16')\n",
    "\n",
    "        # Reduce genome-score size\n",
    "\n",
    "        # Pivot the relevance DataFrame to create a matrix of tag relevance scores for each movie\n",
    "        relevance_matrix = relevance.pivot_table(index='movieId', columns='tagId', values='relevance', fill_value=0)\n",
    "        # Merge the ratings and relevance data\n",
    "        mean_ratings = ratings.groupby('movieId', as_index=False)['rating'].mean()\n",
    "        X = mean_ratings.merge(relevance_matrix, on='movieId')\n",
    "        #X = addColumnOperation(ratings,X)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        ratings = None  \n",
    "        train = X\n",
    "        # mescolare le righe del DataFrame\n",
    "        #X = X.sample(frac=1).reset_index(drop=True)\n",
    "        \n",
    "        if \"Set\" not in train.columns:\n",
    "            train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "\n",
    "        features = [ col for col in train.columns if col not in [\"rating\", \"Set\"]]\n",
    "        target = \"rating\"\n",
    "        \n",
    "        train_indices = train[train.Set==\"train\"].index\n",
    "        valid_indices = train[train.Set==\"valid\"].index\n",
    "        test_indices = train[train.Set==\"test\"].index\n",
    "\n",
    "        self.X_train = train[features].values[train_indices]\n",
    "        self.y_train = train[target].values[train_indices].reshape(-1, 1)\n",
    "\n",
    "        self.X_valid = train[features].values[valid_indices]\n",
    "        self.y_valid = train[target].values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "        self.X_test = train[features].values[test_indices]\n",
    "        self.y_test = train[target].values[test_indices].reshape(-1, 1)\n",
    "        \n",
    "\n",
    "        print(self.X_train)\n",
    "        # Split the training data into training and validation sets    \n",
    "        self.clf = TabNetRegressor(seed=SEED)  #TabNetRegressor()\n",
    "        \n",
    "    def train(self):\n",
    "        self.clf.fit(\n",
    "            X_train=self.X_train, y_train=self.y_train,\n",
    "            eval_set=[(self.X_train,self.y_train), (self.X_valid, self.y_valid)],\n",
    "            eval_name=['train', 'valid'],\n",
    "            eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "            max_epochs=150,\n",
    "            patience=20,\n",
    "            batch_size=1024, virtual_batch_size=1024,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            augmentations=self.aug, #aug\n",
    "        ) \n",
    "\n",
    "    def test(self):\n",
    "        # Predict the labels of the test set: y_pred\n",
    "        y_pred = self.clf.predict(self.X_test)\n",
    "\n",
    "        # Compute the mean squared error\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        rmse = mean_squared_error(self.y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(self.y_test, y_pred)\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "\n",
    "        print(f\"MSE: {mse} RMSE: {rmse} R2: {r2} MAE: {mae}\")\n",
    "        print(\"=====================================\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.00000e+00 2.87500e-02 2.37500e-02 ... 2.97500e-02 8.47500e-02\n",
      "  2.20000e-02]\n",
      " [2.00000e+00 4.12500e-02 4.05000e-02 ... 1.10000e-02 1.05250e-01\n",
      "  1.97500e-02]\n",
      " [3.00000e+00 4.67500e-02 5.55000e-02 ... 1.80000e-02 9.10000e-02\n",
      "  1.77500e-02]\n",
      " ...\n",
      " [2.05383e+05 4.10000e-02 4.02500e-02 ... 2.90000e-02 1.17250e-01\n",
      "  3.92500e-02]\n",
      " [2.05425e+05 4.52500e-02 4.12500e-02 ... 1.50000e-02 1.10500e-01\n",
      "  2.85000e-02]\n",
      " [2.06499e+05 1.00500e-01 9.32500e-02 ... 1.32500e-02 1.40250e-01\n",
      "  3.35000e-02]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "model = Model(ratings, genome_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 11.67023| train_rmsle: 0.30197 | train_mae: 1.78833 | train_rmse: 1.85349 | train_mse: 3.43544 | valid_rmsle: 0.30387 | valid_mae: 1.79529 | valid_rmse: 1.85979 | valid_mse: 3.4588  |  0:00:11s\n",
      "epoch 1  | loss: 3.34823 | train_rmsle: 0.12104 | train_mae: 1.21853 | train_rmse: 1.30273 | train_mse: 1.6971  | valid_rmsle: 0.12201 | valid_mae: 1.22289 | valid_rmse: 1.30869 | valid_mse: 1.71266 |  0:00:22s\n",
      "epoch 2  | loss: 1.09356 | train_rmsle: 0.05416 | train_mae: 0.83401 | train_rmse: 0.92877 | train_mse: 0.86261 | valid_rmsle: 0.05436 | valid_mae: 0.835   | valid_rmse: 0.93227 | valid_mse: 0.86913 |  0:00:35s\n",
      "epoch 3  | loss: 0.52863 | train_rmsle: 0.02066 | train_mae: 0.50827 | train_rmse: 0.59618 | train_mse: 0.35543 | valid_rmsle: 0.02058 | valid_mae: 0.50914 | valid_rmse: 0.59875 | valid_mse: 0.35851 |  0:00:45s\n",
      "epoch 4  | loss: 0.34933 | train_rmsle: 0.01448 | train_mae: 0.41231 | train_rmse: 0.49493 | train_mse: 0.24496 | valid_rmsle: 0.01426 | valid_mae: 0.41482 | valid_rmse: 0.49575 | valid_mse: 0.24577 |  0:00:55s\n",
      "epoch 5  | loss: 0.22653 | train_rmsle: 0.01207 | train_mae: 0.37054 | train_rmse: 0.44892 | train_mse: 0.20153 | valid_rmsle: 0.01184 | valid_mae: 0.37351 | valid_rmse: 0.44917 | valid_mse: 0.20176 |  0:01:05s\n",
      "epoch 6  | loss: 0.17237 | train_rmsle: 0.00994 | train_mae: 0.32646 | train_rmse: 0.4017  | train_mse: 0.16136 | valid_rmsle: 0.00972 | valid_mae: 0.32939 | valid_rmse: 0.40182 | valid_mse: 0.16146 |  0:01:15s\n",
      "epoch 7  | loss: 0.1474  | train_rmsle: 0.00901 | train_mae: 0.32429 | train_rmse: 0.39248 | train_mse: 0.15404 | valid_rmsle: 0.00885 | valid_mae: 0.32581 | valid_rmse: 0.39313 | valid_mse: 0.15455 |  0:01:25s\n",
      "epoch 8  | loss: 0.11919 | train_rmsle: 0.00926 | train_mae: 0.32116 | train_rmse: 0.39205 | train_mse: 0.1537  | valid_rmsle: 0.0089  | valid_mae: 0.3207  | valid_rmse: 0.38932 | valid_mse: 0.15157 |  0:01:35s\n",
      "epoch 9  | loss: 0.09379 | train_rmsle: 0.00956 | train_mae: 0.3165  | train_rmse: 0.39208 | train_mse: 0.15372 | valid_rmsle: 0.00905 | valid_mae: 0.31493 | valid_rmse: 0.38651 | valid_mse: 0.14939 |  0:01:45s\n",
      "epoch 10 | loss: 0.08205 | train_rmsle: 0.01081 | train_mae: 0.3421  | train_rmse: 0.41915 | train_mse: 0.17568 | valid_rmsle: 0.01038 | valid_mae: 0.34196 | valid_rmse: 0.41581 | valid_mse: 0.1729  |  0:01:55s\n",
      "epoch 11 | loss: 0.07339 | train_rmsle: 0.01113 | train_mae: 0.32904 | train_rmse: 0.41617 | train_mse: 0.17319 | valid_rmsle: 0.01068 | valid_mae: 0.33164 | valid_rmse: 0.41303 | valid_mse: 0.17059 |  0:02:05s\n",
      "epoch 12 | loss: 0.06607 | train_rmsle: 0.01138 | train_mae: 0.3391  | train_rmse: 0.42399 | train_mse: 0.17977 | valid_rmsle: 0.01099 | valid_mae: 0.3422  | valid_rmse: 0.42227 | valid_mse: 0.17831 |  0:02:15s\n",
      "epoch 13 | loss: 0.0631  | train_rmsle: 0.01116 | train_mae: 0.3212  | train_rmse: 0.41345 | train_mse: 0.17094 | valid_rmsle: 0.01078 | valid_mae: 0.32472 | valid_rmse: 0.41165 | valid_mse: 0.16945 |  0:02:25s\n",
      "epoch 14 | loss: 0.05666 | train_rmsle: 0.01037 | train_mae: 0.30601 | train_rmse: 0.3966  | train_mse: 0.15729 | valid_rmsle: 0.00998 | valid_mae: 0.30905 | valid_rmse: 0.39424 | valid_mse: 0.15542 |  0:02:35s\n",
      "epoch 15 | loss: 0.0566  | train_rmsle: 0.00989 | train_mae: 0.31175 | train_rmse: 0.39275 | train_mse: 0.15425 | valid_rmsle: 0.00952 | valid_mae: 0.31397 | valid_rmse: 0.3908  | valid_mse: 0.15272 |  0:02:45s\n",
      "epoch 16 | loss: 0.05665 | train_rmsle: 0.01029 | train_mae: 0.30552 | train_rmse: 0.39456 | train_mse: 0.15568 | valid_rmsle: 0.00982 | valid_mae: 0.30718 | valid_rmse: 0.39054 | valid_mse: 0.15252 |  0:02:55s\n",
      "epoch 17 | loss: 0.05698 | train_rmsle: 0.00951 | train_mae: 0.29525 | train_rmse: 0.37883 | train_mse: 0.14351 | valid_rmsle: 0.00907 | valid_mae: 0.2967  | valid_rmse: 0.37497 | valid_mse: 0.1406  |  0:03:05s\n",
      "epoch 18 | loss: 0.05655 | train_rmsle: 0.00975 | train_mae: 0.32259 | train_rmse: 0.39459 | train_mse: 0.1557  | valid_rmsle: 0.0094  | valid_mae: 0.32381 | valid_rmse: 0.39276 | valid_mse: 0.15426 |  0:03:15s\n",
      "epoch 19 | loss: 0.05066 | train_rmsle: 0.01035 | train_mae: 0.34252 | train_rmse: 0.41216 | train_mse: 0.16988 | valid_rmsle: 0.01006 | valid_mae: 0.3447  | valid_rmse: 0.41131 | valid_mse: 0.16917 |  0:03:26s\n",
      "epoch 20 | loss: 0.05171 | train_rmsle: 0.00968 | train_mae: 0.32949 | train_rmse: 0.39847 | train_mse: 0.15878 | valid_rmsle: 0.00938 | valid_mae: 0.33121 | valid_rmse: 0.39731 | valid_mse: 0.15785 |  0:03:38s\n",
      "epoch 21 | loss: 0.04873 | train_rmsle: 0.00911 | train_mae: 0.30378 | train_rmse: 0.37734 | train_mse: 0.14239 | valid_rmsle: 0.00874 | valid_mae: 0.30538 | valid_rmse: 0.37487 | valid_mse: 0.14052 |  0:03:48s\n",
      "epoch 22 | loss: 0.04317 | train_rmsle: 0.00914 | train_mae: 0.29557 | train_rmse: 0.37335 | train_mse: 0.13939 | valid_rmsle: 0.00875 | valid_mae: 0.29781 | valid_rmse: 0.37043 | valid_mse: 0.13722 |  0:03:58s\n",
      "epoch 23 | loss: 0.04685 | train_rmsle: 0.00848 | train_mae: 0.2908  | train_rmse: 0.36251 | train_mse: 0.13141 | valid_rmsle: 0.00813 | valid_mae: 0.29283 | valid_rmse: 0.36025 | valid_mse: 0.12978 |  0:04:09s\n",
      "epoch 24 | loss: 0.04352 | train_rmsle: 0.00828 | train_mae: 0.29858 | train_rmse: 0.36507 | train_mse: 0.13328 | valid_rmsle: 0.008   | valid_mae: 0.30108 | valid_rmse: 0.36405 | valid_mse: 0.13253 |  0:04:20s\n",
      "epoch 25 | loss: 0.04192 | train_rmsle: 0.00847 | train_mae: 0.29758 | train_rmse: 0.36647 | train_mse: 0.1343  | valid_rmsle: 0.00815 | valid_mae: 0.29993 | valid_rmse: 0.36496 | valid_mse: 0.1332  |  0:04:30s\n",
      "epoch 26 | loss: 0.03902 | train_rmsle: 0.00849 | train_mae: 0.29925 | train_rmse: 0.36721 | train_mse: 0.13484 | valid_rmsle: 0.00816 | valid_mae: 0.30087 | valid_rmse: 0.36502 | valid_mse: 0.13324 |  0:04:41s\n",
      "epoch 27 | loss: 0.03885 | train_rmsle: 0.00851 | train_mae: 0.29397 | train_rmse: 0.36429 | train_mse: 0.13271 | valid_rmsle: 0.00814 | valid_mae: 0.29522 | valid_rmse: 0.36129 | valid_mse: 0.13053 |  0:04:50s\n",
      "epoch 28 | loss: 0.03811 | train_rmsle: 0.00815 | train_mae: 0.29167 | train_rmse: 0.35884 | train_mse: 0.12876 | valid_rmsle: 0.00781 | valid_mae: 0.2927  | valid_rmse: 0.35631 | valid_mse: 0.12696 |  0:04:59s\n",
      "epoch 29 | loss: 0.03502 | train_rmsle: 0.00837 | train_mae: 0.30185 | train_rmse: 0.3673  | train_mse: 0.13491 | valid_rmsle: 0.00804 | valid_mae: 0.30289 | valid_rmse: 0.36516 | valid_mse: 0.13334 |  0:05:09s\n",
      "epoch 30 | loss: 0.0363  | train_rmsle: 0.00803 | train_mae: 0.29584 | train_rmse: 0.36042 | train_mse: 0.1299  | valid_rmsle: 0.00769 | valid_mae: 0.2959  | valid_rmse: 0.35796 | valid_mse: 0.12814 |  0:05:18s\n",
      "epoch 31 | loss: 0.03836 | train_rmsle: 0.00759 | train_mae: 0.27664 | train_rmse: 0.34364 | train_mse: 0.11809 | valid_rmsle: 0.00721 | valid_mae: 0.27634 | valid_rmse: 0.33982 | valid_mse: 0.11547 |  0:05:28s\n",
      "epoch 32 | loss: 0.03696 | train_rmsle: 0.00718 | train_mae: 0.26278 | train_rmse: 0.33062 | train_mse: 0.10931 | valid_rmsle: 0.00677 | valid_mae: 0.2617  | valid_rmse: 0.32571 | valid_mse: 0.10609 |  0:05:37s\n",
      "epoch 33 | loss: 0.03784 | train_rmsle: 0.0076  | train_mae: 0.28907 | train_rmse: 0.35051 | train_mse: 0.12286 | valid_rmsle: 0.00725 | valid_mae: 0.28747 | valid_rmse: 0.34694 | valid_mse: 0.12037 |  0:05:46s\n",
      "epoch 34 | loss: 0.03428 | train_rmsle: 0.00726 | train_mae: 0.28788 | train_rmse: 0.34488 | train_mse: 0.11895 | valid_rmsle: 0.00694 | valid_mae: 0.28616 | valid_rmse: 0.34164 | valid_mse: 0.11672 |  0:05:56s\n",
      "epoch 35 | loss: 0.03229 | train_rmsle: 0.00729 | train_mae: 0.2704  | train_rmse: 0.33535 | train_mse: 0.11246 | valid_rmsle: 0.0069  | valid_mae: 0.26876 | valid_rmse: 0.33089 | valid_mse: 0.10949 |  0:06:05s\n",
      "epoch 36 | loss: 0.0309  | train_rmsle: 0.00713 | train_mae: 0.2707  | train_rmse: 0.33325 | train_mse: 0.11105 | valid_rmsle: 0.00674 | valid_mae: 0.2688  | valid_rmse: 0.32866 | valid_mse: 0.10802 |  0:06:14s\n",
      "epoch 37 | loss: 0.02865 | train_rmsle: 0.00633 | train_mae: 0.24897 | train_rmse: 0.31098 | train_mse: 0.09671 | valid_rmsle: 0.00593 | valid_mae: 0.2464  | valid_rmse: 0.30542 | valid_mse: 0.09328 |  0:06:23s\n",
      "epoch 38 | loss: 0.02904 | train_rmsle: 0.00631 | train_mae: 0.25352 | train_rmse: 0.31236 | train_mse: 0.09757 | valid_rmsle: 0.00594 | valid_mae: 0.25102 | valid_rmse: 0.30763 | valid_mse: 0.09464 |  0:06:35s\n",
      "epoch 39 | loss: 0.02968 | train_rmsle: 0.00636 | train_mae: 0.25755 | train_rmse: 0.31563 | train_mse: 0.09962 | valid_rmsle: 0.00596 | valid_mae: 0.25425 | valid_rmse: 0.30989 | valid_mse: 0.09603 |  0:06:45s\n",
      "epoch 40 | loss: 0.0289  | train_rmsle: 0.00615 | train_mae: 0.26054 | train_rmse: 0.31441 | train_mse: 0.09885 | valid_rmsle: 0.00583 | valid_mae: 0.25799 | valid_rmse: 0.31039 | valid_mse: 0.09634 |  0:06:55s\n",
      "epoch 41 | loss: 0.02819 | train_rmsle: 0.00589 | train_mae: 0.2454  | train_rmse: 0.30226 | train_mse: 0.09136 | valid_rmsle: 0.00556 | valid_mae: 0.24348 | valid_rmse: 0.29777 | valid_mse: 0.08867 |  0:07:06s\n",
      "epoch 42 | loss: 0.02722 | train_rmsle: 0.00542 | train_mae: 0.2296  | train_rmse: 0.28637 | train_mse: 0.08201 | valid_rmsle: 0.0051  | valid_mae: 0.22794 | valid_rmse: 0.28216 | valid_mse: 0.07962 |  0:07:17s\n",
      "epoch 43 | loss: 0.02884 | train_rmsle: 0.00536 | train_mae: 0.21467 | train_rmse: 0.27822 | train_mse: 0.07741 | valid_rmsle: 0.00499 | valid_mae: 0.21218 | valid_rmse: 0.27257 | valid_mse: 0.0743  |  0:07:27s\n",
      "epoch 44 | loss: 0.02923 | train_rmsle: 0.00491 | train_mae: 0.22497 | train_rmse: 0.27621 | train_mse: 0.07629 | valid_rmsle: 0.00464 | valid_mae: 0.22292 | valid_rmse: 0.27234 | valid_mse: 0.07417 |  0:07:37s\n",
      "epoch 45 | loss: 0.02758 | train_rmsle: 0.00473 | train_mae: 0.21121 | train_rmse: 0.26582 | train_mse: 0.07066 | valid_rmsle: 0.00443 | valid_mae: 0.20898 | valid_rmse: 0.26125 | valid_mse: 0.06825 |  0:07:46s\n",
      "epoch 46 | loss: 0.02679 | train_rmsle: 0.00469 | train_mae: 0.20676 | train_rmse: 0.2626  | train_mse: 0.06896 | valid_rmsle: 0.00439 | valid_mae: 0.20479 | valid_rmse: 0.25822 | valid_mse: 0.06668 |  0:07:56s\n",
      "epoch 47 | loss: 0.02588 | train_rmsle: 0.00409 | train_mae: 0.19924 | train_rmse: 0.24838 | train_mse: 0.06169 | valid_rmsle: 0.00384 | valid_mae: 0.19736 | valid_rmse: 0.24477 | valid_mse: 0.05991 |  0:08:05s\n",
      "epoch 48 | loss: 0.02581 | train_rmsle: 0.0043  | train_mae: 0.22085 | train_rmse: 0.26441 | train_mse: 0.06991 | valid_rmsle: 0.00412 | valid_mae: 0.21974 | valid_rmse: 0.26263 | valid_mse: 0.06897 |  0:08:16s\n",
      "epoch 49 | loss: 0.02691 | train_rmsle: 0.00423 | train_mae: 0.20209 | train_rmse: 0.25212 | train_mse: 0.06356 | valid_rmsle: 0.00401 | valid_mae: 0.20162 | valid_rmse: 0.24998 | valid_mse: 0.06249 |  0:08:26s\n",
      "epoch 50 | loss: 0.02567 | train_rmsle: 0.00362 | train_mae: 0.19109 | train_rmse: 0.23507 | train_mse: 0.05526 | valid_rmsle: 0.00346 | valid_mae: 0.19075 | valid_rmse: 0.23409 | valid_mse: 0.0548  |  0:08:36s\n",
      "epoch 51 | loss: 0.02493 | train_rmsle: 0.00365 | train_mae: 0.19208 | train_rmse: 0.23657 | train_mse: 0.05597 | valid_rmsle: 0.00349 | valid_mae: 0.19194 | valid_rmse: 0.23539 | valid_mse: 0.05541 |  0:08:46s\n",
      "epoch 52 | loss: 0.02399 | train_rmsle: 0.00397 | train_mae: 0.18524 | train_rmse: 0.23881 | train_mse: 0.05703 | valid_rmsle: 0.00375 | valid_mae: 0.18425 | valid_rmse: 0.23617 | valid_mse: 0.05578 |  0:08:56s\n",
      "epoch 53 | loss: 0.02429 | train_rmsle: 0.00351 | train_mae: 0.19056 | train_rmse: 0.23412 | train_mse: 0.05481 | valid_rmsle: 0.00339 | valid_mae: 0.19127 | valid_rmse: 0.23404 | valid_mse: 0.05477 |  0:09:06s\n",
      "epoch 54 | loss: 0.0243  | train_rmsle: 0.0031  | train_mae: 0.18295 | train_rmse: 0.22318 | train_mse: 0.04981 | valid_rmsle: 0.00302 | valid_mae: 0.18411 | valid_rmse: 0.22392 | valid_mse: 0.05014 |  0:09:16s\n",
      "epoch 55 | loss: 0.02272 | train_rmsle: 0.00251 | train_mae: 0.16919 | train_rmse: 0.20427 | train_mse: 0.04173 | valid_rmsle: 0.00248 | valid_mae: 0.17056 | valid_rmse: 0.20597 | valid_mse: 0.04242 |  0:09:26s\n",
      "epoch 56 | loss: 0.02339 | train_rmsle: 0.00325 | train_mae: 0.17741 | train_rmse: 0.222   | train_mse: 0.04929 | valid_rmsle: 0.00313 | valid_mae: 0.17798 | valid_rmse: 0.22162 | valid_mse: 0.04912 |  0:09:37s\n",
      "epoch 57 | loss: 0.02225 | train_rmsle: 0.00315 | train_mae: 0.17164 | train_rmse: 0.21692 | train_mse: 0.04705 | valid_rmsle: 0.00303 | valid_mae: 0.17234 | valid_rmse: 0.21598 | valid_mse: 0.04665 |  0:09:47s\n",
      "epoch 58 | loss: 0.02149 | train_rmsle: 0.00281 | train_mae: 0.1599  | train_rmse: 0.20318 | train_mse: 0.04128 | valid_rmsle: 0.00269 | valid_mae: 0.16035 | valid_rmse: 0.20199 | valid_mse: 0.0408  |  0:09:58s\n",
      "epoch 59 | loss: 0.02205 | train_rmsle: 0.00271 | train_mae: 0.16356 | train_rmse: 0.20254 | train_mse: 0.04102 | valid_rmsle: 0.00261 | valid_mae: 0.16418 | valid_rmse: 0.20182 | valid_mse: 0.04073 |  0:10:08s\n",
      "epoch 60 | loss: 0.02182 | train_rmsle: 0.00232 | train_mae: 0.15229 | train_rmse: 0.18904 | train_mse: 0.03573 | valid_rmsle: 0.00225 | valid_mae: 0.15284 | valid_rmse: 0.18863 | valid_mse: 0.03558 |  0:10:18s\n",
      "epoch 61 | loss: 0.02189 | train_rmsle: 0.00258 | train_mae: 0.15866 | train_rmse: 0.19808 | train_mse: 0.03923 | valid_rmsle: 0.00249 | valid_mae: 0.15943 | valid_rmse: 0.19758 | valid_mse: 0.03904 |  0:10:28s\n",
      "epoch 62 | loss: 0.02159 | train_rmsle: 0.00241 | train_mae: 0.14295 | train_rmse: 0.18612 | train_mse: 0.03464 | valid_rmsle: 0.00232 | valid_mae: 0.14375 | valid_rmse: 0.1857  | valid_mse: 0.03448 |  0:10:37s\n",
      "epoch 63 | loss: 0.02159 | train_rmsle: 0.00221 | train_mae: 0.1538  | train_rmse: 0.18831 | train_mse: 0.03546 | valid_rmsle: 0.00212 | valid_mae: 0.15326 | valid_rmse: 0.18676 | valid_mse: 0.03488 |  0:10:48s\n",
      "epoch 64 | loss: 0.01995 | train_rmsle: 0.00216 | train_mae: 0.13785 | train_rmse: 0.17698 | train_mse: 0.03132 | valid_rmsle: 0.00207 | valid_mae: 0.13825 | valid_rmse: 0.17594 | valid_mse: 0.03095 |  0:10:58s\n",
      "epoch 65 | loss: 0.02064 | train_rmsle: 0.00208 | train_mae: 0.14936 | train_rmse: 0.18284 | train_mse: 0.03343 | valid_rmsle: 0.00202 | valid_mae: 0.15031 | valid_rmse: 0.18311 | valid_mse: 0.03353 |  0:11:08s\n",
      "epoch 66 | loss: 0.02012 | train_rmsle: 0.00187 | train_mae: 0.13175 | train_rmse: 0.16705 | train_mse: 0.02791 | valid_rmsle: 0.00179 | valid_mae: 0.13255 | valid_rmse: 0.16629 | valid_mse: 0.02765 |  0:11:17s\n",
      "epoch 67 | loss: 0.01995 | train_rmsle: 0.00159 | train_mae: 0.13076 | train_rmse: 0.16106 | train_mse: 0.02594 | valid_rmsle: 0.00157 | valid_mae: 0.1324  | valid_rmse: 0.16186 | valid_mse: 0.0262  |  0:11:27s\n",
      "epoch 68 | loss: 0.02312 | train_rmsle: 0.00173 | train_mae: 0.14342 | train_rmse: 0.17516 | train_mse: 0.03068 | valid_rmsle: 0.00174 | valid_mae: 0.14552 | valid_rmse: 0.17684 | valid_mse: 0.03127 |  0:11:37s\n",
      "epoch 69 | loss: 0.02311 | train_rmsle: 0.00271 | train_mae: 0.14137 | train_rmse: 0.19109 | train_mse: 0.03652 | valid_rmsle: 0.00261 | valid_mae: 0.14132 | valid_rmse: 0.19084 | valid_mse: 0.03642 |  0:11:47s\n",
      "epoch 70 | loss: 0.03398 | train_rmsle: 0.00163 | train_mae: 0.11296 | train_rmse: 0.15016 | train_mse: 0.02255 | valid_rmsle: 0.00159 | valid_mae: 0.11522 | valid_rmse: 0.15131 | valid_mse: 0.02289 |  0:11:57s\n",
      "epoch 71 | loss: 0.02225 | train_rmsle: 0.00143 | train_mae: 0.1324  | train_rmse: 0.1619  | train_mse: 0.02621 | valid_rmsle: 0.00146 | valid_mae: 0.13432 | valid_rmse: 0.16444 | valid_mse: 0.02704 |  0:12:06s\n",
      "epoch 72 | loss: 0.02077 | train_rmsle: 0.00142 | train_mae: 0.12419 | train_rmse: 0.15692 | train_mse: 0.02463 | valid_rmsle: 0.00144 | valid_mae: 0.12733 | valid_rmse: 0.15923 | valid_mse: 0.02536 |  0:12:15s\n",
      "epoch 73 | loss: 0.01897 | train_rmsle: 0.0018  | train_mae: 0.12897 | train_rmse: 0.16431 | train_mse: 0.027   | valid_rmsle: 0.00174 | valid_mae: 0.13064 | valid_rmse: 0.1643  | valid_mse: 0.02699 |  0:12:25s\n",
      "epoch 74 | loss: 0.01945 | train_rmsle: 0.00143 | train_mae: 0.12183 | train_rmse: 0.15207 | train_mse: 0.02313 | valid_rmsle: 0.00143 | valid_mae: 0.12435 | valid_rmse: 0.15392 | valid_mse: 0.02369 |  0:12:34s\n",
      "epoch 75 | loss: 0.0188  | train_rmsle: 0.0011  | train_mae: 0.10664 | train_rmse: 0.13345 | train_mse: 0.01781 | valid_rmsle: 0.00112 | valid_mae: 0.10925 | valid_rmse: 0.13603 | valid_mse: 0.0185  |  0:12:56s\n",
      "epoch 76 | loss: 0.01763 | train_rmsle: 0.00117 | train_mae: 0.09932 | train_rmse: 0.13038 | train_mse: 0.017   | valid_rmsle: 0.00119 | valid_mae: 0.10417 | valid_rmse: 0.13429 | valid_mse: 0.01803 |  0:13:09s\n",
      "epoch 77 | loss: 0.01815 | train_rmsle: 0.00113 | train_mae: 0.10791 | train_rmse: 0.13609 | train_mse: 0.01852 | valid_rmsle: 0.00119 | valid_mae: 0.11293 | valid_rmse: 0.14106 | valid_mse: 0.0199  |  0:13:18s\n",
      "epoch 78 | loss: 0.01659 | train_rmsle: 0.00101 | train_mae: 0.09942 | train_rmse: 0.12592 | train_mse: 0.01586 | valid_rmsle: 0.00104 | valid_mae: 0.10375 | valid_rmse: 0.13017 | valid_mse: 0.01694 |  0:13:27s\n",
      "epoch 79 | loss: 0.01833 | train_rmsle: 0.0012  | train_mae: 0.11751 | train_rmse: 0.14459 | train_mse: 0.02091 | valid_rmsle: 0.00126 | valid_mae: 0.12293 | valid_rmse: 0.15003 | valid_mse: 0.02251 |  0:13:39s\n",
      "epoch 80 | loss: 0.01939 | train_rmsle: 0.00112 | train_mae: 0.10391 | train_rmse: 0.13508 | train_mse: 0.01825 | valid_rmsle: 0.00116 | valid_mae: 0.10873 | valid_rmse: 0.13907 | valid_mse: 0.01934 |  0:13:53s\n",
      "epoch 81 | loss: 0.01935 | train_rmsle: 0.0013  | train_mae: 0.10256 | train_rmse: 0.13536 | train_mse: 0.01832 | valid_rmsle: 0.00127 | valid_mae: 0.10367 | valid_rmse: 0.13601 | valid_mse: 0.0185  |  0:14:02s\n",
      "epoch 82 | loss: 0.01999 | train_rmsle: 0.0011  | train_mae: 0.10246 | train_rmse: 0.13034 | train_mse: 0.01699 | valid_rmsle: 0.00111 | valid_mae: 0.10681 | valid_rmse: 0.13335 | valid_mse: 0.01778 |  0:14:13s\n",
      "epoch 83 | loss: 0.0168  | train_rmsle: 0.00103 | train_mae: 0.09805 | train_rmse: 0.12573 | train_mse: 0.01581 | valid_rmsle: 0.00105 | valid_mae: 0.10149 | valid_rmse: 0.12863 | valid_mse: 0.01654 |  0:14:27s\n",
      "epoch 84 | loss: 0.01681 | train_rmsle: 0.00098 | train_mae: 0.10663 | train_rmse: 0.13379 | train_mse: 0.0179  | valid_rmsle: 0.00105 | valid_mae: 0.11168 | valid_rmse: 0.13909 | valid_mse: 0.01935 |  0:14:38s\n",
      "epoch 85 | loss: 0.01782 | train_rmsle: 0.00108 | train_mae: 0.11    | train_rmse: 0.13603 | train_mse: 0.01851 | valid_rmsle: 0.00113 | valid_mae: 0.11499 | valid_rmse: 0.14117 | valid_mse: 0.01993 |  0:14:48s\n",
      "epoch 86 | loss: 0.01753 | train_rmsle: 0.00099 | train_mae: 0.1038  | train_rmse: 0.13189 | train_mse: 0.0174  | valid_rmsle: 0.00105 | valid_mae: 0.10881 | valid_rmse: 0.13714 | valid_mse: 0.01881 |  0:14:57s\n",
      "epoch 87 | loss: 0.01777 | train_rmsle: 0.00078 | train_mae: 0.09018 | train_rmse: 0.1159  | train_mse: 0.01343 | valid_rmsle: 0.00084 | valid_mae: 0.09534 | valid_rmse: 0.12141 | valid_mse: 0.01474 |  0:15:06s\n",
      "epoch 88 | loss: 0.01708 | train_rmsle: 0.00081 | train_mae: 0.0868  | train_rmse: 0.11205 | train_mse: 0.01256 | valid_rmsle: 0.00085 | valid_mae: 0.0901  | valid_rmse: 0.11628 | valid_mse: 0.01352 |  0:15:14s\n",
      "epoch 89 | loss: 0.01681 | train_rmsle: 0.0008  | train_mae: 0.09137 | train_rmse: 0.11743 | train_mse: 0.01379 | valid_rmsle: 0.00085 | valid_mae: 0.0947  | valid_rmse: 0.12256 | valid_mse: 0.01502 |  0:15:24s\n",
      "epoch 90 | loss: 0.01548 | train_rmsle: 0.00081 | train_mae: 0.08771 | train_rmse: 0.11312 | train_mse: 0.0128  | valid_rmsle: 0.00084 | valid_mae: 0.09151 | valid_rmse: 0.11759 | valid_mse: 0.01383 |  0:15:33s\n",
      "epoch 91 | loss: 0.01575 | train_rmsle: 0.00085 | train_mae: 0.09241 | train_rmse: 0.11839 | train_mse: 0.01402 | valid_rmsle: 0.0009  | valid_mae: 0.09746 | valid_rmse: 0.12374 | valid_mse: 0.01531 |  0:15:43s\n",
      "epoch 92 | loss: 0.01519 | train_rmsle: 0.00066 | train_mae: 0.08398 | train_rmse: 0.1086  | train_mse: 0.01179 | valid_rmsle: 0.00072 | valid_mae: 0.08884 | valid_rmse: 0.11469 | valid_mse: 0.01315 |  0:15:53s\n",
      "epoch 93 | loss: 0.01686 | train_rmsle: 0.00068 | train_mae: 0.08107 | train_rmse: 0.10501 | train_mse: 0.01103 | valid_rmsle: 0.00071 | valid_mae: 0.08441 | valid_rmse: 0.10895 | valid_mse: 0.01187 |  0:16:02s\n",
      "epoch 94 | loss: 0.01688 | train_rmsle: 0.00066 | train_mae: 0.08677 | train_rmse: 0.10936 | train_mse: 0.01196 | valid_rmsle: 0.00071 | valid_mae: 0.09    | valid_rmse: 0.1141  | valid_mse: 0.01302 |  0:16:11s\n",
      "epoch 95 | loss: 0.01555 | train_rmsle: 0.00072 | train_mae: 0.08386 | train_rmse: 0.10818 | train_mse: 0.0117  | valid_rmsle: 0.00077 | valid_mae: 0.08784 | valid_rmse: 0.11346 | valid_mse: 0.01287 |  0:16:20s\n",
      "epoch 96 | loss: 0.0157  | train_rmsle: 0.00077 | train_mae: 0.09171 | train_rmse: 0.11857 | train_mse: 0.01406 | valid_rmsle: 0.00084 | valid_mae: 0.09646 | valid_rmse: 0.12471 | valid_mse: 0.01555 |  0:16:29s\n",
      "epoch 97 | loss: 0.01594 | train_rmsle: 0.00092 | train_mae: 0.10564 | train_rmse: 0.13136 | train_mse: 0.01726 | valid_rmsle: 0.001   | valid_mae: 0.11104 | valid_rmse: 0.13805 | valid_mse: 0.01906 |  0:16:45s\n",
      "epoch 98 | loss: 0.01772 | train_rmsle: 0.00072 | train_mae: 0.08066 | train_rmse: 0.10594 | train_mse: 0.01122 | valid_rmsle: 0.00076 | valid_mae: 0.08438 | valid_rmse: 0.11097 | valid_mse: 0.01231 |  0:16:56s\n",
      "epoch 99 | loss: 0.0178  | train_rmsle: 0.00074 | train_mae: 0.0828  | train_rmse: 0.10761 | train_mse: 0.01158 | valid_rmsle: 0.00078 | valid_mae: 0.08681 | valid_rmse: 0.11216 | valid_mse: 0.01258 |  0:17:05s\n",
      "epoch 100| loss: 0.01739 | train_rmsle: 0.00078 | train_mae: 0.09188 | train_rmse: 0.11726 | train_mse: 0.01375 | valid_rmsle: 0.00083 | valid_mae: 0.09678 | valid_rmse: 0.12306 | valid_mse: 0.01514 |  0:17:14s\n",
      "epoch 101| loss: 0.01547 | train_rmsle: 0.00082 | train_mae: 0.09084 | train_rmse: 0.11832 | train_mse: 0.014   | valid_rmsle: 0.00088 | valid_mae: 0.09628 | valid_rmse: 0.12413 | valid_mse: 0.01541 |  0:17:23s\n",
      "epoch 102| loss: 0.01467 | train_rmsle: 0.00068 | train_mae: 0.08287 | train_rmse: 0.10745 | train_mse: 0.01155 | valid_rmsle: 0.00073 | valid_mae: 0.08818 | valid_rmse: 0.11405 | valid_mse: 0.01301 |  0:17:33s\n",
      "epoch 103| loss: 0.0148  | train_rmsle: 0.00057 | train_mae: 0.0756  | train_rmse: 0.09874 | train_mse: 0.00975 | valid_rmsle: 0.00063 | valid_mae: 0.08125 | valid_rmse: 0.106   | valid_mse: 0.01124 |  0:17:43s\n",
      "epoch 104| loss: 0.01542 | train_rmsle: 0.00056 | train_mae: 0.07847 | train_rmse: 0.10182 | train_mse: 0.01037 | valid_rmsle: 0.00064 | valid_mae: 0.08442 | valid_rmse: 0.10948 | valid_mse: 0.01198 |  0:17:55s\n",
      "epoch 105| loss: 0.01519 | train_rmsle: 0.00059 | train_mae: 0.07942 | train_rmse: 0.10319 | train_mse: 0.01065 | valid_rmsle: 0.00066 | valid_mae: 0.08569 | valid_rmse: 0.11069 | valid_mse: 0.01225 |  0:18:04s\n",
      "epoch 106| loss: 0.01562 | train_rmsle: 0.00057 | train_mae: 0.07868 | train_rmse: 0.10288 | train_mse: 0.01058 | valid_rmsle: 0.00064 | valid_mae: 0.08451 | valid_rmse: 0.11001 | valid_mse: 0.0121  |  0:18:13s\n",
      "epoch 107| loss: 0.01467 | train_rmsle: 0.00059 | train_mae: 0.0769  | train_rmse: 0.10057 | train_mse: 0.01011 | valid_rmsle: 0.00064 | valid_mae: 0.08167 | valid_rmse: 0.10703 | valid_mse: 0.01145 |  0:18:22s\n",
      "epoch 108| loss: 0.01545 | train_rmsle: 0.00054 | train_mae: 0.07697 | train_rmse: 0.10042 | train_mse: 0.01008 | valid_rmsle: 0.00061 | valid_mae: 0.08102 | valid_rmse: 0.10704 | valid_mse: 0.01146 |  0:18:31s\n",
      "epoch 109| loss: 0.01532 | train_rmsle: 0.0007  | train_mae: 0.08918 | train_rmse: 0.115   | train_mse: 0.01322 | valid_rmsle: 0.00078 | valid_mae: 0.09419 | valid_rmse: 0.1211  | valid_mse: 0.01466 |  0:18:41s\n",
      "epoch 110| loss: 0.01759 | train_rmsle: 0.00094 | train_mae: 0.09233 | train_rmse: 0.11923 | train_mse: 0.01422 | valid_rmsle: 0.00097 | valid_mae: 0.09615 | valid_rmse: 0.12446 | valid_mse: 0.01549 |  0:18:51s\n",
      "epoch 111| loss: 0.01816 | train_rmsle: 0.00054 | train_mae: 0.07718 | train_rmse: 0.09922 | train_mse: 0.00985 | valid_rmsle: 0.0006  | valid_mae: 0.08094 | valid_rmse: 0.10574 | valid_mse: 0.01118 |  0:19:00s\n",
      "epoch 112| loss: 0.01486 | train_rmsle: 0.00068 | train_mae: 0.08408 | train_rmse: 0.11208 | train_mse: 0.01256 | valid_rmsle: 0.00074 | valid_mae: 0.08861 | valid_rmse: 0.11792 | valid_mse: 0.01391 |  0:19:10s\n",
      "epoch 113| loss: 0.01421 | train_rmsle: 0.00051 | train_mae: 0.07355 | train_rmse: 0.09568 | train_mse: 0.00916 | valid_rmsle: 0.00058 | valid_mae: 0.07826 | valid_rmse: 0.10253 | valid_mse: 0.01051 |  0:19:19s\n",
      "epoch 114| loss: 0.01448 | train_rmsle: 0.00065 | train_mae: 0.08106 | train_rmse: 0.10575 | train_mse: 0.01118 | valid_rmsle: 0.0007  | valid_mae: 0.0859  | valid_rmse: 0.11121 | valid_mse: 0.01237 |  0:19:28s\n",
      "epoch 115| loss: 0.01596 | train_rmsle: 0.00054 | train_mae: 0.07451 | train_rmse: 0.09747 | train_mse: 0.0095  | valid_rmsle: 0.0006  | valid_mae: 0.07834 | valid_rmse: 0.10358 | valid_mse: 0.01073 |  0:19:38s\n",
      "epoch 116| loss: 0.0145  | train_rmsle: 0.00064 | train_mae: 0.08353 | train_rmse: 0.11054 | train_mse: 0.01222 | valid_rmsle: 0.00072 | valid_mae: 0.08823 | valid_rmse: 0.11661 | valid_mse: 0.0136  |  0:19:47s\n",
      "epoch 117| loss: 0.01639 | train_rmsle: 0.00061 | train_mae: 0.08044 | train_rmse: 0.10424 | train_mse: 0.01087 | valid_rmsle: 0.00068 | valid_mae: 0.08525 | valid_rmse: 0.11092 | valid_mse: 0.0123  |  0:19:56s\n",
      "epoch 118| loss: 0.01467 | train_rmsle: 0.00061 | train_mae: 0.07675 | train_rmse: 0.10171 | train_mse: 0.01035 | valid_rmsle: 0.0007  | valid_mae: 0.08156 | valid_rmse: 0.11086 | valid_mse: 0.01229 |  0:20:05s\n",
      "epoch 119| loss: 0.01552 | train_rmsle: 0.00093 | train_mae: 0.10902 | train_rmse: 0.13333 | train_mse: 0.01778 | valid_rmsle: 0.001   | valid_mae: 0.11299 | valid_rmse: 0.13774 | valid_mse: 0.01897 |  0:20:14s\n",
      "epoch 120| loss: 0.0188  | train_rmsle: 0.00069 | train_mae: 0.0833  | train_rmse: 0.10713 | train_mse: 0.01148 | valid_rmsle: 0.00076 | valid_mae: 0.08584 | valid_rmse: 0.11445 | valid_mse: 0.0131  |  0:20:23s\n",
      "epoch 121| loss: 0.01765 | train_rmsle: 0.00048 | train_mae: 0.07074 | train_rmse: 0.09328 | train_mse: 0.0087  | valid_rmsle: 0.00057 | valid_mae: 0.07597 | valid_rmse: 0.10201 | valid_mse: 0.01041 |  0:20:32s\n",
      "epoch 122| loss: 0.01408 | train_rmsle: 0.00075 | train_mae: 0.09483 | train_rmse: 0.11801 | train_mse: 0.01393 | valid_rmsle: 0.00081 | valid_mae: 0.09793 | valid_rmse: 0.1228  | valid_mse: 0.01508 |  0:20:42s\n",
      "epoch 123| loss: 0.01578 | train_rmsle: 0.00051 | train_mae: 0.07231 | train_rmse: 0.09421 | train_mse: 0.00888 | valid_rmsle: 0.00059 | valid_mae: 0.07748 | valid_rmse: 0.10238 | valid_mse: 0.01048 |  0:20:51s\n",
      "epoch 124| loss: 0.01321 | train_rmsle: 0.00063 | train_mae: 0.08656 | train_rmse: 0.10933 | train_mse: 0.01195 | valid_rmsle: 0.00069 | valid_mae: 0.0897  | valid_rmse: 0.11429 | valid_mse: 0.01306 |  0:21:00s\n",
      "epoch 125| loss: 0.01488 | train_rmsle: 0.00059 | train_mae: 0.07601 | train_rmse: 0.09831 | train_mse: 0.00966 | valid_rmsle: 0.00066 | valid_mae: 0.08047 | valid_rmse: 0.10613 | valid_mse: 0.01126 |  0:21:09s\n",
      "epoch 126| loss: 0.01476 | train_rmsle: 0.00066 | train_mae: 0.07746 | train_rmse: 0.10083 | train_mse: 0.01017 | valid_rmsle: 0.0007  | valid_mae: 0.08058 | valid_rmse: 0.1069  | valid_mse: 0.01143 |  0:21:18s\n",
      "epoch 127| loss: 0.01501 | train_rmsle: 0.00054 | train_mae: 0.07767 | train_rmse: 0.09907 | train_mse: 0.00981 | valid_rmsle: 0.0006  | valid_mae: 0.08144 | valid_rmse: 0.10484 | valid_mse: 0.01099 |  0:21:27s\n",
      "epoch 128| loss: 0.01277 | train_rmsle: 0.00042 | train_mae: 0.06763 | train_rmse: 0.08803 | train_mse: 0.00775 | valid_rmsle: 0.00049 | valid_mae: 0.07153 | valid_rmse: 0.09463 | valid_mse: 0.00895 |  0:21:36s\n",
      "epoch 129| loss: 0.0123  | train_rmsle: 0.00049 | train_mae: 0.06969 | train_rmse: 0.09263 | train_mse: 0.00858 | valid_rmsle: 0.00057 | valid_mae: 0.07461 | valid_rmse: 0.10102 | valid_mse: 0.01021 |  0:21:46s\n",
      "epoch 130| loss: 0.01397 | train_rmsle: 0.00046 | train_mae: 0.06914 | train_rmse: 0.08956 | train_mse: 0.00802 | valid_rmsle: 0.00052 | valid_mae: 0.0732  | valid_rmse: 0.09581 | valid_mse: 0.00918 |  0:21:55s\n",
      "epoch 131| loss: 0.01216 | train_rmsle: 0.00049 | train_mae: 0.07028 | train_rmse: 0.09239 | train_mse: 0.00854 | valid_rmsle: 0.00058 | valid_mae: 0.07547 | valid_rmse: 0.10087 | valid_mse: 0.01017 |  0:22:06s\n",
      "epoch 132| loss: 0.01212 | train_rmsle: 0.0004  | train_mae: 0.06554 | train_rmse: 0.08508 | train_mse: 0.00724 | valid_rmsle: 0.00049 | valid_mae: 0.07143 | valid_rmse: 0.09441 | valid_mse: 0.00891 |  0:22:18s\n",
      "epoch 133| loss: 0.01232 | train_rmsle: 0.00048 | train_mae: 0.06935 | train_rmse: 0.09071 | train_mse: 0.00823 | valid_rmsle: 0.00058 | valid_mae: 0.07535 | valid_rmse: 0.1011  | valid_mse: 0.01022 |  0:22:30s\n",
      "epoch 134| loss: 0.01332 | train_rmsle: 0.00056 | train_mae: 0.07996 | train_rmse: 0.10275 | train_mse: 0.01056 | valid_rmsle: 0.00065 | valid_mae: 0.08583 | valid_rmse: 0.11044 | valid_mse: 0.0122  |  0:22:44s\n",
      "epoch 135| loss: 0.01368 | train_rmsle: 0.00042 | train_mae: 0.06763 | train_rmse: 0.08805 | train_mse: 0.00775 | valid_rmsle: 0.00051 | valid_mae: 0.07307 | valid_rmse: 0.09763 | valid_mse: 0.00953 |  0:22:54s\n",
      "epoch 136| loss: 0.01214 | train_rmsle: 0.00043 | train_mae: 0.06609 | train_rmse: 0.0863  | train_mse: 0.00745 | valid_rmsle: 0.00051 | valid_mae: 0.07149 | valid_rmse: 0.09548 | valid_mse: 0.00912 |  0:23:04s\n",
      "epoch 137| loss: 0.01193 | train_rmsle: 0.00048 | train_mae: 0.06969 | train_rmse: 0.08962 | train_mse: 0.00803 | valid_rmsle: 0.00054 | valid_mae: 0.0737  | valid_rmse: 0.09629 | valid_mse: 0.00927 |  0:23:13s\n",
      "epoch 138| loss: 0.01306 | train_rmsle: 0.00056 | train_mae: 0.07806 | train_rmse: 0.09797 | train_mse: 0.0096  | valid_rmsle: 0.00064 | valid_mae: 0.08415 | valid_rmse: 0.10656 | valid_mse: 0.01135 |  0:23:23s\n",
      "epoch 139| loss: 0.01252 | train_rmsle: 0.00048 | train_mae: 0.07315 | train_rmse: 0.09255 | train_mse: 0.00857 | valid_rmsle: 0.00057 | valid_mae: 0.07902 | valid_rmse: 0.10154 | valid_mse: 0.01031 |  0:23:33s\n",
      "epoch 140| loss: 0.01361 | train_rmsle: 0.00051 | train_mae: 0.07313 | train_rmse: 0.09494 | train_mse: 0.00901 | valid_rmsle: 0.00058 | valid_mae: 0.07702 | valid_rmse: 0.10198 | valid_mse: 0.0104  |  0:23:42s\n",
      "epoch 141| loss: 0.0141  | train_rmsle: 0.00051 | train_mae: 0.0731  | train_rmse: 0.0951  | train_mse: 0.00904 | valid_rmsle: 0.00057 | valid_mae: 0.07748 | valid_rmse: 0.10114 | valid_mse: 0.01023 |  0:23:51s\n",
      "epoch 142| loss: 0.01492 | train_rmsle: 0.00081 | train_mae: 0.08765 | train_rmse: 0.11247 | train_mse: 0.01265 | valid_rmsle: 0.00087 | valid_mae: 0.09171 | valid_rmse: 0.11797 | valid_mse: 0.01392 |  0:24:00s\n",
      "epoch 143| loss: 0.01662 | train_rmsle: 0.00107 | train_mae: 0.11631 | train_rmse: 0.14182 | train_mse: 0.02011 | valid_rmsle: 0.00115 | valid_mae: 0.12162 | valid_rmse: 0.14747 | valid_mse: 0.02175 |  0:24:10s\n",
      "epoch 144| loss: 0.01855 | train_rmsle: 0.00076 | train_mae: 0.08618 | train_rmse: 0.11036 | train_mse: 0.01218 | valid_rmsle: 0.00078 | valid_mae: 0.08757 | valid_rmse: 0.11325 | valid_mse: 0.01283 |  0:24:20s\n",
      "epoch 145| loss: 0.01619 | train_rmsle: 0.00069 | train_mae: 0.07946 | train_rmse: 0.10414 | train_mse: 0.01085 | valid_rmsle: 0.00071 | valid_mae: 0.08176 | valid_rmse: 0.10756 | valid_mse: 0.01157 |  0:24:29s\n",
      "epoch 146| loss: 0.01604 | train_rmsle: 0.00056 | train_mae: 0.07959 | train_rmse: 0.10287 | train_mse: 0.01058 | valid_rmsle: 0.00061 | valid_mae: 0.08363 | valid_rmse: 0.1073  | valid_mse: 0.01151 |  0:24:38s\n",
      "epoch 147| loss: 0.01449 | train_rmsle: 0.00046 | train_mae: 0.0696  | train_rmse: 0.09116 | train_mse: 0.00831 | valid_rmsle: 0.00051 | valid_mae: 0.07268 | valid_rmse: 0.09564 | valid_mse: 0.00915 |  0:24:50s\n",
      "epoch 148| loss: 0.01299 | train_rmsle: 0.00047 | train_mae: 0.07076 | train_rmse: 0.09222 | train_mse: 0.0085  | valid_rmsle: 0.00053 | valid_mae: 0.07564 | valid_rmse: 0.09861 | valid_mse: 0.00972 |  0:25:02s\n",
      "epoch 149| loss: 0.01212 | train_rmsle: 0.00045 | train_mae: 0.06949 | train_rmse: 0.09145 | train_mse: 0.00836 | valid_rmsle: 0.00052 | valid_mae: 0.07432 | valid_rmse: 0.09763 | valid_mse: 0.00953 |  0:25:13s\n",
      "Stop training because you reached max_epochs = 150 with best_epoch = 132 and best_valid_mse = 0.00891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    }
   ],
   "source": [
    "model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.009059816208471365 RMSE: 0.0951830668158542 R2: 0.9598956845605661 MAE: 0.07284897751167234\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'TabNetRegressor' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[48], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mtest()\n",
      "Cell \u001b[1;32mIn[45], line 75\u001b[0m, in \u001b[0;36mModel.test\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     72\u001b[0m mae \u001b[39m=\u001b[39m mean_absolute_error(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_test, y_pred)\n\u001b[0;32m     74\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mMSE: \u001b[39m\u001b[39m{\u001b[39;00mmse\u001b[39m}\u001b[39;00m\u001b[39m RMSE: \u001b[39m\u001b[39m{\u001b[39;00mrmse\u001b[39m}\u001b[39;00m\u001b[39m R2: \u001b[39m\u001b[39m{\u001b[39;00mr2\u001b[39m}\u001b[39;00m\u001b[39m MAE: \u001b[39m\u001b[39m{\u001b[39;00mmae\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m---> 75\u001b[0m score \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mclf\u001b[39m.\u001b[39;49mscore(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mX_test, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my_test)\n\u001b[0;32m     76\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mScore:\u001b[39m\u001b[39m{\u001b[39;00mscore\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[0;32m     77\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m=====================================\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'TabNetRegressor' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "model.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20a32af23fa2dfa3c5d159e60107838eb3f09fc5f820c64a56f9f0f73009b4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
