{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_tabnet.tab_model import TabNetRegressor\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 1038893\n",
    "\n",
    "fix_random(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "root = \"../../data/ml-25m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Data Acquisition\n",
    "def get_data_from_csv(file: str, nrows=None):\n",
    "    if nrows:\n",
    "        df = pd.read_csv(f\"{root}/{file}\", nrows=nrows)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{root}/{file}\")\n",
    "    print(f\"Loaded ml-25m data: {root}/{file}\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ratings_from_csv(nrows=None):\n",
    "    path = \"ratings.csv\"\n",
    "\n",
    "    data = get_data_from_csv(path, nrows)\n",
    "    # data = get_data_from_csv(path)\n",
    "\n",
    "    data.drop(\"timestamp\", axis=1, inplace=True)\n",
    "    # todo: drop user id\n",
    "    #data.drop(\"userId\", axis=1, inplace=True)\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ml-25m data: ../../data/ml-25m/ratings.csv\n",
      "          userId  movieId  rating\n",
      "0              1      296     5.0\n",
      "1              1      306     3.5\n",
      "2              1      307     5.0\n",
      "3              1      665     5.0\n",
      "4              1      899     3.5\n",
      "...          ...      ...     ...\n",
      "25000090  162541    50872     4.5\n",
      "25000091  162541    55768     2.5\n",
      "25000092  162541    56176     2.0\n",
      "25000093  162541    58559     4.0\n",
      "25000094  162541    63876     5.0\n",
      "\n",
      "[25000095 rows x 3 columns]\n",
      "Loaded ml-25m data: ../../data/ml-25m/genome-scores.csv\n",
      "          movieId  tagId  relevance\n",
      "0               1      1    0.02875\n",
      "1               1      2    0.02375\n",
      "2               1      3    0.06250\n",
      "3               1      4    0.07575\n",
      "4               1      5    0.14075\n",
      "...           ...    ...        ...\n",
      "15584443   206499   1124    0.11000\n",
      "15584444   206499   1125    0.04850\n",
      "15584445   206499   1126    0.01325\n",
      "15584446   206499   1127    0.14025\n",
      "15584447   206499   1128    0.03350\n",
      "\n",
      "[15584448 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "def get_tag_relevances_from_csv(nrows=None):\n",
    "    path = \"genome-scores.csv\"\n",
    "\n",
    "    return get_data_from_csv(path, nrows)\n",
    "genome_scores_path = \"genome-scores.csv\"\n",
    "ratings_path = \"ratings.csv\"\n",
    "ratings = get_ratings_from_csv()\n",
    "print(ratings)\n",
    "genome_scores = get_tag_relevances_from_csv()\n",
    "print(genome_scores)\n",
    "# films = get_data_from_csv(f\"{root}/{ratings}\")[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA VISUALIZATION\n",
    "\n",
    "            # # Fill in missing values with zeros\n",
    "            # X.fillna(0, inplace=True)\n",
    "\n",
    "# FARE TEST CON AVG, STD_DEV\n",
    "def addColumnOperation(ratings,X):\n",
    "     # Compute the mean rating for each user\n",
    "     count_rating = ratings.groupby('movieId', as_index=False)['rating'].count()\n",
    "     std= ratings.groupby('movieId', as_index=False)['rating'].std()\n",
    "     std.fillna(0, inplace=True)\n",
    "     min_ratings= ratings.groupby('movieId', as_index=False)['rating'].min()\n",
    "     max_ratings= ratings.groupby('movieId', as_index=False)['rating'].max()\n",
    "     median= ratings.groupby('movieId', as_index=False)['rating'].median()\n",
    "     operation = pd.DataFrame({'movieId':count_rating['movieId'],'count_rating': count_rating['rating'], 'std': std['rating'], 'min': min_ratings['rating'], 'max': max_ratings['rating'], 'median': median['rating']}) \n",
    "     X = pd.merge(X, operation, on='movieId')\n",
    "     X.drop(\"movieId\", axis=1, inplace=True)\n",
    "     return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from pytorch_tabnet.augmentations import RegressionSMOTE\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "           \n",
    "\n",
    "class TabNet:\n",
    "    def __init__(self, ratings, relevance, seed=42,width_values = 8, steps = 3, learning_rate = 2e-2):\n",
    "        self.aug = RegressionSMOTE(p=0.2)\n",
    "        #! df['rating'] = df['rating'].astype('float16')\n",
    "\n",
    "        # Reduce genome-score size\n",
    "\n",
    "        # Pivot the relevance DataFrame to create a matrix of tag relevance scores for each movie\n",
    "        relevance_matrix = relevance.pivot_table(index='movieId', columns='tagId', values='relevance', fill_value=0)\n",
    "        # Merge the ratings and relevance data\n",
    "        mean_ratings = ratings.groupby('movieId', as_index=False)['rating'].mean()\n",
    "        X = mean_ratings.merge(relevance_matrix, on='movieId')\n",
    "        #X = addColumnOperation(ratings,X)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        ratings = None  \n",
    "        train = X\n",
    "        # mescolare le righe del DataFrame\n",
    "        X = X.sample(frac=1,random_state = seed).reset_index(drop=True)\n",
    "        \n",
    "        if \"Set\" not in train.columns:\n",
    "            train[\"Set\"] = np.random.choice([\"train\", \"valid\", \"test\"], p =[.8, .1, .1], size=(train.shape[0],))\n",
    "\n",
    "        features = [ col for col in train.columns if col not in [\"rating\", \"Set\"]]\n",
    "        target = \"rating\"\n",
    "        \n",
    "        train_indices = train[train.Set==\"train\"].index\n",
    "        valid_indices = train[train.Set==\"valid\"].index\n",
    "        test_indices = train[train.Set==\"test\"].index\n",
    "\n",
    "        self.X_train = train[features].values[train_indices]\n",
    "        self.y_train = train[target].values[train_indices].reshape(-1, 1)\n",
    "\n",
    "        self.X_valid = train[features].values[valid_indices]\n",
    "        self.y_valid = train[target].values[valid_indices].reshape(-1, 1)\n",
    "\n",
    "        self.X_test = train[features].values[test_indices]\n",
    "        self.y_test = train[target].values[test_indices].reshape(-1, 1)\n",
    "        \n",
    "        # Split the training data into training and validation sets    \n",
    "        self.model = TabNetRegressor(n_d = width_values, n_a = width_values , n_steps = steps, optimizer_params = dict(lr=learning_rate), seed=seed)        \n",
    "\n",
    "\n",
    "    def train(self,max_epochs = 150,batchsize = 1024):\n",
    "        self.model.fit(\n",
    "            X_train=self.X_train, y_train=self.y_train,\n",
    "            eval_set=[(self.X_train,self.y_train), (self.X_valid, self.y_valid)],\n",
    "            eval_name=['train', 'valid'],\n",
    "            eval_metric=['rmsle', 'mae', 'rmse', 'mse'],\n",
    "            max_epochs=max_epochs,\n",
    "            patience=20,\n",
    "            batch_size=batchsize, virtual_batch_size=1024,\n",
    "            num_workers=0,\n",
    "            drop_last=False,\n",
    "            augmentations=self.aug, #aug\n",
    "        ) \n",
    "\n",
    "    def test(self):\n",
    "        # Predict the labels of the test set: y_pred\n",
    "        y_pred = self.model.predict(self.X_test)\n",
    "\n",
    "        # Compute the mean squared error\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        rmse = mean_squared_error(self.y_test, y_pred, squared=False)\n",
    "        r2 = r2_score(self.y_test, y_pred)\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "\n",
    "        print(f\"MSE: {mse} RMSE: {rmse} R2: {r2} MAE: {mae}\")\n",
    "        print(\"=====================================\")\n",
    "        return r2,self.model\n",
    "    \n",
    "    def load(self,model):\n",
    "        self.model =TabNetRegressor()\n",
    "        self.model.load_model(model)\n",
    "    \n",
    "    def save(self,root,name):\n",
    "        self.model.save_model(f\"{root}/{name}.pt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    }
   ],
   "source": [
    "model = TabNet(ratings, genome_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batchsize: 512 width: 8 steps: 3 learning_rate: 0.02 max_epochs: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0  | loss: 4.46025 | train_rmsle: 0.04021 | train_mae: 0.7208  | train_rmse: 0.81555 | train_mse: 0.66513 | valid_rmsle: 0.0404  | valid_mae: 0.72188 | valid_rmse: 0.81982 | valid_mse: 0.6721  |  0:00:12s\n",
      "epoch 1  | loss: 0.35625 | train_rmsle: 0.07001 | train_mae: 0.9517  | train_rmse: 1.03806 | train_mse: 1.07756 | valid_rmsle: 0.07009 | valid_mae: 0.9534  | valid_rmse: 1.04034 | valid_mse: 1.08231 |  0:00:26s\n",
      "epoch 2  | loss: 0.13125 | train_rmsle: 0.04615 | train_mae: 0.78597 | train_rmse: 0.86657 | train_mse: 0.75094 | valid_rmsle: 0.04612 | valid_mae: 0.78725 | valid_rmse: 0.86821 | valid_mse: 0.75379 |  0:00:37s\n",
      "epoch 3  | loss: 0.08688 | train_rmsle: 0.02904 | train_mae: 0.62842 | train_rmse: 0.70378 | train_mse: 0.4953  | valid_rmsle: 0.02896 | valid_mae: 0.62847 | valid_rmse: 0.70513 | valid_mse: 0.49722 |  0:00:48s\n",
      "epoch 4  | loss: 0.07198 | train_rmsle: 0.01529 | train_mae: 0.45416 | train_rmse: 0.52158 | train_mse: 0.27204 | valid_rmsle: 0.01506 | valid_mae: 0.45263 | valid_rmse: 0.52062 | valid_mse: 0.27104 |  0:01:04s\n",
      "epoch 5  | loss: 0.06358 | train_rmsle: 0.00974 | train_mae: 0.35637 | train_rmse: 0.41792 | train_mse: 0.17466 | valid_rmsle: 0.00955 | valid_mae: 0.3554  | valid_rmse: 0.41679 | valid_mse: 0.17371 |  0:01:21s\n",
      "epoch 6  | loss: 0.0565  | train_rmsle: 0.00869 | train_mae: 0.33095 | train_rmse: 0.39127 | train_mse: 0.15309 | valid_rmsle: 0.00842 | valid_mae: 0.32888 | valid_rmse: 0.38873 | valid_mse: 0.15111 |  0:01:37s\n",
      "epoch 7  | loss: 0.05376 | train_rmsle: 0.00621 | train_mae: 0.26731 | train_rmse: 0.32311 | train_mse: 0.1044  | valid_rmsle: 0.00589 | valid_mae: 0.26374 | valid_rmse: 0.31844 | valid_mse: 0.10141 |  0:01:53s\n",
      "epoch 8  | loss: 0.0473  | train_rmsle: 0.0065  | train_mae: 0.26707 | train_rmse: 0.3247  | train_mse: 0.10543 | valid_rmsle: 0.00623 | valid_mae: 0.26522 | valid_rmse: 0.32143 | valid_mse: 0.10332 |  0:02:06s\n",
      "epoch 9  | loss: 0.04571 | train_rmsle: 0.00641 | train_mae: 0.27082 | train_rmse: 0.32606 | train_mse: 0.10632 | valid_rmsle: 0.00617 | valid_mae: 0.27074 | valid_rmse: 0.32316 | valid_mse: 0.10443 |  0:02:19s\n",
      "Stop training because you reached max_epochs = 10 with best_epoch = 7 and best_valid_mse = 0.10141\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pytorch_tabnet\\callbacks.py:172: UserWarning: Best weights from best epoch are automatically used!\n",
      "  warnings.warn(wrn_msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.10338123066782387 RMSE: 0.3215295175684868 R2: 0.5423711265419986 MAE: 0.26585070988038884\n",
      "=====================================\n",
      "Successfully saved model at model/512_8_3_0.02_10.pt.zip\n",
      "New best model: 512_8_3_0.02_10 with r2: 0.5423711265419986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\pytorch_tabnet\\abstract_model.py:75: UserWarning: Device used : cpu\n",
      "  warnings.warn(f\"Device used : {self.device}\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best model SCORE: 0.5423711265419986\n",
      "MSE: 0.10338123074564745 RMSE: 0.3215295176895077 R2: 0.5423711261975036 MAE: 0.26585070988038884\n",
      "=====================================\n",
      "(0.5423711261975036, TabNetRegressor(n_d=8, n_a=8, n_steps=3, gamma=1.3, cat_idxs=[], cat_dims=[], cat_emb_dim=1, n_independent=2, n_shared=2, epsilon=1e-15, momentum=0.02, lambda_sparse=0.001, seed=42, clip_value=1, verbose=1, optimizer_fn=<class 'torch.optim.adam.Adam'>, optimizer_params={'lr': 0.02}, scheduler_fn=None, scheduler_params={}, mask_type='sparsemax', input_dim=1129, output_dim=1, device_name='auto', n_shared_decoder=1, n_indep_decoder=1))\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "batchsize = [512,1024,2048]\n",
    "width = [8,16,32]\n",
    "steps = [3,5,7]\n",
    "learning_rate = [2e-2,1e-2,5e-3]\n",
    "max_epochs = [70,120,150,210]\n",
    "\n",
    "best_model_params = None \n",
    "best_r2 = 0\n",
    "\n",
    "for batchsize,width,steps,learning_rate,max_epochs in itertools.product(batchsize,width,steps,learning_rate,max_epochs):\n",
    "    print(f\"batchsize: {batchsize} width: {width} steps: {steps} learning_rate: {learning_rate} max_epochs: {max_epochs}\")\n",
    "    model = TabNet(ratings, genome_scores,width_values = width, steps = steps, learning_rate = learning_rate)\n",
    "    model.train(max_epochs = max_epochs,batchsize = batchsize)\n",
    "    r2score, instance = model.test()\n",
    "    if r2score > best_r2:\n",
    "        best_r2 = r2score\n",
    "        best_model_params = f'{batchsize}_{width}_{steps}_{learning_rate}_{max_epochs}'\n",
    "        model.save(\"model\",best_model_params)\n",
    "        print(f\"New best model: {best_model_params} with r2: {best_r2}\")\n",
    "\n",
    "model = TabNet(ratings,genome_scores)\n",
    "print(f'Best model SCORE: {best_r2}')\n",
    "model.load(f\"model/{best_model_params}.pt.zip\")\n",
    "print(model.test())\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "20a32af23fa2dfa3c5d159e60107838eb3f09fc5f820c64a56f9f0f73009b4f7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
