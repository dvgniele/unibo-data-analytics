{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import mean_squared_error, accuracy_score, mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.svm import LinearSVR, SVR\n",
    "from sklearn.model_selection import train_test_split,GridSearchCV\n",
    "        \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 1038893\n",
    "\n",
    "fix_random(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "root = \"../../data/ml-25m\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_csv(file: str, nrows=None):\n",
    "    if nrows:\n",
    "        df = pd.read_csv(f\"{root}/{file}\", nrows=nrows)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{root}/{file}\")\n",
    "    print(f\"Loaded ml-25m data: {root}/{file}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_ratings_from_csv(nrows=None):\n",
    "    path = \"ratings.csv\"\n",
    "\n",
    "    data = get_data_from_csv(path, nrows)\n",
    "    # data = get_data_from_csv(path)\n",
    "\n",
    "    data.drop(\"timestamp\", axis=1, inplace=True)\n",
    "    # todo: drop user id\n",
    "    #data.drop(\"userId\", axis=1, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_tag_relevances_from_csv(nrows=None):\n",
    "    path = \"genome-scores.csv\"\n",
    "\n",
    "    return get_data_from_csv(path, nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_scores_path = \"genome-scores.csv\"\n",
    "ratings_path = \"ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ml-25m data: ../../data/ml-25m/ratings.csv\n",
      "          userId  movieId  rating\n",
      "0              1      296     5.0\n",
      "1              1      306     3.5\n",
      "2              1      307     5.0\n",
      "3              1      665     5.0\n",
      "4              1      899     3.5\n",
      "...          ...      ...     ...\n",
      "25000090  162541    50872     4.5\n",
      "25000091  162541    55768     2.5\n",
      "25000092  162541    56176     2.0\n",
      "25000093  162541    58559     4.0\n",
      "25000094  162541    63876     5.0\n",
      "\n",
      "[25000095 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings = get_ratings_from_csv()\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ml-25m data: ../../data/ml-25m/genome-scores.csv\n",
      "          movieId  tagId  relevance\n",
      "0               1      1    0.02875\n",
      "1               1      2    0.02375\n",
      "2               1      3    0.06250\n",
      "3               1      4    0.07575\n",
      "4               1      5    0.14075\n",
      "...           ...    ...        ...\n",
      "15584443   206499   1124    0.11000\n",
      "15584444   206499   1125    0.04850\n",
      "15584445   206499   1126    0.01325\n",
      "15584446   206499   1127    0.14025\n",
      "15584447   206499   1128    0.03350\n",
      "\n",
      "[15584448 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "genome_scores = get_tag_relevances_from_csv()\n",
    "print(genome_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# films = get_data_from_csv(f\"{root}/{ratings}\")[]\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATA VISUALIZATION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "            # # Fill in missing values with zeros\n",
    "            # X.fillna(0, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addColumnOperation(ratings,X):\n",
    "     # Compute the mean rating for each user\n",
    "     count_rating = ratings.groupby('movieId', as_index=False)['rating'].count()\n",
    "     std= ratings.groupby('movieId', as_index=False)['rating'].std()\n",
    "     std.fillna(0, inplace=True)\n",
    "     min_ratings= ratings.groupby('movieId', as_index=False)['rating'].min()\n",
    "     max_ratings= ratings.groupby('movieId', as_index=False)['rating'].max()\n",
    "     median= ratings.groupby('movieId', as_index=False)['rating'].median()\n",
    "     operation = pd.DataFrame({'movieId':count_rating['movieId'],'count_rating': count_rating['rating'], 'std': std['rating'], 'min': min_ratings['rating'], 'max': max_ratings['rating'], 'median': median['rating']}) \n",
    "     X = pd.merge(X, operation, on='movieId')\n",
    "     X.drop(\"movieId\", axis=1, inplace=True)\n",
    "     return X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FARE TEST CON AVG, STD_DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SVM:\n",
    "    def __init__(self, ratings, relevance, seed=1038893):\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.svm import SVC\n",
    "        from sklearn.decomposition import PCA\n",
    "        # Pivot the relevance DataFrame to create a matrix of tag relevance scores for each movie\n",
    "        relevance_matrix = relevance.pivot_table(index='movieId', columns='tagId', values='relevance', fill_value=0)\n",
    "\n",
    "        # Compute the mean rating for each user\n",
    "        mean_ratings = ratings.groupby('movieId', as_index=False)['rating'].mean()\n",
    "        X = mean_ratings.merge(relevance_matrix, on='movieId')\n",
    "        X = addColumnOperation(ratings,X)\n",
    "        ratings = None\n",
    "        #X = X.drop('movieId', axis=1)\n",
    "        # Merge the ratings and relevance data\n",
    "   \n",
    "        X.columns = X.columns.astype(str)\n",
    "        print(X.columns)\n",
    "        y = X['rating']\n",
    "        X = X.drop('rating', axis=1)\n",
    "\n",
    "        # Split the data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "        #print(self.X_train.shape, self.X_test.shape, self.y_train.shape, self.y_test.shape)\n",
    "\n",
    "        # Initialize the SVM model\n",
    "        #self.svm = LinearSVR()\n",
    "        self.params = {'C': [0.1, 1, 10, 100],\n",
    "            'epsilon': [0.01, 0.1, 1, 10],\n",
    "            'loss': ['epsilon_insensitive', 'squared_epsilon_insensitive'],\n",
    "            'max_iter': [int(x) for x in np.linspace(start = 200, stop = 2000, num = 200)],\n",
    "            'random_state': [seed]\n",
    "          }\n",
    "\n",
    "    # Training\n",
    "    def train(self, num_epochs=10):\n",
    "        for epoch in range(num_epochs):\n",
    "            self.svm.fit(self.X_train, self.y_train)\n",
    "            self.test()\n",
    "        print('training finished.')\n",
    "\n",
    "    def tuning(self):\n",
    "        grid = GridSearchCV(estimator = self.svm, param_grid = self.params, cv = 5, n_jobs = -1, verbose = 2)\n",
    "        grid.fit(self.X_train, self.y_train)\n",
    "        print(grid.best_params_)\n",
    "        self.svm = grid.best_estimator_\n",
    "        \n",
    "\n",
    "    def test(self):\n",
    "        # Predict ratings for the test data\n",
    "        y_pred = self.svm.predict(self.X_test)\n",
    "\n",
    "        # Compute the mean squared error\n",
    "        mse = mean_squared_error(self.y_test, y_pred)\n",
    "        # Compute R^2\n",
    "        r2 = r2_score(self.y_test, y_pred)\n",
    "        # Compute the mean absolute error\n",
    "        mae = mean_absolute_error(self.y_test, y_pred)\n",
    "\n",
    "        print(f\"Mean squared error: {mse}\")\n",
    "        print(f\"R^2: {r2}\")\n",
    "        print(f\"Mean absolute error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['rating', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
      "       ...\n",
      "       '1124', '1125', '1126', '1127', '1128', 'count_rating', 'std', 'min',\n",
      "       'max', 'median'],\n",
      "      dtype='object', length=1134)\n"
     ]
    }
   ],
   "source": [
    "bs = SVM(ratings, genome_scores, SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bs.tuning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SVC()' (type <class 'sklearn.svm._classes.SVC'>) doesn't",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m bs\u001b[39m.\u001b[39;49mtrain(\u001b[39m5\u001b[39;49m)\n",
      "Cell \u001b[1;32mIn[19], line 39\u001b[0m, in \u001b[0;36mSVM.train\u001b[1;34m(self, num_epochs)\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m, num_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m):\n\u001b[0;32m     38\u001b[0m     \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m---> 39\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msvm\u001b[39m.\u001b[39;49mfit(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX_train, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49my_train)\n\u001b[0;32m     40\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtest()\n\u001b[0;32m     41\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mtraining finished.\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\pipeline.py:401\u001b[0m, in \u001b[0;36mPipeline.fit\u001b[1;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[0;32m    375\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Fit the model.\u001b[39;00m\n\u001b[0;32m    376\u001b[0m \n\u001b[0;32m    377\u001b[0m \u001b[39mFit all the transformers one after the other and transform the\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[39m    Pipeline with fitted steps.\u001b[39;00m\n\u001b[0;32m    399\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    400\u001b[0m fit_params_steps \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_check_fit_params(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params)\n\u001b[1;32m--> 401\u001b[0m Xt \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_params_steps)\n\u001b[0;32m    402\u001b[0m \u001b[39mwith\u001b[39;00m _print_elapsed_time(\u001b[39m\"\u001b[39m\u001b[39mPipeline\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_log_message(\u001b[39mlen\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m)):\n\u001b[0;32m    403\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_final_estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\pipeline.py:339\u001b[0m, in \u001b[0;36mPipeline._fit\u001b[1;34m(self, X, y, **fit_params_steps)\u001b[0m\n\u001b[0;32m    336\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_fit\u001b[39m(\u001b[39mself\u001b[39m, X, y\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mfit_params_steps):\n\u001b[0;32m    337\u001b[0m     \u001b[39m# shallow copy of steps - this should really be steps_\u001b[39;00m\n\u001b[0;32m    338\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msteps)\n\u001b[1;32m--> 339\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_steps()\n\u001b[0;32m    340\u001b[0m     \u001b[39m# Setup the memory\u001b[39;00m\n\u001b[0;32m    341\u001b[0m     memory \u001b[39m=\u001b[39m check_memory(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmemory)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.8_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python38\\site-packages\\sklearn\\pipeline.py:230\u001b[0m, in \u001b[0;36mPipeline._validate_steps\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    226\u001b[0m         \u001b[39mcontinue\u001b[39;00m\n\u001b[0;32m    227\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mhasattr\u001b[39m(t, \u001b[39m\"\u001b[39m\u001b[39mfit_transform\u001b[39m\u001b[39m\"\u001b[39m)) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(\n\u001b[0;32m    228\u001b[0m         t, \u001b[39m\"\u001b[39m\u001b[39mtransform\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    229\u001b[0m     ):\n\u001b[1;32m--> 230\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\n\u001b[0;32m    231\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mAll intermediate steps should be \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    232\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mtransformers and implement fit and transform \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    233\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mor be the string \u001b[39m\u001b[39m'\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m'\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    234\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m (type \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m) doesn\u001b[39m\u001b[39m'\u001b[39m\u001b[39mt\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m (t, \u001b[39mtype\u001b[39m(t))\n\u001b[0;32m    235\u001b[0m         )\n\u001b[0;32m    237\u001b[0m \u001b[39m# We allow last estimator to be None as an identity transformation\u001b[39;00m\n\u001b[0;32m    238\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[0;32m    239\u001b[0m     estimator \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    240\u001b[0m     \u001b[39mand\u001b[39;00m estimator \u001b[39m!=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mpassthrough\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    241\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(estimator, \u001b[39m\"\u001b[39m\u001b[39mfit\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    242\u001b[0m ):\n",
      "\u001b[1;31mTypeError\u001b[0m: All intermediate steps should be transformers and implement fit and transform or be the string 'passthrough' 'SVC()' (type <class 'sklearn.svm._classes.SVC'>) doesn't"
     ]
    }
   ],
   "source": [
    "bs.train(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean squared error: 0.20274983221301193\n",
      "R^2: 0.11921067083236414\n",
      "Mean absolute error: 0.1828557514124185\n"
     ]
    }
   ],
   "source": [
    "bs.test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87bd6c09cddab90a09f19a55e9245e3497687050bc7d26cfabaa798d009918f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
