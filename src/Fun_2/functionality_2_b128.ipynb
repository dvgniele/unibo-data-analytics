{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score, mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=DeprecationWarning) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_random(seed: int) -> None:\n",
    "    \"\"\"Fix all the possible sources of randomness.\n",
    "\n",
    "    Args:\n",
    "        seed: the seed to use.\n",
    "    \"\"\"\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True  # slower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cpu\n"
     ]
    }
   ],
   "source": [
    "SEED = 1038893\n",
    "\n",
    "fix_random(SEED)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device))\n",
    "\n",
    "root = \"../../data/ml-25m\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_csv(file: str, nrows=None):\n",
    "    if nrows:\n",
    "        df = pd.read_csv(f\"{root}/{file}\", nrows=nrows)\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{root}/{file}\")\n",
    "    print(f\"Loaded ml-25m data: {root}/{file}\")\n",
    "\n",
    "    return df\n",
    "\n",
    "def get_ratings_from_csv(nrows=None):\n",
    "    path = \"ratings.csv\"\n",
    "\n",
    "    data = get_data_from_csv(path, nrows)\n",
    "    # data = get_data_from_csv(path)\n",
    "\n",
    "    data.drop(\"timestamp\", axis=1, inplace=True)\n",
    "    # todo: drop user id\n",
    "    #data.drop(\"userId\", axis=1, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_tag_relevances_from_csv(nrows=None):\n",
    "    path = \"genome-scores.csv\"\n",
    "\n",
    "    return get_data_from_csv(path, nrows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "genome_scores_path = \"genome-scores.csv\"\n",
    "ratings_path = \"ratings.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ml-25m data: ../../data/ml-25m/ratings.csv\n",
      "          userId  movieId  rating\n",
      "0              1      296     5.0\n",
      "1              1      306     3.5\n",
      "2              1      307     5.0\n",
      "3              1      665     5.0\n",
      "4              1      899     3.5\n",
      "...          ...      ...     ...\n",
      "25000090  162541    50872     4.5\n",
      "25000091  162541    55768     2.5\n",
      "25000092  162541    56176     2.0\n",
      "25000093  162541    58559     4.0\n",
      "25000094  162541    63876     5.0\n",
      "\n",
      "[25000095 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "ratings = get_ratings_from_csv()\n",
    "print(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded ml-25m data: ../../data/ml-25m/genome-scores.csv\n",
      "          movieId  tagId  relevance\n",
      "0               1      1    0.02875\n",
      "1               1      2    0.02375\n",
      "2               1      3    0.06250\n",
      "3               1      4    0.07575\n",
      "4               1      5    0.14075\n",
      "...           ...    ...        ...\n",
      "15584443   206499   1124    0.11000\n",
      "15584444   206499   1125    0.04850\n",
      "15584445   206499   1126    0.01325\n",
      "15584446   206499   1127    0.14025\n",
      "15584447   206499   1128    0.03350\n",
      "\n",
      "[15584448 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "genome_scores = get_tag_relevances_from_csv()\n",
    "print(genome_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FARE TEST CON AVG, STD_DEV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    def __init__(self, ratings, relevance, seed=1038893, batch_size=32, hidden_size1=64, hidden_size2=32, lr=0.001):\n",
    "        # Pivot the relevance DataFrame to create a matrix of tag relevance scores for each movie\n",
    "        relevance_matrix = relevance.pivot_table(index='movieId', columns='tagId', values='relevance', fill_value=0)\n",
    "\n",
    "        # Compute the mean rating for each user\n",
    "        mean_ratings = ratings.groupby('movieId', as_index=False)['rating'].mean()\n",
    "\n",
    "        # Merge the ratings and relevance data\n",
    "        X = mean_ratings.merge(relevance_matrix, on='movieId')\n",
    "        #X = addColumnOperation(ratings,X)\n",
    "        X.columns = X.columns.astype(str)\n",
    "        \n",
    "        ratings = None\n",
    "        X = X.sample(frac=1,random_state=seed).reset_index(drop=True)\n",
    "        #X = X.drop('movieId', axis=1)\n",
    "        y = X['rating']\n",
    "        X = X.drop('movieId', axis=1)\n",
    "        X = X.drop('rating', axis=1)\n",
    "\n",
    "        \n",
    "        # Split the data into training and testing sets\n",
    "        self.X_train, self.X_test, self.y_train, self.y_test = train_test_split(X, y, test_size=0.2, random_state=seed)\n",
    "        self.X_valid, self.X_test, self.y_valid, self.y_test = train_test_split(self.X_test, self.y_test, test_size=0.5, random_state=seed)\n",
    "\n",
    "        self.X_test  = self.X_test.to_numpy()\n",
    "        self.X_train = self.X_train.to_numpy()\n",
    "        self.X_valid = self.X_valid.to_numpy()\n",
    "            \n",
    "        # Convert the data to PyTorch tensors\n",
    "        self.X_train = torch.tensor(self.X_train, dtype=torch.float32)\n",
    "        self.X_test = torch.tensor(self.X_test, dtype=torch.float32)\n",
    "        self.X_valid = torch.tensor(self.X_valid, dtype=torch.float32)\n",
    "        \n",
    "        self.y_test = np.array(self.y_test)\n",
    "        self.y_train = np.array(self.y_train)\n",
    "        self.y_valid = np.array(self.y_valid)\n",
    "        \n",
    "        self.y_test = torch.tensor(self.y_test, dtype=torch.float32)\n",
    "        self.y_train = torch.tensor(self.y_train, dtype=torch.float32)\n",
    "        self.y_valid = torch.tensor(self.y_valid, dtype=torch.float32)\n",
    "        \n",
    "        # Define the neural network architecture\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(X.shape[1], hidden_size1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size1, hidden_size2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden_size2, 1)\n",
    "        )\n",
    "\n",
    "        # Move the model to the GPU\n",
    "        self.model = self.model.to(device)\n",
    "\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            # Move the tensors to the GPU\n",
    "            self.X_train = self.X_train.to(device)\n",
    "            self.X_valid = self.X_valid.to(device)\n",
    "            self.X_test = self.X_test.to(device)\n",
    "            self.y_train = self.y_train.to(device)\n",
    "            self.y_valid = self.y_valid.to(device)\n",
    "            self.y_test = self.y_test.to(device)\n",
    "\n",
    "        # Define the loss function and optimizer\n",
    "        self.criterion = nn.MSELoss()\n",
    "        self.optimizer = optim.Adam(self.model.parameters(), lr=lr)\n",
    "\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "    def train(self, num_epochs):\n",
    "        # Iterate over the entire training dataset multiple times\n",
    "        for epoch in range(num_epochs):\n",
    "            start_time = time.time()\n",
    "            # Set the model to training mode\n",
    "            self.model.train()\n",
    "\n",
    "            # Shuffle the training data\n",
    "            indices = torch.randperm(len(self.X_train))\n",
    "            shuffled_X = self.X_train[indices]\n",
    "            shuffled_y = self.y_train[indices]\n",
    "\n",
    "            # Divide the training data into batches\n",
    "            for i in range(0, len(self.X_train), self.batch_size):\n",
    "                # Zero the gradients\n",
    "                self.optimizer.zero_grad()\n",
    "\n",
    "                # Compute the forward pass\n",
    "                batch_X = shuffled_X[i:i + self.batch_size]\n",
    "                batch_y = shuffled_y[i:i + self.batch_size]\n",
    "                #batch_X = self.X_train\n",
    "                #batch_y = self.y_train\n",
    "                \n",
    "                outputs = self.model(batch_X)\n",
    "\n",
    "                # Compute the loss\n",
    "                loss = self.criterion(outputs.squeeze(), batch_y)\n",
    "\n",
    "                # Compute the backward pass and update the weights\n",
    "                loss.backward()\n",
    "                self.optimizer.step()\n",
    "\n",
    "            # Evaluate the model on the validation data\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = self.model(self.X_test)\n",
    "                val_loss = self.criterion(val_outputs.squeeze(), self.y_test)\n",
    "\n",
    "\n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            # Print the training and validation loss\n",
    "            #print(f'Epoch {epoch + 1}/{num_epochs} - eta: {elapsed_time:.2f}s -\\tTrain Loss: {loss.item():.4f}, Val Loss: {val_loss.item():.4f}')\n",
    "\n",
    "    def test(self):\n",
    "    # Set the model to evaluation mode\n",
    "        self.model.eval()\n",
    "\n",
    "        # Disable gradient calculation to speed up inference\n",
    "        with torch.no_grad():\n",
    "            # Compute the predictions for the test data\n",
    "            y_pred = self.model(self.X_test).squeeze()\n",
    "\n",
    "            # Compute the test loss\n",
    "            test_loss = self.criterion(y_pred, self.y_test)\n",
    "\n",
    "            # Compute the root mean squared error (RMSE) of the test predictions\n",
    "            rmse = torch.sqrt(test_loss)\n",
    "\n",
    "            # Compute the mean squared error (MSE) of the test predictions\n",
    "            mse = test_loss.item()\n",
    "\n",
    "            # Compute the mean absolute error (MAE) of the test predictions\n",
    "            mae = nn.functional.l1_loss(y_pred, self.y_test).item()\n",
    "\n",
    "            # Compute R^2 score of the test predictions\n",
    "            ss_res = torch.sum(torch.square(y_pred - self.y_test))\n",
    "            ss_tot = torch.sum(torch.square(self.y_test - torch.mean(self.y_test)))\n",
    "            r2 = 1 - ss_res / ss_tot\n",
    "\n",
    "            # Print the test metrics\n",
    "            #print(f'Test RMSE: {rmse.item():.4f}')\n",
    "            #print(f'Test MSE: {mse:.4f}')\n",
    "            #print(f'Test MAE: {mae:.4f}')\n",
    "            #print(f'Test R^2 score: {r2.item():.4f}')\n",
    "        return  r2.item(), self.model\n",
    "    \n",
    "    def load(self,model):\n",
    "        self.model =model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'model = NeuralNetwork(ratings, \\n                        genome_scores,\\n                        seed=1038893, \\n                        batch_size=128, \\n                        hidden_size1=64, \\n                        hidden_size2=64, \\n                        lr=0.0005)\\n\\n\\nmodel.train(100)\\nmodel.test()'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "'''model = NeuralNetwork(ratings, \n",
    "                        genome_scores,\n",
    "                        seed=1038893, \n",
    "                        batch_size=128, \n",
    "                        hidden_size1=64, \n",
    "                        hidden_size2=64, \n",
    "                        lr=0.0005)\n",
    "\n",
    "\n",
    "model.train(100)\n",
    "model.test()'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9589004516601562 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "New best model: 128_64_64_0.0001_200\n",
      "[2/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9496766328811646 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[3/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9489186406135559 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[4/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9710853099822998 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "New best model: 128_64_64_0.001_200\n",
      "[5/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9667801260948181 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[6/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9676486849784851 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[7/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9707227349281311 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[8/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.969170868396759 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[9/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9686632752418518 => batchsize: 128, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[10/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9591404795646667 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[11/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9581845998764038 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[12/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9509159922599792 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[13/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9691396355628967 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[14/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9688903093338013 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[15/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9691054821014404 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[16/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9712249636650085 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "New best model: 128_64_128_0.01_200\n",
      "[17/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9754937887191772 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "New best model: 128_64_128_0.01_400\n",
      "[18/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.96419757604599 => batchsize: 128, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[19/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.961455225944519 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[20/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9599696397781372 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[21/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9511814117431641 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[22/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9710016250610352 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[23/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9717674255371094 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[24/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9706191420555115 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[25/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9708439111709595 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[26/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9660924077033997 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[27/324] START => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9690740704536438 => batchsize: 128, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[28/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9574301838874817 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[29/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9565370082855225 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[30/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9588345289230347 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[31/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9694247245788574 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[32/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9690941572189331 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[33/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9632899165153503 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[34/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9687987565994263 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[35/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9664174318313599 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[36/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9665631651878357 => batchsize: 128, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[37/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9541530013084412 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[38/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.951871395111084 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[39/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9548888802528381 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[40/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.963446855545044 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[41/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9701533913612366 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[42/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9717549085617065 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[43/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9591365456581116 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[44/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9641138911247253 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[45/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9698166251182556 => batchsize: 128, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[46/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9572227001190186 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[47/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9511342644691467 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[48/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9563659429550171 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[49/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9691647291183472 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[50/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9730829000473022 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[51/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9711742997169495 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[52/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9710830450057983 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[53/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9676933288574219 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[54/324] START => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9673632383346558 => batchsize: 128, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[55/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9578099846839905 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[56/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9563719034194946 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[57/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.960131824016571 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[58/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9634165167808533 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[59/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9658605456352234 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[60/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9609199166297913 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[61/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9712434411048889 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[62/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9661002159118652 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[63/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.962263286113739 => batchsize: 128, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[64/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9572076797485352 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[65/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.958841860294342 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[66/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9599007368087769 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[67/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9639683961868286 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[68/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9669451713562012 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[69/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9685556888580322 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[70/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9700142741203308 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[71/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9707027077674866 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[72/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.964224100112915 => batchsize: 128, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[73/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9563731551170349 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[74/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9562035799026489 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[75/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9596061110496521 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[76/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9688047170639038 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[77/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9713804125785828 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[78/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.971505880355835 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[79/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: -0.0005609989166259766 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[80/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9648362398147583 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[81/324] START => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9776840209960938 => batchsize: 128, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "New best model: 128_256_256_0.01_600\n",
      "[82/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9595072269439697 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[83/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9580475091934204 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[84/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9529323577880859 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[85/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9719287157058716 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[86/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9645518660545349 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[87/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9642200469970703 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[88/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9723506569862366 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[89/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9694748520851135 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[90/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9631612300872803 => batchsize: 256, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[91/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.963303804397583 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[92/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9474483728408813 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[93/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.947074830532074 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[94/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9715033173561096 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[95/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.96409010887146 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[96/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9639757871627808 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[97/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9745694398880005 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[98/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9672441482543945 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[99/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9743888974189758 => batchsize: 256, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[100/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9649065732955933 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[101/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9551240801811218 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[102/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9512106776237488 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[103/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9756858348846436 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[104/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9702107310295105 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[105/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9729359745979309 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[106/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: -0.0003998279571533203 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[107/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9722510576248169 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[108/324] START => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9775245189666748 => batchsize: 256, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[109/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.955328106880188 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[110/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.949104368686676 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[111/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9514288306236267 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[112/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.966551661491394 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[113/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9649142026901245 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[114/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9666047692298889 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[115/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9744797348976135 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[116/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9687014222145081 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[117/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9683307409286499 => batchsize: 256, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[118/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9563998579978943 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[119/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9520972967147827 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[120/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9488344192504883 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[121/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9647519588470459 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[122/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9645717740058899 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[123/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9647194743156433 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[124/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9710710644721985 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[125/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9687873721122742 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[126/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9761322736740112 => batchsize: 256, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[127/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.953855037689209 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[128/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9526172280311584 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[129/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9456691145896912 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[130/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9639440178871155 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[131/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9648668766021729 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[132/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9717561602592468 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[133/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9723161458969116 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[134/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.976191520690918 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[135/324] START => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9637578725814819 => batchsize: 256, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[136/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9580401182174683 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[137/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.956540048122406 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[138/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9551780223846436 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[139/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9641899466514587 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[140/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9614147543907166 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[141/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9585561752319336 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[142/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9710927605628967 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[143/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.971928596496582 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[144/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9696735143661499 => batchsize: 256, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[145/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9537025690078735 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[146/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9560880064964294 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[147/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9521942138671875 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[148/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9602788686752319 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[149/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9625781178474426 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[150/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9658651351928711 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[151/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9744407534599304 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[152/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9657555818557739 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[153/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9660987257957458 => batchsize: 256, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[154/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9551475048065186 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[155/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9535133242607117 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[156/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9545882344245911 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[157/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9662915468215942 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[158/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9635854363441467 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[159/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.968316376209259 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[160/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9741392731666565 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[161/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9679494500160217 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[162/324] START => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9740962982177734 => batchsize: 256, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[163/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9350337386131287 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[164/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9591395854949951 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[165/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9555331468582153 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[166/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9694637060165405 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[167/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9719810485839844 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[168/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9722649455070496 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[169/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9713188409805298 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[170/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9722536206245422 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[171/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9727193117141724 => batchsize: 512, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[172/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9484272599220276 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[173/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9573076963424683 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[174/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9509028196334839 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[175/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9722750782966614 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[176/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.970982551574707 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[177/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9663490056991577 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[178/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9664297699928284 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[179/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9704113602638245 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[180/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.966896653175354 => batchsize: 512, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[181/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9571436047554016 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[182/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9576629400253296 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[183/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9510012865066528 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[184/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9760974049568176 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[185/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9743214249610901 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[186/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9693278670310974 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[187/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: -0.009813785552978516 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[188/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.974411129951477 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[189/324] START => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9722909331321716 => batchsize: 512, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[190/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.951068639755249 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[191/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9564020037651062 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[192/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9456554055213928 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[193/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9642271995544434 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[194/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9647374153137207 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[195/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9639059901237488 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[196/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9442645311355591 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[197/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9734354615211487 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[198/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9718902707099915 => batchsize: 512, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[199/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9460880756378174 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[200/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.955554187297821 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[201/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9506294131278992 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[202/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9647161960601807 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[203/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9629946947097778 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[204/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9649618268013 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[205/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9741629958152771 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[206/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9719287157058716 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[207/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9665796160697937 => batchsize: 512, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[208/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9567042589187622 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[209/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9533550143241882 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[210/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9507270455360413 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[211/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9673004746437073 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[212/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.968384861946106 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[213/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.968092143535614 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[214/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9668835997581482 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[215/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9719677567481995 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[216/324] START => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9723076820373535 => batchsize: 512, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[217/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9534940123558044 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[218/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9526159763336182 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[219/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9534088373184204 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[220/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.968884289264679 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[221/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9628571271896362 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[222/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9619131684303284 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[223/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9692970514297485 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[224/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.966570258140564 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[225/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9323923587799072 => batchsize: 512, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[226/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9560214877128601 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[227/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.952046275138855 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[228/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.949575662612915 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[229/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9662127494812012 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[230/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9516310691833496 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[231/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9568357467651367 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[232/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9676586389541626 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[233/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9720149040222168 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[234/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9699901342391968 => batchsize: 512, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[235/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9562484622001648 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[236/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9485984444618225 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[237/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9530790448188782 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[238/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9639079570770264 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[239/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9562061429023743 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[240/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9604123830795288 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[241/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9742960929870605 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[242/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9708380103111267 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[243/324] START => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: -0.00575864315032959 => batchsize: 512, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[244/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.888109564781189 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[245/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9458478093147278 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[246/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9533007144927979 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[247/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9557470083236694 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[248/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9696839451789856 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[249/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9742028117179871 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[250/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9696111679077148 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[251/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9682621955871582 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[252/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9650793671607971 => batchsize: 1024, hidden_size1: 64, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[253/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9272346496582031 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[254/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9518778920173645 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[255/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9533379077911377 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[256/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9649555087089539 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[257/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9763266444206238 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[258/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9744001626968384 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[259/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9679123163223267 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[260/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9712371230125427 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[261/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9769895672798157 => batchsize: 1024, hidden_size1: 64, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[262/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9323664307594299 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[263/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9519158005714417 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[264/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.953637957572937 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[265/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9671312570571899 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[266/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9718345999717712 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[267/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9717290997505188 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[268/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9723674058914185 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[269/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9796283841133118 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "New best model: 1024_64_256_0.01_400\n",
      "[270/324] START => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: -0.00017881393432617188 => batchsize: 1024, hidden_size1: 64, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[271/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9091488122940063 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[272/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9525123238563538 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[273/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9550577402114868 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[274/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9562304615974426 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[275/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9695755839347839 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[276/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9649734497070312 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[277/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9558510184288025 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[278/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9687630534172058 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[279/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.976066529750824 => batchsize: 1024, hidden_size1: 128, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[280/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9276213049888611 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[281/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9483388662338257 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[282/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9547868371009827 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[283/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.962159276008606 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[284/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9655755162239075 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[285/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9676703214645386 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[286/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9690214991569519 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[287/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9271993041038513 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[288/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: -0.006450533866882324 => batchsize: 1024, hidden_size1: 128, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[289/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.937968909740448 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[290/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9470952153205872 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[291/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9514848589897156 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[292/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.966953694820404 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[293/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9636443257331848 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[294/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9590039253234863 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[295/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9350069165229797 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[296/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9671310186386108 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[297/324] START => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.969476580619812 => batchsize: 1024, hidden_size1: 128, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "[298/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.929721474647522 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 200\n",
      "[299/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9564444422721863 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 400\n",
      "[300/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9507551193237305 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.0001, num_epochs: 600\n",
      "[301/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9572070837020874 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 200\n",
      "[302/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9610313177108765 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 400\n",
      "[303/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9651578068733215 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.001, num_epochs: 600\n",
      "[304/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9634860157966614 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 200\n",
      "[305/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9739551544189453 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 400\n",
      "[306/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.96906977891922 => batchsize: 1024, hidden_size1: 256, hidden_size2: 64, lr: 0.01, num_epochs: 600\n",
      "[307/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9335002303123474 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 200\n",
      "[308/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9533419013023376 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 400\n",
      "[309/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9482534527778625 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.0001, num_epochs: 600\n",
      "[310/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9649544954299927 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 200\n",
      "[311/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9582599401473999 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 400\n",
      "[312/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9618270397186279 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.001, num_epochs: 600\n",
      "[313/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9580661058425903 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 200\n",
      "[314/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9733096957206726 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 400\n",
      "[315/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9739254713058472 => batchsize: 1024, hidden_size1: 256, hidden_size2: 128, lr: 0.01, num_epochs: 600\n",
      "[316/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "DONE: 0.9410605430603027 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 200\n",
      "[317/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "DONE: 0.9504101872444153 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 400\n",
      "[318/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "DONE: 0.9495610594749451 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.0001, num_epochs: 600\n",
      "[319/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "DONE: 0.9586744904518127 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 200\n",
      "[320/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "DONE: 0.9604578614234924 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 400\n",
      "[321/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "DONE: 0.9525328874588013 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.001, num_epochs: 600\n",
      "[322/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "DONE: 0.9475464224815369 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 200\n",
      "[323/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "DONE: 0.9727449417114258 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 400\n",
      "[324/324] START => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "DONE: 0.9747456908226013 => batchsize: 1024, hidden_size1: 256, hidden_size2: 256, lr: 0.01, num_epochs: 600\n",
      "============================================================\n",
      "Best model SCORE: 0.9796283841133118\n",
      "(0.9796283841133118, Sequential(\n",
      "  (0): Linear(in_features=1128, out_features=64, bias=True)\n",
      "  (1): ReLU()\n",
      "  (2): Linear(in_features=64, out_features=256, bias=True)\n",
      "  (3): ReLU()\n",
      "  (4): Linear(in_features=256, out_features=1, bias=True)\n",
      "))\n"
     ]
    }
   ],
   "source": [
    "import itertools\n",
    "\n",
    "batchsize = [128,256,512,1024]\t\n",
    "hidden_size1 = [64,128,256]\n",
    "hidden_size2 = [64,128,256]\n",
    "lr = [0.0001,0.001,0.01]\n",
    "num_epochs = [200,400,600]\n",
    "\n",
    "\n",
    "best_model_params = None \n",
    "best_r2 = 0\n",
    "\n",
    "total_iterations = len(batchsize) * len(hidden_size1) * len(hidden_size2) * len(lr) * len(num_epochs)\n",
    "current_iteration = 0\n",
    "\n",
    "\n",
    "for batchsize,hidden_size1,hidden_size2,lr,num_epochs in itertools.product(batchsize,hidden_size1,hidden_size2,lr,num_epochs):\n",
    "    current_iteration += 1\n",
    "    print(f'[{current_iteration}/{total_iterations}] START => batchsize: {batchsize}, hidden_size1: {hidden_size1}, hidden_size2: {hidden_size2}, lr: {lr}, num_epochs: {num_epochs}')\n",
    "    log_name = f'NN_{batchsize}_{hidden_size1}_{hidden_size2}_{lr}_{num_epochs}'\n",
    "\n",
    "    writer = SummaryWriter('run/'+log_name)\n",
    "    model = NeuralNetwork(ratings, \n",
    "                        genome_scores,\n",
    "                        seed=1038893, \n",
    "                        batch_size=batchsize, \n",
    "                        hidden_size1=hidden_size1, \n",
    "                        hidden_size2=hidden_size2, \n",
    "                        lr=lr)\n",
    "    model.train(num_epochs)\n",
    "    r2, model_instance  = model.test()\n",
    "    writer.add_hparams({'batchsize': batchsize, 'hidden_size1': hidden_size1, 'hidden_size2': hidden_size2, 'lr': lr, 'num_epochs': num_epochs}, {'metrics/r2': r2})\n",
    "    print(f'DONE: {r2} => batchsize: {batchsize}, hidden_size1: {hidden_size1}, hidden_size2: {hidden_size2}, lr: {lr}, num_epochs: {num_epochs}')\n",
    "    \n",
    "    if r2 > best_r2:\n",
    "        best_r2 = r2\n",
    "        best_model_params = f'{batchsize}_{hidden_size1}_{hidden_size2}_{lr}_{num_epochs}'\n",
    "        torch.save(model_instance, f'model\\model_{batchsize}_{hidden_size1}_{hidden_size2}_{lr}_{num_epochs}.pt')\n",
    "        print(f'New best model: {best_model_params}')\n",
    "    writer.flush()\n",
    "writer.close()\n",
    "print('============================================================')\n",
    "model = NeuralNetwork(ratings,genome_scores)\n",
    "print(f'Best model SCORE: {best_r2}')\n",
    "model.load(torch.load(f'model/model_{best_model_params}.pt'));\n",
    "print(model.test())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "87bd6c09cddab90a09f19a55e9245e3497687050bc7d26cfabaa798d009918f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
